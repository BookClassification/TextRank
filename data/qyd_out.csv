id,title,summary
1,集成对抗性机器学习及其应用研究,"随着深度学习模型在人脸识别、安防监控、无人驾驶等安全敏感性任务中的广泛应用,围绕深度模型展开的攻防逐渐成为信息安全领域研究的热点。黑盒攻击作为现实世界中最为常用的攻击类型,在不知道模型具体结构、参数、使用的数据集等情况下,攻击者通过查询目标系统,充分利用反馈的输入输出对信息来训练替代模型并为之生成对抗样本,然后利用对抗样本的迁移性去攻击目标系统。本文提出了两类基于集成的黑盒攻击策略来阐述深度学习模型脆弱性的存在并有效证明了对抗样本的迁移性与集成替代模型差异性之间的关系。正因为对抗样本的存在,合理分析深度学习模型的脆弱性并设计出更加鲁棒的模型来对抗黑盒攻击成为迫切需要。传统基于单模型的对抗性训练防御算法在抵御黑盒攻击时性能十分有限,而基于多模型的集成对抗性训练却难以有效抵御强迁移性的对抗样本。为此,在原生的集成对抗性训练方法中融入对抗样本强度搜索策略,选出较优的对抗样本强度进行批量混合对抗性训练,并采用量化输入机制降低对抗样本空间维度,减缓对抗样本迁移性,真正实现不损失模型在测试集上精度的同时,保证抵御黑盒攻击的能力。本文在交通标识识别应用中验证了集成对抗性黑盒攻击策略、批量混合对抗性训练的有效性。另外,为了加快对抗样本的生成速率和集成对抗性训练过程,还尝试使用分布式框架实现深度神经网络的分布式训练。"
2,基于深度学习的遥感图像分类研究,"遥感图像数据的获取与处理已进入了大数据应用时代,准确地从不同类型数据中获取有用信息是遥感大数据处理及应用的核心内容。其中,遥感图像的分类与识别是其重要的应用领域。传统的遥感图像分类技术已无法胜任遥感大数据处理的新要求和任务。近年来发展的深度学习技术,在图像模式识别中获得了成功的应用,尤其在人机大赛中取得了佳绩。本文为解决遥感图像大数据的分类和应用问题,利用深度学习中的全卷积密集卷积网络(FC-DenseNet)以及基于空洞卷积(AC)、空洞空间金字塔池化(ASPP)和条件随机场(CRF)技术的DeepLab系统及改进的DeepLabV3模型对遥感图像分类问题展开了研究,并提出了基于梯度优化理论的FC-DenseNet和DeepLabV3两个模型。本文主要工作和内容如下:(1)建立适用于深度卷积神经网络分类训练的舰船遥感图像数据集,为深度学习模型的训练、测试和预测提供数据。同时,针对某些地物目标或区域数据量较少的问题,提出用数据增强的方式对少量数据进行扩充处理,使数据集达到满足深度卷积网络模型训练的要求。(2)对FC-DenseNet、DeepLabV3和DeepLabV3+等三个深度卷积分类模型进行了深入探讨和分析,设计了舰船遥感图像、INRIA航空遥感图像和城市遥感图像的分类实验。研究结果表明,深度卷积学习方法可以实现对遥感图像进行有效分类,并能获得较好的实验效果。(3)通过梯度下降优化算法提出了两种改进的优化模型,即优化的FC-DenseNet模型和DeepLabV3模型,并用前面建立的舰船遥感数据集和INRIA航空遥感图像数据集进行了测试实验。实验结果表明,在不同的梯度下降优化算法中,均方根反向传播(RMSProp)优化算法比自适应矩估计(Adam)算法、自适应学习速率(AdaDelta)算法和自适应梯度(AdaGrad)算法好,具有更好的鲁棒性和收敛性。"
3,基于机器视觉的黄瓜叶部病害程度检测系统研究,"植物病害是危害蔬菜品质的主要因素之一,很大程度上损害农民经济收入,黄瓜在其生长周期中极易受到病害威胁,大规模、高密度的种植方式给传统的病害防治措施带来了巨大挑战。传统的病害防治方法通过人眼观察或者侵染性实验,该方法具有效率低下、主观性强等缺点,并且过量地使用化学农药不仅会导致农药残留、植物抗药性的问题,同时对环境造成污染。机器视觉、人工智能等相关技术在农业领域被广泛应用,特别是在植物病害识别和果实品质检测等相关领域取得优异成果,故本文将不同病害程度的黄瓜叶片病害图像作为研究对象,利用机器视觉和深度学习等相关技术对黄瓜叶部病害程度分级识别方法进行研究,对提高农产品品质和保证农业生态环境的绿色、可持续发展具有重要意义。本论文针对自然背景下不同病害程度的3种黄瓜叶部主要病害类型的分级识别方法进行研究,主要包括以下内容:(1)对采集的不同病害程度的黄瓜叶片图像进行数据增强处理,将黄瓜叶片病害图像进行旋转、扭曲、镜像变换、添加噪声等多种几何变换方法并且不改变图像的类别和属性,扩充数据集样本,解决训练样本不足的问题,在训练中减少模型过拟合问题,并按照一定比例将创建的数据集划分为训练集和测试集。(2)为避免传统识别方法中复杂的图像预处理和人工设计特征过程,本文以VGG-16网络模型为基础构建一个改进的深度卷积神经网络(Convolutional Neural Networks,CNN)模型,该算法首先利用微型迁徙学习、带参数整流函数(PReLU)来构建深度卷积层,对不同尺寸的黄瓜叶片病害输入图像进行快速且稳定的特征提取;然后采用空间金字塔池化的方式实现固定大小的黄瓜病害特征图像的输出表示;最后替换全连接层中的参数以降低计算复杂度,通过Softmax实现黄瓜叶片病害程度识别。实验结果表明,本论文提出的网络模型具有较好的识别性能,对黄瓜叶部病害程度的分级识别率为87.24%。(3)针对CNN在训练过程中的过拟合问题,分析讨论了卷积核尺寸、梯度下降优化算法以及激活函数的参数选择对模型过拟合率的影响,并且调整网络模型中的参数进行实验对比,验证改进的深度CNN模型的图像分类识别性能。"
4,基于集成学习方法的药物―靶标相互作用预测及应用,"新药的研发过程往往周期长、耗资大且具有一定的随机性和盲目性。通常,一个新药从研发开始到成功上市平均耗时10-15年,平均耗费超过8亿美元。尽管药物开发的投资大,但产出并不理想。因此,加速创新药物的研发已成为全球的共识。作为药物研发的源头,药物-靶标相互作用的识别在药物发现过程中起着重要的作用。然而,传统的生物实验以及临床试验的方法不仅需要大量的人力、财力,同时还伴随着高的假阳性率和假阴性率。随着机器学习和生物信息学的快速发展,计算机辅助的药物-靶标相互作用预测方法已经成为一种快速、准确的药物靶标识别手段。本文采用基于集成学习的方法对药物-标相互作用进行预测研究,主要内容如下:(1)药物化合物和靶标蛋白序列的数值化表征。考虑到分子描述符可以根据药物的物理性质、原子数和化学键数这些指标将分子符号表示中编码的化学信息转换成有用的数值,从而可以区分不同的药物分子。因此,本文采用基于分子亚结构指纹的方式来表征药物化合物。为了尽可能多的包含靶标蛋白的生物进化信息,本文使用了位置特异性得分矩阵(Position-Specific Score Matrix,PSSM)来表示靶标蛋白序列。(2)对于数值化表征后的靶标蛋白评分矩阵,本文使用局部相位量化描述符和勒让德矩特征描述算法来客观、高效地抽取具有代表性的生物信息特征。从而获得药物与靶标蛋白的特征向量表示,为下一步药物-靶标相互作用的预测做准备。(3)基于集成学习的预测模型设计。本文采用了两种集成学习分类器,即旋转森林(Rotation Forest,RoF)和随机森林(Random forest,RF),通过分别与两种特征提取算法相结合来预测药物-靶标相互作用。最终,将所提出的模型应用于四个主流的金标准数据集,并与支持向量机分类器以及其他代表性的模型进行了对比。实验结果表明,本文提出的基于集成学习方法的预测模型可以有效地预测药物-靶标相互作用。"
5,基于稀疏表示的蛋白质相互作用预测及应用,"蛋白质作为生命体的基础物质之一,其功能发挥对于各种生命活动如新陈代谢、激素调节、细胞活动和酶的催化反应等都起到关键性的作用。因此,蛋白质相互作用研究不仅有利于了解生命运行机制,而且对于新药研发等方面都具有重要意义。然而,采用传统生物实验方法鉴定蛋白质之间的相互作用不仅成本高昂,而且还存在着较高的假阳性和假阴性率。随着信息技术的快速发展,采用智能计算的方法对蛋白质相互作用进行预测不仅速度快,而且准确率高,已成为预测蛋白质相互作用重要手段。本文的主要工作如下:(1)基于矩阵的特征提取方法选择。为了高效且全面地提取到蛋白质序列中重要的特征向量矩阵,本文分别使用了矩阵主成分分析和矩阵线性判别分析方法对经过数值化表示后的蛋白质序列信息进行特征提取。通过在H.pylori、S.cerevisiae和Human数据集上与其它特征提取方法的实验对比,证明了本文提出特征提取方法的有效性。(2)基于稀疏表示的预测模型设计。本文分别采用了稀疏表示模型和加权稀疏表示模型来实现蛋白质相互作用预测的功能。通过与支持向量机和其它模型的对比实验,发现基于稀疏表示的模型能够很好的与本文使用的特征提取方法相结合,并具有优秀的预测效果。(3)为了满足那些计算机编程能力较为薄弱的研究人员需求,本人利用MATLAB GUI技术设计开发了一套完整的基于稀疏表示的蛋白质相互作用预测系统供大家学习交流。"
6,基于改进模糊支持向量机的煤与瓦斯突出预测,"煤与瓦斯突出是在煤矿开采过程中发生的一种地质灾害,破坏性极强。如果能及时对突出做出准确地预测,可以在灾害发生前做出相应的防护措施,最大限度的保障井下工作者的生命安全。目前在煤与瓦斯突出预测方面应用最多的是支持向量机算法,具有较强的泛化能力。但是经过实际应用检验该算法仍然存在一些缺点:1.抗噪性不强,在预测过程中容易受到错误样本的误导做出错误的判断;2.受参数影响较大,盲目的选取参数会影响算法的分类效果。在突出影响因素选取方面,由于煤与瓦斯突出受多种因素共同影响且相互之间存在高度非线性关系,本文采用灰色关联度理论结合矿井突出实测数据进行计算从8种影响因素中选出5种作为主要影响因素,降低了之后预测的计算难度。在突出预测方法上面,针对以上两条支持向量机的缺点,本文提出了粒子群优化模糊支持向量机这种新型的煤与瓦斯突出预测方法。该方法首先通过模糊隶属度函数计算每个样本的模糊隶属度,降低噪声点对分类结果的影响;其次使用粒子群算法对模糊支持向量机进行参数寻优,虽然与其他常用的参数优化算法比如遗传算法、最小二乘法相比更为简洁,操作简便,但是粒子群算法仍存在容易陷入局部最优的缺点,本文中为解决这一问题对粒子群算法进行了改进:首先在粒子群算法中引入随迭代次数非线性减小的惯性权重提高算法的寻优能力,其次利用模拟退火算法使得粒子群算法中的粒子以一定的概率强行跳出局部最优陷阱。改进后的粒子群算法很大的提升了寻优效率,克服了传统分类模型中参数选取的盲目性。最后构建基于粒子群算法的模糊支持向量机预测模型,该模型首先通过对实测数据赋予相应的隶属度,减小错误样本对模型预测能力的影响;然后利用粒子群算法寻找最优参数,把参数对预测模型的影响降到最低。本文选择了粒子群优化支持向量机模型、模糊支持向量机模型、BP神经网络模型与本文模型在工作性能上进行比较,实验证明粒子群优化模糊支持向量机模型训练速度快,并且分类精度最高。利用MATLAB软件结合矿井实测突出数据对本文提出的改进的模糊支持向量机预测模型进行仿真,输出结果证明该算法相较于其他传统预测方法,训练速度最快,能够在更短的时间内对是否发生突出做出更精准的判断。该方法有效解决了传统预测方法中存在的抗噪性差、训练速度慢以及预测精度低等问题,具有较强的实用性。该论文有图19幅,表12个,参考文献86篇。"
7,考虑竞争和消费意图的电影首映日票房预测方法,"电影首映日票房影响着电影院线首映日后的排片计划,直接影响后续放映日票房,对总票房有重要影响。没有准确的首映日票房预测,电影院线难以对首映日合理排片,易于出现当日高空座率或座位不足,进而影响总票房。映前一周是首映日票房预测和依据预测结果排片的重要时点。因此,提出适合于映前一周的首映日票房预测方法具有重要现实意义。在预测变量类别少,可用数据不足的情况下进行预测是映前首映日票房预测的难点。为实现对首映日票房预测,需要对映前电影票房影响因素和适用算法的研究。首映日票房预测是对电影票房预测方法和需求预测方法的丰富,具有一定理论意义。针对映前一周电影首映日票房预测做了以下3方面研究。首先提出映前电影竞争和消费意图的量化方法。与映后电影票房预测不同,电影映前未产生票房实际数据,也没有观众口碑信息。这两类数据是目前映后电影票房预测方法中最常用数据。因此,映前票房预测可使用的信息类别远少于映后预测。为解决这一问题,考虑将映前可获取的竞争和消费意图信息纳入预测变量。从档期内高票房电影和同类型电影出发,量化上映电影竞争;从社交网络用户显式和隐式消费意图出发,量化潜在观众消费意图。其次,提出一种考虑竞争和消费意图的结合Lasso和XGBoost算法的票房预测方法。在上述研究结果基础上结合电影基本信息,建立了映前电影首映日票房预测变量集。随后在票房预测中引入结合Lasso和XGBoost算法的票房预测算法。充分考虑电影竞争和消费意图带来预测变量增多,易产生过拟合和预测精度下降问题。为解决该问题,在变量选取阶段应用Adaptive-Lasso算法进行特征抽取,缩减预测变量维度,降低训练时间。在预测阶段应用XGBoost算法,提高预测精度和预测稳定性。利用收集的10部电影数据检验,结果表明,在消费意图识别中使用SVM模型和经领域迁移训练后的CIMM模型对社交网络中存在的电影消费意图有较好的判别准确性;提出的结合Lasso和XGBoost的电影首映日票房预测方法与多元线性回归,支持向量回归等传统电影票房预测方法相比,有5%以上的预测精度优势,同时拥有更低的运算耗费;考虑电影竞争和消费意图后的预测准确性高于未考虑的情形。实验结果证明基于竞争和消费意图的电影首映日票房预测方法更适用于电影首映日票房预测。"
8,高校贫困生管理信息系统设计与研究,"教育精准扶贫是我国扶贫战略的重要组成部分,而针对高校学生的精准扶贫工作是国家教育精准扶贫的重要内容,倍受关注。然而,在高校教育精准扶贫工作中存在贫困学生数据信息量大、种类繁杂、扶贫业务人员数量有限等困难,因此,贫困学生信息准确采集与高效管理是高校教育精准扶贫工作顺利实施的基础。随着互联网与人工智能技术的发展,为了解决教育精准扶贫工作中遇到的众多困难时,结合机器学习算法的高校贫困生管理信息系统就成为是科学提高教育精准扶贫效果的重要手段。面向高校教育精准扶贫工作,本文基于Web技术与机器学习算法,设计了一个高校贫困生管理信息系统,通过数据模块与帮扶模块两大模块,实现了贫困生精确识别与扶贫信息高效管理。本文主要工作与创新点如下:在理论上,通过对现有贫困学生分类算法的研究,针对高校贫困学生的特征和高校学生管理特点,利用稀疏贝叶斯学习理论进一步提出概率判别分析,提出一种基于稀疏贝叶斯学习的贫困生识别算法,利用已有贫困学生信息数据训练模型,实现了对贫困学生识别的精准度。在技术上,通过分析高校教育精准扶贫业务工作的具体需求,采用了B/S系统架构、JAVA编程语言和MySQL数据库,融入了AJAX,HTML,JQUERY,ECHARTS及可视化技术,尝试设计基于Web的高校贫困生管理信息系统。该系统设计主要由数据模块与帮扶模块构成,其中数据模块根据功能不同又可以划分为贫困学生信息管理模块、扶贫项目信息管理模块与数据挖掘与分析模块三个子模块;而帮扶模块分为勤工助学模块、闲置共享模块、扶贫资助模块三个子模块,整个系统运行有效实现了数据管理与利用的一体。在应用上,通过对设计系统的实践应用,对于业务人员来说,信息管理较人工及软件辅助管理更便捷;对于学生来说,所判别的贫困生与学生实际情况符合度高。同时,系统的帮扶模块的设计,能够根据贫困生情况自主信息推送和资源共享。本系统的成功应用,能够为高校教育精准扶贫工作顺利实施奠定坚实的基础。"
9,基于数据挖掘的电力调度管理系统设计与实现,"目前因为我国的发展,电网规模也随之迅速扩大,与之同时,相应厂站也累积了大量的电力系统数据量,管理这些数据的难度也随之不断增加。一方面是因为电网结构比以往更加复杂,另一方面是因为供电质量要求的提高需要调度系统更加即时处理。与此同时,随着大数据时代的来临,合理分析使用电力数据,使之服务于电力生产与电力调度也成为了急需解决的课题。电力调度系统在电力的生产与传输这两部分里起到承接的作用,对电网高效率以及高质量的运行状态起到了关键性的作用。随着时代的前进,目前不仅需要对电厂、变电站和电力传输设备进行实时监控,同时也要能够对获得的监控数据进行分析。目前四川电网的调度系统还是半人工方式进行,这种传统落后的方式已经越来越不能适应目前的需求,严重限制了电力生产。本文针对目前这一问题,深入分析当前电力调度管理系统的现状和需求,开发一套同国调和网调联通,省级、地级和县级业务能够进行贯通,各业务系统信息共享的高效智能化电力调度管理系统,从而能够实现四川电网各部门数据的整合以及生产过程的流程化、规范化,确保电力生产和电网运行的健康、持续和稳定发展。为了解决电力系统中自动化程度不高、功能模块不统一以及缺乏对海量电力数据知识合理利用的问题,本文使用了一整套基于数据挖掘的电力调度管理系统,实现了电力调度系统中的几个功能,提高了电力调度系统的自动化水平,同时统合了电力调度系统的几个主要模块,并采用了基于支持向量机的回归算法,利用海量电力调度数据进行电力负荷预测,提高了电力调度的智能化水平。本文的工作第一部分对电力调度管理系统的历史发展和其中的问题进行了相关的介绍。根据过去电力调度系统的设计和当前的新的要求,对电力调度管理系统进行一个总体需求分析。下一部分则是使用到SOA技术来设计系统架构与数据平台,同时设计了主要功能模块调度管理、实时监控、生产分析、调度计划这些子系统。与此同时在电力调度机构里存储的大量电力相关的历史数据可以辅助电力调度系统进行相关决策,在本文中采用机器学习算法根据相关数据进行电力负荷预测。在整体系统的体系结构上,本文选用了面向服务的体系结构进行电力调度管理系统的框架进行设计。系统开发环境本文选用.NET Framework,数据库本文则选用了微软配套的SQL Server 2005,同时本文也采用了支持向量机的机器学习算法实现了智能化电力负荷预测。"
10,基于深度学习的牵引变电所视频图像多目标识别研究,"随着我国高速铁路技术的发展及其对自动化需求的提高,越来越多的牵引变电所向无人值守化发展,变电所中视频监控及巡检系统的智能化也变得尤为重要。所以本文的研究目的是为牵引变电所的远程智能巡检提供技术支持,主要研究如何实现牵引变电所视频图像的多目标识别。现有的牵引变电所监控图像的识别大都针对某一特定目标进行特征提取,无法完成多目标识别。并且不能同时完成鲁棒性好、速度快、准确性高的目标识别任务。本文正是针对这一任务展开的研究,不仅能做到鲁棒性好、速度快、准确性高的多目标识别任务,还能解决在很暗的状态下各色指示灯的颜色都发白,因而无法正确识别的问题。本文基于深度学习的理论,利用了深度神经网络的可迁移性,应用迁移学习的思想,克服了深度学习对数据和硬件的计算能力的依赖性。在计算能力和数据量都有限情况下的得到性能良好的可用于工程实践的牵引变电所视频图像的多目标识别模型。本文基于迁移学习的理论研究,利用SSD(Single Shot Mutibox Detector)和YOLOv2(You Only Look Once v2)模型,结合Python语言和TensorFlow平台,实现了识别准确度高、速度快和鲁棒性好的多目标识别方法。此模型迁移的方法针对牵引变电所视频图像中高压开关柜的仪表、分合指示灯状态以及高压隔离开关的分合状态都能进行自动识别。并且对像素图像的变化、外界环境和光线的变化和不同的摄像机角度都能准确、快速地完成识别功能。对变电所的无人值守化发展具有十分重要地工程意义。"
11,基于Faster R-CNN的公路路面病害检测算法的研究,"随着我国公路网的快速发展,公路安全问题得到越来越广泛的关注,为了保障人民生命安全、减少国家财产损失,公路基础设施需要得到有效养护,出现故障需要及时得到处理。由于天气的影响、车辆的碾压以及公路质量本身存在问题,公路基础设施故障发生率久高不下,为了更好更快地对公路基础设施故障进行处理,需要工作人员及时发现故障,而人工检测方式往往不能及时发现故障。所以,如何准确快速地对公路基础设施故障进行检测成了热点研究问题,公路路面病害检测是公路基础设施故障检测的热点研究问题之一。公路路面病害自动检测是一项具有挑战性的工作,基于数字图像处理方法的公路路面病害检测具有较好的检测效果,目前应用较为广泛。但是,传统的公路路面病害检测算法在图像深层次特征提取方面表现欠佳,难以达到预期检测效果,机器学习与深度学习的发展使公路路面病害检测效果得到了较大提升。针对以往检测算法检测效率低、定位精度差的问题,本文分析了公路路面病害类型与图像特点,提出了一种基于深度学习的检测算法。本文主要研究工作如下:首先,分析了公路路面病害检测领域国内外研究现状与目标检测领域研究现状,比较了国内外公路路面病害检测算法与目标检测算法,并对传统目标检测算法与基于深度学习的目标检测算法做了深入研究。在此基础上,提出了一种基于Faster R-CNN(Faster Region-Based Convolutional Neural Networks)的公路路面病害检测算法。其次,对Faster R-CNN的结构与工作原理进行研究。针对原Faster R-CNN结构中的非极大值抑制(Non Maximum Suppression,NMS)算法造成的同一幅图像中病害间相互抑制的问题,提出应用NMS的改进算法Soft-NMS对NMS算法进行替代,从而减少了检测框的冗余度与病害的漏检率,提升了检测精度。最后,为了进一步提升Faster R-CNN在公路路面病害检测上的性能,本文应用了数据增广方法与迁移学习方法。数据增广方法即通过几何变换增加了公路路面病害图像的数量与特征多样性。迁移学习方法即利用ImageNet数据集对Faster R-CNN进行预训练,并在预训练模型的基础上用制作的公路路面病害数据集对参数进行优化,最终用于公路路面病害检测中。这两种方法提升了算法模型的鲁棒性、减少了过拟合,从而提升了检测精度。"
12,无人驾驶智能伦理决策研究,"为了提高道路交通的安全性和通行效率,无人驾驶已成为未来道路交通发展的必然趋势。无人驾驶汽车将代替驾驶员实现驾驶决策、车辆控制并保证安全行驶等智能驾驶操作。为了使无人驾驶能够安全落地使用,必须能够保证无人驾驶汽车能够做出安全的驾驶决策并且符合人类伦理道德,尤其在处于决策两难困境下。因此,针对无人驾驶伦理困境问题,展开智能伦理决策研究具有重要的研究价值和现实意义。本文研究的内容得到了江西省杰出青年基金、江西省重点研发项目等相关科研项目的支持,以无人驾驶汽车为研究对象,以实现无人驾驶智能伦理决策为研究目标。在回顾与总结国内外研究现状的基础上,分别从无人驾驶决策分析和伦理决策问题建模等方面进行了比较系统和深入的分析研究,并在此基础上设计无人驾驶伦理决策GUI。其主要研究内容和结论如下:(1)以“电车困境”为伦理困境原型,分别对各种电车难题版本场景和目前无人驾驶伦理困境场景进行分析,得出了无人驾驶伦理决策困境主要特点;利用四阶段式伦理决策过程理论对无人驾驶伦理决策过程进行深入系统分析,并分别从个体因素、组织因素和决策问题本身对伦理决策过程影响因素进行分析,总结得出道德强度和决策风险度两个决策特征。(2)通过分析道德机器测试数据集特点,提取得到六种决策困境场景特征,并结合道德强度和决策风险度的含义,构建道德强度和决策风险度量化计算公式;本文主要目的为探索无人驾驶伦理决策解决方案,所以仅以属性数量来量化特征值的形式简化计算;根据六种决策困境场景特征对源数据集进行分类,利用两种决策特征量化计算公式对分类的数据集进行特征值的计算,以特征值为坐标作六种场景下的决策特征分布图,并总结决策规律。(3)综合决策特征分布特点和无人驾驶决策性能要求,本文选择模式识别经典方法贝叶斯学习为基本建模方法;根据贝叶斯学习基本原则建立无人驾驶伦理决策理论模型,并分别对六种场景数据通过模型训练得到最小错误率决策模型,进一步利用测试数据集对模型的可行性进行了验证;并为适应实际驾驶决策针对决策判断进行了修改。(4)利用MATLAB/GUI工具根据所需功能设计了无人驾驶伦理决策GUI决策界面和参数界面,并通过编写控制函数嵌入了伦理决策模型,构建了无人驾驶伦理决策GUI;通过抽样数据构建伦理决策场景的形式对GUI的真实性进行了验证。"
13,基于Spark框架的并行林业文本分类算法的研究与实现,"近年来,“互联网+”技术与林业领域逐渐融合,林业文本经历小型数据、数据扩展以及数据爆发三个阶段,表现出量级大、难以整合的特性。完成海量林业文本的高效分类,能为以林业文本为主体的相关研究包括林业知识图谱的构建、林业信息的主题推荐算法研究、林业信息的舆情分析等提供科学的技术支持与理论依据。然而,通过相关文献的调研可知,林业文本分类的相关研究进程与当前的林业文本领域需求是不相符的,其不足主要表现在两个方面:1)现存分类体系中的分类标签设定不科学、分类算法多基于小批量数据训练,导致分类模型的实际应用能力差;2)分类算法多基于单机环境实现,未考虑算法并行性,导致算法执行效率低,缺乏应对实际的大规模数据分类场景的能力。因此,通过采集更加丰富的林业语料,基于Spark大数据计算平台设计并行林业文本分类算法,以数据和任务的并行化来提高分类的执行效率具有现实性和紧迫性。本文拟将大数据分析技术与林业文本分析相结合,研究以往的林业文本分类标签并进行改进,结合互联网中的林业文本特性,增加分类粒度;并基于Spark计算框架实现XGBoost并行化算法,采用并行化的三种机器学习算法(逻辑回归、支持向量机以及决策树)进行对比实验,分别使用TF-IDF与Word2vec进行特征权重计算,从而进行8种算法组合实验,最后得出一套实用性较强的海量林业文本分类系统。实验结果表明:1)XGBoost与TF-IDF的组合方式的分类性能显著优于其他七种并行分类的组合算法;2)各算法在TF-IDF算法下的执行效率与精准度多优于Word2vec情形,说明目前在互联网中的涉林信息文本通过TF-IDF算法得到的词向量中包含的特征更能代表林业文本的特点;3)该XGBoost算法基于Spark的执行性能优于单机版本,更能有效应对海量林业文本的实时、准确分类。"
14,基于深度学习的植物知识图谱的构建,"随着信息技术的快速发展,特别是人工智能技术的广泛应用,如何处理网络中海量的数据,向用户提供易理解的知识成为研究的热点。知识图谱对实现数据到知识的转化有重要作用,其目的是对真实世界中存在的实体、概念及其关联关系进行描述。在林业领域,知识图谱可在语义检索、数据挖掘、预测分析、智能问答和决策支持等应用场景下发挥重要作用。本文在植物信息领域,研究基于多种数据源构建植物知识图谱的方法,在知识图谱的构建、命名实体识别和基于知识图谱的语义检索等方面展开工作。分析了领域知识图谱的构建过程,并阐述了涉及的关键技术。总结了中国植物志文本的特点,研究如何在其上进行属性命名实体的识别,提出了基于深度神经网络的命名实体识别方法。研究了植物信息相关的数据源,充分利用行业网站和百科网站的信息。利用不同数据源的信息构建植物知识图谱,将其应用于语义检索问题,结合可视化技术构建了基于植物知识图谱的语义检索系统。植物知识图谱作为林业领域知识图谱构建的尝试,可为用户提供智能、直观的语义检索。未来可在此基础上进一步融合其他林业知识,作为智慧林业发展的知识支撑,服务于林业领域的语义检索、知识推理和决策支持等应用。"
15,基于自适应神经模糊推理系统的二氧化碳通量模拟研究,"本文采用自适应神经模糊推理系统(Adaptive neuro-fuzzy inference system,ANFIS)进行碳通量模拟,以期获得较准确模拟,为碳通量研究提供一定的研究方法。基于八达岭站点2015至2017年数据,使用均基于集成学习的随机森林(Random forest,RF)、梯度提升决策树(Gradient boosting decision tree,GBDT)进行特征选择。基于特征选择结果,使用RF、GBDT、均基于不同内部函数的反向传递神经网络(Back propagation neural network,BPNN)、支持向量机(Support vector machine,SVM)、ANFIS进行碳通量模拟。使用决定系数(Coeffcient of determination,R2)、一致性指数(Index of agreement,IA)等指标进行模型评估,选出各个方法的最优模型并对比性能,分析ANFIS模拟可行性和不同内部函数的性能。综合RF和GDBT特征选择结果,全部因子作为输入,RF与GDBT的训练集与测试集R2均在0.79和0.77左右,选择出的5个重要因子分别为光合有效辐射、2号位置10cm 土壤温度平均值、2m处相对湿度平均值、2m处空气温度平均值、4号位置土壤含水量平均值。综合碳通量模拟结果,在ANFIS的内部隶属函数中,高斯函数优于广义S形函数,基于2个高斯函数的ANFIS与基于3个高斯函数的ANFIS性能相当。最优模型为基于2个高斯函数的ANFIS,其训练集与测试集R2为0.768和0.756,IA为0.928和0.922。在集成学习中,RF优于GDBT,其性能与ANFIS最优模型相当。在SVM的内部核函数中,高斯函数优于多项式函数和标准S形sigmoid函数。最优模型为基于高斯函数的SVM,其训练集与测试集R2为0.687和0.680,IA为0.903和0.900。在BPNN的内部激活函数中,tanh函数优于标准S形sigmoid函数。最优模型为基于tanh函数的BPNN,其性能与SVM最优模型相当。四个方法的最优模型在八达岭碳通量上的模拟结果表明,(1)ANFIS与RF性能相当且优于BPNN和SVM,ANFIS没有复杂的调参过程,在碳通量模拟领域具有一定的可行性。(2)综合BPNN、ANFIS、SVM的内部函数模拟结果,高斯函数优于S形函数,tanh函数优于标准S形sigmoid函数,广义S形函数优于标准S形sigmoid函数。(3)ANFIS性能与内部隶属函数个数不是正相关关系。(4)对比基于5个因子输入与全部因子输入的RF和GDBT模拟结果,5个因子贡献率约98%,验证了特征选择的正确性。"
16,桉树立地质量评价与适宜性研究,"立地条件对林木的生长具有重要影响,开展立地质量评价和树种适宜性研究是造林决策、适地适树等方面的研究热点。本文以广西壮族自治区桉树(Eucalyptus)人工林为研究对象,以一类连续清查固定样地数据、森林资源二类调查数据为基础数据,采用差分方程法构建了桉树立地质量评价模型,利用机器学习方法开展了树种适宜性研究。最后,运用模型解析和软件开发技术,实现了基于GIS的立地质量评价专家系统的构建。主要研究内容和结果如下:(1)针对桉树人工林展开有林地立地质量评价研究,构建了桉树立地质量评价模型。采用差分方程法,以6种理论方程为原型,导出10种差分形式的方程作为有林地立地质量评价模型的表达式。运用非线性回归技术,对10种有林地立地质量评价模型进行参数拟合。使用检验数据分别对10种模型进行精度验证,结果表明,与其余的9个模型进行对比,以Richards方程为原型的桉树立地质量评价模型具有较好的预测效果。将桉树基准年龄带入桉树立地质量评价模型,用来评价桉树有林地的立地质量。使用该模型对桉树有林地进行立地质量评价具有较强的实际意义。(2)研究机器学习分类算法在桉树适宜性分析中的应用,探索桉树的适宜性与立地因子之间的关系。分别运用朴素贝叶斯、支持向量机、随机森林共3种机器学习分类算法作为树种适宜性评价的方法,构建了 3种桉树适宜性评价模型。使用上述3种算法进行模型构建时,模型的输入均为地貌类型、海拔、坡向、坡位、坡度、枯枝落叶层厚度、腐殖质层厚度、土层厚度、石砾含量、成土母质,土壤类型共11个立地因子,输出均为适宜种植桉树或不适宜种植桉树。使用检验数据对模型的泛化能力进行对比,结果表明,与朴素贝叶斯、支持向量机算法相比,随机森林算法具有更好的分类效果。在研究区域内,海拔在200～350m之间,土层厚度在80～100cm之间的地区比较适宜桉树生长。机器学习分类算法可较好地评价立地是否适宜桉树的生长,能够运用到树种的适宜性研究中,为科学造林提供支持。(3)在上述研究的基础上,设计了基于GIS的立地质量评价专家系统的工作流程、系统功能结构、系统架构、系统数据库。研究并设计了系统实现的关键算法。将上述技术和方法进行集成,实现了有林地立地质量评价、树种适宜性评价等多种立地质量评价功能,研建了基于GIS的立地质量评价专家系统,并给出了系统的运行实例。"
17,基于极限学习机的潜热通量插补研究和应用,"潜热通量是地球表面能量预算的重要组成部分,也是水文循环中重要的一环。完整的潜热通量数据是估算作物生长模型和水文模型的重要参数,对于精准计算农作物需水量,农业用水调控和区域水资源管理有重要意义。但由于天气及其它原因,检测潜热通量数据的涡度相关仪会受到不同程度的损坏,造成数据的缺失,难以提供完整的潜热通量数据。因此,潜热通量缺失数据的补全就成了亟需解决的问题。传统的潜热通量插补模型需要大量的气象数据,计算过程也比较复杂。在气象资料缺乏的情况下难以精准计算。本文旨在研究当气象资料缺乏情况下采用机器学习方法对潜热通量缺失数据进行插补。本文的主要研究内容包括:(1)使用机器学习的方法对潜热通量影响因子进行特征分析和选取,并从生态学角度对结果进行分析论证。(2)基于选取的影响因子,分别使用极限学习机,误差反向传播神经网络,支持向量回归和XGBoost(eXtreme Gradient Boosting)等机器学习方法对缺失的数据进行插补,实验结果表明,XGBoost与极限学习机效果最佳,R2分别达到了 0.8672与0.8504,但极限学习机在参数调整上更加简便,因此选取极限学习机作为进一步研究的方法。(3)极限学习机初始参数随机导致结果不稳定,而且隐藏层节点过多时会出现过拟合情况,为了提高极限学习机的泛化性能引入核极限学习机,在使用遗传算法进行参数调优后核极限学习机的R2达到了 0.8545,同时在此基础上,根据潜热通量的特性进行分时段实验,结果显示最佳R2可达0.8836,是一种更合适的潜热通量插值补全策略。"
18,神经网络模型在碳通量数据模拟的研究与应用,"在陆地生态系统中,数据缺失是采用涡度相关技术监测通量数据时面临的普遍问题,如何准确地模拟陆地与大气间CO2通量数据交换量是当前全球气候变化研究的主要问题之一。使用机器学习技术持续探索通量数据模拟模型,更加精准地模拟结果,是提升数据集质量的前提和后续数据分析的基础。针对该问题,本文以北京奥林匹克城市森林公园的通量数据为研究对象,利用集成学习与神经网络技术对CO2通量进行分析与模拟,深入探究CO2通量的数据特征。论文主要研究成果可以概括为以下几个方面:(1)探究CO2通量数据的领域特征。本文采用XGBoost模型和基于梯度下降算法的神经网络模型对CO2通量数据的领域特征进行分析。结果表明,XGBoost模型能够对影响因子进行排序,基于梯度下降的人工神经网络可以有效地对环境因子进行特征响应分析。(2)探究CO2通量数据的时序性特征。分析CO2通量数据在不同尺度下(包括年尺度、季节性尺度、月平均日尺度)的变化情况及趋势并且计算自相关系数的平均值。结果表明,前3个时刻对于目标时刻的影响较为显著。(3)设计了基于特征融合的神经网络模型(ANN-LSTM),并与单特征模型模拟结果进行比较,包括反向传播神经网络,Moffat改进神经网络,基于单因子以及多因子的长短时记忆神经网络(Long short-term memory neural network,LSTM)。实验结果表明,本文所提出的ANN-LSTM集成模型在训练集上决定系数、均方根误差、平均绝对误差和一致性指数分别为0.792,3.012 μmol/(m2・s)、2.000 μmol(m2・s)和0.934,在测试集上决定系数为0.811,均方根误差为3.081 μmol/(m2・S),平均绝对误差为2.057μmol/(m2・s),一致性指数为0.937,相比于其他的模型,本方法的模拟精度最高。"
19,基于多源遥感与机器学习的密云水库水质参数反演研究,"近年来,我国在水污染防治方面取得了一定的成就,但依然不能避免一些河流湖泊的水质不断下降的情况,工业化程度越高的区域所面临的水污染问题越严重。密云水库是北京重要的地表水源地,在保护首都水源安全方面发挥着重要作用。然而,水库的水质近年来受到了来自上游水土流失和周边地区农业与人类活动所带来的一定程度的污染,密云水库水源地急需进一步的保护与治理,如何监测把握水质污染程度,有的放矢是保护与治理的关键。所以,密云水库水质参数的精确监测技术迫在眉睫。因此,本研究旨在将无人机遥感、卫星遥感与机器学习结合起来,构建较为精确的多源化密云水库水质参数反演模型,来有效地服务于水库水源地的水质监测与保护,为密云水库水源地的密云水库水源地保护和监管提供支撑。本研究采用高光谱无人机遥感、高光谱卫星遥感和支持向量机(SVM)、神经网络(NN)、弹性网络(Elastic Net)、贝叶斯脊回归(Bayesian Ridge Regression)、套索算法(Lasso)、(线性回归)Linear Regression、决策树回归(Decision Tree Regressor)、K 近邻回归(KNeighbors Regressor)、、随机森林(Random Forest Regressor)、极端随机树(ExtraTrees Regressor)、梯度提升算法(Gradient Boosting Regressor)、AdaBoost算法(AdaBoost Regressor)共十二种机器学习算法构建水质参数反演模型,反演总氮、总磷、氨氮、COD四个影响密云水库水污染的主要水质参数,分析密云水库水质参数在时空尺度上的变化以及密云水库水源地监管措施的实施对水库水质的影响。研究表明:(1)极端随机树(ETR)算法最适合基于无人机高分辨率高光谱数据的总氮、总磷、COD反演模型,决定系数r2高于99%,梯度提升算法(GBR)最适合氨氮的反演,决定系数r2高于99%;极端随机树(ETR)最适于基于Landsat8的总氮、总磷、COD反演模型。(2)经过RFE降维后,线性回归算法(LR)产生了大量失真,而决策树回归(DTR)、极端随机树(ETR)、梯度提升(GBR)算法均能继续保持模型效果,决定系数r2高于99%。(3)反演精度验证结果显示,无人机遥感数据下的总氮、总磷、氨氮、COD的反演值与实际值的相对误差分别为0.02318、0.00039、0.003427、0.45514;Landsat8卫星遥感数据下各相对误差分别为0.2045、0.002683、0.017588、1.44225,均备辨识水质分级的能力。(4)反演结果表明,后八家庄村村水域总氮浓度最高,不老屯村水域的总磷在栅格尺度上的相对波动较大,白河大坝的水质参数普遍高于潮河大坝;总氮、总磷、氨氮在汛期和冬耕播种、返青等时间节点上出现浓度波动。(5)依照《地表水环境质量标准GB3838-2002》分类反演结果水质,表明密云水库总体质量较好,常年处于Ⅱ类水,但总磷浓度略高。"
20,校园网安全情报管理系统,"随着网络普及率地不断提升,网络安全问题已经悄无声息地渗透至人们的生活中。校园网作为师生们学习、生活的一部分,其安全问题已然成为重中之重。如何建立网络安全情报库,并根据自身网络情况实现情报获取来为校园网安全保驾护航,成为了人们日益关心的问题之一。根据此项问题,设计并实现一个为校园网提供威胁信息、事故信息的信息化、智能化安全情报管理系统将对校园网安全提供很大程度的保障。该系统不仅实现了为恶意IP、恶意URL、攻击事件、服务器日志检测记录、敏感词检测记录等威胁情报建立情报库,还定时对校园网官方网页进行敏感词检测,对服务器访问日志中的恶意URL访问请求进行定时筛查,以实现对日志检测记录情报和敏感词检测记录情报的及时获取和更新。校园网管理员不仅可以将已有的网络安全情报进行规范化、信息化管理,还可以即时地获取到针对自身网络所产生的预警情报。本系统基于B/S结构,运用Java Web开发技术、PostgreSQL数据库、Tomcat服务器对系统整体框架进行开发。通过爬虫技术、机器学习、Logstash日志收集框架、Redis缓存数据库等技术实现日志检测记录和敏感词检测记录的定时获取,最终实现情报库的建立。系统能够将不同类型的安全情报进行信息化管理,并高效、及时地获取入侵信息以做出快速应对,对校园网的安全管理具有重大意义。"
21,X教育公司大数据营销智能推荐系统的研究,"X教育公司的官网线上选课系统(简称官网),为用户提供线上选课购课服务,营销转化率常年维持在0.08%以下。经市场营销部门分析,发现官网存在如下问题:在官网上有几千门课程的50多万个班级可供用户线上选课购课,采用关键字全文检索技术实现的筛选课程功能,筛选课程结果的展示中缺少个体特质差异化内容的展示。另外,官网没有整合各类营销活动商机信息,对于是哪些营销活动促进了用户购课还不得而知,更缺少了在官网上对用户开展二次营销的行为。为提高官网营销转化率,市场营销部门提出业务需求,制定了体验式营销策略,计划在官网上实施体验式购课和开展二次营销。IT研发部门,成立大数据营销智能推荐系统项目,用于实现市场营销部门提出的业务需求。首先,运用大数据实时计算技术,收集用户在官网上筛选课程的用户行为信息,实时分析用户行为信息,实时预测向用户可推荐的课程班级,实现体验式购课。然后,运用大数据机器学习技术,整合个各营销活动商机管理系统中的营销活动商机数据,建立用户画像,为已经参加过线上或线下营销活动但还未购课的用户,离线预测向用户可推荐的课程班级,实现对用户开展二次营销。最后,将实时预测和离线预测的可推荐课程班级的信息,展示在官网的“猜你喜欢”展示区,使官网营销转化率达到0.19%,比原官网营销转化率提高了 138%。"
22,基于少数类过采样的马尾松毛虫发生面积等级预测算法及应用,"马尾松毛虫虫害是我国重要的森林病虫害之一,准确的预测预报能有效降低病虫害防治工作成本,提高防治效果。基于经典机器学习算法的林业病虫害预测预报方法无法有效处理样本数量少、分布不均衡、特征维度高的虫害数据,因而在预测样本数量较少的严重级别虫害时准确性有限。少数类过采样能够有效增加模型训练中可用样本的数量、平衡样本空间数据分布,可为林业病虫害准确稳定预测提供思路。因而,本文面向实际林业病虫害防治预警任务需求,针对虫害数据的不平衡性展开研究,重点解决了运用传统机器学习方法建立虫害发生面积等级预测模型时因数据不平衡所导致少数类样本的预测精度有限、泛化能力弱的问题,本文的主要研究工作如下:1.设计了一种马尾松毛虫虫害样本数据库。本文通过国家林业病虫害防治总站和国家气象数据共享中心搜集了广东省4个地区的马尾松毛虫历年发生面积、气象因子等数据,采用组合特征工程对特征数据进行筛选,明确了不同地区影响马尾松毛虫虫害发生的气象因素,为马尾松毛虫虫害发生面积等级预测算法研究的开展提供了素材。2提出了一种基于少数类过采样的马尾松毛虫发生等级预测算法。本文基于合成少数类过采样算法,结合样本排序、自调参k-近邻搜索和集成学习提出了一种改进的虫害发生面积等级分类方法――基于自调参的少数类过采样预测分类算法,本文将该方法应用到马尾松毛虫发生面积等级预测,提升了预测模型的准确性和泛化能力。3.设计了一款马尾松毛虫虫害测报软件。本文基于Python Tkinter模块设计一款面向马尾松毛虫发生面积等级的预测软件。该软件综合了多种机器学习算法,集成了虫害发生面积等级预测、影响因子特征筛选以及预测模型选择等功能,实现了对用户不同应用场景和需求的综合。本文利用UCI公共数据库和实际马尾松毛虫虫害数据对基于自调参的合成少数类过采样分类算法进行实验验证,结果表明,本文所提算法可以提高不平衡数据的分类性能,F-measure、G-mean以及&OC曲线等不平衡数据分类评价指标均优于SMOTE及其部分改进算法,此部分工作可以为虫害预测预报提供参考。马尾松毛虫虫害测报软件可以实现虫害的预测预报,简化了操作流程,为相关的研究工作提供便利。"
23,基于机器学习的漂浮大型藻类遥感研究,"漂浮大型藻类暴发指水体中大型藻类的暴发性增殖和高度聚集现象,在我国属于常见的海洋灾害,对当地的海洋生态系统有很大的影响。因此,及时获得准确的漂浮大型藻类暴发信息,包括其分布范围、漂移路径和暴发周期,对当地政府掌握整体受灾情况,以及对后续防控工作的制定和开展至关重要,有助于我国海洋事业的健康发展。迄今为止,人们所开发的大型藻类提取算法大多可以归结为基于指数的阈值分割法,即通过卫星数据的波段组合运算,将计算结果用设定的阈值进行大型藻类像元的划分。然而,这类算法存在一定的不足,阈值的设定一定程度上依赖于使用者的经验,而且单一的阈值无法适应卫星数据中观测条件的变化,如影像中不同程度的云、气溶胶和太阳耀斑污染等情况,导致算法精度可能依赖相关的掩膜产品甚至是人工目视解译。为了克服这一问题,本文基于机器学习算法中的多层感知机(Multi-Layer Perceptron,MLP),利用GOCI(Geostationary Ocean Color Imager)卫星的瑞利校正反射率(Rayleigh-corrected reflectance,R_(rc))数据建立了适用于东中国海的漂浮大型藻类图像识别模型,有望实现对我国大型藻类暴发事件的全自动长期实时监测。同时,也分析了海洋气象因素对大型藻类的潜在影响,并针对多光谱数据的局限性提出了高光谱数据的重建算法。主要研究结果如下:(1)通过分析GOCI数据中大型藻类与其他类别像元的R_(rc)光谱特征,提出了半自动方案提取了大量优质的样本数据,在此基础上以R_(rc)的光谱特征和空间差异作为输入建立了MLP模型。精度评估结果表明MLP模型能在不同观测条件下有效地检测出东中国海的漂浮大型藻类,整体识别精度达90%左右,且与传统的指数算法相比具有更高的稳定性,有望用于长期自动监测东中国海的大型藻类暴发事件。(2)针对GOCI数据提出了漂浮大型藻类覆盖与分布面积的遥感估测算法,结合MLP模型生成了2011至2018年3至8月东中国海大型藻类暴发过程的空间分布和面积统计产品数据,讨论分析了其时空变化的规律。结果显示,东海漂浮大型藻类暴发一般在3C4月,并于5月份入侵南黄海,同期苏北浅滩北部海域有明显的大型藻类聚集现象,6C7月份东海大型藻类逐渐消散,而山东半岛近海仍由大型藻类占据,进入8月份后逐渐消亡;各年间大型藻类暴发程度均有不同,其中2015年整体受灾较为严重,2016和2017年分别出现了较强的浒苔和马尾藻暴发现象;海表风场和漂浮大型藻类的漂移路径有较强的关系,特别是在夏季,而海表温度对大型藻类覆盖面积的变化并无显著影响。(3)利用全球范围内采集的高光谱实测遥感反射率(Remote sensing reflectance,R_(rs))数据开展了可见光范围内高光谱数据重建研究,使用非线性多元回归方法,成功建立了10种包含不同输入波段的重建模型。通过验证发现,在可见光范围内仅靠8个波段的数据即可重建出高精度的高光谱数据,整体重建误差基本保持在4%以下,且该方法适用于不同水体采集的R_(rs)数据。卫星高光谱大型藻类数据将有助于提高大型藻类的识别精度并推动藻种遥感区分研究。"
24,基于机器学习算法的日喀则地区泥石流易发性研究,"中国的山区面积接近70%,地质灾害频发。泥石流是一种常见的地质灾害,是固体-液体混合物的重力驱动运动,造成的经济损失和人员伤亡十分巨大。泥石流易发性分析对于山地灾害的预警和管理具有重要的指导意义。泥石流易发性分析可以根据区域环境因子推测泥石流发生的可能性。本文选择泥石流频发的西藏日喀则地区作为研究区域,利用卫星遥感数据和泥石流事件历史资料,结合地理信息系统(Geographic Information System,GIS)和机器学习算法对泥石流易发性进行研究,并得出影响泥石流发生的主要环境因子,为日喀则地区城市建设和规划提供科学依据。首先,获取和计算影响泥石流发生的16种环境因子,并基于GIS对多源数据的属性进行统一。其中,归一化潜热指数(Normalized Difference Laten Heat Index,NDLI)首次被应用于泥石流易发性分析。根据频率比法分析环境因子与泥石流分布之间的关系,并将结果作为自组织映射(Self Organizing Maps,SOM)神经网络的输入,进行泥石流易发性分析,同时可以生成“非泥石流”单元。验证结果表明,聚类方法对泥石流易发性分析具有可行性和合理性。然后,从基于SOM的泥石流易发性图中选取“非泥石流”单元,并与泥石流单元一起作为五种机器学习方法的输入(后向传播神经网络,一维卷积神经网络,决策树,随机森林以及极限梯度提升树(Extreme Gradient Boosting,XGBoost)。本文首次将SOM和XGBoost结合,并应用于泥石流易发性研究。使用五种模型评估方法(Precision,Accuracy,Recal,F1 score以及AUC)的结果表明,SOM-XGBoost模型的测试准确率最优:XGBoost(0.953)>RF(0.943)>1D-CNN(0.939)>BPNN(0.932)>DT(0.898),对研究区的预测结果与泥石流分布拥有较好的相关性,且预测效率较高:DT(0.7)>XGBoost(4.5)>BPNN(7.6)>1D-CNN(8)>RF(10.8)(单位:min)。最后,基于树的特征因子重要性对16种环境因子进行排序。实验结果表明,NDLI对泥石流的发生具有最为显著的影响,另外三个主要因子分别为年平均降雨量、剖面曲率以及平面曲率。"
25,基于机器学习多维度的海面能见度研究,"大气能见度是海面重要的气象指标之一,对海洋资源开发、军事活动、航海以及海洋气象研究都具有很大的影响。目前国内外的海面能见度预测研究主要集中在单维度预测方面,其实验结果分析都比较片面。如果能够在有限的数据资料中通过机器学习的方法对海面能见度进行多维度的数据统计分析和预测,则能够对海面能见度的变化有一个更加全面的了解。因此基于这个需求本文进行了基于机器学习多维度的海面能见度研究,主要完成的工作和结论如下:(1)通过对BP(Back propagation)神经网络模型和LMS(Least mean aquare)的理论分析提出了LMS-BP(Least mean square-Back propagation)神经网络海面能见度时间维度预测模型,此预测模型解决了BP神经网络预测模型由于训练样本较大且相关性较高时出现的过拟合和欠拟合情况。通过对多维度的不同气象参数和污染物数据资料的数据统计分析进行训练建模,可以实现高准确率的海面能见度短时预测,比现有的神经网络模型在预测准确率上提高了10%。同时利用本文研究方法进行了不同海域陆地大气污染物PM2.5对海面能见度预测影响的实验,通过实验表明我国陆地的大气污染物PM2.5对海岸线海域和临海海域有一定的影响,对中海海域和远海海域影响较小。(2)提出改进的随机森林海面能见度空间插值算法。主要思想先利用高斯混合聚类模型对不同能见度等级的样本点进行聚类,然后再进行随机森林算法的空间插值预测,提高了随机森林空间插值算法在插值样本点分界面和能见度较低的情况下的空间插值精度。通过实验表明改进随机森林海面能见度空间插值算法比传统的空间插值算法在插值精度上均有提高,其中相比于随机森林空间插值算法在插值精度上提高了15%。通过对海面能见度不同季节、不同能见度等级以及不同天气情况下三个方面的海面能见度空间分布预测实验分析,表明海面能见度空间插值精度在四季中的冬季、一天时间里的中午、晴天以及能见度高于10km的时候较高。同时海面能见度在海岸线海域和临海海域空间分布预测随时间的变化较大,在空间分布上较密集。由此得出结论在海岸线海域和临海域较容易出现能见度差的情况,而中海海域和远海海域相比较少。"
26,基于近似牛顿法的分布式深度学习,"在许多机器学习问题中,往往需要解决大规模模型的最优化问题。最优化问题主要研究各种问题的优化途径及方案,在科学计算和工程分析中起着越来越重要的作用。近似牛顿法作为解决这一问题的有效方法,在计算机视觉、统计机器学习、生物信息和数据挖掘等领域都有广泛的应用。随着深度网络的快速发展,数据和参数规模也日益增长。近些年来,尽管研究人员在提升GPU硬件性能、完善网络架构和改进训练方法等方面均获得了很大的进步,但是在大型数据集上以单一机器训练深度网络模型仍然十分困难,因此,分布式优化及其在大规模深度网络上的训练一直是深度学习研究领域的挑战性问题。随着深度网络数据量和模型参数量的增加,传统的单机训练存在训练时间长,内存容量有限,而分布式优化方法可以很好的解决这一问题。因此,本文将分布式近似牛顿法算法引入到分布式神经网络研究中。该算法将总体样本平均分布至多台计算机,不但减少了每台计算机所需处理的数据量,而且利用计算机之间互相通信高效完成训练任务。首先,对分布式近似牛顿法同步策略进行Matlab同步并行仿真实验,在实验中均衡地划分数据集,并行地对数据集进行计算,在相同矩阵下,并行优化运行时间相比于串行运行时间大大减少,并且收敛性也能得到保证。其次,本文将分布式近似牛顿法用于训练深度网络。该算法使Parameter server集群中的各个Worker节点利用均等分配的本地数据完成计算,并与Server节点进行通信,得到同步优化的结果。利用分布式近似牛顿法训练相同的深度网络时,随着GPU数目呈2的倍数增加,训练时间呈近乎2的指数次幂减少。这与本文的最终目的一致,即在保证精度的前提下,利用现有分布式框架实现近似牛顿法的深度网络训练,提升运行效率。"
27,基于深度学习算法的评论情感分析研究,"随着互联网技术的进步,社交媒体、电子商务蓬勃发展,越来越多的商品交易评论和社交评论出现在互联网中。因此,网络中的各种评论文本迅速膨胀。若依靠人工的方法难以对网上海量的信息进行收集和处理,因此需要进行文本分析从而帮助用户快速从数以亿计的评论中获取重要信息,情感分析技术应运而生。基于词典法构建一个高质量词典需要大量的人力,机器学习方法过分依赖语句向量的特征,这些特征来自于人工选择导致选择不同的特征就会有不同分析结果。深度学习方法作为一种自主学习的分类方法,在不需要人工过多干预的条件下就可以在情感分析任务上取得较好结果。因此基于深度学习的自然语言分析成为了当前的研究热点。针对传统文本情感分析方法正确率低,深度学习方法在训练、测试与分析效率低的缺陷,本文深入研究了基于深度学习的评论情感分析技术,把主成分分析法(PCA)的高效文本分类(Fasttext)方法作为文本向量生成算法,提高生成文本向量的质量。把门控循环神经网络(GRU)和卷积神经网络(CNN)结合,建立了Attention-CNN-GRU评论文本情感分析模型,提高情感分析结果的正确率和模型训练效率。具体研究内容如下。为了提高文字转换后文本向量的整体质量,使用Word2vec的一种改进方法Fasttext。Fasttext方法利用了Hashing Trick算法和分层Softmax算法分别对Word2vec使用的向量表示法和基本Softmax分类法进行改进。Hashing Trick改进后,生成的输入词向量维数减少,再利用主成分分析法对词向量优化,提取主要特征使词向量维度进一步降低。并对Softmax分类法进行改进,建立基于分层Softmax的Huffman树,只需计算路径上所有非叶子节点词向量的贡献值,实现计算复杂度的降低。最终模型能够更快更高质量的输出文本向量。为了获取更好的准确率和更短的训练测试时间,提出结合卷积神经网络和门控循环神经网络的Attention-CNN-GRU模型。传统神经网络相临神经元都是全连接,并且神经元之间无连接,样本处理相互独立,所以不能对时间序列变化处理。门控循环神经网络可以利用时序关系处理句子,存储历史上下文信息并能够考虑到之后的上下文信息。门控循环神经单元在长短期记忆神经单元基础上将忘记和记忆窗口合并,仅由更新门和重置门组成,减少了单元内部计算量,使得计算效率提高。针对不同词语对不同任务的重要程度不同,在CNN-GRU模型的基础上,添加注意力机制,得到Attention-CNN-GRU模型。卷积神经网络的作用则是通过不断训练挖掘评论文本中隐藏特征,进行组合达到特征学习选择的目的。针对深度学习网络中关键参数对训练测试结果影响的问题,实验对比了学习率、弃权系数、批尺寸这三种参数对结果的影响。实验可以看出学习率遵循训练量越大学习率选小一点的规律,弃权系数的选取要找准适合的量,过大会导致模型效果下降,批尺寸也需要结合模型的效果择优选取。实验证明模型在评论情感分类任务上有着很高的正确率和更好的时间效率,对评论情感分析有理论和实用价值。"
28,量子特征选择与量子感知机算法研究,"机器学习是一门基于数据的多领域交叉学科,其目标是从数据中提取一种“模式”,并用该模式来理解先前未知的输入数据。机器学习算法在多个领域,比如经济、军事、医疗中都有很重要的应用。因为量子力学的一些重要特点,如并行性、叠加性和相干性等,可能会给计算带来指数级加速,容量带来大幅提升。于是研究者尝试将机器学习与量子力学结合,产生量子机器学习这个新的研究方向。机器学习和量子信息处理的结合是一个双赢局面。一方面,机器学习和量子计算系统的控制有很好的效果;另一方面,量子力学为提高机器学习的学习效率提供了一个诱人前景,首先是降低计算复杂度,其次是强化机器学习。本文主要研究量子机器学习的两个方向:量子特征选择算法和量子感知机算法。我们知道,研究者比较关注学习算法方面的探索和研究,比如量子感知机算法的研究,但是现有的成果中仍有一些改进的空间。此外,数据特征的预处理,比如特征选择,对机器学习算法训练过程也起着很重要的作用,然而现有的量子特征选择算法研究很少,如何高效准确地选取最相关特征也是一个值得关注的方向。因此本文以提高计算效率、保证算法准确率、降低资源消耗等为目的,对这两个部分进行了深入分析与探讨。主要研究内容如下:(1)提出一个基于二分类的经典Relief算法的量子对应版本:QRelief算法。算法主要包括了四个步骤:量子态准备,相似度计算,权重向量更新和特征选择。经过评估,本算法在效率和资源消耗都优于对应的经典算法,不仅如此,还在IBM Q平台上实施量子实验,验证了算法的正确性。(2)根据经典ReliefF算法,对QRelief算法就行了拓展,提出了一个基于多分类的特征选择算法:QReliefF算法。不同于QRelief算法,本算法使用Grover机制来寻找最近邻的k个样本,相对于之前的算法有一个过程上的提速。(3)提出了一个高效的基于酉权重的一次迭代感知机算法。本算法相较于之前提出的算法,不仅有更好的可用性、更高的准确性以及更广泛的应用性,而且可以适用于非理想训练集。"
29,基于集成学习的不平衡数据分类算法应用研究,"近十年来,不平衡数据分类算法已成为机器学习领域的重要研究方向之一。在不平衡数据分类问题中,由于各类之间的样本数据量极度不平衡,少数类样本容易被多数类样本吞噬,造成分类器模型在分类时无法有效识别少数类。在现实生活中,不平衡数据分类应用范围广泛,如网络入侵检测、银行欺诈监测、机器故障诊断等。因此,研究如何提高分类算法对不平衡数据的分类性能具有重要的实际工程应用价值。本文针对不平衡数据分类问题进行研究与分析,在掌握现有最新不平衡数据分类方法的基础上,从数据层面中欠采样和过采样方法出发,同时结合集成学习对实际问题提出针对性的解决方案,以提高不平衡数据分类算法模型的应用价值,具体工作如下:(1)针对传统分类器模型难以对气温等级中的极端气温进行准确预测问题,提出一种基于密度峰值的聚类欠采样集成分类算法。首先,利用Pearson系数相关法选取气温预测因子,同时根据气象学知识建立江苏区域化气温等级划分表;其次,对由密度峰值算法在多数类样本上快速聚类生成的多个簇中心按照采样率进行欠采样,降低数据的不平衡性;最后,将平衡后的数据带入以BP神经网络为基分类器的自适应增强模型,通过改变样本权值分布来提高该算法模型对于不平衡数据的分类性能。在选取的七个站台的历史逐日气象数据集上进行实验验证,与其他三种传统算法相比,本文提出的算法可以有效识别极端气温等级。(2)针对软件缺陷预测中的过采样方法存在样本重叠及合成样本的错分价值不高问题,提出一种基于距离权值的聚类过采样集成分类算法。首先,基于AGNES算法自底向上聚合策略的思想,对各个少数类子簇进行层次聚类时,筛选是否存在多数类样本,进而生成多个不含多数类样本的少数类子簇;其次,根据各少数类子簇内各样本与其K个最近邻多数类样本的平均欧式距离不同为各个少数类样本分配权值,并根据权值分布对少数类样本进行过采样;最后,将本文提出的基于距离权值的聚类过采样方法和ROS、SMOTE构建随机森林模型,发挥集成模型的整体优势。基于NASA数据集的实验对比结果表明,本文算法模型可以有效改善软件缺陷模块的预测性能。"
30,语音情感的特征提取和分类方法研究,"情感识别是多媒体信息处理、模式识别以及计算机视觉等领域的研究热点。随着深度学习、人工智能的发展,情感识别作为人机交互中的关键所在,受到研究人员的广泛关注。情感的表达方式多种多样,其中面部表情和语音是两种最为重要的情感载体,基于面部表情和语音的双模态情感识别研究具有重要的现实意义。本文主要针对面部表情和语音两种模态,研究用于分类的语音情感特征,以及机器学习和深度学习在语音情感识别方面的应用。主要工作如下:(1)为了提高传统语音情感识别中采用的情感特征识别性能,提出了一种基于变分模态分解(VMD)的语音情感识别方法。情感语音信号首先由VMD提取固有模态函数(IMF),然后对所选主导IMF进行重新聚合,再提取MEL倒谱系数(MFCC)和各IMF的hilbert边际谱。为了验证本文提出的特征性能,选用两种语音数据库(EMODB、RAVDESS)进行实验,按本文方法提取特征后使用极限学习机(ELM)进行语音情感分类识别,实验结果表明:相比基于EMD和EEMD的语音情感特征,本文提出的特征有更好的识别性能,验证了该方法的实用性。(2)在长短时记忆神经网络的基础上,提出了一种基于多层自注意力机制的双向长短时记忆神经网络的语音情感识别方法,完成情感的分类;语音信号作为一种时序序列,在时间上具有很强的相关性,为了利用语音序列前后之间的相关性,研究了一种基于双向长短时间记忆网络的语音情感识别方法;根据双向长短时间记忆网络和卷积神经网络的优点,提出了一种基于双向长短时间记忆网络和深散射谱特征的语音情感识别方法。(3)对情感识别最重要的两个模态语音和面部表情进行了双模态情感识别特征层融合的研究。首先采用面部截取和语音激活对数据集进行预处理,得到人脸情感加权图像,然后将人脸情感加权图像和语音语谱图信号作为分类网络的双模态信号输入,针对训练数据较大的问题,采用深度可分离卷积网络进行分类识别任务,在分类网络中加入SN正则化方法解决输入的两种数据差异较大的问题,并和传统的单模态情感识别进行了对比。实验结果表明,相较于基于语音语谱图的单模态情感识别,双模态情感识别在自制数据集上得到了6.2%的性能提升,验证了本章提出方法的有效性。"
31,易跌倒步态特征及其预警技术研究,"步行是肌肉、骨骼及神经系统共同协调完成的一种肢体运动。步行时,躯体所呈现出的具体姿态和运动方式便是步态。随着人口老龄化问题的日渐加重,跌倒已经成为严重威胁人们健康生活的一大问题,相应的异常步态研究也受到越来越多的关注。步态特征的研究不仅可用于医疗健康,也可广泛用于体育竞技、人机接口和身份识别等诸多领域。而微电子技术的迅猛发展使得小体积、低功耗、多功能的便携式步态数据分析设备的实现成为可能。本文以无线微控制器为硬件核心,设计了一种小型步态数据采集系统,实现了对足底压力和足部运动加速度、角速度的采集。该数据采集系统嵌入鞋底,体积小、使用简单,不会给日常穿着带来额外的负担,具有很高的使用舒适度。为了便于对步态数据进行存储和观察,还开发了专用的手机端应用程序,实现数据的实时显示和本地保存。通过使用该步态数据采集系统,进行了步态数据采集实验,对静止站立、正常步行、不稳定步行与跌倒时的步态数据进行采集。在对不同类型步态数据完成特征分析之后,确定了易跌倒步态的特征和规律,并据此将采集到的步态数据样本进行类别分组。通过构建基于长短时记忆网络(LSTM)的步态类型识别模型,实现了对易跌倒步态的识别。而将该模型集成到手机应用程序中,实现了对易跌倒步态特征的实时检测,以达到跌倒前预警的目的。最终,在实际情境中进行步行测试,验证了步态数据采集系统可以实时地进行步态数据的采集,也证明了步态识别模型能够成功识别易跌倒步态。结果表明该系统可以在步行运动中进行人体跌倒前的预警。"
32,面向深度学习应用的可视化编程系统的研究与实现,"近年来,随着机器学习技术的不断发展与进步,尤其是深度学习算法在图像和大数据处理领域的成功应用,如何高效的开发和应用机器学习技术成为热点问题。目前深度学习算法的开发方式主要基于文本编程语言实现建模。存在学习门槛高、开发效率低的缺点,且难以直观理解算法逻辑。需要一种工具或平台能够降低深度学习建模的学习门槛,以简单易懂的方式展现模型的内在结构。本文设计并实现了一种面向深度学习建模的可视化编程系统。与文本编程方式相比,可视化编程使用图形表示算法和数据的处理流程,无需复杂的代码工程,能让没有编程基础的人也能快速理解模型的工作原理,并轻松掌握算法的构建与数据处理方法。本文在介绍并总结国内外可视化编程的研究现状以及机器学习可视化开发的基础上,分析构建深度学习模型的流程与特点。针对使用可视化编程方法进行深度学习建模和应用,进行了以下三个方面的工作:(1)设计了一种基于数据流的可视化编程语言。采用数据流计算图模型表示算法的计算过程。根据深度学习建模实际需要,设计了该可视化编程语言的图元定义、形式化描述以及功能规约。(2)设计并改进了可视化编程语言的代码生成算法。改进依赖扫描和分层拓扑排序算法,提出一种基于边的计算图代码生成算法,获取必要节点及最优排序。通过定义属性图重写规则,自底向上生成Python代码。并用示例验证所生成的代码。(3)设计并实现一种可视化编程系统。具备跨平台访问能力,以所见即所得的方式进行编程交互,并支持撤销重做功能。以图形化的方式展现数据流计算图的数据处理与计算逻辑,交互式的构建深度学习算法模型,并生成基于MXNet框架的深度学习算法模型以及代码工程。"
33,基于多源遥感数据的森林地上生物量估算研究,"森林地上生物量(Aboveground Biomass,AGB)是评估森林生态系统生产力和健康状况的重要参数。要进行大面积森林地上生物量的高精度估算,需要有效利用多源遥感数据的优势,选择合适的模型,并实现估算范围外推。本研究主要分为两个部分:(1)基于不同遥感数据(机载LiDAR数据、机载LiDAR与机载高光谱数据结合),利用Boruta算法进行特征选择,比较六种回归模型的生物量估算精度,选出最优模型并估算航摄区域森林地上生物量。(2)以航摄区的生物量估算结果作为训练样本,基于Landsat8数据进行估算范围外推,利用最优模型,根据不同的特征组合分别构建森林地上生物量估算模型,选取最佳特征组合,计算外推区域的森林地上生物量。研究的主要结论如下:(1)基于机载LiDAR数据可以获得较好的估算结果(RMSE范围为16.78~25.98??(6(6,rRMSE范围为20.03~29.82%,R~2范围为0.42~0.66),融合高光谱数据后,可进一步提高森林地上生物量估算精度(RMSE范围为15.94~28.87??(6(6,rRMSE范围为19.12~32.72%,R~2范围为0.38~0.70)。(2)经留一交叉验证后发现:基于机载LiDAR数据进行生物量估算,多元线性回归结果误差最大(RMSE=25.98??(6(6,rRMSE=29.82%,R~2=0.42),支持向量回归结果最好(RMSE=16.78??(6(6,rRMSE=20.03%,R~2=0.66);融合高光谱数据后,多元线性回归结果变差(RMSE=28.87??(6(6,rRMSE=32.72%,R~2=0.38),其余模型估算精度都有提高,支持向量回归仍然表现最佳(RMSE=15.94??(6(6,rRMSE=19.12%,R~2=0.70),因此,支持向量回归为研究区的最优估算模型。(3)基于航摄区森林地上生物量估算结果及Landsat8数据,利用支持向量回归模型,对比不同特征组合(纹理+植被指数、纹理+植被指数+地形因子、纹理+植被指数+地形因子+地表参数、Boruta特征集)下模型估算精度,并采用10折交叉验证方式进行精度评价。结果表明:与纹理+植被指数特征集合相比(R~2=0.508,RMSE=16.87t/ha),加入地形和地表参数后,估算精度略有提高(R~2=0.515,RMSE=16.76t/ha);基于Boruta算法获取的特征子集估算结果最好(R~2=0.553,RMSE=16.09t/ha)。(4)将最优特征子集作为输入变量,代入支持向量回归模型估算外推区域生物量,利用18个地面调查数据进行模型的独立精度验证,R~2=0.55,RMSE=11.36t/ha。"
34,基于神经网络量子态的横场Ising模型研究,"我们使用神经网络量子态表示一维与二维横场Ising模型的波函数,这样的波函数相当于一种从自旋位形空间到由网络参数序列决定的复数域的映射,也就是说当我们给波函数输入一种自旋位形时,它就会反馈一个复数。我们使用无监督机器学习方法去寻找基态波函数,具体是,我们采用随机重构(SR)方法不断调整波函数中的网络参数,使得这个波函数不断逼近基态。同时,我们还从最小作用量原理和信息几何的角度为SR方法提供了一种理解方式。在找到基态波函数之后,我们根据它并且使用重要性抽样方法计算了几种关键的热力学量,它们包括,每个格点的平均能量、两点关联函数和关联长度、平均磁矩和磁敏感度。我们探究了这些物理量与外加横场强度的关系,我们得到的结果与已有文献的结果高度一致。特别地,纠缠熵的计算不同于这些物理量,因为在其计算过程中会面临对密度矩阵p的操作,以致无法使用简单的重要性抽样方法计算他们的统计平均值。我们提供了一种可行的用于计算纠缠熵的近似方法,并且其一维结果与已有解析结果高度一致,其二维结果也与已有的几种其它数值结果给出了相近的量子相变的位置。另外,我们还讨论了网络参数α对计算精度的影响,结果显示出α的值对计算精度的影响很小。"
35,人工智能在金融领域的应用研究,"从学术界到产业界,人工智能的应用和影响越来越广。金融业是与人工智能融合最早、最全面的行业之一,通过数据挖掘、精准画像、机器学习、神经网络等一系列人工智能技术的应用将对金融产品、服务渠道、服务方式、风险管理、授信融资、投资决策等带来新一轮的变革。通过深入分析人工智能和金融融合的基础、影响机理、风险及发展对策,对于促进人工智能与金融的深度融合和健康发展具有重要的理论价值和现实意义。近年来,不仅蚂蚁金服、京东集团、百度等互联网企业开展智能金融服务,工、农、中、建、民生等商业银行也纷纷将人工智能技术应用到具体业务当中,智能客服、智能营销、智能风控、智能投顾等业务纷纷出现。人工智能与金融能够有机融合,既有大数据作为基础,又有政策和投资的支持,还有客户需求的外在变化和降低成本的内在要求。人工智能的飞速发展对于深处服务价值链高端的金融带来深刻影响。人工智能通过涟漪效应、数据信息处理、成本和效率途径、情绪管理,实现科技赋能金融的过程。但是,我们也看到人工智能在金融业应用存在的风险,包括技术风险、信息安全风险、监管风险、道德风险和投资风险等等。人工智能与金融的融合发展已是不可逆转,风险和机遇并存,金融业必须加快调整发展的步伐。人工智能时代,传统金融人才要进行蜕变,向复合型人才转变,金融机构顺应金融科技的发展,加大对智能技术研发投资和应用力度,强化风险防控的管理,金融监管部门进一步明确监管责任,将人工智能技术应用到监管方式和手段中,提高监管自动化智能化程度。"
36,基于时序数据的音乐流媒体用户流失预测,"随着互联网的快速发展,音乐流媒体市场正在不断扩大。各大音乐流媒体服务平台通过多样的方式吸引新用户,抢占市场份额。与此同时,平台老用户根据自身喜好更换平台几乎不需要任何成本,这对于音乐流媒体服务平台来说意味着老用户容易流失。用户流失会对企业利润产生很大的影响,所以准确识别出高流失倾向的用户并实施相应的挽留操作显得尤为重要。目前业界的主流做法是利用数据挖掘和机器学习技术来预测潜在的流失用户。针对音乐流媒体领域用户流失数据的特点以及目前用户流失预测方法存在的问题,本文从模型和特征两个层面来改善流失预测效果,具体的研究工作如下:(1)考虑到音乐流媒体领域的用户流失数据集通常包含大量的时序数据,而LSTM模型常被用来进行序列建模,本文提出一种基于集成LSTM的用户流失预测模型,旨在从模型集成的角度出发提升流失预测效果。该集成模型一方面采用LSTM模型作为基学习器;另一方面结合真实数据的特点改进Snapshot集成方法,在模型训练过程中引入样本权重调整机制,同时利用学习法结合子模型输出。实验结果表明,相比于原始LSTM模型,本文提出的模型在PR-AUC上提升4.21%。(2)由于目前用户流失预测任务中常用模型的结构较为简单,表征能力不强,无法从时序数据中充分挖掘信息,本文提出一种基于LSTM和CNN的用户流失预测模型,旨在从模型结构的角度出发提升流失预测效果。该模型通过组合LSTM和CNN来提升模型的特征学习能力,同时发挥这两个模型的优势。实验结果表明,本文提出的模型相比于原始LSTM模型和CNN模型在PR-AUC上分别提升5.05%和6.08%。(3)针对目前用户流失预测任务中构造手工业务特征需要花费大量人力和时间,以及常用的训练样本选择策略会造成历史数据浪费的问题,本文提出两种不依赖于业务的非手工特征构造方法,以及一种基于特征融合的用户流失预测模型,旨在从特征的角度出发提升流失预测效果。首先,利用现有模型对历史数据进行转化来构造历史数据特征。接着,利用树模型对现有特征进行高阶组合来构造树模型特征。最后将新构造的特征与原始特征进行特征融合并对现有模型进行改进。实验结果表明,同时融合所有特征的模型相比于仅使用原始特征的模型在PR-AUC上提升2.71%。"
37,网络化无创血压智能监测系统的研究与设计,"血压是衡量人体健康的重要对象之一,它的非正常波动将会给人体带来严重伤害。近年来,随着饮食结构不合理、精神压力、作息不规律等问题的日渐突出,血压相关性疾病,例如高血压、心脑血管疾病、心血管疾病等越来越普遍,且趋向于年轻化方向发展,所以加强血压的连续性监测显得尤为必要。现有的无创连续性血压检测的方法大多为光电血压检测法,通过研究光电容积脉搏波(PPG)、心电信号(ECG)和血管内腔弹性模型等实现血压测量。但因不同人体之间的个体特征存在一定的差异,所以需针对不同人群分别建立生理信号与血管弹性腔之间的数学模型,增加了血压测量的复杂度。针对这一问题,本文融合PPG、ECG特征及个体特征提出了一种基于机器学习模型的血压修正算法,并结合网络化传输背景和知识,设计了一套基于人体臀部的网络化无创血压智能监测系统。首先,为提高生理信号的质量和处理效率,本文提出了一种基于优质信号的提取算法。首先将预处理后的生理信号按照特征点对信号划分为多个部分,然后通过统计量分析,分别从波形形态稳定性的粗略判断和波形形态准确性的精确判断两方面进行判断,从而将该段信号中的优质信号提取出来,进而避免了因某一异常信号而放弃该段时间内的整段信号,影响后续处理的效率。其次,通过分析血压产生机理和人体各种不同生理特征之间的联系,本文提出基于用户个体特征(包括性别、年龄、身高、体重、有无遗传性高低血压、体质指数),及实时测量的心率、和由优质生理信号处理的血压估测值作为输入参数,以同一时间水银血压计的测量结果作为真实值,构造训练数据集。然后,分别建立支持向量回归模型和随机森林回归模型进行血压预测,并分别使用遗传算法和网格搜索法对模型参数调优。通过大量的经验学习和实验对比,得出随机森林回归模型血压预测结果的各项评价指标均优于支持向量回归模型,所以本监测系统最终选定随机森林回归模型作为血压修正模型。最后,分别从硬件和软件两方面详细阐述了整个网络化无创血压智能监测系统的实现方式。硬件部分主要为网络通信模块与信号采集模块的结合;软件方面,以Visual Studio 2016为软件开发平台,编写了一套多生理参数信息处理系统,主要功能包括数据通讯、生理信号的实时显示、生理参数处理结果展示、历史信息查询等。"
38,基于心电的车载健康监护系统的设计与实现,"疲劳驾驶和心脏类疾病突发已经成为驾驶安全的重大隐患,由此引起的交通事故也时有发生。因此,迫切需要采取措施实时监测驾驶员的生理状况并提高驾驶的安全性。目前,我国在智能辅助驾驶领域,缺乏便于推广的车载健康监测设备。本文把心电采集模块、数据预处理与指标分析模块以及通信与显示模块三者结合,构成了基于心电的车载健康监护系统。信号采集模块主要负责心电信号的提取,采集装置由方向盘和电极片组成;信号处理与分析模块主要包括信号的硬件处理和算法分析,硬件处理平台集成了心率监测器、微控制器等部件。软件部分对采集到的心电信号先经过去基漂、滤波以及放大等预处理,然后是RR间隔序列的提取,接着在对RR间隔序列时频域的分析中可得出十几项用于数据训练的指标,再对多项时频域指标进行PCA(主成分分析),得到低维度的矩阵以及相应的变换矩阵。再用低维度的矩阵进行K-means聚类,划分出不同生理状态相对应的类别,最终得出分析结果;通信与显示模块主要由CAN通信分析工具和上位机组成,CAN通信工具用于将硬件平台的数据总线和上位机相连接,并负责将总线中读取到的数据传递给上位机进行显示与播报。上位机采用Labview的集成模块进行了自主开发,目前可实现对采集到的心电信号进行实时波形显示,以及6种生理状态识别结果的图标提示和语音播报。本文在即时建模(JIT)的基础上提出了一种基于偏最小二乘的多个RRI缺失的插值方法,通过利用偏最小二乘法(PLS)进行局部模型构建,仅当监测到R波误差时,通过局部回归模型插入缺失的RRI,并采用一个测定的RRI阈值来检验R波检测误差。实验结果表明:在出现多个R波丢失的情况下,与传统插值方法相比,所提出的方法在对HRV时频域分析中关键信息的提取率提高近60%,本方法有助于提升基于HRV分析的相关健康监测服务。"
39,基于机器学习的乳腺癌风险分析与预测研究,"IT行业、计算机技术和人工智能技术在数十年里发展日新月异。目前几年物联网信息产业发展势头迅猛,所有的这些造成了信息量不断的增长。特别是在医疗行业领域,医疗数据爆炸增长,已经建立起来了庞大的医疗数据库,有潜在的实用价值。伴随着以深度学习为代表的大数据分析技术不断发展和成熟,出现了大数据分析技术与医疗健康领域开始深度结合。本论文基于大数据Spark平台,开展了有关乳腺癌领域的疾病预测研究,探寻大数据分析技术在乳腺癌疾病预测上应用。首先,论文使用简单的数据挖掘技术,例如倾向得分匹配,卡方验证,KM生存分析,Cox回归针对临床数据做出了有效地分析。对患者的年龄和手术与否分组,得出患者的生存曲线。发现年龄在存活月数上不是主要因素,影响不大。手术方式起主导作用,尤其是同时切除原发灶和转移灶的患者存活月数最长。其次,本论文通过大数据spark平台和随机森林算法建立了患者呈阴性或阳性的预测分析。实验表明:在乳腺癌致病细胞细胞核的相关参数中,Perimeter、Texture和Concave points影响因子对于乳腺癌的致病影响程度较大,更易导致阳性的发生。本文建立的模型预测精度可达99.76%,精度高、方法可靠,有一定的实际应用价值。最终的实验研究结果对于乳腺癌风险的发现具有一定程度的参考意义。接着,本论文建立了基于svm算法模型的患者呈阴性或阳性的预测分析,得到了87.8%的预测精度。对比两个算法模型预测精度值,发现随机森林算法要优于svm算法。最后,本论文通过基于向量机svm和随机森林算法建立了风险致死模型,研究对比两种算法的优劣。实验结果表明基于向量机的模型预测精度达到了74.6%,基于随机森林算法的模型精度达到了75.5%,同时将两条预测曲线下的面积进行比较随机森林的0.796亦大于SVM的0.615,所以在实际的应用中随机森林算法更具使用价值。"
40,票房预测中的社交网络评论情感挖掘技术研究,"近年来,电影艺术已经深入大众的学习娱乐生活中。电影市场每一年都会经历大起大落的票房战争,有些影片能够从观众挑剔的审美观众脱颖而出,有些即时请了高流量的明星却依然收获惨淡的票房,不得不说的是,或许是因为近两年票房整体的不尽如人意。电影制作方与影评媒体的矛盾不断地被摆在大众面前,似乎一些电影票房失利,直接因素就是由于观众的执白影评导致的。随着社交媒体的兴起,电影评论的发布者不再局限于电影研究员或专家学者,各大电影评分类网站、影评类自媒体、观众本身迅速占据舆论的风口浪尖,或是为喜欢的影片发生或是提出尖锐的批评。影评对于电影市场票房到底有多大影响力,以及能从影评中挖掘出多少有价值的信息服务于电影的票房预测,这是本文主要探究的问题。本文从构建多关系主题模型开始,将短影评中涉及的所有电影关注点挖掘出来。另一方面,利用已有的数据训练情感分类的LSTM模型。将短影评汇聚利用人名识别算法提取所有主创的短句,然后利用与训练的情感分类模型对这些短句提取情感特征。将所提取的正负面情感占比的变化情况作为特征加入到预测模型之中,利用生命周期构建多阶段的电影票房预测模型。最后得出结论,在首周使用非线性的SVR模型而接下去的周次使用Lasso模型做票房预测的工作。本文的主要究工作可以概括为以下几个方面:(1)使用主题建模的手段,将影评过滤后提取特定词语组成的主题对象,创建这些对象的属性概念,将评价的关注点以一种主题的形式展现出来,结合影评短文本的特征提出一种多关系主题模型MRTM,实验分析结果表明其有效提高短文本挖掘的主题质量。(2)在传统的口碑、主创等电影本身因素的分析上加入了情感特征,使用基于LSTM的情感分析模型量化主创的情感倾向和变化,这些信息以电影外部特征的形式丰富特征构造过程,旨在分析观众的观感情感态度上的变化和给后续票房预测工作提供有力的变量特征支持。(3)结合电影生命周期的特点,提出一种阶段性的电影票房预测模型和衡量动态变化的主创影响力的方法。结合实验分析,本文最终给出的策略是针对票房预测问题的不同阶段使用不同的预测模型,具体来说,在首映周使用非线性SVR预测方法,在后续周使用Lasso模型。这种方案能有效提高票房预测的精确度和可解释性。"
41,基于极限学习机理论的多楼层定位算法研究,"由于极限学习机(ELM)在训练速度,预测精度和泛化性方面表现优越,使得基于ELM的机器学习算法被提出并用于室内定位。然而,大多数现有的研究工作都是基于二维(2D)室内环境。在本文中,我们将扩展应用场景,并在室内多楼层环境中研究基于ELM的定位技术。主要贡献如下:1.多楼层环境中的定位问题可以转换为机器学习问题,其通过基于ELM的学习技术来解决。本文提出的算法包含两个主要阶段:(1)粗定位阶段:楼层定位;(2)精定位阶段:位置估计。首先,将楼层定位和位置估计分别转换为分类问题和回归问题。然后,基于ELM的技术用于解决上述两个机器学习问题并获得最终目标坐标。2.对于楼层定位,在离线阶段,首先提出主成分分析(PCA)对训练数据进行预处理。PCA可以使用正交变换从相关的RSSI指纹中提取一组线性不相关的变量。由于训练数据的维数减小,离线学习的计算负荷减少。然后,通过将多个单独的ELM学习器进行组合,提出了集成ELM学习用于分类学习并获得楼层分类函数。因为集成ELM可以实现比单个ELM学习更好的泛化性能,所以可以提高学习性能。在在线阶段,首先对接收到的RSSI测量数据进行PCA预处理。然后,可以利用楼层分类函数来估计楼层。3.对于位置估计,在离线阶段,为了获得更好的学习性能,首先根据地理位置信息将训练数据集划分为多个训练数据子集。此外,每个训练数据子集的中心可以通过K均值聚类算法获得。然后,PCA方法作为降维的数学工具,用于RSSI训练数据子集预处理,其可以减少噪声和冗余。最后,将每个训练数据子集依次用于位置回归学习,得到位置回归函数。在在线阶段,通过比较接收的RSSI测量数据与每个训练数据子集的中心之间的距离,选择具有最小距离的训练数据子集对应的回归函数用于最终位置估计。4.开发了基于安卓系统的RSSI指纹采集软件,用于描述所提算法的性能。现场测试表明,对于楼层定位,该算法可以达到甚至超过高成本的传统方法的性能,如KNN方法,K-means方法。由于PCA技术和训练数据集分区预处理,所提出算法的位置估计性能比传统的基于ELM技术的位置估计性能改善显著。"
42,异构网络中基于机器学习的网络选择算法,"随着通信技术的发展,各种各样的异构无线网络相互重叠覆盖,它们各有所长,能够为用户提供各种各样的服务。在这个不断发展的电信行业,移动智能终端变得越来越实惠与强大,没有任何一种单一的网络技术能够满足数据爆炸性增长,因此多种无线接入技术共存成为必要。在这种情况下,如何设计一个智能、高效的网络选择算法成为无线通信领域研究重点。本文针对用户需求及网络环境的动态变化的场景,提出了基于AHP和相似度的网络选择算法;将机器学习与网络选择相结合,提出了基于决策树的网络选择算法;结合多属性决策和遗传算法提出了一种基于加权GRA和遗传算法的网络接入决策算法。本文主要研究内容如下:(1)提出了一种基于AHP和相似度的网络决策算法。该算法根据业务特点为每种业务赋予不同的判断矩阵,用AHP算法求出每种业务下的网络属性权重;考虑到用户需求及网络环境的动态变化,为衡量用户需求与网络属性的相符程度,推导了一种基于Lance距离的属性相似度计算公式,以计算用户需求与网络属性之间的相似度,并加权得到用户需求与网络的总相似度,选择相似度最大的网络进行接入。仿真结果表明,在三种业务下,本文提出的算法都可以有效针对用户业务需求,提高用户服务质量。(2)提出了一种基于决策树的网络选择算法。首先从协同算法获得训练数据,以该训练数据作为训练集,网络属性作为属性集,将连续属性通过二分法离散化处理,选择可以使信息增益最大的属性作为划分特征,不断递归选择划分属性,最终得到一颗泛化能力强的决策树,以此作为决策依据进行网络接入选择,算法简单有效,仿真结果表明,在三种业务下,本论文提出的算法可以有效提高用户服务质量,且该算法简单有效复杂度低。(3)提出了一种基于加权GRA和遗传算法的网络接入策略。它首先利用AHP层次分析法对网络选择问题建立递阶层次结构,通过判断矩阵求得网络属性的主观权重。接着使用遗传算法来调整该主观权重,基于灰色关联分析法定义遗传算法中的适应度函数,将遗传算法中的选择算子、交叉算子和变异算子调整权重,得到适应度最大的网络作为目标网络,可以有效提升用户服务质量。"
43,不完整数据集下基于极限学习机的室内定位算法研究,"随着机器学习的不断发展,位置指纹定位的问题可以转化为机器学习的问题。极限学习机(ELM)算法具有学习速度快,计算复杂度低,泛化性能好的优点,已经被广泛应用于室内定位中。但是在室内定位中,训练数据中的指纹-接收信号强度(RSS)测量值容易受到恶意节点的攻击。同时由于离线数据库采集开销大,往往训练数据样本比较少。因此,本文开展了基于上述两个问题的极限学习机定位算法的研究工作。研究内容如下:(1)首先介绍了指纹定位技术的系统模型和工作原理,在此基础上描述了常用的位置指纹匹配算法。然后研究了极限学习机的相关理论,并对激活函数进行了详细描述,为后续的研究工作打下理论基础。(2)在恶意节点攻击条件下,提出了一种基于在线极限学习机和层次聚类技术的安全定位算法。在离线阶段,利用层次聚类技术辨别受到攻击的训练数据样本。最后利用在线极限学习机训练离线指纹数据训练库中未受到攻击的训练数据样本,获得接收信号强度测量值和所在位置的关系,得到位置递归函数。在线阶段,将采集到的信号强度向量代入离线阶段训练好的位置递归模型,得到位置估计值。算法将层次聚类技术和在线极限学习机应用于定位,利用层次聚类技术辨别受攻击的训练数据样本,排除野值点对离线训练的影响。同时利用在线极限学习机的连续学习能力,提升在线定位性能。(3)在小训练数据集下,提出基于多激活函数的极限学习机定位算法。离线阶段,为了增加非线性以及灵活性,由多种激活函数组成的多激活函数对训练数据进行基于位置的回归学习。利用交叉验证算法获得多激活函数的最优权重系数,从而获得更好的学习和泛化性能。在线阶段,当接收到RSS测量值后,利用位置回归函数计算最终的目标位置。同时对所提算法的训练误差进行了理论分析,理论推导给出了该算法定位误差的上、下限,从而证明该算法定位性能的优越性。"
44,基于机器学习的无线通信场景分类方法,"在机器学习大热的二十一世纪,无线通信技术也因此进入了全面发展的时代,在全球的应用场景越来越广泛,场景分类就是其中的热点。利用无线信道的电波传播特性、信道衰落特性以及信道空时特性来进行研究,可以提取出无线信道的特征,对特征进行分析就可以达到对于当前无线通信场景的分类的目的,这具有非常重要的学科研究价值,对于研究无线通信性能也具有很大的好处。目前场景分类技术多应用于图像以及视频处理领域,而对于无线通信领域中的场景分类技术研究还不够详细。随着机器学习的大热,无线通信环境下需要进行分类的相关场景种类的数据库也越来越庞大,而用耗时的人工进行场景分类已不能满足当前社会的需要,不仅耗费的时间和精力非常大,获得的场景分类效果也不高,所以将机器学习相关技术引入无线通信场景分类方法中来提高场景分类的效率,减少相关开销。本文从无线信道的特征矩阵,机器学习算法以及无线通信场景分类等方面进行研究,重点研究基于无线信道特征的无线通信场景分类方法,并且将机器学习中的SVM算法(支持向量机)和决策树算法引入到无线通信中,提出了基于机器学习的无线通信场景分类方法。该方法可以在场景切换的情况下对无线通信场景实时地进行分类,还可以对分类结果进行分析,弥补了对于场景分类结果研究的不足,展现了不同的属性对于无线通信场景分类的影响。本文主要的研究工作和创新如下:(1)对无线信道的特征进行精简,只选取了角度功率谱、到达角变化和路径损耗三种特征进行分析,降低了无线通信环境下场景分类的计算复杂度,提高了场景分类的速度。(2)针对无线信道多变的特点,设计了一种基于支持向量机的无线通信场景分类方法,可以利用无线信道的特征矩阵实时地对场景进行分类,当环境发生变化时可以实时地分类出来,提高了无线通信环境中在场景变换情况下的实时场景分类效率和正确率,节约了时间成本。(3)将机器学习中的决策树算法引入无线通信场景分类方法,对无线信道的特征矩阵转化成的属性矩阵进行训练,建立分类决策树和结果决策树对无线通信场景进行分析和研究,进一步降低了无线通信场景分类的时间成本,弥补了对于场景分类结果研究的不足,分析不同的属性的影响因子,体现不同的属性对于不同的场景分类结果的影响。"
45,基于可穿戴设备的人体姿态识别研究及系统设计,"近年来,随着微电子技术和计算机技术的发展,可穿戴设备的工艺得到了提高,云计算服务提供商也逐渐能够提供与之相对应的计算资源。可穿戴设备具有体积小、易于携带、操作简单且不受地点限制等优点,伴随着人口老龄化问题的加剧和人们对自身健康关注度的不断提高,基于可穿戴设备的人体姿态识别正在成为医疗监控和个人健康领域不可或缺的一部分。本文在国内外相关研究的基础上提出了基于可穿戴设备的人体姿态识别总体方案,并对目前人体姿态识别领域内流行的数据预处理方法和识别方法进行研究,分别使用基于随机森林的AdaBoost-RandomForest算法、基于神经网络的算法和基于SVM的SVM-KNN算法构建分类器对人体姿态进行识别。经过实验分析,基于SVM的SVM-KNN算法在人体姿态识别上取得了较好的识别效果。此外,本文在人体姿态识别算法的基础上提出了人体姿态识别系统的设计方案,从硬件和软件两方面分别对系统进行设计,利用可穿戴设备中的惯性测量单元(IMU)收集人体在运动时产生的数据,使用低功耗蓝牙作为可穿戴设备与智能手机之间的数据传输协议。服务端则以云计算的方式提供计算资源,采用微服务架构,将系统的各部分业务逻辑进行解耦,实现客户端和服务端的交互。结合服务容器化的思想,使用容器编排技术提出了云端服务的部署方案,增强了系统的可伸缩性以及管理能力。并率先在市政环卫领域展开实践,针对环卫工人等户外作业人员,利用智能手表和云端应用将人体姿态识别系统成功部署,方便有关部门对环卫工人的实时监测和调度管理。"
46,基于单个RGB摄像头的虚拟键盘系统研究,"随着虚拟现实技术的快速发展,人机交互正在从传统基于物理外设的模式逐步转变为人机直接交互的虚拟模式。本文就从人机交互中最常见的键盘接口出发,研究适合室内场景下使用的利用单个RGB摄像头作为输入的虚拟键盘系统。但当前,基于计算机视觉的诸多人机交互虚拟应用在手部区域识别准确率、指尖点提取精度、对背景环境鲁棒性、用户易用性等方面仍有进一步完善的空间。因此,研究一套完整的、高精度的、贴近用户日常使用习惯的虚拟键盘系统变得十分具有现实意义。本文主要在以下两个方面展开了研究。一方面,对于虚拟键盘最为重要的指尖提取方法,传统算法存在着适用场景过于简单、提取精度不高、容易受手部姿态干扰等问题。本文在已有的基于指尖轮廓的K余弦算法的基础上进行了适当改进,对手部极限姿态下易产生误判点簇的情况进行了考虑。结合误判点具有的曲率低、纵坐标小的特征对其进行了剔除,然后利用无监督学习的K-means聚类算法对指尖点簇进行聚类,得到的簇中心作为真正采用的指尖点坐标,使得传统指尖提取算法更适合本文提出的第二种虚拟键盘的使用场景。另一方面,对于如何实现虚拟键盘系统,主要是如何实现按键位置的定位和击键事件的判定这两个模块给出了两种不同的实现思路。一种借助了键盘纸外设,利用键盘纸对键盘位置进行标定,坐落在键位内的指尖点通过击键判定算法控制键位击键;另一种则完全依靠用户手势控制,利用手部的HOG特征作为手势样本的特征,然后采用线性核的SVM分类器对用户的三种手势进行识别,用以控制虚拟键盘的行,用户的指尖点索引控制键位的列,击键判定工作则依靠指尖点纵坐标标定实现。此外,对每一种实现本文从不同角度进行了性能分析,并与已有方法进行了比较。本文通过基于单个RGB摄像头的虚拟键盘系统的研究对未来基于计算机视觉的人机交互系统进行了展望,希望能对未来完全虚拟现实化的人机交互系统研究有一定的参考价值和现实意义。"
47,基于机器学习的手势识别技术研究,"随着人工智能技术的迅速发展,智能化设备逐渐融入到人们生活的方方面面,因此对各类人机交互技术的需求也在不断地增加。手势是人们常用肢体语言之一,是一种自然直观、有效简洁的沟通方式。基于计算机视觉的手势识别逐渐成为人机交互的重要研究领域,是热门的研究课题之一。本文对基于机器学习的手势识别技术进行了深入的研究,主要工作如下:一、研究基于肤色的多手势图像精准分割算法:首先,分析了不同亮度下的肤色在不同颜色空间中的分布特性,通过结合在实际场景中的手势分割质量,从中选出了最合适的颜色空间用于建立肤色模型。其次,分析了多层次手部形状特征,研究了手部区域的最小绑定矩形(MBR)与最小面积绑定矩形(MABR),确定了手腕分割线,实现了对手臂冗余去除,为手势识别模型的建立奠定了基础。二、研究基于新型RF-Net模型的手势识别算法:首先,对RF-Net模型的架构进行了描述:在AlexNet模型的基础上加入了BN层、1*1卷积层、动态学习率等优化方法,提出了AlexNet_I模型,通过固定AlexNet_I模型除全连接层外的网络参数,用于对手势图像的特征提取,即RF-Net模型的卷积架构;随机森林具有抗过拟合能力强和具有高识别率的优点,同时其并行计算策略大大降低了识别时长,用于对手势图像进行判决,即RF-Net模型的判决架构。RF-Net模型结合了卷积神经网络能够通过卷积核提取目标物体的特征优点与随机森林抗过拟合能力强和具有高识别率的优点。通过在Marcel数据集、HGCHA数据集与经过手势分割处理后的数据集中训练,对识别精度与识别速度进行了测试,证明了本文提出的手势分割算法与基于RF-Net模型的手势识别算法在手势识别领域的有效性。三、开发并实现了面向家居场景的手势识别控制系统:首先,阐述了手势识别控制系统的软硬件环境,并对手势采集系统与手势识别功能进行了说明。其次,对系统在功能、性能等方面进行了测试,验证了本系统在功能与性能上的技术优势。"
48,基于信任传递的智能推荐方法研究,"近年来,随着信息技术和互联网技术的飞速发展,信息量呈现出指数级的增长,如何从海量信息中找到用户所需要的,逐渐引起了人们的关注。例如,在互联网时代,电商网站发展迅猛,但用户也面临着如何在数以千万计的商品中选择商品的问题。而推荐系统的出现,就能解决这一问题。最常见的推荐系统,主要的工作原理就是收集用户所感兴趣的物品或者信息,然后将物品或者信息归类整理,最后将相同类别的推荐给该用户。推荐系统不仅能够为用户节省选择时间,提升用户体验,同时也能给电商网站带来更多的收益。本文首先介绍了目前常用的各种推荐系统,包括基于协同过滤的推荐算法、基于内容的推荐算法、基于知识的推荐算法、基于信任的推荐算法和基于混合过滤的推荐算法;详细的介绍了常见推荐系统存在的问题与挑战,比如冷启动问题、数据稀疏性问题等等;系统的介绍了关于推荐系统中常见的评价指标,比如绝对平均误差、覆盖率等等。接着,本文从用户的角度出发,提出了基于用户间信任的推荐系统预测方法,该方法利用信任评级的社交网络来给信任他们的用户生成推荐。该方法定义了用户间的信任值,利用信任的传递性,通过量化用户间的信任关系计算信任值来对某个未评分物品进行预测评分,从而来缓解冷启动和数据稀疏的问题。然后,本文又从物品的角度出发,将机器学习中的决策树算法和基于内容的推荐系统相结合,构成基于内容的智能推荐方法。利用决策树算法,将物品的分类更加精细与明确,从而进一步缓解物品冷启动问题,带来更好的推荐效果。最后,将基于信任传递的推荐算法和基于内容的智能推荐方法结合起来,构成基于信任传递的智能推荐方法。通过实验仿真和对比,验证了该方法的有效性。"
49,基于智能终端的行为识别方法研究,"行为识别是计算机领域热门的研究课题,其已经在不同领域实现了新颖的应用,例如医疗保健、安全和娱乐。随着信息时代的快速发展,微型机电系统(MEMS)技术不断发展和微型传感器的推出,智能终端逐渐成为研究行为识别的有力工具。利用智能终端进行行为识别的方法具有易携带、高鲁棒性和不影响用户正常生活等特点。由于智能终端中的传感器可以检测用户的运动数据,因此,可以利用智能终端来提高识别准确率。然而,该行为识别方法依然存在识别率比较低的问题,特别是相似活动的识别率更低,计算复杂度略高,这些问题都导致识别系统实用性不高。因此,为了能够进一步解决以上问题,本文做了相关的研究,并提出了相应的解决方案。针对行为识别中相似活动的识别率不高问题,本文提出了一种基于智能手机的相似活动的识别系统。本文先通过公式将三维的加速度数据转换为五维向量,提高数据的有效性。之后利用特征提取和特征选择算法获得最优特征集。最终,利用多层感知分类器进行最分类识别。实验结果表明,本文提出的模型识别的平均准确率为99.2%,比一般的研究成果的准确率提高了约3%。相似活动的准确率提高了约5%。针对行为识别中跌倒检测的准确率不高、误报率较高的问题,本文在阈值检测法的基础上,提出了阈值检测和机器学习检测相结合的混合法。先对活动进行一个预判断,若满足条件,则预判为跌倒,并将预判为跌倒的行为再利用机器学习进行进一步分类。反之,预判为日常活动,继续监测。实验结果表明,此方法不仅提高了识别的准确率,减少误报率,并且降低了算法的复杂度。"
50,基于机器学习的网络舆情情感倾向分析研究,"近年来,随着移动终端技术的不断发展,人们可以愈发便捷地通过微博、论坛等载体来表达个人的情绪及观点。用户通过这些载体发布的信息中往往包含着一定程度的情感倾向、意见倾向特征,通过情感倾向分析技术挖掘这些特征对于舆情分析、舆情监控等有着十分重要的意义。本文以论坛文本数据为研究对象,使用基于机器学习的情感倾向分析方法进行了相关研究,具体研究内容如下:首先,介绍了针对论坛数据进行舆论倾向性研究的背景及意义,阐述了业内使用机器学习技术进行情感分析的相关研究现状。同时,针对情感倾向分析的流程和相关技术进行了介绍,包括文本采集技术、文本预处理技术、文本表示技术、性能评估指标等。而后,研究使用朴素贝叶斯技术以及字典法针对论坛文本进行情感倾向性分析,经过算法适用性比较,最终选择了效果更优的字典法。通过扩充分词库、扩充极性词库、构建面向突发事件的情感倾向词典等方式对算法进行了四次优化,最终平均准确率达到了87%,平均召回率达到了81%,能较好地反映文本针对突发事件的意见倾向数值。"
51,基于支持向量机的网络流量分类技术研究,"随着网络技术的发展,网络中的流量增长十分迅速。对网络流量进行实时且准确的分类在网络安全管理以及流量工程中显得尤为重要。对于网络应用类型的日趋增长,传统的基于端口号和协议的方法显得尤为低效。本文对于网络流量分类技术进一步研究如何利用机器学习的方法提升网络流量的分类精度,以及面对大规模流量数据时,如何提升实时传输的能力。首先,在对流量特征进行提取时,面临着流量特征种类繁多的问题,这将导致训练时间的开销增大。为了解决因为特征冗余导致的支持向量机训练开销大的问题,本文提出了一种基于最大相关最小冗余的特征提取方法。该方法利用随机变量之间的互信息,提取出相关性最大冗余度最小的特征值。仿真结果显示,该方法可以有效减少训练时间,提升训练效率。其次,为了减少噪声对支持向量机分类的影响,本文提出了一种新的基于改进隶属度的SVM流量分类算法。这种算法主要是计算每个样本对应于其各类的隶属度,该隶属度由样本到超平面的距离来确定,用来度量每个样本所拥有的权重。仿真结果显示,该方法可以有效的减少噪声和野值对分类精度造成的影响,从而提升支持向量机分类的准确率。最后,在特征提取和支持向量机算法研究的基础之上,本文提出了一种基于Spark的改进有向无环图支持向量机流量分类算法,利用Spark基于内存分布式计算,实现改进有向无环图支持向量机算法,最终得到并行网络流量分类模型,提升网络流量的分类效率。结果表明,面对大规模流量,存在着计算复杂度高,训练时间长的问题,本文设计的基于支持向量机的网络流量分类模型能够有效的提升网络流量的分类效率,以及提升流量分类的准确性。"
52,基于机器学习的异常DNS流量检测研究,"域名服务(Domain Name Service,DNS)是互联网上的重要服务,因此网络中DNS流量通常不会被防火墙阻挡。然而攻击者利用这一特点使用DNS协议隐匿恶意行为,如使用DNS隧道进行文件外传、使用域名生成算法(Domain Generate Algorithm,DGA)进行僵尸网络控制。由于现在多种网络攻击都依赖DNS协议来与攻击者进行数据交互和命令控制,如果能发现异常DNS流量,可以有效的打击网络犯罪。为了在海量网络数据中发现异常DNS流量,本文提出了基于机器学习的检测系统,重点针对DGA域名进行检测。论文首先对异常DNS流量产生的原因进行了分析,根据异常DNS流量的特点,从域名构成特征和IP地址对应特征这两个维度进行研究,提取了元音字母个数占比、去重比例、完全限定域名访问次数、返回IP地址的分散程度、域名解析目标IP地址集的大小等多个特征。接着使用黑白名单过滤模块,对已知的大量正常DNS流量和部分恶意DNS进行过滤,为了提高黑白名单过滤的效率,使用了Bloom filter进行查询操作。该模块降低了后期机器学习的负荷,并缓解了不平衡分类的问题。在进行数据预处理之后,使用了贝叶斯分类、决策树算法进行机器学习训练,最后在实验中使用真实的DNS流量进行验证,并对不同的机器学习方法进行了比较,实验结果显示论文提出的检测方法可以有效的发现异常DNS流量。"
53,组稀疏多任务学习方法及其应用研究,"在构建机器学习模型时,通常会遇到几个相关联任务的情况,例如在图像分类中,不同的光照下,不同的背景情况,不同的拍摄角度等,这些情况都可以通过构建多任务学习的方法来实现。通过任务与任务之间的相关性,挖掘任务与任务之间的潜在信息,获取有用的额外信息,从而建立更具鲁棒性和泛化性能的模型。本文主要研究了组稀疏多任务学习方法,这种方法在给定了已知的相关联任务的输入与输出数据,克服了当前某任务样本量较少的缺点,利用通过其他相关任务的样本,获取有用的信息,提高训练模型的预测性能。同时引入限制模型稀疏性的正则化项,进行特征筛选,组稀疏正则化项可以充分发挥特征筛选的有效性,筛选出有用的相关特征。具体的应用方法为:首先,对数据集进行处理,利用PubChem分子指纹的方法,提取到每个样本的881维特征;然后,利用任务与任务之间的相关性,以及组稀疏正则化项在特征筛选中的良好性能,构建组稀疏多任务学习模型;最后进行特征筛选,筛选出相关的特征结构。最终实验结果表明,通过与单任务学习方法对比,与深度多任务学习方法对比,以及与基于其他正则化项的多任务学习方法对比,在九组数据集上进行验证,可以发现组稀疏多任务学习方法在回归预测性能以及特征筛选中的优越性。"
54,持续学习框架中主动学习算法研究,"计算机技术迅速发展的今天,机器学习在许多领域已经取得了非常优秀的性能表现。新的机器学习算法层出不穷,虽然新的算法架构在相同的条件下性能有所提升,但是机器学习的成功更多地还是依赖大量的标注数据。可是在许多专业的领域,数据标注不仅枯燥乏味、消耗时间,而且需要大量具有专业领域知识的人力资源,这通常不是一项容易的任务。为了降低人工标注数据的成本,本文提出了一种持续学习框架CLBSS。CLBSS基于主动学习方法,主动学习的主要目的就是通过主动学习样本选择算法从大量未标注数据集中选取最有价值的部分样本进行人工标注,减少人工标注样本的数量。CLBSS应用主动学习算法,持续地从未标注数据中选取最佳子集进行人工标注,进而完成模型更新。CLBSS主要由基分类器,主动学习样本选择算法和已标注样本采样算法三个模块构成。基分类器是CLBSS的主体,主动学习算法和已标注样本采样算法都依赖于基分类器,依据不同的分类任务通常采用不同的基分类器。本文的任务场景设定为音频分类,音频分类通常首先要把原始音频特征转化为频谱图,然后对频谱图进行分类识别,所以专为图像分类设计的卷积神经网络称为基分类器的首选。主动学习样本选择算法是主动学习过程的核心。常见的主动学习样本选择策略主要基于“最具识别力”或“最具代表性”准则。“最具识别力”准则侧重于考虑当前模型的特点,选取当前模型分类最“模糊”的样本进行人工标注。“最具代表性”准则则更多地考虑数据本身的特点,尽可能的发掘更多样化的数据。CLBSS采用了新的融合“最具识别力”和“最具代表性”准则的主动学习样本选择策略,汲取了两种策略的优点,使得选取的样本更加合理,更有利于基分类器性能的提升。已标注样本采样算法对分类器学习过的样本进行下采样,在学习性能和效率之间取得了很好的平衡。随着持续学习轮次的不断增加,标注数据量也会不断增加,对标注数据进行下采样可以缓解数据膨胀问题。但是,如果完全不使用已学习过的标注数据,而只使用当前批次新标注的数据,则会造成灾难性遗忘问题,即对分类器学习过的数据分类性能急剧下降。所以使用部分已学习过的数据也有助于缓解灾难性遗忘问题。实验结果表明,基于融合策略的主动学习算法能够使得分类器获得更加鲁棒和快速的性能提升。与其他持续学习框架相比,CLBSS通过对已标注数据的下采样,可以避免不必要的计算代价,并且减少了数据的存储需求。"
55,基于机器学习的生物医学命名实体识别的研究,"在大数据时代的背景下,生物医学的研究正在快速发展,每年都有大量的文献在增加。海量的生物医学文献作为一个巨大的非结构化数据库,提供了丰富的生物医学研究知识,是最重要的生物医学领域资源。因此,如何从这些海量的文献中快速获取专业知识受到了越来越多的关注。生物医学文本挖掘技术在文本知识的自动获取中发挥着重要的作用,而命名实体识别作为该项技术的任务之一,旨在从生物医学文献中识别出指定类型的名称,如蛋白质、DNA、RNA、细胞等,为进一步地抽取关系和其他潜在信息提供了前提。本文的研究工作包含以下三个部分:(1)基于条件随机场的生物医学命名实体识别。使用生物医学语料库,根据生物实体的特性人工设计了15种特征;采用条件随机场算法训练模型,结合单独最优组合法挑选出最优的特征集,分析各个特征对实验结果的影响,经过测试评估,综合评价值F最高可达75.91%。(2)基于双向长短期记忆网络联合条件随机场的生物医学命名实体识别。传统的机器学习算法不仅需要人工选取特征,还需要一定的领域知识;同时模型的好坏取决于高质量的数据集和最优的特征集合,这需要付出众多的人力代价。为了解决传统方法存在的问题,本文提出了基于双向长短期记忆网络结合条件随机场的命名实体识别方法,经过训练、测试和评估,F值达到了76.81%。实验结果表明,此方法不仅不需要人工抽取特征,而且预测效果优于单向、双向的长短期记忆网络和传统的机器学习算法。(3)生物医学命名实体识别系统的设计与实现。采用双向长短期记忆网络联合条件随机场算法训练出的模型,以autism为关键词检索相关联的文献进行实体识别并对数据进行直观地展示,表明算法的有效性和实用性。本文提出的命名实体识别的方法,表现出了较好的识别效果,能够高效快速地从海量的生物医学文献中自动识别出实体名称,从而为实体关系抽取奠定了基础。"
56,基于机器学习的智能高考志愿推荐系统,"随着互联网和教育信息化的快速发展,个性化推荐系统在教育领域的应用已越来越广泛。填报志愿是高考中的一个重要环节,但是考生面对众多院校、专业的情况下,很难迅速获取有效信息,做出适合自己的个性化的选择。本文通过分析考生和家长的个性化需求,从海量的学校和专业中挖掘出有价值的信息,推荐给考生和家长,为考生填报志愿提供帮助。本系统从各大网络平台获取了各高校的相关数据作为高考志愿文本中的历史数据,并且针对历史数据中,特征词汇较少的情况,增加了维基百科的数据作为扩展来训练词向量。针对传统的文本表示方法没有考虑语义、存在维度灾难的问题,将word2vec引入到基于内容的推荐算法中,改善了现有的相关网站只通过关键词搜索,搜索结果不含语义特征的现象。同时,对于现有的相关网站存在只能根据特定的专业进行信息检索的缺点,并考虑考生和家长所提出的专业意向比较自由、偏口语化的现象,将余弦相似性方法与简单共有词方法相结合,改进文本相似度计算方法,从而解决了考生和家长不知道院校中某专业的具体专业名称的问题。接着对历史数据中的多元属性,如院校等级、专业等级、校园环境、师资力量设置权重,优化了现有的个性化推荐系统。最后基于以上提出的优化方法,设计并实现了一个高考志愿推荐系统。经过实验验证,优化后的系统改进了现有相关网站的检索功能。"
57,基于脑电的情绪识别研究与系统开发,"情绪在人类生活的各个方面都发挥着重要的作用,因为人的行为举止、推断决策等都很难避免内心情绪的影响。已有研究表明,通过分析人类的脑电信号可以识别出其情绪信息。因此,基于脑电信号的情绪识别研究具有很大的应用前景。近年来,机器学习技术的发展为基于脑电信号的情绪识别研究提供了可靠的技术手段。传统的机器学习技术简单地从多通道的脑电信号中提取特征,然后连接成单个特征向量,没有考虑到脑电信号中至关重要的时间动态信息。深度学习技术中的长短时记忆网络(Long Short-Term Memory,LSTM)因其时间上的递归结构,所以可以很好地解决这个问题。为此,提出一种新的基于LSTM的情绪识别模型。脑电信号被分成多个非重叠的信号段,分别从每段信号中提取了时域、频域和非线性动力学特征,将其沿时间轴连接成特征序列并用来训练基于LSTM的分类模型。在DEAP数据集上验证了该模型在愉悦度、唤醒度和喜欢度上的二分类准确率,其中每种情绪均分为低和高两类。实验表明,该模型在愉悦度和喜欢度上的分类准确率均优于已有方法,在唤醒度上的分类准确率也十分具有竞争力。同时,本文对基于脑电信号的情绪检测系统的开发进行了介绍,系统主要包括五个模块:总控模块、脑电预处理模块、脑电特征提取模块、情绪识别模块和数据库模块。总控模块负责执行用户在客户端选择的操作;脑电预处理模块提供给了各种脑电信号分析与处理的工具,如降噪和频带提取等;脑电特征提取模块用于提取与情绪相关联的特征;情绪识别模块可以根据提取的脑电特征检测出被试的情绪变化情况;数据库模块主要用于存储用户信息、被试信息和检测结果。客户端能将被试在愉悦度、清醒度和喜欢度上的情绪变化情况和区间统计情况展示给用户。"
58,基于蜻蜓算法和花朵授粉算法的特征选择方法研究,"在现实世界中,我们的研究离不开各种各样的大量数据。然而,因为现在数据采集技术的不完善以及采集到的数据本身存在许多冗余的噪声,所以如果想要在分类过程中提高分类精度,降低算法的复杂性,减少运行过程中占用的存储空间,就需要删除采集到的数据中的不相关信息,从而达到去除数据噪声的效果。根据现有的常用手段,降维技术经常被用于数据去噪。通过比较原始数据集与去除噪声之后数据的相似性,可以将降维技术分为特征提取和特征选择。特征提取与特征选择一样,他们两者都是根据原有特征,找到最能区分样本类别的一个或者多个特征。伴随着计算机技术的发展以及我国科研的进步,最近这几年时间互联网和硬件设备正在高速发展,所以在日常生活中自然而然地产生了大量的数据。所谓大数据时代的来临,就是因为这些新产生的数据本身蕴含着很多有价值的内容,人们通过深入研究这些新产生的数据可以帮助现有的医疗、网购、金融以及空间信息等领域进一步发展。要想数据能够被医疗、网购、金融以及空间信息等领域所应用,首先需要对数据进行收集和整理。然而,现实中被收集到的数据包含了很多冗余以及不相关的信息,这是由设备、技术和某些非人为的因素所造成的。这些冗余以及不相关的信息会给数据的表示、存储以及分析处理等工作带来巨大的困难,以致于可能会使得数据所蕴含的有效信息无法被准确的获取。由于采集到的数据规模大、维度高、冗余度高,数据挖掘和机器学习等领域的数据分析技术便迎来了重大挑战。所以本文采用基于群智能优化算法的特征选择方法。因此,本文主要从以下四个方面进行特征选择的研究:(1)将蜻蜓算法与花朵授粉算法相融合,在蜻蜓寻找到较优食物后,更加深入的局部开发,提升精度,提出蜻蜓花朵授粉算法;(2)为了使得提出的算法能应用于特征选择中,将融合后的算法进行离散化;(3)提出基于融合蜻蜓算法和花朵授粉算法的特征选择方法,并使用支持向量机作为分类器,名为离散蜻蜓花朵授粉算法;(4)将提出的方法在特征选择问题上进行应用,并和其它同类方法进行对比研究。为了验证本文提出新特征选择算法的有效性及效率性,本文选取了UCI数据集中常用的6个数据集,对离散蜻蜓花朵授粉算法进行测试。最后通过对比经典和国内外最近的特征选择算法,可以发现本文提出的算法在大部分数据集中都优于对比算法。因此本文提出的特征选择算法具有良好的理论意义及应用价值。"
59,基于机器学习的行人姿态估计及识别的算法研究,"视频行为识别的目的是自动检测并分类来自输入视频的正在进行的活动。它在监控,在线视频,运动分析等方面有很多应用。在某些特定的场景中,监控视频中的非正常行为是大家关注的重点,通过系统自动识别异常行为,工作人员可以及时的判断目标区域是否存在危险行为以及它的特点,从而防止恶性活动的进一步扩散及更恶劣后果的出现。视频行为识别是机器学习在安防领域的深入应用,这个产业也吸引着越来越多的研究人员和学者的加入。视频行为识别是指从视频序列中自动分类,其类别通常是人类行为,如步行,慢跑等。视频分析与图像分析最大的区别在于,视频序列包含额外的时间信息,所需的计算量通常要大得多。因此,当前人体行为识别算法的难点集中在这几点:1.如何提取有效的时间域特征和空间域特征是姿态识别和行为分类过程中最重要的问题;2.如何有效融合相同的空间域下和不同时间域下的特征,共同完成姿态的估计和行为的描述;3.为了满足实际应用的要求,算法的效率非常重要,即如何在保证特征提取能力的基础上缩小模型规模;4.网络在训练集上的分类结果非常好,但往往在测试集上的分类结果并不理想,即如何保证模型的泛化能力。这些问题限制了计算机模型自动完成视频中行为的识别,为智能监控、公共安全监督等实际应用带来的困难。本论文围绕上述问题提出了相应的解决办法,并通过实验完成了对算法效果的验证。人体行为识别任务是典型的分类问题,通常配合大规模的样本完成机器学习模型的训练以使其收敛。典型的一种样本是视频,其中包含着不同的人在不同时间下的在不同空间位置的多种行为,因此需要同时考虑单个行为的多种表达方式和多种行为之间的本质区别,换句话说,也就是样本的全面性和独特性,因此文本尝试了多种数据增强方式以观察其有效性。目前,对于基于视频分析的人体行为识别任务的研究仅仅到达了动作识别的层级。在这个任务中,行为对象包括两种:其一是满足某些特定规则的固定种类的简单动作,例如行走、慢跑、跳跃和下蹲;其二是具体环境下的特殊情形,包括不法分子的抢劫、偷窃、打架斗殴。在后者的环境中,人体作为非刚体,其动作和行为很难被准确的表征,因此往往通过采取跟踪其运动轨迹的方式进行判断。如今,以上两个小方向的研究仍面临着严峻的挑战,远不能满足实际应用的需求。针对这些问题,本文通过开发新的深度卷积神经网络架构来解决高级语义信息抽取的问题。另外,传统用来描述人体姿态和行为的特征难以抵抗噪声,以及视角的变化。本因此,文通过改善传统的训练方法来增强模型的鲁棒性,改善网络对噪声、遮挡和视角变化的抵抗能力。在视频分析领域,人体行为识别的研究逐渐成为备受关注。它具有广泛的应用和很大的实际意义。可以看出,大多数算法利用具有先验知识的深度卷积神经网络完成用于行为分类的视频序列的时空域特征的提取。在本文中,针对视频行为动作的类内类间变化太大,视频中复杂的环境背景因素(环境的变化,镜头的抖动等)的影响,高层次视觉的难以理解和表示等问题,在三个公共视频数据库上完成了对人体行为的分类,分类结果证明基于统计人体姿态信息的分类方法具有良好的效果。创新点主要包括:时空域特征的有效提取和描述,不同类别特征之间的融合(包括局部特征和全局特征融合、时序特征和空域特征的融合),基于多核支持向量机人体行为识别等。"
60,机器学习方法在上市公司财务舞弊预测问题中的应用,"上市公司公开发布的财务报表是使投资者了解其公司规模、经营状况、盈利潜力等综合水平并做出相关投资决策的最主要依据。过去人们认为,数据是最具有说服力的,而且如果财务报表中的数据出了差错,很容易通过较为简单的计算来发现,因而对财务报表给予了极大的信任。然而,随着市场经济的开放和现代技术手段的发展,一些上市公司为牟取私利而对财务报表进行舞弊,且舞弊手段日渐隐蔽,有时很难被及时发现,其潜在危害十分巨大。因此,亟需有效的方法来预测财务舞弊。本文旨在通过建立数学模型,针对上市公司公布的某年度财务报表数据进行分析,根据模型预测结果判断其是否存在舞弊现象。通过查阅近年来的相关文献发现,国外对财务报表的研究主要关注公司破产和公司财务危机等问题,国内研究主要关注上市公司是否会被特别处理(ST)及其是否会出现财务困境,而对财务舞弊预测的相关研究较少,因此本文对财务舞弊预测进行一定的研究和分析是很有意义的。本文将机器学习方法应用到财务舞弊的预测中。机器学习既可以自上而下的验证或反驳假设,又可以自下而上的从数据中得出无假设的结论。因此,本文采用机器学习方法分别建立了三种模型:Logistic回归模型,支持向量机(SVM)模型,以及随机森林(RF)模型。Logistic回归模型在发现隐藏的数据信息方面应用广泛,以往的研究也证明其具有良好的效果,本文以此为基础进行讨论,并对模型做出了一些改进。由于财务报表是否舞弊是一个典型的分类问题,因此采用机器学习中分类和预测更加准确的算法可能会取得更好的效果。由于获取的样本量有限,而样本维数较高,并且恰为经典的二分类问题,于是处理具有这些特性数据的支持向量机模型成为了一个很好的选择。随即,由二分类自然地联想到二叉树,从而对各个决策树分类器拟合集成效果较好的随机森林模型也成为了本文的选择。由于财务报表舞弊手段存在变化,模型若能随着时间的推移添加或删除变量以及自动选择变量,则能够更加有效地识别上市公司进行舞弊的财务报表。因此,对于每个模型,本文都利用交叉验证对参数进行选择,从而对模型进行了优化。根据2013-2018年间在证监会及其下属证监局官方网站上公布的被公开行政处罚的公司名单,本文收集了舞弊公司在不同舞弊年度的财务报表数据及相应年度非舞弊上市公司的财务报表数据。所获取数据中的一部分用来建立模型,另一部分用来检测模型。由于舞弊公司在上市公司总体中的数量相对较少,本文采用不同的数据处理方法,分别建立了非平衡数据加权模型、过采样模型和欠采样模型。对于模型效果的判断,本文选取了五个指标来进行分析。结果表明,欠采样方法下的支持向量机模型的查全率最高,而欠采样方法下的随机森林模型在其他指标上表现更好,因此本文建议在基于支持向量机模型对公司是否舞弊进行预测时,结合随机森林模型进行综合考虑。最后,对模型的应用进行拓展,用模型选择出舞弊概率较大的公司,并将其从股票池中剔除,回测结果表明投资组合的收益将得到提高,表明本文的研究具有很好的应用价值。"
61,基于机器学习的电网调控云防误系统研究与应用,"随着电网规模日益增大,各级电网运行人员面对的设备数量快速增长,日常工作中拟写操作票、日常操作、运行方式调整等都面临的误操作风险也逐步增大。单纯依靠人的主观意识去避免误操作难度太大。在此背景下,操作防误应运而生,由传统五防过渡到现在的拓扑防误,防误功能越来越多,防误面越来越广,目前防误系统的功能主要是,在调控指令发送前进行防误分析,若操作属于误操作,则进行闭锁,减少因操作失误造成的损失。而当前阶段的防误系统,主要还是基于专家经验建立起防误规则库,运行逻辑算法进行防误约束,防误规则库主要依赖人工进行配置,更新方式难以适应电网的快速发展。本文从新一代防误系统的建设需要出发,研究智能防误系统的构建,重点围绕基于机器学习的防误分析技术、基于边缘计算的调控云-端一体化防误技术进行研究,以全省运行单位实际操作为样本,通过样本训练形成防误模型,依托调控云数据共享的优势,构建云端广泛互联、边缘计算应用体系,旨在提高调控防误系统的识别精度和智能化水平,降低误操作风险,为电网的安全稳定运行提供支撑。论文主要工作和创新点如下:1)基于防误分析判断原理,从架构上和流程上对防误系统进行了重新设计,研究了基于机器学习的电网调控云防误系统的构建,并应用于实际电网调控自动化主站。2)将深度学习算法与防误分析理论相结合,引入基于栈式稀疏自编码器构建基于机器学习的防误分析神经网络模型,利用PCA和SVM提高防误分析准确率。3)基于边缘计算理论构建了防误系统调控云,实现防误系统的省地县一体化,解决了以往防误知识库各单位人工配置,无法对知识库进行统一更新的问题,为防误系统智能化提供了一种实用、高效、安全的防误手段。"
62,再次剖宫产术中出血危险因素分析及机器学习对术中输血预测研究,"目的:随着我国“二孩政策”全面放开,再次剖宫产产妇逐年增加。与初次剖宫产相比,再次剖宫产由于前置胎盘、胎盘粘连、子宫瘢痕等合并症较多,发生术中出血及输血的概率明显增加。因此,研究通过回顾性的大样本临床病例数据分析,探讨围术期患者因素及麻醉方式对再次剖宫产术中出血风险的影响;并利用相关临床数据构建术中输血的预测模型,分析比较人工神经网络(artificial neural network,ANN)、极端梯度提升(extreme gradient boosting,XGB)和Logistic回归3种机器学习算法对术中输血的预测效果。方法:1.通过检索医院电子病历系统,搜集我院2015年10月至2017年10月再次剖宫产产妇2442例的临床病历资料,年龄20~45岁,BMI18~40kg/m~2,ASAⅠ~Ⅳ级。剖宫产常规采用椎管内麻醉,全麻仅用于患者强烈要求、椎管内麻醉禁忌或失败等情况。根据术中出血标准分为明显出血组(MH组,n=494)和非明显出血组(NMH组,n=1948)。分析比较两组产妇的术前、术中和术后各项指标。然后以是否发生明显出血为因变量,将单因素分析中P"
63,数据驱动的物联网安全威胁检测与建模,"物联网的普及使得海量有漏洞设备连接入互联网,带来大量安全隐患,物联网安全问题成为物联网能否大规模应用的关键所在。随着大数据和人工智能(AI)的发展,物联网(IOT)呈现AIOT的发展趋势,物联基础设施将成为新一代的信息基础设施,未来也必将形成“物联”“数联”“智联”三位一体的体系结构,物联网安全解决之道也必然顺应物联网的发展趋势,实现以智能算法为引领、物联网安全数据为驱动的物联网安全解决途径。近年来,研究人员在物联网安全方面做了大量的研究,取得了一些重要成果,但还存在一些问题。例如,在安全管理架构方面,随着边缘计算、雾计算技术的不断成熟,分布式的安全管理架构已经成为物联网安全研究的主要方向;在流量分析方面,大多数研究都是将基于深度包分析等传统互联网流量分析技术直接应用于物联网流量异常检测,而很少考虑物联网流量特点的轻量级检测需求;威胁感知与知识建模作为当前安全领域的热点,主要用于潜在威胁发现,关联和评估,目前的研究成果能够分析资产的相关安全信息以进行风险分析和评估,但无法实现知识之间的关联和推理,不能及时自动发现和更新安全知识。本文紧紧围绕数据驱动物联网安全的研究思路,首先对物联网安全知识和数据类型进行了汇总分析;其次,以物联网流量数据,物联网安全知识库数据为基础,运用随机森林等机器学习算法以及知识图谱等智能技术,对模型中的设备识别模块,异常检测模块,威胁感知和安全知识管理模块分别进行了研究;最后,结合物联网的典型特点,设计了一种分布式的物联网安全管理模型。主要内容如下所述:1.汇总分析了物联网知识数据类型。梳理了包括物联网系统和网络基础知识数据、安全威胁知识数据、安全防护知识数据、安全核心数据在内的四种知识数据类型对后续研究内容,如设备识别、异常检测、知识图谱威胁建模等提供了数据理论基础。2.研究了防止可疑设备接入的物联网设备识别问题。首先提出了通过设置白名单,进而构建通信流量特征指纹的物联网设备识别方法;其次,提出了使用随机森林方法来训练设备识别模型的方法;最后,通过实验验证了设备识别模型的检测具有较好的检测准确率。3.研究了有效应对DDOS攻击等物联网安全威胁的流量异常检测方法。提出了一种基于设备型号的流量异常检测模型,首先采用设置阻尼时间窗口的方法提取时间统计特征并构建指纹,根据设备类型对指纹进行分类;随后采用主成分分析法对特征进行降维并用BP神经网络算法进行异常检测的训练和识别。通过比较随机森林与支持向量机在检测中的效果,实验表明,在基于设备型号的异常检测方面,BP神经网络具有最好的检测效果。4.提出了一种能够处理复杂安全关系和具备动态更新机制的知识管理模型。首先,研究了自顶向下的物联网安全知识图谱的构建流程,重点研究了物联网安全本体建模、知识抽取、知识融合以及知识推理;其次,设计并实现了一次物联网安全知识图谱的构建过程,即网络爬虫爬取信息,三元组数据存储以及Neo4j知识库可视化;最后,使用cypher查询语言检验了对各类安全属性和关系的查询效果。实验验证了该方法能够快速准确的查询到物联网安全信息,为安全管理人员提供可靠的安全指导。5.设计实现了一种分布式的物联网安全管理系统。共包括三个主要模块:设备识别模块、异常检测模块和威胁感知模块,分别对应本文的三项主要研究内容。其次,该系统包含安全网关和安全服务器,安全网关负责监视设备,获取流量,构建指纹以及检测设备异常。安全服务器根据安全网关提供的流量、指纹和异常检测结果执行设备类型的识别,构建异常检测模型以及完成安全信息知识库的关联。"
64,基于推理机和GBDT的企业赊销信用风险研究,"赊销销售已成为一种常态化的企业销售模式,会影响企业的经营成本,限制企业的发展规模,对采取赊销销售业务模式而又没有相应的赊销信用风险管理的企业必然会引起企业经营不确定的风险。如何有效识别优质客户,规避赊销信用风险一直成为困扰着企业赊销信用风险管理的核心问题。本文首先对国内外文献中针对商业信用风险管理相关理论进行了梳理分析,发现赊销信用风险问题单纯的运用理论分析和单统计模型分析得出的结论都存在片面性,且统计模型研究通常基于一些统计学假设,进而导致结论与实际状况有偏。其次,本文基于大数据和机器学习理论支持,结合国内外文献研究结论,对某行业龙头企业的目标赊销客户进行研究,以企业内部赊销客户为样本,对已有历史交易记录和客户基本信息进行分析,预测客户赊销账款逾期信用风险。本研究将时序数据转换成统计特征与基本特征进行结合,从时间维度、空间维度两方面挖掘目标客户赊销风险评估模型的特征表现,构建多层次集成学习模型,通过与SVM、MLP以及Logistic回归等经典模型进行对比,考察预测模型ACC和预测耗时等指标的表现,从理论上得出同一数据集情况下,得到客户赊销信用风险评估模型最优拟合模型。通过对比传统推理机和本研究的混合推理机的效率和准确度,混合推理机在输入特征较多情形下获得极高准确度的同时极大降低推理耗时。同时,对于混合推理机中机器学习模型部分,使用新的集成学习模型代替传统的线性模型和多层感知机,在小数据集上获得与线性模型接近的准确度和性能,在大数据集中较线性模型获得了更高的精准度,相对于多层感知机获得了更高的效率。本文还针对企业实际赊销业务场景,深入分析赊销信用管理流程,评价了各个环节的风险漏洞。提出新的基于混合推理机的赊销信用风险管理流程,并从事前预防、事中控制、事后跟踪三个阶段保证各业务部门和信用管理组织之间的协同运作,覆盖企业赊销信用风险管理的主要环节和关键控制点,形成交易环节的全过程闭环信用管理。"
65,基于大数据平台的恶意IP分类算法研究,"随着互联网的快速发展,在铁路售票系统中,网络售票量远远超过了车站窗口、全国代售点等售票渠道,网络购票成为了大众出行购票的首要选择。同时受利益驱动,互联网售票行业也面临着灰色产业的威胁。研究发现,在春运、节假日等售票高峰期,频频存在恶意刷票的现象,严重影响了用户正常的购票体验。为了对一些恶意数据请求进行拦截和实时处理,开发了基于大数据平台的风控系统。在该系统的策略分析环节,由于无法有效的区分当前请求IP的来源,影响了策略阈值的选取,存在着误伤的风险。此外售票系统面临着每天上千万的访问量,产生了海量的数据集,如何高效的进行数据分类也成为了问题的关键。本论文针对以上问题,结合数据挖掘相关知识开展了研究,提出了基于大数据平台的恶意IP分类算法。本论文的主要贡献包括以下方面:1.在恶意IP分类问题上,本文介绍了常用的分类算法,通过仿真实验,分析了已有算法的优缺点,筛选出更适合当前应用场景的随机森林算法RF。为提高分类精度,提出了基于随机森林的恶意IP分类算法IPRF。IPRF算法主要是改进了特征选取步骤,采用了 Bagging与Forest-RI相结合的特征选取方法,增加样本特征选择的随机性,构建分类器时,引入了基于OOB估计的权重计算。通过五组数据集的对比实验,表明IPRF算法有效的提高了分类准确率,提高了分类器的性能。2.在数据分类效率问题中,针对海量的数据量,提出了基于MapReduce框架的并行化思想,结合IPRF算法,提出了基于大数据平台的恶意IP分类算法,研究并设计了并行化流程。基于大数据平台,通过三组不同数量的数据集进行对比实验,验证了算法的可行性,缩短了算法执行时间,有效的提高了数据处理的效率。基于大数据平台的恶意IP分类算法的实现能够使得在风控系统的策略分析环节更加完善,有效的避免对正常用户的误伤,从而促使策略的阈值选取更合理化,从而更好地完善风控系统,有效的加强对异常购票行为识别。"
66,基于GPS定位数据的出行行为研究,"进行居民出行调查、分析居民出行特征和掌握居民出行规律是科学规划和有效管理交通系统的重要环节。通过传统的问卷调查法来获取居民出行数据极易受到调查对象主观意识的影响,而通过GPS中记录的地理位置及时间信息来获取居民出行数据的方法能够避免该不足,为交通建模以及交通运行监控平台的搭建提供了全面可靠的数据支撑。因此利用GPS设备获取出行轨迹数据来研究居民出行行为、掌握交通分布特征成为近年来学者们研究的热点。其中,通过挖掘分析GPS轨迹数据,获得完整的出行链信息,进行居民交通出行方式和出行目的的识别是研究出行行为的主要内容。本文在获得出行者的GPS轨迹数据基础上,采用C4.5决策树、BP神经网络、随机森林等机器学习算法识别交通出行方式并结合地理位置信息识别出行目的。首先对所采集的数据利用一定的剔除规则进行预处理,从中提取出行特征。为提高数据质量,采用五点三次平滑法对轨迹数据的速度和加速度进行平滑处理。其次,为从离散的轨迹数据中确定出行者的停留信息,利用设定的时间参数和距离参数提出了三维数据处理的时空聚类算法。根据居民停留位置和时间信息提取轨迹数据中的出行段,提取各出行段的特征参数并利用C4.5决策树、BP神经网络、随机森林三种机器学习算法识别交通出行方式,结果表明随机森林算法的效果最佳,准确率最高可达到90%。最后为弥补以往基于规则判断出行目的的局限性,利用高德地图服务,提取出行者停留区域周边的POI信息并计算信息熵,结合时空聚类算法所获得的停留时长、停留开始时间等特征,识别居民出行目的。研究结果表明,基于GPS数据对出行行为的研究能够较好地应用于出行方式的识别和出行特征的分析中,对于GPS轨迹数据在居民出行研究领域的推广、分析居民出行行为规律、促进城市交通系统的健康发展具有重要作用。本文有两个主要创新点:首先,为了将轨迹数据划分为单一交通出行方式的出行段,设计了一种三维数据时空聚类算法识别出行者停留的位置和时间;其次,在识别交通出行方式中,使用了人们较少使用的随机森林算法,得出的精度比C4.5决策树、BP神经网络等算法的识别精度更高,并且在识别出行方式的类别中,加入了常常忽略的电动自行车的识别,对其识别的准确率高达88%。"
67,面向气象数据监控系统的优化设计与研究,"气象数据是气象领域开展预报和研究的基础。气象数据的准确、可靠和安全与否直接影响数据的传输、加工和天气模式预测等工作,进而影响监控系统、数据加密解密等方面的设计。现阶段气象系统在资料传输、运行监控和数据安全等方面存在一些不足:第一,气象系统网络结构相对落后,然而传输时效、质量控制与处理等方面的现实需求却与日俱增,在此背景下,优化网络结构和加强气象数据传输的能力亟待提高。第二,气象数据多以明文存储。随着气象数据的战略价值不断提升,国内外以窃取敏感气象数据为目的的攻击渗透不断增加,明文存储面临信息泄露的风险不断增大。第三,多数气象信息监控系统相互独立,各系统重要性定位不清,同时缺乏必要的关联关系,导致各类告警需要人工进行分析和处理才能实现故障源定位,处理效率相对较低。本文以解决上述问题为出发点,首先通过设计MSTP和MPLS VPN混合组网的方案,对国家级和省级气象部门之间数据传输时效性、稳定性以及安全性等进行优化,解决了气象网络稳定性不足和资料到报时间无法满足考核节点要求的问题。然后利用机器学习的有关技术,通过Louvain算法确定各系统的重要性和系统之间的连接关系,使用逻辑回归和TF-IDF算法对原有告警日志进行分析,提取关键信息,完善新系统的告警内容,以此为基础设计一套全流程的数据监控系统,将原有多个系统的监控信息进行整合,实现从数据到报信息到设备运行情况的全面监控,最大限度地提高运维监控效率,解决原有监控运维的低效问题。最后,初探可搜索加密技术在气象数据存储方面的应用:首先利用时效性要求相对较低的监控数据进行加密存储和检索来验证其可用性;进而选取部分核心气象数据进行实验,进一步验证其在气象领域应用的可行性,为后续深入的研究打下基础。本研究方案创新性如下:(1)在气象领域应用混合组网方式,解决国省气象部门之间气象数据交互时效性问题。(2)实现国家级气象业务系统的全面监控,通过有关机器学习算法对监控过程进一步优化,提高整体运维效率。(3)设计和实现了一种简单的可搜索加密算法并在实际环境下进行了验证,为该技术在气象领域的应用打下一定的基础。本研究结果一定程度上解决国家级和省级气象数据传输和监控过程中存在的主要问题,也对全国各省级气象系统的建设和优化有一定的参考意义。"
68,基于大数据平台相关技术下的银行个人客户信用风险评估,"互联网技术的发展是迅速的,而数据信息的增长的速度更是呈指数级,大数据相关技术对各领域的发展方向和发展方式造成了巨大的影响。在银行业看来,海量数据、大数据技术既给其发展带来了全新的发展机遇,同时也让银行的各项传统业务在发展创新过程中面临着巨大的挑战。本文从银行个人客户的信用风险方面着手,旨在通过大数据技术提升银行信用风险管理水平。本文学习了大数据基本概念,分析了大数据的相关技术对银行业的影响,并进一步研究国内外目前对于大数据相关技术的研究以及在金融业中的具体应用。同时,还研究当前银行业主流信用风险控制方法,阐明银行个人风控体系建设的意义。本文重点关注个人客户违约率测算,通过对比主要的个人客户违约率测算方法,本文最终选用逻辑回归方式进行预测。为了更加贴近银行实际,本文以无锡市A银行为基础,结合该银行现有系统体系,进行进一步研究。基于华为的大数据产品平台,通过Spark Mlib工具进行机器学习,逻辑回归。最后分析运算结果,发现模型的准确率维持在80%以上,结果在我们的接受范围之内。在研究的过程中,遇到了各种各样的问题,受限于个人研究水平及用于建模的数据完整性,最终结果并未如预先计划的那样完美,但我们可以初步得出以下结论:数据的收集及处理能力将很大程度上决定后续工作的难度和最终结果的准确度;充分地进行数据挖掘,对风控模型的建立有着非常重要的作用;在数据收集的渠道方面,除了需要收集传统渠道下结构化数据,还需要收集互联网甚至物联网下的非结构化数据;本次探索对数据的相关检验做得还不够。对于结果分析,考虑到训练模型的数据量较少,结果基本可接受。此次研究为今后个人客户信用审核作参考,对降低银行个人客户信用贷款不良率有一定的参考意义,也提供了一种新的思路。"
69,基于骨架点分割算法的文本验证码攻击模型的研究,"验证码,又被称为区分人类和计算机的图灵测试,是世界上使用最为广泛的公共全自动安全程序。验证码的设计目的,在于确保每一个在网络中访问的用户都是人类而非计算机程序。这样既保证了服务器能够服务于人类,也避免了由程序恶意攻击而导致的服务器瘫痪、网络秩序的混乱和财产的损失。目前,验证码主要包括文本验证码、语音验证码、行为验证码等类型。在众多的验证码形式中,文本验证码由于它的易于设计和维护、代码体积小等优点,成为了使用最为广泛的一种验证码形式。所以,针对文本验证码的自动识别技术备受关注。目前文本验证码采用的防御技术大致分为复杂的背景、噪声、干扰线、扭曲旋转、字符粘连五类。字符粘连是目前的验证码防御技术中相对可靠的一种,此类验证码内的字符通常有10%到50%不等的重叠,且字符的长度也不固定,无法通过预测字符的潜在区域来分割验证码。当验证码分割算法无法准确分割字符时,分类器的识别性能会降低。所以字符粘连型验证码被广泛使用。不定长度的字符粘连型验证码仍然是验证码识别领域的研究热点。本文针对字符粘连型文本验证码,设计了一种新的基于骨架分割算法的验证码攻击模型,该模型能够有效地破解字符粘连型文本验证码。主要工作内容分为以下几点:(1)根据传统验证码分割算法的不足以及粘连字符验证码的特点,提出了一种新的文本验证码分割算法。该算法不同于传统方法的“切片式分割”,而是通过打破字符内部结构的方法,将字符破坏重组,从而将字符从验证码中分离出来。该算法能够快速有效地分离和识别字符,相较于传统的分割算法(CFS算法,三色柱投影法等),正确率有了较大的提升。(2)重组后的字符序列的临近字符具有相关性,而传统Softmax输出层只能对依据内容对图片进行分类,无法利用字符序列的相关性信息。针对这一缺陷,提出Scored输出层,通过Scored函数对每一个可能存在的字符赋予置信分数,最后在输出序列中选取前K个(K为验证码包含的字符数)最大置信度为输出,增强了网络的表达能力。(3)设计了大量实验来评估所提模型的性能。实验的数据集包含Microsoft,Apple,Wikipedia等世界上流量较大的十余个网站的超过10000张文本验证码图片。实验结果表明,本文模型能够取得良好的效果。此外,与传统的验证码分割算法以及最先进的验证码攻击模型分别进行了对比。结果表明,基于骨架点分割算法的验证码攻击模型在识别字符粘连型验证码方面具有一定优势。"
70,网络垃圾信息识别方法研究,"网络以一种全新的信息传播方式影响和改变着我们的生活,也让我们不经意进入了一种大众传媒的新时代中。在网络中人人都可以随时发布信息,这导致了网络信息的泛滥,同时也导致了网络垃圾信息的泛滥。近几年,深度学习技术迅猛发展,大大改变了自然语言处理领域的现状。本文针对Quora网站上的提问标题作为文本数据进行分析,希望识别出其中的垃圾信息即虚假提问。由于数据的特殊性,很多提问文本作为垃圾信息具有一定的隐蔽性。传统的基于词频的机器学习方法的表现受到了限制,这类问题对我们的模型和效果提出了新的要求。因此,本文同时运用机器学习和深度学习的方法,进行对比研究,探索各种方法在Quora数据集上的表现情况。本文采用的传统机器学习方法分别是朴素贝叶斯模型和逻辑回归模型。在传统机器学习方法中,我们通过TF-IDF技术将文本转化成向量,作为模型的输入,通过对模型超参数进行调整,提高模型分类效果,然而,这两种单个模型的表现均不优秀。因此,本文又将两种分类的结果作为输入,用岭回归构建堆叠法集成模型,并通过调整正则化项系数,使模型效果提升,同时避免过拟合。最优秀的传统机器学习模型达到了0.60436的F1-score。在本文采用的深度学习方法中,本文使用词嵌入技术将每个词转化为固定维度的向量,一篇文档则转化成矩阵形式,作为模型的输入。本文共选取了三种预训练词向量,并一一进行实验。然后,本文依次使用了卷积神经网络,循环神经网络,胶囊神经网络作为分类器进行预测分类。在卷积神经网络中,本文采用的架构是通过四组卷积层和池化层得到输出结果,再通过平坦化以及全连接层预测最后的分类。在循环神经网络中,本文采用的架构是词嵌入层加上两个双向循环神经网络再加上全连接层预测最后的分类。在胶囊神经网络中,本文采用的架构是词嵌入层加上空间随机失活层加上双向门限循环单元层加上胶囊神经网络,最后用全连接层预测最后的分类。实验结果表明,三种深度学习的方法效果均远优于传统机器学习方法,最优秀的是胶囊神经网络,得到测试集F1-score为0.69782。但是,深度学习模型也有其不足之处,由于其参数量较大,模型训练所需时间较长。如何在不损失模型精度的同时,提升模型的训练效果,将会成为今后研究的重点。"
71,基于遗传算法的P2P网贷违约预警模型研究,"P2P网络借贷作为小额信贷领域的一种延续和创新,是民间普惠金融和互联网金融的重要组成部分,对传统信贷业务结构构成了补充,自21世纪初出现以来在全球范围内得到高速发展。按照行业成熟度和监管力度划分,我国P2P网络借贷行业的发展大致可分为两个阶段。2007-2015年期间,国内发展普惠金融和互联网金融的需求与P2P网贷相适应,同时监管相对滞后,行业在这一阶段表现出快速而野蛮的生长态势。2015年后,我国监管持续发力,在国内外新的经济金融环境压力下,该阶段表现为“劣质平台”的淘汰和大量平台的跑路失联、停业违约,对剩余平台提出了更高的风控要求。为此,在监管趋于完善、行业趋于集中的趋势下,本文将回归微观风控,聚焦对用户的违约预警模型研究。本文在使用Logistic模型构建P2P网贷违约预警模型的基础上,尝试利用自启发的全局搜索算法――遗传算法来优化其特征工程。首先,为更全面地探索优化过程细节,以数据披露相对完备的美国Lending Club数据集为研究案例,通过数据清理和多次遗传运算获得优化模型,结果表明优化后的模型可以使原分类模型在准确率、精确率和召回率均得到显著提升。然后,为探索优化方法在国内网贷实务中的应用价值,本文进一步以国内的拍拍贷数据为研究案例,比较分析中美网贷违约风控的差异,通过实证分析,得出模型的预警效果在各项指标上得到较为明显的提升,验证了优化效果,对前文研究内容进行补充。未来的研究可以针对本文在算法综合性、违约行为多分类上的不足之处进行扩展。最后,本文通过所探究的技术应用,基于数据风控的角度,对我国P2P行业发展及监管提出以下四点建议:第一,打通平台间与平台外授信数据,防范过度授信;第二,数据开源,吸收社会算力与研究方法,增强模型精度;第三,积极创新,在传统信贷分析框架中扩展新数据维度,积极使用诸如遗传算法等机器学习算法,同时注重扩展诸如“朋友圈”、“常去地点”等新型信用分析指标;第四,推动数据立法,规范电子合同,完善网贷数据登记、披露机制。"
72,基于卷积神经网络的交通方式识别研究,"随着移动互联网的迅速发展,具有全球定位系统(GPS)定位功能的移动终端设备无处不在,这为研究交通问题提供更多便捷性。用户出行的交通方式是交通需求分析和交通运输规划的重要组成部分,因此对用户出行的交通方式的研究具有重要意义。随着城市交通的快速发展,居民出行方式、出行次数以及出行距离数据变得极其庞大。传统调查居民出行数据的方法主要基于人工,但面对快速增长的居民出行数据时,传统调查方法的客观性不足、成本高、调查周期长等问题逐渐暴露出来。近年来,GPS定位技术的发展推动了GPS设备和服务成本的降低,具有定位功能的智能手机全面普及,这进一步推动了居民出行交通方式智能识别与数据自动采集的研究。GPS设备记录的数据具有质量高、更新快、覆盖范围广等优点,这使得GPS轨迹识别成为解决传统出行调查问题的新兴方法。GPS数据记录的是用户时空轨迹数据,如何从GPS轨迹数据中自动识别出用户出行交通方式的语义信息成为了研究的重点与难点。对出行交通方式识别的研究最主要的难点在于参数选取、时序分析等,参数选取不合适、时序分析方法不对都会阻碍交通出行方式识别准确率的提高。本文针对以上难点,设计基于深度卷积神经网络模型,从GPS轨迹中识别交通出行方式,实现对自行车、步行、小汽车与公交车的识别。本文首先对原始GPS轨迹数据进行预处理,包括阈值处理和平滑处理,去掉异常数据以及受外界干扰较大的数据,得到质量较高的GPS轨迹数据,这为研究奠定数据基础。其次,对预处理后的数据进行深度分析,根据分析结果,对不同交通方式的速度、加速度、急动度、转向角4种特征进行对比,阐述选取这4种特征能作为区别不同交通方式的原因。再次,在上述分析的基础上,选取多组不同层级的卷积神经网络,以上述4个参数作为各组卷积神经网络的输入层,对比各组卷积神经网络的识别结果,选出识别效果最佳一组。最后对得到的卷积神经网络模型进行优化,得到识别效果最优的卷积神经网络模型。将本文得到的卷积神经网络模型的研究结果与传统出行交通方式识别以及其他研究结果对比分析发现,本文所建模型的识别效果更优,也证明了卷积神经网络模型在出行交通方式识别领域的优越性。"
73,基于神经网络的电子病历实体识别,"电子病历是指记录病人从进入医院到结账出院期间所接受的所有诊断和治疗过程的原始信息。它除了包含大量医学术语、医患间的自由叙述,即医嘱、忌口、查房记录和患者对肢体疼痛的描述外,还包含了检验结果及其单位或剂量p频繁出现的缩写药物名等。通过对电子病历进行识别获得的医学实体以及其他医学领域相关的术语,对加快构建计算机辅助诊断系统的智能化起着非常重要的作用。最近,越来越多的学者们尝试将深度学习模型应用于对电子病历医学实体识别任务中。本文采用BERT模型和在序列标注任务上应用最为广泛的双向长短时记忆网络开展了医学领域命名实体的识别研究,并进行了实验验证。首先,实验数据使用全国知识图谱与语义计算大会2018年的电子病历评测数据,分别在BiLSTM-CRF和BERT模型下进行实验,从中文电子病历文档中提取医学类命名实体并采用BIO标注策略给出其所属的实体类别和位置信息。其次,探讨增加领域数据集对模型识别效果的影响,采用BiLSTM-CRF和BERT模型对扩充后的数据集进行实验。实验结果证明,通过增加领域数据能有效提升模型的识别效果。最后,将两组数据集上的实验结果与CRF基线系统和前人的工作进行对比与分析。在评测数据集上进行的实验中,BERT模型识别效果最好,F1值达到93.93,超过CRF4.26%。其次是BiLSTM-CRF模型,F1值为90.91,两种NER模型实验效果都高出CRF模型。而在扩充后的数据集上进行的实验中,BiLSTMCRF模型呈现明显的提升,F1值从90.91到95.25提高了4.77%,与前人的工作相比,本文实验结果也明显高于前人的工作(F1值分别为89.09、90.14和88.61)。本研究采用两种不同的深度学习模型对中文电子病历进行了医学领域命名实体的识别。实验结果证明,对比传统的CRF方法,BiLSTM-CRF方法在进行中文电子病历实体识别时能实现特征的自动学习、捕获文本序列的长距离依赖关系,同时也验证了使用神经网络进行电子病历实体识别任务的有效性。"
74,基于分子描述符的中草药化合物类药性预测及应用研究,"目前,中草药已经在世界范围内得到了广泛的关注。中草药的治病机制与西药的治病机制在分子水平上比较起来,大多数中草药的治病机制却尚不清晰。如何让中草药与现代医学接轨,中草药的计算机辅助现代化研究就显得尤为重要。虚拟筛选、药效团模型、机器学习等中草药化合物类药性预测方法都是极为重要的计算机辅助中草药现代化研究方法。当下越来越多的中草药化合物被广泛应用为候选类药化合物。制药公司开发药物的一个重要途径就是从中草药中发现具有相关靶点的潜在活性化合物。在众多中草药化合物类药性预测方法中,虚拟筛选技术可靠性强、预测速度快、预测精度好,因此一直处于中草药化合物类药性预测方法中的核心地位。特殊医学用途配方食品采取直接食用或胃肠导管给药的途径对营养缺乏的临床病人进行营养支持,是一种全新的应用于临床患者营养支持的产品。特殊医学用途配方食品由于具备防止患者胃肠功能退化、易于存储运输、价格低廉的优势,逐渐被临床医生和营养师所推崇。但目前市面上的特殊医学用途配方食品成分较为简单,营养素来源单一。论文首先综合研究了以上几种基于生物信息学的类药性预测方法,基于生物信息学的类药性预测方法在对整体数据库的类药性分析和对特定候选化合物的类药性预测上均具有较好的效果。在整体数据库的类药性分析方面,对化学品目录数据库、药物数据库和中药化合物数据库中的化合物进行了基于八种分子描述符的综合系统性分析。在特定候选化合物的类药性预测方面,对大枣多糖的类药性进行预测,并对大枣多糖在特殊医学用途配方食品中的应用提出设想。论文进一步以中药大枣为主要原料开发了一款特殊医学用途配方食品全营养配方产品,从营养素平衡的角度对配方进行了筛选和优化。最后由于开发的产品原料均为粉粒体,采用干法工艺制得成品。粉粒体状原料的混合均匀度与混合时间、成本之间的平衡问题一直是干法工艺亟待解决的难题。因此在充分研究各原料质量分数、粒径分布、Carr流动性指数、松装密度、含水量的基础上建立适当的混合工艺流程进行试验。通过对混合时间、混合装填量、混合转速的分析,找到时间、成本与混合均匀度的平衡点。综上,论文基于分子描述符研究化学品目录数据库、药物数据库和中草药化合物数据库,得到中草药化合物数据库中分子相较于其他来源化合物更具备类药性特征的结论。对大枣多糖的类药性进行分析,确定其具备较强类药性和生物活性。从营养素平衡的角度对特殊医学用途配方食品的配方进行了筛选和优化。通过对混合时间、混合装填量、混合转速的分析找到时间、成本与混合均匀度的平衡点。"
75,基于机器学习的线路跳闸预警研究,"电网线路跳闸预警是电网领域的重要课题,其主要研究内容在于通过准确预测电网线路跳闸发生概率,通过提前干预,消除电网运行过程中跳闸故障,提高电网运行稳定性。当前国网中线路跳闸预警方法只能依赖预测雷电,间接的预测跳闸概率,准确率低,过分依赖专家规则。本文根据国网线路跳闸预警方法缺乏运用运维数据与机器学习技术现状,提出了一种新型的基于two-steps的线路跳闸预警算法。其中:第一阶段为基于置信度与基尼不纯度的线路跳闸相关属性选择算法,第二阶段为基于集成学习的线路跳闸预警算法。相关研究归纳如下。第一阶段:首先对线路跳闸相关数据进行可视化分析,数据预处理,特征工程等;然后通过对线路跳闸相关数据特征进行基尼不纯度计算,获取线路跳闸相关属性特征排序,获取符合阈值要求的线路跳闸相关属性;其次基于置信度的计算与选取,在获取已排序好的线路跳闸相关属性中计算特征置信度,计算后可获得线路跳闸相关属性选择规则。最后将线路跳闸相关属性选择算法应用在测试集中,从而实现线路跳闸属性选择。第二阶段:首先收集整理第一阶段使用了线路跳闸相关属性选择算法的数据集作为训练数据。然后导入至基于集成学习的线路跳闸预警算法模型,进而完成模型的训练。最后根据训练完成的模型便可以进行预测。由于集成学习能够组合多个弱学习器得到更强更全面的学习器,在线路跳闸预测场景中使用集成学习方法的预测效果相比传统的数据挖掘方法更好。本文通过相关实验对提出的相关算法进行了验证,证明了其有效性和可行性。同时本文方案在J省的PMS(power production management system)系统中投入生产实测,进一步证明了上述方案的可行性和有效性。本文基于two-steps的方法,降低了样本数据维度大小,提高了预测准确性,在实际生产中取得了不错的效果。同时不需要额外的检测设备,可适用于不同级别的线路,具有良好的可推广性。"
76,基于深度学习的肝脏疾病诊断,"肝硬化等相关肝疾病日益威胁着人类的健康,因此对于肝疾病的诊断具有十分重要的意义。然而客观临床上采集的医学肝影像存在纹理结构不均匀,生理病变不清晰等问题,使得临床医师在主观诊断时容易存在一定的误差。因此针对上述问题,借助于计算机辅助诊断技术,本文首先在传统机器学习领域本文采用了MB-LBP和Gabor做特征融合,结合学习矢量化神经网络LVQ实现了对肝类疾病较好的分类。但是机器学习方法仍存在诸多弊端,人工提取特征耗时耗力,并且提取高质量特征存时也在一定困难。针对上述问题,本文进一步采用了深度学习的方法,其自动学习特征分类,极大提高了运行效率并且泛化性能力更强。本文基于该领域主要提出了两种识别系统:(1)本文首先使用了轻量级卷积神经网络SqueezeNet,相比较于传统卷积神经网络的网络层数多,结构参量大等问题,其具有更少的参数,训练更加方便高效,并且更加适用移动端或者嵌入式设备的深度学习应用。本文通过轻量级卷积神经网络SqueezeNet与SVM支持向量机相结合,较好的实现了对肝硬化识别分类。(2)其次,本文首次提出了一种新的模型结构GoogleNet-PNN,结合了GoogleNet卷积神经网络高效精准的学习图像特征和PNN概率神经网络训练容易、收敛速度快等的优点,并使用PSO粒子群算法优化了该结构,在肝病分类的实验中取得了较好的效果。由于深度学习的网络模型需要一定量的样本集训练参数使其达到最优,而现实中的医学图像的样本集数量远远小于自然图像集,若训练不充分容易产生过拟合现象并影响最终模型的性能。针对上述问题,本文采用了迁移学习和数据增强两种方法进行预训练和扩充数据集的方式进行优化。本文在最后实际应用了部分训练好的模型,在医学诊断具有很好的参考价值。"
77,基于多策略的高校助学金精准预测的研究与应用,"近年来随着高等教育的普及,高校人数也随之激增。同时对于高校中经济有一定困难的学生,党和政府也下发了一系列文件来帮助困难学生,使他们顺利完成学业。当前高校决定是否资助贫困生以及确定资助学生的助学金发放等级是按照“学生申请―老师签字―学校审批”的程序来进行的,这样的程序不可避免的会受到一些人为因素的影响。与此同时,随着大数据和互联网时代的到来为高校处理精准资助问题提供了新的思路和技术支持。本论文采用四川某高校2013―2015两年的学生在校行作为数据挖掘对象,使用数据挖掘技术和机器学习算法建立高校助学金精准预测模型并以F1值作为该模型的评估指标。本文首先进行数据预处理,接着进行探索性数据分析和特征工程以期获得优秀的特征数据。随后通过交叉验证法校验模型精度,并在模型构建过程中对比了随机森林算法、AdaBoost算法、支持向量机以及GBDT算法在助学金精准预测模型上的效果,初步发现GBDT算法效果相对最优。为了进一步提高助学金预测模型的性能,本文利用集成学习中的Stacking方法进行多模型融合,最后结合GBDT算法,AdaBoost算法和随机森林算法通过一定比例融合由此进一步提升了模型的性能。这种基于多策略的组合模型可以帮助管理者获取大学生在校期间的日常行为数据和贫困生在该模型的资助等级划分,从而辅助发现“虚假认定”和“隐形贫困”学生,对于优化高校助学金评选发放,节省高校相关管理者时间和完善助学金发放监督机制都具有实际意义。"
78,基于改进机器学习方法的股票预测研究,"随着我国经济的快速发展,人民的生活水平在不断提高。人们在生活逐渐富裕的同时,对于投资的需求也在不断增长,并且投资方式也越来越多样化。股票投资是人们生活中很常见的一种投资方式,如果能实现一种高效的股价预测方法,据此制定股票投资策略,就可以降低人们投资的风险,并增加投资收益。论文中使用两种机器学习算法对股价进行预测,并将预测结果用于制定个股投资策略和组合投资策略。支持向量回归机和RBF神经网络模型在解决回归问题的实践中被广泛应用,尤其是在处理经济数据时有很好的效果,据此论文通过总结前人的研究成果,将这两种机器学习算法应用于股价预测这一实际问题中。实验中采用股票收盘价序列作为基本数据,并以坐标延迟法重构归一化后的收盘价向量。向量重构的参数时间延迟和矩阵维数采用复自相关法和G-P算法确定。实验使用遗传算法GA优化支持向量回归机SVR和LSSVR的正则化参数与核函数宽度,并使用K-means聚类算法优化RBF神经网络隐含层高斯径向基激活函数的数据中心点与扩展常数,以聚类簇数作为隐含层神经元的个数,并以此计算网络的初始权值;论文基于这两种算法对股票收盘价进行预测。实验使用坐标延迟法重构股票收盘价时间序列,简化了选取股价数据维度的工作,并且使模型可以基于历史数据预测未来一段时期的股票收盘价;实验在对支持向量回归机和RBF神经网络的参数进行了优化后,基于这两种算法对八种股票不同时间段的收盘价进行了预测,文中展示了预测的结果,并通过分析模型的预测结果和评价指标评估模型的优劣,分析结论表明支持向量回归机在训练集上的拟合效果总体上好于RBF神经网络模型,而RBF神经网络模型在预测集上的预测效果则略优于支持向量回归机;并且两种模型均有效预测出了收盘价的涨跌趋势。实验之后,论文基于预测结果对部分收盘价上涨的股票使用不同的策略分别进行了投资模拟试验,试验中收益率的计算结果进一步验证了文中使用的股价预测方法的可行性。"
79,基于网络行为的用户画像算法研究,"伴随着整个社会对互联网、特别是移动互联网的广泛接受,用户产生数据呈现爆发式增长。我们每天都会在网络上留下大量的行为数据,比如查询词、网页访问记录等,这些数据类型丰富、时效性强,为分析用户的爱好习惯及个人属性信息、构建用户画像模型,提供了充足的数据资源。用户画像是企业大数据的基础,充分利用用户行为记录数据,刻画出用户属性信息全貌,高效地构建用户画像,将有利于企业实现精准营销及个性化服务。传统人工给用户画像打标签的效率较低,所以借助算法模型来预测标签成为用户画像的一个热门研究方向。但是目前主流的机器学习算法未能深入挖掘特征间的复杂关系,在高维、稀疏特征时预测效果仍不尽人意,还存在较大提升空间。而混合算法往往能结合各算法的优点,一定程度上克服缺陷,提高预测精度。针对用户的查询记录数据,为了实现用户多维人口属性标签的预测任务,对用户画像构建方法进行了深入研究,研究工作总结如下:1)提出了一种基于随机森林算法的二层集成学习框架。在第一层模型中,基于6种传统的机器学习算法来作为用户查询词特征提取器,并与用户的数字特征相融合,作为第二层模型的输入;在第二层模型中,使用随机森林算法作为分类器,采用不同的拟合策略来挖掘用户画像和用户的人口属性标签之间的隐藏信息。最后,通过实验证明,相对于单一基模型,基于随机森林算法的二层集成学习算法有更好的泛化能力和预测能力。2)提出了一种基于XGBoost算法的二层集成学习框架。针对用户查询词语料的特点,本文分析对比三种常用的文档向量表示方法的优缺点,对Doc2Vec提出改进,并结合BP神经网络算法,提出了BPDM(BPNN based Doc2Vec Model)算法模型,用来抽取用户查询词语义之间复杂特征。使用BPDM算法和基于随机森林算法的二层集成学习算法作为本框架第一层中的用户查询词特征提取器;在第二层模型中,使用XGBoost算法作为分类器,以此来构建用户画像模型。实验结果表明,该方法能有效降低特征维度,丰富基分类器的多样性,高效、准确地实现用户画像模型对多维人口属性的预测。"
80,基于深度学习的风功率预测模型的研究,"风电场功率预测系统用于预测风力发电场未来一段时间的发电能力,便于电网进行电力调度,该系统是风电场并网发电的必要条件。目前,国内大部分的功率预测系统的预测精度都无法达到电网调度中心的要求。为了提高风电场功率预测的精度,对深度学习在功率预测模型中的应用展开研究,从数据质量控制、数值气象预报匹配、功率预测模型的设计等角度减小功率预测模型的误差。此外,针对部分风电场冬季风机凝冻无法发电的问题,提出基于长短期记忆网络的风机凝冻预测方法,该研究成果可提升风电场发电能力,有较高的实际应用价值。主要研究内容包括以下几点:(1)针对风电场历史数据存在大量异常数据、缺失数据的问题,研究了包括数据异常检测和数据断点填补的数据质量控制流程。对基于长短期记忆网络(Long Short-Term Memory,LSTM)网络的数据异常检测方法进行了研究,并与多种基于机器学习算法的异常检测方法进行了实验对比;对基于多视图学习的数据填补方法进行了研究,并与传统的插值法和基于整合移动平均自回归模型(Autoregressive Integrated Moving Average model,ARIMA)预测的数据填补方法进行了实验对比。(2)针对现有风功率预测系统准确率偏低的问题,研究了基于数值气象预报的功率预测模型。因数值气象预报普适性较差,提出基于相似性排序的数值气象预报数据源匹配方法;设计了基于四层反向传播(Back Propagation,BP)神经网络的功率预测模型,与同类型的模型相比,该模型建立了更为精准的风与功率之间的映射关系,极大地降低了因模型造成的误差。(3)针对部分风力发电场冬季风机凝冻影响发电的问题,研究了基于LSTM网络的凝冻预测方法。由于数值气象预报中温度、湿度等直接影响凝冻概率的因素误差较大,本文中使用风电场测风塔的实时测量数据代入LSTM网络模型进行未来一段时间的温度和湿度预测。实验表明,LSTM网络的预测结果与基于ARIMA的时间序列预测方法相比,预测结果与实际数据的拟合度更高。本文中研究的功率预测模型在多家风电场进行了测试,平均准确率在83%以上,在国内属于较高水平。本文中的凝冻预测模型可较为准确地预测风电场未来一段时间的温度和湿度情况,根据该预测结果,风电场可合理安排风力发电机加热系统的启动时间,防止风力发电机凝冻造成的损失,该方面的实际应用研究在国内尚属首例。"
81,基于语义分析的铁路车载无线通信设备故障分析与预测,"随着铁路信息化程度的不断提高,多业务融合需求程度不断增加,铁路工作者需要从纷繁复杂的业务数据中快速获取有价值的信息,传统的仅凭人工和传统的数据处理工具已经不能满足海量数据计算分析和列车运行实时监控的需求。铁路机车综合无线通信设备(简称为CIR,Cab Integrated Radio Communication Equipment)是确保列车调度指挥、保障行车安全的重要行车设备,承载着列车调度通信、防护报警、语音通信、列车尾部风压查询等重要功能。CIR设备在列车运行过程中记录了大量设备运行数据,直接反映出设备的运行状态。本论文力图通过对CIR数据的整理、分析,实现对车载设备故障分析与实时预测,为CIR设备维护、升级提供建设性意见。通过数据分析,可以对设备故障做到提前预防、事中诊断与定位、事后评估等功能,从而为设备维修工作的决策提供数据支持。本论文针对CIR数据进行深入分析、研究,根据其类似自然语言的特点,运用语义分析等自然语言学习领域广泛应用的数据模型进行深入挖掘分析,对无限隐马尔可夫模型和n-GRAM语言模型进行了改进,提出了 Beam采样无限隐马尔可夫模型和LSTM-n-GRAM模型,实现了CIR数据状态分类与与故障实时监测,与传统人工手动的数据分析手段相比,具有数据分析量大、准确性高、查询分析速度快、实时性强等特点。两种模型实现的方式和理论基础不同,但结论均反映了CIR数据具有马尔可夫性,丰富了列车故障分析与实时预测的理论,为设备维护与故障诊断提供了解决思路,并在铁路运输生产中得到了实际运用与验证,证明其具有理论价值和工程应用价值。具体包括以下几方面创新性工作:一是基于CIR数据的时序特性,结合马尔可夫假设,使用改进的无限隐马尔可夫模型――Beam采样无限隐马尔可夫模型对CIR数据进行分类,对正常状态和未知数量的异常状态进行划分,实现了对CIR状态的有效监测,并结合实际列车运行CIR数据进行了验证。二是考虑CIR故障监测的实时性要求,使用改进的n-GRAM模型――LSTM-n-GRAM模型进行了状态预测,并使用CIR数据得到了实际验证。实验表明:使用n-GRAM假设的短期数据与使用整个时间序列数据的模型性能没有明显差别,LSTM-n-GRAM模型在进行数据分析时无需使用全部数据进行计算,极大提升了计算效率,避免了梯度消失等问题。从而大大提高了 CIR状态监测的实时性。"
82,基于机器学习的多特征融合室内定位的研究,"近年来,随着移动互联网的发展以及移动数据业务的激增,基于位置的服务(Location Based Services,LBS)在人们的工作生活中的应用也越来越广泛。基于无线局域网(wireless LAN,WLAN)的定位技术以其硬件成本低、组网灵活、易于推广等优势受到众多研究者的关注,相关领域的研究成果相继被提出。其中,基于接收信号强度符(Received Signal Strength Indicator,RSSI)的指纹定位技术目前最为流行。基于指纹的定位技术依赖于指纹的独特性,以更好地匹配唯一的位置坐标。仅采用单一的RSSI信道特征作为位置指纹可能丢失大量的多径信息,限制定位精度的提高。因此,本文提出一种基于多特征融合的定位技术。通过相关的文献查阅以及仿真实验,完成了如下研究工作:(1)构建基于多特征融合的核机器模型。基于正定核空间变换理论以及借鉴图像处理中多特征融合方法,对正定核线性组合模型进行改进,构建基于多特征融合的核机器模型,实现多种特征在机器学习过程中自适应地融合。RSSI易受到环境的干扰波动性较大,定位精度不稳定。基于到达时间(Time Of Arrival,TOA)的定位技术在视距(Line Of Sight,LOS)条件下定位精度高,然而在未检测的直接路径(Undetected Direct Path,UDP)的条件下,定位性能急剧下降。而基于RSSI定位技术对UDP条件不敏感。因此,为实现RSSI与TOA的优势互补,本文构建基于RSSI-TOA融合的核机器模型。采用岭回归优化算法进行拟合,经仿真实验表明,基于多特征融合的核机器模型在参数优化的过程中具有自适应特征选择的效果,相较于基于单特征的核机器模型具有更高的精度和鲁棒性。(2)研究基于多特征融合的核机器模型的优化算法。提出基于Group LASSO正则化的样本选择算法、基于L1范数正则化的特征选择算法以及超参数优化算法。对基于Group LASSO正则化样本选择定位算法的优化过程提出了一种基于回溯线搜索梯度下降算法以及牛顿迭代法融合的高效迭代优化算法,仿真实验表明,此迭代算法的收敛速度较单一的迭代优化算法快10倍以上。(3)通过仿真实验对的四种优化算法从定位精度、鲁棒性以及计算复杂度方面进行性能评估,得出结论:岭回归优化算法、超参数优化算法的定位性能较优。同时采用性能较优的两种优化算法将本文的基于多特征融合的定位方法与基于Wi-Fi与PDR融合的反馈校正定位方法――扩展卡尔曼滤波(Extended Kalman Filtering,EKF)算法和无迹卡尔曼滤波(Untracked Kalman Filtering,UKF)算法进行性能比较,得出本文的超参数优化算法在精度和计算复杂度上的综合性能最优。"
83,基于大数据的铁路道岔缺口监测分析研究,"目前随着我国铁路行业高速发展,我国铁路基础设施的数量也在逐渐增多,而设备的健康状况管理与监测问题一直没有得到很好的解决。当前我国铁路对于运输设备的维护主要采取“计划修”的手段,即以预防为主的定期维护,而这种传统的维修模式已经不能满足我国铁路发展形式下的新要求,迫切需要对铁路设施运行与健康状态进行监测分析,采取“状态修”或“预测修”的智能维护模式。另外,当前铁路系统各专业也已经积累了大规模的海量数据,并且还在呈现不断增长的趋势,但目前还缺乏一种有效手段来对铁路基础设施的健康状态进行统一管理以及对设备运行过程中所产生的海量数据进行有效的挖掘分析。本文以道岔缺口及转辙机设备状态的监测分析为研究重点,全面了解分析了国内外研究现状,提出了铁路道岔缺口大数据智能监测分析平台的研究思路,并通过铁路道岔缺口大数据智能监测分析平台相关技术的研究,实现了铁路道岔缺口及转辙机设备的状态管理、智能监测与综合分析。本文主要研究内容包括以下几个方面:(1)首先围绕当前铁路道岔缺口监测现状与实际业务需求进行分析,并根据目前主流物联网、大数据以及机器学习的相关技术,对道岔缺口大数据智能监测与分析平台的整体架构、各部分主要功能以及所涉及相关技术进行了设计与研究。(2)在完成了铁路道岔缺口大数据智能监测与分析平台设计的基础上,对其各部分功能的具体实现方法与技术细节展开了深入研究,包括数据采集接入存储的实现、大数据处理分析的实现以及数据挖掘机器学习模型的实现等。(3)文章最后对于道岔缺口大数据智能监测分析平台在实际生产环境中的功能和性能进行了详细的测试,经过对测试结果的研究分析,证明了本文所设计平台能够有效地实现对道岔缺口以及转辙机设备的智能监测分析,满足铁路基础设施对于设备状态的管理和监测需求。"
84,CT影像组学在胃癌诊断及病理分型中的可行性研究,"目的探讨CT影像组学特征在胃癌的诊断及病理分型中的可行性研究。方法回顾性收集2017年11月至2018年3月唐山市工人医院肿瘤外科及胃肠外科经手术病理证实的胃癌患者59例,病理结果为印戒细胞癌患者14例,腺癌患者39例,印戒细胞癌中有部分腺癌组织及腺癌中有部分印戒细胞癌组织的患者6例。以病理结果为金标准,对59例患者CT图像进行影像组学研究。首先,59例患者均进行CT平扫检查,CT检查前均行胃低张气体充盈。将CT图像导入汇医慧影Radcloud平台,进行手动感兴趣区(Region of interest ROI)勾画(包括病变组织及部分正常胃组织),提取特征,采用方差阈值法(variance threshold)、K最优法(select K best)和LASSO回归(Least absolute shrinkage and selection operator)算法逐步筛选特征,然后随机将计算机生成的80%的数据(纳入胃癌诊断中的47人;纳入胃癌病人中进行病理分型的腺癌31人和印戒细胞癌11人,共计42人)分配给训练组进行训练,20%(纳入胃癌胃癌诊断中的12人;纳入胃癌病人中进行病理分型的腺癌8人,印戒细胞癌3人,共计11人)分配给验证组,对训练组进行验证,用ROC曲线(receiver operating characteristic curve,受试者工作特征曲线)分析来说明放射特征的预测性能。最后,对其中提取的更为相关的特征进一步进行统计学分析。结果1在胃癌的诊断中,训练组选取了25个较有鉴别能力的特征,AUC均在0.9以上,敏感度及特异度也均较高。其中四分位数间距(Inter-quartile Range)、能量(Energy)、运行熵(Run Entropy)及最大值(Maximum)的诊断价值更大,对其进行统计学分析,其诊断效能较高。2在胃癌的病理类型的研究中,训练组选择8个特征对胃腺癌与印戒细胞癌进行鉴别,其中差分熵(Difference Entropy)及偏度(kewness)的诊断价值更大,对其进行统计学分析,其诊断效能中等。结论1基于CT平扫的影像组学分析用于胃癌的诊断,可以为肿瘤的诊断提供参考,特别是四分位数间距、能量、运行熵、最大值的诊断价值更为重要,为胃癌的诊断提供参考。2基于CT平扫的影像组学分析在胃癌的病理分型的研究具有临床参考价值,其中差分熵、偏度的效能较大,可见减少有创检查,为临床选择胃癌的治疗方法提供参考。图11幅;表7个;参128篇。"
85,低速碰撞下汽车吸能盒结构优化设计,"随着时代与经济的不断发展,汽车成为人们生活中不可或缺的工具。随着汽车给人们带来便利的同时,也带来环境污染、出行安全等问题,尤其是汽车低速碰撞的发生越来越频繁。吸能盒是在汽车低速碰撞中起到重要作用的部件,它可以由自身的溃缩吸收碰撞能量,减少冲击对驾驶员和车身带来的伤害,然而现今市面上车型的吸能盒设计均存在碰撞峰值力过大与吸能量不足的问题,易造成前纵梁、发动机等重要零件的受损和对驾驶员的伤害。因此针对吸能盒优化设计的研究对于车身安全与碰撞吸能结构有很好的理论和实践意义。本文通过对比国内外碰撞标准与法律法规,选取美国汽车修理研究协会RCAR(Research Council for Automobile Repairs)标准作为参考基于非线性有限元理论基础建立吸能盒碰撞分析模型,完成低速碰撞试验在仿真平台上的实现,并在保证求解精度的情况下简化模型,极大提高了分析效率。选取了合适的吸能盒材料与其性能评价指标引导吸能盒设计。本文主要工作可以总结为几点:(1)建立了优化的锥形多胞吸能盒结构,提升吸能盒单位质量吸能量,更好体现轻量化设计理念。通过分析传统吸能盒与多边形吸能盒、诱导槽吸能盒、多胞吸能盒等设计的特点,结合锥形与多胞结构建立锥形多胞吸能盒,采用构建响应面模型的方法分析了壁厚与锥度对于锥形多胞吸能盒性能的影响并对其进行优化设计,优化后的结构相比较原八边形多胞吸能盒峰值力降低59.08%,单位质量吸能量提升77.11%。(2)采用机器学习的方法对折纸结构吸能盒进行预测、分析和优化。鉴于折纸结构在各行业领域中的应用及其特点建立折纸结构吸能盒仿真模型,采用参数化建模的方法实现折纸结构吸能盒自动化建模。采用机器学习的方法对折纸吸能盒的几何参数对其性能与塌陷模式的影响进行分析,随后采用多目标优化的方法对该结构进行优化设计,最终得到性能良好的折纸吸能盒结构,其峰值力较传统八边形吸能盒峰值力降低17.65%,且总吸能量与单位质量吸能量均有不同程度的提升。此研究的分析过程验证了机器学习方法在工程中应用的可靠性,为薄壁吸能结构与机器学习方法在工程中的应用奠定基础。"
86,面向家庭服务机器人指令深层信息提取,"随着社会和科学的快速发展,智能服务机器人已经实现了从荧幕到人们的日常生活中,要实现智能服务机器人更方便快捷地为人们服务,还是有许多问题需要解决。自然语言指令浅层信息已经完成了识别任务,本文是在指令关键信息的提取上进行了深入的研究,提出一种运用支持向量机算法来提取指令中隐含的深层信息,帮助机器人去理解语音指令。首先,本文在家庭环境中收集人们发给智能服务机器人的语音指令,对收集到的语料进行分词、词性标注等文本处理。其次,对语料库中的指令语句的实体特征进行分析,运用条件随机场模型并构造识别实体的特征模板,调用条件随机场算法进行关键信息识别。对于指令中隐含的深层信息在支持向量机模型的基础上,运用LibSVM方法来实现实体之间关系的提取,把提取到的实体信息和实体关系信息进行存储,以此方式来提高家庭服务机器人为人们服务的执行效率。最后,由于XML知识库具有方便操作速度快的特点,本文把从指令中提取到的浅层信息和隐含的深层信息都存放到了XML知识库中。在论文中出示了实体识别的实验结果和分析,本文实现了提取指令深层信息的识别系统。图11幅;表11个;参41篇。"
87,基于小波神经网络与支持向量机的股票预测及优化,"股票市场数据通常具有极强的波动性,对股票市场数据的预测一直以来都是金融领域的重要课题。股票预测即对股票价格指数的运行趋势进行预测,这也是国内外在统计金融领域的研究热点。传统的股票预测方法主要是线性预测法,其中较为常见的就是建立自回归移动平均模型。在金融研究领域,自回归移动模型(ARIMA)是一种主要的预测手段,这是一种线性的预测方法,其对一些平稳数据的预测效果较好,但是对具有强波动性的股票数据往往效果欠佳。由于ARIMA模型的非线性预能力较差导致其始终无法产生较为满意的预测结果,研究者需要寻找更多适用于股票预测的方法。机器学习对金融行业数据的处理有着得天独厚的优势,其能精准分析同一时间内的大量股票数据或财务数据的变动,并很快得出相应的结论,这样使金融市场的运行效率得到显著提高。在股票市场的趋势预测方面,其能运用股价指数的相关特征对股票市场数据进行预测,在财务数据管理方面,机器学习算法可对公司的资产负债表、现金流量表等财务数据进行有效分析。我们需要寻找一些可以对非线性数据具有良好适应性的预测方法,所以拟用机器学习的相关算法,本文采用的是小波神经网络(WNN)和支持向量机(SVM)。小波神经网络是将小波与神经网络结合的理论方法,这种方法融合了两种理论的优点,是一种有效的股票预测方法。支持向量机以坚实的数学理论做支撑,其采用核函数方法可以有效解决一些复杂计算,并应用结构风险最小化原则使得这种方法在金融预测领域广受推崇。使用BP算法的WNN收敛速度慢且易陷入局部最小,为改善模型性能,提高预测精度,拟用用粒子群算法(PSO)优化WNN,优化WNN参数以建立股票预测模型PSO-WNN。为了遵从实验的逻辑性,同样建立股票预测模型PSO-SVM。运用MATLAB进行仿真实验,通过分析实验结果,证明小波神经网络和支持向量机在股票预测中的可行性。设定相关统计指标衡量预测效果,评估优化效果,并分析比较模型在优化后的预测性能,最后综合分析整体的预测性能。"
88,非平衡化标记补全的多标记学习及其应用,"多标记学习是处理真实世界具有丰富语义对象的主要学习框架之一。在人工智能、机器学习等方面应用广泛。在多标记学习中,示例具有多种标记属性,而这些标记间存在局部或者全局的相关性。显然合理利用标记间的这种关系可以获得额外的分类信息,这有利于提高多标记学习系统的性能。在真实世界中,样本的标记数通常远小于未标记数,否则示例的多义性将失去意义。但不可否认的是未知标记中也可能包含了大量有价值信息。目前很多考虑标记相关性学习算法都是假定标记间相关性是对称的,然而标记间关系并非一定对称。基于以上考虑,本文展开研究,主要工作如下:(1)目前众多的研究者通常直接将标签置信度矩阵作为先验知识直接加入到分类模型中,并没有考虑未标注先验知识对标签集质量的影响。基于此提出一种非平衡化标记补全的核极限学习机多标记学习算法:首先使用信息熵计算标记之间的相关关系得到标记置信度矩阵,然后利用非平衡参数方法对基础的标记置信度矩阵进行改进,构建出一个非平衡的标记补全矩阵,最后为了学习获得更加准确的标记置信度矩阵,将非平衡化的标记补全矩阵与核极限学习机进行联合学习,依此来解决多标记分类问题。(2)针对近邻空间的标记相关性问题,利用近邻空间中元素的相关性提升近邻标记空间的质量,提出一种近邻标记空间的非平衡化标记补全算法:首先利用标记之间的信息熵来衡量标记之间关系的强弱,进而获得基础标记置信度矩阵;然后利用提出的非平衡标记置信度矩阵计算方法,获得包含更多信息的非平衡标记置信度矩阵;接下来度量样本在特征空间中的相似度,得到k个近邻标记空间样本,再利用非平衡标记置信度矩阵计算得到近邻标记空间的标记补全矩阵,最后利用极限学习机作为线性分类器进行分类。(3)考虑样本特征空间信息进行重构,增强特征空间的样本联系的同时引入标记相关性信息,提出一种结合均值漂移和非平衡化标记补全的多标记学习算法:首先利用均值漂移聚类方法将特征空间中特征间的信息进行重构;接着利用标记之间的信息熵来衡量标记之间关系的强弱,进而获得基础标记置信度矩阵;然后利用提出的非平衡标记置信度矩阵计算方法,获得包含更多信息的非平衡化标记补全矩阵;最后利用重构的特征空间与非平衡化的标记补全矩阵构成新的训练集,根据新的训练集采用已有的线性分类器进行预测。"
89,基于多示例多标记的多领域数据分类,"近年来,随着大数据和人工智能的迅速发展,标记学习成为重点研究领域之一。其中,多示例多标记学习(Multi-Instance Multi-Label Learning,MIML)作为一种新型的学习范式,拓展了多示例学习(Multi-Instance Learning,MIL)和多标记学习(Multi-Label Learning,MLL)。MIML对于现实世界中许多复杂和模糊对象具有更好的表示能力,同时示例的表达方式也更加契合对象所存在的多义性。因此,MIML学习框架成为模式识别与标记学习重点研究课题之一,众多学者提出了大量MIML分类算法,并在文本、图像、音频和生物信息等多领域数据分析处理中取得较大成功。本文将主要针对基于MIML框架进行多领域数据分类问题研究,通过对MIML的深入学习探究,实现对于MIML分类算法中退化策略算法、分类算法和端到端分类算法的改进,主要研究工作如下:(1)目前基于K-Medoids聚类退化MIML算法将各示例间视为相互独立,退化过程可能造成较多的信息丢失,且K-Medoids聚类需聚类簇K的先验知识,不同的K值对分类结果影响较大。针对该问题,提出了一种改进均值漂移算法的多示例多标记分类算法,通过带有权值且为非参数聚类算法的均值漂移退化MIML,考虑示例间的相关性,尽可能减少退化过程信息的丢失。实验进一步验证了算法的有效性。(2)传统神经网络算法需要较多的网络参数设置,在求解最优解时很有可能出现局部最优解,而无法得到全局最优解。而极限学习机(Extreme Learning Machine,ELM)是一种高效且具有优化学习算法的单隐层前馈神经网络,求解时只需设置隐藏层节点数,并随机初始化权值和偏置就可求解出全局最优解。但传统ELM算法需设置隐藏层节点数,并且需初始随机权值和偏置,易受随机值的影响导致计算结果并不稳定,采用核ELM则可以解决这一问题。因此,提出将回归核极限学习机作为基分类器的MIML分类算法,在保证分类精度的同时降低了分类的时间消耗。通过对比实验表明了算法了可靠性。(3)近年来随着计算机硬件的飞速发展,深度学习技术也得到了广泛的应用。但目前基于卷积神经网络(Convolutional Neural Networks,CNN)的MIML分类算法多使用Softmax函数进行分类,但此函数将类与类之间视为互斥事件,并不符合MIML学习框架。因此,提出将CNN网络中Softmax函数替换为ELM分类器,构造出一种端到端的图像分类算法。将所提CNN-ELM-MIML模型与原始CNN进行对比,表明所提算法的合理性。"
90,基于混合核极限学习机的标记学习研究及应用,"随着机器学习的发展目前有大量的机器学习算法被提出,人工神经网络(Artificial Neural Networks,ANN)就是其中的一个重点研究方向。单隐藏层神经网络又是ANN中发展最为完备使用范围最为广泛的一类算法。传统的神经网络算法例如BP神经网络(Back Propagation Neural Network)有着参数复杂,训练速度慢,对数据需求庞大的问题,而极限学习机(Extreme Learning Machine,ELM)则是对传统单隐藏层神经网络算法的扩展创新,它极大的避免了传统神经网络算法的缺陷,所以将极限学习机引入到使用传统的神经网络算法进行处理的问题中可以提升算法性能。当前随着网络使用率的提升,现在有大量互联网用户每天都在产生海量的数据,同时这些数据非常的零散,数据的信息密度和使用价值也都很低,所以这样就需要一种合适的方法来处理这些数据,标记学习就是一种性能表现良好的数据分类处理办法,它通过建立已知特征到标记的映射来处理未知数据的标记识别问题,目前已经有了大量的研究成果。核函数作为一种高效的维度空间映射方法在人工神经网络算法中有重要的应用,而基于核的极限学习机也是提升改善极限学习机性能的一种有效方法。对此本文提出将混合核极限学习机应用到多标记问题和性别标记识别问题中。基于核极限学习机的多标记学习算法能够有效提高标记分类性能,但是现有算法大都使用单一核函数,未能有效解决多标记中数据差异性问题。本文将混合核引入到极限学习机算法中,提出基于混合核极限学习机的多标记学习。首先在极限学习机中通过混合核函数将特征映射到高维空间,然后对原标记空间建立混合核极限学习机模型求得输出权值,最后通过模型计算预测未知样本的标记。通过与现有算法在相同数据集下进行的对比,结果表明本文算法在五个评价指标下性能优于多个对比算法,统计假设检验进一步说明本文算法的有效性,有利于多标记学习算法性能提升。目前大部分性别标记识别问题都是基于传统的神经网络算法,本文将在多标记识别中有较好表现的混合核极限学习机应用到性别标记问题中。通过LBP(Local Binary Pattern,LBP)和LPQ(Local Phase Quantization,LPQ)来提取人脸图像特征,并进行性别标记之后用这些特征和标记来训练混合核极限学习机得到预测模型。然后将未知性别标记的人脸图像同样提取特征后通过该预测模型来判断性别。通过对比其他算法在同一个公开数据集上的识别率,证明了混合核极限学习机在性别标记问题中的有效性。"
91,基于PCA和BP神经网络的信息安全模型研究,"随着计算机信息技术的快速发展,信息安全问题也愈发严峻。信息化技术已经和我们的生活、工作甚至国家安全紧密的连接在一起,但严峻的信息安全形式是我们不容忽视的问题。目前计算机系统的信息安全防御主要是借助防火墙、网闸等网络安全设备,这些网络安全设备主要的防御方式是借助于现有的病毒特征库,以一种对比识别查杀防御的方法,来保护信息的安全。这种以病毒库对比的防御方式有一种滞后的缺陷,当一种新型的病毒出现以后它不能够马上发现并发出反馈。虽然传统的防火墙、加密等信息安全技术有一定的防御作用,但都属于静态安全技术范畴,此类安全设备不能抵抗新型的、特征库不具备此类异常数据特征的病毒或攻击,面对此类病毒或攻击,如果没有设置相应的安全策略,安全设备(例如传统的防火墙、网闸)便失去了过滤阻断作用使网络系统暴漏在危险之中,以及对合法开放的端口发起的攻击大多也无法起到安全防护的作用。伴随着信息技术的不断发展,新型的木马病毒和攻击手段也大量的出现,基于特征库、安全策略以及端口管控的传统安全方法,面对新型的病毒和攻击手段,不能够以一种预先主动识别的方式来防御计算机病毒攻击侵害,已不能完全满足当前网络安全的要求。而人工智能中的一些机器学习算法例如:神经网络算法、遗传算法以及模糊技术等具备自主学习的特点,应用在信息安全领域可以实现一种主动安全防御的效果,以一种动态防御的手段在保护网络及时检测阻断异常数据的同时,对信息系统内部病毒攻击也能提供实时的保护。因此,将机器学习算法应用到信息安全方面已成为信息安全领域的研究热点。由于信息安全中的异常数据通常具有高维、海量的特点,导致传统的检测方法针对异常数据检测效率不高且对未知的异常数据识别率低。本文提出了一种基于PCA结合改进型BP神经网络的信息安全检测方法。该方法通过对已知的异常数据进行训练学习后,不但能够高效识别出已知的异常数据,对没有训练学习过的异常数据也能做出识别。这种基于PCA的BP神经网络异常数据识别方法应用于信息安全防御中就很好的、高效的解决了传统异常数据识别方法不能预先主动防御的缺陷。本文最后通过在MATLAB环境下的仿真结果表明:(1)将统计方法中的PCA和机器学习算法BP神经网络相结合的信息安全模型应用在信息安全领域不但对已知的异常数据识提高了识别率,而且对未知的、还未产生的新的异常数据也有很好的识别效果。(2)改进后的BP神经网络算法,加快了算法的收敛速度,提高了神经网络效率,提升了网络异常数据识别率。(3)通过仿真对比实验结果表明PCA结合改进的BP神经网络检测模型相较于传统三种经典算法的检测效果识别率较高的同时误报率也更低。"
92,基于Kinect骨骼信息的人体动作识别方法研究,"在计算机逐步智能化发展的今天,人们的日常生活变得更加方便和快捷。便捷生活的背后离不开各种数据的支撑,利用计算机去分析以人为中心的相关数据是一种研究人们生活习惯的方法。而人们的生活习惯大多是通过他们的行为来表现的,人体动作是人类行为的一部分,所以人体动作识别在我们在实际生活中应用十分广泛。在机器学习算法日趋成熟的条件下,人体动作识别已经成为人机交互领域中的热点问题。本文是通过Kinect骨骼数据去研究人体不同的动作,首先提出了一种二维平面投影特征的人体动作识别方法。该方法是根据工程上三视图投影的思想,利用人体关节部位的三视图方向投影来寻找人体运动的特征。从不同的二维平面多视角地去剖析人体动作,有助于解决人体遮挡和单一视角缺陷的问题。结合人体运动的规律,构造出关节向量来表达身体部位的运动情况,每两个关节向量之间的夹角代表这两个身体部位的相对运动关系。用三个投影平面里17个关节角的组合表示了整个身体框架的运动系统,同时考虑到每帧动作随时间在变化的关系,通过余弦相似度计算出每一时刻的关节角信息,最终根据样本量大小和运动特征的特点,选择出合适的分类器,达到对人体动作分类的目的。在上述研究方法的基础上,本文提出了一种分层特征融合的人体动作识别的方法。该方法采用对人体动作分层识别的策略,从生物学角度把人体分为五大部分,用这五部分之间的组合来表示人体动作。先对所有的动作粗分类,粗分类的运动特征同样也是利用关节角度的二维平面投影信息,这样就把一些差异性较大的动作分离出来。再对未分离出来的人体动作细分类,细分类的运动特征考虑了运动的本质以及人的整体和局部的关系,兼顾了人体关节多自由度间的协调性。利用运动学中角速度和加速度的物理特征来描述人体的运动,分别从两个不同的维度把这些特征融合起来,充分地发挥了该特征对运动细节表达的关键作用。最后根据运动特征的属性设计双层不同的分类器,把第一层较好的分类效果带到第二层中,从而增加了动作识别的稳定性。利用人体骨骼数据中隐含的信息,能够准确地辨别人的动作。通过在MSRAction3D公开数据集上的实验,证明了本文方法的实时性与可靠性,展现了在识别时序动作上的独有优势。"
93,基于高斯过程的偏微分方程数值解法构造,"高斯过程,又称为高斯随机过程,它是机器学习中一种强大的模型,可用来处理人工智能中的许多应用问题.本文将基于高斯过程来构造线性、非线性偏微分方程问题的数值算法.具体过程为:首先对偏微分方程的未知解函数提出先验假设,使其服从高斯过程.然后给定一个训练集通过贝叶斯线性回归模型得到观测值的概率分布,再由极大似然估计求出该模型的相关参数.最后根据贝叶斯条件概率公式,预测未知函数的后验概率分布,并借助后验概率分布来求出偏微分方程的数值解.数值模拟的结果表明该方法具有一定的精确性和可靠性."
94,上证50ETF期权市场中的交易策略设计,"金融衍生品交易策略研究与其自身的定价密切相关。从无风险套利理论的角度来看,当市场完全有效且定价完全合理时,市场价格应该及时、充分地反映所有信息。价格竞争机制将使各个合约间的价格维持平衡。但是,由于实际市场并不完全有效,理论价格和市场价格往往偏离,导致合约之间的价格平衡被破坏。此时就会出现无风险套利机会,可以获取正的超额收益,这就是衍生品定价理论的基本原则。只有更为准确的定价才能找到理论价格和市场实际价格间的偏离,并为后续交易行为提供指导性的参考。在经典的定价方法中,蒙特卡洛模拟法是将期权的期间分割为几个时间间隔。从分布样本中提取模拟的价格变化和运动路径,并用取平均值的方式来得出T时间的收益。期权价格则通过用无风险利率贴现来获得。其明显的缺点是太过于依赖模拟次数。而Black-Scholes期权定价模型所需要输入的五个参数(基础资产现货价格、标的资产波动率、期权的执行价格、期权期限相对天数、市场无风险利率)中,除基础资产波动率以外,其余变量都可以直接在市场中观察到。对于投资者来讲,直接使用公式更方便,这是B-S公式能够被广泛使用的主要原因。定价是否准确决定了市场参与者是否能做出更好的投资策略。B-S公式中的波动率参数是最为关键的一个指标,能反映出期权的内在盈利能力,是决定期权价格的核心变量。由于没有现有指标,需要通过一些数理方法和计量模型取估计波动率。例如在使用WIND金融数据终端时发现,当中的期权综合屏栏目里设置了一个期权价格计算器和套利监控功能模块,使用的是经典的B-S定价公式。其中的波动率参数需要用户手动设置,但只有两个选项:代入常数和代入历史波动率。此两种方法计算出的价格以及基于此进行的套利监控,效果都不理想。翻阅投资者论坛中的评论也发现,大多投资者都认为终端中自带的期权价格计算器计算的价格准确程度有待商榷。究其原因,是程序在设定的时候,没有充分考虑到波动率对于B-S期权定价的重要程度,仅选用了两种不准确的波动率代入方法,导致了最后的定价不准确。本文由此得到启发,通过比较另外两种不同的波动率预测方法,并回测相应的交易策略,以求找到更准确的B-S定价公式参数设定方法,以及制定配套的交易策略,让B-S公式计算出的理论价格更好的成为交易策略的引导,为广大期权投资者能更好的掌握价格走势做出一点贡献。本文在研究中分别运用传统GARCH方法和机器学习支持向量机SVR方法预测波动率,代入B-S公式定价并回测相应的交易策略,比较和确定更为准确的定价方法,进而为投资者制定交易策略提供参考。"
95,基于深度学习的机载点云分类研究,"在现代科学技术的不断发展和推动下,“智慧城市”,“数字地球”,“数字城市”等一系列新兴理念不断被提出,同时伴随着三维激光扫描技术的日趋成熟,大规模城市数据的采集和获取变得更为简单和便捷,对这些数据的处理和分类是实现城市智能化分析的关键一步。尤其是机载激光扫描的大规模城市点云中包含大量对象类别和许多相邻或重叠的部分,这就为多目标的分类带来了极大的挑战。针对这个问题,本文围绕大规模城市场景的多目标自动化分类提取这一主旨,重点展开了以下几个方面的工作:首先对大规模城市机载点云进行预处理,然后基于近邻空间进行3D最近邻邻域的优化求解,对于每个点云,求解最近邻中的3D特征。类比3D特征的提取方法,将机载点云投影到二维xoy平面,基于2D最优圆邻域提取2D特征,利用基于滤波器的方法和信息增益策略度量进行特征筛选,然后将2D和3D特征进行横向组合,利用构建的卷积神经网络测试文中提出方法的有效性。实验结果表明:组合特征的整体分类效果和3D特征的整体分类结果分别为:94.12%和97.01%。由于AlexNet模型的稀疏特性使其能够充分学习到与训练数据相关的特征,为了进一步提高机载点云的分类效率,本文微调并使用AlexNet对组合特征矩阵进行分类识别,最终整体的精度能达到97.79%。"
96,人工智能生成物著作权保护问题探究,"法律的发展具有滞后性的特点,著作权法也不例外,科学技术的发展刺激著作权法发展的同时,著作权法也为科学技术提供了一定的支持与保障。现阶段,人工智能的发展一日千里,人工智能朝着越来越智能化的方向发展,人工智能生成物层出不穷,部分人工智能生成物表现出越来越强的“类人类作品”特点,与此同时现行的著作权秩序也受到了一定程度的冲击,这种冲突主要体现在以下三个方面:第一方面,著作权法语境下,人工智能生成物该如何定性?第二方面,人工智能是否可以成为著作权法意义上的作者?第三方面,人工智能生成物的著作权应当如何归属?本文围绕以上三方面的冲突,以现阶段人工智能以及人工智能生成物的基本理论作为出发点,结合域外人工智能著作权保护状况及启示,立足于《民法》以及《著作权法》的基本理论为当前人工智能生成物著作权保护过程中存在的问题谋求化解之道。本文分为六个部分对于人工智能生成物的著作权保护问题展开探讨。第一部分在人工智能现有的发展背景下,以人工智能对现行著作权法体系带来的冲击为主线,对相关的学术观点进行梳理,在此基础上对于本文研究的问题以及研究前述问题所运用的方法进行了进一步的明确;第二部分回归于理论基础,对于人工智能以及人工智能生成物的相关概念进行剖析,分析现阶段人工智能以及人工智能生成物的特征,同时明确现阶段开展人工智能生成物的著作权保护所面临的问题从而为下文人工智能生成物著作权保护的探究指明了方向;第三部分对域外人工智能生成物的著作权保护研究状况进行梳理,对人工智能生成物既要宏观把控,也要对人工智能生成物微观洞悉;第四部分在著作权法语境下展开对于人工智能生成物的定性研究,在作品认定条件的基础之上对于人工智能生成物的作品属性进行了认定;第五部分则从民事主体以及作者的一般性认定条件出发对于人工智能的作者主体地位进行了否定;第六部分则在人工智能不具备作者主体地位这一理论前提的基础之上对人工智能著作权归属模式的各种可能性进行了比较,最终为人工智能生物著作权归属制度的完善提出了解决之道。"
97,量化选股智能建模及参数优化研究,"量化选股模型是量化投资策略的重要组成部分,机器学习算法是量化选股模型的重要研究手段,若能提高模型对股票收益的预测精度,不仅可以帮助投资者研判股票价格趋势,也能为其带来显著的投资回报.由于股票市场是一个庞大的非线性系统,数据质量和算法参数的选取会对模型的预测效果产生较大影响.因此,单一的传统预测方法已经无法较好地表现出股票价格的综合趋势.为探索新的量化选股方法,将智能算法用于量化选股建模,并探讨基于主成分分析(PCA)、人工蜂群(ABC)算法和极限学习机(ELM)的组合预测及参数优化模型.本文的主要研究内容如下:1)以沪深300成分股为研究对象,由于股票市场的各类因子具有时间和空间的双重特性,根据各因子的内在经济意义,对其分别进行归一化处理、简单趋势化处理和深度趋势化处理,然后采用ELM对处理后的三组数据进行建模,并与SVM的预测结果进行对比.对比结果表明数据经过深度趋势化处理后,模型对正样本特征的学习更加充分,且ELM对上涨股票的预测能力较好,更具有实践意义.2)采用PCA算法对三组数据进行降维处理,利用ELM对处理后的数据进行建模预测.实验结果表明,PCA提高了ELM模型的预测精度,且深度趋势化后数据的预测效果更好,模型预测准确率达到53.61%.3)将ABC算法与PCA-ELM相结合,采用ABC算法对ELM的参数进行优化,利用优化后的模型对深度趋势化后的数据进行预测,并与PCA-GA-ELM和PCA-DE-ELM的预测结果进行对比.实验结果表明,ABC算法对ELM的参数优化效果更好.此外,采用朴素贝叶斯和Xgboost模型对相同数据进行预测,结果表明PCA-ABC-ELM模型的预测精度更高,预测准确率达到59.67%.4)为进一步分析模型预测效果,将PCA-ABC-ELM的预测结果转化为投资信号,对沪深300指数成分股进行短期及中期仿真投资实验.实验结果表明,该模型的4日累计收益为8189.11元,年化收益率为66.38%,21日累计收益为50835.63元,年化收益率为80.45%,均显著优于同期沪深300指数的业绩表现,体现了该模型在沪深300成分股量化选股方面的可行性与有效性."
98,无线传感器网络故障检测算法的研究,"无线传感器网络(Wireless Sensor Network,WSN)是一种无线数据采集网络,它由专门部署在特定工作环境下的大量的,可移动的或可静止的传感器节点通过自组织、分布式的组成形式协作地进行数据采集、分析、整合、上报等工作,并具有自组织、放置灵活、移动性强和扩展简便等特点,通常应用于恶劣、危险的环境中,执行数据的采集等任务。大部分的传感器网络环境中,并不将节点与节点间的传输可靠性置为首要目标,而是将相关数据传输的可靠性置为第一位。大量的资源受限节点包含于传感器网络中,节点间的信息传输通过多跳通信来完成,正因为这些特性导致了网络中节点发生的故障概率要高于传统网络,因此需要建立传感器节点的故障检测机制。本文从现有的无线传感器网络故障检测算法着手,并结合现代无线传感器通信网络特性、分簇思想进行研究,提出一种基于SVR预测、构造传感器节点偏差等级模型、以及节点偏差等级更新机制的无线传感器网络故障检测算法。面对大规模无线传感器网络环境采用分簇思想对网络进行划分。在分簇过程中,采用一种改进的LEACH分簇算法,引入能量模型对分簇网络的性能进行描述,使分簇更加均匀,均衡节点能耗,降低网络整体能耗。成员节点在本地执行SVR预测算法,根据预测出的数据计算节点的偏差等级,处于不同偏差等级的成员节点以不同频率向簇头发送预测样本数据的信息,而簇头根据发送过来的数据按照存储的偏差数据集设置的标准进行故障检测并判别节点故障。同时,在预测模型中对核函数的选取进行了仿真分析,基于簇头节点的偏差数据集反馈机制对节点的偏差等级实时更新。仿真结果说明,本文所研究的基于SVR预测的故障检测算法在不同规模的无线传感器网络环境下的故障检测效果、故障检测率、检测精度、检测能耗方面均能保持优异的性能。图 [51] 表 [8]"
99,基于互联网金融下的信贷逾期预测的研究,"随着互联网金融的迅速发展,信贷风险预测越来越重要,风险控制是当下的热点之一。随着信息化建设的不断完善,海量数据被沉淀和积累。需要更多的大数据技术去分析并获取更有价值的信息,为实现自动化提供原理支持,从而节省成本,提高效率。本文通过对近6万用户贷款信息数据进行分析,提取有价值信息,建立多个信贷逾期预测模型,优化并对比分析各模型,为实现自动化逾期预测提供原理支持。首先对数据进行预处理,主要是对缺失值和重复值的处理。其次是特征工程,包括特征衍生、特征选择和特征编码。特征工程尤为重要,直接决定了预测模型的好坏。在建模之前,需对离散特征编码,原因是部分模型对离散特征不识别,会把离散特征作为连续值处理,则会导致错误,但是少数模型却能够识别离散变量,比如随机森林。接着进行建模,本文主要用了Logistic回归、决策树DT和Xgboost模型建模。每个模型经过多次调整优化,使得预测模型最优,预测结果效果更加显著。建立的模型需要一定的指标去评估,文中模型的评估指标主要有:AUC、精确率、准确率、召回率和KS值。从整体来看,逻辑回归和决策树训练出的模型,预测效果几乎相同,但逻辑回归的预测效果更好,而训练决策树的模型的效率会更高。调整前后的Xgboost模型的预测效果没有得到显著的优化,但调整后的模型预测效果更优。在建立Logistic回归模型时,模型中加入了L2正则项,由于本文数据的特征比较多,L2正则项的加入可以有效防止模型过拟合。本文把缺失值当做一种特征处理,并且缺失值占比特征对模型有较显著的重要性。综上,通过对比各个模型的评估指标,Xgboost模型预测效果是最优的,而Logistic回归和决策树的预测效果次之。通过本文的研究可以为信贷逾期风险预测模型的建立提供以下参考:第一,特征工程是整个建模过程中的关键,其中特征衍生最为重要,通过对数据的提取分析,从而对用户精准画像,挖掘有价值的特征,进而做好特征工程,有效提高预测模型的准确度和性能。第二,在做相关信贷逾期预测模型时,即使有缺失值,不要直接删除缺失值,而是把它当做一种特征来处理。第三,缺失值对模型的精度影响很大,互联网金融平台要不断健全和完善用户信息系统,减少用户信息缺失。第四,在实际建立信贷逾期预测模型时,可以首先考虑Xgboost模型。可以以此模型为基础,进行模型的融合,建立更加准确的模型。"
100,基于深度学习的人脸识别研究,"身份识别技术在现代社会生活中充当着很重要的角色,与人们的生活息息相关。人脸身份识别技术具有直观性优异、非接触性强以及隐蔽性好等优势,被广泛应用到安防领域、公安领域、支付领域等。属于深度学习的卷积神经网络(CNN)推动了人脸识别技术的发展,现在基于CNN的人脸识别较传统方法占据更大的优势。基于人工设计特征的传统人脸识别技术,人工获取特征的工作量很大,识别效果易受个人主观与场景的局限,导致实时性与准确度不高。而利用卷积神经网络识别人脸,可以避免复杂的特征提取,直接学习到最佳的图像特征,在不同场景的应用下具有鲁棒性、实时性。ResNet、DenseNet网络是最近提出的,模型效果最好。ResNet可达152层,但是深层网络导致训练效率低;DenseNet的稠密连接方式,可导致隐含的深度监督,有助于培训更深层次的网络架构,但是这种特征重用会导致后续层引入冗余特征信息。通过参考ResNet网络结构,引入DenseNet稠密连接结构,本文设计了12层的CNN模型架构。在保证一定的特征重用下,但不至于引入太多的冗余信息,该网络具有良好的信息流传递性,隐含的深度监督。在网络中引入批归一化与Dropout改善网络,进一步缓解过拟合,训练网络参数的优化算法选择Adam,激活函数选择ReLU。保证一定的识别速度与精确度,降低对计算机硬件资源的依赖性,实现了人脸的在线识别。在CASIA-webface人脸库训练所设计的CNN模型,针对训练结果调整模型超参数,得到最优模型,再与VGG16、ResNet14模型对比,验证该CNN模型的性能优异,在CASIA-webface上可达到95.6%以上的测试准确度。通过调用OpenCV库自带的Haar Cascade分类器实现人脸检测功能,并在人脸检测与人脸识别之间增加去模糊图片步骤,过滤清晰度低的图片,进一步提高识别效果。最后,本文的人脸识别系统测试结果在92.5%左右,识别速度在1s以内,满足人脸识别系统的设计要求。图[65]表[7]参[70]"
101,基于数据挖掘算法的微信公众号阅读量分析,"近年来,随着网络和科技的迅猛发展,各种自媒体平台不断涌现。微信公众号作为新网络时代的社交工具,以其实用的便利性和发布信息的及时性得以迅速发展。不过,随着不同功能和类别的公众号层出不穷,微信用户的注意力越来越分散,微信公众号粉丝增长越来越难,文章打开率也越来越低。在此情境下,对影响微信公众号阅读量的因素进行研究和把握,有利于公众号提高发布信息的阅读量,从而在日趋激烈的竞争中充分发挥媒体特性。通过对微信公众号阅读量的研究分析,可以帮助公众号用户找到有价值的信息,并为公众号运营者提供相应的发展方向和策略。目前,对于微信公众号阅读量分析的研究尚处于起步阶段,因此探究影响微信公众号阅读量的关键因素,掌握微信公众号的运营策略具有重要的理论意义和实用价值。本文从微信公众号运营者的角度入手,对于某公众号分析网站上的998条数据进行详细分析。以公众号某个月平均每次发文所能获得的总阅读量为因变量,选取了包括公众号类型、发文时间等14个影响阅读量的特征指标,运用了决策树回归、Adaboost、Bagging、随机森林、支持向量机、线性回归6种数据挖掘算法构建模型。通过十折交叉验证法,对每种算法模型的拟合结果进行比较,确立了基于随机森林算法建立影响总阅读量的分析模型。首先基于全部数据集运用随机森林算法建模,选出模型拟合优度最佳的指标组合,包括公众号类型、公众号类别、名称长度、头像是否彩色、日均发文次数、单次篇数、原创占比、视频占比、标题长度、标题标点指数、标题正向情感得分、信息熵共12个特征指标。然后将全部数据集划分为800个训练样本集,198个测试样本集。利用训练集数据建立随机森林模型,一方面将预测集数据带入模型进行阅读量的预测和分析,发现该模型能够对公众号的阅读量给出较为合理的解释,符合实际情况,具有实际运用价值。另一方面,运用随机森林算法建立的模型将优选出来的12个特征指标进行重要性排序,得出了单次发文篇数、日均发文次数、公众号类别、信息熵、视频占比、原创占比、标题标点指数是运营公众号的重要因素,并针对运营公众号提出了相应的策略和建议。通过本文的研究,有力地为微信公众号平台的进一步建设和优化奠定了理论基础,并且提供了实用的运营策略和方向。"
102,基于机器学习的智能临床决策方法研究,"随着机器学习方法在各个领域的应用,近年来产生了很多具有现实意义的成果。医疗这一传统行业也存在很多富有前景和挑战性的的应用。本论文尝试通过机器学习方法,开发一种智能临床决策方法,为医生提供临床决策支持。具体地,本论文主要关注以下三个问题:临床信号的特征提取,药物相互作用的预测,以及临床治疗方案的推荐。对于临床信号,本文提出了一种数据驱动的多变量信号特征的提取方法。这一方法基于回声状态网络(ESN)将信号编码成特征。进一步的理论分析表明,基于自回归(AR)模型的特征提取方法可以看作是基于ESN方法的简化。实验结果表明,这种基于ESN的特征提取方法具有优越性,并为无监督医疗信号的特征提取建立了一个新思路。对于药物相互作用的预测,本文将其表述为一个多任务二元回归问题,将每种相互作用类型的预测作为一个任务来处理。与只计算相互作用矩阵中缺失项的矩阵方法相比,本文提出的方法可以直接对二元关系回归,从而获得了更好的可扩展性。为求解这一模型,本文还开发了一种有效的近似梯度方法。对于临床治疗方案的推荐,本文旨在开发一种算法,学习患者电子病历(EMR)中的历史数据,根据患者的疾病状况、化验结果和治疗记录为患者提供下一个周期的治疗方案。重要的是,这种算法需要同时考虑患者的治疗记录序列和化验结果序列。这些记录不仅具有异质性和时序性,还往往具有不同的记录频率和记录长度。此外,该算法还需要将静态信息(如患者的人口统计学信息)与时间序列相结合,为患者提供个性化的治疗处方。为此,本论文提出了一种新的长短时记忆网络(LSTM)学习框架,通过隐藏神经元之间的联系,对不同类型医学序列之间的相互关系建模。"
103,面向心血管疾病识别的心电信号分类研究,"心血管疾病是危害人类健康的主要疾病之一,具有隐蔽性强、发病率高、致死率高等特点。对于居民来说,准确的检测出心血管疾病的类型,对于心血管疾病的诊断和治疗有很重要的意义。心电图中包含了丰富的信息,是诊断心血管疾病的有力工具。因此,可以通过对心电图进行分类,来进一步确定心血管疾病的类型。本课题主要对信号预处理和自动分类识别技术进行了研究,主要工作如下:(1)心电信号的预处理。本文的预处理包括信号的噪声去除和QRS波的检测两部分。针对心电信号的主要噪声,如工频干扰、基线漂移和肌电干扰,设计了小波软阈值滤波器,对信号进行了时频分析。将噪声进行了有效的去除,得到了干净有效的信号。针对信号的形态特征,基于自适应双阈值算法来对心电信号的R波进行较为准确的定位。借助于一高一低双阈值对信号的R波进行了准确的定位。最后以R波为基准点,对信号的Q波和S波进行了定位,识别率为99.63%。(2)针对小样本心电数据,提出了基于小波变换的频域特征分析法,采用了随机森林、K-近邻和C4.5三种传统机器学习算法在MIT-BIH心律不齐数据上进行了验证分析。首先结合离散小波变换对信号进行了五尺度分解,然后在不同的尺度上提取了频域特征和香农熵特征。接着使用了信息增益法对信号的特征降维,得到更为有效的特征。最后将降维后的特征输入分类模型中,并使用十折交叉验证模型的分类效果。实验结果表明,随机森林取得了最好的分类效果,灵敏度为98.1%,特异性为99.5%,正确率为98.08%。(3)针对大样本心电数据,搭建了基于卷积神经网络的分类模型,并使用MIT-BIH心律不齐数据进行了验证。模型一共10层(一个输入层、4个卷积层、3个池化层、1个全连接层和一个输出层)。将整个数据库中的数据分为训练集和测试集,用卷积神经网络模型对训练集的数据分批训练,不断优化模型,最后用测试集的数据来进行模型的测试。测试集得到的灵敏度为99.45%,特异性为99.86%,正确率为99.78%。本算法能够很好的将信号分类,对心血管疾病的分析有一定的意义。"
104,基于回归模型CRRT手术中肝素剂量预测,"随着人类生活水平的提高,人们越来越重视身体健康。近几年来,慢性肾脏病的突发率越来越高,连续性肾脏替代疗法(Continuous Renal Replacement Therapy,简称CRRT)为治疗此疾病的首选方法。CRRT手术治疗法是通过持续血液净化的方式来替代受损的肾功能,在持续血液净化过程中,主要注射的是肝素剂量。现阶段,肝素剂量的注射量主要是根据医生的经验来断定的,这对医生的经验要求很高,难免会出现判断失误,这样不仅会浪费宝贵的医疗资源,还会使病人承受不可预知的风险。所以为了减少医生的主观误判,本文利用机器学习的相关算法,探索出一种回归模型来预测CRRT手术中的肝素剂量,以此来协助医生做出正确的决策。具体研究内容如下:首先,针对给定的样本集,进行数据预处理。针对完全相同的行数据集进行去重,目的是减少以后对其数据集学习的时间;针对缺失值处理,采用均值填充法进行插补缺失值;针对数据进行标准化处理,采用的是z-score算法和范围缩放算法。其次,针对预处理后的数据集,采用遗传算法和随机森林算法相结合的方式,进行特征提取。针对数据特征提取,采用z-score算法和范围缩放算法分别对数据进行标准化处理,并分别进行11次实验,最终从22个属性中选出18个重要属性用于后续的模型预测。针对不平衡数据处理,采用EasyEnsemble算法和SMOTE算法相结合的组合抽样法。最后,针对模型的选择,采用回归模型。在模型训练之前,针对目标变量即肝素剂量,采用取ln变换对其进行优化,并通过实验对比验证对肝素剂量进行优化,能使模型拟合效果更加好一些。在训练模型的时候,用决策树回归模型、支持向量回归模型和梯度提升回归模型分别对原始数据集和经过EasyEnsemble算法和SMOTE算法处理过的数据集进行实验,并通过对比模型评价指标平均绝对值误差、均方误差和R的平方,最终得出在不平衡数据集处理后,选择梯度提升回归模型来预测CRRT手术中的肝素剂量。"
105,冬笋探测器的设计,"冬笋是一种常见的食材,营养价值丰富,由于其隐藏在泥土之下,探寻非常困难,目前主要靠老农民的经验肉眼观察才能探寻到。论文依托浙江省科技厅重点研发项目“竹林机械化经营设备研发”开展研究,开发冬笋探测器,以减轻农民的劳动强度。论文主要的研究内容和成果如下。论文首先分析了多种无损检测手段,选取了时域反射法作为冬笋探测的主要理论依据,根据该理论提出一种合适的冬笋探测方案;第二,探究了麦克斯韦方程与土壤和冬笋的电参量模型,从原理上验证探测的可行性,并搭建了探测器整体硬件结构:包括高频、低频、天线等模块;第三,对系统结构中高频模块的天线进行选型,选取了线性开槽天线,并对其尺寸进行设计,然后用HFSS有限元软件进行仿真,使用参数扫描进行优化,使之满足探测所需要求;第四,对硬件电路行进设计,其中包括:信号源、幅相检测模块、处理器及外围电路等,并在硬件基础上开发了相应软件。在功能上能实现信号源频率可调;幅相检测模块能精确测量幅值比、相位差;单片机采集A/D转换后的信号能通过LCD显示、超过阈值后进行报警等,并使用Altium Designer完成PCB的设计;第五,为验证探测器可行性对试验进行设计,设计试验并加以验证,利用SVM算法进行机器学习划分阈值,最后进行实地探测。结果表明,设计的探测器探测准确率较高,在70%左右,其成本不到探地雷达的十分之一。"
106,目的论视角下的科普文本翻译,"随着全球化的逐步深入,科技日新月异,国际交流日益频繁。科普文本翻译作为人们了解国内外最前沿科技的重要途径,在国际科技信息交流与传播方面发挥着重要的媒介作用。如何使得科普文本得到客观准确的翻译,已成为当今科技翻译工作者共同关注的重点和难点。本论文以《预测机器:人工智能的简单经济学》(PrEiction Machines:The Simple Economics oq Artificial Intelligence)这一具有广泛应用价值的科普性文本(科技文本的一种)的汉译为例,采用从整体到局部的描述性研究方法,通过将宏观层面的翻译目的和文本功能再现与微观层面的用词原则及句法和篇章重构相统一,旨在探讨用目的论指导科普文本翻译实践的可行性。本论文包括引言,主体和结论三大板块,论文主体分为三部分,第一部分是对目的论进行概述并分析其指导科普文本翻译的可行性;第二部分主要全面地分析原文本的语言特点;第三部分是本论文的重点:其将目的论翻译理论应用到科普文本翻译的具体操作及问题的处理之中,并从中归纳总结翻译策略与技巧。本文的结论是:在翻译科普文本时,译者应明确翻译目的,努力在最大程度上还原原文信息,同时,译文只有让读者易于理解和接受,才能真正实现其在译语文化环境中的预期功能和目的,从而向大众普及科技知识,促进科技交流与创新。本文通过列举具体实例并分析相应的翻译策略,旨在为从事科普文本翻译的译者提供一些有价值的参考,以促进科普文本翻译质量的提高。"
107,基于深度学习的新闻文本分类模型研究,"在自然语言处理领域,文本分类作为一种信息处理的基础技术一直是热门的研究方向。文本分类中的每一个环节都会影响最终分类的效果,包括文本预处理、文本表示、特征选择和分类算法,这些过程中所涉及到的诸多算法都是学者们研究的焦点。随着深度学习的兴起,许多网络模型在文本分类领域表现优异。新闻文本数据具有易获取、数据量大等特点,新闻文本分类技术研究成本相对较低且属于一种支撑类的基础技术。因此,对新闻文本做自动分类技术的研究对于新闻推荐、数据新闻、广告推送等领域也都具有十分重要的影响。为了提高对新闻文本分类精度,本文主要工作以及创新点如下:1.深入研究并介绍了自然语言处理领域文本分类的基本过程,详细解释了过程中所涉及到的机器学习技术和深度学习技术。在文本表示和特征选择过程中,针对新闻文本的特点,选择词嵌入方法,借助Word2Vec工具表示文本数据,该模型既可以保证词向量的语义关系又能避免维度灾难问题,提高分类性能。2.基于已有工作,分别研究并改进了 SRB文本简化模型和嵌套LSTM模型,提出了一种基于文本简化方法的混合模型。首先,该模型通过SRB网络逐句简化新闻文本,并生成具有高语义相关性的简单句子,既简化后面句子层面的模型训练难度,又不丢失语义信息。其次,将句子向量输入到嵌套LSTM网络以学习句子间的相关性及其特征表示。3.混合模型采用了注意机制来突出关键句子的特征表达,既能适应新闻文本的特点将句子简化,又能在获取上下文特征相关性的同时突出关键句的作用,运用混合模型的思想将各个模型优势结合。4.将本文提出的模型与五种典型的深度学习模型进行比较,在三个流行的不同中文新闻数据集上设计多组对比实验,实验表明,本文所提出的模型实现了最先进的分类精度。最后,通过参数调整,探究了参数对结果的影响。"
108,基于机器学习的精神科量表工具优化及应用,"近年来,随着人们的生活水平不断提高,生活节奏不断加快,人们所承受的精神压力也在不断增大,精神类疾病的患病人数在急剧增加。其中双相情感障碍成为精神类疾病的一大杀手。双相情感障碍在发作初期,很容易被误诊为抑郁症,而抑郁症与双相障碍属于两类不同的精神疾病。如果误诊加以错误的治疗,很有可能会引发其他疾病。目前通常使用国际通用精神科量表,比如情感障碍评估(Affective Disorder Evaluation,ADE)来诊断。ADE诊断量表是一个他评量表,由美国研发,国内使用的版本由ADE翻译而来,中美在文化及人文精神上存在差异,直接翻译的条目并不适合直接在国内临床使用而需要进一步的修订。近年来,机器学习算法得到长足发展,将机器学习算法用于优化相关量表的研究开始出现。在这篇论文中,利用机器学习方法,使用CAFé-BD数据来优化ADE量表。为找寻最优解决方案,采用5种机器学习算法。首先,在医生的建议下,从ADE中选择出合适数目的问题,然后利用最小冗余最大相关算法,对这些选择出的问题按照对最终结果的影响排序。排完序以后,采用前向特征选择的方式,依次选择合适的特征,分别放入上述五种算法中训练得到五个分类器,然后将新的数据依次放入到这五个分类器中,就会得到五种预测结果。实验以预测结果的受试者特征曲线(Receiver Operating Characteristic Curve,ROC)下的面积值(Area Under Curve,AUC)作为优化的选择标准,以简明国际神经精神访谈(Mini-International Neuropsychiatric Interview,MINI)诊断结果作为优化目标标准,对量表进行优化。通过这种方法,ADE量表被优化成两个版本,分别是用于诊断双相亚型的量表和用于诊断双相Ⅱ型和单相抑郁的量表。优化版的双相亚型量表包含16个问题,题目数量减少了85.7%,准确率得到0.813,敏感度为0.678,特异度为0.902。优化版的双相Ⅱ型和抑郁量表包含43个问题,题目数量减少了61.6%,准确率为0.922,敏感度为0.943,特异度为0.909。优化后的两个量表在准确率上都比原来ADE的准确率有所提高。优化的量表根据客观的题目得到分析结果,更加客观可靠。目前,优化版量表已经应用在了体检中心的智能心理体检服务以及医院的预诊系统中,实现了筛查与辅助诊断的功能。"
109,Lstm Based Short Message Service(SMS) Modeling for Spam Classification,"短信服务(SMS)在现代通信技术中得到了广泛的推广。短消息服务组件是现代社会中最快、最常用的电子消息发送方法。垃圾邮件或未经请求的短信已成为组织、网络系统和私人客户端的一个值得注意的问题。通过垃圾短信,垃圾邮件发送者正在影响时间和内存空间,这是计算世界中最重要的资产。垃圾邮件的分类是一个有趣而突出的问题。这里介绍了与垃圾邮件相关的问题以及努力管理垃圾邮件的不同方法。对SMS中的垃圾邮件可用性进行分类是一项具有挑战性的任务,因此,在这方面已经进行了大量的研究,这些研究采用了机器学习技术,如朴素Bayes(NB)、随机森林(RF)和支持向量机(SVM),用于垃圾邮件分类。虽然这些方法表现出了足够的性能,但在垃圾邮件分类方面效率不够。因此,需要进行严格的研究,以找到更准确、更稳健的方法。为了解决这个问题,我们提出了一种新的长期短期记忆(LSTM)方法,它是一种具有包括记忆细胞在内的门控机制的递归神经网络(RNN)的高级结构。此外,本研究还采用了Word2Vec工具,该工具将简化文本转换为向量空间中单词的表示形式。为了评估我们的方法的有效性,SMS数据集已被免费使用。实验结果表明,该方法优于最先进的机器学习方法,如随机林(RF)、SVM、kNN(k最近邻居)、决策树,并提供了97.5%的精度。"
110,基于EEMD_LSTM模型的沪深300指数预测研究,"我国的股票市场作为实体企业筹集资金的重要渠道,各种类型的投资者配置自身资产的重要渠道,是我国金融市场的不可缺少的重要组成部分。对于股指的预测一直以来都具有重要的研究意义。然而股票的数据本质上是高度嘈杂的、动态的、非线性的、非参数的和混沌的,有悖于一些经典理论的基本假设,制约了经典理论的适用范围。因此,找到合理的股票市场数据的特征提取方法,构建一个能够描述股票市场复杂的非线性动力系统模型,对于进一步揭示股票市场内在的运行规律,更好的发挥股票市场应有的功能,更加及时揭露金融风险等方面,都有重大的现实以及理论价值。本文通过使用集合经验模态分解(Ensemble Empirical Mode Decomposition,EEMD)算法将沪深300指数收盘价分解,成功得到了 10个本征模量函数和一个残差函数,并分析了本征模量函数的时频域特征。使用标准的R/S分析,发现沪深300对数收益率中存在的最长记忆周期与本征模量函数的最长周期大致相符合,验证了本征模量函数周期具有的实际意义。最后建立了基于EEMD-LSTM模型的沪深300指数预测模型,建立了多种的评价指标衡量模型性能,建立了参照模型对比模型的预测效果。最终结果表明EEMD-LSTM模型具有更好的预测性能。EEMD方法能够对神经网络模型的预测性能有较大提升。改变了数据集时间跨度及频率后,EEMD-LSTM模型与其他模型相比同样具有更优的预测结果。通过实验还发现,数据集的选择对预测结果的影响不如EEMD分解。"
111,基于知识与数据共同驱动的移动用户支付行为识别研究,"随着移动支付的快速发展和全面普及,支付数据规模也呈爆炸式增长,商家迫切希望利用用户消费行为偏好,快速定位目标消费群体,而对支付行为数据的有效挖掘是分析用户消费偏好的必要手段。本文在企业委托的“大数据公共数据模型开发服务”项目支持下,利用移动数据进行用户支付行为偏好分析,主要包括用户发生支付的方式、时间和地点识别。本文针对传统方法识别移动支付方式、时间和地点存在的精度差、效率低等问题,提出一种基于知识与数据共同驱动的移动用户支付行为识别方法。在支付方式、时间和地点识别前引入支付事件识别,首先利用数据驱动模型对上网行为事件进行识别,筛选出支付事件后,再利用知识驱动模型识别其支付方式、时间和地点,不仅提高了识别准确率还改善了识别效率。在数据驱动模型方面,针对现有时间序列划分方法对用户上网行为划分不精确等问题,本文利用用户上网行为数据中事件的特性,提出一种基于事件驱动的用户行为时间序列自动划分方法,改善模型特征提取的有效性。并对划分后的上网行为事件提取支付相关特征,利用机器学习分类模型进行移动支付事件识别。在知识驱动模型方面,针对关键词提取算法本身的缺陷及未考虑移动支付领域的知识特点,本文提出一种基于改进TF-IDF的移动支付方式关键词提取方法,并利用方差贡献度的思想构建移动支付方式关键词库,改善知识驱动模型中知识库的有效性,从而提高移动支付方式识别性能。同时,本文根据移动信令数据中基站位置信息,构建用户行为位置信息库,实现移动支付时间和地点识别。实验结果表明,在数据驱动模型移动支付事件识别方面,本文所提基于事件驱动的用户行为时间序列自动划分方法在准确率和召回率上均优于对比方法;在知识与数据共同驱动模型方面,本文提出的知识与数据共同驱动的模型在_1F准则下识别性能优于对比方法,对不同移动支付方式识别分别达到了88.3%(支付宝)、86.7%(微信支付)和95.5%(无支付),满足模型应用需求。"
112,融合行为金融学的机器学习选股算法研究及应用,"目前机器学习的相关算法多用于图像识别,模式识别等专业领域并且都拥有较高的分类准确率,这主要得益于同类别数据样本间拥有较强相似性,模型通过对训练集的充分学习从而可以在测试集上取得较高的准确率。但在金融领域中,大部分数据均不具有此特性,机器学习模型对其预测的准确度远远低于上述领域。因此若要挖掘金融数据间的关联规则,应该尝试将金融理论逻辑与机器学习算法进行融合,提高算法在金融领域的有效性。本文以沪深300的行情交易数据作为数据源,根据股票数据的时间序列特性对数据进行处理;运用集成学习的算法思想,选取K-近邻(KNN Classifier),梯度提升(GradientBoosting Classifier)和自适应提升(Adaboost Classifier)这3个分类器通过改进的投票算法聚合成一个新的分类器模型,完成T交易日的股指行情信息对T+1交易日股指涨跌情况的预测,改进的投票算法综合考虑了弱分类器本身的分类效果,分类效果得到提升。在对大盘指数进行有效预测的基础上进行选股算法研究:通过分析公司最近一个季度的基本面数据,将数据挖掘中Affinity Propagation(近邻传播聚类)与集成学习算法Adaboost相结合构建基本面数据分类器,对股票进行业绩分类,形成选股池;择时操作则由行为金融学中的反转策略结合股票技术分析中较为常用的技术指标――KDJ进行择时买入操作,择时卖出操作则通过设置止盈止损率来进行确定。将大盘预测与选股进行结合制定选股算法模型:对投资策略进行收益检测和风险评估――在量化交易平台“优矿”进行模拟交易,结果表明本文所制定的选股算法取得的收益能够取得超越大盘的收益率,并且各项风险指标均表现良好,是较为可靠的证券投资算法,对中小投资者具有一定参考价值。"
113,基于RBM模型和LFM模型的推荐算法研究与实现,"随着互联网技术的快速发展,网络中的各种数据也呈现出指数级的增长。这些数据在给人们带来便利的同时,也带来了“信息过载”问题。目前,以协同过滤为代表的个性化推荐技术已成为解决这一问题的重要手段,使得人们能够高效地从海量信息中获取到自己所需的信息。然而,随着大数据时代的来临,协同过滤推荐技术的发展也面临着许多挑战,诸如数据稀疏性问题、可拓展性问题、推荐准确性问题等。为了解决协同过滤推荐技术中存在的数据稀疏性问题和可拓展性问题,本文针对RBM模型和LFM模型在协同过滤算法中的应用进行了深入研究和改进。主要工作如下:1.深入研究了RBM模型的相关理论知识和其在协同过滤算法中的应用,并对该模型在训练过程中只使用了严重稀疏的评分矩阵问题进行了相应的改进,引入了基于用户兴趣偏好评分的方法对RBM模型的预测评分进行优化,并提出了融合用户兴趣偏好和RBM模型的推荐算法。实验结果表明,改进后的算法比基于RBM模型、CRBM模型和Dual_RBM模型的推荐算法有更好的推荐效果。2.深入研究了LFM模型和k-means算法的相关理论知识,并对LFM模型在协同过滤算法中存在的模型训练时间长、用户信息损失和可拓展性差等问题,提出了融合用户偏好聚类和LFM模型的推荐算法。首先利用k-means算法对偏好相似的用户进行聚类,再利用LFM模型对每个簇中的用户评分矩阵分别进行训练,最后利用训练好的LFM模型和最近邻用户的评分对项目进行评分预测。实验结果表明,改进后的算法比LFM模型推荐算法有更好的推荐效率和推荐效果。3.利用改进后的推荐算法设计并实现了一个电影推荐系统。该系统能够根据用户的兴趣偏好信息为用户提供个性化电影推荐服务。"
114,基于计算机视觉的驾驶员行为分析系统设计,"交通事故中有相当一部分原因是由于驾驶员的危险驾驶行为引起的,主要包括开车时驾驶员存在疲劳驾驶、驾车打电话、驾车抽烟和视线长时间偏离行车路线等危险驾驶行为。本文利用计算机视觉技术设计实现了一套可在通用车载机平台运行的驾驶员行为实时分析系统,用以监督该类危险驾驶行为。本文介绍了国内外计算机视觉技术在驾驶员行为分析领域的发展和应用。利用摄像头获取驾驶员座椅区域的图像数据,通过计算机视觉技术,对驾驶员是否存在危险驾驶行为进行实时检测。主要做了以下工作:(1)利用基于深度学习的MTCNN(Multi-task Cascaded Convolutional Networks)算法实现对司机的人脸检测和面部特征点定位,训练了针对驾驶室环境的人脸检测模型,提高了人脸检测对环境的鲁棒性,获取驾驶员面部在图像中的准确位置。在车载机平台上使用NCNN库调用该检测算法的检测模型,并达到了良好的检测效果。(2)对定位到特征点的人脸图像进行分割,得到眼睛、嘴和耳朵周围等区域的待分类图像。采用HOG(Histogram of Oriented Gradient)特征与SVM(Support Vector Machine)相结合的方法对驾驶员的危险驾驶行为进行模型训练和分类,实现了对上述多种危险驾驶行为的检测分析。设计了对镜头遮挡进行判断的检测算法。(3)对驾驶员行为分析系统进行实际环境下测试。最终实现了具有较高检测率、较低误检率、运行速度快、对硬件资源占用较少的分析检测系统,满足项目需求。综上所述,本文采用基于深度学习的MTCNN人脸检测和特征点定位算法,实现了对驾驶员面部的检测;采用HOG特征与SVM相结合的方法驾驶员的行为进行分析。最终在车载机平台上实现了满足实际项目需求的驾驶员行为分析检测系统。"
115,基于机器学习的含蜡原油管道蜡沉积预测算法研究,"含蜡原油管输时的蜡沉积现象是影响管道安全运行的重要问题,严重时甚至会堵塞管道,威胁原油安全输送。同时,当不同种类的原油混合后,其流变性和析蜡特性都会发生改变,管道的蜡沉积规律更加难以预测。因此,针对不同种类含蜡原油及其混油的管输过程,建立高精度、适用性好的蜡沉积预测模型,指导含蜡原油管道安全运行具有重要意义。本文拟基于传统的蜡沉积动力学模型、以及具有非线性处理优势的人工神经网络和支持向量机算法,开展基于机器学习的含蜡原油管道蜡沉积智能算法研究,具体的研究工作如下:首先,以大庆原油、俄罗斯原油及其不同比例的混合原油作为实验油样,进行包括粘温关系、析蜡热特性参数和凝点等基础物性和流变性参数测定。在此基础上,采用室内小型环道蜡沉积模拟实验装置进行实验,利用单因素实验方法对油壁温差、油温、流速和混油掺混比例等四种因素对蜡沉积速率的影响规律进行分析,并基于灰色关联理论得到除掺混比例外各影响因素的主次关系为:油温>流速>油壁温差。其次,在动力学模型方面,考虑到蜡沉积过程中的沉积物蜡含量、蜡分子扩散系数中的相关不确定因素对蜡沉积速率的影响,为使模型预测更为准确,基于粒子群优化算法对RBF神经网络和支持向量机两种蜡沉积预测模型对蜡沉积速率分别进行预测,以平均相对误差、平均绝对误差、标准差和均方根误差四个指标对包括蜡沉积动力学模型在内的三个模型的预测结果进行对比分析。结果表明,基于粒子群优化的支持向量机模型预测值平均相对误差最小,预测结果最接近实验值;经优化后RBF神经网络的平均相对误差减小幅度更大,优化效果更好;蜡沉积去倾向系数法的四项误差指标均大于其他两个模型,其预测数据的离散程度最大。最后,根据三种模型的对比分析结果,采用粒子群优化算法对RBF神经网络模型和支持向量机模型进行参数优化,并使用优化后的模型对前文中37组实验数据中的蜡沉积速率进行预测,相比于未经优化的模型,经过优化后的模型预测精度更高,预测数据离散程度减小。根据这一实验基础,对庆哈输油管道的实际运行情况进行蜡沉积速率预测。其中,优化后的RBF神经网络与支持向量机模型平均相对误差下降分别为7.50%与2.27%,优化后的RBF神经网络比支持向量机的精度提升更高,但RBF神经网络的平均相对误差仍高于支持向量机。"
116,基于深度学习的树种识别算法研究,"传统基于图像的树种识别相关研究包括植物叶片识别、花卉识别、树皮纹理识别以及木材纹理识别等,都是根据植物的单一器官进行识别,并且传统的基于人工提取特征的机器学习方法对单一纯色背景的植物图像有较好的识别效果,但是对自然环境下的复杂背景下的植物图像识别效果较差,本文提出一种基于深度学习和树木整体图像的树种识别方法,实现了对复杂背景的树木图像进行自动识别。本文的主要研究内容如下:(1)采用自主拍摄和网络爬取相结合的方式构建了一个TreesNet树木整体图像数据集,共包含10个树种总计1593幅RGB图像。同时,采用了翻转、裁剪等方式对图像进行数据增强,数据增强后生成了大量新的图片,最终得到的图像数量是原始数据集的10倍。(2)基于AlexNet、VggNet-16、Inception-V3、ResNet-50四种模型在原始树种数据集和使用了数据增强后的数据集上进行训练,分别采用了直接训练和迁移学习两种训练模型的方式,比较迁移学习和直接训练得到的模型的准确率。(3)基于集成学习的思想,采用相对多数投票法和加权平均法分别对上述直接训练和迁移学习训练出的四个模型进行集成,生成集成模型。(4)通过Web App技术将模型打包移植到移动端,开发出一款树种识别应用。本研究实验结果表明,数据增强能有效改善过拟合问题,从而提高模型的泛化能力,同时本文提出的基于集成迁移学习的方法对复杂背景下的树木整体图像识别率达到了99.15%,相较于传统机器学习方法有很大的提升。"
117,基于统计学方法的朝鲜语大数据文本挖掘研究,"我们现在所生活的是高速运行、时刻在向前发展的社会环境,科技的不断创新将我们带进了一个全新的大数据时代,发达的科技不仅仅日益丰富着人们的生活乐趣,同时将人们之间的关系进行了还原,心与心的距离缩小了,更重要的是改变了人们的沟通方式。大数据作为现代科技环境的中心,是一种极其重要的资源,大数据顾名思义当然是数据量“巨大”,但真正的价值不是它的大,而是它内在所包含的信息,那些可以被有效利用起来的信息,使之逐渐变成有意义的时代产物。如何发现这些信息是有价值的可以被人们使用的呢?那么就要通过文本挖掘技术来探究,文本挖掘是由机器学习、并行计算、统计学、数据挖掘、自然语言处理、概率、图论等各个学科相互融合的,涵盖着以上学科的精华,基于此就是文本挖掘被许多学者和专家进行研究的原因所在,融合了多种学科和技术,不存在明显的学术限制,可以使得各个领域的学者进行交流合作与探讨。由于朝鲜长期实行信息的封闭政策,官方的各种统计数据都零散的存在于各类文献资料或是新闻报道中,这给朝鲜半岛问题的系统研究带来了诸多不便,基于统计学方法的朝鲜语大数据文本挖掘研究就是要解决此类问题。本研究选取的新闻数据共计约500万条,其中朝鲜语数据150万条,中文数据350万条,将这些数据导入进Transwarp Data Hub,即一个功能较为完善周全的大数据综合平台。进行数据清洗与转换、文本预处理与分类、建立朝鲜新闻专属词库和更新朝鲜语语料库等关键步骤,通过服务器中的R Studio应用统计学知识进行文本挖掘的相关研究,根据朝鲜半岛的资料及具体问题的特征建立分析模型,结合各种已成熟的算法以实现朝鲜语大数据文本挖掘,其中关键环节是朝鲜语语料库的更新和朝鲜新闻专属词库的建立,对有关朝鲜专属语料的添加、更新、编辑、剔除等工作,更新后的语料库与建立的朝鲜新闻专属词库为基础,在词性标注方面有了更高的一致性,并对得到的结果进行具体分析,最终的研究结果可以为人文社科类学者在研究朝鲜半岛诸多问题上提供强有力的数据支撑和理论支持。"
118,基于机器学习的北京市快递网点布局研究,"快递网点在一个区域的重复选址或网点分布密集会导致分流、资源浪费现象,网点分布过稀疏又会导致对客户需求覆盖不够。合理的快递网点布局分析需要应用科学、综合的研究方法,对该网点所在区域的地理、社会、经济等因素进行全面研究。近些年来,随着大数据技术的不断发展和智慧城市研究的不断深入,我们可以利用的数据不断增多,利用这些大数据结合机器学习算法进行服务设施布局研究,有助于实现了城市规划的智能化发展,然而机器学习在快递网点选址和布局方面的应用仍然存在较大的空白。本研究采用机器学习及大数据分析技术,以北京市五环内为研究对象,拟在确定北京市快递网点与其他服务设施之间布局的量化关系模型。首先,利用爬虫技术收集影响网点布局的北京市人口、商业网点、交通站点的GIS位置,然后利用GIS的网格化手段将北京市五环内区域划分成大小合适的网格,统计网格内的各类服务网点的数量得到的样本数据。其次,利用多元线性回归模型确定物流网点数量与各因素之间的定量关系,随后又利用机器学习的神经网络、支持向量机、随机森林、GBDT算法,对样本样本数据集学习,从而建立了一系列快递网点数量的机器学习模型。最后通过对单一模型进行强化,得到最优的集成学习模型。本研究得到的模型和数据不仅为北京市五环内快递网点建设的合理规划提供决策依据,而且利用机器学习建立网点布局模型的思路为分析其他城市快递网点或物流服务设施布局提供方法借鉴。本篇论文含图47幅,表13个,参考文献77篇。"
119,微博舆情的情感分析与社会动员,"当前,中国社会已进入社会敏感期和矛盾多发期,主要表现为经济较快增长、政治基本稳定、社会矛盾尖锐。在这样的现实环境下,突发事件频发,进而发展为声势浩大、影响广泛的舆情事件。在微博的传播生态中,舆情事件的演化又呈现出新的元素和特征。围绕着微博舆情的情感现象与社会动员状况的问题,相关研究最早在计算机科学、情报学、社会学等学科展开。之后,新闻传播学的学者们开始涉足该领域,并涌现出一系列研究成果。但在方法论层面或囿于机器学习、情感词典等方法的局限;或单纯地展开质性分析,缺乏量化指标体系的测量。为此,立足于本学科,本研究以“山东于欢案”为研究对象,以利用新浪微博“发现”功能搜索的830条与本案相关的微博文本为语料库,采取文献研究法、内容分析法和个案研究法,通过四个章节重点分析了“山东于欢案”的情感表达方式、情感表达内容、情感画像、社会动员方式、社会动员的影响因素和社会动员的效应等问题。在此基础上,笔者又对情感与社会动员的关系进行了探讨。研究发现:第一、在“山东于欢案”中,评论、文字、多种符号复合传播成为最主要的情感表达方式;主要的情感倾向为消极情感,认可、质疑和愤怒成为主要的情绪类型;政府、媒体更偏向于表达无情感,而大V和草根等群体对消极情感表达得更多。第二、在“山东于欢案”的社会动员层面,理性动员与感性动员兼具,主要集中于感性动员,策略与剧目多元,人力动员和舆论谴责成为最主要的动员方式;意见领袖和议程设置使“山东于欢案”在动员进程中的理性元素得以增强;微博舆情中的社会动员具备推动信息公开、实施环境监测,倒逼事实真相、还原事件全貌的作用以及谣言传播更为迅猛的负面效应。第三、消极情感更能够引发社会动员,且集中在感性动员;积极情感和无情感引发社会动员的效力相当,且偏向于引发理性动员。而情感之所以能够引发社会动员,是基于情感表达丰富社会动员方式、情感渲染促进群体共识形成、情感共鸣推动社会动员开展这三者的层层递进而实现的。"
120,共享单车情境下的公交出行研究,"“公交优先”是高效城市交通发展的重要战略。以每日通勤为例,从占用道路和停车位的角度来看,与其他公路运输方式相比,公共汽车是最经济有效的出行方式。协作消费的新模式-共享单车确实成为人们解决近年来“最后一公里问题”的有效工具。这种新兴的出行模式具有重大影响,在一定程度上构成了与当地公交车的竞争关系。随着城市交通需求的快速增长,城市交通供需矛盾的加剧也随之出现,因此,共享单车提供了绿色高效旅行模式的替代方案。更重要的是,人们开始尝试从传统的公共交通转向新的模式。因此,为了更好地应对这些影响,协调城市交通系统,最大限度地发挥社会经济的整体效益,探索共享自行车与公交系统之间的关系和互动机制具有重要意义。本文利用陈述性偏好(SP)实验得到的状态偏好数据,研究了在共享单车情景下人们出行时选择公交车的影响因素。本文基于SERVQUAL模型和现有满意度量表,探讨影响出行者选择决策的因素。特别是,对于公交出行行为,对现有的测量指标进行分类,并测量期望与现实感知之间的差距。本文利用基于潜变量的MNL模型与Breiman提出的决策树和随机森林算法进行比较,对数据进行了全面分类和分析,探讨在共享单车影响下公交车选择的影响因素。MNL模型很好地解释了人们选择的重要影响因素,然而,分类方面并不那么系统和清晰。Breiman提出的决策树和随机森林算法可以从个人出行模式选择的角度减少高复杂度、不确定性和随机性的问题,并获得更直观、通用和方便的政策建议决策,这对于理解和预测人们的出行需求非常重要。本文的重点是新交通方式对传统模式的影响以及对未来发展趋势的研究。本文选择的变量是独特的,引用了行为经济学、心理学理论,并考虑到了服务质量潜在的变量。本文还涉及不同的出行目的,城市公交车服务满意度和共享单车服务满意度,以及选择某些天气条件如何影响人们的旅行模式。最后,本文进行了方法论的比较,将基于潜变量的Logit模型和随机森林进行比较研究。本文在共享单车影响的背景下进行深入的调查和分析。在具体研究成果的基础上,本文探讨了如何提高城市公交车的利用率,从而支持城市交通系统的可持续发展。"
121,基于机器学习分类算法的微博恶意用户识别研究,"近些年,各种社交应用软件影响着人们的日常生活。其中微博因其传播速度快,信息覆盖面广的特点,成为了人们日常获取信息,分享心情的热门平台。微博在给人们带来网络社交便利的同时,也充斥着许多恶意用户,他们发布垃圾信息,影响舆论趋势,给人们正常使用微博带来了困扰。本文以新浪微博上的恶意用户为研究对象,通过分析新浪微博上的恶意用户的行为和账户信息,设定识别恶意用户的特征集合,采用机器学习分类算法对恶意用户进行识别。本文主要工作如下:(1)针对通过微博接口采集微博用户数据存在的局限性问题,本文设计了一种爬虫程序,该程序能够根据实验需求采集微博用户的相关数据,并且无需人工频繁干预,不受网站接口调用次数的限制。从程序实际的运行结果来看,使用本文所设计的爬虫程序可以高效准确地采集微博用户的信息。(2)本文对微博上的机器用户和广告用户进行研究。为了提高对这两类恶意用户识别的效果,通过绘制特征和用户数量累积分布图对恶意用户的特征进行分析,本文提出了点赞数量、个人介绍以及网页和推荐关注所占比三个新特征,并将它们与传统特征集合结合,设定了新的特征集合。分别利用机器学习分类算法中的k近邻算法、朴素贝叶斯算法、决策树算法进行实验,实验结果表明,与采用传统特征集合相比,采用本文所设定的新特征集合识别机器用户和广告用户的精确率更高。(3)针对采用传统朴素贝叶斯分类算法(NBC)识别恶意用户效果不理想的问题,本文对NBC算法进行了改进。考虑到不同特征对分类结果的重要性差异,在NBC算法的基础上,本文提出了基于信息增益的加权朴素贝叶斯分类算法(WNBCI),该算法通过计算信息增益构建特征排名表得到各个特征的权值,实验结果表明该算法比NBC算法具有更高的精确率。进一步考虑到同一特征的不同取值对分类结果的影响不同,本文在WNBCI算法的基础上又提出了基于信息增益和基尼指数的加权朴素贝叶斯分类算法(WNBCIG),该算法结合每个特征的信息增益和不同取值的基尼指数得到各个特征的权值,实验结果表明该算法比WNBCI算法具有更高的精确率。(4)本文设计了一个微博恶意用户识别系统,利用该系统可以获取微博上的热门话题和用户公开的信息。而且该系统使用WNBCIG算法对微博上的恶意用户进行识别,为微博研究人员提供了便利。"
122,石林巴江流域径流过程对气候及土地利用变化的响应研究,"云南石林岩溶区以其独特多样且分布集中的岩溶类型闻名于世,作为岩溶发展动力之一的水资源,不仅参与岩溶区自然变化,并对岩溶区社会的工农业生产、社会建设、生活用水等起到重大作用。因此我们需要了解岩溶区水资源的发展演变特征与形成规律,为当地经济生态可持续发展提供依据。石林巴江流域地处云贵高原喀斯特岩溶区,是珠江上游南盘江的一级支流,流域内的水文水资源与水文生态系统特殊,石漠化趋势突出。由于特殊地理环境与人为因素的影响,流域内水资源与生态系统的可持续性,已经成为制约当地经济发展的重要因素。因此,本文立足于前人研究的基础上,采用数理统计、遥感技术与水文模型相结合的分析方法,结合已有的气象水文实测数据资料,分析了巴江流域气候变化与土地利用变化的趋势,探讨了流域径流过程对气候与土地利用变化的响应,以期为流域水资源合理利用、水土流失治理、改善生态环境等提供参考借鉴依据。论文的重要研究成果如下:(1)巴江流域1965~2017年间气温的倾向率为0.38℃/10a,总体呈波动上升趋势,年内季节变化中冬季气温上升最快,其倾向率为0.50℃/10a;流域气温序列在1996年产生突变,且在1996年突变后气温变化呈显著性上升趋势;气温变化在21和28年上存在着周期振荡,其中28年为主振荡周期,并且贯穿整个研究时段。流域降雨量在53年来以-16.32mm/10a的速率呈明显的下降趋势,由于流域地处北亚热带季风气候区,具有明显的干湿季之分,因此年内降雨季节变化趋势差异较大,其中夏秋两季分别是以-3.09mm/10a、-3.22mm/10a的倾向率呈下降趋势,而春冬两季则分别以0.17mm/10a和0.87mm/10a的倾向率呈上升趋势;流域降雨量序列在1975年产生突变;流域降雨小波周期分析表明流域内存在着5a、10a、15a和28a多个振荡周期,其中28a为主振荡周期,并且具有全时域性。(2)1980~2009年巴江流域的径流总体趋势以-545.69×10~4m~3/10a的速率下降,而春冬两季径流变化分别以84.88×10~4m~3/10a和57.53×10~4m~3/10a的速率增加,与流域径流的整体趋势相悖;流域径流量在1983年出现突变;流域径流量在研究期内的2a、4a、8a中有振荡周期,其中8a的振荡周期具有研究时段全时域性特征。通过对研究时段年内径流的均匀系数与集中度、集中期进行分析,结果表明径流量年内分布极不均匀,其中最高差值达到了0.39,并且在1983年径流突变年份的不均匀系数达到了最低;流域径流聚水量主要发生在夏秋两季,这两季占了年内径流总量的78.9%,且有67%年份的径流产生在7、8两月。(3)对巴江流域1988~2015年的土地利用变化特征进行了分析,研究表明巴江流域在研究期内的综合土地利用年变化率为0.83%,建设用地面积与草地面积在研究期间总体呈增加趋势,分别以每年3.11%、3.33%的速率在增长;而水域、林地、耕地以及未利用地在研究期间则呈减少趋势,但是下降趋势较小,年下降率不足1%,分别以每年-0.17%、-0.79%、-0.20%、-0.55%的速率下降,其中耕地、未利用地与林地三者的转移变化比较大,而水域、草地、建设用地在研究期间内面积的转移变化较为平缓。(4)基于多元线性回归模型与相关性分析法,对巴江流域1980~2009年的径流量与气候变化之间相应作了分析。结果表明研究期内流域径流量之与降雨量具有较强的相关性,因此利用多元线性回归模型定量性的分析径流与降雨之间的响应关系,发现当降雨量以0、±1%、±5%、±10%变化率变化时,相应的径流量对应的变化量为0、±2.06%、±9.79%、±19.59%,由此可见降雨量是引起流域径流量变化的敏感因素。(5)利用ANN神经网络与Mboost机器学习模型,结合分离评判法原理对巴江流域1980~2009年间气候因素与土地利用变化对径流量的贡献率做了分析。以2002年为界限,前期建立基准期与2002年以后作为人类活动期,其中ANN模型算出的土地利用变化的在贡献率为94.4%,Mboost机器学习模型算出土地利用变化的贡献率为96.9%。由此得出,在2002年以后人类活动期间土地利用变化对流域径流量的影响远大于气候因素。整体而言,上述研究成果为巴江流域水资源进一步的研究增添了新的思路与方法。不仅有助于提高人们对巴江流域水资源演变规律的认识,并对流域水资源的合理利用和生态水文的可持续发展提供了一定的理论依据。"
123,基于数据驱动的生活用纸物理特性预测及其打浆工艺优化,"生活用纸与生活息息相关,相应的有着更严格质量标准和精细化的技术要求。本论文以生活用纸为研究对象。在生活用纸厂的典型生产线上,采集各个重点生产环节的数据。经过数据预处理,建立生活用纸磨浆打浆度模型和原纸物理特性指标预测模型;以满足原纸质量要求和最小成本为目标,建立打浆工艺优化模型。首先,针对浆料的打浆度无法在线监控的问题,基于梯度提升决策树(Gradient Boosting Decision Trees,GBDT)算法建立了磨浆打浆度模型。采样并获取不同浆板组合、不同磨浆工艺下,磨浆后纸浆的纤维形态和打浆度数据。经过数据预处理,获得建模的训练集。基于GBDT算法的磨浆打浆度模型,用交叉校验法检验模型精度,模型的均方根误差为0.99,平均相对误差(MRE)为3.96%,平均绝对误差0.78(°SR),结果表明模型有良好的精度。对比支持向量机回归算法,在相同计算机环境下GBDT运算时间是支持向量机回归的五十分之一,表明GBDT运算速度快。对GBDT模的树型结构进行分析,计算了11个模型输入变量的相对重要性,其中比能耗、流量和分丝帚化率的相对重要性较高,即他们对打浆度的影响较大需要在生产中重点监控。其次,针对生活用纸的物理特性的在线预测的问题,运用了主成分分析法对数据集降维,并且运用了机器学习技术,分别建立了生活用纸的平均抗张强度、伸长率纵向、伸长率横向和吸水性的预测模型。以实际生活用纸质检数据做验证,平均抗张强度的MRE为11.20%,伸长率纵向的MRE为10.48%,伸长率横向的MRE为8.23%,吸水性的MRE为6.01%。平均抗张强度、伸长率纵向和吸水性有良好的模型精度,R~2均高于0.8。利用Lasso算法对模型输入变量进行重要性分析。其中最显著的是,卷速和真空网笼速度对伸长率纵向,有显著于其他输入变量的影响,应该重点监控。最后,在建立的原纸物理特性模型的基础上,建立了生活用纸打浆工艺优化模型。以成本最小化和满足质量要求为两个目标,基于进化算法求解浆料配比和磨浆工艺参数值。以某品类生活用纸为案例,结果表明,基于快速非支配排序算法的生活用纸打浆工艺优化模型,可求解出成本更低且符合质量要求的生活用纸打浆工艺。"
124,基于大数据的公交线网速度预测模型研究,"如今随着世界经济的不断进步,这加速了国内外交通行业的生产,运输水平,城区的机动车数量不断提高,交通流不断增加,这导致出现了很多交通安全问题。如果能够使城市公共交通的线网速度预测能力提升,将一定程度缓解交通压力。这也是当前很多学者的研究重点,国内外对此都有很多开创性的成果。然而,实现公交线网速度的精确预测并不容易,这是因为:(1)多种因素结合造成的影响,仅天气一个影响因素就有数种变化趋势;(2)公交系统采集到的数据量相当庞大,维度较高;所以如果仅仅运用传统的数理统计方法对数据进行处理,很难对各个维度的数据进行有效的分析,从而降低预测精度。本文研究基于大数据的分析技术,对公交线网速度进行预测,主要研究包括以下几个方面:首先,本文研究了国内外对公交线网速度预测的方法或者算法的优势和劣势,同时研究了当前机器学习算法的应用情况,为本文应用大数据技术提供思路和启发;对公交线网速度预测的影响因素做了全面的分析,针对公交车辆运行过程中的重点的影响因素,对数据进行数理统计,对时间数据计算最大值、最小值、平均值、标准差等统计,这将对影响因素进行分类,对后续的数据处理提供理论依据;根据采集到的GPS信息数据,IC卡刷卡数据进行数据预处理工作;对线网速度与公交车到站的关联进行分析,并对线网速度的预测进行转换。之后,提出模型建模,用机器学习中的SVR模型以及DBN模型来进行数据演练及预测,选取并细化数据集,对数据进行转换,使其能够分别应用于回归问题和分类问题,经过模型训练后,分析模型训练得到的结果,在不同情形下进行对比;实验结果表明两种算法评价尺度都足够实现模型的训练,预测精度达到了预期水平。最后,对两种算法在不同情况下的优劣程度进行了分析,综合运用后,表明两种模型对公交线网速度的预测水平较高,对城市交通的压力能够带来很好的缓解,并对交通运输类的实际问题有了大数据层面的开拓性研究。"
125,机器学习在蛋白质磷酸化、硝基化和硫化位点识别中的应用研究,"蛋白质翻译后修饰,也称为共价修饰,是调控蛋白质功能的重要机制,在信号通路和生物学过程中发挥着不可替代的作用,并可逆地决定了细胞的动力学和可塑性。然而,随着蛋白质翻译后修饰数据的高通量发展,传统的实验方法往往是费力、费时和昂贵的,快捷便利的计算识别修饰位点的预测方法应运而生。本论文主要基于机器学习,针对酪氨酸硝基化、硫化和磷酸化以及7种真菌的丝氨酸、苏氨酸和酪氨酸磷酸化位点分别建立了在线预测工具,并对其进行蛋白质组学分析。具体内容如下:1、基于弹性网络优化特征方法预测和分析酪氨酸翻译后修饰位点。酪氨酸翻译后修饰,主要包括硝基化、硫化和磷酸化,涉及不同的生理和病理过程。因此,预测整个蛋白质序列中酪氨酸残基的硝基化、硫化和磷酸化具有重要意义和实用价值。在这里,我们采用序列特征、物理化学性质和进化信息对特征进行编码,引入弹性网络进行特征选择,建立了在线预测酪氨酸硝基化、硫化和激酶特异性酪氨酸磷酸化位点的工具TyrPred(http://computbiol.ncu.edu.cn/TyrPred)。交叉验证和独立测试结果表明,利用弹性网络提取训练的重要特征可以显著提高预测性能,同时我们期望TyrPred能够对现有方法起到补充作用。2、基于特征优化策略计算预测和分析真菌特异性磷酸化位点。蛋白磷酸化主要发生在丝氨酸、苏氨酸和酪氨酸残基上,调节多种生物过程。目前真核蛋白磷酸化位点的计算预测主要集中在动物和植物上,尤其是人类,真菌较少。因此对真菌特异性磷酸化的鉴定越来越受到重视。我们基于收集到的真菌磷酸化位点实验数据,按物种和修饰残基进行分类,并以不同特征编码,采用两步特征优化方法进行训练,提出了一种新的真菌特异性磷酸化预测工具―PreSSFP(http://computbiol.ncu.edu.cn/PreSSFP)。Motif和特征分析结果表明7种真菌物种间存在显著差异,为今后真菌磷酸化的计算分析提供新的线索。"
126,《机器学习―新型人工智能》（节选）翻译实践报告,"计算机网络的发展使得人们对信息的采集、传播的速度和规模达到史无前例的水平,实现了全球信息的共享和交互。在信息化时代,利用机器学习将无序的数据转换成有用的信息,至关重要。本报告所选翻译文本为一本权威的讲述机器学习的著作《机器学习――新型人工智能》(Machine Learning―The New AI),笔者节选了第一和第三章作为翻译材料,所选材料第一章详细的叙述了计算机科学及其应用的发展,解释了数字技术是如何从大型计算机发展成台式个人计算机以及后来的智能在线设备和移动设备的。而第三章主要讲的是学习算法是如何用于模式识别,其中重点介绍了人脸识别和语音识别。原文本属于典型的科技文本,文本中有大量技术词和半技术词,而且句型复杂,多为长难句,整体语言客观,专业性极强,是科技文本翻译问题的理想材料。本次翻译实践根据翻译目的论的忠实原则,尽量规范文本中科技术语的翻译;根据翻译目的论的目的原则,对文本中长难句的翻译采取了不同的翻译策略,如换序、省译和拆分法,力图使译文简洁,逻辑严谨,符合汉语的表达习惯;根据译文语言表达的连贯性,笔者探讨了译文中经常出现的语言表达问题,如死译问题、词语搭配不当问题和语义模糊问题,同时采取了相应解决办法,如增译法、转译法和意译法等,力求表达规范,实现译本的通顺简洁。通过《机器学习――新型人工智能》的汉译实践,笔者锻炼、提升了翻译能力,将所学的翻译方法和技巧用于实践,同时了解了科技英语以及机器学习相关内容,获益匪浅。"
127,基于boosting模型的逆向投资策略研究,"本文创新性地将机器学习中的Boosting模型与逆向投资策略相结合,并探索将其用在中国证券市场,希望即能保留逆向投资的思想理念,寻找市场阶段性关注度较低或未被人挖掘出来但基本面良好的股票进行投资;同时又能利用机器学习的高效数据分析和准确客观判断的优势,排除投资者的非理性情绪影响,从而形成更为有效易行的策略方案。本文选取的股票池是自2007年以来的全A股,剔除ST和停牌、刚上市三月内的股票。根据逆向投资策略的要点和衡量标准,对成交量、涨跌幅、收盘价等各类数据信息进行筛选并合成出相应的指标,再对其进行特征提取、数据预处理和训练期参数调节等过程;随后按机器学习方法,对Boosting模型进行样本内外滚动训练学习、重要性分析、分层测试分析等流程步骤,并对模型结果和回测组合进行比较和优化,主要包括Boosting模型内部细分算法(GBDT、XGBoost、Adaboost)比较、与线性回归、支持向量机、随机森林和朴素贝叶斯等对照模型比较、选股组合按是否行业中性进行比较、不同调仓频率(分月度和季度)的回测比较分析以及模型止损优化等步骤,最终获得较为理想的方案。基于以上研究过程,本文发现XGBoost分类正确率略微胜于Adaboost和GBDT,而运行速度和模拟回测效果远胜于其他两种。其次,XGBoost模型在分类效果指标正确率和收益率上均胜于线性回归、支持向量机、随机森林和朴素贝叶斯等对照算法模型,但最大回撤率不及线性回归模型,而运算速度上有明显优势,其他所需运算时间普遍为XGBoost的2~8倍。同时按选股是否行业中性及不同数目进行比较,发现随选股数量的增多,收益率逐渐下降,最大回撤率则提高,表现最优的是各行业入选2只股票,或全A股市场选择20只股票。而月度调仓组合和季度相比,除最大回撤率相对较高外,其他指标如收益率、夏普比率等均更优。而在加入止损条件后,年化收益率明显提高,可达28.5%,最大回撤率也有显著下降,优化效果明显,逆向投资策略在中国证券市场仍有效。由于XGBoost较为复杂,策略模型搭建和优化上仍有些不足,未来可以在回测训练参数、构建的策略指标以及止损条件等进一步优化和完善。"
128,基于机器学习的急性肾损伤预测及临床应用优化,"智慧医疗是利用计算机技术、大数据分析技术、临床诊疗设备等,对患者进行更科学、智能化的诊疗,从而减低患者的发病率和死亡率。目前,大数据、人工智能、机器学习等方法逐渐在医疗服务领域得到应用,并产生了巨大的社会价值和产业空间。急性肾损伤是一种发病率和死亡率极高的急诊危重病,探究影响急性肾损伤的关键风险因素、对患者的发病率进行预测预警研究,根据患者的病症链优化诊疗流程并应用于临床实践,使医生及早对急性肾损伤患者进行医疗干预,从而降低发病率和死亡率具有重要意义。本文以MIMIC-Ⅲ数据库为基础,根据《2012改善全球肾脏病预后组织指南》对急性肾损伤患者的早期诊断标准为依据,从数据库中提取出满足条件的1698例患者以及对应的个人基本信息和指标数据,运用R语言对原始数据进行缺失值填补、离散化等预处理。将粗糙集、灰色关联度、元胞自动机和遗传算法进行有机结合,运用多主体智能筛选的元胞遗传算法进行20次独立重复实验最终得到呼吸、心率、肌酐、肌钙蛋白T、葡萄糖、P02、PC02、氧饱和度、二氧化碳总量、血小板、中性粒细胞、尿红细胞、尿白细胞、尿蛋白定性14个影响急性肾损伤的关键风险因素。接着,采用逻辑回归、基于决策树的自适应加强(Adaboost)算法、多层感知机(MLP)对急性肾损伤进行预测预警分析及交叉验证,从准确度、精确度、召回率几个方面综合评价模型的性能。结果显示:输入经过元胞遗传算法筛选的关键指标进行预测的效果优于未经元胞遗传算法筛选的全部指标预测,集成算法的预测效果优于单一算法,从不同算法的综合评分可以看出多层感知机的性能优于基于决策树的自适应加强算法和逻辑回归。最后,在上述研究的基础上通过分析急诊危重症急性肾损伤患者关键指标的变异值及其对早期诊断的价值和临床意义,从急救数据采集与信息共享、根据关键指标对急性肾损伤进行早期判断、床旁监测系统以及临床医生决策路径几个方面对现有的诊断、决策方式进行优化,以期降低急性肾损伤患者的发病率和死亡率。"
129,大规模物联网设备组织信息的发现与提取,"随着互联网技术的不断发展,物联网技术也迎来了高速度高质量的发展。一方面,物联网拉近了物与物,物与人,人与人之间的联系,实现了万物之间的沟通,加速了科技的进步。另一方面,物联网使用简单、便捷、节能,是新世纪下实现高效、高质量的重要技术。然而近些年出现的针对物联网设备攻击等安全事件,在一定程度上影响了网络的发展和国家的安全,物联网技术逐渐受到各行各业的关注,目前已经成为学术界的研究热点。尽管有很多研究人员对物联网的各个方面展开了研究,但是在安全和管理的相关研究文献中,仍发现有大量的物联网设备可以通过IP地址访问和可见,这极容易造成关键设施及信息被泄露和乱用,引发网络安全事件。因此,本文从安全的角度深入研究物联网设备所属组织的属性信息,目前学术界对物联网设备组织信息的研究较为缺失,组织信息的提取缺少可靠的依据,而设备所属组织对于管理和加强设备安全都是非常重要的。本篇论文研究大规模物联网设备的组织信息提取技术,包括物联网设备识别和设备组织信息提取:(1)在物联网设备识别方面,论文通过解析应用层响应数据的报文内容利用应用层服务的差异性,提取物联网设备的特征,结合常规的四种机器学习分类算法,提高物联网设备识别的精度。(2)在物联网设备组织信息提取方面,通过实践观察,本文发现许多设备组织者会将组织的细节信息写入物联网设备上的应用层协议数据报文中,如公司或用户名等等,这些硬编码的信息可以作为设备组织信息提取的依据。因此,本篇论文结合自然语言处理技术提出基于规则的信息提取技术和基于命名实体识别的信息提取技术,获取应用层响应报文中的组织信息。为了验证设备识别和组织信息提取的可行性,本篇论文搭建了原型系统并进行了实验验证。实验结果表明,机器学习分类算法对物联网设备的识别精确率能够达到97%,覆盖率达到97%。论文收集了 9300万个HTTP响应数据报文,通过设备识别技术,发现了将近430万个暴露于互联网上的物联网设备。此外,本篇论文还提取了近60多万个物联网设备的组织名称,并对提取到的组织进行了分类统计与分析。实验结果表明,物联网设备识别和组织信息提取技术对于网络空间的安全与防御有着重要的价值。"
130,产品评论的方面级观点挖掘技术研究,"随着互联网和网络购物的日益流行,产品的评论通常被作为是否选购该产品的重要依据,因此,如何从大规模的产品评论中高效地获取到对潜在消费者和商家更具有价值的信息逐渐成为研究热点。本文对产品评论进行方面级观点挖掘技术研究,能够快速准确地获取到产品各属性的评价情况,对潜在消费者选购和商家改进产品都有重要意义。本文的主要研究工作如下:1.针对目前多数评价搭配抽取方法存在人工标注工作量高、依赖于外部情感词典和动词词性考虑较少等问题,提出了一种基于规则的评价搭配抽取方法。该方法通过词性、依存句法分析和语义依存分析的结果制定规则,首先进行核心搭配的抽取,然后引入识别并列评价对象的算法及改进的识别修饰成分的算法,结合核心搭配组成部分的不同词性进一步制定规则来识别完整的评价对象和评价短语。在中文手机评论数据集上进行实验的准确率达到71.95%,召回率达到66.74%,F1值达到69.25%;在中文酒店评论数据集上进行实验的准确率达到60.42%,召回率达到62.24%,F1值达到61.31%。实验结果表明本文方法进行评价搭配抽取的有效性。2.针对已有的方面级情感分类研究中,大多数方法通常需要构建完善的情感词典和判断规则,而基础的机器学习方法存在分类性能有待提高等问题,提出了一种基于情感词汇与机器学习的方面级情感分类方法。该方法选取部分正向、中性和负向情感词组成情感词汇,并将互信息中各类别的占比作为基础机器学习方法分类概率的权重,选择加权后概率最大的类别作为情感倾向。在中文手机评论数据集上进行实验的宏平均值达到84.46%,比基础的机器学习方法提高了4.53%,微平均值达到84.49%,提高了4.55%;在中文酒店评论数据集上进行实验的宏平均值和微平均值都达到83.62%,都提高了4.11%。实验结果表明本文方法可以有效提高方面级情感分类性能。3.设计并实现了一个产品评论的方面级观点挖掘系统,该系统通过用户输入的产品ID,自动地进行评论数据爬取、预处理、评价搭配抽取及其情感分类,然后将观点挖掘的结果以图形化界面展示。"
131,基于深度学习的交通流量预测,"随着社会的发展,交通拥堵等交通问题已日渐显著。作为解决交通问题的有效手段之一,智能交通系统已经越来越受到人们的推崇。其中,交通流量预测是智能交通系统的基础,它通过利用历史数据对交通流量进行准确预测,从而对交通规划、用户出行提供准确的建议。然而,目前的交通流量预测的方法还存在很多的不足。大部分的交通流量预测方法仅基于流量的时间序列特征信息进行预测,这样会造成信息的缺失从而降低预测的准确性;其它的预测方法虽综合利用了特定地点的时空特征信息,但空间特征提取方法并不完善,提取出的空间特征信息的准确度有待提升,因此会对预测的准确性带来不良影响。针对上述问题,本文提出了一种基于深度学习的交通流量预测方法,通过对数据的处理与整形,利用图卷积网络与长短期记忆网络提取交通流量的时空特征,对其进行预测,并结合时间周期、天气信息等其他相关因素特征对交通流量进行预测的结果,实现更准确的预测。本文的主要贡献如下:(1)针对传统的交通流量预测空间特征提取方法的不足,提出了一种更实用、更符合实际交通网络结构的空间特征提取方法。该方法的特色在于:它将路网视为拓扑图,其中道路上的交通流量作为边的特征,利用图论中线图转换的方法,将路网拓扑转换为路邻接拓扑,道路上的交通流量变为节点信息特征,然后将路邻接拓扑矩阵与节点特征矩阵送入图卷积网络中,实现对交通流量空间特征的合理提取与利用。在北京市出租车数据集上的实验评估结果显示,该方法相对于CNN+LSTM准确率有显著的提升,均方误差为1.8774,预测误差降低了56.9%。(2)通过结合深度学习提取的时空特征的预测结果与其他相关特征的预测结果,设计了一种基于深度学习的交通流量预测系统。该系统通过合理提取交通流量的时空特征进行预测,然后将该结果与利用交通流量有关的其他特征(周期特征、天气特征)的预测结果结合,得到最终的交通流量预测结果。在北京市出租车数据集上的实验评估结果显示,本文提出的交通流量预测系统相比于以往的方法准确率有了明显提升,均方误差为1.6203,相比于CNN+LSTM预测误差降低了62.8%,相比于(1)中提出的预测方法预测误差降低了 13.7%。本文提出的流量预测方法具有通用性,能够用于道路网络和信息网络的时空序列预测问题,因此有一定的理论研究价值。本文提出的流量预测方法和系统能够准确预测道路交通流量,有着很强的现实意义和实际价值。图30幅,表7个,参考文献42篇。"
132,基于NSGA-Ⅱ算法及机器学习的压水堆组件装载方案优化研究,"压水堆燃料装载方案的优劣与核电站经济性和安全性直接相关,本文针对压水堆燃料组件装载方案优化过程中的两个主要问题:方案搜索空间大以及方案评价耗时长,分别进行优化。以组件无限增殖因数以及功率峰因子作为压水堆组件装载方案的优化目标,本文选用NSGA-Ⅱ算法缩小有效寻优空间,进行组件装载优化,并结合中子物理特性,进一步研究组件装载方案优化过程中,NSGA-Ⅱ算法的交叉概率以及初始化种群大小的设计问题。研究结果表明NSGA-Ⅱ算法在针对组件装载优化问题上,收敛性强,优化能力稳定,交叉概率对功率峰因子优化影响较大,对无限增殖因数影响相对较小,选用种群数目较大的初始条件时,NSGA-Ⅱ算法的优化潜力更大,更容易跳出局部最优解。在使用NSGA-Ⅱ算法进行装载方案优化过程中,每次方案评价都涉及求解中子输运方程,耗时较长,本文选用多种机器学习算法,以3×3,5×5,7×7,9×9,14×14,17×17共六种大小规模的燃料组件作为研究对象,探索机器学习模型对组件燃耗、无限增殖因数以及功率峰因子的预测能力,并结合树模型算法特征,研究针对上述3种目标值的组件装载方案的特征重要性。最后采用lightgbm算法以及神经网络算法,精细化研究机器学习算法对17×17组件的燃耗、无限增殖因数以及功率峰因子预测能力。研究发现在大样本数的前提下,各类机器学习模型的预测能力都较好,预测误差均在可接受范围内。组件中~(235)U装载量对各类中子物理参数的预测效果影响都较大,组件装载方案偏度值对功率峰因子以及无限增殖因素预测效果影响较大。最后,经过精细化模型调整后,神经网络算法以及lightgbm模型对17×17燃料组件3类中子物理参数预测能力非常好,验证了采用机器学习算法预测中子物理参数的可行性。在NSGA-Ⅱ算法以及机器学习模型研究基础上,本章节尝试解决搜索空间大以及方案评价耗时长两个问题。选用SiC包壳事故容错燃料作为研究对象,在探索SiC包壳事故容错燃料的中子物理可行性以及优劣性以后,使用NSGA-Ⅱ算法以及机器学习模型对SiC包壳事故容错燃料组件进行装载方案优化研究。研究发现在相对较小的样本数目条件下,模型对无限增殖因素数预测效果较好,对功率峰因子预测效果相对较差,误差均在可接受范围。将机器学习应用于组件优化过程中装载方案评价后,在较短的时间内可得到装载方案,经确定论方法验证,采用机器学习最终得出的装载方案较优,且与直接采用确定论方法得出的装载方案差距不大,证实在组件装载问题优化过程中,采用机器学习评价装载方案具有可行性。"
133,非肌层浸润性膀胱癌组织干性调控机制研究,"背景与目的:膀胱癌是泌尿系常见的恶性肿瘤,可分为非肌层浸润性膀胱癌(Non-muscle invasive bladder cancer,NMIBC)和肌层浸润性膀胱癌(muscle invasive bladder cancer,MIBC);研究表明有高达 45%的 NMIBC 会进展为 MIBC,而MIBC患者需行根治性手术后输尿管皮肤造口,这给患者带来了生活上的不便和经济负担。因此研究NIBC患者疾病进展的机制很有临床价值。研究表明强其多能分化和维持自我更新的能力且体细胞去分化程度与膀胱肿瘤组织干性呈正相关。目前,研究人员大多通过对单个基因进行干性验证来研究其在NMIBC的进展与肿瘤干性细胞相关,成熟的体细胞通过诱导特定基因表达可增细胞去分化中的作用;但该方法很难发现新的干性基因以及验证的基因具有局限性。本课题将利用机器学习算法对NMIBC组织中干性基因进行量化并进一步通过肿瘤组织基因表达情况对干性相关调控机制进行研究,寻找调控组织干性的关键信号通路及转录因子,以期为预防NMIBC进展提供潜在生物标志物。材料与方法:本课题从EGA数据库官网下载编码为“EGAS00001001236”的NMIBC基因表达数据,其中包含460例NMIBC样本和16例MIBC样本;并在线下载对应的临床随访信息。利用机器学习算法对NMIBC全谱基因进行干性打分,同时利用cox回归模型筛选与疾病进展相关的基因,根据皮尔森相关系数将相关系数高的干性基因作为关键干性基因。随后对不同样本间的关键干性基因表达量进行组间均一化后对基因表达特征进行研究,选用合适算法将NMIBC患者分为干性不同的亚型,研究各亚型间疾病进展快慢的关系。探索不同组织干性与年龄、性别和各种不同分子分型等的相关性;利用Reactome数据库对关键干性基因功能及其富集通路进行研究并根据基因分布空间位置寻找调控的关键干性基因的转录因子,计算各转录因子的干性相关系数和其所调控的关键干性基因数目筛选出潜在的与组织干性相关性高的多个转录因子;研究转录因子与被其调控基因间表达的关系,将共表达一致性高的转录因子作为可能与组织干性相关的潜在因素。研究结果:本研究对检测的43204个基因干性进行计算,筛选出187个与干性相关的基因,其中有7个基因与干性的相关系数小于0,分别为MMP2,TFEB,APCDD1,PCDHGC,LTBP4,SYNPO和PDEA;其中与干性和疾病进展显著正相关(卡方检验,P<0.001)且相关系数大于0的138个基因定义为关键干性基因。根据这些关键干性基因在NMIBC中的表达量基于曼哈顿距离算法和Ward.D2聚类方法可将其分为干性高组和干性低组两种亚型,在不同的两种亚型中,关键干性基因表达在组内的均一性较好;随访时间均大于60月的生存分析结果显示干性高组患者疾病进展较干性低组疾病进展更快(卡方检验,P<0.001);Ta期肿瘤组织主要聚集在干性低的亚型,T2-4期则主要聚集在干性高的组织(卡方检验,P<0.001);低级别的肿瘤组织更易出现在干性低组,而高级别正好与之相反(卡方检验,P<0.001);乳头状的生长方式在干性低组常见,实体型的则好发于干性高组(卡方检验,P<0.001);Lund分型中基因不稳定型与干性高组在分子分型方面具有很高的重合度,而基底样A型与未筛选型则主要聚集在干性低组中(卡方检验,P<0.001);12基因特征中,高危组主要与干性高组重合(76.51%),而干性低组中高危组仅占37.00%,低危组占63%(卡方检验,P<0.001);具有CIS特征的主要汇集在干性高组,而非CIS正好与之相反(卡方检验,P<0.001);CLASS分型中,管腔型原位癌样主要分布在干性高组,管腔样和早期基底样则主要聚集在干性底组(卡方检验,P"
134,视频用户QoE的感知和预测,"视频流媒体已经成为目前因特网的主要应用,为了给视频用户提供更好的网络服务,运营商有必要了解并保障用户的观看体验。用户的观看体验,即体验质量QoE(Quality of Experience),是用户对视频服务质量的主观感受。如果没有终端用户的配合,运营商无法得知用户的主观QoE,即便是应用层的客观QoE参数(视频帧率、码率、初始时延、卡顿等),运营商也难以获得。因此,运营商通常采用监测网络流量来推测视频用户的QoE。然而,目前这种解决方法也因HTTP自适应流媒体传输技术(HAS)的使用和加密视频流的逐渐普及,而面临新的挑战。HAS机制中码率自适应请求算法(ABR)能够自适应网络变化,而选取匹配网络状况的视频块进行传输,从而会模糊掉网络流量波动所带来的用户QoE信息。这样会使得运营商无法判断用户QoE得以改善的原因是ABR自适应的结果还是网络状况改善带来的结果。与此同时,目前越来越多的HAS视频流开始采用加密传输服务,使得运营商无法继续采用深度解析包的方法进行网络流量分析。本文工作注意到视频客户端ABR算法所造成的流量特征模糊的问题,同时也注意到ABR算法是以视频块为基本单位进行自适应码率调整。因此,与传统方法以“包”为颗粒度不同,本论文提出以视频“块”为颗粒度进行视频流量分析和挖掘,进而评估用户QoE。具体地,论文包括以下两个部分工作。第一部分工作,研究了如何从加密的HAS视频流量中重建视频块序列。本文首先基于网络测量的方法对HAS加密视频流的传输特性进行分析,然后基于视频流量传输模式的分析结果,提出一种HAS视频流的块序列重建算法。实验结果表明,采用我们算法从网络流量中重建的视频块序列,均方根误差不高于0.132,具有很好的拟合精确度。由于播放器的演播状态直接影响到用户QoE,播放器的演播状态又可以采用应用层客观的QoE参数来表征,因此第二部分工作基于视频块序列的特征来推断播放器的演播状态。具体地,论文工作首先为此提出一种新的应用层客观QoE度量指标:缓冲区综合状态,用来表征播放器的演播状态。接着,利用HAS客户端与服务器之间的双向视频流量,重建视频块序列,使用时间序列数据挖掘技术,建立了网络流量特征与新的应用层客观QoE指标之间的预测模型,用于实时估测视频的演播状态,从而实现视频用户QoE的跨层感知和预测。实验结果表明,采用我们的方法能够获得较好的实时预测效果。"
135,基于机器学习的室内射频指纹定位技术研究,"近年来,无线局域网络的广泛部署和移动智能设备的迅速普及为无线室内定位提供了便利条件。在众多纷纭的定位技术中,射频指纹技术由于具有精度高、成本低的优点,吸引了越来越多的研究人员关注。但与此同时,室内电磁环境复杂,加之随机因素过多,无疑会给射频指纹定位的精度带来影响,因此针对此问题,本文将机器学习引入射频指纹定位中,尝试提出新的算法以提高定位精度。在传统的射频指纹定位系统中,由于射频信号受到多种因素的影响,尤其是在真实的大规模复杂室内环境中,指纹信号和地理位置之间对应的的数学模型难以构建。针对该问题,我们提出了一种基于七层神经网络的射频指纹方法。该方法先通过将原始的指纹信号输入到四层的深度神经网络中挖掘出射频指纹中的潜在特征,然后再将该潜在特征输入到一个三层的神经网络中进行定位。由于挖掘的特征对于不同的物理空间具有更好的适应性,该射频指纹定位系统在UJIINDOORLOC公开数据集上可以实现99%的定位准确率。其次,实验结果表明,当选取的测试集采集时间比训练集晚四个月时,定位准确度下降到72%,这说明,在基于机器学习的射频指纹定位中,随着时间的推移,定位精度快速下降。通过分析以RSSI为代表的射频指纹随时间变化的统计特征,发现在不同时间段内,射频信号具有不同的数据分布,导致了定位系统的时效性较差。针对该问题,我们提出了两种基于迁移机器学习的射频指纹算法。一种是基于特征的迁移机器学习,该方法是通过挖掘离线指纹数据和在线指纹数据的潜在指纹特征来实现精确定位,因而具有更好的时间适应性。另一种则基于样本的迁移机器学习,通过引入小部分新的指纹数据来改变原始指纹数据分布,从而提高定位精度。在UJIINDOORLOC公开数据集上的测试结果表明,当选取的测试集采集时间比训练集晚四个月时,基于特征迁移机器学习的射频指纹定位系统,可以实现82%的定位准确率;基于样本迁移机器学习的射频指纹定位系统,可以实现90%的定位准确率,均比直接训练的模型的准确率有了显著的提高。"
136,大规模基站网络流量模式挖掘和预测,"随着4G无线技术普及,无线基站流量持续增加。作为承载无线网络的基础设施,分析基站流量的静态和动态特征、挖掘基站流量演变模式对无线基站的运营方案制定、参数合理配置至关重要。目前已有的测量和模型工作,聚焦在短时间粒度(如分钟、小时、天)的流量变化规律,至今尚缺少一个长时间尺度(如一年)的城市基站流量变化的准确测量和模式挖掘结果。为此,本文基于一个中国大型无线网络运营商在一个大型城市的基站网络的流量测量数据,对超过7千个基站、以月度为单位、持续一年的基站流量的静态和动态特征进行了观察与测量,并对基站流量的时间变化模式进行了聚类、分析和预测。本文贡献如下:(1)提出了一种新的基站流量演变模式的聚类方法。该方法基于基站月度总流量值在一年内的排序序列进行聚类。在我们数据集上的实验结果表明:该方法对短时间序列(不存在周期性)的波形涨跌特点有很好的描述,能得到比传统方法更容易理解的聚类结果。(2)基于该聚类方法,我们对运营商的7千多个基站的流量演变模式进行了大规模聚类分析,获得了 6种典型基站流量演变模式,最主要的一种流量模式涵盖了 38.6%的基站,特点为流量总体呈上升趋势,11月份达到高峰,次年2月降到低谷。其它模式包括:“春节返乡”、“双11”电商购物模式等。结合该城市的特点,我们对各模式的形成原因做出了解释,这些发现为运营商掌握其基站的流量演变的规律提供了有益的指导。(3)提出了一种基于基站地理位置和地址语义信息的基站模式预测方法,对一个新建基站的流量模式进行预测。因为新建基站的初始信息很少,预测困难,因此我们创新性地将基站语义标签信息引入到基站流量模式预测中。实验结果表明:通过加入基站词向量表征,预测模型的F1-score提升了 5%,其中两种模式的预测准确度较高。本文对大规模实际基站网络流量的分析结果对于网络运营商有重要的实际价值,本文提出的长期流量变化模式模型、聚类算法、和预测算法,具有通用性,能够被应用于类似的各种应用场景,具有重要的理论价值和实际意义。图20幅,表8个,参考文献43篇。"
137,少模光纤模分复用系统非线性均衡技术研究,"在光通信系统中,利用光纤中多个正交的光波导模式作为独立信道进行传输,即模分复用(Mode Division Multiplexing,MDM)技术,可以实现系统容量的成倍增长。少模光纤与多模光纤相比,具有足够强的抗模式耦合能力,且与单模光纤相比系统容量更大,因此使用少模光纤是一种很好的折中方法。但在实际传输过程中,非线性效应、色散和衰减等链路损伤以及制造工艺缺陷破坏模式间正交性造成的模式耦合都会降低系统的传输性能,其中光纤链路中的线性损伤和模式耦合可以通过数字信号处理及线性均衡算法进行有效补偿,因此,如何进行非线性损伤补偿,实现非线性均衡是少模光纤模分复用系统的研究重点。本文围绕少模光纤模分复用系统的非线性均衡问题展开研究,首先介绍了少模光纤中的链路损伤,之后依据传输理论搭建了模分复用系统传输模型,引入多种非线性均衡算法来补偿非线性损伤从而恢复信号。本文的主要工作包括以下几个方面:(1)分析了少模光纤中的链路损伤,包括非线性效应、线性效应和模式耦合。针对2×2 MDM系统,将广义多模非线性薛定谔方程(Generalized Multi-Mode Nonlinear Schrodinger Equation,GMM-NLSE)进行简化得到弱耦合NLSE。设计可解复用的弱耦合少模光纤,以此为基础搭建2×2 MDM系统模型。(2)对模分复用系统的非线性均衡技术进行了研究。首先介绍并仿真了经典的反向传输(Back Propagation,BP)算法。针对该算法计算复杂度高导致信号实时性差的问题,本文采用基于机器学习的最邻近(Nearest Neighbor)算法,包括K最邻近(K-Nearest Neighbor,KNN)算法和基于权重的KNN(Distance-Weighted KNN,DW-KNN)算法以及人工神经网络(Artificial Neural Network,ANN)算法进行非线性均衡,详细介绍了这三种算法的基本原理和算法流程。(3)对基于包含LP001模和LP11模两个模式的2×2模分复用系统进行仿真,从误码率、均衡后星座图以及非线性容忍度三方面对进算法性能行对比。仿真验证,在2×2 56Gb/s 16QAM模分复用系统中,KNN、DW-KNN和ANN算法均能达到降低误码率的目的,ANN算法Q因子较DW-KNN算法提升0.5dB,较KNN算法提升0.8dB。当光信噪比(Optical Signal Noise Ratio,OSNR)为 18dB,误码率为10-3时,ANN算法非线性容忍度较DW-KNN高1.4dB,较KNN算法高2.1dB。因此,ANN算法的非线性均衡性能更好。"
138,基于TDM-PON和C-RAN架构的休眠感知资源分配研究,"日益增长的数据业务以及大量智能设备的应用促进了无线通信的演进,但同时也带来了许多新的挑战。而无源光网络(Passive Optical Network,PON)与云无线接入网(Cloud Radio Access Network,C-RAN)的融合网络结合了光网络与无线网络的优势,能够满足日益增长的移动无线网络需求。C-RAN将传统基站中的基带处理单元(Baseband Unit,BBU)和前端无线发射单元(Remote Radio Head,RRH)从地理位置上分隔开,并通过PON将这两个部分相连接,构成一种分布式RRH与集中式BBU相结合的架构。因此,本文从C-RAN整体架构出发,并以提高网络能效为目的,对其中资源管理以及设备休眠相关问题进行研究,并提出相应的策略。首先,本文对PON以及C-RAN网络进行了详细介绍,包括研究背景、网络结构、技术特点等;然后从内容缓存、协作资源管理、网络节能等方面介绍了其研究热点。最后通过介绍C-RAN网络前传资源管理策略引出本文工作重心。其次,本文提出一种负载聚合的C-RAN节能机制。考虑用户服务质量(Quality of Service,QoS)以及网络资源,建立网络能耗的优化模型。基于BBU与RRH两者的独立性,将原始问题分解为两个子问题即BBU资源分配问题与RRH资源分配问题,并采用启发式算法解决网络资源分配问题。结果表明,所提机制在保证用户QoS的同时,有效地提高了网络资源利用率与网络能效。再次,本文提出一种基于机器学习的混合供电C-RAN的资源分配机制。根据网络收集能量的特性,建立回归分析模型,利用这种模型,计算出不同时刻能量到达率。基于无线信道的时变性和能量到达率,通过强化学习使得网络与环境进行交互学习,实现网络资源的优化分配。结果表明,所提机制保证了用户QoS,提高了网络资源利用率与网络能效。最后,对本篇文章的主要工作内容和创新点进行总结,并对后续的研究工作提出目标。"
139,基于词典与改进信息增益的微博情感分析,"随着计算机与网络技术的发展日新月异,社交媒体与网络平台已然成为人们获取、发布、共享、传播信息的载体。这些信息对于政府与企业进行网络舆情监控、电子商务等都具有重要的社会意义与商业价值。本文以新浪微博平台中的人们所发布的语料信息为研究对象,重点研究分析了情感分析任务中基于情感词典与基于机器学习的两种方法。主要研究内容如下:1.针对现有的情感词典由于对网络新词的涵盖率较低而无法应用于微博领域的情感分析问题,本文搜集了当前现有的一些基础情感词典,网络情感词典与表情符号库,并在去重后构造了基础综合情感词典。针对SO-PMI算法中共现窗口大小与语料库规模对算法效果产生不利影响等问题,本文提出了使用距离互信息与古德-图灵平滑方法来对SO-PMI算法进行优化,并利用改进后的SO-PMI算法来扩展基于微博领域的情感词典。通过实验对比综合基础情感词典、基于传统SO-PMI算法扩展的情感词典、基于拉普拉斯平滑的SO-PMI算法扩展的情感词典以及本文所构建的中文微博综合情感词典,使用本文所构建的情感词典进行情感分析的效果皆好于其他三种情感词典。2.研究分析了常用的特征选择算法并着重研究了信息增益算法。针对传统信息增益算法中没有考虑特征项在类内与类间分布情况以及没有平衡正相关特征项与负相关特征项的比例等的问题,提出了类间集中度与类内分散度并以此来提高特征项对类别的区分效果。借鉴卡方统计量的方法求两者最大值以此来将类间集中度与类内分散度的计算应用于整个语料库,并引入比例因子来降低负相关特征项所带来的不利影响,提高了正相关特征项的比例。通过实验对比基于传统信息增益算法与本文所改进的信息增益算法,利用本文所改进的信息增益算法在微博情感分析中的效果好于传统信息增益算法。3.本文将整合成的中文微博综合情感词典与改进的信息增益算法结合来对特征选择这个过程进行优化。该方法结合了两者的优点,对特征项的降维效果明显好于两者单独使用的情况。图[16]表[10]参[53]。"
140,基于电子产品领域商品评论的情感分析方法研究和实现,"在产品评论中,现有的情感分类是根据用户评论时自主设置的星级数来分为好评差评。但是每个用户对于星级的把控不同,造成产品评论情感分类存在较大的误差。产品评论是潜在消费者在进行购买产品时,进行决策的一个重要参考内容。当分类与评论星级不匹配时,常常会引起潜在消费者对产品本身的质疑。除此之外,产品评论是商家制定销售战略,提升产品性能和服务质量不可缺少的信息来源。但是一个产品的评论可能达到上万条,人工去分析将耗费大量的人力物力,因此通过计算机对其进行分析就显得至关重要。本文以从京东商城爬取的12000条手机评论作为电子产品的代表来对产品评论进行情感分类,并针对短文本中关键词提取的准确率较低和Tri-Train算法中初始分类器的差异性不稳定以及隐性置信度筛选引入噪声影响分类器性能的问题,对现有的关键词提取技术和Tri-Train算法进行改进。主要工作如下:(1)电子产品文本评论内容偏向口语化和网络化,新词使用比较频繁。但是结巴分词识别新词的能力有限,使结巴分词的结果不是很准确。针对这一问题,本文在从京东爬取的语料数据上,使用互信息和左右熵,获取新词语,并将这些新词加入结巴词库,再用新的结巴词库进行分词,以提高分词结果的准确性。(2)针对现有关键词提取效果不佳的问题,本文分别对基于TF-IDF提取关键词的方法和基于情感词典提取关键词的方法的优缺点进行分析,提出了利用基于情感词典提取关键词和基于TF-IDF提取关键词相结合的方法进行关键词提取,并利用Word2vec进行文本特征表示的特征选择方案。该方案有效的利用了基于情感词典提取关键词和基于TF-IDF提取关键词的优点,形成了优势互补。为了提高利用情感词典提取关键词的效果,本文利用现有的手机评论文本语料构建手机评论领域的领域词典。经实验证明,该方法较好提高了分类器的准确率和F1值,改善了其分类性能。(3)Tri-Train是一种常用的半监督算法。该算法一定程度上可以利用未标记数据提高分类器的分类性能。但是该方法目前存在两个问题:一是构造的三个分类器的差异性不稳定且不够大。二利用隐式置信度筛选代替显示置信度筛选,会引入噪声数据,一定程度上降低分类器的性能。针对问题一,本文利用三种差异性能较大的算法代替原算法中只使用一种监督算法的方法,分别对有放回采样后的数据进行训练来构造三个分类器,以增大其差异性。针对问题二,本文利用文本相似性对噪声数据进行滤除。经验证,该方法在一定程度上可以提高Tri-Train算法的分类性能。"
141,面向网络评论短文本的情感分析研究与实现,"随着互联网的快速发展,微博、贴吧、抖音等各种社交型网络平台对人们生活的影响越来越大,大量的网络用户在各种平台上会产生海量的信息,分析这些海量信息所隐藏的情感极性具有极大的商业和社会价值,因此对社交型网络平台的文本进行情感分析,已经成为当今的热点。在网络评论文本中,网络新词层出不穷,由于网络评论开放性的特点,表达相似语义的评论在不同背景语境下,情感极性都有可能发生改变。针对以上问题,本文提出了一套综合的网络评论文本的情感分析方法。本文具体的工作如下所示:(1)针对网络新词问题,本文建立了一套新词自动发现及情感识别系统。在新词发现的方面采用传统的基于统计的新词发现方法,该方法可以自动发现新词省去了大量的人工标注工作,在新词情感识别方面提出了一种基于新词上下文、情感词典基准词及新词分布式语义相似度的综合比较方法,来判断新词情感极性,最后自动建立了网络新词情感词典。(2)在网络评论背景多样性问题上,本文提出了一种基于背景增强的情感分类模型,该模型对评论进行情感分类的时候,将评论的相关新闻或帖子作为其背景,并将其作为评论文本情感分析的特征,加入到情感分类模型中,从而提高了模型在不同背景下情感分析判断能力。在实验中将加入背景的混合特征模型与传统的情感分类模型进行对比准确率、召回率、F值三个指标均有所提高。"
142,推荐系统中动态推荐算法研究,"互联网技术的飞速发展使人类进入了大数据时代,“信息过载”成为亟待解决的问题之一。推荐系统作为一种解决“信息过载”问题的技术已被广泛应用于互联网应用。传统基于统计学习和深度学习的推荐技术通过定期更新模型来应对物品流行度的变化和候选集的更新,不能及时根据物品流行度的变化而更新推荐优先级,新物品加入时也不能迅速地完成冷启动。动态推荐算法(如多臂老虎机Bandit)能够一定程度上解决上述问题,但准确度有待提高,这是因为:1)它们的模型能力有限,以Contextual-Bandit类算法中的LinUCB为例,LinUCB算法采用线性模型拟合用户对特定物品的兴趣,表征能力有限,由此限制了算法性能;2)它们没有考虑用户特征分布的异质性,推荐效果不佳。针对以上两个问题,本文选定新闻推荐作为动态推荐算法的具体场景,基于一个大规模、真实的在线新闻系统的用户行为日志,测量了该新闻推荐系统中新闻流行度的动态变化、新闻上下架的模式,观察了用户特征分布。基于观察结果,提出了两个算法来分别改进上述问题,并基于实际数据对算法进行了评估。主要贡献如下:(1)针对现有模型表达能力欠佳的问题,本文提出使用神经网络代替常规数学模型来建模用户和期望回报之间的关系,解决了神经网络在线更新和损失函数选择的两个难题。具体来说,为解决神经网络的在线训练在样本不均衡的情况下难以收敛的问题,我们提出了用户反馈敏感的训练方法:根据不同的用户反馈采用不同迭代次数。该方法相对于传统的训练方式取得了近40%的增益。其次,本文将推荐问题建模为回归、分类和策略梯度问题,系统地尝试了分类、回归和策略梯度三种损失函数。通过实验发现:在合理的配置下,采用策略梯度的损失函数,我们的算法相较于LinUCB算法取得了 2.1%的性能增益,证明了算法的性能。(2)针对传统Contextual-Bandit算法没有考虑用户特征异质性的问题,本文创新性地提出了一种对用户特征敏感的分级推荐算法。该算法能够动态判别用户所属的类别,然后根据用户的类别,动态匹配合适的推荐器,来获得最佳的推荐性能。实验表明,该算法相较于传统的LinUCB推荐算法取得了 3.3%的性能增益,证明了算法的性能。本文在Contextual-Bandit动态推荐算法上的研究,进一步提高了当前主流动态推荐算法的性能,具有一定的理论价值和应用价值。"
143,基于扰动的网络流量数据隐私保护方法研究,"随着互联网技术、大容量存储技术的迅猛发展以及数据共享范围的逐步扩大,数据的网络化与透明化成为不可阻挡的大趋势,用户在网络中产生的数据信息被频繁地用于数据挖掘,导致隐私泄露等网络安全问题层出不穷。因此,大数据环境下的网络数据隐私保护成为当前重要的研究方向,力求实现数据的可用性和隐私的安全性之间的平衡。基于对网络流量数据挖掘技术和隐私保护模型的研究,针对网络流量敏感属性泄露问题,本文提出了基于扰动的网络流量数据隐私保护方法,并且从数据可用性和安全性两个方面进行衡量。本文的研究内容主要分为以下三个方面:(1)针对网络流量数据含有的冗余属性对分类挖掘效果的影响,提出了一种基于信息熵的网络流量属性特征选择算法,提取了与应用类别相关度高且属性之间冗余性小的特征子集。实验证明筛选出的特征子集能够准确地表达原始数据的特征并可有效地应用于分类。(2)为了防止网络流量属性中的敏感数据泄露,结合属性的概率分布,设计了一种基于扰动的网络流量数据隐私保护算法。该算法在生成与原始属性独立同分布的数据基础上,进一步采用序映射来恢复属性之间的对应关系,以实现在保护数据安全性的同时提高数据的可用性。(3)从数据的可用性和安全性两方面验证基于扰动的网络流量数据隐私保护算法的有效性。实验证明,扰动后的数据与原始数据相比,仍然能够保持较高的分类准确率,即保持了数据的可用性;同时数据之间的相似性较差,能够较好地隐藏原始数据,即数据的安全性得到了有效保障。综上,本文针对网络流量分类方法进行了分析,设计了基于信息熵的特征子集选择算法,并重点提出了针对网络流量数据的隐私保护算法,最后在真实网络流量数据集进行了仿真验证。实验证明,使用该算法处理后的网络流量数据能够兼顾数据的安全性和可用性,缓解了已有算法在两者性能中的矛盾,可以有效地解决网络流量在数据挖掘过程中的隐私泄露问题。"
144,标识网络中基于多维属性的服务管理机制研究与实现,"一体化标识网络旨在解决传统互联网在移动性、安全性、可管可控性等方面的问题,同时可融合多种业务,为用户提供普适服务。目前,标识网络在服务方面主要研究服务标识、连接标识以及标识间映射等问题。在服务管理方面,由于现有服务描述方法粒度较粗,标识网络难以达到较好的服务管理效果。针对此问题并结合实际区域管控项目,本文在标识网络中提出一种基于多维属性的服务管理机制。该机制通过挖掘服务多维度的属性信息对其进行细粒度描述,为每项服务生成对应的服务标签,用于网络管理者制定策略以对网络进行管控。该机制的提出使得网络管理者可以对服务进行多维度区分,避免区域管控时对正常服务造成影响,对未来网络的安全性研究具有积极意义。论文研究与实现工作如下:首先,对标识网络体系架构和现有网络服务属性进行研究,选择具有代表性的属性作为服务管理机制的核心。考虑到区域专网的实际使用情况,本文的服务研究对象分为传统网络的已发布服务和在标识网络中发布的新增服务。已发布服务选择服务内容、服务地区、服务域名、服务时间、服务热度作为研究属性,新增服务在以上属性基础上增加了服务规模、服务行业、服务协议等属性。其次,基于上述属性,设计并实现服务管理方案。在挖掘已发布服务属性时,采用文本分析技术提取服务文本内容主题,并将其作为服务内容属性信息;通过调用应用程序编程接口获取已发布服务地区、时间、热度属性信息;通过分析服务对应的统一资源定位符得到服务域名属性信息。获取新增服务属性时,设计一种客户端-服务器模式的信息采集系统。服务发布者在客户端的用户界面按规定格式提交服务属性信息到服务管理层,服务管理层接收提交信息并向客户端返回提交结果。两种服务属性信息均结构化存储在数据库中,用于生成包含多维属性信息的服务标签。最后,在搭建的标识网络环境中,对基于多维属性的服务管理机制进行测试,验证了已发布服务和新增服务属性获取、存储功能和服务标签生成功能,还对已发布服务内容采集和属性获取方案进行了性能分析。本文结论如下:标识网络中基于多维属性的服务管理机制具有可行性,所设计方案能够分别获取并存储已发布服务和新增服务的多维属性信息,基于该属性信息可生成服务标签用于网络管理。此外,相比于其它方案,本文方案的已发布服务内容采集效率和属性获取的精确率、召回率及F1值均较高。"
145,基于知识追踪的智能导学算法设计,"智能教育系统能够建立以学习者为中心的教育环境,提升学生学习效率,已被列入国家新一代人工智能发展规划。智能导学系统能够通过学生习题作答情况追踪学生各个知识概念的掌握程度,自适应地给学生推荐习题以加强学生对知识的掌握水平,提高学生的学习效率,对其的研究具有重要的理论价值和实际意义。目前,制约智能导学系统性能的瓶颈有两个:1)知识追踪模型不能准确追踪学生各个知识概念的掌握程度,预测学生习题作答结果。原因在于当前的知识追踪模型没有设计合理的模型结构来有效使用题目的概念特征(知识点标签),导致模型性能不佳。2)习题推荐算法的设计依靠人工制定规则,效率不高,而基于启发式的习题推荐算法,只关注学生短期内的成绩提升,难以找到让学生能力稳步提升的习题。针对上述问题,本文基于一个大规模、真实的在线教育系统的学生答题数据,测量观察了与学生作答结果相关的有效特征,设计了特征的有效表征方式和新的利用知识概念结构设计的知识追踪模型,创造性地将深度强化学习应用于习题推荐中,设计了习题推荐策略算法,并基于实际数据进行了评估。具体贡献如下:(1)为了提升知识追踪模型的性能,创新性地将题目概念的等级结构引入神经元网络的设计,设计了新的深度学习知识追踪模型,改进了模型追踪性能。首先,针对题目的多级知识概念特征,基于动态键值记忆网络DKVMN,提出了概念敏感的知识追踪模型DKVMN-CA。实验证明:该模型的神经网络结构能够有效地利用题目的多级知识概念特征进行知识追踪,明显提升了知识追踪模型的性能,相比DKVMN模型,AUC值提升了 1.2%。其次,修改模型,在模型中加入题目难度、关卡特征、做题时间等特征,进一步提升了知识追踪模型的性能,AUC值提升了 1.9%。(2)以改进的知识追踪模型DKVMN-CA为学生模拟器,创新性地将深度强化学习引入习题推荐算法中,优化习题推荐策略。该习题推荐策略能够根据学生作答历史,考虑学生的长期成绩提升进行习题推荐,以最大化学生在完成题目推荐序列后的各个知识概念掌握程度。实验证明:该算法相对于启发式习题推荐策略,能够找到使学生成绩提高的题目以持续地提升学生知识水平,解决了启发式推荐算法经过一定次数的习题推荐后,再无法找到合适题目以提升学生的成绩的问题。据我们所知,这是目前首次将深度增强学习应用于数学习题推荐,为未来的习题推荐方法提供了新的参考。图17幅,表2个,参考文献46篇。"
146,基于机器学习算法的精神分裂症听觉稳态诱发脑电研究,"目的:基于精神分裂症听觉稳态诱发脑电,运用支持向量机和深度信念网络算法建立诊断预测模型,比较模型在精神分裂症中的诊断价值。方法:使用Mipower脑电信号采集器采集14名精神分裂症患者和15名正常对照者的听觉稳态诱发脑电信号。从时域和频域两个方面分析脑电信号,提取脑电信号在能量、相位、信噪比和微分熵的特征。应用基于线性核、径向基函数核、sigmoid核的支持向量机和深度信念网络算法构建预测模型,通过准确率、灵敏度、特异度和ROC曲线下的面积(Areas Underthe ROC curve,AUC)比较四种模型的分类性能。结果:深度信念网络模型的准确率、灵敏度、特异度、AUC分别为85.6%,88.33%,75.50%,0.88,而基于线性核、径向基函数核、sigmoid核的支持向量机模型准确率分别是74.6%,78.5%,72.8%,灵敏度分别是 88.30%,92.98%,79.53%,特异度分别是 39.39%,56.57%,42.42%,AUC分别是0.74,0.86,0.71。深度信念网络模型分类性能明显高于三种支持向量机模型。结论:上述结果证明了深度信念网络可以学习到数据的本质特征,分类能力远好于支持向量机。基于深度信念网络算法的诊断模型可以有效协助临床医生对于精神分裂症患者的诊断,达到早期发现疾病的效果。"
147,基于半监督学习的医嘱辅助决策方法研究,"随着互联网信息存储与数据处理技术的迅速发展,医院的信息化建设得到了有效的技术支持,其中对医院患者的就医记录由从前的病案室纸张记录,也转变为构建电子病历系统的数字化方式。电子病历数据作为患者就诊过程中信息的重要载体,为智能辅助医疗决策研究提供了数据支持。但由于电子病历数据存在形式多样,如表格、数字与自由文本等,非结构化文本数据中包含大量专业化描述等特点,也产生了对电子病历数据预处理、数据的标注均耗时耗力等问题。为了更加有效挖掘电子病历的潜在价值,利用已有临床诊疗经验,很多学者结合机器学习技术对医疗辅助决策方法进行研究。针对以上电子病历数据特点以及研究过程中的问题,结合在标注样本较少实际问题中机器学习方法的应用,本文拟采用半监督学习方法,在结合少量标注数据的基础上,从患者相似群组和医嘱方案选择两个方面出发,对医嘱辅助决策方法进行研究。主要包含以下三部分内容:(1)数据预处理研究。本文针对电子病历多类型数据进行了归一化与标准化映射,同时考虑其自由文本比重较大、内容具有领域专业性特点,在文本分词时结合构建领域词典辅助分词,并通过对比实验验证了该方法对医疗专业术语识别的有效性。(2)患者相似组类别划分研究。本文综合考虑了患者基础与诊疗信息进行患者属性体系构建,同时基于多指标考量对患者间相似程度估计,构建成对约束集合作为监督信息用以指导半监督聚类学习模型,优化患者相似组类别划分效果。(3)医嘱辅助决策方法研究。本文提出在医嘱列表选择过程中,首先将医嘱按诊疗方案类别进行初步归类,综合考虑患者相似性以及医嘱类别对医嘱选择的影响,根据患者相似度、不同诊疗方案的重要性,以患者、诊疗方案两个维度更加细粒度的分析计算每条医嘱的总体相关性情况。本文通过多组对比实验,证明基于半监督学习的患者相似组划分优于单纯的无监督聚类算法,综合考虑电子病历多维度属性信息与患者成对约束信息,并将诊疗方案类别辅助患者与医嘱的关系考量,能够提升医嘱辅助决策模型的效果。本研究所提出的基于半监督学习的聚类方法能够更好的适用于医疗数据的研究,在此基础之上所构建的基于患者相似度、医嘱与患者相关性分析的医嘱辅助决策思想可以帮助更好的利用已有数据资源辅助临床医护人员诊疗,同时采用适当的诊疗方法,提高开具医嘱的效率和准确性。"
148,基于Twitter社交网络数据的流感预测应用研究,"随着全球气候变化,流感的发病人数大幅增加,严重流感的死亡率接近50%,因此对流感暴发进行预测研究愈发重要。现有研究中,已将社交媒体用于地震灾害检测和趋势预测,本研究将机器学习算法和大数据方法结合应用于流感暴发的预测。通过文本分类模型实现Twitter社交网络数据预处理,利用时间序列预测模型对澳大利亚昆士兰州的流感疫情进行趋势预测。本文主要研究内容如下:1)应用XGBoost算法实现流感数据文本分类,解决了传统机器学习算法对于文本分类效果较差的问题。为了验证该方法的性能,以Twitter数据为研究对象,首先通过关键词过滤技术提取疑似流感数据,然后采用XGBoost算法对疑似流感数据进行分类预测,并与传统的朴素贝叶斯算法进行对比。实验结果表明,XGBoost算法对Twitter数据的分类结果正确率为90%,明显优于朴素贝叶斯算法的分类结果,可用于Twitter数据中流感发病频率及发病时间的提取。2)提出基于Twitter数据和温度数据的多元时间序列预测模型,解决了一元时间序列预测模型时效性差、预测结果相对误差较高的问题。首先通过2015年第1周至2017年第32周的流感历史数据,建立ARIMA一元时间序列模型预测未来四周流感发病数;再将Twitter数据与温度数据作为输入变量,建立ARIMAX多元时间序列预测模型预测未来四周流感发病数。结果表明ARIMAX模型的平均相对误差为3.30%,低于ARIMA模型,ARIMAX模型预测效果更佳,可用于实时预测流感发病数。3)针对流感监测可视化界面较为单一的问题,建立了一种流感监测预测综合可视化系统。首先通过调用百度地图API展示了流感热力图,再使用D3可视化技术结合地理位置数据展示了流感分布地图与流感历史曲线图、未来趋势图等。该系统通过时间及空间关系网络结构解释流感暴发的地理位置分布和趋势发展,可以直观地引导流感疫情的分析和预防。"
149,无线传感网络中的数据融合研究,"近年来,传感器网络中的数据量呈指数增长,数据融合技术是减少数据传输量和节约节点资源的主要手段。考虑现有传感器节点有限的计算能力和能量资源,本研究分别对时间序列数据和多媒体数据两种不同数据结构设计数据融合模型。具体工作内容如下:1.针对现有传感器数据融合未考虑时空冗余导致通信成本较高的问题,研究一种基于聚类和预测算法的数据融合模型,保证无线传感器网络的数据精度并节约节点能源。在训练阶段,利用历史数据训练一个在线循环极限学习机,并对节点进行聚类,基于实际地理距离得到节点强连接。在数据融合过程中,终端用户和传感器节点使用相同的预测机制预测未来的传感数据,保证数据序列同步更新。最后,通过基于节点强连接的协作传输模式,减少预测失败时的冗余传输。仿真结果表明:给出的数据融合模型在有效预测传感器数据的同时,降低了通信成本。2.针对多媒体数据聚类算法未考虑到传输过程中数据受损导致的聚类精度低与数据不完整问题,研究一种优化变分自编码网络,用于学习缺失数据的特征,并利用高阶张量模糊C均值算法提高不完整数据的聚类性能。初始化过程中,优化基于变分自编码器的特征提取模型,学习并提取不完整数据的低维特征。为了捕获低维数据特征空间中的非线性相关性,采用张量距离作为距离度量,对低维特征进行基于高阶张量的模糊C均值算法聚类。最后,解码器输出最终聚类结果和利用低维特征重建的图像数据。仿真结果表明:给出的模型不仅能有效提取不完整数据的特征,而且能提高聚类性能和完成数据重建。"
150,空分复用弹性光网络中资源分配策略研究,"近年来,在云、物联网和超带宽等应用驱动下,视频业务及物联网终端规模迅猛发展,光纤通信的信道带宽消耗量呈指数式快速增长,采用单芯光纤的弹性光网络传输容量已经逼近其物理极限,对光网络容量提出了更高的要求。为了实现更高的通信传输容量,基于多芯光纤的空分复用弹性光网络应运而生。然而,空分复用弹性光网络在具有容量大、资源划分粒度精细等优点的同时,也带来了频谱碎片、芯间串扰等突出问题。为此,论文提出了空分复用弹性光网络中串扰感知频谱碎片避免策略和阻塞感知频谱碎片整理策略。为了在资源分配前采取适当的策略预防频谱碎片的产生,同时降低芯间串扰,提出了一种串扰感知频谱碎片避免策略。该策略首先对每条纤芯上的频谱资源进行分区,通过交替使用每个分区中的资源减少芯间串扰。为了使有限的资源能够容纳更多的业务,将资源分配过程转化为二维矩形packing填充问题。为保证填充更加高效,在业务填充之前,首先利用Elman神经网络对业务相关属性进行预测,然后根据预测结果确定业务填充优先级,最后根据确定的优先级依次将业务填充到二维资源池中,从而减少了频谱碎片,提高了资源利用率。仿真结果表明,在降低芯间串扰的同时,所提策略可以获得较高的资源利用率和和较低的阻塞率。尽管频谱碎片避免策略能够通过对网络资源合理地规划,在一定程度上减小碎片的产生。但在网络运行一定时间后,由于业务的频繁拆建难免会产生新的频谱碎片,为此进一步提出一种阻塞感知频谱碎片整理策略。首先,预测网络中未来一段时间的业务量,并结合上一时间段的阻塞率和业务量计算出下一时间段的阻塞率,然后比较预测的阻塞率和预设阻塞率阈值的大小完成是否触发频谱碎片整理操作的判决。为了在碎片整理过程中充分考虑空分复用弹性光网络中的多纤芯特性,将纤芯分为3类,并对不同纤芯上的业务采用自适应的碎片整理操作。仿真结果表明,所提策略在充分考虑多纤芯特性的同时,降低了网络阻塞率且具有较低的碎片整理时延。"
151,基于机器学习分类算法和数据库的频谱感知,"频谱感知作为认知无线电关键技术和研究内容之一,对于解决日趋紧张的频谱需求及高效频谱利用之间的矛盾具有重要的研究意义。本文针对传统频谱感知在实际环境中性能不足和实现条件的困难,研究探索将数据库和机器学习的方法应用到频谱感知技术领域,具体内容包括:在实际认知无线电网络环境中,由于多径损耗、无线传播环境复杂等现实因素,使得信号传播衰减严重,导致次级用户(Secondary User,SU)对授权频谱状态的辨识精确度不够,难以有效支撑SU对于授权用户(Primary User,PU)活动状态的准确判断,再加上阴影效应问题等,更容易造成SU对PU的干扰等严重问题。针对这些问题,基于机器学习方法,提出一种混合AdaBoost算法以实现合作频谱感知。该算法利用SVM作为第一个子分类器,同时以单层决策树作为其余的子分类器。各个子分类器的权重由各自的分类性能决定,分类性能越好的分类器权重越高,最后根据各个分类器的权重形成最终的分类器,在整体上有效增强分类器性能,提高频谱检测概率,更好地保护PU不受SU干扰。针对传统频谱检测算法性能有限以及SU为了保证检测效果,导致实现成本过高等问题,提出一种基于地理指纹数据库的频谱感知方案。该方案利用基站参考信号到达SU的时间估值建立无线指纹数据库。SU在检测PU信号前,周期性地上报当前位置的指纹信息,网络端利用指纹匹配机制锁定SU所在的地理位置,并据此读取该处对应的PU授权频段可用状态,以控制SU的进一步操作,即接入PU频段、检测PU频段或不接入PU频段,此感知方案在保证感知性能的基础上,可大大简化SU终端的感知过程,减少大量不必要的感知操作,显著降低SU在感知过程中的能耗。此外,还引入机器学习和联合网格预测,进一步提高该感知机制的感知性能。"
152,基于深度学习的电商产品评论情感分析研究,"电子商务平台上商品评论文本呈现爆炸性增长,利用自然语言处理和机器学习等技术自动、高效地对电商平台的文本进行情感分析具有十分重要的意义。目前主流的情感分析方法包括基于规则的方法、基于机器学习的方法和基于深度学习的方法。随着大数据技术的发展以及语言形式的多样化,深度学习已经成为自然语言处理领域的研究热点,并在情感分析领域取得重大突破,因此基于深度学习的情感分析方法被深入研究。主要研究内容如下:1.针对现有跨领域情感分类方法中文本表示特征忽略了重要单词的情感信息,且在迁移过程中存在负迁移的问题,提出一种基于注意力机制的卷积-双向长短期记忆(AC-BiLSTM)模型的知识迁移方法。首先,利用低维连续的词向量对文本进行向量化表示;其次,采用卷积操作获取局部上下文特征之后,通过双向长短期记忆网络充分考虑特征之间的长期依赖关系;然后,通过引入注意力机制考虑不同词汇对文本的贡献程度,同时为了避免迁移过程中出现负迁移现象,在目标函数中引入正则项约束;最后,将在源领域产品评论训练得到的模型参数迁移到目标领域产品评论中,并在少量目标领域有标注数据上进行微调。实验结果表明,AC-BiLSTM模型可以有效地提高跨领域情感分类性能。2.针对传统深度记忆网络进行方面级情感分析忽略词序信息和上下文依赖信息的问题,提出一种基于卷积-双向最小门单元记忆网络(CNN-BiMGU-MemNet)的方面级情感分析方法。首先,将上下文用Word2Vec词向量模型表示,把高维原数据映射成低维连续的词向量;然后,将词向量输入到卷积记忆网络和双向最小门单元记忆网络中分别获取文本中单词的顺序信息和上下文长期依赖信息;最后,结合卷积记忆网络和双向最小门单元记忆网络的输出向量表示,并将其输入到softmax层进行情感分类。实验结果表明,CNN-BiMGU-MemNet模型在准确率和宏平均F1值上均优于其他对比模型,能够有效地提高分类性能。"
153,基于深度学习的多模型融合文本情感算法研究,"随着互联网技术的飞速发展,网络评论空间中产生了大量的信息,这些信息主要由微博评论、商品评论、社交评论等组成。而评论往往带有比较强烈的情感色彩,因此对网络评论进行情感分析具有重大的社会价值和现实意义。本论文对情感分析领域的现状以及深度学习理论进行了深入地研究,分析了该领域存在的一些问题,从提升情感分析预测的准确率出发,首先针对单一深度学习模型存在的不足,提出了一种多模型融合文本情感的算法;其次,针对词向量中缺乏情感信息的问题,提出了一种情感词向量的构建方法。本论文具体的工作内容和创新点如下:(1)为了解决单一的深度学习模型难以在获取高度抽象文本特征的同时学习句子的序列特征的问题,本论文提出了一种多模型融合的深度学习算法,首先利用卷积神经网络的并行特征提取能力对数据进行特征提取。接着结合双向长短时记忆神经网络抽取句子序列特征的优点,将提取的特征送入双向长短时记忆神经网络模型进行训练,同时使用全局均值池化的方法减小模型的复杂程度。本论文在亚马逊评论数据集和SSTb数据集中进行对比实验,实验结果表明,与传统算法相比,本论文提出的算法能够有效地提升情感分析的准确性。(2)为了使词向量具有情感信息,本论文构建了情感词向量训练框架,通过改进Skip-Gram词向量训练模型,将情感信息融入词向量训练模型中,从而构建情感词向量。对于情感分析任务而言,情感词向量可以丰富文本的情感表达,提高情感分析的准确性。实验采用亚马逊评论数据集进行情感词向量的训练,而后利用SSTb数据集对不同的词向量进行对比。首先,分别计算亚马逊数据集中正负样本中的高频词,分别挑选出现词频最多的且具有强烈情感色彩的词作为正向情感词组和负向情感词组;接着通过SO-PMI算法计算剩余词情感倾向,同时使用TF-IDF对单词情感进行加权;最后使用改进的Skip-Gram模型对词向量模型进行训练,从而得到情感词向量的表达。实验证明,该方法可以有效区分诸如“good”和“bad”这一类上下文结构相近但情感相反的词,从而进一步提升情感分析任务的效果。"
154,面向概念漂移和不均衡数据流的分类算法研究,"近年来随着大数据和云计算的迅速发展,在互联网等方面源源不断地产生大量的数据流。学者们为了获取并分析这些领域的数据流中隐含的大量的有用信息,为此对数据流挖掘领域展开了深入研究。然而,静态数据与数据流并不完全相同,数据流的特点是快速性、连续性、多变性、无限性等。特点的不同决定了数据流挖掘算法并不能完全沿用传统的数据挖掘算法。不仅如此,数据流中会产生概念漂移现象即数据的分布会随着时间的变化而随之变化,这一现象无形中对数据流挖掘也造成了巨大的难度。与静态数据相同的是,数据流中也存在类不均衡现象,这些都是流挖掘过程中不得不面对和迫切需要解决的重点和难点问题。因此,本文主要围绕以上问题,对数据流中的概念漂移现象和类不均衡问题展开深入研究,其主要的工作内容包括:针对数据流中概念漂移问题,本章介绍了基于数据分布的概念漂移检测算法,主要分为概念漂移检测模块和概念重现检测模块。该算法不仅能处理数据流中的概念漂移现象,还可以检测到重现概念问题。首先利用概念漂移检测算法检测出数据流中的概念漂移问题,然后在概念重现模块中解决重现漂移的问题。最后在数据流机器学习实验分析平台MOA上对该算法进行大量验证与分析。结果表明该算法具有低误报、低漏报和低检测时延,不仅有效地提高了分类的性能指标,还发现了概念漂移现象中的重现概念问题。针对存在类不均衡问题的数据流中概念漂移的分类问题,本章提出一种基于集成学习的不均衡数据流分类算法。该算法首先处理数据流中类不均衡问题,先采用上采样技术,再采用下采样技术,增加正样本,减少负样本,减少过拟合,均衡数据流。其次采用集成方式周期更新分类器权值应对概念漂移。动态更新分类器权值时,不仅考虑了分类器对当前数据块的分类正确率,还引入了分类器对当前数据块的错误分类的代价。在分类器的淘汰策略中,计算分类器在集成分类器中的贡献值,根据贡献值替换分类器。最后在数据流机器学习实验分析平台MOA上对本文算法进行大量验证与分析,结果表明该算法具有较高的分类正确率。"
155,基于集成学习的偏标记学习算法研究,"随着大数据时代的迅猛发展,运用机器学习的手段对大数据进行处理和分析已经成为一种公认有效的最佳方法。但是在各个领域中,呈现出数据的海量特征、数据标记的特异性,使得传统的机器学习方法无法对其进行数据处理。偏标记学习是处理数据标记特异性的弱监督学习框架产物,该框架与传统的弱监督学习框架不同之处在于示例的标记并非明确且单一,而是淹没于众多候选标记集中,这样的示例在现实中非常普遍,同时偏标记学习框架本质上也是对传统弱监督学习的一种扩展。偏标记学习是一种特殊的多类分类问题,任务是通过训练集得到一个多类分类器,而多类分类问题可以转换分解为构建多个二分类问题来解决,但是却极少考虑数据集中类别数目不均衡问题造成的分类器分类性能差、鲁棒性差;偏标记学习算法研究较少,很多现有机器学习算法通过改造后可运用于处理偏标记学习问题。基于此问题,本文主要做了一下几方面内容。1、本文提出一种KD树均衡训练集的集成偏标记学习方法,利用KD树的快速检索,使得划分的正负类样本数趋于均衡,再利用集成学习中的Stacking方法进行训练,对未知样本采用投票求和方式的方式进行预测。在公开UCI数据集和真实数据集上进行实验,实验表明提出的KD树均衡训练集的集成算法有较好的表现力。2、本文提出基于示例特征最大差异的ECOC算法,从ECOC框架的本质特性出发,寻找出特征差异最大的样本构成数据集,训练差异大的基分类器;ECOC的二值编码矩阵则是通过特征差异较大的样本候选标记或运算作为列编码来构造,最后对样本的预测通过各分类器的数据与编码矩阵进行比对从而实现预测。在公开UCI数据集和真实数据集上进行实验,实验表明提出的基于示例特征最大差异的ECOC算法有较好的表现力。"
156,智能电网中虚假数据注入攻击检测研究,"智能电网作为一个基于能量的网络物理系统,它将传统的物理电力传输与信息通信技术相结合,在提高能源利用效率的同时,也面临网络安全的威胁。虚假数据注入(False Data Injection,FDI)攻击作为智能电网中的一种网络攻击,其能够绕过数据采集与控制系统(Supervisory Control and Data Acquisition,SCADA)的不良数据检测技术,使状态估计结果出现偏差,导致SCADA做出错误的决策,从而影响到智能电网的安全。因此,研究FDI攻击特点,进而制定有效的防范措施对保证智能电网的安全和稳定运行具有非常重要的意义。于是,本文围绕FDI攻击的检测展开研究,具体内容如下:1.基于ELM的OCON的FDI攻击检测框架:在该框架中,为了能够有效地检测出多个总线节点同时存在FDI攻击,并识别受到攻击的总线,OCON中状态识别层的子网采用基于one-against-all的ELM算法(Extreme Learning Machine,ELM),以便对虚假数据和正常数据进行有效地分类。而全局层则根据状态识别层的结果,制定自适应的阈值识别FDI攻击发生的总线节点。最后,为了提高系统的恢复性,提出了基于电力数据空间相关性的预测恢复策略,使虚假数据恢复正常。利用美国纽约独立系统运营商的负载数据,在IEEE14总线测试系统上,对提出的ELM\based OCON的FDI攻击检测框架进行了仿真验证。结果表明:提出的检测框架不但能够以较高的检测准确率有效地检测和定位多个FDI攻击的总线节点,同时能够有效地恢复虚假数据。2.基于一种先预测后分类的FDI攻击检测框架:在该框架中,首先在预测阶段采用基于条件受限玻尔兹曼机(Conditional Restricted Boltzmann Machine,CRBM)的ELM。由于ELM的输入权重和偏置是随机设定的,利用CRBM训练ELM的权重和偏置参数可提高ELM对时序数据的预测准确率。然后在分类阶段采用基于小波的卷积神经网络(Wavelet-based Convolution Neural Network,Wavelet-based CNN),小波多分辨率分析和CNN的卷积层及池化层都具有特征提取的功能,通过分析发现小波多分辨率分析中的滤波和下采样分别与CNN的卷积层和池化层具有相同的原理。由于CNN卷积层的初始卷积核是随机设定的,利用小波函数的高通和低通滤波器作为CNN卷积核的初值,可以减小训练复杂度,提高分类准确率。最后,利用预测数据与实际数据的残差对Wavelet-based CNN进行训练,来检测FDI攻击。分别在IEEE14和IEEE118总线测试系统上对提出的一种先预测后分类的FDI攻击检测框架进行了验证,并在分类阶段,将Wavelet-based CNN与CNN进行对比。结果表明:相比于基于传统CNN的方法,Wavelet-based CNN的FDI攻击检测方法,对于较小的虚假数据供给量具有更高的检测准确率,同时在含有噪声的情况下,该方法具有一定的鲁棒性。"
157,基于机器视觉的羽毛球发球违例检测系统设计与实现,"羽毛球是我国传统体育项目,拥有广大受众。由于羽毛球判罚体制的主观性,经常出现运动员与裁判就某一判罚发生争论的现象。赛场上也使用一些信息化设备辅助判罚,但这类设备仅用于判断球体是否出界,并没有实现对发球过程的违例判决。随着人工智能技术的发展,一些以往不能解决的问题可借助人工智能技术逐步得到解决,本文拟用人工智能领域中的机器视觉技术来解决羽毛球发球过手的判决问题。羽毛球发球有两个特点:一是发球动作幅度小,导致动作检测不易实现;二是发球时间不确定,致使无法获悉发球时刻。本文采用机器视觉技术设计了一种发球过手违例判断方法,先用自适应增强变种算法(Gentle Adaboost,GAB)训练分类模型,完成对目标物体(羽毛球和球拍)的检测;结合检测区域,提取球心坐标作为目标点,对检测到的球拍部分构筑轮廓作为目标区域,再定义两者位置关系,根据目标点与目标区域的相对位置变化关系提取判决关键帧;最后由图像角度表示方法,建立状态判别模型,将判决关键帧中的球拍状态作为输入,输出结果量化为角度值,实现对是否发球过手的判决。系统采用模块化架构模式,在实现的过程中,着重解决三个问题:一是训练目标分类模型;二是如何根据目标点与目标区域的位置关系选取判决关键帧;三是根据过手违例状态建立判别模型,将目标区域轮廓量化为正负角度值。系统实现后,经测试表明,本文所提方法能成功实现对发球过手违例的判决,且所训练分类模型平均召回率分别为90.7%和89.1%,对违例状态的识别率为77%。本系统对人工智能技术应用到羽毛球赛场进行了尝试,为今后类似应用提供了参考价值。"
158,基于骨骼点的人体运动识别系统的设计与实现,"当前时代是人工智能高速发展的时代,人机交互技术也随着人工智能技术的发展,已经进入白热化阶段,而动作捕捉技术作为人与计算机自然的、多模态的交互技术的一个重要分支,在近几年发展迅速。本文结合惯性传感器,设计并实现了一种基于骨骼点姿态信息对人体运动进行识别的系统。该系统通过采集位于人体主要骨骼点的传感器数据,通过多蓝牙配对传输的方式传输到上位机,利用支持向量机对人体运动进行分类,实现对一般人体运动的识别。该系统轻巧便捷,使用方便,对环境适应性强,且成本较低。在本文中,首先调研了国内外研究学者对人体运动分析与识别技术的相关工作,然后,介绍本系统在设计过程中涉及到的相关知识和基础理论,并由此设计实现了一种基于人体骨骼点姿态信息的运动识别系统,针对不同功能模块的设计需求和特点进行了详细的研究。首先,针对本系统多节点、实时性、动态性、识别方便的特点,根据姿态传感器解算理论、校准技术、传感器组网技术等,确定了以MPU6050和蓝牙无线传输为主体的硬件实验平台。其次,根据人体运动姿态特点,在低成本的前提下,结合实验环境,设计了合理的数据采集方案,并使用该方案采集人体运动姿态信息,构建人体骨骼点姿态信息的运动数据集。最后,对采集的骨骼点姿态信息进行分析,通过支持向量机等机器学习分类算法对运动姿态进行分类训练,并对不同分类算法进行比较。整个系统从模块化、轻便化出发,有机地整合各关键技术,设计了基于骨骼点姿态信息的人体运动识别系统。实验结果证明,该系统采集节点的姿态数据能够通过多蓝牙直连的方式进行采集,能够保证实时性。利用该系统采集不同测试者的运动信息组建的人体运动数据集,可以通过多种分类方式进行分类,且不同的动作识别准确率都较高,能够满足设计系统设计需求。在基于1762组数据的测试中,利用支持向量机进行分类训练,人体运动识别准确率达到88%,其中静态动作分类准确率能达到90%,动态动作分类准确率能达到80%。该系统轻便简洁,使用简单,克服了有线采集方式的空间局限性,可应用于康复治疗、运动训练、虚拟交互、特效制作等领域。"
159,基于MCP惩罚的AdaBoost集成剪枝技术的研究,"AdaBoost是一种有力的集成学习方法,能将一系列低预测精度的弱学习器结合成为一个高预测精度的强学习器。然而,与其它集成学习方法相似,AdaBoost也需要使用大量的基学习器来产生最终的预测结果,因此当数据维度较高或集成规模较大时,构建AdaBoost集成模型对计算机的内存空间产生了挑战。回归模型中的特征选择方法能够显著地降低数据维度,并且在集成学习中也已证明了其有效性。通过对集成模型进行剪枝,我们能够产生一个规模更小,精度却更高的集成模型。在本文中,我们提出使用最小最大凹度惩罚函数(MCP)对AdaBoost模型进行集成剪枝,在简化集成模型的同时改进预测精度。本文首先使用MCP惩罚的逻辑回归对高维数据进行变量筛选处理,再使用AdaBoost集成方法进行建模,并以实验说明对高维数据使用MCP进行变量筛选不仅不会损害后续AdaBoost模型的性能,反而能提高其预测精度;在建立AdaBoost集成模型后,取其基学习器的预测结果作为逻辑回归中的预测矩阵,从而使用带有MCP惩罚项的逻辑回归对集成模型进行剪枝,MCP的剪枝效果将与LASSO与SCAD惩罚函数的效果作比较。在真实数据集上进行的实验结果表明,在有噪声数据集中,使用MCP函数进行集成剪枝得到良好的效果:在本文涉及到的所有六个有噪声数据集中,使用MCP剪枝后的模型均比原模型有更高的预测精度,同时其平均集成规模大幅降低至原模型的5%至20%,其总体效果也优于使用另外两个惩罚函数剪枝的模型。通过实验,本文得出以下结论:在使用AdaBoost进行高维数据的分类预测时,使用带MCP惩罚项的逻辑回归模型能够在缩小集成规模的同时提高模型表现。"
160,支持向量回归在高频金融时间序列中的应用研究,"对于高频时间序列问题的研究一直是数据科学家研究的热点,伴随着机器学习算法的不断发展,为其研究找到了新的突破口,在众多类型的高频时间序列中,高频金融时间序列数据的预测更是预测难度最大的时间序列之一。以神经网络为代表的深度学习虽然可以达到很高的精度,但其要求数据量大,运算速度慢,对计算机硬件要求高,容易陷入局部极值等一系列内在缺陷使得其无法完全适应高频金融时间序列数据这类样本数量有限且存在大量噪声的数据类型。单一的机器学习模型难以胜任高频金融时间序列的研究,而国内外的研究重点主要集中在单个模型的改进和参数优化上面,显然,对于高频金融时间序列的研究还有待进一步加强和充实。针对高频金融时间序列的非线性、非平稳、低信噪比等固有特点,为提高高频金融时间序列数据的预测精度,本文在改进进化算法参数寻优的基础上,分别针对高频金融时间序列数据非平稳和低信噪比的特点以及单步预测和多步滚动预测模式的不同,构建了基于K均值聚类的支持向量回归模型用于单步预测,以及基于小波降噪和K均值聚类的支持向量回归模型用于多步滚动预测。实证结果表明,两种模型在单步与多步滚动预测性能上较支持向量回归模型均具有明显地提升。第一部分,阐述了国内外对于高频时间序列的研究现状。从传统的数理统计模型到机器学习,从神经网络到支持向量机的转变,对比了支持向量机和神经网络的优劣,并重点介绍了从支持向量机到支持向量回归的推导过程。第二部分,针对高频金融时间序列非线性的特点,选用支持向量回归模型进行预测。介绍了模型参数对模型精度的影响,并在进化算法的基础上做出了改进,利用改进进化算法进行参数寻优后的模型对高频金融时间序列数据进行预测。实证结果表明,基于进化算法的支持向量回归模型比基于传统参数寻优算法的支持向量回归模型具有更高的预测精度,其收敛速度更快,且在一定程度上可以扩大初始值的选择范围,对于无先验经验的参数寻优更加高效、友好。第三部分,针对高频金融时间序列中支持向量回归模型无法克服的数据非平稳问题,通过在改进进化算法参数寻优的基础上构建基于K均值聚类的支持向量回归模型来解决。一方面利用改进进化算法为模型寻得的最优参数提高模型的预测精度;另一方面是利用了无监督学习算法对数据进行聚类,在理论上能够将时间序列的异常波动和正常波动区分开来,使分类后的数据趋于平稳,从而提升模型的预测精度。实证结果表明,在同样以改进进化算法进行参数寻优的条件下,基于K均值聚类的支持向量回归模型可以在单步预测时提供比传统支持向量回归模型更好的预测精度。第四部分,针对高频金融时间序列数据低信噪比的特点以及滚动预测模式的特点,在基于改进进化算法和K均值聚类的支持向量回归模型的基础上加入了小波降噪算法。该模型在降低了预测难度的同时也不失实际意义,并出于实际应用的考虑,进行多步滚动预测,通过滑动时间窗口检验模型性能。实证结果表明,在同样以改进进化算法进行参数寻优的条件下,基于小波降噪和K均值聚类的支持向量回归模型在统计学意义上表现出比基于小波降噪的支持向量回归模型更好的预测精度和稳定性。最后,就前文的所述进行总结,提出本文的不足之处,就未来可能的研究方向进行了分析。"
161,基于多源数据的用户体验分析研究,"随着科技的发展,软件产业正前所未有地改变着人们的衣食住行。面对激烈的市场竞争,用户体验被越来越多的软件公司所重视。各类软件公司通过挖掘用户信息以改进各自的软件,进而提高用户体验,使软件更具竞争力。精准分析用户体验有助于提升用户体验质量并延长软件寿命。用户体验分析包括评估用户体验以及在评估后获得的准确的用户体验上进行分析。精准评估用户体验可以获得真实的用户体验并为后续用户体验分析提供可靠性保障。对用户体验进行分析可以获取与用户体验相关的用户特性和软件因素,进而定位用户群体并通过改进相应的软件因素以提升用户体验,最终获得软件利益最大化。此外,由于用户体验领域中的研究样本较少,在小样本上分析得到的结果准确性得不到保证。因此,本文的目的是准确地评估用户体验,获取充分的用户体验与用户特性以及软件因素三者之间的关系,并且提出用于用户体验小样本的高准确率可解释模型。针对现有主观评估方法或客观评估方法对于用户体验评估具有片面性的问题,本文基于主客观相结合的评估方法对其进行改进以评估用户体验。首先,本文设计了包含用户体验以及用户特性的问卷以获取主观用户体验,然后分析用户体验与用户特性以及软件因素之间的关系,最后利用心率变异性验证以上关系。现有的分析用户体验与相关因素之间关系的方法有统计学习方法和机器学习方法。然而,现有的基于统计学习方法的研究和机器学习模型只得出了部分用户体验与用户特性以及软件因素之间的关系且现有的用于分析用户体验小样本的机器学习模型是不足够准确的。为了充分的分析用户体验关系,本文选用具有可解释性的RIPPER算法。此外,本文改进RIPPER算法中的FOIL信息增益公式以解决该算法在特定值样本缺失时的问题,并利用改进的RIPPER算法分析用户体验与用户特性以及软件因素三者之间的关系。现有的提升小样本分析准确率的方法分为直接作用于小样本上的机器学习方法和利用辅助数据的迁移学习方法。本文首次将迁移学习中的TrAdaBoost算法引入用户体验领域以提升小样本分析的准确率。为了在提高小样本分析准确率的同时解释用户体验与用户特性以及软件因素三者之间的关系,本文基于可解释的迁移决策树提出Transferin Cart(TrCart)算法。此外,本文首次将基于实例的迁移学习算法TrAdaBoost和基于模型的迁移学习算法TrCart结合,得到在用户体验领域小样本上准确率高的且具有可解释性的模型Transfer Adaboost in Cart(TrAdaboostCart)算法。"
162,方差正则化的交叉验证模型选择方法研究,"统计机器学习的主要目的是依据训练数据集建立预测模型,用以描述给定数据的统计规律,并通过已有的模型对新数据进行预测。其中,模型的建立和选择是关键。所谓模型选择,指的是通过估计已建立的不同模型的性能,从而选出其中最好的模型。在传统的统计回归分析中,模型选择指的是变量的选择,从上世纪60年代开始它就一直是统计学中的重点研究问题。分类情形的模型选择主要包括两个方面:一方面是分类器(分类算法)的选择,对于给定的某个数据集,基于某个性能度量指标选择多个分类器中性能最好的一个;另一方面是特征(变量)的选择,选择一个最优性能的特征组合。现有文献中,回归和分类模型的选择常常是直接基于泛化误差的估计来进行,如基于广泛使用的泛化误差的交叉验证估计方法来进行模型的选择。然而,注意到基于这些估计的方法在选择模型过程中只使用了估计本身(均值的信息)而没有考虑估计的方差的信息,这样较大的方差将导致模型大的波动,趋向于选择较复杂的模型,从而导致模型较低的泛化性能。因此,本文将方差作为正则化项添加到传统的回归和分类模型选择准则中,提出了一种新的交叉验证框架下的方差正则化的模型选择准则。首先,通过模拟实验验证了方差正则化项在模型选择中的重要性。接着,大量模拟和真实数据上的实验验证了无论是对于回归还是分类任务,提出的方差正则化模型选择准则相比传统模型选择方法都能选择到具有更小泛化误差的更简单模型。进一步,从理论上证明了提出的方差正则化的交叉验证模型选择准则具有选择的一致性,即在有限样本下选择的最优模型在样本趋于无穷时同样成立,保证了模型选择的稳定性。"
163,机器学习技术在声波逆散射问题中的应用,"逆散射问题广泛应用于雷达遥感、石油勘探和生物医学成像等领域,相关数值求解方法的研究具有重要的学术意义和实用价值。本文从数值计算角度研究一类典型的逆散射问题:利用声波远场数据反演不可穿透散射体的形状。这类问题的求解常常面临非线性性和不适定性等挑战。为克服上述困难,国内外众多学者对波动方程的散射理论进行了广泛深入的研究,提出并发展了一大批有效的计算方法,如优化方法、迭代算法和采样类方法等。这些算法从本质上都依赖于散射问题的物理机制与数学模型,可将其归结为模型驱动的计算方法。近年来,以深度学习为代表的机器学习技术在自然语言处理、计算机视觉等领域得到了越来越多的关注。区别于传统的模型驱动算法,深度学习属于数据驱动的新型计算技术,并且已经在图像处理和地球物理等领域的逆问题求解中取得了巨大成功。然而,据我们所知,对于散射体的形状重构这一经典的逆散射问题,目前尚未有关于深度学习方面的研究。因此,本文的目的是研究深度学习技术在这类逆散射问题上的应用,通过计算实例探讨其可行性,同时对比分析深度学习技术与传统算法的重构效果。具体地,本文内容安排如下:第一章概述了一些与本研究课题相关的背景知识,包括课题的研究背景和意义、国内外在该方向的研究历史和发展现状、以及本文的具体研究的模型等。第二章首先给出了求解正逆散射问题所需预备知识的简要介绍,主要包括位势理论、求解正问题的积分方程方法以及求解逆散射问题的经典数值方法等内容。然后简要回顾了深度学习相关的基本内容,主要包括人工神经网络的基本原理、反向传播算法的具体实现、以及神经网络中的参数选取策略等问题。第三章和第四章是本文的主要研究结果。第三章考虑了深度学习算法中最关键的组成部分,即训练数据集和神经网络结构。首先提出了两种训练数据集的构造方法,随后讨论了算法实现的框架,最后通过数值算例验证了所提出的训练集是简便易行且行之有效的。第四章通过大量数值仿真实验,主要包括全部数据和数据缺失情形的反演结果、以及深度学习算法与Newton迭代法的重构效果对比等,说明深度学习算法是求解逆散射问题的一种有效技术。特别地,针对单入射波所对应部分观测数据的情形,深度学习算法在反演精度上具有超越模型驱动算法的优势。"
164,基于决策森林的蛋白质二级结构预测算法研究,"蛋白质是人类机体的重要组成并且机体内几乎所有的活动都需要具有特定功能的蛋白质参与。蛋白质的空间结构决定其主要功能。因此对于蛋白质结构的研究有助于更好的了解它的功能。但并不能直接通过模拟蛋白质的折叠过程来了解它的空间结构。然而蛋白质是由氨基酸序列组成的,因此,通过氨基酸序列来预测蛋白质的二级结构进而了解它的三维构象便成为了一种常用的方法。在大数据、云计算和人工智能快速发展的时代背景下,采用机器学习的方法对蛋白质的二级结构进行预测已经成为生物信息学中的一个研究热点。基于决策树森林模型及机器学习技术,本文深入研究了蛋白质的八类二级结构预测,主要研究内容如下:针对蛋白质的八类二级结构预测问题,提出了一种基于梯度提升的决策森林预测算法。该算法基于氨基酸序列的PSSM谱特征采用交叉熵损失函数的二阶泰勒近似作为优化目标,以决策树确定的映射函数作为优化参数,通过贪婪地在特征值上选取最佳分裂点来构造决策树。此外,为了防止过拟合,进一步在目标函数中引入了_2L正则化项,以便控制模型的复杂度。在标准的CB513蛋白质二级结构评估数据集上,本文提出的算法达到了64.89%的_8Q准确率。针对梯度提升决策森林算法运行速度慢的缺点,本文基于直方图思想提出了一种快速梯度提升的预测模型。该模型通过直方图的方法将样本特征离散化,对于大量的样本数据采用单边梯度技术对数据进行采样,并采用特征绑定技术对多维特征进行降维,实现了样本数量和特征两个维度的并行。通过大量的实验对影响模型性能的指标进行分析,实验结果表明,基于本文所提出的快速梯度提升算法对蛋白质的二级结构进行预测,在测试集上的_8Q准确率达到了66.35%。另外,在同样的数据集上,相对于其他算法来比较,本文所提出的算法运行速度非常快,时间复杂度很小。"
165,机器学习方法在临近降雨预报中的应用研究,"传统的临近降雨预报方法主要是利用数值方法、外推技术和概念模型等来预报。这些临近降雨预测的方法考虑的因素众多、模型的构造过于复杂且预测步骤多、累计误差较大。近年来,机器学习方法在气象预报中得到广泛应用。本文利用雷达降雨产品,引入支持向量机(SVM)、梯度提升树(GBDT)、极限提升树(XGBoost)三种机器学习方法应用于雷达降雨产品的临近降雨预报,使用TS评分、命中率POD、空报率FAR和漏报率MAR四个定性检验指标来综合比较各机器学习方法在临近降雨预报中的预报效果,还将XGBoost方法和PPLK方法相结合进行短临定量降水预报,使用了相关检验指标进行了评估。下面是本文的主要研究结果和结论:(1)基于SVM方法的临近降雨预报研究。建立了雷达降雨产品-晴雨预报的非线性支持向量机训练模型,达到了在考虑较少影响因子的基础上对雷达降雨产品进行临近降雨预报,在降雨分布比较集中的雷达降雨产品中降雨的命中率都较高,实验验证了该方法的可行性。(2)基于GBDT方法的临近降雨预报研究。建立了雷达降雨产品-晴雨预报的梯度提升模型,实现了从数据驱动的角度对雷达降雨产品进行临近降雨预报,在各类雷达降雨产品中的临近预报都较好,实验验证了该方法具有一定的可行性。(3)基于XGBoost方法的临近降雨预报研究。建立了雷达降雨产品-晴雨预报的XGBoost模型,实验表明其对不同雷达降雨产品的临近降雨预报能力都很强,TS评分和命中率都在较高的水平,实验验证了该方法的有效性及准确性。(4)将XGBoost方法临近降雨预报的结果和SVM方法、RF方法及GBDT方法临近降雨预报的结果进行了比较,实验结果表明XGBoost方法的预报性能明显优于其他三种预报方法,预报精度是最高的。(5)将XGBoost方法和PPLK方法相结合对雷达降雨产品进行短临定量降水预报,实验验证了XGBoost方法与PPLK方法相结合的预报性能会高于PPLK方法,也再次证实了XGBoost方法在降雨预报中的实用性及高效性。"
166,基于Sentinel-1的南极冰盖冻融探测方法研究,"极地冰盖的冻融与全球气候变化、海平面变化、冰架崩解的关系密切,准确观测极地冰盖变化对理解全球变化研究具有重要的科学意义。Sentinel-1 SAR数据结合Google Earth Engine(GEE)遥感大数据云计算平台,为极地观测提供了重要的技术支撑。本文基于GEE平台,利用Sentinel-1 EW SAR数据,以南极半岛的Larsen C冰架及其周边区域为例,开展南极冰盖冻融探测方法的研究。得到的主要结果如下:(1)针对GEE平台提供的Sentinel-1 EW数据中存在的宽度不等,且宽达十几公里的黑边噪声问题,提出基于信息熵+缓冲区结合的方法,有效去除黑边噪声,提高影像信息的有效性。基于Sentinel-1分析融化与冻结的后向散射系数变化特征,以及冰川带后向散射系数特征、空间分布,分析结果与Liu等基于Radarsat-1 SAR的冰川带后向散射系数分析结果一致。(2)本文综合应用GEE平台的随机森林、分类回归树、支持向量机分类方法,选用海量Sentinel-1数据,开展南极冻融信息探测方法实验。实验结果表明:基于分类回归树、支持向量机的探测精度较高,随机森林的精度较低,三种方法在一定程度上均能探测出冰盖冻融信息,但对干雪带和湿雪带有一定程度的混淆。(3)本文首次提出了基于变化检测+决策树的南极冰盖冻融探测方法。在GEE平台上,以冬季6、7、8月份的Sentinel-1数据的中值为基图像,夏季影像与同轨道的基图像做差值的变化检测,确定雪带后向散射系数变化阈值和高程阈值,做阈值分割,实现南极冰盖冻融信息探测。使用该方法探测2015年12月-2016年3月,2016年10月-2017年3月,2017年10月-2018年3月的南极冰盖冻融信息,对探测结果,采用自选样本和自动气象站数据进行精度验证,自选样本验证的平均总体精度为93%,平均Kappa系数为0.90;自动气象站点验证的平均精度为83.86%。并将该方法应用于格林兰岛的冰盖冻融探测,验证精度约为90%。因此,基于变化检测+决策树的南极冰盖冻融探测方法在冰盖冻融探测中具有一定的应用前景。"
167,手性化合物的比旋光度预测及绝对构型自动识别,"手性化合物的绝对构型的实验检测通常是昂贵且耗时的,而比旋光度的理论预测可以辅助解决这一问题。本论文通过机器学习方法进行了对映体绝对构型的自动识别,并定量地预测了手性分子的比旋光度值,具体研究内容如下:1.手性离子液体的绝对构型的自动识别编码手性阳离子结构的PAS描述符与代表非手性阴离子的二进制指示变量相结合构成分子手性描述符。通过相向传播人工神经网络(CPG NN)进行手性离子液体的比旋光度预测。输出层的映射图清楚地显示了PAS描述符具有区分左旋和右旋化合物的能力,并将具有高比旋光度绝对值的化合物分配到特定的区域。此外,CPG网络揭示了含有不同阴离子的离子液体所覆盖化学空间的多样性,并使阳离子、阴离子和比旋光度之间的关系可视化。CPG NN最终定量预测的结果为:测试集的RMSE=22°。基于相同的数据集和手性描述符,CPG NN正确地识别了测试集中大部分对映体的绝对构型。由于PAS描述符属于分类指数,而且在定量预测中,监督的机器学习法往往优于半监督的CPG网络,所以我们又提出了定量的ePAS描述符,并利用多层感知器(MLP),随机森林(RF)和多线性回归(MLR)建立定量预测模型。其中,结果最好的模型为:将PAS和ePAS描述符结合,递交到RF中进行变量选择,然后使用最相关的30维描述符建立RF模型。最终,相应的训练集和测试集的RMSE均在10°~11°之间。所得定量结果明显优于使用PAS描述符的结果。若将RF应用于定性预测,则所得模型能正确地识别测试集中95%对映体的绝对构型。2.手性氟化物的比旋光度预测采用PAS描述符代表44对手性氟化物对映体,建立了定性与定量的比旋光度预测模型。对于定性预测,采用+1和-1代表比旋光度的符号作为CPG网络的输出。训练集中的化合物在映射图上的分布验证了PAS描述符具有区分左旋和右旋氟化物的能力。将测试集的PAS描述符也映射到训练过的CPG NN中,测试集的8对对映体显示在被激活的神经元上并正确分类。对于整个数据集进行leave one-pair out交叉验证,44对中有41对对映体的绝对构型被正确地识别。以上结果表明,建立的定性模型令人满意,可以正确地识别大部分的L-化合物和D-化合物。分别采用PAS,PAS+ePAS和cPAS描述符表示手性氟化物的结构,建立定量模型。由于不相关的变量可能会增加计算的复杂性并导致分类的准确性降低,因此我们基于RF的变量重要性选择描述符,并将其用于定量构效关系研究。其中,由手性氟化物共有的结构特征衍生的cPAS描述符得到了包含11个变量的子集。采用这个子集所建立的RF模型得到了最好的定量预测结果。对于整个数据集的leave one-pair out交叉验证,其结果为R=0.969,RMSE=11.4°。此外,数据集中有30个化合物的比旋光度是在氯仿中测量的,我们使用机器学习的方法预测了这30个化合物的比旋光度,并与文献中量子化学的计算结果进行了对比。结果表明,机器学习法不仅可以快速预测氟化物的比旋光度,同时能够达到量子化学计算的准确度。3.仲醇手性拆分的主产物的绝对构型预测从文献中挑选出了34个仲醇及以它们为反应底物在同一条件下进行手性拆分得到的对映体产物和对映体过量值(ee)。为了预测对映体产物中主产物的绝对构型,分别用+1代表主产物和-1代表次产物。采用PAS描述符描述仲醇对映体,并分别通过CPG网络、多层感知器(MLP)、多元线性回归(MLR)和随机森林(RF)建立定性预测模型。所得结果指出,整个数据集交叉验证的正确率为97%~100%。此外,根据RF、M5和Greedy选择的变量,我们发现轨道的电负性和电荷密度对预测主产物的绝对构型起着重要的作用。"
168,基于深度学习的矿用地磅车牌识别研究,"在煤炭行业中,企业在进行煤炭的运输、存储时需要快速的对煤炭物资进行精确的称重管理,矿用地磅作为一种有效的称重仪器,在煤炭的运销过程中扮演着非常重要的角色。车牌作为车辆的关键性身份信息,为了提高来往运输车辆计量管理的准确性,研究矿用地磅车牌识别具有十分重要的意义。本文对矿用地磅系统中的车牌识别技术进行了深入的研究。通过研究发现,传统车牌识别技术的模块之间依赖性较强,容易导致误差的积累,影响最后的识别结果。而且由于煤炭行业的特殊性,长期运输煤炭资源的车辆容易导致车牌沾染上煤灰、煤泥等污渍,还容易导致车牌磨损,使得车牌字符模糊。如果通过传统的车牌识别方法进行研究,则需要对矿用地磅车牌图像进行复杂的预处理。通过综合分析,本文采用深度学习的方法,将矿用地磅车牌识别分为车牌检测和车牌字符识别两个过程,无需进行车牌的矫正和字符的分割,而且也无需对图像进行复杂预处理操作。经过分析,本文根据矿用地磅车牌的特点对YOLOv3网络进行改进,使其更好的适用于矿用地磅车牌的检测。在车牌字符识别问题上,由于本文的车牌检测算法是将整张含有车牌的图像进行输入,因此在车牌检测阶段,神经网络不但学习到了车牌的特征,也学习到了车牌中字符的特征。据此本文采用迁移学习的思想将训练好的车牌检测网络的主干网络DarkNet-53进行调整改进后用于矿用地磅车牌字符的识别,这样有利于经过较少次数的训练即可准确识别车牌中的字符。为了支持深度学习车牌识别模型的训练,本文采用人工模拟的方法产生了大量的车牌图像。本文通过对矿用地磅车牌识别进行深入研究,提出的矿用地磅车牌识别方法对黑夜以及车牌倾斜等特殊情况具有较好的鲁棒性,相对提高了矿用地磅系统的可靠性和自动化程度,具有一定的理论意义和工程价值。"
169,基于SVM矿井环境无线多模信号的检测识别,"矿井信息化是煤矿安全生产的有效保障,而矿井多个信息子系统往往采用不同的信号模式,形成一体化信息系统必须实现多系统融合,多模信号的检测识别是多系统融合的关键。本文研究矿井环境对信号特征参量的影响,以支持向量机(SVM)作为分类器,建立矿井环境多模信号的分类识别模型,对井下多系统的研究与融合提供理论基础。针对矿井环境对信号的调制识别进行研究,选用模式识别方法,其分为特征参数提取和分类器设计两大部分。针对特征参量提取问题,选取信号的四阶累积量作为特征参量,分析并得出信号在高斯白噪声信道下的二阶矩、四阶矩以及四阶累积量值;在此基础上,进一步分析信号四阶累积量与阴影衰落和小尺度衰落的关系,并得出其经过这两种衰落信道的表达式。针对分类器设计问题,选取SVM作为目标分类器,以信号的四阶累积量作为SVM的输入,分别在二叉树分类器、一对余类分类器、一对一分类器以及决策树分类器情况下,实现对BPSK、OFDM、16QAM和64QAM四种信号的分类识别。仿真结果表明,决策树分类器识别效果较一对多分类器效果差;基于SVM算法下的三种分类器识别性能相当,且在低信噪比下,识别效果不理想。针对普通SVM分类器在低信噪比下低识别率的问题,提出优化SVM分类识别的方法。将数据样本集分为测试数据集和训练数据集,使用粒子群算法和遗传算法对训练数据集中SVM的惩罚因子和核函数进行寻优处理,得到优化的SVM模型,并用此模型对测试集进行测试分类。文中使用Matlab平台环境进行仿真,仿真结果表明,在信噪比为-5dB的三种信道环境下,四种信号的平均识别率均能达到80%以上;在信噪比大于-3dB的三种信道环境下,四种信号的平均识别率均能达到90%以上。"
170,基于信息融合的综采工作面瓦斯浓度预测研究,"在煤矿灾害中,瓦斯灾害往往伴随着严重的事故后果,因此,准确可靠的瓦斯浓度预测能为矿井瓦斯的防治工作提供有效的治理措施和决策依据。本文对陈家山煤矿监测系统连续5天的瓦斯浓度监测数据进行了分析,结合对工作面瓦斯浓度场的模拟形成了综采工作面采煤机区域的瓦斯浓度分布区间预测,本文的主要研究工作如下:通过对瓦斯浓度数据采用传统时间序列预测方法和机器学习算法进行分析,利用统计学方法得到矿井瓦斯浓度监测数据的数学特征,并对瓦斯浓度原始序列进行预处理,使输入数据满足算法的输入要求。应用自回归滑动平均(ARMA)、三次指数平滑(Holt-Winters)和支持向量机回归(SVR)算法分别对每隔10min的8个时间点的瓦斯浓度值进行预测,结果表明:三种算法都能反应瓦斯浓度的变换值,对原始数据的拟合效果较好,并与矿井实测值进行对比,平均绝对误差分别为:0.013%,0.024%和0.008%,并将三种算法进行组合,得到最终的组合模型,预测结果表明,在SVR-ARMA和SVR-Holt-Winters组合模型中,SVR-ARMA的组合效果较好,与实测值对比结果表明,这种组合方式能够为矿井瓦斯预测提供一定的技术支持。通过对综采工作面建立二维几何模型,得到风流场和瓦斯浓度场的分布规律,应用上隅角瓦斯浓度预测值对瓦斯浓度场进行修正,得到了每隔10min的8个时间点的采煤机区域的瓦斯浓度分布区间。通过对数据挖掘和数值模拟得到的瓦斯浓度信息进行融合,预测综采工作面部分区域的瓦斯浓度分布区间,可以为矿井瓦斯预测预警工作提供一定的决策依据。"
171,晋中盆地土壤重金属污染特征分析,"对晋中盆地12个县市土壤进行采样,测定了土壤重金属Pb、Cr、Cd、As和Hg的含量。利用单子污染指数法、潜在生态危害指数法和内梅罗综合污染指数法并结合Arcgis克里金插值法对研究区土壤重金属危害进行生态风险评价,以了解研究区土壤污染现状。采用地统计学方法半方差分析,统计学方法相关分析、主成分分析和聚类分析,机器学习方法随机森林回归模型对研究区重金属进行源分析。(1)五种重金属含量均值都高于山西省背景值含量,其中As和Cr含量均值接近山西省背景值含量,Pb略高于山西土壤背景值、Cd和Hg则存在明显超标,其中Hg和Cd分别有11.5%和60.0%的样点超过国家土壤质量二级标准。(2)单项污染指数结果表明,研究区主要的污染贡献重金属为Hg和Cd,Pb次之,Cr和As最少。综合污染指数评价结果和潜在生态风险评价结果表明,盆地污染程度较为严重,达到中等污染和重度污染的样点占比共达到95%以上;污染空间分析显示:盆地整体污染程度较深,在太原北部阳曲、太原南部清徐、介休地区存在明显的污染突出地区。(3)源解析结果显示:As和Cr主要来源于土壤母质等自然源,Pb、Cd和Hg主要来源于工、农业生产等人为源。随机森林结果显示:影响Cd含量的主要因素重要性排序依次为土壤有机质含量、人均工业产值和土壤全氮含量,说明Cd的积累受工业活动和农业活动中化肥施用的共同影响;影响Hg含量的主要因素重要性排序依次为人均工业产值和污染企业距离,说明Hg主要来源于工业污染活动;影响Pb含量的主要因素重要性排序依次为道路距离、人均工业产值和污染企业距离,说明Pb既受交通运输的影响又受工业活动的影响。"
172,基于卷积神经网络的荒漠化草原草种分类研究,"草原退化已经成为我国主要的生态问题之一。我国的草原主要分布在内蒙古中东部地区,是重要的畜牧业生产基地,也是我国重要的生态保护屏障。近年来,由于人类的活动和自然环境的变化,致使草原环境出现了恶化,荒漠化草原环境频现,草原退化严重。草原退化不仅表现为牧草生产能力的降低,还表现为植被群落结构和地表土壤性质的改变。本课题将以内蒙古荒漠化最为严重的乌兰察布草原为研究对象,具体实验地点为四子王旗地区的荒漠化草原。为实时准确地得到草原的退化信息,采用的是地面高光谱遥感技术。高光谱遥感图像包含的信息多,且能够图谱合一,可以通过高光谱图像分类草种。但是由于高光谱图像数据量大,草原草种的分类难度较高,使用传统的分类方法很难得到好的分类效果。因此,借助强大的深度学习方法解决高光谱图像的分类是本课题主要的研究方向。针对高光谱图像分类的难题,本课题会从深度学习和传统的机器学习两个技术方向解决本课题的问题,具体的工作如下:首先,针对高光谱遥感图像数据量大、波段冗余度大、波段间相关性强的问题,采用基于子空间划分的高光谱图像波段选择方法,对高光谱图像的波段进行选择,减小数据量。利用自动子空间划分法,根据各波段之间的相关系数获得相关系数矩阵,对相关系数进行排序,将全部的波段划分为若干个子空间,然后根据自适应波段选择法进行计算,获得各个子空间内的最大指数波段,最后根据给定的阈值完成波段选择。其次,完成数据的预处理之后,将输入到深度学习和机器学习之中。在深度学习训练过程中,首先将数据进行标准差标准化,然后输入卷积神经网络。通过卷积层的三维卷积核对图像提取特征,然后利用池化层进行降采样,获取特征图的最大值,最后经由全连接层输出结果值。在机器学习训练过程中,采用两种数据输入方式,一种是直接输入图像,另一种是利用灰度共生矩阵提取图像的纹理特征,利用支持向量机(SVM)的方法对数据进行处理分类。最后,通过调整参数得到最优的卷积神经网络和SVM的模型之后,比较两个模型的好坏,从两种模型的分类结果表明,卷积神经网络在图像分类中具有较高的优势。"
173,基于对象分割的卫星图像中物体变化检测与识别算法研究,"遥感变化检测技术是以多源遥感数据为基础,以知识库为辅助对不同时段的目标、现象、过程状态的变化进行探测、识别及分析的计算机图像处理技术,包括多源数据的获取、原始数据预处理、变化信息提取及变化性质确定、变化信息后处理及检测精度评价等内容,其主要目的是通过判断目标是否发生变化,确定发生变化的区域,鉴定变化的类别,评价变化的时间和空间分布模式。随着机器学习以及深度学习的发展,以大数据为核心的深度学习算法已经从传统的自然图像处理,并逐渐扩展到遥感图像处理。本文结合机器学习及深度学习算法,对基于对象分割的卫星图像中物体变化检测和识别的算法开展深入研究,选题具有重要的意义和实用价值。本文将机器学习算法和深度学习算法相结合,以建筑物为研究对象,对卫星影像的建筑物变化检测和识别开展一系列研究,论文主要的研究内容和创新点包括以下几点:(1)对现有的遥感图像数据集进行分析,得到现有的数据集有物体变化检测和识别。针对遥感图像变化检测包含前后时相影像的特征,以前时相为参考,对后时相影像进行图像规定化。针对不同样本库分布不均衡、类间距离过近等问题,提出样本库均衡模块;为了解决样本量不足的问题,提出针对卫星图像的数据扩增算法。(2)针对从高分辨率遥感影像中识别出建筑物变化困难的问题,本文提出了一种基于堆栈降噪自编码器(Stacked Denoising Auto Encoders,SDAE)的建筑物变化检测方法。首先,对于遥感影像匹配误差,对不同时相同一场景图利用尺度不变特征变换(Scale-invariant feature transform,SIFT)算法提取出他们的特征点,进行图像对齐。然后,使用堆栈降噪自编码器提取图像的特征,并采用模糊C均值(Fuzzy C-means,FCM)算法获取发生变化的区域。算法检测效率高,能适应不同源影像的光谱差异。(3)根据建筑物空间特性具有一定规律性的特点,在U-net模型的基础上提出了一种新的模型Widenet(W-net)。并且针对建筑物集群分布和零散分布这两种情况造成的正样本和负样本分布不均衡问题,采用混合损失函数来解决训练数据的不平衡问题。连接两个U-net模型,将其命名为W-net,第一个U-net输出辅助信息,如建筑物拓扑和像素距离。第二个U-net通过将每个像素划分为建筑物或非建筑物来生成建筑物掩码。(4)针对遥感图像覆盖场景大,背景复杂,需要检测算法鲁棒性高,检测效率高,并且克服不同源影像间的光谱差异问题,本文结合上述提出的基于SDAE和FCM的无监督变化检测算法检测出变化区域,然后在变化区域的基础上利用W-net网络进行建筑物识别,结果表明,本文提出针对建筑物的变化检测算法可靠性高,检测速度快。"
174,基于高光谱图像分析的地物变化检测方法研究,"地物目标的变化检测与城市发展、全球变化、土地利用变化等一系列问题息息相关。高光谱变化检测利用多时相同一地表区域的遥感图像,是一种快捷、适宜的技术手段。遥感图像时空分辨率限制高光谱变化检测发展,重点是要解决大尺度、大范围、高层次的变化问题。根据处理手段不同变化检测方法分为直接比较法和分类比较法,根据目标对象不同分为像素级、特征级和目标级的变化检测。基于像素的变化检测是指经过配准的遥感图像像素是否发生变化及哪些类型发生变化。这种基于像素的变化检测准确性很高,但预处理的性能对检测结果影响很大,像素会受到辐射,大气,角度等因素的干扰,可能会产生很多的错误信息,影响变化检测结果。像素级变化检测中阈值的选择起到关键性的作用,即难以确定地物变化类型。本课题以实现像素级高光谱图像地物变化检测为出发点,研究高光谱图像基于像元的一维光谱域数据的预处理即降噪测量方法研究、高光谱地物变化检测算法实现研究等两个方面开展基于高光谱图像的地物变化检测方法的研究,主要研究内容如下:(1)基于小波变换和EMD相结合的降噪方法以及特征增强EMD的地物变化检测方法研究:基于小波变换和EMD的降噪方法克服了传统傅里叶变换易造成信号高频信息缺失的缺点。进行光谱相似性匹配的地物变化检测方法研究,重点是基于相似性匹配和基于距离度量的地物差异特征向量的提取,基于有监督的阈值选择,获得最终的地物变化检测图谱;(2)基于深度学习的高光谱图像空谱结合地物变化检测方法研究:为了充分利用高光谱图像的空间域和光谱域信息,给出一种新的提取像元空间域和光谱域联合特征的深度卷积神经网络;(3)基于迁移学习及生成对抗网络在高光谱地物变换检测方法研究:首先采用直推式迁移学习方法,利用源数据的有标签样本来训练模型的低层参数,利用目标数据训练模型的高层参数和对低层参数进行微调,从而提高高光谱变换检测的精度;在迁移学习的基础上,采用对抗式自动编码器充分利用样本的时序信息来生成多重类型地物变化检测样本,最终利用扩充后的训练样本来训练模型,使检测精度更高。"
175,基于深度卷积神经网络的变转速行星齿轮箱故障诊断方法研究,"行星齿轮箱在众多机电系统中承担着至关重要的传动作用,其一旦发生故障,将有可能带来经济损失与人员伤亡,因此非常有必要对其进行状态监测与故障诊断。然而在变转速行星齿轮箱的智能诊断领域,从振动信号中提取故障特征非常困难,而且智能诊断模型难以对未知转速下的故障进行诊断。本文针对以上问题,首先通过分析行星齿轮箱振动特性,建立了行星轮故障情况下的行星齿轮箱振动模型,结合实测行星齿轮箱振动信号进行分析,验证了变转速下的行星齿轮箱振动信号具有强非平稳性与多频率调制特性。结合行星齿轮箱振动信号特性设计了基于深度卷积神经网络(DCNN)的故障智能诊断方案,该方案能够自动提取故障特征,能够在已知变转速下诊断两种难以分辨的行星轮故障。针对智能诊断模型在未知转速下的跨域诊断问题,本文提出了三种优化策略。首先通过在训练过程中加入少量未知转速的验证样本,使模型能够在未知转速下进行智能诊断;其次,考虑到在训练阶段无法获取目标转速下的振动信号的情况,基于Dropout策略和残差模块对深度卷积神经网络结构进行优化,以增强模型的泛化能力,从而实现在未知转速下的故障诊断;最后,通过生成对抗网络生成未知转速下的振动信号来扩充训练数据集,进一步提升了诊断模型在未知转速下的故障诊断能力。通过实验证明了所提出的基于DCNN的智能诊断方案能够实现变转速行星齿轮箱的故障诊断,且三种优化策略都能有效提升诊断模型的跨域诊断性能。本文为变转速行星齿轮箱故障诊断提供了有效的智能诊断方案,并为智能诊断模型在未知转速下的跨域诊断问题提供了新的思路和可行的解决方案。文中包含图51幅,表12个,参考文献73篇。"
176,基于卷积神经网络的机械故障诊断域自适应算法研究,"随着装备向自动化、智能化方向发展,为保障机电系统高精度高可靠性运行,健康状态监测与维护已经成为一个重要的研究方向。与此同时,卷积神经网络与深度学习技术,大大推动了数据驱动故障诊断算法的发展。然而,以下问题严重制约了卷积网络的应用:数据标签难以获得、实际工况变化复杂、采集与测试机器存在差异。本文将迁移学习中域自适应理论引入到智能故障诊断算法中,分别针对数据标注、跨工况和跨设备三个层次的适应性问题进行研究。对卷积神经网络理论基础进行介绍,同时将迁移学习与域自适应概念引入故障诊断领域,详细介绍了本文所采用的数据集,并且搭建丝杆故障信号采集平台,用于验证所提出算法的准确率。研究基于物理模型的迁移学习故障诊断算法。本文改进了现有对抗生成网络,向物理模型生成的有标注仿真信号中添加真实采集信号的特征,得到趋于采集信号分布的生成信号,并以此训练分类器进行故障诊断。试验结果表明,提出的算法能够极大程度降低传统对抗生成网络模式坍塌、训练不收敛等问题,并且在生成数据时保持了故障信息,可以使用无标注数据进行故障诊断,验证提出算法的域自适应能力。研究基于胶囊网络的ICN跨工况故障诊断方法。针对现有算法难以适应工况变化的问题,本文使用无池化层的胶囊网络,并添加多路卷积分支结构以提高网络的非线性,提取更加抽象的特征。在轴承和丝杠多个数据集上进行故障诊断实验,验证提出算法在跨工况故障诊断情况下的域自适应能力。研究基于W-距离的特征正则化跨设备故障诊断方法,克服了现有故障诊断算法由于设备差异造成的低准确率问题。在迁移学习领域,W-距离作为一种常用的分布差异度量准则,难以求取精确解,本文提出W-距离在迁移学习情况下的近似简化定理并给出证明。并且本文通过对多个网络公开轴承数据集与自采集轴承、丝杠数据集进行测试,验证了提出算法的在跨设备设备故障诊断情况下的域自适应能力。"
177,非均衡数据驱动的重载铁路列车智能控制算法,"重载列车重量大、编组长,线路条件复杂,司机驾驶过程中工况切换频繁,不当的牵引或制动将增大列车纵向冲击力,甚至发生脱钩的危险。在长大下坡道处,司机需采用循环制动的方式施加空气制动控制列车速度,再充风时间不足将导致列车失去制动力,给列车安全运营埋下隐患。在重载列车编组方式、运行交路和载重等都相对固定的条件下,迫切需要在列车控制方式上做出优化,代替司机控制实现自动驾驶。本文以朔黄铁路为研究背景,通过分析SS4G型机车的列车运行数据发现,不同工况下运行数据比例严重失衡。针对此非均衡特性,引入机器学习领域的分类方法,设计非均衡数据驱动的重载列车空气制动以及牵引/电制动智能控制模型,实现列车智能驾驶。主要工作包括如下:(1)基于随机森林算法实现重载列车运行数据特征降维。数据标准化处理后,搭建随机森林模型对重载列车运行数据的特征进行学习,量化不同特征在智能控制中的重要性,采用序列后向消除方式提取备选特征集实现特征降维。(2)基于Adaboost算法实现重载列车空气制动智能控制。通过比较C4.5与CART两种决策树算法对数据集的预测效果确定Adaboost基分类器类型;鉴于重载列车运行数据中,施加空气制动类别的数据严重不足而引起的非均衡特性,从训练样本子集的抽取方式以及投票权重两方面对Adaboost算法实现优化,使其对空气制动预测的F1-Measure值提升0.0439,高精度实现空气制动智能控制。(3)基于支持向量机SVM算法实现重载列车牵引和电制动智能控制。通过为多数类和少数类分配不同的惩罚因子C+和C_,实现对非均衡数据分类的优化;引入核函数将数据集映射到高维使其线性可分,比较多项式核函数与RBF核函数在不同场景的性能差异,结合列车运行速度生成动态更新因子,进而连接两种核函数构建混合核函数对算法实现优化,提升模型对数据的辨识度。(4)搭建重载列车动力学模型实现智能控制模型验证。结合重载列车控制策略输出特性以及列车运行数据搭建重载列车动力学模型,引用朔黄铁路神池南站到肃宁北站区间408km线路数据,仿真重载列车运行场景。通过比较本文智能控制模型与司机驾驶结果,从速度、空气制动再充风时间等方面验证模型控制的安全性,从驾驶时间验证模型准时性,从工况切换次数验证模型输出的合理性,从而证明本文重载列车智能控制模型的正确性。"
178,铁路场景下卫星定位可用性评估及预测方法研究,"精确列车定位是列车行驶安全的重要保障,随着卫星定位系统的发展,国内外先后开展了对下一代列控系统(Next Generation Train Control System,NGTC)的研究,基于卫星的列车定位手段成为主流。卫星信号在传播过程中易受环境遮挡,铁路沿线环境复杂多变,不同程度的遮挡导致卫星定位精度发生变化,严重时甚至会导致定位功能失效。因此,对铁路不同环境场景下卫星定位可用性进行评估与预测对保证列车行驶安全有重要意义。本文提出铁路场景下卫星定位可用性评估及预测方法,该方法首先基于层次聚类算法对铁路沿线场景进行分类,量化重构各场景下的环境遮挡,并评估不同场景下的卫星定位可用性。然后根据卫星历书和环境遮挡信息预测出各场景下可见卫星分布,结合Xgboost模型和可见卫星分布的预测结果对不同场景下卫星定位可用性进行预测。本文主要工作内容如下:(1)调研了卫星定位系统和基于卫星的列车定位可用性评估研究现状。在对前人研究总结的基础上,归纳了铁路场景卫星定位可用性评估指标:SIS可用性、HDOP可用性、沿轨道精度可用性和垂直轨道精度可用性。根据上述四项指标得到卫星定位可用性,并将其分为可用、降级、不可用三种状态。(2)针对铁路沿线场景复杂多变的情况,本文提出了基于层次聚类的铁路沿线场景分类算法。算法从卫星接收机历史数据中提取可见卫星几何分布等与环境相关的参数并进行预处理,将生成的环境特征作为层次聚类算法的输入,根据层次聚类距离与步数之间的关系,对铁路沿线场景进行分类。根据分类结果,重构各个场景下环境对卫星信号的遮挡情况,并评估不同环境场景下卫星定位误差及可用性性能。(3)通过解算卫星历书并结合各场景下的环境遮挡信息,预测可见卫星数和卫星几何分布,以及SIS可用性和HDOP可用性。将可见卫星几何分布作为输入,利用优化后的Xgboost算法进行沿轨道/垂直轨道精度可用性预测。最终预测出卫星定位可用性状态。本文对铁路沿线场景卫星定位可用性评估及预测方法进行了实验验证,搭建了青藏铁路数据分析平台,对青藏铁路沿线的可见卫星数、HDOP值和预测的卫星定位可用性进行展示。实验结果表明,本文提出的基于层次聚类的场景分类方法准确的将实验区间的铁路沿线分为开阔、路堑、隧道、高山、半边天共计5类环境场景,并对各场景下的环境遮挡进行重构,与3D建模、鱼眼镜头方法进行比较,证明了本文方法能够准确的对环境遮挡进行重构。根据重构的环境遮挡情况,基于卫星历书和Xgboost模型对铁路沿线各类场景下卫星定位可用性进行预测,预测准确率达到95%以上。图66幅,表33个,参考文献66篇。"
179,基于数据的城轨乘客路径选择与客流拥堵动态估计研究,"随着新线的不断接入,城市轨道交通网络不断扩大,如何建立起更精确的路径选择模型,并快速地预测路网中客流的动态变化与拥堵状况成为一个亟需解决的问题。本文利用机器学习手段,研究基于数据驱动的路径选择与客流拥堵动态估计方法与模型,在客流分布动态推演工具的支持下,形成路网客流分布的动态变化,并对不同情况下的路网客流拥堵状态进行快速预测。主要研究内容包括:(1)对乘客路径选择及路网客流动态的一般建模方法进行了分析,提出了利用乘客路径选择结果数据和客流分布推演仿真数据进行机器学习,构建基于数据驱动的路径选择模型与客流拥堵动态估计模型的思路与研究框架。(2)利用路径选择数据对不同类OD间路径选择规律的差别进行了分析,提出了考虑OD间客流构成异质性的路径选择集成学习框架,给出了基于站点模糊聚类的路径选择集成学习方法与步骤。使用FCM聚类算法对地铁站点进行聚类,得到不同客流构成下的OD类别及其类别隶属度,为路径选择子学习器的训练与结合提供了依据。(3)构建了基于SVR的路径选择子学习器,利用乘客路径选择数据进行了模型训练。进一步,运用集成学习方法,结合站点模糊聚类结果对路径选择子学习器进行了组合,形成了准确性更高的路径选择决策模型,并对集成学习前后的预测数据进行了对比和验证。(4)利用城市轨道交通路网客流动态分布推演仿真系统作为客流推演的工具,提出了利用不同场景下的仿真结果数据进行机器学习,快速估计客流拥堵状态的方法。构建了基于LSTM的路网客流拥堵动态估计模型,利用仿真数据进行了模型训练。(5)以新线开通后的北京市轨道交通为背景进行了案例分析,对本文的研究方法进行了验证。"
180,列控车载设备故障间隔时间统计分布建模及预测方法研究,"“八纵八横”高速铁路网的提出使我国进入了高速铁路建设蓬勃发展的大时代,高效性、安全性和平稳性使得高速列车逐渐成为人们出行的首选,如何使高速列车的运行更加安全高效也逐渐成为铁路领域研究的重点。目前,铁路领域的故障预测研究主要集中在地面设备,但高速列车是客运的主体,一旦发生故障将导致不可估量的损失。故障间隔时间可以反映系统或装备故障的内在演化规律,因此,本文以车载设备微小故障间隔时间作为主要研究对象,对其进行统计分布建模及可靠性分析,并建立组合预测模型对其进行预测。本文的主要研究内容如下所示:(1)通过查阅大量文献资料,详细总结了故障预测技术和故障间隔时间的研究现状,并介绍了车载设备的结构和功能。基于动车设备质量分析工区交接班记录表和ATP车载设备配件更换历史记录表,将车载设备故障划分为六大类共16种故障类型。本文的数据来源为某型号车载设备ATPCU-LOG文件中记录的故障信息,对故障数据进行预处理,并利用分词技术和Apriori关联规则数据挖掘算法得到故障规则库,为后续研究奠定基础。(2)根据故障规则库,从历史故障数据中提取出车载设备微小故障间隔时间样本序列,首先对其进行统计分布分析,然后假设样本序列服从两参数Weibull分布或指数分布,分别利用最小二乘法和极大似然法求解模型参数,最后基于灰色关联分析法得到最优统计分布模型,从而建立基本可靠性模型,并根据最优分布模型对车载设备进行基本可靠性分析,求得车载设备的平均微小故障间隔时间、微小故障率函数和基本可靠度函数。(3)针对样本序列的非线性问题,建立基于时序分解的故障间隔时间组合预测模型对其进行预测。首先利用STL算法对样本序列进行时序分解,分解成周期项、趋势项和剩余项,然后对分解后的各项数据分别用回声状态网络、BP神经网络和支持向量机预测模型进行预测,最后分四种组合模型对各项预测结果相加得到最终预测结果,并与三种单一预测模型相比较,发现组合预测模型比单一预测模型的预测效果更好,最优组合模型为ESN+SVM+SVM,预测精度可达96.49%。综上所述,本文以车载设备系统级和部件级微小故障间隔时间作为主要研究对象,对其建立最优统计分布模型,并对车载设备进行可靠性分析。建立基于时序分解的组合预测模型预测微小故障间隔时间,仿真验证结果表明其预测效果比单一预测模型更好,预测结果可以使列车司机和现场维修人员能够提前预知故障情况并做出应对措施。图60幅,表12个,参考文献70篇。"
181,基于交叉熵理论的列控车载设备故障组合预测方法研究,"车载设备作为高速铁路列车运行控制系统(以下简称列控系统)的重要组成部分,是保障列车安全高效运行的核心部件。其中,列控系统300T车载设备在目前上线运行的车载设备中占有较高的使用比例,由于其具有结构复杂、模块众多、跨地区长时间高速运行、行车环境多变等特点,任何轻微故障或安全隐患都有可能降低列车运行的可靠性。因此,有必要对列控系统车载设备的故障状态进行及时预测,提前发现并消除潜在故障,实现视情维修,以保障高速列车运行安全和运营效率。目前,对于列控系统车载设备的故障研究主要集中在故障类型分析、故障诊断和识别等方面,针对列控系统车载设备故障预测的相关理论、方法和技术研究较为缺乏,特别是没有能够实际应用于现场的实用化故障预测理论和方法,现场故障数据处理强度极大。为缓解现场故障分析与处理压力,实现真正意义上的状态修,非常有必要开展列控系统车载设备故障预测相关研究。本文从列控系统300T车载设备的日志数据出发,首先对车载设备日志数据进行了清洗处理,分析了车载设备多故障模式,构建了用于部件级和系统级故障预测的故障统计特征,实现了故障运行状态的有效识别,设计了基于交叉熵理论的列控车载设备故障组合预测方法。论文的主要工作包括:(1)分析了列控系统300T车载设备日志数据的特点,设计了数据预处理策略以准确实现故障数据统计,采用多状态系统理论进行了车载设备的运行状态划分,基于模糊FMEA方法实现了车载设备运行状态的评估,实现了故障等级内故障类型的准确划分。(2)分别选取故障率和当量故障率作为车载设备部件级及系统级的故障特征,分别采用支持向量机、极限学习机及网格搜索优化支持向量机对车载设备运行状态进行了识别研究,仿真结果表明,采用当量故障率能够有效表征车载设备运行状态,网格搜索优化支持向量机的状态识别准确率为93%,在三种方法中准确率最高,验证了使用该方法进行车载设备状态识别的可行性。(3)以当量故障率和故障率数据序列作为数据支撑,首先,采用K近邻非参数回归预测模型、改进灰色Elman神经网络预测模型分别进行短时预测;其次,基于交叉熵理论将两种模型进行优化组合,并选取常用的等权重组合模型进行对比分析,预测出部件级的故障时间;最后,通过网格搜索优化支持向量机对当量故障率预测值进行状态识别,进而预测出系统级的故障时间、故障等级和故障模块。仿真结果表明,相比其它三种预测模型,交叉熵组合预测模型的预测结果预测精度最高,,故障等级预测准确率为87.33%,故障模块预测准确率为94.4%,故障模式预测准确率为77.77%,验证了使用交叉熵组合预测模型进行车载设备故障预测的可行性。本文在系统分析车载设备日志数据的基础上,引入基于交叉熵理论的故障组合预测方法对车载设备进行故障预测,能够有效实现对车载设备故障时间、故障等级、故障模块和故障模式的预测,预测准确度基本满足动车段数据处理工区的故障分析和预测需求,为实现面向车载设备的视情维修奠定基础。图58幅,表37个,参考文献82篇。"
182,大型活动下城市轨道交通进出站客流短时预测研究,"近年来,城市轨道交通行业发展迅速,成为人们出行的重要方式,同时随着经济社会的发展,大型活动的举办也越来越频繁,大型活动的举办会造成大量人群在较短时间和较小空间内的聚集,产生城市轨道交通突发大客流,对乘客安全和车站运营造成影响。做好大型活动所引发的突发客流的准确预测,是进行合理客流组织和安全运营的必要支撑,因此,对于大型活动下的城市轨道交通客流进行短时预测具有重要意义。本文通过对大型活动下城市轨道交通客流规律进行研究,提出了一种大型活动下城市轨道交通客流预测特征构建和提取方法,建立了组合预测模型,实现了大型活动下的城市轨道交通客流的进出站准确预测。本文的主要工作如下:(1)对大型活动城市轨道交通客流的变化规律进行研究分析。首先说明大型活动的概念、特性及分类,并进一步说明大型活动下城市轨道交通客流的概念和描述指标,其次归纳大型活动下城市轨道交通客流的影响因素,最后分析其变化过程和变化范围,归纳变化特性,并选取集中爆发型活动客流进行进一步的预测研究。(2)给出了大型活动客流预测机器学习框架下的特征构建和提取过程。首先建立了基于机器学习的大型活动下城市轨道交通客流预测框架,从常规特征和活动特征两方面进行特征构建;其次阐述了常规特征与活动特征的具体构建依据及方法,创新性的提出了活动特征的构建方法;最后采用Lasso算法对构建的全特征集合进行特征选择,从而得到所构建模型的输入特征。(3)构建了梯度提升回归树和随机森林相结合的RF-GBRT客流组合预测模型。首先分析了大型活动下城市轨道交通客流预测的难点,并在误差分析基础上提出解决思路,其次选用集成学习中的梯度提升回归树模型(GBRT)和随机森林(RF)作为预测基础模型,并分别结合改进的粒子群算法(PSO)进行了参数寻优,将预测模型进行组合,获得适应于大型活动的RF-GBRT组合预测模型,确定了用于模型验证评估的交叉验证法和评价指标。(4)以北京地铁东四十条站为例进行了实例研究。选取东四十条球赛时段的AFC数据,利用python工具进行了实验验证。对比了不同特征集下的预测结果,证明本文所提出的特征构建和提取方法的有效性;并与KNN、SVR、LR等常用客流预测方法对比,证明本文所提出的RF-GBRT模型预测方法具有更好的预测效果。"
183,机器学习在高速铁路光传送网的应用研究,"高速铁路光传送网(OTN,Optical Transport Network)是高速铁路正常运行的保障。光传送网络故障的产生会导致业务的中断以及信息的丢失,不仅会影响列车的安全运行,也对用户造成经济损失。因此在网络发生故障时,高效的故障定位机制能够为故障的快速恢复提供条件,是网络安全运行的保障。此外,当前高速铁路信息业务量不断增大,业务的种类趋向多样化,为满足业务的需求,光传送网络的拓扑结构也越来越复杂。在这种发展趋势下,如何保证网络的良好的服务质量(Quality of Service,QoS)成为了最基本的问题之一,而光网络的拥塞控制则是实现优良的QoS机制的关键技术。本文将机器学习的算法应用于光网络的故障定位和网络的拥塞程度的预测中,主要研究内容如下:(1)提出了基于GRU(Gated Recurrent Unit)神经网络的故障定位的方法,主要解决光传送网络的单链路故障。该方法是利用神经网络对链路的历史故障数据进行训练,然后通过分析发生故障时链路的状态信息来实现对故障链路的定位。本文基于铁路骨干环链路搭建动态业务模型进行故障定位的仿真,仿真中对GRU的参数进行了优化,并在相同条件采用结构相似的LSTM(Long Short Term Memory)神经网络进行对比实验,表现了 GRU模型相对优异的性能。仿真结果表明本文提出的方法可以迅速定位故障,减少发现故障到修复故障的时间,且具有95.7%的定位准确率,同时节省了使用监测器的成本。(2)提出了基于支持向量机(Support Vector Machine,SVM)进行光网络拥塞程度预测的模型,主要针对光传送网络拥塞的问题。该模型可以根据业务具体分配的信息(每个业务带宽分配的大小,每个业务带宽的持续时间,源节点,目的节点)对光网络中的下一时间周期的网络拥塞程度进行预测分类。仿真实验中采用的SVM为一对一的多元分类模型,核函数为RBF,并用网格搜索法优化了 SVM的参数。仿真结果表明基于SVM的光网络拥塞程度的预测模型有97.8%的分类准确率,这对光网络的管理与规划,合理的分配光网络资源以及提高光网络的业务的QoS提供了一个良好的策略。"
184,轨道动检数据的时序预测模型研究,"近年来,随着机器学习与数据挖掘的迅速发展,时间序列数据的智能处理和分析在各行各业得到了广泛应用。行业时间序列数据呈现出大数据量、高复杂性、非线性的特点,因此对其的判别、预测等也面临极大的挑战。铁路轨道动检数据是由轨检车等检测设备采集的多元时间序列数据,不仅反映铁路基础设施的当前服役状态,而且蕴含丰富的状态演化信息,将先进的机器学习与数据挖掘技术应用于基于轨道动检数据的状态预测任务中,为铁路工务部门日常的养护、维修提供技术支撑,对于保障铁路运营安全,提高数据资源的利用率具有重要的理论意义和实用价值。本文从时间序列预测模型的研究出发,针对铁路工务部门对高速轨道形变预测的任务,重点研究桥梁徐变上拱预测模型以及CPⅢ差异沉降预测模型,本文的主要工作及研究成果包括:(1)针对桥梁数据分类提取问题,提出了一种基于轨道动检高低不平顺数据的多项式逻辑回归桥梁分类方法,首先对轨道动检高低不平顺数据波形进行分段处理,然后对分段后波形进行特征提取,最后通过多项式逻辑回归算法进行分类。通过在验证集上进行分类验证实验证明了所提出的桥梁数据分类提取的有效性。(2)针对高速铁路桥梁徐变上拱预测问题,提出了一种基于LSTM神经网络的桥梁徐变上拱预测模型,首先构建时间维度上的桥梁数据集,然后计算某一跨桥梁在每一时刻的徐变上拱值,构建出桥梁徐变上拱的时间序列数据,最后通过基于LSTM神经网络桥梁徐变上拱预测模型实现预测任务。在24米和32米桥梁数据集上进行的验证实验,证明了基于LSTM神经网络的预测模型对实现桥梁徐变上拱预测的有效性。(3)针对高速铁路CPⅢ差异沉降预测问题,提出了一种基于Siamese神经网络的CPⅢ差异沉降预测模型,首先构建Siamese神经网络的双输入的样本,需要将表征CPⅢ差异沉降的两次动检数据作为输入,然后通过Siamese神经网络的两个子网络将二者转化到特征空间中,最后通过网络结构中的度量模块实现二者的“距离”度量,实现CPⅢ差异沉降预测。通过在验证集上进行的实验证明了所提出的基于Siamese神经网络的CPⅢ差异沉降预测模型的有效性。"
185,基于多模态融合的特种车辆识别的研究与应用,"随着大数据、云计算和5G技术的成熟,人工智能逐渐突破技术的瓶颈开始快速发展。近年来,人工智能技术在汽车领域的应用尤为重要。在“城市大脑”等智慧交通中,无人驾驶汽车也正在逐渐变为现实,其中车辆识别技术是智慧交通中的重要技术之一。常见的特种车辆有工程抢险车、救护车、警车、消防车等。由于特种车辆关系到解决社会应急问题,并且法律规定正在执行任务的特种车辆具有道路优先通行权,无人车对正在执行任务的特种车辆进行避让显得尤为重要。所以在车辆识别技术中,针对特种车辆的识别的研究具有重要的价值和意义。本文利用深度学习和多模态融合技术实现了一种特种车辆识别的研究与应用。通过获取声音、图像等多通道采集的多模态数据信息,建立多模态特种车辆数据集,利用高效的云平台计算能力,设计针对特种车辆识别的深度神经网络,完成小样本数据集的特种车辆图像和音频模型的训练,在深度学习和认知计算的基础上,实现了对道路上正在执行抢险救援等应急任务的特种车辆的实时检测和识别,进一步完成特种车辆的多模态融合识别和避让决策,具体工作包括如下。(1)通过收集和处理音视频的数据,构建包含特种车辆的图像和音频的多模态数据集。其中正样本包含工程抢险车、救护车、警车、消防车的图像和音频数据,负样本为普通车辆的图像和音频数据。(2)利用多模态信息融合方法对识别结果进行决策,提高识别精确率。设计了特种车辆图像识别算法、特种车辆音频识别算法和特种车辆多模态融合识别算法,实现对特种车辆图像及音频的识别。通过获取的多通道数据信息,对特种车辆进行检测、特征提取、识别和融合决策。对于融合后系统无法准确判断的结果,提示进行人工辅助操作,确保人类在无人驾驶中的优先级。(3)开发了基于Android的特种车辆识别应用程序。主要功能包括数据采集、特种车辆识别、多模态决策融合和驾驶指令执行。数据采集主要利用摄像头和麦克风实现特种车辆的视音频数据采集等功能。特种车辆识别模块主要包括特种车辆的图像识别和音频识别,并将识别的结果传递给多模态决策融合模块进行决策和判断。在多模态决策融合模块中,实现对正在执行任务的特种车辆的判断识别。最后通过驾驶指令执行模块,根据当前车辆和正在执行任务的特种车辆的相对位置,发出相应的驾驶指令。本研究提供的多模态融合的特种车辆识别方法,可为无人驾驶设备的智能化提供一种有效参考,在当前车联网技术尚未成熟和未来有人驾驶和无人驾驶共存的环境中,相关应用的实现可为未来智慧城市和无人驾驶的应用提供有效的解决方案。"
186,基于LSTM深度神经网络的短期交通流预测,"为了解决日益严重的交通问题,尤其是交通拥堵问题,交通部门开始广泛的应用智能交通系统(intelligent transportation system,ITS)来进行动态交通管理。短时交通流预测,不仅仅是智能交通的核心组成部分,更是交通管理部门实施交通管理及诱导的核心依据。同时,准确的交通流预测信息还可以为出行者提供详细的、实时的道路信息,来提高道路的通行能力,避免拥堵。所以,准确的交通流预测模型尤为重要。另外,伴随着大数据的不断发展和应用,获得的交通流数据越来越多,如何应用这些数据来更加精准地预测短时交通流已成为至关重要的问题。由于短时交通流具有不确定性、周期性、相关性和非线性等特点,是一种典型的时序数据,所以准确预测的核心就是获取数据之间的潜在关联和影响。基于以上背景,本文建立了基于长短时记忆神经网络(long-shorttermmemory,LSTM)的短时交通流预测模型,具体研究内容如下:首先,本文分析了目前短时交通流预测模型的优缺点,然后对交通流的参数以及与处理方法进行介绍,第二步对机器学习和深度学习进行详细的阐述,为模型的建立奠定理论基础。之后建立了基于长短时记忆网络的预测模型,然后详细介绍了模型的网络结构和训练过程,通过不断地调整参数,使模型到达最优。最后通过与反向传播(back propagation,BP)神经网络模型、支持向量机(support vector machine,SVM)以及门控循环单元(gated recurrent unit,GRU)神经网络进行对比,表明该模型的均方根误差(root mean squared error,RMSE)、平均绝对误差(mean absolute error,MAE)、平均绝对百分比误差(mean absolute percentage error,MAPE)更小,预测准确率更高。本文还采用了不同路段的数据分别进行训练。通过对比可以看到,该模型对于本文所选的各个路段的预测准确率基本稳定在93%左右,说明基于LSTM的短时交通流预测模型可以较准确地获取数据的时序性特征,而且具有良好的稳定性,可以适用于不同路段的交通流预测。"
187,基于神经网络的道路通行时间预估方法的设计与实现,"该项目来源于高睿鹏老师的科研项目以及本人在滴滴出行公司实习期间的实际项目。该项目基于智慧交通的应用及发展,结合多源异构交通大数据来预估道路的通行时间。在交通出行领域,道路的通行时间已经成为人们出行选择的重要参考指标之一。在实际的交通应用场景中,道路的通行时间也是衡量道路运行状态、交通规划、智能交通研发、城市交通运行水平的一个重要指标。准确预估道路的通行时间不仅能够提高人们的出行效率,还能够进一步提升交通的服务质量。当前道路通行时间的预估方法主要集中于路径的OD(origin-destination,OD)研究。该研究主要分为两类,一类是基于路径的预估方法,另一类是基于数据驱动的预估方法。通过大量的实验证明,当前方法在数据的稀疏性、模型的泛化能力以及数据的利用率方面相对来说具有很多的局限性。为了有效解决上述问题,本论文在现有方法的基础上,提出了基于神经网络的道路通行时间预估方法。在本方法中,分析利用多源异构数据特征如GPS轨迹数据、路网数据以及外部属性数据如天气、日期等,通过结合不同的数据特征输入到网络模型进行训练预测,得到网络模型的预测值。在该方法的实验过程中,本论文首先对现有的多源异构数据进行数据分析及建模;其次,针对不同的数据特征采用不同的数据处理方法,如为了进一步有效地提取路网数据的空间特性,本论文对路网数据采用DeepWalk算法,目的在于保留路网拓扑邻接关系的特性基础上,将路段编号进行向量化处理;对于外部特征,由于其属于类值属性,不能直接输入到网络模型,所以本论文采用Embedding方法将其向量化表示,不仅能够保留其语义之间相似性,还能够降低数据维度。最后,基于不同的交通数据特征,结合长短时记忆网络LSTM(Long Short-Term Memory,LSTM),采用深度学习框架PyTorch实现了预估道路通行时间的方法。通过对北京、上海两地的数据集进行模型的训练与测试,采用不同的评价指标,如平均绝对误差比MAPE(Mean Absolute Percentage Error,MAPE),平均绝对误差MAE(Mean Absolute Error,MAE)以及均方误差MSE(Mean Square Error,MSE)来评估模型的效果。在实验过程中,模型的MAPE的值分别为0.1736和0.1807,MAE的值分别为103.66和12.35,MSE的值分别为13279.21和13762.18。通过对现有不同方法的结果分析,本论文提出的道路通行时间预估方法具有较低的预测误差,其模型效果优于其他现有的方法。"
188,基于GMM模型与RWI-HLLE算法的高速公路运行状态评价,"高速公路运行状态评价分析、交通运行状态获取是交通运行管理与出行信息获取的基础,通过大量的交通运行数据对高速公路的运行状态进行等级划分与状态识别能够对交通运行状态的发展规律进行研究。通过对高速公路运行状态的识别,可以使出行者及时获取相关道路运行状态信息,避免造成更大范围拥堵的形成,对于高速公路运行管理有着重要意义。本文围绕高速公路运作状态等级划分与识别问题,根据高速公路运行管理部门的实际需求,结合高速公路交通参数,对高速公路运行状态评价指标体系、高速公路运行状态等级划分评价以及高速公路运行状态识别综合评价进行深入研究。并通过实验分析对所建立的模型算法进行验证,说明了研究方法的可行性。本文的主要研究工作如下:建立了高速公路运行状态评价指标体系。根据高速公路实际运行需求,集合指标体系建立原则,对高速公路运行评价指标进行了分析,确定了评价指标体系。通过实际数据的分析,构建了满足动态评价与周期评价的指标体系。提出了基于高斯混合模型(GMM)的高速公路运行状态综合评价方法。以高速公路交通运行数据为依据,采用GMM-EM算法模型对数据进行聚类分析,根据聚类中心与比例对各指标及整体运行状态进行等级划分,对高速公路运行状态进行判别与综合评价。实现了基于改进局部线性重构算法(RWI-HLLE)的高速公路运行状态识别。对LLE算法进行改进分析,提出了基于重构权值的增量Hessian LLE算法,采用数据集对算法进行验证,说明了算法的有效性;基于RWI-HLLE算法对高速公路运行状态进行识别,并采用实际数据验证了该方法的科学性与可行性。立足于高速公路运行管理与出行服务的实际需求,结合高速公路交通运行数据,采用聚类算法与流形学习算法的理论基础,对高速公路运行状态的综合评价与状态识别进行合理的分析,通过实验证明了本文研究结果的准确性与实用性。"
189,无人驾驶感知辅助系统的研究与仿真实现,"随着计算机硬件与软件的快速发展,无人驾驶已经成为国内外加紧研发的前沿技术。如今大多数汽车制造商承诺到2020年半自动驾驶将会上市,许多业内专家展望不久的将来全自动驾驶汽车也将成为可能。成熟的无人驾驶技术不仅会提高整个社会的交通效率,而且可以减少交通事故的发生,挽救更多人的生命。感知系统作为无人驾驶系统的基础组成部分,直接影响着决策系统和控制执行系统的效果。感知系统主要运用计算机视觉技术提取无人车运行环境中的信息,包括对车道线的检测、无人车行驶前方行人、车辆的识别和跟踪等,并能够在感知功能的基础之上达到辅助无人驾驶、为决策和控制执行系统提供支持的目的。本文在实现了相关感知算法的基础之上,结合无人驾驶的实际情况提出了一系列预警标准,完成无人驾驶感知辅助系统。与此同时,虚拟仿真技术的应用领域越来越广泛,鉴于在真实道路上测试感知辅助系统的效果所需成本高、不可控因素强,本文建立了一个基于Web与Unreal Engine结合的无人驾驶虚拟仿真平台。本文主要的研究内容包括:(1)研究并实现车道线检测算法。鉴于车道线在颜色、纹理、位置的特殊性,本文将这些特征组合起来按照多重自适应阈值标准进行特征点预提取,由于传统方法使用hough变换,利用直线近似拟合车道线,对弯道幅度较大的场景并不适用,本文使用局部动态窗口选取定量且分布均匀的拟合点,用多项式拟合车道线。(2)研究并实现前方车辆和行人检测算法。实验中使用视觉词袋作为分类器训练、测试的依据。而鉴于背景信息会干扰目标检测,本文提出使用基于OTSU的图像分割方法提取图像目标区域,对目标区域提取词袋特征。为了保证视觉词汇的均匀分布性和独立性,避免视觉词汇混淆,影响检测结果,本文提出基于类别信息的视觉词典构建方法。实验结果表明,基于类别对目标区域提取视觉词汇能够提高检测准确率。(3)鉴于在真实道路上测试感知辅助系统的不易控性,本文设计并实现基于Web和Unreal Engine结合的无人驾驶虚拟仿真平台,通过用户在浏览器中的不同选择可以在UE端动态创建出不同的虚拟仿真环境,将Web的友好人机交互特性与Unreal Engine强大的视觉仿真特性相结合。(4)将本文实现的无人驾驶感知辅助系统应用于虚拟仿真平台进行模拟实验,实验中设置不同的环境变量,经过反复测试与分析,实验结果表明本文实现的感知辅助系统具有可行性和有效性。"
190,复杂情况下的道路边缘检测算法研究,"自上世纪八十年代以来,基于计算机视觉的车辆自主导航技术已经成为自动驾驶与车辆辅助驾驶研究中的热点方向之一。其中,道路识别技术更是车辆自主导航系统的重要组成部分,然而,目前在乡村道路、盘山公路等无明显标线的非结构化道路的驾驶环境下加之阴影的存在,道路识别技术仍然存在着准确率低、实时性差和易受光照影响的缺点。为了克服以上缺点,本文针对复杂阴影的驾驶环境下的识别率低、易受道路阴影影响、参数拟合不准确等缺陷,在保证系统实时性的前提下,按照图像预处理、路面阴影消除、道路边缘线拟合及跟踪的结构进行深入研究。本文主要工作如下:(1)利用支持向量机算法、神经网络算法以及改进的最大类间差算法分别对道路场景图像进行分割处理,从而能够将道路区域从复杂阴影的道路图像中分割出来,并针对三种不同的道路分割算法进行实验设计与结果分析;(2)根据不同的道路方向类型,设计不同的函数模型,利用最小二乘法对已提取的道路线进行拟合。由于复杂情况下,道路边缘线会出现许多噪声点,影响拟合结果,本文又着重对LMedSquare算法进行改进研究,提高拟合精度;(3)分别介绍卡尔曼滤波算法和粒子滤波算法在道路模型参数进行跟踪预测方面的具体应用,并利用改进的卡尔曼滤波算法对道路模型参数进行跟踪预测,避免系统对采集到的图像进行逐帧处理,提高算法实时性。实验结果表明,本文算法对非结构化道路有着较强的鲁棒性,有效地避免了阴影及噪声的干扰,并且在道路中没有道路线的情况下,依然可以发挥效用,为车辆在复杂情况下的自主导航打下良好的基础。"
191,基于单线激光雷达的车辆检测与跟踪,"环境感知技术在无人驾驶中起着重要作用,是实现辅助驾驶和自主驾驶的前提条件,目标识别是无人驾驶环境感知中的重要部分。针对车辆检测,本文完成了两种实验分析:本文提出了一种基于单线激光雷达作为主传感器,基于OptoBot-IV实验平台,首先通过激光雷达扫描并获取空间轮廓数据,对每帧数据采用凝聚层次聚类算法进行目标分割,采用最小二乘法进行直线拟合,通过锐角判别方法判别目标车辆的方位;然后对目标车辆进行特征提取,通过交叉验证和网格搜索对支持向量机的参数进行优化以实现更好的分类效果,最后采用卡尔曼滤波(Kalman Filter)实现目标车辆的跟踪;实验结果表明,本文提取多种目标车辆特征值组成特征向量并配合参数优化后的支持向量机可以实现较高识别率。文中同时进行了多种分类器效果分析,实验结果表明,每一个分类器虽然在降维和交叉验证后的正确率都有所变动,但是由于准确率不足以评价一个分类器的性能,最后通过分析ROC曲线和AUC值得出最优的分类器为随机森林。基于路边的静态平台上使用单线激光雷达对电动自行车,货车,乘用车和公交车四种车型识别。使用分类器支持向量机(SVM)对交通参与者的类型进行分类,为了提高识别正确率,采用K折交叉验证和网格搜索的方法获取最优参数,在四种车型分类过程中,应用了四次分类器来处理特定的分类,最终实验的总体识别正确率为85.55%,其中对误判的车型单独进行了识别分析,分类精度分别为96.62%、98.20%以及96.18%,这表明所使用的单线激光雷达是可以作为识别道路交通参与者类型的工具。"
192,陕西某水库坝基岩体质量评价及抗剪断强度参数预测研究,"岩体力学参数的确定一直是岩体力学研究中热点问题之一,力学参数取值直接影响设计方案及工程岩体稳定性,大多岩体工程发生问题都源于岩体力学参数估算取值的偏差。水利水电工程中,坝基岩体力学参数取值直接影响工程的安全运行与造价,是工程勘察设计重难点问题之一。对于投资大、工期长的大型工程,获取岩体力学参数最直接有效的方法即是岩体原位测试,但现场原位测试施工难度大、所需费用高,且试验结果会受到尺寸效应的影响。大量工程实践表明,岩块的强度与岩体强度之间存在一定的隐含联系,在工程应用中可利用岩石试验结果、原位试验以及现场调绘的资料来估算工程岩体力学参数,得出与岩体实际情况较接近的参数估算值。本文以陕西某水库坝基出露的奥陶系马家沟组灰岩为研究对象,结合坝址区岩石试验及原位测试结果,分析岩体结构面特征,评价建基岩体质量;收集相关岩体力学参数取值数据,运用机器学习方法建立岩体力学参数预测模型,并运用于坝基岩体力学参数估算,为水库工程坝体建设提供合理准确岩体力学参数建议值。研究结论如下:(1)对坝址区岩体结构面发育规模、性状进行分析,采用结构面宽度、间距、充填状态、延伸长度等指标,结合现行工程地质勘察规范,提出了适用于坝址区岩体结构面分级标准,将坝址区岩体结构面分为四级,分别为Ⅱ级、Ⅲ级、Ⅳ级、Ⅴ级结构面。(2)选取岩体结构特征、纵波波速、完整性系数、变形模量、抗压强度等代表性指标将坝基岩体质量分为Ⅱ～Ⅴ类四级,且主要为Ⅱ～Ⅲ类岩体,并对各级岩体的可利用性作出判别。(3)建立了岩体抗剪断强度参数预测的支持向量机模型,并运用该模型预测水库坝基岩体抗剪断强度参数,模型精度检验结果显示预测误差较小,满足工程使用精度需求。"
193,机器学习在室内智能照明工程中的应用研究,"照明系统作为建筑的重要组成部分,正随着智能建筑的兴起而迅速发展。照度计算是照明系统工程中的必要环节,可用于照明系统设计,室内照度校验和灯具的控制,而传统的照度计算方法――利用系数法由于利用系数查表过程复杂,给照明系统的设计和控制带来了不便。机器学习作为人工智能中的研究热点,善于解决分类和回归问题,在照明工程中也有了广泛的应用。本文将机器学习方法应用到照明工程中,使用机器学习方法改进了利用系数法,在保证计算精度的同时简化灯具利用系数计算过程,并基于聚类算法和改进的照度计算方法设计了一种室内智能照明控制系统。主要研究内容包括以下三个部分:(1)针对传统利用系数法中灯具利用系数查表法过程复杂且计算结果不精确的问题,提出了使用机器学习方法拟合灯具的利用系数表,以改进照度计算方法。以YG1-1型荧光灯管的利用系数为数据集,分别建立了基于神经网络的利用系数计算模型、基于支持向量机的利用系数计算模型和基于随机森林的利用系数计算模型,使用交叉验证和控制变量法进行模型超参数的调节。同时对三种模型的计算精确度进行比较,找出最优的模型。使用训练好的模型进行灯具利用系数的计算,以简化计算过程,提高计算精度。(2)对基于神经网络的利用系数计算模型进行优化,以降低计算结果的相对误差率,提高收敛速度。优化途径主要包括模型的权值初始化方法优化、更新算法优化和网络结构优化。在权值初始化方法优化中,提出了使用粒子群优化算法寻找初始权值,同时将结果与其他初始化方法进行比较。在更新算法优化中,比较并分析了多种梯度下降法训练模型后的相对误差率。在网络结构优化中,提出了使用两个神经网络分别计算有效地板反射比为0.2时的利用系数和有效地板反射比不为0.2时的利用系数修正系数,以充分利用灯具利用系数表中的所有数据。最后,通过比较性实验验证了三种优化途径在基于神经网络的利用系数计算模型上的有效性。(3)针对传统照明系统无法实时、智能地控制照明区域,导致电能浪费的现象,设计了一种基于改进DBSCAN算法的智能照明控制系统。使用传感器获取室内人员位置信息。将位置信息转化为照明平面上的二维坐标数据并使用改进后的DBSCAN聚类算法对数据进行聚类分析,找出人员分布相对密集的区域;使用利用系数法在每个区域上进行照度计算,计算每个区域需要开启的灯具个数或开启灯具的光通量。在照度计算过程中,使用(2)中提出的神经网络模型进行利用系数计算,以简化计算,提高计算精度。通过对照明区域的实时控制,有效减少电能消耗。"
194,基于支持向量机的出厂水水质控制方法的研究,"居民供水安全是涉及到国计民生的大事,出厂水水质安全达标是其中的最重要一环。目前在国家政策引导下城市多水源供水格局己形成,水源水质在时空上存在很大差异。针对水源水质变化,水厂工艺运行调整水厂通常采用以人控为主的粗放式且相对固定惯用控制净水剂、氧化剂的加药量以保证出厂水水质。该模式下严重造成能耗增加和水质不稳定的问题产生。本课题以水厂出水水质稳定为目标,在对国内外水质预测与控制技术深入分析和调查的基础上,提出了基于支持向量机的出厂水水质控制方法。该方法基于水厂加药数据、加药时间及出厂水水质数据,采用支持向量机回归原理,构建了智能自动加药控制方案,对加药量、加药时机进行优化投加控制,以保证城市不同原水状态下的安全供水。本课题主要内容包括:(1)构建基于支持向量机的水质控制模型。常用水质控制工艺下,出厂水水质控制关键因素为加药量与加药时机。将加药对滤后水水质指标的效果存在一定的时间差考虑在建模中,以一定时间序列建立数据仓库,以总管压力、源水流量、源水浊度、源水余氯、源水PH、滤后水浊度、滤后水余氯、滤后水PH、加药量为输入变量,以PAC投加量为输出变量,采用MATLAB仿真工具,建立基于支持向量机的加药量控制模型,即为:PAC自动加药模型。(2)构建出厂水水质控制系统检测体系。基于出厂水水质控制系统检测体系的基本原理,搭建检测体系的软硬件环境。通过水质控制监测系统的参数设置进行分析,建立数值采集系统实现对水厂运行参数的实时采集与存储,并搭建检测体系设备硬件环境。(3)以浙江某水厂为对象,实现基于支持向量机的出厂水水质控制方法的验证与应用。以浙江某水厂为研究对象构建水质控制系统,进行数据采集,通过净水厂净水过程中的真实数据进行前述模型训练,并随机选取不同的水质数据进行模型的测试。该模型采用仿真模拟与应用效果对其展开验证,结果显示该PAC自动加药模型能够对现场水质有着较佳的控制效果,很好的达到了预期目标。将本课题研究成果应用于水厂制水工艺的在线监测和加药的智能决策控制,可实现准确、快速、方便地对现场水质的实时控制,且出厂水浊度值更低,水质效果更佳,出厂水质可以得到很好保障,并能为来自于多水源供水安全提供支持。"
195,高精度饮用水质参数自动监测方法与应用研究,"随着我国经济的飞速发展,环境与安全问题日益突出,特别是水资源污染问题时有发生。近年来在生活饮用水方面出现的问题经常见诸报端,已引起全社会的高度重视。水质管理方式也逐渐从人工管理向自动管理方向发展。由于饮用水水质安全涉及范围广且影响面大,所以设计一个合理可行的饮用水安全自动检测算法,以此来降低自动监测异常预报结果和人工化验结果之间的误差率,具有十分重要的现实意义。论文首先从水质监测的发展历程及目前饮用水水质监测方法的发展趋势进行分析,针对水质自动监测中,由于传感器数据存在误差而导致水质异常预报误报率高的问题,提出一种基于滑动窗口的自学习型饮用水安全检测算法。算法将滑动窗口与机器学习技术相结合,利用滑动窗口周期性地特点,对多个水质监测数据进行框定,并根据不同水质特点采用限定性机器学习方法对水质数据进行处理。最终通过对窗口大小的伸缩,逐步求精,减少误报情况的发生。其次,从目前传统行业应用系统与移动设备相结合的大趋势出发,利用Android系统具有的移动方便性、通用性等优势,结合水厂水质业务管理方式自动化的要求,为自来水厂管理人员设计并开发了一款基于Android的饮水安全监测预报系统。通过对系统进行需求分析、整体架构设计、数据库设计等,确定了采用SOLite、SQL Server等技术进行数据存储;使用JSON数据帧协议格式与异步HTTP技术相结合作为客户端与服务端进行数据交互的技术路线,周期性的抓取服务器端采集的传感数据。最终达到系统水质预警的准实时性。同时,将以滑动窗口为支撑的自学习型饮用水安全检测算法加入系统设计中,提升了系统的精确性和实用性。最后,以西安乐游原水厂数据为例,对系统进行测试。结果表明,由水质安全检测算法判定结果与水质实际检测异常情况之间的误差控制在3.4%以内。系统预警误报率低且可以稳定运行、使用方便,达到了水厂管理人员对水质安全监测软件期望的基本要求。"
196,基于数据挖掘的电力客户投诉分析与预测研究,"伴随新一轮电力体制改革深入推进,售电侧逐渐开放,电力经营主体数量增多,电力市场竞争日趋激烈,同时,消费者服务观念觉醒,维权意识提高,服务需求呈现多元化、个性化,服务品质逐步晋升为用户衡量产品价值的标准,服务营销成为企业打造竞争优势的首选理念。此外,电力企业客户服务系统中已经积累了海量、详实的业务数据,具备了规模化、多样化和实时性的特点。因此,在大数据时代的背景下,利用先进的数据分析技术进行数据挖掘、综合分析,进而提升服务、优化管理,助力电力营销,增强企业竞争力,这已成为各个电力企业的共识。本文以某电力公司客户为研究对象,95598客户服务中心的业务工单为数据基础,调研了电力客户服务的工作现状和需求,应用数据挖掘和信息技术对客户服务所关注的投诉等问题展开研究。首先,结合历史数据的特点和挖掘需求,选取文本挖掘技术和灰色关联法分析了投诉的分布特征和易发原因,利用文本相似度实现了重复诉求工单的自动识别与提取,并对算法的识别率进行了验证,探究了重复诉求发展的业务关联规则。其次,分别从定量和定性角度预测客户投诉行为,前者针对单月投诉量的发展趋势,建立投诉数量的一元时间序列预测模型,后者依据客户诉求描述的文本内容,采用朴素贝叶斯和随机森林分类算法构建出模型,以此评估客户单次来电的投诉倾向性。最后,综合应用前两点成果,提出了一套电力客户投诉闭环管控和服务提升系统,包含投诉预警和针对投诉易发原因的服务提升策略,并结合电力公司的组织结构,丰富和细化了系统架构和运行流程,可达到降低投诉率和提升服务质量的目标。基于文中研究使用的方法和结论,采取以C#面向对象语言为主,R语言和Python语言为辅的方式,形成具有较强人机交互特性的工单处理软件,可分别支持投诉分析与预测、重复诉求提取与分析以及输出服务提升策略,由此将研究成果实现为应用工具,并已投入到实际场景中,协助电力公司开展服务工作。"
197,基于计算机视觉的风机叶片表面损伤检测研究,"风能作为可再生能源,已在世界范围内获得了广泛应用。由于风力发电机的所在环境恶劣、所受应力强烈等因素,风机的叶片表面可能产生裂纹、油污、砂眼等损伤,这严重影响了风力发电的效率和安全性。当前叶片表面损伤检测方法多为人为操作,存在耗时长、效率低、主观性强等缺点。因此,本文基于无人机采集的风机叶片图像,利用图像处理、机器学习、深度学习等计算机视觉技术,针对叶片损伤进行自动检测算法和健康维护系统的研究与开发工作,主要完成以下内容:(1)对风力发电机叶片损伤特性及图像处理理论进行分析,研究了基于Halcon的图像处理方法。对叶片图像进行相机标定、快速自适应加权中值滤波、图像加强、动态阈值分割等操作,完成了对叶片损伤图像的处理和初步识别。(2)对 HOG、Haar-like、LBP 等特征及 CatBoost、XGBoost、AdaBoost 等分类算法进行对比和分析,利用原始和扩展的LBP特征集,并基于AdaBoost开发包括决策树和支持向量机在内的多重级联分类器,形成了 LBP-ADA模型,对叶片损伤进行特征提取和模型训练。通过对图像的旋转、平移、放缩、添加噪点、改变明暗等方式将原始图像进行扩充,形成机器学习图像数据库。(3)基于深度学习理论对微小损伤检测算法进行研究。通过引入特征金字塔网络(FPN)结构对You Only Look Once(YOLO)算法进行改进,提出一种新型的YSODA算法。该算法对YOLO进行浅层和深层的特征图融合,并在其网络结构上增加FPN结构进行高级特征提取。实验测试表明,该算法可有效提高叶片微小损伤的检测精度。(4)以准确率、召回率和加权调和平均数为评价指标通过对多种方法进行交叉实验,表明了 LBP-ADA算法检测叶片损伤的有效性。同时,以准确率和实时性为指标对YSODA算法进行测试,并与LBP-ADA和文献算法进行对比分析,可知本文提出YSODA算法在微小损伤检测方面具有准确度和效率高等特点。最后,将本文提出的多种检测模型应用于实际风机叶片健康维护系统的开发,并成功实施于实际风场的叶片损伤检测中。该系统可自动生成包含风场信息、损伤信息等关键数据的叶片质量检测报告,达到了实际风场的运维要求。"
198,衡水供电公司异常用电大数据分析系统的研究与设计,"日益严重的异常用电与窃电行为不仅损害电力企业的经济利益,还危及到电网的安全运行,一直是困扰电力行业正常发展的难题之一。传统的定期巡检与校验、用户举报窃电等手段严重依赖人力排查,效率低下,而常规的异常用电检测判定方法则误报太多,实用性不高。随着坚强智能电网和泛在电力物联网的建设与发展,电力用户用电信息采集与电力营销业务应用等系统产生的营销计量数据向巨大规模发展,大数据特征日益明显。借助大数据技术对营销计量大数据进行综合分析、异常筛查与即时预警,可以快速提升异常用电分析的效率和准确性。本文通过对营销计量大数据的分析,给出了基于营销计量大数据的窃电用户识别方法。首先,构建异常用电分析大数据集,抽取违约窃电处罚信息、电能、工况、事件记录等原始数据,进行持久化存储。其次,建立正常用电与异常用电的评价指标,提取窃电行为特征,构造样本集。最后,采用分类与回归树(CART)与支持向量机(SVM)等异常检测算法对窃电用户辨识模型进行训练、评估与在线辨识。采用Python与scikit-learn进行了实验测试,采用混淆矩阵与ROC曲线对实验结果分析,验证了方法有效性。本文给出了衡水供电公司异常用电大数据分析系统的物理架构,设计了系统技术架构,包括数据源层、采集层、存储处理层、服务层、接口层与应用层等,满足营销计量大数据的批量和实时采集、批量离线存储和处理、实时在线处理、内存计算、异常用电分析等需求。设计了系统的主要应用功能,包括异常用电分析、异常任务处理、综合查询统计等,对异常用电与窃电行为进行诊断,筛选存在用电异常、违约用电窃电嫌疑的用户,实现多维度查询用户异常及任务处理信息。结合具体案例,给出了台区选择操作、异常用电诊断与统计报表等具体功能实现。"
199,SiC MOSFET开关振荡特性及并联应用器件筛选的研究,"碳化硅(SiC)MOSFET是一种很有前景的开关式电力电子变换器器件。更宽的带隙、更快的开关速度和更高的导热系数,使得其在高压、高温和高频应用中要优于硅IGBT和硅MOSFET等硅基器件。然而,SiC MOSFET的应用仍面临着开关振荡和并联电流不平衡等挑战。SiC MOSFET器件的高开关速度加剧了开关振荡。随之引发的传导振荡使器件的功率损耗增加,并会引起谐波,对电力系统产生不良影响;而辐射振荡则可能会对通信和控制系统造成电磁干扰。因此,了解这些振荡的触发机制和特征是有必要的。除此之外,本文还研究了并联器件之间的电流不平衡问题。SiC MOSFET的器件参数存在着显著的差异性,当器件并联时会导致电流不平衡。而这可能导致局部发热及进一步器件的退化和失效。本文通过对开关瞬态过程的详细分析,揭示了振荡的触发机理,建立了一个简单的二阶RLC等效电路模型。并研究了电路和器件寄生参数的不同对开关振荡的影响。在理论分析和仿真分析的基础上,确定了关断瞬态振荡和峰值增大的原因。实验结果也验证了这一分析。在器件并联筛选方面,首先通过对同批次SiC MOSFET器件产品的测试,确定器件参数的分布情况。在此基础上,提出了一种基于线性回归算法的机器学习模型,用于器件并联前的分选。通过实验结果表明,所提出的器件分选方法能够有效地减小并联器件的暂态和稳态电流不平衡。"
200,基于人工神经网络与支持向量机的负荷预测比较研究,"电力负荷预测已成为电力工程的重要研究内容之一,其是一个复杂的多变量、多维度的估计问题。智能电表及传感器的应用,提供了不同形式分布式能源的大量历史数据,进一步增加了问题的复杂性。传统的负荷预测方法无法准确跟踪负荷随机变化,准确性较差,但基于人工智能的机器学习算法因具有数据建模的灵活性和精确性,具有提高负荷预测准确性的潜力。本文给出了人工神经网络(ANN)短期预测方法和支持向量机(SVM)的短期负荷预测方法。利用支持向量机的核函数对负荷预测中的复杂非线性关系进行建模,建立了多项式核、无线基函数核和皮尔逊函数核函数的三种支持向量机模型。本文比较了支持向量机模型采用不同核函数时的性能,明确了适用于负荷预测的最佳核函数。通过软件WEKA的仿真结果验证了所提方法的性能,确立了支持向量机参数、核的优化以及神经网络模型的参数。基于上述任务,本文收集了巴基斯坦配电网6周的历史数据,并对该数据进行预处理,删除了丢失值和异常值,使数据规范化以获得更好的性能;再利用所得数据对支持向量机模型和神经网络模型进行检验,并基于错误度量指标比较了基于不同核函数的支持向量机模型与ANN模型的负荷预测优劣。研究结果表明,基于PUK的支持向量机模型优于神经网络模型,能够提高系统的负荷预测预测精度。"
201,基于卷积神经网络的输电线路故障快速检测与识别,"在电网系统中,对于输电线路的巡检保护是保障电网能否正常运行的重要环节,多数情况下采用图像处理技术对无人机采集到的海量图像进行识别检测。但由于传统机器学习步骤繁杂,耗时极长,已不适用于对数量庞大的数据集识别检测。而随着计算机技术的不断发展,出现了深度学习算法,它可以自动对图片特征进行提取,使图像在网络中能被更好的识别,同时相较于传统网络有着更强的泛化能力;但在深度学习算法中,浅层神经网络对于复杂背景下的图像识别并不十分理想,由此产生了深层神经网络用来针对数据量较大,背景相对复杂的图像数据集。由于输电线路故障图像的特殊性,故本文选择采用深层神经网络对数据集进行识别检测。本文以TensorFlow为平台,对9类输电线路故障进行识别检测实验,提出使用以VGG16为基础网络的Faster-RCNN的网络用于输电线路故障图像的识别与检测,并通过对RPN网络中batch_size大小的不断调整,确定网络中的正负样本比例,从而达到对网络优化的目的,由此形成输电线路故障检测网络模型。在网络训练过程中,首先对无人机采集到的输电线路故障图像进行分割预处理,并利用图像增强技术对数据集进行扩充,最终得到3300张图像并将其分为训练集和测试集,然后选择合适的基础卷积神经网络,再通过改进RPN网络以及使用软化非极大值抑制对原始的Faster-RCNN网络进行改进,以其作为数据集的检测网络,最后通过网络得到预测框图及其预测分数,经过统计运算获得各类的MAP,得到网络测试集的总MAP为93.68%。通过实验可知,在背景复杂的输电线路故障图像数据集中,运用改进后的检测网络对其进行识别和检测,可以对输电线路故障进行良好的判断。改进后的网络有效的提高了网络的运行效率,对输电线路故障识别准确率也有显著提升。对于提升电网巡检效率,保障电网正常运行提供了新的思路。"
202,基于分类模型的电商用户复购行为预测研究,"电商网站每天服务于亿万的用户,人们在淘宝、京东、当当等电商平台消费购物的同时,会产生海量的数据资料,从中挖掘出潜在的价值便具有重大的意义,合理地利用这些数据可以为用户带来更好的消费体验。本文以某电商平台脱敏处理后的某一时段真实用户、商品和行为数据为研究对象,结合数据挖掘技术和机器学习分类算法,主要研究工作如下:(1)电商用户消费行为数据的特征工程研究。重点研究了数据预处理、特征分析、特征构建和特征选择等技术,挖掘出用户的复购行为特点,构造统计特征、衍生特征和行为衰减等特征,将原始数据转化为高维可训练的有效样本数据,并结合相关系数和随机森林选择出影响用户复购行为重要性前10的数据特征。(2)分类模型的对比研究。从传统用户-商品的角度出发,结合机器学习中的分类算法,选取了常用的逻辑斯蒂回归、Xgboost和支持向量机构建出三种预测模型,通过交叉验证和网格搜索的方式对模型的训练参数进行调优,对比结果发现基于Xgboost算法的模型预测效果要优于其他模型。(3)模型融合方法的研究。通过对模型融合的思想和方法研究,本文使用Soft-Voting方法实现预测模型的融合,经过实验结果论证,融合后模型相较融合前预测精度提升3%左右。本文研究以数据为驱动,针对电商用户的复购行为进行预测研究,从用户-商品和用户-商品品类两种角度分析构建特征,并提出了一种将用户-商品角度下(U-I)预测模型和用户-商品品类角度下(U-C)预测模型进行融合的方案,有效解决了单一角度模型数据敏感且易过拟合问题,可应用于电商业务场景,帮助电商平台实现精准营销,提高用户留存率。"
203,基于多源数据和机器学习算法的土壤水分预测,"旱灾是农业生产面临的最主要的自然灾害之一,特别是在西北干旱半干旱地区。通过对土壤水分进行建模预测和土壤水分的时空分布特征分析,探索科学合理的土壤水分预测方法,提高土壤水分预测的精度,有利于在农业生产管理中充分利用各种资源以提高农产品的产量和品质,对农业防灾、减灾、受灾评估等提供一定的科学依据。以陕西省宝鸡市主要冬小麦种植区为研究区域,基于土壤水分定点实测采样数据、气象数据和土壤容重、潜水埋深、耕层厚度、土壤沙砾占比等多源数据,建立宝鸡市冬小麦种植区土壤水分数据库和预测因子数据库;将机器学习算法(Machine Learning Algorithms)中的随机森林算法(Random Forest Algorithms)、最小二乘支持向量机算法(Least Squares Support Vector Machine Algorithms)和径向基神经网络算法(Radial Basis Neural Network Algorithms)与土壤水分预测因子相结合,建立相应的土壤水分预测模型,对研究区土壤水分进行模拟预测并对不同预测模型进行精度验证评价,根据最优预测模型的预测结果,对研究区的土壤水分进行时空分布特征和冬小麦旱情分析;最后对土壤水分预测因子的重要性进行定量分析和重要性排序,分析各个预测因子对土壤水分及其变化的影响。研究结果以期为土壤水分预测模拟、农作物生产管理和干旱预防等提供较为科学的技术支持,成果如下:(1)将机器学习算法应用到土壤水分预测中,探索机器学习预测模型在土壤水分研究中的适用性,为土壤水分空间预测研究提供新的探索方案;结果表明三种土壤水分预测模型的预测精度都达到了88%以上,证明了机器学习算法在土壤水分建模预测中的良好应用能力。三种模型中径向基神经网络预测模型对研究区土壤水分的预测精度高于最小二乘法支持向量机预测模型和随机森林预测模型,最符合宝鸡市冬小麦种植区土壤水分的实际情况;在三种土壤水分预测模型中,径向基神经网络预测模型和最小二乘法支持向量机预测模型对0~20cm土层的预测效果比20~40cm土层好,而随机森林预测模型则是在20~40cm土层的预测效果略好于0~20cm土层。(2)宝鸡市冬小麦种植区2014年至2018年的3~5月份的土壤水分时空分布的主要特征为,土壤水分年际变化小,月间差异大。从年尺度时间序列看,土壤水分五年来的变化幅度不大,其中,以2015年和2017年土壤水分整体含量略高,以2016和2018年土壤水分整体含量略低;20~40cm土层的土壤相对含水量整体上略高于0~20cm土层,而0~20cm土层土壤水分随时间变化的幅度要小于20~40cm土层。从月尺度时间序列看,土壤水分在3至5月份的变化幅度较大,其中3、4月份土壤相对含水量较5月份低;20~40cm土层土壤水分随时间变化的幅度大体上要小于0~20cm土层,且20~40cm土层土壤水分含量整体上略高于0~20cm土层。从空间分布来看,3月份土壤水分年际变化小,土壤水分高值主要集中分布在研究区西北角的关山中低山区和研究区南部的秦岭中低山区、秦岭北麓黄土低山丘陵区等地,低值主要分布在沿千河、渭河流域由西北向东南一线的渭北黄土台塬区、渭河河谷阶地区、渭南黄土残塬区和渭南、渭北洪积扇区;4月份土壤水分年际变化较大,2014年和2015年土壤水分空间分布特征相似,高值主要分布在麟游县境内的千山地区、千河流域,低值主要分布在西南方向的秦岭北麓地区,2016年至2018年的土壤水分空间分布相似,高值主要集中分布在秦岭北麓地区和关山中低山区;5月份土壤水分年际变化小,高值主要分布在西南方向的秦岭北麓山地丘陵地区、东北方向的千山山地和西北方向的关山山地地区。(3)2014年至2018年的3~5月份,宝鸡市冬小麦种植区的冬小麦旱情发生范围较广,持续时间较长,但冬小麦干旱程度总体较轻,总体为轻度干旱水平,且冬小麦干旱年际差异较小,月间差异较大。从年尺度来看,2015年和2017年旱情较轻,其余年份旱情相对而言稍重。从月尺度来看,三个月份都有不同程度和范围的旱情发生,3、4月旱情范围较大、程度较轻,5月份范围较小但程度较重,旱情整体月间差异不大。从空间分布上来看,冬小麦干旱在陇县境内的千河河谷阶地区以及凤翔县、岐山县、扶风县境内的渭河河谷阶地区和渭北黄土台塬地区发生频率高且程度较重。(4)在2014年至2018年的3~5月份的宝鸡市冬小麦种植区,相比于地形要素、土壤属性要素和地理位置要素,气象要素对土壤水分的影响更大,尤以气象要素中的降水、气温和日照等因子影响最大;且随着时间变化,海拔、风速和降水等预测因子对0~20cm土层土壤水分的影响逐月减小,而地形湿度指数因子对其的影响逐月增大;在20~40cm土层,随着时间变化,纬度和降水对土壤水分的影响逐月减小,而海拔、水汽压、相对湿度和最大风速等影响因子对其影响逐月增大。总的来说,各个预测因子对土壤水分的影响不仅会随着土层深度改变而不同,还会随着时间变化而不同,因此,因时因地地选取土壤水分预测因子,对土壤水分预测的准确度显得尤为重要。"
204,基于机器视觉的红枣表面缺陷检测算法研究,"新疆红枣具有极高的营养及药用价值,又被称为“黄金寿枣”,受到消费者青睐,社会需求量不断加大,激发了企业家产业化经营枣树的积极性。但同时,霉烂、虫害、裂纹等缺陷严重影响了红枣的品质和价值,必须进行分拣。机器视觉技术,具有效率高、精度好、检测信息丰富、非接触等优点,在农产品品质分级领域获得了广泛应用。然而,针对红枣表面的缺陷检测研究仍然在不断地探索和提高,其识别技术则更为困难,是检测与识别中的难点问题。本研究在前人的理论研究和实际应用基础上,利用实验采集平台实现对红枣的图像数据采集。一方面研究采用基于颜色、纹理等特征的最佳组合方式实现特征提取,结合合适的机器学习算法实现缺陷红枣的检测。同时,利用卷积神经网络可以自主学习事物间差异的优点,结合强化学习方法,构建新型卷积神经网络,提高缺陷红枣的检测识别率,本文研究内容分为以下部分。首先,基于图像处理技术的红枣分割方法和图像预处理研究。利用机器视觉图像采集系统,实现视频、图像数据采集。摄像机采集到的图像,由于光照问题、采集系统自身问题以及环境影响,会产生阻碍图像分割、提取和识别等因素,因此研究工作主要使用几何变换、中值滤波、图像增强与形态学操作等图像预处理方法对拍摄到的水果图片进行旋转、去噪、增强等,为后面的图像分割和特征提取做准备。基于特征选择的红枣表面缺陷检测方法研究。根据先验知识,确定红枣缺陷的具体症状表现。研究使用颜色和纹理信息对缺陷红枣进行表征,通过试验确定表征力强的参量作为表达特征向量。再根据得到的特征向量研究选取合适的分类器,通过样本训练实现红枣的缺陷检测。试验选取HSV颜色空间的明度(V)分量作为照度―反射模型输入,进行表面亮度均一化校正,提取R、G、B、H、S、V和亮度校正图像颜色特征。同时,采用融合局部二值模式(Local Binary Patter,LBP)和灰度共生矩阵(GLCM)统计量作为纹理特征,并结合支持向量机分类器实现缺陷检测。最后,基于卷积神经网络的红枣表面缺陷检测算法研究。研究提出一种基于帧间最短路径搜索的目标定位方法和集成卷积神经网络模型(Ensemble-Convolution neural network,E-CNN)。通过建立图像坐标系及图像预处理操作,获得图像中每个红枣目标的位置坐标,并将其映射至空间坐标系中,结合帧间最短路径判定规则,实现目标位置坐标随视频时间序列更新、传递,并且运用此方法能快速、有效地构建数据集。基于“Bagging”集成学习方式,E-CNN通过训练集构建基础卷积神经网络树模型,再根据每棵基础树模型输出结果,通过“投票”方式得出模型最终结果。试验结果表明,利用帧间最短路径搜索的目标定位方法,定位准确率达100%。同时,使用E-CNN模型,模型的识别准确率和召回率分别达到98.48%和98.39%,分类精度大于颜色特征分类模型(86.62%)、纹理特征分类模型(86.40%)和基础卷积神经网络模型(95.82%)。"
205,基于多源高分辨率遥感数据的人工林树种分类研究,"树种的精细分类对于人工林的资源管理和信息提取至关重要,遥感数据因其覆盖广、具有重复探测能力等特点已经成为了树种制图的重要数据源。近年来,高分辨率数据也用于人工林的提取,但大部分是针对单一的类别或树种,多树种精细分类的研究仍然很少。本文以内蒙古旺业甸为研究区,从多时相ZY-3多光谱和立体像对数据中,提取五种类型的变量:(1)基于像素光谱的特征,例如光谱波段、植被指数;(2)基于空间的特征,例如图像纹理;(3)时相特征,例如生长季和落叶季;(4)基于立体像对提取的高度特征,反映不同的林分立地特征;(5)地形因子,例如高程、坡度和坡向。对比分析不同时相数据(落叶季、生长季、两期数据结合)、不同变量组合(V1-光谱波段;V2-V1+植被指数、图像纹理、分割变量、地形变量;V3-V2+林分结构变量)和不同分类算法(最大似然法(MLC)、人工神经网络(ANN)、k最近邻(kNN))、决策树(DT)、随机森林(RF)和支持向量机(SVM))对树种精细分类的影响,结果表明:(1)相比于仅使用光谱波段,多源变量的组合能提高总体地类和森林的分类精度,其中,总体精度提高3.7-15.5%,森林总体精度提高1.0-12.7%,使用支持向量机时,取得最高总体精度为84.5%,使用最大似然法时,取得最高的森林总体精度为89.2%;(2)多时相数据的结合可以提高分类精度,相比于使用单期数据,多时相数据结合时,总体精度提高了7.8-15.0%,森林总体精度提高了6.0-11.8%;(3)仅使用光谱变量时,最大似然法比机器学习算法取得更高的总体精度;但是当使用多源变量时,随机森林和支持向量机等机器学习算法的总体精度要高于最大似然法;林分结构变量的加入,对白桦和樟子松的分类精度有所提高,其他树种的精度没有明显变化;(4)对于单树种,油松、樟子松、红松、杨树和榆树、其他阔叶的树种精度在92%以上,落叶松和白桦的树种精度分别为87.3%和84.5%,但是,这些单树种的最高树种精度来自不同的数据源和分类算法,没有单一的分类算法可以为所有的树种提供最高的树种精度。本研究的目的是为总体地类、森林和单树种分类识别合适的变量和分类算法,研究表明同一数据或分类算法不能为所有的地类提供最佳的分类精度,在以后的研究中可以尝试使用分层分类的方法,分别使用单树种对应的最佳变量和分类方法。"
206,利用机器学习算法预测绵羊全基因组蛋白质互作关系,"绵羊对推动我国畜牧业发展具有重要经济意义。绵羊生产和养殖过程中还有诸如遗传基础与营养调控等相关分子机制需要解析。蛋白质-蛋白质相互作用(PPI)也是在分子生物学中解决上述分子机制的重要入手点。目前尚未发现有关于绵羊PPI的系统预测和研究。基于上述背景,本研究针对绵羊全基因组的PPI进行研究,包括PPI预测以及其数据库的搭建。首先,本研究利用机器学习方法对绵羊基因组范围内PPI进行预测。筛选来源于20个数据库的20类蛋白质注释信息,作为后续计算方法训练用到的特征数据。通过比较6种常见的机器学习方法(随机森林、决策树、贝叶斯分类器、逻辑回归、支持向量机和神经网络),发现随机森林分类模型的准确率可达0.89、精确率为0.99、AUC为0.95,显著优于其他分类器。因此最终确定随机森林作为本研究使用的模型分类方法。针对28,592个绵羊蛋白,本研究预测出820,072对绵羊蛋白互作关系。之后利用共表达以及直系同源数据进一步佐证了预测结果的生物学意义。其次,基于预测的全基因组绵羊PPI数据,成功搭建绵羊蛋白质互作数据库。数据库主要实现数据上传与存储、网络图的展示、相关蛋白质功能信息的展示等功能,为今后深入研究绵羊蛋白质互作及功能提供了有效的数据库资源。该研究为绵羊蛋白质研究提供了一个较完整的数据资源,为深入挖掘蛋白质互作机制、发现某些特定的生物功能提供了数据支撑,为从分子角度解析绵羊生物学机制进而对辅助解决绵羊养殖问题提供了一定的理论依据。"
207,智慧牧业中基于深度学习的羊分娩场景识别算法应用研究,"畜牧业在内蒙古地区国民经济中占有极其重要的地位,而养羊业在草地畜牧业中占有重要的地位。目前,国内外对于母羊分娩的处理办法仍停留在人工发现人工处理阶段。人工操作不能保证及时准确地检测到初生羔羊,稍有延误,就会造成不可逆转的损失。如果使用以人工智能为核心的计算机系统来代替人工进行检测,可以避免很多不必要的损失。既降低了初生羔羊的死亡率,也减少了人力消耗,对实现智慧牧业有很大帮助。本课题从计算机视觉角度来研究羊分娩场景,采用深度学习的方法训练神经网络模型,使模型最终可以检测出羊分娩场景中的初生羔羊。课题选择Faster-RCNN神经网络模型来完成羊分娩场景下初生羔羊的检测任务,由于缺乏针对羊分娩场景的大型公开数据集,故通过采集羊分娩原始数据、筛选可用实验数据、扩充实验数据、标注实验数据来自制羊分娩场景数据集。使用自制的羊分娩场景数据集分别训练基于不同特征提取网络、基于不同覆盖域阈值、基于不同检测框合并算法的Faster-RCNN神经网络模型,通过实验结果以及检测可视化结果的对比,选取针对羊分娩场景中初生羔羊检测效果较好的Faster-RCNN神经网络模型。最后将针对羊分娩场景中初生羔羊检测效果最好的Faster-RCNN神经网络模型应用到实际场景中,使其达到于真实场景中检测初生羔羊的效果。本课题提出的基于深度学习的羊分娩场景中初生羔羊的检测,通过使用自制的羊分娩场景数据集训练神经网络模型,并通过对比实验结果选取检测效果较好的Faster-RCNN神经网络模型,最终可以达到检测实际羊分娩场景中初生羔羊的效果,具有较好的工程应用价值。"
208,基于智能算法的高维生物医学数据集的特征选择策略研究,"随着基因芯片技术在医学领域被广泛应用,大量微阵列数据被迅速积累,通过对这些数据进行分析并构建有效的分类模型,对一些潜在病患的早期诊断和临床治疗具有重要的研究意义和应用价值。然而,基因微阵列数据具有“高维小样本”的特点,如结肠微阵列数据集包含了两千多个基因特征。面对如此大规模的微阵列数据集,专家在短时间内不能直接进行分析和诊断治疗。此外,大多基因数据通常含有一些冗余或噪声数据,可能会导致疾病诊断算法的建模和训练时间过长时的过度拟合而误导,从而导致错误的医疗诊断。作为一种有效的降维方式,特征选择在生物医学领域已经引起广泛的关注并成为近年来生物信息学领域的研究热点。特征选择技术是对微阵列基因数据进行适当分析和分类的关键步骤,如果没有合适的特征选择方法,现有的模型很难准确捕获重要信息。本质上,特征选择问题可以被视为一个双目标优化问题,即在保持或提高预测精度的同时优化特征子集。目前已经存在一些针对微阵列生物医学数据的特征选择方法。其中,基于Wrapper的特征选择方法在搜索过程中旨在获得较高的分类精度而吸引了越来越多研究学者的注意。搜索策略是Wrapper方法中最重要的步骤,基于种群机制的元启发式搜索通常用于Wrapper方法寻找最佳特征子集提高分类性能。本文从提高Wrapper方法的搜索性能入手通过对不同类型的智能算法进行改进来对高维生物医学数据集进行特征选择。主要研究如下:1、提出了一种基于改进克隆花授粉的特征选择策略(IBCFPA)。克隆花授粉算法CFPA是通过Levy飞行公式和自花授粉交替来更新解。为了进一步提高CFPA的搜索性能,引入绝对平衡分组策略,将克隆花授粉算法搜索出的当前最优解进行克隆操作形成新的种群并分组,首先进行组内的局部更新,再进行组间的全局更新。通过自适应高斯突变操作来改善当前最优解,设置一个监管机制来判断搜索到的最优解是否陷入局部最优。实验结果表明,与其他智能算法相比,该方法IBCFPA可以高效选出最佳的特征基因获得更高的分类精确度。2、提出了一种基于改进珊瑚礁优化算法的特征选择策略(BCROSAT)。珊瑚礁优化算法CRO是通过模拟珊瑚礁幼虫的繁殖和进化过程更新个体的群体智能算法。在初始化过程将每个珊瑚幼虫模拟成一个二维向量,构建珊瑚初始种群。通过锦标赛选择策略从所有珊瑚虫中按一定的概率选择一个解来替换初始种群中最差解,不仅增强初始化种群的多样性,而且提高了初始解的质量。为了增强CRO算法的局部搜索能力,将模拟退火算法SA作为CRO算法的局部搜索算子。实验结果表明,BCROSAT算法的搜索性能优于IGA和MPSO等。为了验证BCROSAT算法的性能,使用不同的分类算法KNN,SVM和ELM结合10-折交叉验证来评估该算法的分类精确度。3、提出了基于增强的Wrapper模式的特征选择策略。鉴于Filter方法能够高效地对高维数据进行过滤,提出结合Filter和Wrapper模式的特征选择策略以提高分类的性能。在对基于花授粉算法和珊瑚礁算法的特征选择研究基础上,进一步结合卡方检测,分别提出了基于卡方和花授粉的特征选择策略Chi-IBCFPA和基于卡方和珊瑚礁的特征选择策略Chi-BCROSAT。在初始化过程构建双种群初始化策略,将一部分初始种群个体通过卡方检测来进行预处理,另一部分种群个体通过随机初始化设置。实验结果表明,提出的结合算法Chi-IBCFPA和Chi-BCROSAT的性能明显优于近年来提出混合模式IGGA和IG-PSO,结合后的Wrapper算法能够更高效的搜索出最佳特征子集达到较优的分类性能。"
209,基于中文电子病历文本的医学语义网络构建方法研究,"随着医疗信息化以及计算机硬件的发展,电子病历在我国得到了极大的普及,因此每天产生的电子病历数据爆发式增长,但是电子病历中的文本数据难以结构化从而得到二次利用,电子病历文本挖掘是现在很多学者的研究点,主要集中在电子病历命名实体识别和电子病历实体关系抽取这两个研究任务。英文领域的电子病历文本挖掘已经有了丰硕的成果,国内的研究还处于起步阶段。这是因为(1)缺乏规范统一的专业术语库,电子病历文本中的术语没有标准化,国外成熟的知识库无法对中文领域电子病历文本研究做直接指导;(2)语料匮乏,缺少公开的标注语料以及标注规范,并且电子病历文本具有高度专业性特点,普通人难以识别其中的实体及关系,严重限制了中文电子病历文本挖掘的研究。基于此,文本研究基于中文电子病历文本的命名实体识别和实体关系抽取的方法,从而构建基于中文电子病历文本的医学语义网络。主要工作包括以下几个方面:本文首先分析中文电子病历的数据结构特点和语言特点,提出基于元数据的数据清洗模型。针对电子病历中术语不统一问题,自行标注特定疾病的小部分语料,使用条件随机域(Conditional random fields,CRFs)模型并引入词典实现特定疾病中小语料库识别多术语任务。扩充电子病历命名实体识别标注语料,并为后续实体关系抽取和语义网络构建奠定基础。针对实体关系抽取任务,本文参照统一医学语言系统(Unified Medical Language System,UMLS)语义网络结构,明确本文的实体关系抽取类型。利用长短时记忆模型(Long-Short Term Memory,LSTM)在文本实体关系抽取任务上的优势,将Att_BiLSTM模型移植到医疗领域中来,抽取电子病历文本中句子级别实体与实体之间的功能上相关的语义关系,实验结果证明在TrCP(治疗导致了医疗问题)、TrIP(治疗改善了医疗问题)和TrAP(治疗施加于医疗问题)三种关系的识别上具有良好表现,F值分别达到0.862、0.861和0.862。引入领域知识库UMLS的工具MetaMap获取中文实体在UMLS中的概念形成IS-A关系,不仅与国际知识库建立关系促进中文医学文本挖掘研究发展,还进一步补充了国际知识库的中文语义网络部分。最后本文结合中文电子病历案例数据集,实现电子病历命名实体识别以及两类实体关系抽取的算法实现,构建特定疾病肾癌的医学语义网络,并通过工具Gephi实现语义网络可视化。该语义网络可以促进后续进一步研究如药物推荐、疾病预测、智能医疗问答系统等,具有重要意义。"
210,基于机器学习的脑电信号识别研究,"随着脑科学研究的发展,精准的脑电信号识别不仅可以帮助医生进行疾病的诊治,同时可以帮助患者进行疾病的预测。但是脑电信号的分类研究中仍存在算法复杂度过高导致不适合应用于可穿戴设备中、样本量太少导致分类效果差、数据类别不平衡导致性能不稳定等问题。如何解决脑电信号识别面临的这些关键问题成为推动脑科学进一步发展的重要因素。本文首先分析了脑电信号识别面临的主要问题,同时在了解国内外研究现状的基础上,通过提出相应的算法来依次解决上述提到的三个问题。首先,本文在小波分解得到的多个子频带上提取多种不同类型的时频特征进而组成特征集合,并提出改进的基于相关性的特征选择算法,同时将其应用于特征集合上进一步获得最优特征集,并采用五种分类器对癫痫病患者的发作期、发作间期以及正常脑电信号进行三分类识别。最终使用波恩大学癫痫数据集来验证算法的真实性能,其中逻辑模型树的识别结果最佳,达到了97.2%的分类准确率。该算法通过减少冗余的特征数目,从而达到降低算法复杂度的同时提高分类精度的目的。此外,我们实现了一个基于共空间模式算法和卷积神经网络的癫痫模型。由于癫痫预测数据存在发作前期数据和发作间期数据处于极度不平衡的问题。故本文采用时域分解重构的方式生成发作前期数据,从而达到癫痫数据的平衡。同时癫痫预测数据量并不属于小数据集,因此设计了一个组合共空间模式算法根据数据集特性提取其时频特征。同时,使用我们设计的卷积神经网络(Convolutional Neural Network,CNN)进一步优化特征并进行预测识别。该算法最终被应用于CHB-MIT数据集,达到了92.2%的敏感性和0.11/h的误报率,实现了较高的敏感性以及较低的误报率。最后,因为脑电信号数据采集过程较为复杂且招募受试者也较为困难,所以通过以下三种方法进一步改进共空间模式算法使得该算法更适应于小样本数据集的脑电信号的分类识别:(1)通过引入非目标用户的协方差矩阵降低目标用户的协方差矩阵估计方差,从而实现正则化协方差矩阵。(2)通过正则化目标函数即添加一个惩罚项至目标函数中从而减小噪声的影响同时增加整个算法的鲁棒性。(3)因为脑电信号具有较强的个体差异性,因此应用小波包获得具有相同大小的子频带,进而使用前两步中的改进共空间模式方法在所有子频带上提取特征,同时应用最大相关最小冗余算法选取与类别相关性最大、与其他特征相关性最小的特征子集,最终,线性判别分析算法得到的较高的准确率(82.01%)显示了改进方法对小样本数据较强的分类能力。本文针对现有的脑电信号识别面临的主要问题,提出了针对三种不同情况的分类识别算法,并应用于不同的数据集中,能够很好的满足面临不同问题的脑电信号分类任务的需要,可以为其他分类任务提供有效的参考途径。"
211,基于长短时记忆神经网络的脑血管疾病预测系统研究,"脑血管疾病具有发病率高、致残率高、复发率高以及死亡率高的特点,目前该病患病人数和死亡率在各国都已经居于首位,脑血管病发病后,再发病的危险性是一般个体的9倍,复发率明显增加,这也强调了脑血管疾病的二级预防的重要性,所以脑血管疾病的预防研究成为目前医疗领域重点发展的方向。构建疾病预测模型是脑血管疾病预防的重要手段。在此背景下,为了进一步提高医疗水平,对脑血管疾病实现预防,论文中构建了脑血管疾病预测指标体系,结合长短时记忆(LSTM)神经网络对具有时序性特点的医疗数据的适用性,构建LSTM神经网络的疾病预测模型,实现脑血管疾病的复发风险等级预测。本文的主要研究内容如下:(1)新型诊疗模式和预测指标体系的构建。分析了目前脑血管疾病的诊疗模式以及存在的局限性,提出基于疾病预测的新型诊疗模式。在Essen等风险评分量表的基础上,提出一种基于领域粗糙集的前向贪心属性约简算法,建立了包含6个一级指标、18个二级指标的脑血管疾病预测指标体系。(2)脑血管疾病预测模型的构建。结合收集的脑血管疾病数据的时序性特点,基于LSTM神经网络建立脑血管疾病的预测模型,使用训练数据进行模型参数调整,采用Adam算法优化模型,最终完成模型构建。用测试数据评估模型性能,并将预测结果与支持向量机(SVM)预测模型结果对比,验证模型的有效性。(3)脑血管疾病预测系统的设计与实现。通过对系统功能、非功能需求分析和设计,完成疾病预测等主要功能模块的开发,实现LSTM预测模型在脑血管疾病预测系统中的应用,并提出预测系统的应用建议。本文使用领域粗糙集理论完成了预测指标的筛选,并将LSTM神经网络应用到脑血管疾病的风险等级预测中,实现了疾病的复发风险预测和个性化干预,降低了疾病的复发率和死亡率,为脑血管疾病预测提供了一种有效的方法。"
212,基于深度卷积神经网络的肝脏静脉血管的分割研究,"血管尺寸很小且分支结构异常复杂,因此血管的自动分割迄今为止仍然是医学图像分割的一个巨大挑战。传统的血管分割算法有阂值法、区域生长法和形态学法等,这些算法不是需要人工参与,就是对那些对比度不明显或存在疾病的血管分割出现问题,且分割效果不佳。基于神经网络的医学图像分割无需人为设计特征量,可以自动从大量样本图像中学习图像特征,实现图像分割的目的。目前,实现了医学图像中眼底血管、脑血管和肺血管的分割,而肝脏中的血管与器官对比度不明显,分割难度较大,因此很少有人将其用于肝脏静脉分割,因此,本论文尝试用深度学习的方法自动学习血管的特征,对CT图像中的肝脏静脉血管进行分割。本文提出的基于二维卷积神经网络的血管分割算法,对肝脏静脉血管有良好的分割效果,但二维卷积神经网络丢失了 CT图像的三维信息,影响分割精度。为了提高血管分割的准确率,本文在二维卷积神经网络的基础上设计了三维卷积神经网络,应用于肝脏血管的分割。本文提出的基于深度卷积神经网络的血管分割算法,使用不同大小的数据块作为输入,并通过多层卷积神经网络来获取图像的特征,最终实现血管的自动分割。具体从以下几个模块对肝脏静脉血管的分割进行研究:(1)首先采用灰度变换增加CT图像的亮度和对比度,在初期样本标记的繁琐过程中,使用阈值法和三维打标签的方法,减少工作量和节省了很大一部分的时间和精力。最终在专业医师的指导下,结合手动来标记血管样本,完成了血管的金标准采集工作。(2)提出基于二维卷积神经网络的血管分割算法,通过输入不同大小的图像块,不断调整网络的结构和参数,利用Google开发的深度学习的框架TensorFlow进行数据流的处理。最终,针对不同大小图像块的训练得到的模型进行测试,得出了在输入图像块大小为25*25的时候,血管分割的实验结果的Dice相似系数、准确率、召回率相对较好,Dice相似系数可达到0.9031,准确率为0.8161,召回率为0.9989。(3)针对第三章提出的深度卷积神经网络的血管分割算法仅局限在二维的基础上,考虑到CT图像的特殊性,提出基于三维卷积神经网络的血管分割算法。最终,基于三维卷积神经网络的肝脏静脉血管分割的算法的Dice相似系数提高到了 0.9243,准确率为0.8611,召回率为0.9976。实验结果表明了三维卷积神经网络的算法的可行性,可以获得比二维输入数据更好的实验结果。"
213,计算机辅助颅骨性别自动识别方法研究,"颅骨性别识别是法医人类学的热门研究课题之一,在刑侦、考古、人类学等领域具有重要研究价值。传统的形态学方法和测量法,依赖专家主观经验、测量精度要求高且操作繁琐,导致性别鉴定误差大和鉴定过程复杂耗时。计算机辅助颅骨性别识别不仅有效地缩短了颅骨性别鉴定的周期,避免了测量时对颅骨造成二次破坏,而且识别率高。因此,以三维颅骨作为研究对象,结合图像处理技术和机器学习方法对颅骨进行性别分类研究成为热点。针对传统方法存在的问题,本文提出两种自动化的颅骨性别识别方法,实现三维颅骨的性别识别。本文研究工作主要包括:(1)提出了一种结合统计形变模型和支持向量机的颅骨性别鉴定方法。首先,为了科学有效地建立统计形变模型,需要对所有颅骨样本建立点对应关系,利用TPS算法变形进行全局非刚性粗配准,再使用ICP算法进行精细配准,最终实现所有颅骨配准,建立它们的点对应关系;然后,利用PCA建立颅骨的统计形变模型并求解模型参数,得到颅骨的特征向量;最后,利用支持向量机方法对提取的特征向量降维并设计分类器,实现对颅骨的性别分类。实验结果表明,统计形变模型可以更有效地表征颅骨,能够取得较高的准确率。与以前的方法相比,这种方法不是测量距离或体积相关的变量,而是描述颅骨全局形状变化。当统计形状模型和判别函数建立时,未知颅骨性别的确定变得很容易,不需要专业知识和繁琐的手动测量,还能保证较高的正确率。(2)提出了一种结合改进卷积神经网络和最小二乘法的颅骨性别鉴定方法。首先,获取颅骨多角度的图像,得到颅骨训练样本集;然后,用改进的CNN获取颅骨特征并计算颅骨图像分别属于男性或女性的概率,挖掘图像内容深度信息;最后,利用最小二乘法进行特征融合获取最优参数,进而构建分类模型,最终实现了完整颅骨和非完整颅骨的性别鉴定并获得较高的识别正确率。实验结果表明,该方法能够获得较优的分类性能。从多角度颅骨图像获取颅骨特征,提高了颅后部分对二态性的影响,有效地减少了由人类视觉和主观因素造成的误差,也减少了时间消耗和繁琐的预处理;与传统机器学习方法相比,深度学习算法更适合大样本数据集,而且它的学习能力强,分类精度高,对噪声数据鲁棒性和容错性较强。"
214,基于词典和机器学习的中文小说的情感研究,"书籍是人类进步的阶梯。作为精神食粮,书籍对人们产生着巨大的影响。在这日新月异的科技时代,如何从海量书籍中选择优秀作品对读者而言是重要的,怎样创作出优秀作品脱颖而出同样值得创作者思考。探寻成功小说的共有模式并客观地理解该模式是解决上述问题的有效方法。小说作为常见的文学体裁,具有极高的研究价值。基于小说的情感动态变化可作为剧情发展的高度代理这一理论基础,本文从计算机角度出发,以小说的动态情感变化曲线为切入点结合随机分形理论进行探究。传统的文本情感分析主要集中于对短文本的情感极性分类与标注,对长文本的情感研究并不多见,适合中文小说情感分析的语料较为缺乏,且传统的情感分析停留在对结果的归纳与总结,缺乏对研究结果的进一步探究。针对以上不足,本文工作内容如下:(1)针对研究语料缺乏这一问题,结合当前情感分析研究现状、自身研究条件和小说表现手法多样,上下文联系紧密等特点。本文以大连理工大学出版的《情感词汇本体库》为基础词典,从以下三个方面对其扩充与调整:1.利用Word2vec构造词向量,计算词向量的余弦相似度、基于同义词词典的语义相似度和点互信息实现新词发现。2.构造专属小说情感研究的情感-意象库。3.利用现有情感资源进行词语搭配以扩充词汇量。以此构造中文小说情感词典。(2)本文引入随机分形理论深度解读小说情感曲线。利用自适应分形分析方法去除情感曲线的总体趋势,考察波尺度与残差之间的幂律关系,计算Hurst指数以刻画情感曲线的长程相关性并将其作为特征,以此探索优秀小说的共有模式。为验证结论具备一定合理性,本文将Hurst参数与书籍的豆瓣评分及当当网的销量数分别做相关性分析用以验证。实验结果表明:本文提出的改进情感词典的方法可有效地进行词汇扩充,使之更准确地捕捉情感变化;94%优秀中文小说的情感动态曲线的特征值Hurst均大于0.5,这表明成功小说的情感动态变化普遍具有持续的长程相关性这一共同模式,同时从动力学角度提供了一种机制来解释小说成功的原因。实验验证了 Hurst参数与豆瓣评分,书籍销量均具有较强的正相关性,这证明了 Hurst参数可作为客观衡量中文优秀小说的参考指标且具有一定的合理性。"
215,基于神经网络对鼠标移动轨迹的情绪识别,"情绪是当今每个人在生活中不可忽视的一部分,所以人们的情绪状态的识别非常重要。针对情绪识别问题,传统的方法主要是对人们的外在行为指标或人们的生理信号进行个体情绪识别研究。但是这些信号的收集过程比较困难,需要志愿者的高度配合或是需要高成本的可穿戴设备进行数据收集。在目前人工智能发展盛况空前的背景下,本文基于神经网络提出了多种对鼠标运动轨迹的情绪识别的方法。对人们在使用计算机时的情绪状态进行识别,具有一定的商业价值。对于互联网企业而言,可以提供令客户更加满意的服务。本文具体研究内容及结果如下:1.在建立数据库时,本文采用的是征集志愿者人为收集的方法。收集到的数据先经Excel软件应用VBA程序做批量处理,之后送入matlab软件中做矩阵变换处理。最后生成规范统一的数据集。2.在构建BP神经网络模型时,本文创新性地采用了积分变换和统计分析两种特征提取方法。经过训练和测试之后统计不同状态下的情绪识别正确率,实验结果表明:对于不同个体的情况,两种方法的结果互有高低,且都有不错的效果。但是在某些极端的情况下,对于个体操作鼠标习惯差异较大时,其结果就显得不尽人意了。这也是后续研究中所需要解决的一大问题。3.在完成浅层BP神经网络的实验后,本文还引入了深度神经网络模型。本文采用了三种不同的网络模型:CNN、ResNet以及RNN。在Keras深度学习框架中分别进行训练和测试,最后实验结果表明:卷积神经网络模型与残差网络模型均能得到不错的结果,且残差网络模型的效果是本文所有模型中最好的,最高的测试结果能够达到98%的识别正确率,更好的地方在于其结果都相对BP神经网络模型更加稳定。但是对于循环神经网络而言,其结果表明这个模型不适用于解决本文中的研究内容。总的来说,本文前三个模型已经可以达到预期的效果,对于收集人们鼠标移动轨迹来识别计算机使用者的情绪状态的方法是有效的。"
216,回归算法在智商预测中的应用研究,"智商(IQ)可以综合衡量个体认知能力的差异,被临床心理学家视为具有临床意义的有效统计指标。目前的智商评估主要是通过主观量表评分实现的,存在很大的主观性和不确定性。磁共振技术的出现,使得研究智商个体差异的脑机制成为可能,而现代机器学习技术的发展为基于磁共振图像开展智商的客观评估提供了有效工具。本研究基于76名18-55岁成年人样本的脑静息态功能磁共振图像,提取160个脑感兴趣区的fMRI信号时间序列的相关性度量脑区之间的功能连接强度,并以这些功能连接强度为特征,以智商值为标签,构建预测模型实现对智商的有效预测。具体研究工作如下:(1)基于经典回归算法的智商预测研究。基于脑功能连接特征,本研究采用基于集成学习、树模型、核方法、线性模型等四类(共12种)算法构建预测模型。留一法交叉验证实验结果表明,基于线性模型的预测表现要优于其他算法,而在基于线性模型的4种算法中,有对特征进行选择的算法得到了更好的结果。(2)基于主动学习的智商预测研究。主动学习算法可以有效处理没有足够的训练样本的情况,因而适合本研究的小样本场景。本研究中基于贪婪取样的预测模型和基于期望变更最大化的预测模型,分别结合岭回归、支持向量回归、弹性网回归方法,构建智商预测模型。实验结果表明,主动学习方法的应用可以提升预测效果。(3)基于迁移学习域适应方法的智商预测研究。本研究分别基于模型融合的域适应(DAMF)、加权正则化域适应回归(WARR)两种算法,构建智商预测模型。实验结果表明该方法引入对提升智商预测效果作用有限,提示我们的“源域集和目标集数据分布不一致”假设可能不适用于当前研究问题。综上,本研究基于人脑的RS-fMRI图像,结合经典回归算法、主动学习算法、迁移学习域适应等机器学习算法,对成年人的智商进行预测。实验结果表明采用经典线性回归模型可以达到很好的预测效果;主动学习算法的引入可以有效提升预测效果;迁移学习域适应算法的引入在提升智商预测效果方面作用有限。本研究的创新性在于:(1)系统地比较了多种经典回归算法在基于静息状态fMRI的智商预测方面的效用;(2)率先将主动学习算法结合回归算法应用于基于静息状态fMRI的个体认知参数定量评估;(3)率先校验了域适应算法在基于静息状态fMRI的个体认知参数定量评估方面的有效性。"
217,档案学视角下区域政务微博的知识发现模型研究,"利用政务微博这一社交媒体平台发布区域政务信息、倾听社情民意已成为我国地方国家机关政务信息活动的重要形式,相应地,地方机关通过微博平台提供的政务信息服务使得用户能够迅速知晓、概览本地重要新闻与热点事件,并从中汲取信息、获取知识。伴随着用户的信息阅读方式由全文化转变为碎片化,以从全文中提炼出的信息单元或知识单元为基本要素聚合而成的知识地图在节省读者时间、提高读者知识吸收效率方面具有重要价值。基于以上两点,同时为尊重信息单元与知识单元的来源关系、保证知识组织与知识发现的质量,本文提出了一种档案学视角下的区域政务微博知识发现模型,旨在对具有文件、档案属性的政务信息资源进行知识化开发,方便用户的知识吸收与利用,进而提升地方国家机关的政务信息知识服务水平。首先,本文对区域政务微博、档案信息资源的知识发现、社交媒体文件等核心概念进行了阐释,并对国内外相关研究进行了综述与总结,指出了本文在研究过程中的理论依据与应用的核心技术体系。其次,以档案学应用理论为基础,融合图书情报学的理论成果对经典档案学理论进行了有机整合与六元组形式的描述,阐明了其在知识组织与知识发现过程中的价值。再次,基于整合的档案学理论,借助以LDA主题建模和依存句法分析为核心的自然语言处理技术与以应用本体构建为核心知识组织技术,完成了区域政务微博知识发现模型的构建工作,确立了“原文本数据-聚类数据-信息单元-知识地图”的数据挖掘与知识开发流程。最后,以西安市为区域实例,以“专题-事件”为微博内容类别的划分标准,利用爬虫软件采集相关微博文本进行实证分析,以知识地图作为知识发现的可视化成果,结果表明本文整合、构建的理论与模型在实践层面具有一定的可行性。本文构建的档案学视角下区域政务微博的知识发现模型能够在一定程度上为区域内政务信息资源的整合与开发利用提供帮助,同时帮助用户提高知识识别与利用效率。然而,本文在理论整合的合理性、知识组织与知识发现的精度与深度、实验的信度与效度方面还存在较大的改进与提升空间,以深度学习为基础实现知识的动态表征与推理、增强全模型的智能化水平是其后的主要研究方向。"
218,指纹方向场识别技术研究,"当前社会,指纹识别技术已经取得了许多的进展,并已经进入了产品化的阶段,在电子产品,安全,刑侦等领域有着广泛的应用。但在刑侦领域,很多情况下,由于指纹提取环境的复杂性和长时间的环境侵蚀作用,提取指纹的质量很差,甚至无法通过肉眼进行辨认,这对嫌犯的确认工作等造成了很大的困难。对于这类低质量指纹,在指纹的增强复原和比对之前,通常需要通过提取方向场来辅助去噪。本课题面向应用,通过结合深度学习技术和传统图像处理算法,实现低质量指纹的方向场提取。本文提出的要求是做出一套能提取更精确的指纹方向场的算法系统,来替代原始系统中的指纹方向场提取部分。本文对指纹方向场提取系统进行了设计,并解决了系统中指纹特征提取难,网络收敛难,输出相互平滑等问题,并对系统提取指纹方向场的效果进行了测试和验证。首先,针对系统整体设计,本课题总共给出了三种可能的方案,分别是是直接解码,聚类方案和传统视觉结合深度学习的方案。经过验证,最终直接解码和聚类方案由于在现场指纹上表现较差被排除。其次,针对系统中的传统视觉算法,本文设计了系统的图像预处理部分。预处理分别两个部分。首先是对图像中主要噪声的滤除。卡通-纹理分解能够有效的提取图像中的纹理部分,但仍然会保留大量的纹理噪声。之后使用频域滤波可以滤除大部分纹理噪声。第二部分是指纹有效区域的提取。指纹图像包含了大量非指纹的部分,还有很多区域指纹纹理破坏过于严重,导致很难还原。剔除这些区域对于指纹方向场预测的准确性有比较大的提升。同时,本文设计了系统中从预处理的指纹图像中提取方向场的深度学习网络。模型基于语义分割网络,并针对语义分割网络在本文环境中应用产生的问题进行了改进。网络输出改为回归型之后收敛速度和准确度得到了很大提高,加入机器学习提升算法后解决了由角度定义造成的角度鸿沟问题。本文也设计了针对本项目的相应损失函数。最后,本文为测试系统性能,设计了相应的定量测试实验。本文最终的算法系统在使用弱标签的情况下一次匹配准确度指标精度超过了0.85,达到并超过了原始系统的准确率,充分证明了算法的泛化能力和可靠性。"
219,基于统计学习方法的空气质量评价与分类,"空气质量水平与人们的生产生活息息相关。《2018全球环境绩效指数报告》中显示,中国的环境质量在全球180个国家地区中排名177位,空气污染问题是当下亟待解决的问题之一。为有效开展下一步空气污染治理工作,需要对空气污染数据进行深入研究,探寻其发展趋势和变化特征。科学合理地对空气质量进行评价和分类,为改善城市空气质量提供合理有效的建议。本文研究样本为全国31个省会城市2013年12月1日至2018年12月28日的空气质量数据与天气数据。采用缺失森林填补法对原始数据集进行数据插补,使用统计学习方法从时间维度对数据进行深入研究,建立多种机器学习模型对31个城市空气质量进行评价和分类,并从多角度进行模型性能度量。本文的主要研究工作有:(1)对空气质量整体情况分析并分年度统计首要污染物。发现空气质量指数较高的城市多为北方城市,且季节波动较大。2016年之后,_3O逐渐取代PM_(2.5)成为一些城市的首要污染物。(2)根据污染物数据对省会城市进行聚类,并对典型城市空气质量进行时间维度分析。使用主成分分析与层次聚类相结合的方法,将31个省会城市划分为3类,并选出典型城市南宁、北京、郑州。自2014年以来,空气质量指数年均值呈下降趋势,全年空气达标天数均在2018年达到最高。北京的AQI月均值在每年的5-7月呈现反弹趋势,这是由于北京市5-7月份_3O均值达到最高值,且为占比最高的首要污染物。AQI均值在周内各天均值并无明显差异,周变量不是影响空气质量指数的关键因素。(3)为避免AQI单指标评价的片面性,本文综合考虑污染物质量浓度、天气以及周期等因素,选取三种机器学习方法对空气质量等级进行分类预测并进行模型优选。从算法预测精度来看,随机森林相比BP神经网络提高了4.18%,GBDT算法相比BP神经网络提高了4.55%,预测精度达到了98.89%;从模型的运行时间来看,随机森林模型相比神经网络减少了61.766s,GBDT模型相比神经网络减少了66.964s;从宏查全率、宏查准率以及宏观F1指标来看,GBDT算法均有较好的表现。可以将GBDT算法有效用于空气质量等级分类。"
220,多级聚类演化的随机SVM集群在fMRI上的应用,"大脑是由数以千亿的神经元相互连结形成的复杂生物器官,在大脑的结构和功能上进行探索与研究,有助于阐明大脑的运行机制,对及时干预和治疗神经系统变性疾病有着重要的指导作用。功能磁共振成像作为一种非侵入性的新兴神经成像手段,为探究大脑的神经功能活动提供了客观、有效的数据支撑。本文基于功能磁共振成像,创新性地提出了多级聚类演化的随机支持向量机集群(Multilevel Clustering-evolutionary Random Support Vector Machine Cluster,MCRSVMC),并运用该方法分别对阿斯伯格症和轻度认知障碍展开研究。本文的主要贡献描述如下:(1)提出一种新的MCRSVMC算法。在对多个SVM基分类器进行组合的基础上,引入聚类演化的方法构建MCRSVMC,以提高模型的最终分类性能。MCRSVMC可以用来实现特征选择,并进一步检测疾病的异常脑区,为神经系统变性疾病的诊断研究开拓了新的思路。(2)利用MCRSVMC对阿斯伯格症的分类诊断展开应用研究。首先从ABIDE数据库下载63个阿斯伯格症患者和72个正常对照的静息态功能磁共振成像数据,然后构建图论拓扑特征,最后采用MCRSVMC算法对患者和正常对照进行分类。结果表明,基于最优特征的准确率为95.24%,并且可以找到额中回、海马、补充运动区等病灶。该研究结果表明MCRSVMC算法能够有效地帮助医师对阿斯伯格症患者进行辅助诊断。(3)利用MCRSVMC对轻度认知障碍进程展开应用研究。首先从ADNI数据库下载36个正常对照、42个早期轻度认知障碍和38个晚期轻度认知障碍患者的静息态fMRI数据,然后构建图论特征,最后利用MCRSVMC对轻度认知障碍进程的不同阶段进行多组实验。基于最优特征,MCRSVMC在正常对照组和早期轻度认知障碍组的分类上达到了89.47%的准确率,在早期和晚期轻度认知障碍组的分类上达到了90%的准确率。在检测病灶的过程中,发现海马旁回和后扣带回等脑区在两组实验中同时出现异常,说明这些脑区在“正常认知早期轻度认知障碍晚期轻度认知障碍”的演变进程中起着关键的作用。这些实验结果展示了MCRSVMC方法在追踪轻度认知障碍发病路径中的巨大潜能。"
221,基于关联挖掘的教学评论情感分析研究,"随着互联网普及程度的上升,网络直播教学、微课、MOOC等多种在线学习方式也如雨后春笋般发展壮大。在教育领域内,教学评价是教学活动中极为重要的一部分,其主要构成是教师教学过程的评估和学生学习效果的价值判断,目的是使得教学的改进工作有的放矢。当前,各类网络学习技术不断完善,但教学的评价工作却相对滞后,导致各大网络学习平台虽有百家争鸣之势,内容却纷繁芜杂,无法让学生快速定位,为了提高在线课堂的质量,提升学生的学习兴趣,加强教学评价环节已是刻不容缓。当前网络在线学习平台的教学评价的形式主要是等级评定和留言评论,对于数量庞大的评论文本,要快速定位评价内容,使用机器学习方法进行情感分析也是必然趋势。综合国内外研究现状来看,当下情感分析的研究主要采用SVM、ANN等监督式的学习类方法,不管采用哪种方法进行情感分析的研究,方法自身都有一定的局限性,从而影响实验操作过程,或无法得到理想的实验结果。例如,支持向量机(SVM)算法难以对大规模的样本进行模拟训练,在多分类问题方面表现较差。本文所涉主题范围主要为在线课程学习,本研究旨在探究情感分析新方法,拓展情感分析方法的多样性,以便在面对不同的研究样本类型时,研究者可以有更多的选择空间,同时能选取更适合研究样本的研究方法。本研究方法是通过获得开放式在线教学的反馈评论并采用的新的情感分类方法,并将语境的情感分为正面或负面,来确定教学情感语境下对开放式反馈的最佳分类。本研究采用了一种基于关联挖掘,称为情感短语模式匹配的新方法。模型分析的对象为网络在线学习平台课程的开放式评论,从在线学习平台中提取参与者对课程的观后评论作,并允许学生向教师或平台反馈影响教学和学习的因素。所采用的方法由四个主要阶段组成:(1)通过情感词典收集反馈数据并执行标记;(2)使用基于关联挖掘方法,情感短语模式匹配(SPPM)分析情感分析短语,结合情感词组频率,利用前向双向遍历,将教学反馈句子中的多个词组分离出来;(3)根据已有的情感词典的情感极性分值进行情感分析;(4)使用支持向量机(SVM)算法对数据进行二次分析,再与本研究实验结果进行横向对比,验证情感分析结果,校验本研究实验的有效性。本研究方法的优越性主要在于方法的易操作性,早先的大多数研究操作过程过于专业化,难以推广使用。本研究实验结果是根据评价指标体系(准确率、精准率、召回率、F1分数)判断研究效果,本研究采用的方法所得出的结果在多方面优于支持向量机(SVM)算法的表现。经对比试验证实,本研究采用的方法――情感短语模式匹配,在文本情感分析方面能达到情感分析的真实目的。在研究过程中发现,国内的情感分析研究与国外相比还有很大差距,主要表现在情感词典方面,分类不够详细多样,缺少极性值评估,词库更新力度不足。希望今后的研究学者们可以加强该方面的研究,促进文本情感分析的健全发展。"
222,在线学习环境下基于眼部状态识别的学生注意评估研究,"近年来,在线学习尤其是大规模开放课程得到了迅速的发展。在线学习消除了人的年龄、身体状况、个体接受能力差异等在传统学习中不可回避的某些障碍,使得任何学生可在任何地点、任何时间学习任何内容。此外,信息通信技术和基于多媒体的技术的发展也为监测,分析和预测学生学习行为的趋势和模式创造了机会和条件。这种类型的分析可以帮助教师设计一种新的有效的教学方式,并以更好的方式提供教学内容。在线学习过程中,由于教师和学生被网络空间分离,学生与教师之间缺乏情感上的交流,并容易使学生产生厌学等负面情绪导致学生注意力不集中或放弃学习。因此如何评估在线学习系统中学习者的注意状态,得到对学习者认知、情感有效的反馈,对制定更有针对性和吸引学习内容起到重要作用。这项研究旨在提出一种学生视觉注意状态评估算法。通过分析这学生学习时的视频源并提取视觉注意特征来解决学生面临的注意力问题。为了评估学生注意状态本文首先解决学生学习情况下学生的眼睛定位、人眼状态的评估等问题。本文的主要工作包括:(1)学生的眼睛定位:为了定位学生眼睛,本文首先使用Adaboost和监督下降法来检测人脸并提取人脸68个特征点。经过大量实验,我们发现监督下降法算法可以达到精确的定位学生的眼睛。这部分实验为后面的眼部状态识别和学生注意评估打下基础。(2)学生眼部状态识别:提出了基于Gabor和支持向量机的人眼状态识别算法。其中Gabor滤波器可以提取代表眼部的细节特征,然后使用支持向量机对这些特征进行分类。通过实验对比,我们发现Gabor和支持向量机优于现有的算法。(3)学生注意状态评估。我们综合人眼定位、人眼状态。使用PERCLOS准则对学生的注意状态进行打分。并通过仿真实验,证明了算法可行性。"
223,贴片元件安装缺陷机器视觉检测技术研究,"随着电子制造技术的发展,电路板上元件贴片安装(SMT)已广泛采用自动光学检测技术(AOI)进行安装缺陷检测。目前AOI设备基本都采用统计建模、模板匹配的检测方式,可靠性高、速度快。但每次更换产品型号,都需要重新进行统计建模,要通过对人工目检为合格的样本进行统计学习以建立模板,然后进行自动检测。这种建立模板方式耗时且繁琐,所以AOI设备在小批量多品种的电子制造企业应用效果不好。本文研究了基于深度学习的贴片元件焊接缺陷检测方法。在AlexNet网络的基础上建立深度卷积网络,通过对大量各种型号的电阻、电容等小型元件的焊接样本进行学习,然后对不同型号的电阻、电容元件的焊接缺陷可以进行有效检测。这样建立了通用方法,对不同型号产品,只需判断电阻和电容等元件位置,即可进行其焊接缺陷检测,避免了更换产品型号后需要重新建立模板的环节,提高了生产效率。深度学习能够直接从输入的图片中提取分类特征,并通过多层卷积网络得到高层次的抽象特征,找到焊接缺陷图像的共同特征,对于不同型号的元件都能做到准确快速的焊接缺陷检测。实验结果表明,本文提出的基于深度学习的贴片元件焊接缺陷检测方法,能够高效地实现不同型号元件的焊接缺陷检测。另外,本文对贴片元件安装缺陷检测过程中的元件定位、快速型号检测问题进行了研究,并进行了创新设计。对于贴片元件的定位,采用了PCB元件信息提取与最小外接矩形检测技术相结合的方法,就元件定位和偏转角度检测进行了研究,在许可的检测精度误差范围内提高了检测速度。对于贴片电阻型号检测问题,本文设计了字符特征编码与光字符验证相结合的型号检测算法,该算法通过对字符进行灰度跳变检测并编码,进行字符验证,只需要在检测线位置进行扫描,不用进行每一个像素点的比对,也不用分割出单个字符,该算法不仅对元件具有良好的鲁棒性,而且提高了贴片元件型号的检测速度。通过对PCB贴片安装生产线采集图像进行的实验室检测实验,验证了本文方法的有效性,进一步将应用于改进AOI设备的性能。"
224,工业互联网背景下F公司精益六西格玛应用研究,"近年来随着工业4.0、工业大数据、人工智能、工业互联网等新技术和新概念的推出,掀起了第四次工业革命,把制造业带入了智能制造时单。随着新技术日新月异的发展,智能手机各项关键技术加快了普及步伐,导致行业竞争逐渐加剧。各开发商为了求得一线生机或者为了占据行业食物链的顶端保留自己的竞争优势,不断加快研发速度,缩短产品生命周期,压缩产品需求批量。这些行业因素给传统制造业,尤其是对习惯了大批量生产的手机单工行业巨头,带来了巨大的挑战。精益六西格玛生产是从宏观的流程的角度对整个流程进行改善,消除的是库存,搬运,等待,过多过早的加工,维修、重工的浪费,过度加工的浪费,动作的浪费,管理的浪费等八大浪费。并从微观的角度以数据为基础,消除的是变异,提高的是品质,从而对系统的解决公司面临的品质、效率和成本问题,提供了有效的方法。本文通过对六西格玛和精益生产结合起来的精益六西格玛的应用进行研究并在F公司目前面临的管理问题中进行实践性的尝试。在解决问题的过程中充分考虑了工业互联网这个时单背景,将工业互联网技术充分融合在精益六西格玛的推动过程中。使新技术服务于精益六西格玛的导入,弥补精益六西格玛的短板,使精益六西格玛更好的解决F公司的问题。通过对F公司运营方式和面临管理问题的分析,讨论了在工业互联网新技术革命背景下精益六西格玛在F公司应用的切入点和实施一般路径。通过对于F公司精益六西格玛应用推动的研究,寻求对F公司目前面临的管理问题的解决。对F公司的核心竞争力的提高有一定的帮助,同时也对同分企业提供一定的借鉴价值。"
225,基于机器学习的工业物联网设备故障诊断系统的设计与实现,"传统工业设备维护的计划性维修模式,导致设备维护不及时、维修成本高等问题。人工智能技术的应用为设备故障诊断提供了新途径。目前多数针对智能设备故障诊断的研究局限于算法理论方面,且受限于有限的公开数据集,模型的数据维度有限,实际可操作性不强。本文结合实际工业物联网应用场景,研究了工业数据采集技术和基于机器学习故障诊断算法,针对滚动轴承部件设计研发了工业物联网智能设备故障诊断系统。本文主要工作包括:(1)设计了工业物联网数据采集系统和设备故障诊断算法。论文分析了工业物联网设备故障诊断系统需求,针对数据采集系统的设备接入、本地网关和云平台三个模块,设计了系统硬件组织架构、数据传输网络架构和系统软件架构。论文采用数据挖掘技术和机器学习算法,研究了实际系统滚动轴承五种类型的传感数据的特征,提出了基于提升树预训练的循环神经网络故障诊断算法。(2)实现了工业物联网数据采集系统和设备故障诊断算法。论文研究了工业物联网传输协议和工业传感技术,采用工业数据采集技术和大数据技术,实现了滚动轴承的多维传感数据的采集、传输、存储和展示等功能。本文提出的基于提升树预训练的循环神经网络故障诊断算法,利用提升树对采集到的多维传感数据进行预训练,对特征同时进行组合和降维,降低了模型下游的循环神经网络模型的复杂度,可以满足实时性要求较高的工业物联网设备故障诊断需求。(3)本文对实际搭建的工业物联网数据采集系统和提出的设备故障诊断算法进行了功能测试和性能分析。数据采集系统进行了数据显示、数据存储和故障诊断等功能的测试,测试结果表明系统运行稳定,能够实时对设备故障进行诊断。论文在树模型参数、多维数据特征和模型对比等方面对基于提升树预训练的循环神经网络故障诊断算法进行了性能分析。实验结果表明,本文提出的设备故障诊断算法在准确率方面获得了显著的提升。"
226,基于数据聚合的无源无线传感器网络MAC层设计与实现,"将传感器网络应用于工业现场,实现工业设备的实时监控、保障设备安全运行、实现工业智能化和自动化,是物联网技术发展的必然趋势。论文依托于北京市“无源无线传感器网络关键技术研发及应用”项目,通过对机车车轴的振动数据进行分析并通过工业传感器网络回传数据,实现对轨道交通场景下车辆的运行状况的监测和预警。将无线传感器网络部署在轨道机车上,通过能量收集模块将机车车轴的振动的机械能转化为电能为传感器节点供能。由于电能收集速率慢且供能不稳定,通过加速度传感器采集的高速数据流在低速低功耗的无源无线传感器网络中不能及时有效的传输。网络规模较大,数据经由多跳网络传输时会导致强烈的漏斗效应,造成汇聚节点负载过重,能耗加剧,甚至造成网络瘫痪,严重影响了网络的稳定性和数据的有效性。针对无源无线传感器网络中节点能量受限情况下,数据采集量大且传输困难、节点资源受限不能进行复杂计算和大量存储、以及多跳网络下漏斗效应明显、丢包率严重等问题,本文提出了一种基于机器学习的故障诊断方法进行数据压缩降低数据传输量,并提出一种基于数据聚合的无线传感器网络MAC层时隙分配方案,进一步降低网络的流量,降低网络的能耗。针对高速振动数据流,在节点端借助传感器节点的有限的存储资源和计算能力,对振动数据进行特征提取,并使用机器学习模型对设备状况进行诊断。在节点进行数据传输时只传输诊断结果,并只在必要时对原始数据进行回传。方案在实现故障诊断的同时并降低了节点的95%以上的数据传输量,降低了节点的能耗,延长了节点的存活时间。针对无线传感器网络能量受限下数据传输的问题,提出一种基于TDMA的MAC层数据时隙分配方案,对网络进行超帧设计并进行时隙分配。将传感器节点依照物理部署位置进行分簇,不同分簇之间占用不同的信道进行簇内数据交互,避免了簇之间的碰撞冲突。通过簇头选举算法对簇头进行选取,由簇头节点对簇内节点传输的诊断状态进行聚合传输,进一步降低节点传输的数据量。通过时隙占用算法,簇头节点为需要额外传输时隙的节点进行共享时隙分配,保证了网络时隙分配的灵活性。论文的最后对基于数据聚合的无源无线传感器网络进行的功能测试,通过对网络节点进行抓包分析,对传感器网络的功能进行了验证。实验表明,本文的设计在保障了诊断精度的同时,降低了网络的数据量,降低了传输能耗并延长了节点的使用寿命。"
227,I2P匿名通信网络流量识别与分类,"I2P是一种常用的匿名通信机制,通过多级加密隧道机制实现对通信双方的身份信息和通信关系的隐藏。I2P在为用户的网络访问提供匿名保护的同时也被恶意用户所滥用从事非法活动。因此,I2P匿名网络流量识别与分类研究,有助于有效识别攻击者的恶意行为,对保护网络安全有着重要的理论意义和应用价值。基于P2P架构,I2P采用大蒜路由机制实现用户信息隐藏。一方面,由于I2P节点生存周期短、更新速度快等特点,设计I2P内部资源采集方案,提出两种节点收集算法。另一方面,针对网络中匿名流量少、动态端口机制、加密后难以检测与识别等挑战,本文提出利用报文长度特征和NTCP协议分两阶段实现I2P流量识别的方法和基于流特征的I2P流量分类的方法。本文主要工作和贡献如下:(1)在数据采集阶段,通过研究I2P匿名网络中节点发布与更新机制,设计I2P网络内部资源节点采集方案,提出通过网络数据库NetDB实时监控功能模块和补种网站定期爬取功能模块实现I2P节点的发现与采集的方法。基于节点RouterInfo结构的解析,构建节点信息数据库,为后续流量识别与分类实验研究提供数据标定基础。(2)由于I2P采用动态端口机制,因此针对传统端口识别方法对匿名流量识别的局限性以及网络中匿名流量较少、难以检测等问题,本文提出一种基于报文长度特征和NTCP通信协议分析的I2P流量检测方法,实现对大量普通流量中I2P流量的检测和识别。该方法主要分为两阶段进行I2P流量识别:首先基于报文长度熵值分析过滤非I2P流量,然后基于报文载荷长度序列匹配准确识别I2P匿名网络流量。在实验采集数据集上进行实验研究,证明该方法能有效、快速地识别I2P匿名网络流量。(3)针对匿名服务众多、匿名网络流量混杂等问题,提出一种基于流特征的I2P匿名流量分类方法,将I2P流量分类为匿名文件共享、匿名聊天、匿名网站等三种匿名服务流量。根据选取流量统计特征数量不同,设计三组对比实验,基于四种分类算法(NaiveBayes、BayesNet、SVM、RandomForest),采用准确率、精确率、召回率等指标评价分类模型性能。实验表明,RandomForest分类性能表现最优,分类模型的分类性能也会随着特征数减少而提升。与传统方法相比,本文提出的I2P流量识别分类算法性能更优。"
228,边缘云辅助异构网络中基于视频转码业务的资源分配研究,"随着无线网络的高速发展和手持设备(智能手机和平板电脑等)的迅速普及,用户对多媒体业务的需求呈爆炸性增长。由于用户设备的多样性,源视频必须被转码为不同的版本,但视频转码却是一个计算昂贵且耗时的过程。由于无线网络的动态特性及计算资源的稀缺性,为用户提供满足时延要求的视频转码业务是一项巨大的挑战。鉴于此,本文针对点播视频转码和直播视频转码两种不同的业务展开了研究,具体内容如下:1)针对点播视频转码业务,本论文提出一种基于移动边缘计算的异构网络框架,通过将终端设备的视频卸载到移动边缘计算服务器上进行转码,能有效地减轻终端的计算负担。与现有的文献不同,由于运营商是以盈利为目的的,本文联合卸载决策和计算资源分配以最大化卸载的视频数量来提高移动运营商的收益,并且降低时间延迟。另外,边缘计算服务器为每个用户开辟了一个缓冲队列,用于存储在一个时隙内还没有被转码的视频。在效用函数中,这个队列长度被定义为惩罚项以避免严重的时间延迟。本文采用一种基于actor-critic加强学习的资源分配算法来解决此优化问题。仿真结果表明,本文提及的算法能获取最佳策略使被转码视频的数量最大化,并能降低时延。2)针对直播视频转码业务,本论文提出一种基于软件定义的边缘云辅助异构网络架构来实现直播视频的转码和传输,该方案不仅可以显著降低核心网的通信压力,还可以大幅度减少时间延迟。通过联合用户调度、转码策略选择、计算资源和无线频谱资源分配以最大化视频质量,同时满足直播视频业务的时间延迟要求。与现有文献不同,为了接近真实的无线环境,我们在研究中将可用的计算资源和无线频谱资源建模为随机过程。考虑到无线网络的动态特性和可用资源的有限性,我们将问题建模为马尔可夫决策过程(Markov Decision Process,MDP)。由于此MDP的动作空间是连续与离散动作混合的动作集合,传统的学习算法不能找到最优策略。因此,本文提出了一种增强的Actor-Critic(AC)算法来解决该问题,其中Actor部分和Critic部分均引入资格迹来加速学习过程。仿真结果表明,与策略梯度(Policy Gradient,PG)算法和深度Q学习网络(Deep Q-Network,DQN)相比,该算法具有更好的性能。"
229,基于深度学习的音频场景分类方法研究,"在声音信号检索(Sound Information Retrieval,SIR)领域,音频场景分类(Environmental Sound Classification,ESC)作为该领域的热点问题,致力于通过分析从各种音频信号中提取的复杂特性,识别其对应的特定场景所包含的语义标签,从而对其周围环境进行感知和理解,最终实现特定音频场景的分类。常用音频信号特征提取方法为梅尔频率倒谱系数(MEL Frequency Cepstrum Coefficient,MFCC)。这种方法虽然抗干扰能力强,能够抓取音频数据中最有辨识度的部分,但却只能分析信号的短时特征,往往不足以完整刻画整个音频数据的结构特点。近年来深度学习技术日益成熟并作为最有效的特征提取方法之一,已在机器学习、图像识别、自然语言处理等诸多领域取得突破性进展~([1])。卷积神经网络(Convolutional Neural Networks,CNN)作为典型的深度学习网络框架,具有权值共享和局部连接等特性,特别是带有池化层的卷积神经网络在对城市声音声源分类方面卓有成效。然而,池化操作往往会导致信息的大量丢失,从而影响分类结果准确性。本文在CNN具有良好结构特征分析能力的基础上,将传统音频信号特征提取方法MFCC进行了进一步结构特征分析,探索更好的深度学习方法以解决传统的音频场景分类问题。首先通过深度学习的经典模型CNN进行实验,并采用了结构特殊的膨胀卷积方法对比,发现膨胀卷积由于其“网格型”结构可以在原始参数不增加的情况下,扩大感受野范围,覆盖更多帧,从而很好代替传统带有池化操作的卷积运算。同时,通过对膨胀卷积结构特点的进一步研究,发现膨胀系数变大或扩大膨胀卷积层数将使实验精度降低。认为在膨胀卷积模型中存在固有“网格”缺陷,因此会丢失很大信息,过度放大的感受野使得框架太大而不能获得声音信号随时间变化的特性。可以预见,基于深度学习的音频场景分类问题在今后的工作中还存在很多值得深入探究的内容。本文主要研究内容及取得成果如下:(1)整理总结国内外音频信号处理问题及深度学习技术的发展现状,发现传统音频信号处理只能分析信号的短时特征,后续识别问题步骤繁多复杂,且主要基于一般浅层分类器的应用。通过研究典型深度学习方法,寻找适合的结构化模型在语音识别分类上进行实践应用。(2)深度学习的方法多种多样,不同结构对不同场景特征敏感度不同,识别性能存在差距。本文研究了带有池化操作的传统卷积神经网络的音频场景特征提取分类方法。并在模型设计中引入了膨胀卷积思想,通过这种特殊结构的卷积操作形式,在城市声源数据集中取得了比传统卷积神经网络更好的结果。(3)深入研究膨胀卷积的结构对实验结果的影响,发现扩大膨胀率或膨胀卷积层数将使实验分类精度降低。这可能是音频信号具有短时稳定性,膨胀模型有“网格”连接缺陷,经过MFCC处理的特征再通过这种网格结构,覆盖帧的范围严重改变,最终影响整体音频信号的特征提取。"
230,基于机器学习的AIOps技术研究,"随着全球信息化快速发展,网络规模日益庞大,IT系统的安全、高效、高质量运维成为业界关注和研究的热点。近年来随着机器学习技术发展,将人工智能与IT 运维相结合,出现了智能运维 AIOps(Artificial Intelligence for IT Operations)技术。本文主要研究了 AIOps框架下的两大问题,即KPI(Key Performance Indicators,关键性能指标)异常检测和IT运维故障分析,并在此基础上设计和实现了 AIOps智能运维系统。本文的具体工作如下:(1)针对KPI异常检测技术的研究,本文分析了智能运维场景下KPI指标的特点,设计了 KPI智能异常检测模块总体框架;采集KPI指标,从多个层面提取不同的特征,通过采用SMOTE过采样与随机欠采样相结合的方法对不平衡数据集进行平衡以及采用Z-Score方法对提取的特征进行标准化处理,运用于KPI异常检测模型中;本文选用BP神经网络作为KPI异常检测训练模型,尝试不同网络选出最优结构,通过特征筛选实验减少冗余特征,提升模型的性能;接着本文分析BP神经网络的缺陷,从优化权值初始化和优化梯度下降两个方面对算法进行改进和实验分析,并应用于提出的集成KPI异常检测模型中,进一步改善模型性能。(2)针对IT运维故障分析技术的研究,本文分析了运维故障特点,设计了故障分析模块总体框架;选用支持向量机构建故障分析模型,对支持向量机的核函数种类进行筛选实验,选定了合适的核函数;本文利用网格搜索方法对支持向量机的参数进行基本确定,并绘制了热力图,在此基础上提出了改进模拟退火算法并进行了实验,提升了故障分析模型的性能。(3)本文设计并实现了 AIOps智能运维系统。首先对AIOps智能运维系统的需求进行分析;根据系统需求设计了系统的总体架构、系统功能框架以及系统数据库;最终详细实现了系统各功能模块并给出实现结果。"
231,基于轻量级神经网络的指纹分类应用研究,"指纹分类是在大型指纹库中搜索目标指纹的一项非常重要的技术,并且在国家公民身份验证以及寻找犯罪分子过程中是尤为关键的一环。传统指纹分类方法对不同质量、不同规格的指纹图像自适应性不高,无法得到较高的分类结果,且人工计算量繁杂。深度学习因其强大的表达能力广泛应用于各类图像处理中。基于深度学习的指纹分类则是利用大量有标签数据训练神经网络,使其自动学习图像中潜在的抽象特征,从而实现指纹的自适应分类,人工干预较少,为指纹分类的研究开辟了新方向。鉴于此,本文采用深度学习方法构建轻量级神经网络,用于指纹图像特征自动提取及分类,通过多种特征融合增强神经网络的表征能力;结合迁移学习,降低网络对目标数据量的要求,提升小样本指纹图像的分类性能,以此对指纹分类展开研究,主要内容如下:(1)提出一种基于轻量级Finger-SqueezeNet网络的指纹分类模型。由于指纹分类数据集规模较小,若直接训练深度卷积神经网络,很容易出现过拟合现象。因此,本文采用轻量级网络代替深度卷积神经网络,减少模型参数,提高模型运行速度。为此,在SqueezeNet网络基础上,构建一个Finger-SqueezeNet模型,将模型压缩至1M以下,极大程度地减少了参数量。(2)为提升小样本指纹图像的分类性能,本文在轻量级网络的基础上结合迁移学习,提出一种基于迁移学习的轻量级指纹分类模型。首先,采用指纹方向场图对轻量级网络进行预训练;然后,通过指纹图像数据集进行参数优化;最后,将优化后的网络进行指纹分类实验验证。实验结果表明,迁移的轻量级网络模型能够有效提升指纹分类性能。(3)提出一种轻量级多特征融合的指纹分类算法。首先,将指纹图像输入到轻量级网络进行特征学习,提取深度特征;同时,采用查表法获取指纹图像的细化图,并利用改进的分布式求和梯度法求取细化图的感兴趣区域(Region Of Interest,ROI);然后,将指纹ROI与深层特征进行融合,使深层网络也能学习浅层的纹线走向信息,从而增强网络对纹型的敏感度。实验结果表明,在深层特征中融合指纹ROI,使网络充分地学习指纹的纹型信息,从而提高了指纹分类结果。"
232,基于多特征融合的人脸美丽预测研究,"人脸的美在社会活动中起着重要的作用;影响了数字娱乐、模特和表演等职业、以及个人职业前景。人们对美丽的追求和向往吸引了各领域学者对人脸美丽预测的研究。但是,传统的人脸美丽预测方法在特征提取上耗费了大量时间,而且预测效果不理想。目前,研究者们通过深度学习方法,采用卷积神经网络(Convolution Neural Network,CNN)替代手工提取特征,让网络智能地提取人脸美丽特征,从而为机器自动进行人脸美丽预测提供了可能。本文提出基于多特征融合的人脸美丽预测研究,采用多特征融合代替传统的单一特征来增强网络的预测能力。本文主要研究内容如下:(1)采用一种融合几何特征与PCANet网络的人脸美丽预测模型。将PCANet网络提取的直方图特征与几何特征进行融合,得到更具鲁棒性和区分度的特征,最后通过SVM回归器和随机森林回归器进行5折交叉验证实验。实验结果表明,PCANet网络融合几何特征后的预测性能优于未进行特征融合的预测性能,说明融合的几何特征能有效提高人脸美丽预测结果。(2)采用一种结合局部二值模式(Local Binary Pattern,LBP)与卷积神经网络的人脸美丽预测新方法。LBP算子提取的人脸图像具有局部纹理特征和光照不变性,通过在CNN网络中加入LBP纹理图像,学习LBP图像的局部结构特征,使网络提取更具结构性和层次性的人脸美学特征。在输入图像进行通道融合后,使用1×1卷积层对通道特征图进行线性组合,实现网络跨通道的交互与信息整合。实验结果表明,在CNN网络中融入LBP纹理图像,能有效提升人脸美丽预测结果。(3)采用一种融合多层卷积特征的人脸美丽预测模型。与传统卷积神经网络不同,多层卷积特征融合的卷积神经网络将多个浅层特征、中间层特征与深层特征进行融合,来增强人脸美丽特征的提取过程;不仅考虑了深层特征的抽象语义信息,而且考虑了浅层特征的局部细节信息,使得人脸美丽预测更加准确。实验结果表明,融合浅层、深层卷积特征的模型优于单层模型。(4)在多层卷积特征融合模型中嵌入Sequeeze and Excitation(SE)模块,该模块通过建模通道之间具有的相互依赖关系,能自适应地重新校准通道式的特征响应,从全局信息出发使网络有效选择放大有价值的特征通道,并且抑制无用的特征通道,增强网络的表征能力。实验结果表明,所提方法在大规模人脸美丽数据库(Large Scale Facial Beauty Database,LSFBD)中的表现优于现有方法。"
233,基于用户行为序列的网络购买行为预测,"网络购物多年来发展迅速,已成为人们日常生活中必不可少的一部分。每个电子商务平台都存放了数亿可靠用户,并产生了大量的实际数据。怎么从这些数据中寻得规则,掌握用户的想法,高效解决用户实际问题,提升用户购物体验,是大数据应用在精准营销中的关键问题。因此,本文使用机器学习算法从用户、商品、用户-商品历史数据中学习其中的购买行为模式来获取模型,实现网络购买行为预测。本文以中国大数据算法大赛(如期而至-用户购买时间预测)为背景,将用户在京东电子商务平台上的真实购买行为数据作为研究数据,使用机器学习算法进行建模。在构建模型前,要做基础的准备工作,包括数据预处理、数据分析、特征工程等,确定最终的建模目标和线下训练集、线下验证集的划分,还有构建原始模型的原始特征群,并实验记录最初实验效果。本文研究以数据为驱动,针对网络购买行为预测,将用户商品行为记录为用户行为序列,提出用户行为序列的效用函数,分别从行为频率和时间间隔考虑效用函数,进而从用户行为序列挖掘用户商品偏好。在利用效用函数得到用户商品偏好数据后,将数据带入模型训练,实验主要在初始结果最优的Logistic Regression(逻辑回归)和GBDT(梯度提升决策树)模型上进行比较,在Logistic Regresion模型上用户评价S1提升0.014,最终结果达到0.663,表明提出的方法有较好的效果。同时,本文还提出将用户行为序列中的商品组成document,使用CountVectorizer和TfidfVectorizer分别来做词向量,CountVectorizer只考虑词汇在文本中出现的频率,TfidfVectorizer除了考量某词汇在文本出现的频率,还关注包含这个词汇的所有的文本的数量,能够削减高频没有意义的词汇带来的影响,挖掘更有意义的特征。获取词向量后,将对应词向量在LDA主题模型上训练,获得主题概率分布,通过设置不同的主题数实验,获得最优的主题数n_topics=15。将主题概率分布数据带入模型训练,实验在GBDT模型上用户评价S1提升0.059,最终结果达到0.703,实验效果相对效用函数的结果更好。最后,还通过效用函数和主题概率分布进行联合评测,联合评测在Logistic Regression模型上有提升效果,Logistic Regression模型最终结果达到0.672,验证了所提出的的方法是可行且有效的。本文预测模型可以很好地提升预测结果,其中基于用户行为序列的特征生成方法,可以作为时间序列类数据的一种特征生成方法,在周期内用户对实体的行为记录生成行为序列,然后利用上述两种方法生成特征。"
234,基于知识图谱构建的微博话题推荐研究,"由于微博用户的数目急剧的增加,每天在微博平台产生的话题数目也随之大量的产生,面对着大量产生的话题,用户往往很难筛选出自己感兴趣的话题。为了解决这个问题,本文提出了基于知识图谱构建的微博话题推荐算法以其帮助用户找到自己感兴趣的话题,使得微博话题能被其感兴趣的用户浏览。主要的研究内容如下:(1)建立微博话题知识图谱。先对获取的微博文本进行预处理,将处理后的微博文本使用学习到的前后缀规则获取命名实体。接着对微博语句进行依存句法分析,通过Bootstrapping微博关系抽取算法抽取微博关系。最后将命名实体视为节点,抽取的对应关系视为连接两节点的边,通过软件绘制实现知识图谱的可视化展示。(2)建立话题用户兴趣度矩阵。定义用户微博词语特征词集合(User Weibo word feature set),并使用TF-IDF依据用户微博历史数据进行获取。将微博话题知识图谱与微博话题知识图谱进行匹配,获取用户兴趣度矩阵,得到选取所有用户对所有话题的偏好。最后再将用户使用划分聚类的方法k-means进行聚类分析。(3)基于话题知识谱图和用户兴趣度的微博推荐。我们首先定义了微博话题命名实体系数,用来表征微博话题的命名实体对于用户的重要性,然后在微博话题知识图谱和用户聚类分析的基础上,将微博话题进行基于话题知识图谱的协同推荐,获得微博话题推荐集合。再将待推荐的微博话题特征词权值向量与微博话题命名实体系数构成的向量进行相似度计算,基于用户内容的筛选,获得相似度高的推荐话题集合,最终获得推荐集合。经过实验的数据的验证,基于话题知识图谱的微博推荐算法可以使推荐给用户话题的准确率有很大程度的提高,很大程度上减轻了用户寻找感兴趣话题的时间,及时高效的帮助用户获取了对自身有用的信息。本文创新地将微博话题知识图谱和协同过滤推荐结合起来,通过建立用户兴趣度矩阵很大程度的缓解了协同推荐的冷启动问题,并定义了微博话题命名实体系数,将协同过滤获得的话题中不符合用户偏好的话题进行过滤,最终提高了推荐的准确率。图[13]表[16]参[62]。"
235,基于深度循环神经网络的关系抽取方法研究,"信息抽取主要研究如何有效地、自动地从海量数据中抽取出有用的信息,在知识服务方面具有重要的意义。关系抽取作为信息抽取的重要组成部分之一,一直以来是自然语言处理领域的研究热点。关系抽取任务的主要目的是将半结构化或非结构化的自然语言文本转换为结构化文本,然后找出句子中两个已被标识的实体之间的语义关系,是知识图谱、问答系统等智能应用的基础。以往,大多数关系抽取的研究都是基于传统的机器学习方法,这些方法通常依赖于人工制作的特征。但是,特征工程是劳动密集型任务,需要大量的人力和时间。随着深度学习方法在自然语言处理领域地成功应用,大量学者开始采用深度学习方法研究关系抽取任务,削弱了人工构造特征的需求。然而,这些方法存在两个问题:一是忽视了实体与上下文之间的交互信息;二是不能很好地获取远距离的上下文依赖关系。围绕这些问题,本文以基于长短时记忆网络的关系抽取方法为基础,从以下三方面开展研究:(1)针对“忽视实体与上下文之间的交互信息”的问题,提出了一种基于实体依赖的长短时记忆网络关系抽取模型。首先,为了保存实体周围的上下文信息,本文使用两个双向长短时记忆网络将前后两个方向的上下文文本编码为其语义表示;然后,通过实体依赖的思想建模实体词与其上下文之间的关联性,并选择上下文的相关部分来推断实体之间的语义关系;最后,本文采用SemEval-2010 Task 8数据集对模型进行训练,并选择了8种目前较好的关系抽取方法与本模型进行对比。实验结果显示,本模型的综合评价指标F1值为85.6%,比其它方法高出约0.5%至6.8%,有效地提升了实体关系抽取的性能。(2)针对“不能很好地获取远距离的上下文依赖关系”的问题,提出了一种基于自注意力机制的长短时记忆网络关系抽取模型。目前常用于提取实体关系的神经网络模型,例如卷积神经网络和循环神经网络,均不能很好地获取远距离的上下文依赖关系。本文认为充分地利用远距离的上下文依赖关系,有助于模型更加精准的抽取句子中实体之间的语义关系。为了解决这个问题,本文提出了一种基于自注意力机制的长短时记忆网络关系抽取模型,本模型能够学习句子中各个词之间潜在的依赖关系,可以对相关上下文进行较为全面地分析,捕获到更加有益的信息。本模型首先使用一个双向长短时记忆网络将实体词与上下文词编码为其特征表示,然后将得到的表示矩阵输入到多头注意力模块中得到实体与其上下文的多层注意力表示,最后连接一个分类层对语义关系进行分类。与上述8种关系抽取方法的对比实验表明,本模型可以获得85.2%的F1值,比其它方法高出约0.1%至6.4%,较好地解决了现有关系抽取模型不能充分获取远距离的上下文依赖关系的问题。(3)为了进一步探索提高语义关系分类准确性的方法,本文将基于实体依赖的长短时记忆网络与自注意力机制相结合,提出了一种联合自注意力机制的实体依赖长短时记忆网络关系抽取模型。本模型将上述两种模型的优势结合在一起,使得实体与其上下文之间的交互信息以及远距离的上下文依赖关系可以共同作为关系分类的依据,从而能够更加充分地利用实体周围的上下文信息。本文使用SemEval-2010 Task 8数据集作为模型的训练数据,将得到的结果与其它现有的8种优秀的关系抽取模型以及上述两种关系抽取模型进行对比。实验结果表明,本模型可以较好地将实体依赖的长短时记忆网络与自注意力机制结合,其F1值高达85.9%,进一步提升了关系抽取的准确性。"
236,融合预训练语言模型的机器译文质量评估,"近年来,神经机器翻译技术取得了重大突破并得到了迅速的应用和推广。但是,依然存在诸如机器译文质量评估问题、集外词问题、长句翻译问题、过翻和漏翻问题等。机器译文质量评估(Quality Estimation,QE)是研究如何解决在没有参考译文的情况下对机器译文的质量进行评估的问题,其研究成果不仅可以帮助机器翻译系统过滤掉低质量的翻译结果,以及构建高质量的平行语料库,还可减少译后编辑的工作量。因此,该研究具有重要的研究意义和实用价值。现有的QE方法主要包括两类,一种是基于机器学习的方法,另一种是基于深度学习的方法。这两种方法都致力于提取与QE任务紧密相关的特征,抽取的特征的好坏决定了系统性能的优劣。近期,预训练语言模型刷新了多个自然语言处理任务的最佳成绩,展现出强大的表征学习能力。因此,本文主要探索如何将预训练语言模型融入到QE任务中,以提升QE的性能。本文的主要工作和创新点包括:(1)提出了一种将ELMO、GPT和BERT等预训练语言模型提取出的机器译文特征和“双语专家”模型提取出的特征相融合的机器译文质量评估方法。两者提取到的特征相互补充可有效缓解QE任务特征稀疏问题。实验结果证明,在句子级别和词级别两个子任务上都取得了显著提升。(2)提出了基于BERT+LSTM+MLP架构的句子级别机器译文质量评估方法。LSTM网络将多语版BERT提取到的源语句和目标译文高层特征编码为固定大小的向量表示,并送入全连接神经网络中进一步学习,最终得到模型预测得分。实验结果表明,该方法可达到目前QE的最好水平。(3)提出了一种融合依存句法信息的机器译文质量评估方法。将源语句和目标译文中每个词的依存标签转化为向量表示并与各自的词向量进行拼接,拼接后的向量送入模型中进行训练,显示地使模型学习依存句法结构信息。实验证明,QE模型的性能得到了进一步提升。总之,本文创新性地提出了将预训练语言模型和依存句法信息融入QE任务的方法,并通过实验验证了提出方法的有效性、先进性和实用性。"
237,基于视觉信息的Web数据高效提取技术研究,"Web数据提取技术在网络数据挖掘、情报获取、商业竞争和大数据分析中发挥着重要作用。随着互联网的普及和快速发展,网络中承载的海量数据信息已经成为一个宝贵的资源,但由于Web页面难以获取、数据形式不统一,加上随处可见的噪声信息等原因使Web数据不能得到充分利用。如何有效的抽取Web页面中包含的结构化数据成为一个热门的研究方向。本文分析了 Web页面获取困难的原因和网页的视觉信息特点,针对DOM树匹配算法、Web数据提取规则描述语言和Web数据自动化抽取技术进行深入研究,主要工作内容如下:(1)本文对传统DOM树匹配的特点进行剖析,结合Web数据自动化提取过程提出了基于XPath和LCS的DOM树匹配算法。该算法不仅降低了DOM树匹配的时间复杂度提升了DOM树匹配的效率,而且结合XPath进行数据抽取提高了数据抽取的准确性。(2)分析了 Web2.0中常用的动态网页技术和网页视觉特征,提出了面向提取规则描述的WDERD语言,解决了Web数据提取中动态页面难以获取的困难。该语言描述了网页操作、数据标记、循环过程和网页渲染等操作过程,详细描述了Web数据提取的整个过程。针对WDERD语言提取规则的生成过程,本文设计了通过Chromium嵌入式框架自定义插件扩展,对用户操作动作和操作页面元素进行记录,自动化生成Web数据提取规则的WDERD语言描述,让普通用户可以通过简单页面交互生成WDERD语言规则描述完成Web数据的抽取任务。(3)本文设计并实现了基于视觉信息的Web数据提取系统。系统分为WDERD语言解析模块、页面获取模块、DOM树匹配模块、数据记录模块、数据项提取模块和数据存储模块。通过与OXPath包装器和八爪鱼数据采集器进行Web数据提取实验对比,结果表明基于视觉信息的Web数据提取系统在保证Web数据提取准确率的同时提升了Web数据提取的效率。"
238,基于Hadoop平台的个性化新闻推荐系统的设计与实现,"这是一个追求信息的时代,随着互联网技术的普及,人们获取信息的途径越来越容易了。为了满足人们对信息的渴望追求,各种各样的新闻资讯类应用开发层出不穷,网络新闻通过新闻展示,超链接等方式可以容纳海量的信息,新闻也更丰富,也越来越多样化。但是互联网上信息数据以爆炸式的速度快速增长,产生了许多的垃圾信息并导致了信息过载出现并变得越来越严重,信息过载慢慢成为人们迅速尔高效获取有用资讯信息的一个巨大的障碍,这导致消费者想从大量信息(物品)中找到自己感兴趣的信息,信息产出者想让自己生产的信息脱颖而出从而得到关注都是一件很难的问题,推荐系统的任务就是连接用户和信息(物品)。在信息过载的推动下,推荐系统成为了各大互联网公司攻城略地开疆拓土的必备良器。个性化新闻推荐系统就是为了解决信息过载这个问题。为了实现精准的个性化服务首先便是对用户进行建模,完善用户画像,其次使用现有的推荐算法作为召回操作并参考实际业务需求添加符合业务的召回方法,为个性化推荐提供较好的推荐底层数据,然后使用机器学习算法中的逻辑回归模型做点击率预估,在这个部分之前我们使用到了最优化算法与特征提取等方法对模型进行优化,这提高了我们的模型的准确率与泛化能力有很大的提升,最后就是使用用户画像与召回数据进行组合并使用模型进行预测,为了减少预测结果的偏差,我们在使用保序回归对预测结果进行校正,较少误差。为了使得用户有更好的体验,我们将整个系统布置在Hadoop平台,使用Spark进行数据操作,大大提升了系统的响应速度与稳定性。目前该系统部分功能已经上线。每一次推荐速度响应小于1秒,每次推荐用户10篇个性化新闻给用户,新闻的点击率在15%到20%。模型准确率相对较高,基本满足系统定位要求。"
239,基于卷积神经网络的新闻文本分类研究,"随着互联网和信息技术的快速发展,网络新媒体已经成为信息交互的有效平台。其中非结构化的新闻文本作为信息的一种重要承载形式呈爆炸式增长。如何高效准确地对海量新闻文本进行分类,提取所需信息是当前最热门的研究课题之一。并且由于其内容简短,表达方式多样化和语法结构不规范,增加了分类的难度。所以目前迫切需要一种有效的文本分类算法对文本语义进行更好地提取,从海量的新闻文本中挖掘出有价值的信息。自深度学习思想被提出以来,已经在图像识别、机器翻译和语音识别等领域中取得了出色的表现。和传统机器学习算法相比,深度学习模型通过多层非线性空间的变换,能够刻画出数据的本质特征,为提高新闻文本分类模型的准确性提供了良好的基础。深度学习模型中的卷积神经网络(Convolutional Neural Network,CNN)已成为一种主流的文本分类模型。本文提出了一种基于卷积神经网络的新闻文本分类框架,对文本分类中的特征表示、特征提取和分类器构造等关键环节进行了不同程度地改进。本文的主要工作如下:(1)文本的特征表示方法对最终分类结果有很大的影响。基于分布式表示的word2vec词向量将词映射成d维空间中连续稠密的实数向量,通过计算向量间的余弦距离可以来衡量词语间语义相关性。本文将卷积神经网络模型的输入层使用词向量替换传统的one-hot向量,通过CBOW模型训练词向量,对词进行向量化表示。针对词向量只能获得词的上下文的语义而缺乏对文本整体语义信息的弱点,引入LDA主题模型,将词向量和主题向量进行拼接得到一种更有效的特征表示方式,更好地提取文档的浅层语义信息。(2)在从文本的词粒度级别出发对特征表示进行优化的基础上,结合注意力机制,赋予影响文本分类结果的关键特征更高的注意力概率值;在卷积层中设计不同尺寸的卷积核文本的深层语义特征进行提取。在池化层使用最大池化方法对特征进行降维和压缩。最后高质量的特征向量在全连接层进行连接并且通过softmax分类得出文本所属类别。实验结果表明,本文模型的准确度、召回率和F1值分别达到96.4%、95.9%和96.2%。说明改进后的CNN模型通过特有的层次结构,能够从文本浅层语义特征中提取深层语义特征,为建立高效精准的新闻文本分类模型提供了有力的支持。"
240,恶劣光照条件下人脸检测及表情识别研究,"人脸表情是与生俱来反映人情绪变化的生物特征。基于人脸活动单元编码系统分类获得的七种基本表情在不同个体之间具备相同的情绪含义,这一分类方法使表情的分类具备了科学标准与量化分析的可能性。随着计算机视觉技术的发展,表情的分类可以通过机器识别和神经网络技术实现自动化操作,让计算机模仿人眼实现对人脸表情的正确辨别。在表情识别研究上逐渐形成了从人脸检测、特征处理到表情分类三个基本流程。其中,人脸检测旨在解决人脸定位问题,为特征处理确定具体区域。特征处理主要包括特征提取、降维和分类,其中特征的提取可以根据分类器设计的需要使用不同的核函数提取出相适用的特征种类。表情分类是实现表情正确识别的关键步骤。研究过程中存在着诸多影响正确率的问题,比如光照、姿态、尺度等。本文对图像的预处理、特征提取及表情分类进行了研究,主要研究工作如下:1、恶劣光照条件下人脸检测问题。在日常环境中进行拍照或录像往往无法避免光照因素的影响。特别是在夜间、灯光及遮挡环境下非常容易导致无法有效检测人脸的情况,在安检、监控以及夜间拍摄上会影响效率甚至造成失误。为降低甚至避免光照因素造成的不良影响,本研究针对恶劣光照条件下人脸的检测进行了光照归一化的研究。本研究主要对直方图均衡化方法做了改进,基本思想是均衡化算法结合阈值分割算法对图像做分层次处理,对图像拼接滤波后可以得到很好的可视化效果,进而顺利实现人脸检测。2、基于机器学习的表情识别是人脸检测的一个重要研究方向,本研究在人脸检测的基础上,利用机器学习的方法,在图像处理、特征提取、特征分类阶段分别作了如下研究:图像处理阶段,在样本分割上本研究提出了基于集成回归树算法(ERT)确定出人面部核心区域的特征点,进而分割出不规则的人脸图像的方法;在特征提取和分类阶段,采用具有旋转不变性和光照不变性的LBP卷积核进行不同尺度的面部特征化处理,并在同一表情的基础上对不同人脸的同一区域提取出不同尺度的特征值,为Adaboost自适应增强算法提供训练数据。利用LBP提取的纹理特征具有很强的表情属性的特点,从数据层面排除了颜色、亮度、旋转角度变化的影响。同时由于circle LBP可以调整采样点半径和采样点数量,可以为Adaboost提供大量的训练数据。"
241,基于SVM模型优化的互联网新闻自动分类研究,"随着科学技术的快速发展,互联网已在各行各业得到广泛应用。大数据时代的到来使人们在获取信息资源的过程中,也会有大量干扰、不良的危害信息,网络信息的恣意传播很容易在获取信息时出现低效率、信息误导等情况。如何对互联网新闻数据进行准确的分类、提高信息的利用率成为了众多科研人员的研究目标。随着人工智能和智能化平台的发展,SVM研究又逐渐变热,重新成为热点。SVM在文本和图像分类等领域都有着较为显著的成果。本文在分析总结新闻自动分类过程中的分词,表示,降维,分类以及结果判定的基础上,着重对降维和分类进行了深入研究。本文主要研究内容如下:(1)针对互联网新闻文本数据量大,冗余数据资源较多不便于使用者查找有效信息等问题,做出以下改进:在数据预处理中,使用线性判别分析(LDA)可以让映射后的样本有最好的分类性能。在LDA进行特征降维之前,先使用单因素方差分析对每个属性与类别进行相关度的分析,将不相关或者相关性较低的特征剔除,再使用LDA在线性变换上将原始数据映射到能够较好区分特征与类别的低维度上,实现数据降维。(2)为提高鲸鱼优化算法的收敛速度和寻优精度,提出一种基于非线性收敛因子和局部扰动的鲸鱼优化算法。算法首先引入非线性收敛因子,提高鲸鱼种群的多样性,扩大鲸鱼搜索食物的范围。同时在鲸鱼包围捕食阶段,采用一种局部扰动策略,使算法在跳出局部极值时的能力增强,提高算法的寻优精度。实验结果表明,改进后算法和粒子群算法、蝙蝠算法、基本鲸鱼优化算法相比,寻优速度、收敛精度、算法稳定性上都要优于其他算法。(3)通过深入分析SVM的思想、原理和流程,针对基本SVM模型中存在的易发生分类准确率不高、参数优化费时等缺点,做出以下改进:在SVM参数选取中,使用鲸鱼优化算法,快速找到全局最优解,提高模型的分类准确率,改进后的鲸鱼优化算法在模型参数优化中效果更佳。并用互联网新闻自动分类系统与优化后的SVM模型结合,使互联网新闻信息更清晰直观的呈现给新闻用户,不仅可以提升用户获取有效信息的效率,也可以提高用户的使用兴趣,减少冗余数据对用户的干扰,实现本文的使用价值。"
242,基于步态识别的携带物改变检测研究,"携带物检测与步态识别是计算机视觉领域的热点问题,现有方法面临如下两个突出问题:(1)视频监控系统虽已广泛应用,但在一些监控死角或不适宜架设监控系统的场所,往往容易高发恐怖袭击或治安事件,如故意留置危险物品或发生盗抢行为,上述危险事件发生常常伴随嫌疑人的携带物改变,如何利用发生恐怖或治安事件场所以外的监控影像进行人重识别以及携带物改变检测、进而预警或事后追踪是亟待解决的问题;(2)现有方法在进行步态识别时多使用步态能量图作为模型的输入,而在步态能量图的合成过程中,没有考虑目标检测识别出的人物区域会出现非联通的情况(断头或无头),以至于无法找到正确的重心坐标,从而合成不准确的步态能量图,导致步态识别准确率不高。针对上述问题,本文的主要工作及创新点如下:(1)步态能量图的合成部分。针对部分非连通人物区域影像查找正确重心的问题,本文提出了基于重心对齐的步态能量图优化合成算法。首先,通过学习得到判断断头与无头情况的条件,把这些图像进行区别处理,对于断头的图像把头部与躯干合并,对于无头的图像找到并删除;然后,计算出保留图像的准确重心坐标;最后,使用重心对齐技术合成步态能量图。实验表明,使用该算法对齐后合成的步态能量图,取得了更好的合成效果,提高了步态识别的准确率。(2)携带物检测与步态识别双识别部分。在无法拍摄到盗窃或者放置危险物品等可疑行为发生过程的情况下,对已经发生或者即将发生的危险及时做出正确判断是十分必要的。若使用神经网络对是否同一人与是否携带改变分步进行判断,虽然可以满足需求,但是由于使用了两个网络,则需要计算大量的参数,从而耗费大量的时间。针对此问题提出了基于改进的孪生网络的步态识别与携带物检测算法,通过把传统的孪生神经网络进行改进,使其变为双输出的结构,将进出特定场所的两段视频进行对比,不仅能判断是否为同一人,而且还能判断出前后是否存在携带物状态的改变。该算法在训练时,将由两段视频生成的步态能量图两两配对,并将每对定义双标签(第一维标签定义是否同一人,第二维标签定义是否携带改变),所以,此方法不需要直接观测到携带物发生改变(转移或离开)的过程,也无需事先建立接触者的行迹资料。此方法与传统的步态识别算法相比,步态识别的准确率也得到有效提升,本文方法对是否同一人(步态识别)以及是否携带改变(携带物检测)同时判断处理时,给出的判断准确率达到87.54%。因为使用一个网络同时判断两个问题,在保证了识别准确率的同时,节省了参数的计算成本。"
243,基于情感分析的推荐算法设计与实现,"当利用网络中的信息,为了增强用户与商品之间的粘合度,在搜素引擎出现后相继推出了推荐系统和个性化推荐系统,而基于情感分析的个性化推荐系统也逐渐体现出了越来越重要的地位。基于情感分析的个性化推荐系统目前的研究重点在情感分析模块,即如何正确准确的分析用户的情感倾向。目前网络信息越来越全面,能够体现用户情感倾向的信息种类越来越多。如何将不同的情感表达方式进行有效的结合,如何能够将中文信息进行准确的分析,随之出现的中文文本切词技术,情感量化模型设计及不同情感表达方法的结合方法。中文切词方面利用LSTM模型处理特征提取等问题,情感量化模型中存在模型不成熟的问题,不同情感表达方法进行结合时存在的问题。本文针对以上问题展开了研究,具体的研究内容如下:(1)针对中文分词的准确率问题,对LSTM模型进行了改进。首先,基于模型记忆时间的问题,改进模型从而达到控制模型的记忆时间。其次,针对LSTM模型的复杂性,改进模型从而增强特征提取的能力。(2)对于情感量化模型建立,具体对中文评论语句进行情感量化。充分利用了评论文本的所有词语,不单是考虑情感词,还加入了语句中的否定词和程度副词的研究。能够较为准确的计算出整个评论语句的情感值。针对如何将用户评论和用户评分进行有效结合,利用用户情感表述的不同方式,采取蒙特卡洛的方法计算出两者不同的权重值,将两者进行有效的结合,能够计算出更为准确的情感倾向值。(3)针对本文数据的独特性,选取了适应本文数据的改进的协同过滤推荐算法进行推荐,使得处理后的数据得到了更充分的利用,从而使得推荐的准确率相较于之前的推荐算法在准确率上得到了提升。综上所述,本文在情感分析方面做了大量的研究和分析,对LSTM模型进行了改进,对情感量化模型进行了设计及对用户评论和用户进行有效结合进行了研究和设计。经过仿真实验和实验结果验证,本文所改进的LSTM模型在中文分词方面准确率和召回率得到了提升和改进,设计的情感量化模型及用户评论和用户评分的结合用于最后的推荐算法中后,推荐结果在准确率和召回率上得到了一定的提升。"
244,Python脚本的脆弱性检测研究与实现,"随着人工智能和机器学习的快速发展,Python广泛应用于网络爬虫、机器学习、数据分析等领域,并且Python拥有强大第三方库,这使得Python在编程语言中的地位越来越高。但是,由于系统的不安全性,无法保证Python脚本在其整个生命周期内都是可信的。当系统受到攻击时,计算机中的Python脚本可能会被篡改。因此,需要研究Python脚本中存在的脆弱性,为此,本文从完整性验证和漏洞检测两个方面进行研究。在本文中,完整性验证和漏洞检测都是基于两个Python脚本,一个原始Python脚本和一个当前的Python脚本。原始的Python脚本在其生命周期内被更改后,就称为当前Python脚本。本文的研究内容及创新点如下:(1)当原始的Python脚本来源可信时,通过完整性校验检测当前的Python脚本与原始的Python脚本是否语义一致。这里的完整性校验是一种宽松的完整性校验,更加倾向于相似性检测而非密码学意义上的完整性校验。在此,提出一种UNIX diff指令和抽象语法树相结合的相似性检测方法。实验证明该方法可以有效地避免基于树形结构的相似性检测所带来的缺点。(2)当原始的Python脚本来源可信并且其完整性已经被破坏时,需要对当前的Python脚本进行漏洞检测。对此,对具有良好扩展性的Python漏洞检测工具Bandit进行分析,总结其优缺点,并针对其缺点进行改进――将污点分析与Bandit结合起来。实验证明该方案可以在不影响Bandit性能的前提下,降低漏洞的误报率。(3)当原始的Python脚本来源不可信时,直接对当前的Python脚本进行漏洞检测。对此,提出了一种基于特征矩阵的Python克隆代码漏洞检测方法。首先,针对不同的漏洞类型,提取相应的关键特征,依照不同关键特征对Python脚本进行前向或后向的程序切片。然后,利用基于代码块的抽象语法树,将代码转换为向量,构建特征矩阵。最后,利用机器学习的方法,对特征矩阵进行降维并计算相似度。实验证 明该方案可以有效地检测出Python程序中存在的漏洞。"
245,基于局部空间特征的点云分类方法研究,"三维点云数据所特有的空间结构信息为进一步提升视觉应用的精度提供了可能,因此吸引了越来越多研究者的关注。点云分类是点云数据处理的一个重要研究方向,也是一个具有挑战性的课题,相关研究的重点主要集中在以下方面:(1)提高点云分类算法的精度,(2)在保持精度的前提下提高点云处理速度。本文主要研究了点云精简算法、特征描述子构建方法以及对应的分类算法,旨在保持分类精度的条件下提升点云分类算法的速度。本文的主要工作如下:(1)针对当前点云精简算法中存在的精简效率不高、精简导致精确度降低的问题,本文提出了一种点云的非均分层方法及分层点云精简算法。首先利用点云的空间结构信息完成非均分层处理;然后计算各层的曲率信息并据此去掉分层中不重要的点,实现单层点云的精简;最后将精简后的各层点云进行拼接得到完整的精简点云。对比实验结果表明了本文提出的点云精简算法的有效性。(2)针对经典的点云特征描述子存在特征维度较高、计算效率不高的问题,本文提出了一种二值化几何特征描述子(BGFD)。首先利用特征重要性评价及特征冗余性分析选择出最优几何特征子集,对其进行二值化处理得到二值化特征表示(BGFD)。采用BGFD与经典描述子进行场景目标匹配的对比实验结果表明,本文提出的低维度、高效率的特征描述子保持了较高的描述能力。(3)针对高精度的深度学习点云分类算法存在模型训练时间过长的问题,本文提出了一种基于二值化特征描述的点云分类算法。利用二值化处理方法对点云的RoPS特征进行改进生成了二值化RoPS特征(B-RoPS),并与BGFD特征进行拼接形成融合的二值化特征描述,以此作为点云分类算法的输入特征,实验结果表明基于上述特征的点云分类算法在保持较高分类精度条件下提升了模型训练速度。"
246,基于文本相似度的版权保护系统的设计与实现,"随着网络时代的飞速发展,网络知识版权问题备受关注,互联网领域的侵权行为日益突出,在版权意识愈来愈强的今天,主动寻求为原创内容进行版权保护的解决方案尤为重要。设计有效的版权保护系统一方面有助于保护社区平台优质原创内容的安全,另一方面为优秀的原创用户提供更优秀的产品体验功能,突出社区重视原创保护的理念,促进原创用户的社区粘性和创作动力。本学位论文从文本内容方面进行文本相似度算法在文本版权保护方面的研究,设计了在版权保护领域下文本相似度的计算方法。文本相似度算法表示采用一定的策略来比较两个文本之间的相似程度,目前文本相似度算法的研究主要有两个方向:一种是语义词典法,通过构建语义词典,将文本中的最佳关键字与词典进行匹配,通过计算匹配对的相似度来表示文本的相似度,另一种是用向量表示文本内容,通过构建空间向量模型,计算向量之间的夹角即两个向量的余弦相似值,从而得到文本的相似度。目前学术界对于版权保护有很多贡献,但在具体文本相似度匹配时往往忽略了文本的上下文语义,为了解决这一不足,本文采用了将Word2vec和LSTM相结合的方法对文本相似度进行分析,提高了文本相似度分析的准确率。以长短期记忆网络(LSTM)算法为基础,设计和实现基于特征值和特征向量的相似度计算方法。首先对语料库进行预训练,包括对文本进行预处理和特征工程,基于Word2vec构建词向量模型,为下一阶段的文本相似度计算模型提供准备。其次,对长短期记忆网络LSTM模型基于内容库语料进行训练和预测,检测句子对之间的相似性。最后设计版权保护系统,进行线上服务,对用户新发表的文章内容进行模型预测,通过返回句子之间的相似度并进行加和取平均计算文章的相似度,同时将原创内容实时更新到原创库中,并实时更新倒排索引库。通过大量对比实验,本系统所采用的基于Word2vec与LSTM的混合相似度计算策略在准确率等评价指标上均优于HowNet等计算方式,通过性能测评证明了本系统具有很好执行效率,对版权保护起到了一定作用。"
247,基于多属性注意力机制的实体解析方法研究,"大数据环境下,海量的数据资源产生于多个数据平台,多源数据融合技术将来自多个数据源的实体信息进行整合,为数据挖掘、机器学习等数据分析任务提供高质量的分析数据集。这些数据集中可能包含大量的重复实体,不但造成资源浪费、还会影响数据分析的结果。实体解析技术是提高数据质量的关键技术,它能够解决数据重复性问题。现实世界中,同一实体可能来自多个不同的数据平台,不同的数据平台对同一实体的描述可能不一致,如数据格式、表达方式等。实体解析的任务就是从大量的重复实体中找出哪些是重复实体,并进行数据清洗,提高数据的质量。目前,实体解析研究主要集中在重复记录检测方面。现有的实体解析方法大多是基于特征匹配的,即人工的提取实体对之间的相似性特征,并设计合适的匹配函数对实体对是否匹配进行判断。一方面,现有的相似性特征都是利用字符或者文本的字面相似性,忽略了语义信息;另一方面,在进行实体匹配中忽略关键属性的作用,即在实体匹配任务中不同属性之间的差异性贡献。这些问题影响实体解析的质量和效率。针对以上的问题,本文提出基于多属性注意力机制的实体解析方法,主要研究内容如下:(1)提出多属性注意力机制的实体匹配模型。为了提取实体对之间的语义相似性特征,本文利用BERT模型做表格数据的预训练,利用表格数据在BERT预训练模型上微调的方式,获得每个字符的高维语义向量。同时,为了突出各个属性对于实体匹配的差异性贡献,本文将表格中的每个元组拆分成单词序列,利用双层LSTM对整个元组进行深度学习建模,同时以属性为界限分割,在每个属性之上添加注意力机制,突出各个属性的差异性贡献。(2)提出基于属性列的加权哈希分块方法。为了提高实体解析的效率,本文在局部敏感哈希方法的基础之上,提出了基于属性列的加权哈希分块方法。本文利用属性列与元组之间的语义关系,计算得到每个属性对于元组语义表达的权重信息,在对属性列进行局部敏感哈希编码之后,利用各属性的语义表达和权重信息对整个元组进行加权哈希编码。本文提出的方法在多个公开数据集上进行实验。实验表明,本文提出的实体解析方案可以有效的提高实体解析的质量和效率,且更适用于大数据量的实体解析任务。"
248,情感文本的识别与分类算法的研究与实现,"近年来,互联网中的社交媒体信息迅速增长,利用好这些网络文本数据,并挖掘和分析其中有价值的情感信息,是非常有意义的。所以情感倾向性分析任务已经成为了自然语言处理领域的研究热点。海量的网络文本中,包含观点句和非观点句,其中的观点句也就是主观性文本才是情感分析研究的对象。因此本文首先实现了对主观性文本的分析和提取,再对主观文本进行了进一步的情感分析,研究其是否能够辅助情感倾向性的计算。论文的主要工作包括:(1)在进行情感文本的识别过程中,本文将词语的词性特征作为主客观分类的重要线索。根据词性标注的结果总结了九类主观特征的词性种类。将词性特征与词向量拼接,结合卷积神经网络,并通过实验确定了词性向量的合理维度和卷积核的大小,设计了基于词性特征和卷积神经网络的主客观分类模型。根据实验结果统计加入词性特征使得模型准确率提高了 2%,并比传统的基于N-POS和支持向量机的主客观分类模型准确率提高了将近4%。(2)在进行主观文本的情感倾向性计算时,文本中的转折句和总结句影响着整个句子的整体倾向性。因此本文提出了基于主干分析的情感分析计算方法。本文总结了包含23个转折性连词和总结性连词的连词词典,通过与连词词典匹配识别出整个句子的主干成分。实验结果表明,加入句子的主干分析的情感分析方法比原情感分析模型的准确率提高了 1%。(3)在文本的各个分句中,不同的程度副词对情感词的修饰表达出的情感强弱不同。据此,本文提出了情感权重词向量的情感分析方法。根据不同的程度副词,结合程度副词词典,赋给词向量相应的情感权重。实验结果表明,情感权重词向量的方法比原情感分析模型的准确率提高了 1.6%。(4)本文最后设置了六组情感分析模型的对比实验,使用LSTM神经网络模型,基于情感权重词向量和主干分析的情感倾向性计算方法与基模型比准确率总体提高了大约2.6%。基于主干分析和情感权重词向量的情感分类模型比传统的基于情感词典和支持向量机的情感分析方法准确率高出8%。实验结果表明,加入情感权重词向量和句子主干分析方法对于情感分析是合理有效的,准确率得到了提升。本文对未进行主客观分类的文本数据进行了情感分析实验,结果表明主客观分类后的文本减少了客观文本对情感分析带来的噪声,有助于情感分析的准确性提升。"
249,基于语义关联关系的不一致数据检测与修复方法研究,"在互联网中存储了大量的网络表格数据,这些网络表格蕴含丰富的语义信息,但表中数据通常存在不一致性,这种由数据不一致性导致的错误可能会给网络表格的使用者带来不同程度的困扰。研究学者们提出了很多网络表格的数据清洗算法,用以清洗网络表格中的不一致数据。现有的数据清洗算法存在一定的局限性:一方面,算法在清洗不一致数据时仅利用了表格中少量语义信息并且需要人为给定约束信息,导致算法的灵活性较差并造成额外的资源开销。另一方面,由于算法存在错误检测不完全等问题,降低了数据清洗的质量。因此,本文提出了基于语义关联关系的不一致数据清洗方法。针对上述第一个问题,本文提出了基于网络表格的语义关联关系构造算法。算法首先利用预训练好的词向量表示网络表格中的列标签,其次通过整体语义相关性识别网络表格中语义信息最重要的关键列,最后使用层次化的语义相关性构造列标签之间的语义关联关系。实验证明,本文提出的语义关联关系可以作为有效的约束信息辅助数据清洗算法。针对上述第二个问题,本文首先利用词向量对网络表格中的拼写错误进行预处理。其次为了有效地减少交叉干扰项对不一致数据检测和修复造成的影响,利用关键列对网络表格进行分块预处理。最后利用语义关联关系作为约束信息,采用最大独立集的思想对分块后的表格进行清洗,并将清洗后的表格合并再清洗。实验表明,本文提出的算法在两个数据集上都取得了较好的清洗效果,并优于现有的数据清洗算法。"
250,基于多源异构数据的混合推荐模型,"随着互联网的发展,互联网中的数据呈现快速增长的趋势,导致了用户难以找到想要的信息,而推荐系统的出现大大减轻了用户查找信息的负担。随着数据的丰富,推荐系统逐渐向结合多种数据推荐发展。单一的评分数据不能充分表达出用户的偏好,而评论数据可以补充更多的用户信息,社交网络能够反映出用户间的相似性。但是目前使用机器学习技术结合评分、评论和社交网络进行个性化推荐的方法较少且存在准确度不高和特征表示困难等问题。本文结合评分、评论和社交网络数据,提出了两种处理多源异构数据的个性化推荐模型:模型一为基于传统机器学习的多源异构数据推荐模型。该模型结合评分、评论和社交网络数据,通过社区划分、评论特征提取和回归算法预测用户对物品的评分。在训练阶段,使用话题或词嵌入模型提取用户评论文本的话题信息,通过社区发现算法为用户划分社区,再使用回归算法训练得到社区模型。在预测阶段,用户特征通过其发出的评论特征叠加得到,商家特征通过其收到的评论特征叠加得到,最后将特征输入回归模型进行评分预测。模型二为基于深度学习的多源异构数据推荐模型。该模型应用深度表示学习算法提取评分和文本中的特征,结合社交网络为用户进行个性化物品推荐。在训练阶段:使用PV-DBOW进行用户评论文本特征的表示学习,得到评论的特征向量,从而得到基于评论的用户和物品特征;使用神经网络学习评分特征,从而得到基于评分的用户和物品特征;通过串联的方式,将基于文本的特征和基于评分的特征进行融合,得到用户和物品最终的融合特征;使用基于对的学习对网络参数进行更新,得到更好的用户和物品的融合特征。在预测阶段,将用户和物品特征相乘得到推荐概率并进行降序排列,得到向用户推荐的物品列表。在实验阶段,模型一对比了不同文本处理方法对评分预测的准确度影响,还和其他的相关模型进行了比较。实验表明,模型一能够提高评分预测的准确度。模型二对比了添加社交网络对推荐结果的影响,然后和其他相关算法进行对比。实验表明,模型二能够提高推荐结果的质量。本文提出的两个基于多源异构数据的模型采用不同算法,分别提高了评分预测和排名推荐的准确度。"
251,多视图K-means聚类算法研究,"大数据时代,人类收集、存储、传输、管理数据的能力日益提高,各行各业已经积累了大量的数据资源。同一数据对象的多源信息采集技术和多样化的特征表示能力使多视图数据在众多实际应用中越来越普遍。而对于特定的机器学习任务,数据对象的多个视图彼此之间通常具备互补性和一致性,有利于利用不同视图的优势提高机器学习的有效性,因此多视图学习逐渐受到了人们的关注。多视图聚类作为多视图学习的基本任务之一,通过充分融合多个视图中的信息,从而获得有效的类划分结果。现有的经典多视图K-means聚类算法,由于其简单高效、易于实现的优点,已经成为众多多视图聚类中应用最为广泛的算法之一。然而多视图K-means聚类算法不但存在K-means固有的初值敏感、类数目事先指定的问题,还存在如何自适应学习视图对类结构的权重贡献,以及样本对不同视图重要性的“局部”学习问题。本论文针对以上两个问题展开研究,取得了如下研究成果:(1)针对K-means型多视图聚类算法的类个数和初始中心选择问题,本文研究了不同初始化方法对多视图K-means的影响,提出一种基于采样的主动式初始中心选择方法(SDPC)。该方法首先对原始数据集进行均匀采样,运用DPC算法和CV指标获得候选类中心和类个数,然后对剩余节点进行直接指派,将得到的指派结果作为多视图K-means聚类算法的初始类划分。相比随机初始化、K-mean s++等其他初始化方法而言,SDPC算法不仅解决了类个数和类中心的问题,实验结果显示SDPC算法还以约10倍的计算速度加快了 DPC算法的种子选取进程,降低了算法的复杂度。(2)针对现有多视图K-means聚类算法没有全面考虑多视图数据的不同样本间存在“局部”信息的差异性问题,本文提出一种新颖的多视图样本权聚类方法(SWMVC)。该方法不仅可以学习不同样本点中的多个视图间权重的“局部”差异,而且学习到的“局部”差异可以反映出不同视图对簇结构贡献的“全局”差异,具有较好的灵活性。多个数据集上的实验表明:SWMVC方法在具有较好互补性的异质多视图数据上聚类效果提升明显。"
252,属性选择算法研究,"不管是科学研究还是工业领域,都已经与各式各样的数据密不可分。随着精度要求的提高,高维数据变得愈加普遍。然而,高维数据不仅带来存储成本和计算开销的大幅增加,其中存在的大量冗余会给机器学习模型带来干扰,并最终导致获取知识的不准确。内在的认知模型往往仅存在于少数属性之中,意味着高维数据存在大量冗余,而用来决策的属性只占少数。因此,在进行数据挖掘或者知识发现之前,需要对高维数据进行预处理,即通过降低数据维度,避免冗余干扰,从而有效提高分类、回归、聚类等数据处理手段的准确性。数据降维技术作为重要的数据预处理方法在机器学习、模式识别、工业生产、科研领域都扮演着极其重要的角色。子空间学习和属性选择是两种主要的数据降维方法,子空间学习是鲁棒性的投影模型,而属性选择是解释性的选择模型,本文旨在稀疏属性选择框架中嵌入子空间正则化因子提出新的属性选择算法,使算法同时具有鲁棒性和解释性。具体来说:1.提出基于自表达和双稀疏惩罚的无监督属性选择算法。通过利用属性自表达损失函数对数据进行重构,然后同时利用l1范数正则项和l2,1范数正则项对重构系数矩阵进行稀疏惩罚,从而实现对冗余属性的双重筛选,使保留下来的属性均为最重要属性。2.提出基于自表达和主成分分析(PCA)正则项嵌入的无监督属性选择算法。通过将经典的子空间学习算法PCA嵌入到稀疏属性选择框架中,在保持数据主信息量不变的前提下学习各属性重要性,从而剔除冗余属性。3.提出基于自适应结构学习和低秩约束的属性选择算法。利用低秩正则项在充满噪声的高维数据中捕捉数据隐藏的全局结构,且利用动态图结构学习捕捉数据的真实局部结构特性,从而为模型的训练提供充足信息并最终提高属性选择的准确性。利用真实公开数据集对提出算法进行验证,在不同的评价指标下,本文提出的算法优于最新的属性选择算法。"
253,基于注意力机制及深度学习的文本情感分析研究,"随着互联网行业的发展,电商评论和社交平台的推广,积累了大量的文本数据。通过提取这些文本信息中蕴含的观点和情感,能够帮助人们做一些决策和推广。文本情感分析已经成为自然语言处理领域中国内外研究的热点方向。传统的文本情感分析模型需要在人工标注的特征工程基础上,并结合语法规则才能取得不错的效果。随着深度学习模型在处理文本序列上的发展,在没有人工标注的特征工程前提下,引入注意力机制,关注文本信息中关键部分,在文本情感分析任务中有着优异的表现。本文主要是以文本情感极性分类和不同主题文本情感分类为研究出发点,构建了正反向序列AT-LSTM模型和融合主题特征的深层注意力的LSTM模型(deeper attention LSTM with aspect embedding,AE-DATT-LSTM)来处理文本情感分析任务。针对文本情感极性分类研究,首先在LSTM网络的模型基础上,为了关注文本中的关键信息,引入注意力机制,构建AT-LSTM模型,采用预训练好的Glove词向量,同时将文本的正反向序列采用注意力机制进行分析,然后进行特征融合和分类处理,构建了正反向序列的AT-LSTM模型。在SemEval-2017 Task4数据集上的实验结果表明,该方法在文本情感极性分类任务中,正反向序列模型提高了文本情感极性分类的准确率。针对不同主题文本情感极性分类研究,构建了融合主题特征的深层注意力的LSTM模型,将主题词向量和文本词向量通过双向LSTM进行训练,对于得到的主题特征和文本特征进行特征融合处理,将得到的特征向量经过深层注意力机制的处理,由分类器得到相应主题的情感分类结果。在SemEval-2014 Task4和SemEval-2017Task4数据集上的实验结果表明,该方法在特定主题情感分析任务中,较之前基于注意力的情感分析模型在准确率和稳定性上有了进一步的提高。对于特定主题情感极性分类任务,通过引入主题特征和深层注意力机制能够使得情感分析模型学习到更多有价值的信息,为舆情分析、文本推理等领域提供了方法的支持。"
254,非平衡过采样方法及其在视频流量识别中的应用研究,"随着网络技术和应用的迅速发展,视频流量成为互联网中增长最快的流量类型,其占据了网络流量的大部分。快速增长的视频流量对互联网的管理造成了严峻的挑战。此外网络中充斥着大量不健康和非法的视频,这些视频严重危害人们的身心健康同时也扰乱了社会的稳定发展,因而从网络的角度对互联网中的视频流量进行有效的管理是一个迫切需要解决的问题。互联网中的视频流量是一种典型的非平衡数据,像色情和暴力的视频相对于正常的视频流量是比较少的,因此互联网视频流量的识别是一种非平衡问题。目前有很多不同的方法可以解决非平衡问题,其中数据层面的方法由于其独立于分类器的特性而受到广泛的关注,然而这些方法有一定的缺陷,它们只是简单的考虑局部近邻信息然后线性的生成数据,这会导致错误样本的生成。本文针对互联网视频流量的非平衡问题展开研究,建立了一个从基础数据的采集到视频流量识别方法的解决方案。在本文中首先提出了一种新的有效特征提取方法,即字节码分布(BCD),为互联网视频流量类型的识别做前期准备。BCD方法首先从视频流中计算每个字节码值(0到255)出现的次数,然后计算每个字节码出现的频率。这样256个比率就是提取的视频流量的特征。比起传统的包层面的特征,BCD特征包含了更多的视频类型信息,可以更加正确地识别。针对视频流量的非平衡问题,本文提出了一种新的数据层面的方法,即生成式学习(GL)。在GL中,采用高斯混合模型(GMM)来拟合原始数据的分布并基于此分布生成新数据。生成的数据包括合成的少数类和多数类,用于训练学习模型。相关实验结果表明,GL方法在与其他非平衡过采样方法对比中具有竞争力,并且Wilcoxon符号秩检验结果证明了所提出方法的显著优势。该方法以较高的AUC值成功的识别出非平衡互联网中的视频流量。为进一步提升非平衡互联网视频流量的识别效果,本文针对GL方法的不足,提出了另一种新的过采样方法,即高斯分布引导的过采样(GDGO)。在GDGO中,首先通过一个计数因素和一个距离因素加权少数类实例,然后通过概率选择机制选择锚点少数类实例,最后以锚点少数类为中心生成符合高斯分布的数据。相关实验结果表明,GDGO的性能高于其他对比的非平衡过采样方法,假设检验结果再一次验证了提出的方法对于解决非平衡问题的有效性。GDGO也进一步提高了非平衡互联网视频流量的识别。"
255,模型决策树方法研究,"信息时代的快速发展使得数据的采集、传输变得更加容易,数据规模也呈现指数式增长的趋势。这样庞大的数据中蕴藏着巨大的价值,所以对大数据的分析和利用便显得尤为重要。对数据进行分类是机器学习领域中的一个重要任务,比如垃圾邮件识别、图像识别、人脸识别、语音识别等。决策树(Decision Tree,DT)凭借其优秀的数据分析效率和易理解的输出结果在分类问题中得到了广泛的应用,然而因为决策树采用递归方法构建,在数据规模较大的情况下,训练效率较低,并且过度分类的决策树可能会产生过拟合现象。因此研究高效的决策树构建算法仍然具有重要的应用价值。本文针对上述问题开展研究,具体内容包括:(1)提出模型决策树方法。针对决策树递归构建造成算法时间变长、效率变低的问题,本文提出一种模型决策树算法(Model Decision Tree,MDT)。MDT算法在训练数据集上采用基尼指数生成一棵不完全决策树,然后用一个简单分类模型对其中的非纯伪叶结点(非叶结点且结点包含的样本不属于同一类)进行分类,进而生成最终的决策树。这样产生的模型决策树与原始的决策树算法相比,能够在算法精度不损失或者损失较小的情况下,提高决策树的训练效率。(2)提出模型决策森林方法。模型决策树虽然能够提高决策树算法的训练效率,但是随着非纯伪叶结点规模的增大,模型决策树的精度也在下降。因此针对模型决策树算法精度较低的问题,提出了一种模型决策森林算法(Model Decision Forest,MDF)。MDF算法将模型决策树作为基分类器,利用随机森林的思想,生成多棵模型决策树。算法首先通过旋转矩阵得到不用的样本子集,然后在这些样本子集上训练出多棵不同的模型决策树,最后将这些树通过投票的方式进行集成。在标准数据集上的实验结果表明,本文提出的模型决策森林在分类精度上明显优于模型决策树算法。本文针对经典的决策树算法在构建时采用递归方式造成训练时间长、训练效率较低的问题开展研究,提出了两种新的决策树模型,不仅可以提高构建树的效率,而且具备了一定的抗过拟合能力。本文的研究成果丰富了决策树算法的研究,具有较好的应用潜力。"
256,基于卷积神经网络和协同过滤的图书推荐系统,"随着当今网络和大数据的飞速发展,人们已经脱离了信息匮乏的时代。网络给人们带来了便利,提供了大量的信息,同时人们对网络上的服务也提出了更高的要求,人们希望得到更快、质量更高的服务。而信息的爆炸式增长,带来了两个问题,一方面,简单搜索不能针对性的提供个性化服务,用户很难在海量的信息中获取到自己不了解但可能感兴趣的信息。另一方面,作为信息的生产者,如何最有效地利用信息,将信息推送给潜在目标用户也是一个难题。如今网络上图书信息成倍数地增长,用户常常需要花费大量时间来浏览、寻找自己感兴趣的图书。为了优化用户体验,个性化推荐算法是有效的解决方法。本文针对于图书推荐系统,提出了效果较好的推荐方法,对系统的整体框架、算法改进进行了阐述说明,论文的主要工作如下:1.构建了图书中文语料库,使用Word2Vec中的Skip-Gram模型对自然语言进行建模,生成词向量,完成了卷积神经网络输入数据的预处理。并对比了现有的三个语料库和本文的图书中文语料库对卷积神经网络输出结果的影响,得出了本文语料库的预处理结果优于现有中文语料库的结论。构建卷积神经网络,本文实现了基于Yoon Kim的网络模型改进的卷积神经网络。实验证明改进后的卷积神经网络在本文的图书数据集的分类问题上要优于原有模型。2.将基于内容推荐与协同过滤进行结合,设计了图书推荐系统,改进后的卷积神经网络应用于基于内容的推荐,与协同过滤结合,得到了优于传统协同过滤的结果,并在一定程度上改善了冷启动问题。"
257,面向短文本的情感分类算法研究,"伴随着信息技术的突飞猛进以及移动互联网的快速普及,广大群众更乐于在互联网上发表自己的评论、分享自己的生活,这创造了互联网上海量、包含丰富情感信息的短文本语料库。对短文本进行情感分类早已经不仅是学术范围内的任务,生活中购物网站通过对消费评价信息进行分析,帮助消费者消除消费者和商家之间的信息不对称,使得消费者购买到满意的商品和享受到优质的服务。政府通过舆情分析系统,利用短文本分析技术引导舆论走向,保护民众利益、维持国家安全与稳定,成为新时代为人民服务的重要手段和途径。因此,面向短文本的情感分类研究有着重要的理论价值和现实意义。本文以“面向短文本的情感分类算法研究”为题展开研究,对当前国内外研究现状和主流算法进行了深入的介绍和分析。针对短文本缺乏丰富的上下文语义信息这一研究难点,从文本表示和分类模型两个方面,进行了以下研究:(1)分布式向量化模型Paragraph Vector是一种隐性语义模型,该模型训练出的向量的每一个维度的含义人们无法解释,且该模型的训练只运用了局部窗口的信息,无法对窗口之外甚至整个语料库的信息加以利用。针对以上问题,本文提出了一种面向短文本的词对主题句向量模型BTPV(Biterm Topic Paragraph vector),该模型将BTM(Biterm Topic Model)得出的全局半显性信息和Paragraph Vector训练过程中的局部隐性信息相融合来训练句向量。实验结果表明,与常见分布式表示模型相比较,基于该模型表示的短文本取得了更好的聚类效果,为研究短文本情感表示提供了技术支撑。(2)基于word2vec和LSTM的中文情感分类方法在训练过程中需要记忆上下文的词语间的关系,导致其效率低下,成本较高。针对这个问题,本文首先在第三章的BTPV模型的基础上提出了一种面向短文本情感分类的分布式表示模型BTSPV(Biterm Sentiment and Topic Paragraph Vector),该模型在训练过程中融合了情感信息,其次提出基于BTSPV和MLP的情感分类方法。实验结果表明,与基于word2vec和LSTM的方法相比,该方法的效率有很大的提升。达到了实际使用中要求的准确率和效率的相对平衡。本文针对短文本情感分类任务,围绕短文本缺乏丰富上下文语义信息的研究难点,开展了系统的研究,提出了面向短文本表示的分布式表示模型与情感分类算法,为短文本情感分类提供了新的技术支撑。"
258,基于深度学习的中文反讽识别及其情感判别研究,"目前,情感分析是自然语言处理中最活跃的研究领域之一。反讽是一种隐式情感表达的修辞手段,通过使用与实际意图相反的词来达到讽刺或者幽默的语言表达效果。反讽的真实语义无法通过文本词汇直接推断出来,它的字面意思和真实意图存在着矛盾冲突,因此,反讽识别及其情感判别更具挑战性。以往的文本情感分析往往忽略了这一语言现象,影响了情感分析的准确率。为了提升文本情感分析的准确率,本文对中文反讽识别及其情感判别开展研究。通过分析中文特有的语言现象和微博的特点,归纳了中文微博反讽的语言特征,提出了融合语言特征的卷积神经网络模型和融合上文信息的注意力机制的LSTM模型来进行反讽识别及其情感判别。主要研究工作如下:(1)中文微博反讽的语言特征选择。由于反讽与语言习惯有关,不同语言的语法结构和语义表达存在差异,和英文反讽相比,中文反讽的语法结构和语义表达更加复杂,使得中文反讽识别及其情感判别在词语层面上比英文反讽识别及其情感判别更具有难度,英文的反讽特征并不能够直接用于中文的反讽识别及其情感判别中。本文在借鉴中英文反讽识别相关工作的基础上,考虑中文微博自身的特点,归纳了中文微博反讽的几种语言特征,并通过卡方统计量选取了多种语言特征对应的特征词。(2)融合语言特征的卷积神经网络模型。传统的机器学习方法依赖于人工选取特征,这些特征的选取需要专业领域知识和大量的实践,而且单凭人工特征难以获得句子的深层语义信息。本文针对传统特征选择方法无法挖掘句子深层语义的不足,采用Skip-gram模型训练微博词向量,提出了一种融合语言特征的卷积神经网络模型。该模型在利用中文反讽语言特征的同时,融合了句子的深层语义信息。实验结果显示,该模型在中文反讽识别方面比传统的机器学习方法有明显的提升,F值达到了0.8187,同样该模型在反讽情感判别方面较单独的CNN模型有一定的改善。(3)融合上文信息注意力机制的LSTM模型。对于微博中的反讽句,它的上文信息往往叙述了反讽的原因,表达了微博的整体情感。因此,上文信息对于反讽识别及其情感判别起着关键性的作用。由于传统的CNN模型仅从连续的N-gram向量矩阵中获取局部的特征,无法解决句子中非连续性依赖和交互性问题,相互独立的节点无法有效表示序列化的文本。因此,为了更好的对句子进行语义表示,本文在融合语言特征的卷积神经网络模型的基础上,加入了LSTM和注意力机制。实验结果显示,该方法提高了中文反讽识别的精确率,并对反讽的情感判别也有一定的提升。"
259,科研工作者合作潜力预测问题研究,"科研合作是学术成果非常重要的实现形式,很多高水平的研究成果通过合作实现,这一现象正凸显了合作在解决科学问题中的重要地位。目前科研合作的相关研究多以合作者推荐为目的,仅对学者产生合作的行为数量做研究,而对于合作结果质量(等级)的相关研究却较为少见。在合作过程中如何选择潜力最大的合作者达到合作收益最大化仍是问题的关键所在。研究合作潜力可以为学者提供预判指导,迅速准确选择与预期一致的合作者,最大化科研效率。随着社会生活和研究方式的升级,对合作行为的分析和解读已成为一个热门的研究课题,计算机技术的飞速发展为大数据的处理和挖掘提供了新的途径。如何根据已有的合作大数据挖掘合作行为背后的潜力模式,预测与当前合作者结果的等级显得尤为关键。本文紧随国内外研究前沿,针对科研工作者合作潜力的预测问题做了一些研究和探讨,取得的成果如下:(1)在数据爆发式增长的信息时代,从海量信息中找到真实有益的关键信息越来越难。为了解决这个问题,基于学者-文章大数据,经过特征分析和优化,综合考虑学者的个人属性和相关属性,分别从文章标题、文章等级、文章数量、时间及署名序多维度构造样本特征,以文章所发表的期刊会议等级作为合作者序列对的样本标签以表示当前合作的潜力高低,利用集成学习方法的强学习特性,提出了基于多因素分析的科研工作者合作潜力预测模型。各项实验指标以较少的样本和时间收敛于较高值,说明了模型的优越性。(2)科研合作数据中包含学者、会议、文章等主体,学者之间有合作关系、学者与文章有署名关系、学者与会议有发表关系等。本文以节点表示主体,边表示关系构建异构信息网络,把更丰富的信息数据赋予“未曾发表高等级文章的普通学者”,依托异构网络下的元路径概念,对未发表过高等级文章学者的合作潜力进行预测,提出了一种基于元路径的方法。该算法以分类方法预测合作潜力,实验效果说明了方法的可行性。总之,本文基于对真实科研合作数据的提取分析,对科研工作者合作潜力预测问题进行了量化建模研究,并在真实数据上对算法有效性进行了验证。本文的研究有助于科研工作者合理选择合作者,分配科研精力使收益最大化,同时也为为科研合作问题的分析提供了新方法与新思路,在合作者推荐和社会网络等领域有一定的价值。"
260,基于深度学习的网络热点新闻预测方法研究,"现如今,互联网的发展如火如荼,催生了多种网络应用。特别是Web2.0与大数据时代的到来,通过大量的网络新闻数据来分析股市,个人理财,关注国家财政大事。网络新闻这一简单快捷的方式,逐渐受到了越来越多用户的青睐。然而各大新闻网站每天报道的新闻数目繁多,质量良莠不齐,用户不可能耗费精力全部查看进而获得有用信息,用户往往只关注网络热点新闻,因此本文针对网络热点新闻的预测问题展开研究,结合新闻文本的特点,论文主要工作如下:1)网络新闻数据的抓取与预处理:使用python设计并实现了网络新闻数据抓取系统,使用爬虫从搜狐新闻网站上的财经新闻专栏抓取以下两类新闻:热点新闻和非热点新闻,并通过时间的积累长期抓取,以获得大量的财经新闻数据,之后将新闻进行整合。为了避免不必要的误差,在形成中文语料库之前,其中中文文本的分词、去停用词处理必不可少,经过一系列的处理最终得到标注着热点和非热点的新闻语料库。2)提出网络热点新闻的深度学习模型:使用双层双向长短期记忆神经网络LSTM的变体GRU和注意力机制Attention来搭建网络新闻流行度预测的深度学习网络模型,在中文维基百科和搜狗实验室网络新闻语料库上使用Word2Vec训练词向量,使用词嵌入层(Word Embedding)将新闻文本用词向量表示,使用预训练的词向量进行初始化,并在模型的训练过程中不断调整,从使用词向量表示的新闻文本中提取抽象化的特征;最后使用全连接层(Dense)进行网络热点新闻的预测。实验结果表明,仅仅通过简单的调参,基于BIGRU-ATTENTION的模型预测结果优于其他基础深度学习模型以及传统机器学习模型,并且使用GRU代替LSTM,提高了效率,节约程序运行时间,为深度学习进行文本分类奠定了良好的基础。"
261,基于深度学习的中文文本分类算法研究,"文本分类是一个典型且基础性较强的研究领域。传统方法是将文本分门别类后依靠人工手段获取特征信息,深度学习方法是将特征提取和分类融为一体,已取代了传统方法,可自动获取特征信息,特别是在数据挖掘、自然语言处理、计算机视觉等方面应用广泛。新闻文本分类是自然语言处理中不可替代的技术,新闻是人们获取最新消息、了解时事信息的最佳手段,使用高效的方法实现新闻文本分类具有重大意义及价值。本文深刻分析了传统文本分类方法存在的劣势,着重研究深度学习方法中的卷积神经网络(Convolutional Neural Network,CNN)和循环神经网络(Recurrent Neural Network,RNN)在新闻文本分类中的应用。论文完成的主要内容如下:(1)针对文本分类中TCNN模型不能充分获取文本局部特征和关键词信息,RCNN模型不能充分提取文本上下文特征信息的问题,论文提出了TC-AM模型和GCNN模型文本分类算法。TC-AM模型使用三层卷积池化操作获取文本局部特征,引入双通道注意力机制(DAM)使得文本表示的特征更具代表性,给文本信息分配相应的权重,获取关键词信息。GCNN模型采用双通道前后向双向门限循环单元(DFB-GRU)充分获取文本上下文特征信息。在搜狗新闻语料上测试表明:两种改进后的模型均表现出较好的分类效果,提高了分类的准确率、精确度、召回率以及F1值。(2)针对TC-AM模型只能获取文本局部特征信息和关键词信息,GCNN模型仅能获取文本上下文特征信息的现象,论文提出了一种基于深度学习融合模型(TGC-AMM)的文本分类算法。该模型旨在结合TC-AM和GCNN两者的优势,使得融合模型既能充分获取文本局部特征信息,又能充分获取文本上下文信息,还能更好表示文本特征,提取关键词信息。在搜狗新闻语料上进行测试表明:融合模型的分类效果突出,可有效提高分类的准确率、精确度、召回率以及F1值。"
262,基于集成学习的多特征Android恶意应用程序检测,"随着大量程序样本的积累,以数据统计为基础的机器学习方法已经成为检测恶意应用的重要方法之一。现有的基于机器学习的检测方法通常以权限或API为特征表示应用行为,这种方法普遍存在特征提取维度过高、特征选取不够全面以及单一分类算法不能有效发挥多类特征在恶意应用检测上所起的不同作用等问题。针对现有机器学习检测方法存在的弊端,本文提出一种新的Android恶意应用检测方法。主要研究内容如下:(1)针对恶意应用检测时对所有权限与API进行提取,造成特征维度过高,检测效率较低的问题,本文总结了恶意应用最常用的50个权限与39个API,并将其作为特征集。通过对大量恶意应用进行分析后发现,大部分API和权限不能够有效区分恶意应用和正常应用,对所有权限与API进行特征提取,会造成大量冗余数据。因此对本文所总结的特征集进行特征提取,可以减少特征提取维度,提高特征提取效率。(2)针对单一使用API或权限特征无法充分体现恶意应用程序的特性,造成一定误报率这一问题,本文提出了一种基于多特征的Android恶意应用程序检测方法。在保留API和权限的基础上,增加了组件、图片、界面元素等资源文件特征,最后将这些特征保存到同一个特征向量集合中,并采用机器学习算法构建了一个多特征检测模型。实验结果表明,新增的资源特征容易提取,而且与单一特征检测方法相比,基于多特征的检测方法表现出了出更好的准确率。(3)应用程序的不同特征在不同机器学习分类算法上的表现会有所差异,单一的机器学习分类算法不能有效的发挥应用程序不同特征在恶意应用检测上所起到的不同作用,针对这一问题,本文提出了一种基于集成学习的多特征Android恶意应用程序检测方法。将提取的权限、API以及资源特征分别用不同的分类算法进行训练并将其结果作为子模型进行集成学习,选取每类特征的最优算法,采用加权投票选择的方式对最优算法中的分类结果进行特征融合。实验结果表明,该集成方法有效弥补了传统检测方法的不足,从而能更加高效地检测Android恶意应用程序。"
263,基于深度学习的异常行为识别算法研究,"随着计算机视觉和深度学习技术飞速发展,在公共安防领域,基于深度学习的一系列智能算法拥有广阔的应用市场和巨大的研究价值。针对监控数据呈现规模巨大、存在冗余无效数据、缺乏高质量标注数据等特点,如何利用深度学习进行高效、准确的异常行为识别是重要研究课题。本文主要分为两部分来开展异常行为识别的研究工作。(1)针对重新训练Inception-v3算法耗时过长,识别率不高,在缺少高质量标注数据的情况下容易发生过拟合等问题。本文使用了一种基于预训练Inception-v3迁移学习识别算法。在特征提取阶段,使用预训练好的Inception-v3算法进行迁移学习提取特征;在预测阶段,建立三层前馈神经网络、k-近邻算法、随机森林、LightGBM、SVM、两层前馈神经网络进行行为预测,并对部分预测结果进行Average算法融合。实验结果显示:相比于重新训练Inception-v3算法,使用预训练Inception-v3算法进行迁移学习识别率更高,更不容易发生过拟合;在迁移特征的基础上,建立前馈神经网络算法预测效果优于传统机器学习算法;算法融合对异常行为识别的识别率进一步的提升。(2)针对采用单一空间流卷积神经网络提取到的特征表达能力不强,进行异常行为识别准确率不高等问题。本文使用双流CNN+LSTM混合算法,采用空间流网络处理RGB图像、时间流网络处理光流图像,分别提取外观特征、运动特征,以增强特征表达能力。同时引入LSTM建立异常行为识别分类算法,相比于普通神经网络,LSTM引入输入门、遗忘门、输出门,在一定程度避免梯度爆炸和梯度弥散,并能捕获时序信息以进行分类。实验结果显示,双流CNN+LSTM混合算法比单一空间流神经网络算法识别率更高。"
264,基于机器学习的文本分类算法,"作为处理文档的重要方式,文本分类在信息处理、新闻分类、舆情监测、文档的自动分类等方面中起着重要作用。最近几十年,机器学习的理论和方法得到了完善和充实,将相关理论和成果应用到文本分类中获得了大量的研究成果。但是在大数据时背景下的文本数据具有数量大、无序、主题分布不均等特点,如何提高文本分类正确率是当前面临的挑战。文本分类需要进行特征选择、文本表示、分类器模型构建,而其中使用到的算法存在一些不足,因此本文将从这三个方面展开对文本分类算法的研究工作。(1)针对词频征选择算法在提取特征项时不考虑特征项与类别间的相关性问题,因此提出了一种基于词语相似度和词频混合特征的文本分类算法。该算法通过计算每一类文本所有的词条与对应类别特征项表中的特征项的相似度值,若计算的值大于预先设置的相似度值时给予保留作为内容,反之不保留。当计算所有文本集合中词条的相似度值之后,通过词频提取与类别相关性较强的特征子集,剔除对类别划分影响较大的特征项。实验验证了改进后算法的有效性。(2)针对传统的VSM存在维度过高、向量化表示非常稀疏、无法很好地表示文档的语义的问题,提出基于TF-IDF和Word2vec改进的向量空间模型。该模型通过在预处理的文本集合上使用Word2vec计算所有单词向量,并对从每个文档提取的特征项执行TF-IDF权重计算,最后通过结合特征项的权重和词向量将整个文本表示成空间向量。实验验证了改进后模型的有效性。(3)针对SoftMax回归线性模型最终产生的决策超平面属于线性模型,而文本分类具有非线性的特性,使用该模型分类会影响文本分类的宏F值问题,本文通过扩展类别属性Xn的平方项和互乘项得到非线性SoftMax回归文本分类算法,该算法将决策函数中的线性假设转化为非线性假设获得非线性模型。实验验证了改进后算法的有效性。"
265,基于迁移学习的谣言检测机制研究,"随着互联网技术的快速发展,在线社交网络成为一种新的信息发布和共享的服务平台,逐渐成为人们日常学习、生活中的重要组成部分。由于这些平台发布信息的门槛较低,且信息多样化、表达自由化,使其成为谣言的产生与扩散的绝佳平台。而恶意的谣言往往具有一定的危害性,容易引发社会恐慌,这对社会的进步、国家的发展尤其不利。社交网络中,不实信息的泛滥特别是谣言的充斥已近成为日益突出的社会问题。现有的谣言检测方法主要采用传统的机器学习方法进行检测,这些方法都需要大量的数据标注。然而,微博文本内容短且具有随意性,这些特性使得大量且有效的标注数据非常难以获取,标注样本又非常费时费力。再者,人的主观因素容易导致其对谣言产生误判。与此同时,微博信息更新迅速,能够被有效标注的数据已经不足以训练得到一个可靠的分类模型。迁移学习是运用已存有的知识来实现对相关领域问题进行解决的一种机器学习方法。而意见评论检测的数据与方法与微博谣言又具有一定的相似性。随着迁移学习的出现,传统机器学习中的两个基本假设被打破,为解决上述问题提供了可能。目前迁移学习主要应用于图像处理等领域,如何有效实现迁移学习在谣言检测领域的应用,也成为一大难点。针对以上问题,本课题针对Twitter中充斥的谣言进行识别与检测,采用迁移学习方法,将评论中的知识进行迁移,以此实现目标域(即谣言检测领域)的有效分类。主要工作内容如下:首先,需要对源域与目标域数据进行数据处理与分析。其次,本文提出了一种基于卷积神经网络(Convolution Neural Network,CNN)的深度迁移模型来实现对Twitter中谣言的检测。具体来说,本文给出了一种学习率自适应更新的方法来解决迁移过程中出现的负迁移现象。最后,使用深度学习框架TensorFlow实现了所提模型,在已标注谣言规模不足的情况下,构建了更为准确的谣言检查机制。经过实验验证,本文提出的模型在谣言检测上取得了更为准确的识别结果,可以作为一种有效的谣言检测手段应用于实际工作。"
266,基于深度学习的监控系统特定人脸模拟生成方法研究,"在机场、火车站、教室等公共监控系统应用环境下,采集到的人脸图像往往是在不受控条件下,具有多种变化。例如人脸姿态、光照、小部分遮挡等影响,造成的人脸图像信息缺失导致识别性能迅速下降。传统的一些机器学习方法使用的是浅层结构,这种神经网络无法探索到样本内部的复杂函数,例如BP神经网络和支持向量机等,并且极易受到例如光照、复杂背景等外界因素的影响,泛化能力均有明显不足。深度学习通过深层的神经网络结构学习并表征输入数据分布式表示,拟合复杂函数,体现了深度学习对输入数据深层特征的提取能力。因此本课题选用基于深度学习的生成模型方法克服不受控条件下人脸图像部分信息缺失的影响,对缺失数据进行预测补充。本课题主要对深度生成模型(如生成式对抗网络GANs等)的学习原理、训练参数以及人脸生成的效果进行应用研究。通过提取公共场合监控中的静态人脸图像,对截取的人脸图像归一化、打马赛克模拟遮挡情况等预处理,构建训练集。使用TensorFlow深度学习框架,将处理好的训练集分别输入深度卷积生成式对抗网络(DCGAN)、基于上下文编码器的生成式对抗网络和基于Pix2Pix方法的生成式对抗网络进行训练和调参等操作,并针对应用背景进行模型结构的加深优化,保存训练好的模型,将训练结果进行对比分析。在Keras深度学习框架下,通过迁移学习VGGNet对课堂监控下的学生面部表情进行特征提取并分类,通过人脸表情识别正确率的比较来评价实验系统中所使用的方法。实验测试系统使用PyQt进行研究开发,对输入的人脸图像被遮挡区域进行马赛克处理,通过模拟生成,输出完整的人脸图像,最后对修复后的人脸图像进行表情识别,实验结果证明了算法的有效性。"
267,基于信息融合的图像显著区域检测算法研究,"图像显著区域检测是计算机视觉领域的研究热点,图像显著区域检测的目的是模拟人的视觉注意力机制,选择出图像中最吸引人的部分,为后续的图像处理提供便利。图像显著区域检测在图像分割,目标检测,图像检索等领域都具有非常广泛的应用。随着应用领域的拓展以及应用场景的复杂,显著区域检测技术还在不断的发展。本文对图像显著区域检测的相关理论以及已有的算法进行了分析,并提出了两种显著区域检测方法。基于局部显著信息的频繁项挖掘显著区域检测方法具有较高的准确性,但是检测时使用的局部显著信息会使检测到的显著区域不完整。为了让检测算法在考虑检测准确性的同时,还可以得到较完整的显著区域,本文在基于频繁项挖掘的显著区域检测算法中加入了基于轮廓特征的全局显著信息,提出了基于局部与全局显著信息的显著区域检测方法。实验表明该方法可以得到完整的显著区域,可以提高图像显著区域检测的准确性。基于神经网络的显著区域检测算法是任务驱动的显著区域检测方法。为了使网络能结合不同尺度的显著区域信息,能够利用已有的基于轮廓完整性的先验知识,同时不断的修正自己的检测结果,本文融合了显著先验与输入图像,把全卷积神经网络中不同尺度的特征相互融合,采用基于轮廓完整性显著先验及多尺度特征融合递归全卷积神经网络来进行显著区域检测。实验表明该方法可以得到较好的检测结果。"
268,基于BLSTM的中文短文本情感分析算法研究,"文本情感分析是依据文本数据提供的特征计算该文本的褒贬等情感倾向,为制定决策提供有效依据。文本情感分析是自然语言处理的基本任务,是人机交互、人工智能的关键技术之一,被广泛应用于国防建设、政府管理、舆情分析、医疗卫生及商业等领域,通过大数据文本分析,可为国家方针政策制定、社会改革、企业经济运行及个人的日常工作生活等提供辅助支持。目前,已有的情感分析算法虽然已经取得了一定的效果,但是,依然存在着一些问题和挑战。例如,词向量的文本表示方法存在分词歧义及无法表示一词多义的现象;普通神经网络方法无法很好地识别短文本稀疏特征中更重要的部分,不能充分利用文本的句法结构等信息。针对上述问题,本文主要研究内容包括:1.针对目前中文信息处理领域以词向量表示文本时对分词准确性要求较高,无法处理分词歧义与一词多义现象的问题,提出一种改进的基于字向量的双向长短时记忆网络(Bi-directional Long-Short Term Memory,BLSTM)情感分析算法。利用字向量对中文短文本进行细粒度表示,通过BLSTM网络捕捉句子的上下文语义信息,降低了分词可能产生的噪声对算法性能的影响,有效提升了短文本情感识别算法的精度。2.针对传统神经网络算法无法更好的关注中文短文本的局部关键特征,对全局信息拟合能力较弱的问题,提出了基于自注意力机制和BLSTM的情感分析算法。采用BLSTM编码文本序列后利用自注意力机制进行动态权重调整,结合全局语义信息得到关键特征,仿真实验表明该算法的性能得到较大提升,在两类数据集上最好的F1测度分别为89.74%和91.10%。3.针对现有深度学习算法未考虑句子的层次结构及语义信息的问题,提出基于分治策略和SATT-BLSTM的情感分析算法。该算法利用分治策略,以字向量为单位自底向上融合为短语向量,再得到句子的情感特征表示,同时引入句子的结构信息用于情感判别,实验结果表明了该算法的有效性和可行性。"
269,基于机器学习的Android本地层代码混淆分析研究,"在Android app源代码加固与保护领域,相较于Android Java层代码混淆保护,针对Android本地层(Android Native)代码的混淆保护是一种应用范围更广、分析难度更大的防护方式。Android本地层自身可用的混淆器和混淆方法的多样性,导致了安全分析人员逆向分析的难度和开销的增加。因此,如何能够从Android本地层混淆样本中正确识别出所使用的混淆器和混淆方法,既能更好地辅助安全分析人员逆向工作的开展,有利于逆向工具的裁剪和优化,也能促进混淆算法的更新,并进一步提升混淆算法的有效性和安全性。目前已有的各种利用机器学习针对Android app的反混淆主要针对于易分析的Java层,对于逆向难度更高、恶意负载聚集得更多的Android本地层,由于混淆变换的复杂性,相关的分析和研究还并不够多。本文以Android本地层原生程序为切入点,通过逆向工程对Android本地层中的混淆技术进行研究,并借鉴一些经典的机器学习算法,结合Android本地层的特殊性进行考虑,提出了一种Android本地层混淆程序识别方法ANRec来识别出其中所使用的混淆器和混淆方法。该方法主要包括以下几个方面:(1)针对Android本地层混淆样本的难获得问题,本文并不采用传统的样本获取思路,即先爬取大量apk,再逆向分析判别所用的混淆器和混淆方法的方式,而是采用本文所设计的Android本地层混淆样本生成器直接有目的性地生成不同混淆样本来进行研究。(2)为了更好地对Android本地层混淆程序所使用的混淆器和混淆方法进行分类和识别,本文首先通过逆向工程对不同混淆器和不同混淆方法所生成的样本进行处理,以求了解其内部工作原理,并寻得一些具有信息性的特征。(3)对于不同混淆器的分类和识别研究,本文根据之前逆向工程所研究出的混淆器相关工作原理,设计了一种基于图神经网络的Android本地层混淆程序的混淆器分类与识别方法。(4)对于不同混淆方法的分类和识别研究,提出了文本化的特征提取方法,分别从静态和动态反汇编文件中提取相应的词频逆文本频率特征,并使用经典的机器学习算法进行分类器训练。(5)设计并实现了基于ANRec方法的原型系统,并通过实验进行分析评估。实验结果表明两种不同的分类模型对Android本地层混淆样本都具有较好的识别效果,并基本上能够准确预测和识别出所使用的混淆器和混淆方法。"
270,基于机器学习的人脸检测算法研究,"人脸检测是图像处理的重要组成部分,也是计算机视觉的一个重要研究领域,在智能安防、人机交互及免密身份验证等方面有着非常广泛的应用。目前人脸检测方法对于姿态视角多变、背景复杂、光照变化等影响因素的处理还存在着局限性。本文在机器学习理论框架下对人脸检测算法进行了探究,提出了两种提高人脸检测准确性和鲁棒性的算法:1.为了提高姿态视角多变情况下人脸检测的准确性,本文提出了基于BING和多纹理CS-LBP的多视角人脸检测算法。该算法中将二值化规范梯度(BING)引进到人脸检测中,训练能够进行人脸目标筛选的两级模型,实现对人脸区域的初选。基于中心对称局部二值模式(CS-LBP)改进多纹理特征,分别从四个纹理方向对人脸图像进行表达,增强算子的辨识能力。此外,通过计算面部拓扑距离完成人脸姿态视角划分,采用多个单视角嵌套级联分类器和多层感知器(MLP)级联相结合的人脸检测结构,提升对多视角人脸检测的鲁棒性。通过在人脸数据集FDDB和PASCAL Faces上的相关验证实验,结果表明本部分提出的人脸检测算法能够有效地提高人脸检测的准确性和检测速度。2.为了弥补单一特征在人脸描述方面的局限性,本文提出了基于局部多核学习特征融合的人脸检测算法。该算法将多纹理CS-LBP特征、ORB和HOG进行联合,从纹理信息、关键点提取和梯度特性三个方面描述人脸图像。对每种局部特征进行稀疏编码并采用空间金字塔匹配视觉词袋模型对编码向量统计表达,增强描述子的抗干扰能力。为了实现多特征的有效联合,提出了基于局部多核学习(LMKL)改进的特征融合算法,引进多特征融合的方式,构建新的选通函数,通过学习为每种特征赋予相应的权重,保证权重分配的合理性。实验表明,本部分提出的基于局部多核学习特征融合的人脸检测算法能够更加全面地反映人脸图像特性,有效地提高了人脸检测的鲁棒性。"
271,基于生成对抗网络的跨年龄人脸识别技术研究,"人脸识别因具有不易伪造、用户易接受、检测方式便捷且可靠性高等优点,在现实生活中得到了广泛应用。然而,人脸识别技术面临的一个重要制约因素在于跨年龄段人脸识别问题,即由于待检人员实际年龄与其保存在数据库中的面部图像采集的时间,存在较大的差异,导致人脸面部的信息特征发生明显改变,出现无法有效识别或误识别的情况,尤其在年龄跨度越大情况下,无法有效识别或误识别的问题更加严重。针对上述问题,本文先对人脸识别系统中的机器学习方法进行研究,设计了基于机器学习的跨年龄人脸识别实验,通过实验发现:常用机器学习的方法不能很好实现跨年龄人脸识别的目的。对于这一问题,并结合近几年来,生成对抗网络在图像处理和机器视觉领域中良好的实验效果,本文对生成对抗网络技术展开深入研究,提出了一种基于生成对抗网络技术的人脸跨年龄段识别方法,该方法利用条件性对抗自动编码器(Conditional Adversarial Auto Encoder,CAAE)模拟生成待检人员在不同年龄段的面部图像,利用生成图像与数据库中所保存的图像进行相似性比对。通过减小人脸随着年龄增大而带来的特征差异,从而提高跨年龄人脸识别率。本文设计并进行了单样本不同年龄人脸验证实验与指定年龄段多样本人脸验证实验,实验结果表明,本文所提出方法在指定年龄区间内经CAAE生成的模拟人脸图像在用于跨年龄识别时,其识别准确率明显高于未经CAAE处理的跨年龄人脸图像,为人脸跨年龄段识别问题的研究提供了一种新颖、可行的思路与方法。"
272,基于DNS日志的用户访问行为分析和研究,"国内的各个高校先后建设了自己的校园网络,实现了教育信息化和互联网化。快速便捷的校园网络为高校师生提供了丰富的资源,开阔了学生的眼界。用户在使用网络获取信息的同时,会产生大量的访问数据,从海量的用户访问数据中挖掘出有价值的信息成为近年来的研究热点。在复杂繁多的日志中提取有价值的信息并对这些信息进行分析和建模是本文研究的主要内容。本文以学校信息中心的DNS日志为数据源,所做的主要工作如下:(1)对原日志数据过滤和清洗。去除重复和无用的数据,为以后的数据分析打下基础。(2)对日志中用户访问域名分类的研究。在DNS日志中,用户访问的域名是一个非常重要的字段,通过对域名的归类,能够得到用户的部分网络访问特征。本文采用域名分类库和域名分类器两种工具相结合的方法对域名进行主题归类。域名分类库的建立是通过网络爬虫爬取域名分类网站得到的。域名分类器则是采用机器学习算法在大量的已经归好主题类别的域名基础上训练得到的,主要作用是对未在域名分类库中匹配到的域名归类。(3)对用户网络访问特征聚类的研究和分析。通过对用户访问的域名标签化处理,得到用户行为特征向量,之后进一步对这些数据做聚类分析,得到不同的用户群的访问特点。本文分析了K-means聚类算法的不足之处,采取Canopy算法和K-means相结合的方式来对用户聚类分析。针对课题数据存在数据量大且维数较多的特点,本文实现了基于Map Reduce编程框架下的分布式K-means聚类算法,实验证明,该算法能够有效的根据用户特征聚类。(4)用户网络行为特征的统计分析。本文从多个方面对学生上网行为特征进行了分析,包括不同时段用户访问活跃度、用户访问域名主题分析、域名访问量分析、各个用户群的特征分析等等,在多个维度上展现了用户的访问特征。本论文通过对北京交通大学信息中心的DNS日志挖掘和分析,得到用户的上网行为习惯和访问偏好,最终得到学生的网络行为特征,旨在引导学生合理的应用网络,为全校师生提供更优质的网络服务,为校园管理人员掌握学生的网络使用状况提供依据。"
273,微博上谣言的特征提取及识别算法的研究,"随着社交媒体信息的快速发展,以新浪微博、抖音、快手为代表的新兴媒体平台成为人们获取信息、分享信息、传播信息的主要平台。然而,这些社交媒体平台带来信息访问的便利性和丰富性时,也为虚假信息的传播带来了便利性和广泛性。社交媒体中谣言的广泛传播严重阻碍了人们获得可靠信息的途径,并可能在一些紧急情况发生时导致巨大的经济损失或造成严重的公众恐慌。传统的谣言检测方法将谣言视为分类问题,致力于提取谣言的社交特征,但是这些方法都忽略了当前庞大的官方谣言数据集和谣言的语义特征。近年来,深度学习在各领域中取得了一定成就,同时词向量表示在应用中表现出良好的性能,这为谣言检测领域的相关研究带来了启发。为了解决目前谣言检测中存在的单一特征的问题,本文从传统的谣言检测方法和基于深度学习的谣言检测方法两方面入手,利用官方认证的谣言数据集提取谣言的社交特征,以实现谣言的早期检测。同时,结合词嵌入表示和神经网络模型,以提高谣言的语义特征检测,并将语义特征和社交特征融合,全方位多层次的对社交媒体上的新闻进行虚假新闻识别。主要的研究工作包括:1.设计基于主题和预防模型的谣言检测算法。首先对官方谣言数据集主题提取,按主题分类后提取该谣言子集的特殊符号的统计特征。然后将样本与官方谣言子集中的微博进行相似度计算,将其值作为统计特征进入有监督的机器学习。最后实验结果表明,提出的分类特征有效的提高了检测谣言的正确率。同时,在早期谣言检测工作中也具有较好的效果。2.设计基于多特征融合的深度神经网络模型来学习事件级新闻的谣言检测。事件级新闻指新闻发布的原始微博及相关的评论转发内容。事件级新闻可以获取更多的语义信息同时展示了该新闻的传播途径。将事件级新闻划分成子事件,每个子事件提取语义信息,将子事件的向量表示作为输入向量输入到神经网络中,以学习子事件的语义特征和潜在的时序特征,同时提取该事件的社交特征,将神经网络的输出和社交特征结合做分类结果,来提高模型的表达能力。实验结果展示,该模型比传统的谣言检测算法得到的正确率提升了 9%左右,比消息级新闻的谣言检测算法检测效果提升了 4%左右,同时比单语义特征的谣言检测模式更有效。"
274,文章内容低质量审核系统的设计与实现,"随着移动互联网技术的日趋成熟,网络自媒体平台迎来发展热潮。用户对于资讯信息需求的不断提高促使网络自媒体平台呈现多样化发展,从单纯地发布新闻资讯扩展到提供生活、娱乐、社会、财经等各方面内容。相比于传统媒体,网络自媒体平台具有较高的自主性,言论尺度相对宽松。与此同时,由于自媒体平台的进入门槛较低,导致其中的文章良莠不齐。若不能对文章进行有效筛选,很可能造成错误的舆论导向。对待发布文章进行内容审核,剔除其中包含低质量信息的文章,以确保营造积极向上的阅读环境是目前各网络自媒体平台面临的关键问题。然而,在当下的信息爆炸时代,每天产生的资讯文章可达百万篇。显然,采用传统的人工审核方式不仅产生的人力资源成本较高,而且无法在保证信息时效性的同时达到较为理想的效果。因此,采用机器审核的手段对文章进行检测是解决上述问题的关键方法。本文设计的文章内容低质量审核系统采用机器学习和深度学习的相关算法对文章进行审核。从文章的文字内容和图像内容着手,去检测文章是否符合规定。作者独立设计并完成了以下三个模块:(1)政治敏感审核模块提供对文章政治敏感程度的识别。比如文章内如含有描述危害国家社会安全稳定的内容时,则会被识别为政治敏感类文章。政治敏感审核模块采用机器学习相关算法模型进行识别。(2)低俗色情审核模块提供对文章低俗色情识别的功能。针对标题、内容和文章所附带的图片进行色情程度的识别,综合各识别结果得到一个总的低俗色情程度的预测。(3)广告营销审核模块提供对文章是否是广告营销文的识别。在识别过程中,会对文章文字内容进行是否是广告营销文的识别,同时对文章内附带的图片进行检测是否存在宣传广告的矩阵式二维码(QRCode)。文章内容低质量审核系统被应用于针对网络自媒体发布文章的审核。线上测试结果表明,在文章内容低质量审核系统应用上线之后,各类违规文章的数量相较于系统上线之前,数量明显减少,从而改善了阅读环境,从而达到了本系统的设计目的。"
275,基于机器学习的参数注入式攻击检测方法研究,"网络攻击行为检测在网络安全防御体系中起着重要的作用。当安全防护网被攻击者突破,能否及时检测到攻击行为是对攻击行为响应和阻断的前提,因此如何提高攻击行为检测的准确率和响应时间是衡量攻击检测模型的重要指标。Web服务作为互联网中信息服务的主要方式,Web技术快速更新的同时伴随着安全问题也在增多。如何对Web攻击行为进行快速准确的检测是当前网络安全研究面临的重要课题。本文针对目前Web攻击检测技术存在的过分依赖特征库、误报高等问题,并针对Web攻击的特点,提出基于隐马尔科夫机器学习的方法建立Web攻击检测模型。测试表明,本文方法在对攻击行为识别速度和识别准确性方面较当前主流方法有较大程度的提高。本文的主要工作有:(1)建立数据集,收集了 Web应用中的正常访问请求和攻击行为请求。收集了18000条正常访问序列作为基于正常访问序列建立检测模型的数据样本集。收集了20000条恶意攻击样本,2500条跨站攻击样本,500条SQL注入作为基于恶意攻击行为建立检测模型的数据样本集。(2)建立隐马尔科夫机器学习框架,利用数据集对框架进行训练得到Web攻击检测模型。(3)对模型进行测试,测试表明本文使用隐马尔科夫模型对网络攻击行为的检测,基于正常访问样本集建立模型对异常攻击访问的检测率为97%。异常访问样本集建立模型对异常攻击访问的检测率为98%。模型的泛化检测能力测试中,对基于正常访问样本建立的检测模型对混合样本进行检测的识别率和基于攻击样本建立检测模型对攻击行为检测的识别率进行了测试。"
276,类别不平衡学习方法及其在Android恶意应用检测中的应用,"随着移动设备的普及和移动应用用户数量的爆发式增长,移动智能终端安全面临着巨大挑战。机器学习作为人工智能领域的重要方法,近年来在通过分析网络行为进行移动恶意应用检测的研究中得到了广泛应用。然而,由于网络流量天然存在的类别分布不平衡特性和持续到达特性,给机器学习模型训练带来了诸多困难与挑战。首先,在真实环境中,正常行为的网络流量数量要远远多于恶意行为的网络流量数量,这种类别不均匀分布的数据集使得传统的基于数据集类别均匀分布假设所设计的分类算法无法达到预期的分类效果。其次,网络流量每时每刻源源不断地产生,数据规模越来越大,给机器学习模型构建带来了巨大困难。本文针对基于网络流量进行的Android恶意应用检测领域中遇到的上述关键问题,从普适的类别不平衡学习方法入手,到Android恶意应用检测领域中特有的类别不平衡学习方法,最后到大数据环境下的类别不平衡学习方法,由简入繁,系统地开展了以下研究工作:(1)针对于类别不平衡学习问题,提出一个基于自适应加权和高斯概率密度函数的过采样算法。该算法通过分析位置和样本数量两种因素,给每一个少数类样本分配不同的权重,然后根据此权重,结合高斯概率密度函数,合成少数类样本。该算法在37个公开的非平衡数据集之上,通过与7种现有的数据重采样方法对比,验证了其有效性,并成功应用到Android恶意应用检测领域中。(2)针对于类别不平衡学习问题,提出一个基于多样性测量和种群增量学习算法进化的非平衡集成学习模型。该模型以本文设计的样本多样性测量指标为适应值函数,借助种群增量学习算法生成一个具有最大多样性的训练子集合。通过与相关算法在44个公开的非平衡数据集上进行测试,证明该模型具有显著性优势。此外,该模型同样成功应用到Android恶意应用检测领域中。(3)针对于基于语义信息构建Android恶意应用检测模型中的类别不平衡学习问题,提出一个基于signature辅助的随机过采样模型。该模型通过借助提取的HTTP协议流中的signature实现合成全部为内容特征的新恶意样本。在与11种数据重采样方法在两种不同非平衡率的网络流量数据集上的对比实验中,该方法表现突出。(4)针对于大规模网络流量数据的类别不平衡学习问题,改进了一个基于分布式框架的类别不平衡学习模型。该模型利用Spark分布式平台的广播机制使每个计算节点上都能保留全部的少数类样本信息,并且可以自适应地寻找最佳过采样比例。应用该模型,可以有效的在大规模类别不平衡网络流量数据集上构建Android恶意应用检测模型。综上所述,本文针对于网络流量数据的类别不平衡分布和海量数据规模问题,提出了有效的解决方案,并通过实验验证了本文所提方法的优越性。本文的研究工作对推进恶意应用检测领域中的大数据条件下的类别不平衡学习问题具有一定的理论意义和应用价值。"
277,基于机器学习的武警警务数据研究,"随着改革强军的稳步推进,部队信息化正在加速发展,各大战区、军兵种、军委机关的数据量迅速增长。武警警务数据作为部队数据之一,虽然具有广阔的应用前景但由于保密规定限制,敏感度高,不易从互联网获取等特点,一直未被各级重视和合理利用,本文在深入了解国内外警务数据分析研究的基础上,合理地采用LSTM神经网络模型,对处理后的武警警务数据进行训练,用来预测未来一段时间内某个地区发生危及社会稳定的重大事件的数量。具体研究内容如下:1.传统的武警警务数据存储方式粗放多样,复杂而繁琐,数据源涉及众多领域,类别多,结构各异,有着大量的无用信息。本文对警务原始数据进行了整理和分类,采用删除法和填充法处理数据中的缺失值,对于离散型数据运用one-hot编码来处理属性分类问题,并运用数据概化方法来提升数据的一致性,通过将现有数据中的信息进行清洗,筛选,将数据的储存变得标准化,归一化,达到预测系统可以应用的水平。2.本文对原始武警警务数据进行收集和处理后,将之用于训练LSTM神经网络模型。本文设置24种不同的参数,进行不同的测试,最终得到了一个相对有价值的预测模型。"
278,基于XGBoost混合模型的LF钢液温度预估研究,"精炼炉(LF)精炼过程是炼钢过程中重要的工艺过程,在我国冶钢企业中已经得到广泛的应用,LF精炼工艺中最重要的环节是温度控制,如何精确控制钢液温度是历来研究的重点。LF精炼过程钢液温度的精确控制,有助于提升成钢质量、降低炼钢成本、选择最佳控制策略、降低人员操作风险等。在实现LF精炼过程的钢液温度自动化控制中,LF钢液温度预估模型的精确预估起着至关重要的作用。首先,本文对LF精炼工艺过程及影响钢液温度因素进行研究分析,针对专家系统预估模型在钢厂实际应用中的不足,并结合机器学习算法的强大学习能力,设计了一种基于极限梯度算法(XGBoost)的混合预估模型,实现智能预估模型和专家系统预估模型并行预估,这种混合预估模型不但提高了智能模型精度,而且将智能模型和专家系统预估模型两者的优势进行了互补。用实际生产的数据对模型进行训练和测试,结果表明该模型具有较好的适用性。其次,鉴于XGBoost算法的结构复杂性,在学习过程中涉及多个参数优化问题,不同的参数组合可能造成模型的精度相差较大。在参数优化方面,传统的随机搜索和网格搜索法效率非常低,使得算法具有一定不确定性和随机性,因此本文采用贝叶斯优化算法(BOA)对智能模型中的参数进行优化,构建了BOA-XGBoost算法与专家系统预估模型混合预估的模型,然后对模型进行训练测试实验,实验结果表明使用BOA参数优化效果要优于传统参数优化方法,并将优化后和比优化前的混合模型进行对比分析,优化后的混合模型的精度有了明显的提升,模型更符合企业生产需求。最后,将优化后混合预估模型应用到LF精炼系统中,设计了一个温度预估功能模块,并利用实际生产数据对其功能进行了测试。测试结果表明,该温度预估功能模块具有较高的精度和稳定性,适用于LF精炼过程中对钢液温度进行预估,为LF精炼过程钢液温度精确控制提供了参考依据。"
279,基于SVM的高速公路PPP项目融资风险研究,"对于资金量大、融资困难、建设时间持久、工程量繁杂的高速公路建设工程项目来说,解决资金问题是首中之重。为此,中国积极引进欧洲盛行的公私合营的项目模式――PPP模式,很大程度上降低了政府在相关项目上的资金压力。但是引进新模式有利有弊,PPP模式在中国应用时间比较短,虽然已建立了相关的规章制度,但发展规划和方向还不够明确,也没有相当完善的制度保障,因此,PPP模式在中国项目的应用上,存在着相当多的风险。风险不仅仅与项目相关各方的利益收入有关,同时也与投资的成败息息相关,这也正是PPP模式下高速公路项目融资风险研究的必要性。本文研究的主要结论有:(1)本文在研读文献的基础上,结合工程实际,对高速公路PPP项目的融资风险进行了详细分析,按照风险的表现形式将高速公路PPP项目的融资风险因素分成7个类别,分别是:政治环境风险、经济环境风险、工程建设风险、技术风险、经营管理风险、环保风险以及不可抗力风险,后又将这7大类风险因素进行详细分类,分类出共25个风险因素,形成25个风险评价指标,以此建立起高速公路PPP项目融资风险的评价指标体系;(2)本文结合工程实际,引出了一种机器学习的方法――支持向量机回归(SVR)评价预测模型对高速公路PPP项目的融资风险进行评价预测,经过实例验证得出,支持向量机回归预测模型在攻速公路PPP项目融资风险评价预测问题上确实具有可行性及预测准确性;(3)在SVR的基础上,使用启发式的智能算法遗传算法(GA)和蚁群算法(ACO)对支持向量机回归评价预测模型进行优化,可得到参数优化后的均方误差MSE,通过对比各算法对支持向量机模型中参数优化的均方误差MSE可知,蚁群算法和遗传算法在支持向量机模型参数选择和优化问题中确实有优化效果,且遗传算法对参数的优化效果相对更好一些;(4)通过对比两种启发式智能算法的优化效果及优化后模型的预测稳定性可知,以绝对百分比误差APE作为稳定性评判标准时,遗传算法的优化效果最优且相对更为稳定,同时证明了遗传回归支持向量机(GA-SVR)评价预测模型在高速公路PPP项目融资风险评价预测问题上的适用性、预测的准确性和稳定性。(5)分析GA-SVR模型的预测结果可知所举实例项目的总体风险较大。使用PPP模式的高速公路项目基本属于资金量庞大、技术要求高的项目,在项目的每个阶段都存在着一定的风险因素,这些因素对项目整体的影响程度或大或小。在这种风险指标众多而训练样本较少的情况下,使用支持向量机这种小样本的机器学习方法对风险进行评价预测,将会是一个高效且准确的选择。"
280,面向短时交通流分析与预测的循环神经网络算法研究,"自改革开放以来,中国经济水平增长迅速,且目前仍处于中高速增长水平,在此基础上我国的汽车行业与居民的汽车保有量蓬勃发展,但与此同时居民交通出行压力日益增加,智能交通系统智能化的要求不断提高。短时交通流预测是智能交通系统的一个重要研究方向,准确高效的短时交通流预测,对交通诱导与管理,国民出行具有重要意义。本文针对短时交通流预测研究的主要完成以下工作:(1)针对本文实验的交通流数据集完成数据剪枝,数据清洗与填补,完成建模过程中必要的流量统计,时间序列划分等工作,为后续研究做出重要铺垫。(2)本文研究并实现了基于PageRank算法的交通网络节点拥堵预测方法。利用交通网络结构和网页结构的相似性,计算度量交通网络节点的PageRank值,并发现t-1时刻交通节点的PageRank值和t时刻该节点的交通拥堵指数存在强线性相关性,以此相关性来预测交通拥堵状况,实验验证此预测方法有83.6%的平均准确率。(3)本文研究并构建了基于循环神经网络的短时交通流预测方法,在实验数据集上首先对单一采样点的交通流量在Vanilla LSTM模型上进行预测。同时研究多采样点构建的时空流量矩阵在CNN-LSTM模型上的预测效果,并将CNN-LSTM模型中LSTM单元替换为GRU单元并利用CNN-GRU模型展开预测。最后综合对比三种循环神经网络算法与传统交通流预测方法ARIMA模型,GM模型对于短时交通流序列的预测效果,实验发现CNN-LSTM预测模型的预测误差LSTM模型预测平均误差低30%,较传统预测模型提升更为显著。(4)实现了基于Spark的短时交通流分析系统,系统通过命令行和函数式编程实现分布式计算与数据存储。并在此系统上实现了文章第三章的PageRank交通拥堵预测算法,同时此系统还具有Spark SQL,机器学习的拓展功能。"
281,基于网络搜索数据的品牌汽车销量预测研究,"近年来,我国汽车产业发展迅猛,但是产能过剩的问题日益凸显,汽车生产企业面临严峻的发展困境,所以需要科学、准确的汽车销量预测为汽车生产企业提供必要的决策支持,但是汽车生产销售是复杂的周期性过程,实现不同时间周期的精确预测具有一定的难度。而现有研究存在的问题主要包括研究对象选取不当,特征选取体系不完善,预测模型性能有限等方面,因此,本文以网络搜索数据为基础,以多个热销品牌汽车为研究对象并按照机器学习学科领域的完整研究过程,应用多种特征选取算法,实证分析多种预测模型,基于不同时间粒度深入研究,以实现对于品牌汽车销量精确且系统的预测,主要的研究内容包括以下几个方面:(1)品牌汽车销量与网络搜索数据关系模型构建。首先分析了传统时间序列模型的局限性,然后根据购车决策行为发生的过程,说明网络搜索数据在一定程度上代表着消费者购买意向,最后完成了品牌汽车销量与网络搜索数据关系模型框架的建立。(2)品牌汽车网络搜索关键词特征选取。为了减少主观性且最大程度保留有效信息,控制模型复杂度,解决多重共线性及特征冗余等问题,基于特征工程理论,首先使用过滤法进行特征初步筛选,然后在候选特征集上应用基于Lasso模型的变量选取算法以及提出两种基于Svm和RandomForest的启发式递归变量选取算法进行二次特征选择,针对不同品牌的关键词库运用三种方案得到多组最优关键词特征集合,为模型建立做好准备工作。(3)品牌汽车销量多时间粒度预测研究。运用惩罚线性回归、支持向量回归及随机森林三种机器学习算法,基于多组特征子集建立品牌汽车销量短期的预测模型,结果表明基于RandomForest的启发式递归变量选取算法得到的特征子集整体性能最优,随机森林模型指标评价最好;针对不同时间粒度深入研究,发现中长期网络搜索数据与对应销量相关趋势关系显著增强,但不同时间粒度最优特征子集存在差异;在中期和长期销量预测中,随机森林模型的性能仍然是最好的,所有品牌的最优MAPE的均值分别为2.74%和2.94%。通过总结所有实验结果,本文提出的基于网络搜索数据的品牌汽车销量的多时间粒度预测方案,基本实现了包括数据获取,数据预处理,特征选取,预测建模等全流程的体系架构,并且达到了较为精确的预测需求。"
282,热网关键节点泄漏监测系统的设计与研发,"由于长期使用被腐蚀或者质量不过关的管道以及其自身存在老化的原因,导致地下供热一次管网运行过程中发生泄漏事故。研究表明,供热一次管网的泄漏会引起泄漏点周围温度、电导率以及管道内部压力的波动,管网泄漏状况与这些物理量之间存在着复杂的非线性关系,仅依靠单一物理量的变化很难全面评定管道泄漏状况。针对该问题,本文设计并研发了一套分布于管网现场、能适应恶劣环境的高稳定性、低功耗、高精度的热网关键节点泄漏监测系统,实时获取管网泄漏状态信息。热网关键节点泄漏监测系统主要由现地监测单元及供热一次管网运行状态在线监测系统构成。现地监测单元完成现场数据采集和无线数据传输,包括管道状态参数采集模块、微控制器、通信模块、电源模块等。通过在线获取热力管网的周边环境温度及电导率、管网内部运行压力参数,以RF射频结合GPRS无线通讯的方式将获取所得数据传送至数据监测后台。数据监测后台是基于C#语言开发的供热一次管网运行状态在线监测系统上位机软件,其将接收的各监测单元数据进行显示和存储,并对存储在后端SQL数据库的数据采用长短时记忆神经网络预测;同时,采用基于引力搜索法优化的最小二乘支持向量机算法建立多分类热网关键节点泄漏故障模型,将反映供热管网运行状况的各类状态参数作为训练样本进行训练分类,将预测结果代入分类模型,以评估管网的运行状况,为状态检修鉴定基础。其次,本文针对热网关键节点泄漏检测终端的供电锂电池建立了一阶阻容模型进行模型搭建,将电池电路模型参数[k0,k1,k2,k3,k4,Cp,Rc,Rd]作为扩展卡尔曼滤波算法的模型参数,采用递推最小二乘算法对电池模型参数进行实时更新,以电池内部温度、实时电流和电压为输入,电池SOC作为输出对电池剩余荷电状态进行分析研究。当电池电量过低时,及时上报至远程监测系统,提示工作人员及时更换电池,防止电池电量低导致的漏报和误报问题。设计研制的热网关键节点泄漏监测终端在华能某热电厂井室环境内进行安装调试,并已批量投入使用。现场实验均表明,该系统应用效果较好,满足设计要求,为地下供热一次管网泄漏的在线监测与准确评定奠定了基础。"
283,基于微信公众平台的移动学习研究,"随着互联网与教育愈加紧密的融合,移动技术和移动终端慢慢渗透到中小学的教育之中,同时中小学也加强了对信息技术课程的投入。移动学习和微信公众平台因其在教育事业相关联的特性而进入教育工作者及其研究者的眼帘。目前,中学网络教育中绝大部分采用大型的网络教学平台进行混合学习,极少有学校开展移动学习性质的课程,而利用微信公众平台辅助教学的移动学习更是少之又少。本研究结合实验研究法和行动研究法,利用用户数量极大,影响最为广泛的微信公众平台构建移动学习的教学环境,构建基于微信公众平台的移动学习模式,并通过黄石某示范高中的《人工智能基础》课程进行具体的教学实践。在研究论文的第三章中,首先进行基于微信公众平台的移动学习模式构建,模式主要包括前端分析模块、活动与资源设计模块、实施与评价模块,以此模式作为后续教学设计与实施的思路。在研究论文的第四章中,在对之前基于微信公众平台的移动学习模式构建的基础上,选择汤晓鸥、陈玉琨主编的、华东师范大学出版社出版的《人工智能基础》(高中版)课程进行具体教学应用,分课前预习、课中教学、课后复习和系统分析四个部分进行实际教学阐述。在研究论文的第五章中,根据问卷调查、访谈结果和学生的综合成绩分析应用的实际效果,多维度出发,得出更科学的结论。通过此次研究,总结出以下结论:基于微信公众平台的移动学习模式,有助于学习者突破课堂教学的局限,将学习延伸至课堂之外,体验借助微信学习中所带来的的自主开放的学习氛围;提升学习者的积极性,促进了师生之间的互动交流;课堂从普遍的教师讲授学生被动地去听,转变为从课前预习到课后巩固,不仅可以及时地掌握学生的学习动态,还可以对教学过程中不完善的地方进行及时地改善。"
284,应用分层迭代支持向量机的OFDM信号调制识别研究,"正交频分复用(Orthogonal Frequency Division Multiplexing,OFDM)是一种特殊的多载波调制信号,因其具有实现成本低廉、频谱利用率高和较强的抗多径衰落能力等优点,目前成为无线宽带通信系统的首选。在全球范围内,被广泛应用于民用通信和军事通信等众多领域,如数字视频广播(DVB)系统、第四代超宽带移动通信系统、无线局域网(WIFI)和各种战术/战略通信系统等。但是,信号在空间传输过程中,由于受到信道噪声和空间中其他信号的干扰,对OFDM进行调制识别影响比较大,因此本文提出一种应用支持向量机的分层迭代结构,用来解决OFDM信号在复杂电磁环境下的调制识别问题。本文的主要内容包括:1.介绍了OFDM系统原理以及OFDM信号调制识别基本理论和关键技术,同时分析了单载波信号包括MPSK信号、MFSK信号、MQAM信号,以及多载小波小波包调制(Wavelet Packet Modulation,WPM)信号的调制特点。2.介绍了支持向量机(Support Vector Machines,SVM)的基本分类原理,分析了OFDM信号同其他信号的特征参数,包括区分多载波和单载波的高阶累积量,以及区分多载波之间的双谱图的对应关系。3.研究了在瑞利信道背景下,结合SVM的分类理论和各调制信号特征值的区别,提出了一种分层迭代SVM分类器的OFDM信号调制识别结构,分析了各调制信号的高阶累积量和双谱特性,将其作为分类器的训练样本参数。并设计了一种基于径向基核函数(Radial Basis Kernel Function,RBF)的三层支持向量机分类器,依次区分开OFDM信号与单载波及小波包信号,其次采用分层迭代法训练分类器参数,先对每一层进行训练,再对训练好的三层分类器进行整体迭代训练进一步优化分类器的参数,最终识出OFDM调制信号。研究结果表明:三层分类器迭代结构能有效地识别OFDM信号,其不仅和单载波分类,同时可以和多载波小波包信号进行分类。"
285,基于机器学习的交通标志识别方法研究,"经济与科技发展的日新月异,时刻改变着人们的衣食住行,汽车行业的瞬息万变使人们对车辆本身性能和质量的要求不断提高。道路上车辆数目的与日俱增给人们出行带来极大方便的同时也使交通安全、环境污染等问题日益严重,辅助驾驶技术和无人驾驶技术因此成为国内外专家学者和科技公司的研究热点。交通标志包含大量的道路信息,不仅能够分担驾驶员的驾驶压力,降低道路交通的负载,而且可以防止出现交通安全问题,避免人身安全与财产损失。因此,快速可靠的交通标志识别系统成为辅助驾驶与无人驾驶系统中至关重要的组成部分,然而真实环境中道路场景复杂多变,现有的交通标志检测与识别方法在实时性和准确性上仍具有提升空间。本文针对交通标志识别展开研究,主要工作内容如下:针对图像模糊不清、受不良光照等因素影响产生的质量问题,利用YCrCb颜色空间,在局部范围内,调整图像的灰度直方图,达到提高图像亮度的目的,有效地降低了不良光照带来的影响,使标志区域颜色更加鲜明。针对交通标志检测问题,利用RGB与HSV颜色空间,采用图像掩膜的方法分割出蓝、红、黄颜色区域,然后采用形态学处理的方法滤除不良目标影响,改善标志轮廓信息,结合标志的几何形状提取出可能存在交通标志的感兴趣区域。计算感兴趣区域的HOG特征,选择GTSRB数据集作为样本集,并对数据作增强处理,改善样本分布不均匀现象,利用SVM分类器对感兴趣区域中是否存在交通标志作出检测。在GTSDB测试集和自建数据集中分别对算法进行验证,检测准确率分别达到96.29%和95.54%,平均每张图片的检测时间为0.36s。针对交通标志的识别问题,基于传统的LeNet-5卷积神经网络结构,进一步改进它的结构,对模型中的参数和算法进行调整优化,得到改进的用于交通标志识别的卷积神经网络模型。分别在GTSRB测试集和自建数据集中进行试验,识别准确率分别达到98.20%和98.76%,平均每个标志的识别时间为4.01ms,相比其他算法,实时性和准确性方面均有所提高,但距离实际应用仍具有提升空间。"
286,基于机器视觉的缝迹几何量检测与缺陷识别研究,"服装生产过程中的缝迹品质检验工序是服装生产关键的一个环节。目前服装企业的缝迹质量检测线基本依靠人工目视逐针检查,会出现误检和漏检的情形，成本高,效率低。因此,迫切需求一种能够准确、快速且能长时间运行的缝迹质量检测方法。论文主要研究内容成果如下:(1)通过对服装企业缝迹检测线现场调研及检测目标特征分析,,搭建了适用于缝迹的几何量检测和缺陷识别的实验平台,构建缝迹几何量检测位置校正模型。由于缝迹背景复杂多样且存在噪声干扰,对缝迹图像采用双边滤波,达到对缝迹“保边”的特性。针对缝迹针脚点为圆弧状的特点,选取八个方向的Sobell算子模板,在缝迹边缘上的灰度梯度方向运用多项式差值法对缝迹进行亚像素边缘提取,保证了针脚点提取的稳健性。(2)采用基于 HOG特征的支持向量机(SVM)算法,将已分类的缝迹缺陷样本进行HOG特征提取,得到缝迹缺陷特征数据集。利用该特征数据集训练出适用于缝迹缺陷分类的SVM分类器,对缝迹缺陷类别进行识别和分类。(3)对缝迹样本完成了实验测试,验证了本文算法有效性。"
287,图像与视频的有趣性理解和预测方法研究,"随着计算机视觉与人工智能的快速发展,数字多媒体的日益普及,人们对生活追求的不断提升,带来了数据的海量激增,但现存数据的质量良莠不齐,通过对有趣性的研究与预测,能够帮助人们高效地完成相关信息的检索,对于广告推广、视频摘要与点播等方面具有积极的作用。本文基于机器学习方法,从图像与视频有趣性的二分类预测角度出发,构建了相应的预测模型,使得计算机能够模仿人类的感知方式,自动地完成图像和视频的有趣性二分类任务。对于图像有趣性二分类任务,为了能够描述有趣性这个概念,使其转化为可计算的问题,本文构建了一个图像有趣性预测框架。该框架首先确定了不寻常、美学和一般偏好三个描述有趣性的重要线索,每个线索由不同类型的特征构成,其中不寻常由离群系数和熟悉度构成,美学由激励、纹理、颜色、复杂度和形状特征构成,一般偏好由局部特征和场景描述符构成;其次,使用判别相关分析或多集判别相关分析对同类型特征进行融合;最后,采用简单多核学习方法对图像有趣性进行分类。实验结果表明本文构建的有趣性预测框架,能够较全面地捕获图像的有趣性信息,取得较高地分类准确率,具有良好的预测性能。对于视频有趣性二分类任务,为了解决静态特征忽略视频动态信息,无法全面表述视频视觉信息的问题,本文采用静态特征与动态特征相结合的方式来表征有趣性,并采用AdaBoost分类器对视频有趣性进行分类。其中,基于视频帧提取颜色直方图、SIFT、HOG、Gist和LBP特征作为静态特征;基于视频帧在XY、XT和YT三个正交平面上建模,分别提取三个平面上的LBP特征,并将其串联作为动态特征来描述视频的时空信息。实验结果表明本文采用的动静结合方式弥补了视频动态信息缺失的不足,对于视频有趣性具有较好的分类效果。"
288,目标检测中候选区域准确高效定位的机器学习方法研究,"目标候选框可以完成对目标物体的初步定位,是目标检测和目标识别的基础,既适合对多类目标的定位也适合对单类目标的定位。在实时监控系统、门禁系统、刷脸支付等实际环境中具有重要作用。所以,目标候选框的准确高效定位具有重要研究意义。本文主要从目标候选框生成的高效性与准确性两个方面进行研究。(1)本文主要针对BING方法定位准确率不高的问题,首先使用扩展模板提取特征增强物体边缘特征的判别力,从而改进原梯度特征定位偏差的问题。然后采用高斯软权重非最大值抑制算法,解决了最大目标候选框附近非最大目标候选区域被强制归零的问题,提高了BING方法定位的准确率。最后在公开的数据集上对改进算法进行验证。实验结果表明,改进的BING算法在不增加算法计算复杂度的基础上,提高了BING方法定位的准确率。(2)本文基于具有较高准确率的选择性搜索方法进行两方面的改进,一是在初始分割阶段使用汉明距离计算相邻像素之间的相似性,二是针对选择性搜索方法合并策略计算复杂的问题,使用一种基于颜色的哈希策略的方法计算图像初始分割区域的相似度,从而判断相邻区域是否可以合并。这种方法大大地减少了选择性搜索算法在区域合并时计算的迭代次数,并在公开的测试集上进行验证。结果表明,本文改进的选择性搜索方法在尽可能不降低准确率的基础上,效率提高了60%。基于目标候选框在DPM行人检测算法中的应用。本文使用改进BING算法和改进选择性搜索算法代替DPM行人检测算法中的滑动窗口完成对行人的检测。通过行人数据集INRIA对检测结果进行验证,实验结果表明,使用改进目标候选框结合DPM的方法检测行人,加快了DPM行人检测的速度,实现了对行人的高效准确定位。"
289,卷积神经网络在量子态表达中的应用,"传统求解量子力学的方法是通过二阶偏微分方程得出波函数的具体形式,进而计算得出微观粒子的性质。波函数利用正交基展开,正交基的数量即希尔伯特空间维度的计算量会呈指数增加,这使得关于波函数的求解变得困难。随着人工智能和图形处理器GPU的蓬勃发展,机器学习方法在各个领域都开始崭露头角。因此,探索机器学习技术在量子力学问题求解中的应用是一个新颖而有意义的问题。卷积神经网络(Convolution neural network,CNN)属于监督学习,需要大量的精确解来训练CNN模型。由于简谐振子、氢原子的势函数与能量本征值之间存在一一对应的解析解,本课题以简谐振子和氢原子为例,研究机器学习在量子态表述中的应用。简谐振子和氢原子的势函数在二维平面上的投影是一幅幅平面图像,解析解作为标签评估CNN预测能量本征值的准确性。可以将多个谐振子和氢原子的势函数二维图像和标签作为输入训练CNN模型,利用CNN以处理图像的方式得到谐振子势函数与基态能量本征值间的映射关系,以及氢原子势函数与基态、第一激发态及第二激发态能量本征值间的映射关系。训练好的CNN模型可以预测不同谐振子的基态能量,不同氢原子的基态、第一激发态及第二激发态能量而不必求Schrodinger方程。为此,在MATLAB上分别构建了四个224×224的样本图像数据集。在TensorFlow深度学习平台上对VGG网络模型进行了改进。利用改进后的18层Bright VGG网络模型对数据样本进行训练,建立二维势函数与能量本征值之间的映射。本课题搭建的Bright VGG网络模型对不同谐振子的基态预测值平均绝对误差从0.0427eV改进到0.0372eV,相对误差从0.566eV改进到0.429eV,标准差从1.233%改进到了 1.042%。通过对比说明了本文搭建的Bright VGG网络的预测准确性和可靠性。同时,本文训练好的CNN模型能够对简谐振子和氢原子的量子态作出较准确的预测,实验结果验证了本文所提CNN方法表达量子态的有效性。"
290,面向自然图像和计算机生成图像鉴别的机器学习算法研究,"随着数字媒体技术快速发展,人们可以利用复杂数学模型生成高度逼真的计算机合成图像,这极大地促进了虚拟现实技术的发展,但同时也带来了数字图像的真实性鉴别等安全问题。如何区分采集自真实场景的自然图像和计算机生成的强真实感虚拟图像是目前数字图像真实性鉴别中的重要课题之一。已有方法中大多采用传感器模式噪声作为图像取证特征,但其中滤波降噪算子和描述模式噪声的纹理特征表达能力不足。本文结合双树复小波(Dual-Tree Complex Wavelet Transform,DT-CWT)与机器学习中的支持向量机(Support Vector Machine,SVM)和深度卷积神经网络(Deep Convolutional Neural Network,DCNN)等理论和方法,提出了一套解决方案。具体研究工作如下:1・提出了一种基于双树复小波域与支持向量机的自然图像和计算机生成图像区分算法。该算法首先利用降噪算子得到图像的传感器模式噪音,并使用奇异值分解(Singular Value Decomposition,SVD)进行增强处理。然后在双树复小波变换基础上,提取每个子带的能量和偏差作为特征。最后利用SVM进行分类。实验结果表明,该方法不但提取的特征维度较低,而且精确度较高。2.提出了一种基于深度卷积神经网络的自然图像和计算机生成图像鉴别算法。在预处理阶段,运用算法1中的降噪算子生成模式噪声图像。在特征提取阶段,利用本文设计的8层深度卷积神经网络对模式噪音图像进行特征提取。最后选用SVM和SoftMax作为分类器。实验结果表明,相比现有文献,本算法具有网络结构简单和训练速度快等优点,且取得较高精确度。3.提出了一种基于迁移学习的自然图像和计算机生成图像识别算法。本算法首先运用1中的降噪算子生成模式噪声图像,然后以微调的方式将AlexNet、VGG16、ResNetl8三个预训练模型在小规模的图像集上进行参数移植再训练。通过实验验证,利用训练好的深度神经网络进行参数微调后解决本文的图像识别问题,不但能够适应小样本数据的需求,而且可以达到更高的准确率。"
291,深度学习在文章编辑中智能语义检查算法的研究,"科技的发展使如今各行各业的数据量不断变大,印刷行业也随之改变。本文针对印刷工艺的文字类原稿编辑工作中的语句校正问题进行研究。本文设计并实现了基于长短时记忆神经网络的语义检查算法。此算法首先采集、整理并构建了标准的语料数据集;其次利用词嵌入算法将经过处理的语料数据映射到词向量空间;最后根据词嵌入算法得到的结果训练用来识别语句段并对语句中的词预测、检查的语言模型。具体内容如下:(1)设计了一种新的词嵌入方法,利用这种方法构建了新的词向量模型。该词嵌入方法首先根据收集的相关文本语料、汉语言语法关系以及现有词嵌入算法顺序性和全局共线性较差的缺点设计的。其次是通过统计词-词组的频数建立一种以词组为词的特征列的矩阵,并通过聚类算法将矩阵降维,将词映射到一个低维的词向量空间中,构建了一种新的词向量模型。最后用现有词嵌入算法构建另一种词向量模型。将这两种词向量模型进行对比分析,虽然根据相关文本统计词-词组的频数做特征矩阵聚类后生成的词向量模型在全局共线性略优于现有词嵌入算法,但是聚类使基于词-词组的词嵌入方法整体效果略逊于现有词嵌入算法构建的词向量模型。(2)采用两种词向量模型分别构建基于LSTM的语言模型后结合的联合预测模型。该模型首先分别使用两种词嵌入算法构建的基于LSTM的语言模型进行文本预测,然后融合二者结果生成最终预测结果。使用语言模型进行词语预测准确率的实验结果表明,联合预测模型的准确率是高于两个单一模型的预测效果的,在解决相关主题文本中语句的词语检查问题上是一种比较稳定、有效的语义检查方法。"
292,中文文章与主题关键短语提取方法研究,"随着互联网技术的不断发展,日益增多的网民所产生的文本信息有待及时有效的处理。因此,高效的文本挖掘技术就成为关键性研究课题,其中,文章关键短语与主题关键短语提取技术是文本挖掘的基础研究内容,它们共同影响着文本挖掘在各个领域中的应用质量。目前,文章关键短语与主题关键短语提取技术被广泛应用于许多领域,如:关键词搜索引擎、语音识别、文本情感分析和用户商品智能推荐等。本文的主要工作是基于统计、自然语言处理和机器学习,在原有三种经典算法的基础上提出了改进后的三个关键短语提取方案,本文的具体研究内容和研究结果如下:(1)提出了一种基于TF-IDF与多特征约束的中文关键短语提取方法。首先,分析了TF-IDF统计量设定的局限性,根据中文词语特点加入更多约束条件完成多特征约束,然后,加入了顺序组合技术来弥补TF-IDF无法提取短语的缺陷,在此基础上融入中文分词系统与改进的短语排序技术共同构成该方案主体,并在大量实验中完成算法具体参数的定值。最后,给出了该方案与国内外经典相关算法的对比实验结果,从量化的数值上可以看出本方案的关键短语挖掘效果相对于对比算法有显著的提升。(2)针对经典的关键短语提取算法所提取关键短语准确率低、歧义性强、涵盖信息量少等问题提出了一种改进后的文章关键短语提取算法。首先,在英文关键短语提取算法TAKE的启发下,通过加入中文分词系统来改善原有算法在中文分词能力上的不足,然后,融入基于多领域特异性的新词识别技术,提升了最终的分词效果,并在此基础上增加了词语过滤和特征计算等技术融合后形成了一种改进的TAKE算法。最后,通过与多种传统关键短语提取算法的对比,实验表明:本方案在提取的精确率、召回率和F值指标的量化结果中相比于传统算法有比较明显的提升。(3)提出了一种主题关键短语提取算法。首先,针对原有算法Kert中文分词效果不佳,引入新的统计量改善分词效果,并依据Kert中FP-Growth所产生短语语序歧义的问题提出了约束合并算法,然后,改进原有排序算法完成算法整体框架。最后,通过对比实验表明本方案针对主题关键短语挖掘工作相比于对比算法有更加良好的表现。"
293,面向网络教育新闻文本的区域分类方法研究,"随着互联网的快速发展和普及,网上教育新闻数据也越来越多。为了让关注教育新闻的相关人员根据需要,方便地获取到我国34个行政区中特定区域的教育新闻。本文通过收集大量的教育新闻文本,建立了带标记的教育新闻文本集,设计了适用教育新闻文本的区域分类方法。本文主要工作可以概括为:(1)为了降低人工标记文本集的成本,本文对网络教育新闻文本集的自动标记法进行了研究,提出了一种基于CGLTF-IDF特征提取和半监督聚类的教育新闻文本集自动标记方法。首先,通过网络爬虫进行文本获取并对其进行清洗;其次,收集教育地理名词形成教育地理词库,并对文档-逆文档频率(TF-IDF)特征提取方法进行改进,设计了适用于教育新闻文本的特征提取方法(CGLTF-IDF);然后,为了形成高质量带标记的训练集,提出了基于权值的样本选择标记策略;最后,构建了基于CGLTF-IDF特征提取和半监督聚类的教育新闻文本集自动标记模型,并对文本集进行标记。实验结果表明此种方法可以有效地对网络教育新闻文本集进行标记,从而为后期研究提供可训练的数据集。(2)为了对教育新闻文本进行行政区域分类,本文设计了一种基于投票策略的教育新闻文本的区域分类方法(V-ECM)。首先,分析现有文本分类算法及文本表示方法,设计并实现了基于朴素贝叶斯、卷积神经网络和长短期记忆网络3类教育新闻文本区域分类模型。其次,依据这3类分类模型的特点,设计了一种基于投票策略的教育新闻文本的区域分类方法,实现教育新闻文本的区域分类。最后,将V-ECM应用到实际的教育信息系统中,满足了用户需求。"
294,基于深度学习与自注意力机制的情感分类方法研究,"传统的情感分类算法大多基于浅层的机器学习,采用人工设计的特征选择方法进行特征提取,但这些方法耗时长,训练难,人工成本高的缺陷很难适用于如今数据集庞大的应用场景。基于深度学习的情感分类方法,能从海量数据中主动学习包含语义信息的词向量,通过不同的深度神经网络获得句子或文档的特征和情感表达。深度神经网络中的损失函数对模型训练过拟合影响力显著,优化损失函数能够提高模型泛化能力,减少过拟合;情感词在文本分类中占有重要地位,循环神经网络中对输入词在情感分类结果的贡献度进行快速排序,增加情感词在文本分类中的影响,能够定量减少情感信息的丢失;在情感分类任务中引入自注意力机制,能充分学习到句子内部的词依赖关系,优化特征向量,有效解决信息冗余。基于上述思想,本文结合深度神经网络和自注意力机制展开文本情感分类方法的研究,通过设计模型结构和优化策略,提出四种情感分类模型,以期获得更好的分类效果。本文主要研究工作和创新点如下:(1)以长短期记忆网络和卷积神经网络为基础,对二分类任务中所用的交叉熵损失函数进行优化,使模型更有效地去拟合预测错误样本,减少过拟合。基于优化的交叉熵损失函数,设计了 LSTM-BO(Long Short-Term Memory Binary-Optimize)和 CNN-BO(Convolutional NeuralNetworks Binary-Optimize)模型,并在中文、英文两类数据集上进行参数优化实验和对比分析实验。实验表明,LSTM-BO和CNN-BO模型能够一定程度上提高情感分类准确率,明显降低损失率,防止过拟合。(2)循环神经网络能够处理文本数据的序列信息,通过计算输入词对最终分类结果的影响程度并排序。根据排序结果,对情感倾向比较强烈的词分配较高权重,减少情感信息的丢失。据此,本文设计了W-RNN(Weight-Recurrent Neural Network)模型,并在中文、英文两类数据集上通过定量与定性实验验证模型的有效性。(3)注意力机制可以帮助算法模型发现关键特征,自注意力机制能有效捕获句子的内部结构,优化特征向量。本文提出将自注意力机制与双向长短期记忆网络相结合的策略来解决情感分类问题,实验验证了结合自注意力机制后的SA-BiLSTM(Self Attention-BiLSTM)模型更容易捕获句子中长距离的相互依赖的特征,能够有效解决信息冗余问题,进一步提高情感分类准确率。"
295,机器学习在趋势预测中的研究及应用,"作为一种集成多种高精尖科技的大型复杂系统,卫星发挥的作用已经体现在各种领域中,并占有无可替代的位置。然而,卫星常年暴露在恶劣的宇宙环境中,会受到太阳活动、宇宙射线,太空垃圾等外界因素的干扰,同时其在工作过程中由于一些内部自身因素,都会导致故障的发生。卫星在长期监测管理的过程中,会产生大量遥测数据,从中可挖掘出各种有用信息,然后有效利用关键参数的潜在变化规律来进行未来趋势预测,对于卫星正常工作具有重要意义。本文将机器学习算法应用于卫星关键参数趋势预测中,主要有如下几部分:(1)针对卫星关键参数受噪声影响、数据缺失以及机器学习预测模型选择问题,分析比较了几种常用方法和3种评价指标,提出了基于BAS优化的自适应小波阈值去噪算法,实验数据表明该算法可行且有效。(2)利用浅层学习模型中的快速学习网络(FLN)、Elman神经网络以及回声状态网络(ESN)实现趋势预测。针对传统ESN当前时刻的状态值与前一时刻的状态值没有直接关系,因此通过增加调节参数β来控制前一个时刻神经元的状态,提高ESN的记忆能力。由于采用最小二乘回归法训练网络输出权值可能存在解的“奇异”问题,则采用岭回归算法(Ridge Regression,RR)取代原有的线性回归方法,从而有效调节输出权值的幅值。针对ESN网络参数的选择问题,利用樽海鞘群算法(SSA)获得ESN网络重要参数的最优值,使得预测模型更加准确。(3)针对单一模型对非线性、非平稳时间序列预测难以达到理想的预测精度,将改进的集成经验模态分解(MEEMD)和长短时记忆网络(LSTM)结合形成MEEMD-LSTM组合预测模型。该模型首先采用MEEMD将原始序列分解为若干个不同时间尺度或趋势的本征模态函数(IMF)分量,再采用LSTM预测模型对每个IMF分量进行预测,最后集合每个分量的预测结果得到有效的预测结果。(4)将提到的几种机器学习模型应用于锂离子电池容量趋势预测实例中来验证算法的有效性,实验结果表明,在浅层学习模型中ESN网络预测精度较高,使用群智能算法组合预测模型能够提高传统ESN神经网络的预测精度;深度学习模型中MEEMD-LSTM模型具有较好的预测效果。(5)采用MATLAB与C#语言联合编程开发了一套综合电子系统健康监测软件系统。"
296,基于强化学习的倒立摆控制算法研究,"科技时代,人工智能充斥在我们生活的各个领域,从AIphaGo到AlphaZero都在渔释着它的强大。机器学习作为人工智能的核心,是使计算机具有智能的根本途径。强化学习作为机器学习研究领域的一个热门方向,其通过智能体与环境的交互作用,从中汲取经验,以自学习的方式不断更新改进控制策略,逐步达到最优或近优控制效果。由于强化学习是一种无模型无监督的机器学习方法,因此具有通用性强,适用范围广泛,参数自整定等优点,能够极大降低控制系统的设计难度和人力投入,具有广阔的应用前景。因此,研究强化学习具有重要的理论价值和实际工程应用价值。倒立摆系统是一个多变量、非线性、高阶次、强耦合的自不稳定系统,能够模拟反映多数常见的控制对象,其控制算法具有多输入单输出的特点,因而是一种典型的自动控制理论研究装置。以该问题作为研究对象,能够有效反映出控制算法在实际应用系统中的随动性、鲁棒性、跟踪及镇定性等问题。因此,本文以一级直线倒立摆系统为对象,进行深度强化学习算法的研究。主要研究内容以及成果如下:(1)对强化学习的基础概念进行介绍并分析。通过对常用强化学习算法的理论推导和马尔科夫决策过程各参数分析,为强化学习以及深度强化学习算法在倒立摆控制系统中的应用奠定了理论基础。(2)通过OpenAI Gym游戏库,完成了深度强化学习DQN算法、双网络DQN算法、PG算法在一级直线倒立摆平衡控制中的实验仿真。结果表明,三种控制算法均可以快速完成训练,达到对倒立摆的平衡控制。在此基础上,论文进一步研究测试了三种不同reward给定方式对算法的影响,通过实验比较,发现线性化reward方式具有最快的训练速度,从而为强化学习在真实倒立摆控制训练提供了重要经验。(3)搭建了基于PLC的一级直线倒立摆硬件实验平台,通过PID控制算法对倒立摆的平衡控制,验证了实验平台的有效性,并为强化学习算法的控制研究提供了测试基准。(4)基于DQN算法,实现了一级直线倒立摆的起摆控制。经过大约50个训练回合后,控制算法即可在200个控制周期(一个控制周期为20ms)内,使摆杆由下垂位置摆动到直立位置附近,完成倒立摆起摆控制。(5)基于Q学习算法,研究了倒立摆平衡控制。针对真实控制环境中噪音较大、训练量受限、部分训练样本难以获得的局限性,研究设计了具有多元训练策略的off-policy控制算法,该算法能够从人工示教或其他控制算法中获取经验,提高训练效率,从而通过有限实验快速完成训练并获得更好的控制效果。由于该方法有效降低了实验训练量,从而使强化学习算法以更小的人力投入,获得更好的控制效果,为强化学习在实际工程的应用做了初步的实践,具有良好的应用前景。"
297,有限注意与A股市场股价回归预测,"随着当前互联网技术的革新,社交媒体快速的发展,使得人们在网上可以实时在线发表自己的观点,成为了人们新的沟通方式。网络在线评论已经成为了不少人们对于自己观点的表达方式,对于证券市场来说,在网络上已经发展了不少专业的股票论坛,供人们发表自己对股票投资问题的看法。深入分析和挖掘网络平台上投资者所发布的信息,是对于投资者行为及情绪的了解方式,也是挖掘投资者情绪的基本手段。近年来,投资者情绪已经成为了股票投资中更为关注的指标之一,从早期的结构化指标到如今文本挖掘,受到了越来越多的金融企业、监管机构的注意,也逐渐成为了学者们的研究热点问题之一。本文聚焦于网络平台上的海量文本数据,通过文本挖掘对非结构化的文本数据进行提取并分析,通过对国内股票论坛平台的信息对比,选择了雪球网论坛作为本文研究投资者有限注意的基础。雪球网论坛是一个开放性的股票交流论坛,论坛中的在线评论等信息能够比较好地从一个侧面映射投资者对相关股票的即时想法。近年来国内在本文挖掘与股票预测的相关领域内有相应的研究,取得了一定的研究成果。本文在前人研究成果的基础上,主要对投资者有限注意与股票预测的关系作以研究,同时对机器学习的不同方法进行了比较。理论研究上,论文首先界定了有限注意及不同理论基础等,并在已有研究成果的基础上提出了基于文本挖掘的股票在线评论数据构建投资者有限注意指标的研究意义。从情绪分析的角度上来看,主要通过自然语言处理将所有的文本信息进行情感分类,将文本数据的情感分为积极文本、消极文本和中性文本三类。进一步,在分类处理好信息后,建立向量空间模型与情感特征模型,分别采用支持向量机回归与logistic回归两种算法对文本的分类结果进行量化处理。实际应用研究上,本文首先以采用爬虫技术从雪球网论坛上获取的上证50指数在线股票评论的文本数据为研究对象,阐述了数据的获取和预处理过程,并进一步构建了基于文本挖掘的投资者有限注意指标。同时,本文也选取的结构化数据的指标,与投资者有限注意的指标共同作为自变量,并选取上证50指数的收盘价作为因变量。接下来,本文研究了相应自变量与因变量之间的相关性,通过平稳性检验与格兰杰因果检验筛选出与因变量相关的相应指标,再通过对相应指标构建两种模型来检验不同模型下的自变量指标对股票市场预测的准确性。研究表明看涨情绪指标和普通情绪指标与股票市场收盘价具有相关性,并且基于支持向量机的投资者有限注意指数对股票市场预测的准确率更好。"
298,基于神经网络的双丝MIG快速成形系统焊缝形状预测与参数优化,"随着市场经济的发展,以及产品制造的竞争加剧,快速成形技术因柔性高、生产周期短、成形件性能优良等优势而备受关注。作为快速成形的一种,电弧快速成形利用电弧热熔化焊丝,按照设定轨迹堆积成金属零件,其具有制造灵活、成形件致密度高的优点,并且已在机械制造领域广泛应用。现搭建的粗细双丝MIG快速成形系统既有粗丝敷熔率大的优势,又有细丝成形精度高的特点。为在使用过程中指导焊缝成形和优化焊接工艺,达到减少试验和节省焊接成本的目的,本文通过建立神经网络模型,实现直观预测焊缝形貌和焊接工艺参数的优化。首先进行了样本数据的采集,利用正交设计方法设计试验方案,以焊接速度、焊丝直径、送丝速度及焊接电压为试验因子,试验中不考虑各个因素之间的交互作用,因为各因素、水平数不尽相同且没有可供直接选择的正交表,所以重新进行了混合正交表的设计。使用双丝MIG快速成形设备进行试验得到80个样件,样件经处理后在显微镜下得到可观察焊缝形貌的照片,采集焊缝几何参数如熔宽、余高和熔深,数据记录在表格中供后续训练使用。随后试验分析了正交表中四个试验因子在双丝MIG快速成形系统中对焊缝成形的影响,初步探究试验因子影响焊缝成形的规律,为后续预测数据提供理论基础,也进一步验证设计的焊接系统有较好的稳定性。为达到通过程序直接输出焊缝形状的研究目的,本文采用关键点坐标和曲线方程类别共同确定焊缝上部和下部轮廓曲线。使用Python语言和Tensorflow机器学习框架编写程序,借助Tensorboard可视化工具建立三类神经网络模型:第一类网络模型预测焊缝的成形系数进而转换为关键点坐标;第二、三类神经网络模型用以预测焊缝上部和下部轮廓曲线类别。在训练第二、三类网络模型之前,对第二章采集的焊缝图像数据做了提取和分类,做成one-hot标签供训练使用。结果显示,三类网络模型的loss曲线下降稳定且第二、三类网络模型的准确率达到80.7%和83.8%。最后建立反向焊接工艺参数预测模型,同第一类正向网络模型联合使用优化焊接工艺参数,结果表明参数预测误差在5%以下。为方便使用,通过Matlab软件创建了可视化界面,界面内有网络超参数信息、预测界面和数据管理3个模块。最后使用该界面预测15组测试集数据的焊缝形状,记录预测过程中熔宽、余高和熔深数据,通过数据分析得出第一类网络模型的预测性能较好;计算得到测试集数据焊缝上部和下部曲线类型的准确率分别为0.8318和0.8780,优于训练集数据的准确率,说明第二、三类网络的泛化性能较强;通过像素点计算法得到图像面积,对比实际焊缝面积和预测焊缝面积,15组数据的平均相对误差为5.16%,说明本文建立的预测模型的可靠性较高。"
299,基于深度神经网络的地铁客流预测系统研究,"近些年来,伴随着经济的快速发展和城市人口的急剧增长,大城市的交通拥堵问题愈发严重,城市轨道交通系统有效地缓解了此问题。但是随着地铁线路规模的扩大和运营方式的复杂化,地铁运营的安全和效率也面临着更加严峻的挑战。客流的精准预测可以帮助优化行车间隔和制定合理的运营方案,从而有效地缓解交通拥堵和提高乘客的舒适度。大数据与深度学习技术在诸多领域发挥了重要作用,研究表明,在数据充足条件下,深度神经网络在回归预测问题中有着优异的表现。随着城市轨道交通信息化的发展,数据的搜集手段逐渐完善,研究城市轨道交通的客流大数据处理技术,利用深度神经网络对城市轨道交通客流进行精准预测,具有重要的现实意义。论文首先对北京地铁自动售检票系统(Automatic Fair Collection System,AFC)的客流数据进行数据预处理,随后建立了长短期记忆(LSTM)神经网络和卷积神经网络(CNN)模型,利用模型分别对地铁客流量进行精准预测。最后结合Teradata大数据环境,编写基于B/S架构的系统实现实时的客流量预测。论文的主要研究工作如下:(1)基于原始的AFC客流数据,论文从时间维度对地铁客流数据进行统计分析,研究得出了工作日和节假日客流量的分布差异和周期性变化规律;并针对不同车站的客流量分布差异,从时间和空间两个维度上对客流量进行了统计分析。(2)为了完成时间维度的客流预测,论文首先对原始AFC客流数据进行数据预处理,使数据转换成时间序列的一维数据。随后建立LSTM深度神经网络模型,并基于网格搜索算法寻找LSTM模型最优超参数组合。最后利用LSTM模型对北京地铁的客流量数据进行预测,仿真结果表明,相比于传统的机器学习模型,LSTM模型的预测效果有较大的提升。(3)为了完成空间与时间二维的客流预测,论文首先将原始AFC客流数据转换成以时间为横坐标、车站为纵坐标的二维数据。随后建立CNN深度神经网络模型,并寻找CNN模型最优超参数组合。最后使用CNN模型对北京地铁客流量数据进行预测,相比于传统的机器学习模型,预测结果同样有较大的提升。与LSTM模型不同的是,CNN模型充分考虑了站与站之间的空间特性。(4)为了将论文的深度学习模型运用于实际系统中,论文实现了基于B/S架构的可视化预测软件,软件能实时从数据库中获取客流量数据,并利用训练完成的深度神经网络对客流量进行预测。B/S架构的软件免于安装,利用Web浏览器显示客流量的预测结果和变化趋势。图69幅,表13个,参考文献88篇"
300,Web应用防火墙中流量处理模块的设计与实现,"Web应用防火墙(Web Application Firewall,WAF)是专门针对Web应用的安全解决方案。它将安全与业务隔离,降低了因Web应用攻击带来的损失和网站安全开发的成本。随着互联网的发展,各企业业务体量的增加,除防御传统Web应用攻击外,他们还需要阻止爬虫抓取网站内容和“薅羊毛”等恶意访问。面对恶意访问,企业往往通过在Web应用中添加检测代码来进行防御。但这样做会增加业务功能与安全功能的耦合,而且增删检测代码需要重新验证和部署Web应用,这些都增加了Web应用的维护成本。同时进行检测往往需要在全站范围内对符合条件的访问进行筛选和统计,Web应用往往采用Web服务器集群的模式工作,添加此功能会不可避免地带来架构复杂性和开发成本。本文的主要目的是针对恶意访问防护,提出基于Web应用防火墙使用自定义脚本进行扩展的解决方案:企业根据安全需求编写检测脚本并交由Web应用防火墙运行,以进行访问统计和执行安全防护操作(如封禁、报警等)。流量处理模块是Web应用防火墙中实现该解决方案的主要模块。不同Web应用具有不同的业务体量,其实时负载也在变化中,因此本文设计了具有可伸缩性流量处理模块,使得企业还可以动态增减Web防火墙中流量处理模块节点的部署,达到处理性能与成本的权衡。本文的主要工作是对Web应用防火墙中流量处理模块进行设计与实现。本文介绍了国内外对于恶意访问防护解决方案的现状,引出本文解决方案;阐述了实现流量处理模块所需的相关技术及选用理由;分析了流量处理模块的功能需求,并结合行业标准考虑了可伸缩性,性能和安全性(Security)等非功能需求;设计了流量处理模块的体系结构并描述了其与Web应用防火墙其他组件的交互;对流量处理模块的流处理模块、插件模块和节点接口模块进行设计与实现,并展示了他们如何利用相关技术满足功能需求与非功能需求;最后对本文现阶段工作进行了总结,提出了该解决方案下一阶段可以开展的工作方向。企业使用基于本文解决方案设计的Web应用防火墙,可以在保持Web应用中安全与业务的隔离,使得Web应用在不需要重新部署和不变更原来的架构的前提下,获得所需的自定义安全防护功能。"
301,麻醉恢复期低体温危险因素分析及护理对策研究,"目的:1.探讨全麻及椎管内麻醉恢复期患者发生低体温的危险因素,并对危险因素的重要性进行排序,为针对性地采取措施预防麻醉恢复期患者低体温的发生提供理论依据。2.提出预防麻醉后低体温发生的策略,对充气加温毯的使用方法进行改良,并观察将其应用于麻醉恢复期低体温患者复温的效果,为临床寻找安全有效且经济方便的复温措施提供理论依据。方法:第一部分:选取山西省某三甲医院2017年10月至2018年9月术后进入麻醉恢复室的全麻及椎管内麻醉患者3415例,根据入麻醉恢复室时是否发生低体温分为低体温组和非低体温组,计算低体温的发生率并收集相关临床资料。在查阅文献的基础上,对可能与低体温相关的因素进行收集整理,进行单因素统计分析,将差异有统计学意义的因素进行多因素Logistic回归分析,筛查麻醉恢复期患者低体温的独立危险因素。采用机器学习模型对低体温的相关因素进行重要性排序。第二部分:选取山西省某三甲医院麻醉恢复室低体温患者80例作为研究对象,将其随机分为两组,每组40例。在麻醉恢复室分别采取改良的充气保温被和充气加温毯为患者复温,比较两组患者的复温时间、复温速度、PACU停留时间、寒战发生情况。采用独立样本t检验和卡方检验对数据进行统计分析。结果:第一部分:1.本研究共纳入患者3415例,其中248例患者发生麻醉恢复期低体温(低体温组),发生率为7.26%;3167例未发生低体温(体温正常组)。2.根据查阅文献结果,收集16个可能与患者低体温有关的因素进行单因素分析;结果显示两组间差异有统计学意义(P0.05)。3.多因素Logistic回归分析显示,泌尿外科专业手术、年龄>65岁、手术时间>2h、输液量>1000mL、BMI0.05)。2.两组患者入麻醉恢复室时均处于轻度低体温状态,入PACU耳温组间比较差异无统计学意义(P>0.05)。两组患者复温时间、复温速度、PACU停留时间及寒战发生情况,组间比较差异均无统计学意义(P>0.05)。结论:1.麻醉恢复期低体温是手术麻醉患者发生率较高的一个并发症(7.26%)。2.麻醉恢复期患者低体温的独立危险因素重要性排序由高到低分别是:体质指数BMI2h、年龄>65岁、输液量>1000mL、低室温、泌尿外科专业手术。3.对于轻度低体温患者,改良的充气保温被可以达到充气加温毯的复温效果,同时降低了成本,适用于麻醉恢复期低体温患者的复温。"
302,储层地质模型实时修正方法研究,"三维油藏地质模型是研究油藏的重要手段,近年来,围绕提高模型精度,降低地下空间不确定性展开了大量的研究工作,相继出现了随机建模、相控建模、等时建模、多步建模等方法来提高模型准确性。本文通过对各类地质建模方法研究,综合三维地质建模、随钻测井、机器学习岩性识别解释方法、水平井地质导向及水平井优化等技术,建立了一套随钻地质模型实时修正流程方法。以渭北油田某一区块为例,针对其开发特点,在现有地质认识的基础上,建立先期地质模型,依据机器学习方法进行测井解释,对研究区岩相模型进行滚动更新,并以此为地质导向模型,指导水平井钻井,提高油层钻遇率。由此建立的随钻地质模型实时修正方法可以更充分利用新的钻井反馈信息,减少模型不确定性,提高油藏认识,使所建立的岩相模型逐渐接近地下真实情况。本文取得的成果和认识有:1、通过对随钻地质导向技术及地质模型实时修正方法调研,建立了一套基于随钻解释的地质模型实时修正流程;2、基于研究区的油藏地质特征,依据邻井资料,采用多步建模的方法建立先期地质模型。通过先期地质模型,设计水平井钻井轨迹,并采用数值模拟方法进行水平井长度优化设计;3、收集随钻测井数据,并对其进行标准化处理,通过Python语言编写机器学习岩性识别代码,采用随机森林算法进行随钻测井数据的快速岩性解释;4、在随钻测井岩性解释的基础上,设计自动更新工作流,进行岩相模型的滚动更新,并根据模型修正结果对预设计井轨迹进行优化。"
303,基于神经网络与注意力机制结合的语音情感识别研究,"随着计算机行业的不断发展,人工智能走进人们的生活,通过语音实现人机交互正逐渐成为主流的人机交互方式,语音情感识别能够让机器感知人类的情绪,听懂人的情感,在心理健康状态监控,教育辅助,个性化内容推荐,客服质量监控方面都具有广泛应用前景,但目前语音情感识别系统的识别率较低不足以大规模商用,提高情感识别准确度是一个亟待解决的难题。语音情感识别一般的系统框架主要分为两部分:语音情感特征提取和情感分类,本文针对于分类器模型提出了三个创新点进行优化:1.针对传统LSTM模型将隐藏的变长向量统一编码成固定长度向量容易造成信息损失而且将每帧语音视为了具有相同的重要性,与实际情况不符的问题。本文提出了一种基于LSTM的自注意力机制模型,将情绪隐藏向量表示为情绪的帧级隐藏向量的加权平均值,其中帧级隐藏向量的权重由注意机制自动学习,使得模型能够提取出更具有情绪代表性的特征来区分不同语音情绪,提升情绪识别准确率。2.针对LSTM模型单一子空间的特征表示。在自注意力的基础上,本文还提出了多头的注意力机制模型去学习不同子空间位置的特征表示,使得模型能够在多个子空间捕捉到更全面的情绪特征,从而提高情绪识别的准确度。3.针对情感数据集采集成本高但深度学习模型对数据量需求大的问题。本文提出了一种通过按不同比例增加噪声和混响的方式快速且低成本扩充有限数据集,从而提升情感识别的系统性能。为验证算法性能,本文将新提出的三种的优化方法分别与LSTM基准模型在数据集IEMOCAP和EMODB上进行对比实验。实验结果表明三种优化方法均具有更优越的性能,并且给出了各种方法的适用场景和使用边界条件。最后组合三种方法能够获得最大的性能提升,相比LSTM基准模型,本文提出的注意力机制模型在数据集EMODB上情感识别错误率下降22.78%,在IEMOCAP上情感识别错误率下降16.09%。"
304,动态异构信息网络的表示学习研究,"基于图的机器学习是一项重要且无处不在的任务,其应用已逐渐遍布在我们的日常生活中。该研究领域的主要挑战是找到一种表示或编码图结构的方法,以便机器学习模型可以轻松利用它。然而,传统的图表示法由于依赖图邻接矩阵、邻接表或人工构造特征,已经无法适应大规模网络的机器学习需求。网络表示学习旨在将网络中的节点表示为低维稠密的向量,并用低维向量解决后续的机器学习任务。近年来,由于该方法可以有效降低各种网络分析任务的复杂性,已成为新的研究热点。然而,现有的网络表示学习方法大多针对静态网络,无法表示动态演变网络。针对上述问题,本文旨在研究动态异构信息网络的表示学习问题,并采用了基于随机游走的方式学习网络节点的表示。基于随机游走的网络表示学习方法首先通过随机游走构造节点序列,然后将节点序列输入SKIP-GRAM模型以学习节点的低维表示。然而现有的这类方法由于在进行随机游走时没有同时利用网络拓扑、语义、文本与时间戳等信息,网络表示学习的效果有待提升。鉴于此,本文提出了一种新的基于动态随机游走的异构信息网络的表示学习方法。本文首先构造了一个动态异构信息网络,然后提出了一种新的自动提取并延长元路径的方法,还结合边的时间戳信息提出了一种新的用于生成节点序列的基于边的动态随机游走方法。在动态随机游走过程中,采用提出的两种游走控制策略分别动态调整节点序列的数量和长度,以优化特定时间戳下构造的异构信息网络的节点序列。最后,将构造的节点序列输入异构型SKIP-GRAM模型,学习节点的低维向量表示。本文使用两个不同的真实数据集验证了本文提出的方案。实验结果表明,和现有主流算法相比,本文提出的动态异构信息网络的表示学习方法在分类、聚类以及可视化等任务中均取得了较优的效果。本文首先介绍了网络表示学习的研究现状并分析了现有方法存在的问题,然后详细阐述了本文提出的异构信息网络的动态表示学习方法,给出了本文方案的设计与实现,并通过实验验证了本文方案的有效性和准确性。最后,给出了本文的结论和未来工作。"
305,基于Multi-Agent的PC构件生产线智能控制系统的研究,"建筑工业化已经成为国际建筑行业发展的主流,预制混凝土构件的工业化生产是建筑工业化的一个重要环节,而目前大多数国内预制混凝土构件生产线的智能化和信息化水平不高。为响应我国颁布的《中国制造2025》和“两化融合”战略,本文以预制混凝土构件(简称:PC构件)生产线控制系统为研究对象,致力于研究基于Multi-Agent的PC构件生产线智能控制系统。首先,通过调研该类生产线控制系统的国内外研究现状,引入了Multi-Agent控制理论,并深入分析了PC构件生产线智能控制系统的控制指标、控制和协作需求等问题,设计出了解决方案,确立了论文的研究内容及研究方法。其次,建立了PC构件生产线智能控制系统的Agent及Multi-Agent基本模型,具体包括Agent自适应模型、黑板会话模型、基于合同网机制的竞标模型等;并构建了PC构件生产线调度系统简化模型,分别进行了生产时耗、生产能耗、生产环境和生产健康的评估算法设计,其中生产能耗采用KNN(K近邻算法)机器学习算法进行评估;研究了基于订单堆积度的生产时耗与生产能耗的变权重综合评估调度算法。第三,完成了基于Multi-Agent的PC构件生产线关重件智能体控制系统的硬、软件设计,包括硬件选型、基于EPLAN P8的码垛机智能体电气接线图设计、现场总线通讯网络设计、RFID硬件系统设计等;并完成了RFID系统的数据读写程序和集智能选窑、智能定位、智能交互等为一体的码垛机智能体控制程序的编制与仿真实验验证。最后,完成了KNN机器学习评估调度算法程序的编制,并采用江苏汤辰机械装备有限公司PC构件生产线的3000多条实际生产数据,进行基于生产能耗评估的KNN机器学习评估调度算法程序试验,验证了该算法程序对能耗预测的准确性;采用WINCC-Simulation仿真软件,进行变权重综合评估调度算法仿真实验,得出了时耗权重系数、能耗权重系数与订单堆积度一一对应的函数关系。"
306,基于平均影响值的SVM在遗传数据疾病分类和特征提取中的应用,"目的:将平均影响值(Mean Impact Value)与支持向量机(Support Vector Machine)结合进行模型构建,并将其应用于遗传数据疾病分类和变量筛选当中,为遗传数据在疾病分类和特征提取方面提供方法学参考。方法:本研究拟采用GAW18(Genetic Analysis Workshop 18)数据,对该数据进行整理和分析后,构建合适的样本集。将样本数据分为训练集和预测集,采用基于平均影响值的支持向量机建立预测模型,并比较多种核函数下支持向量机、优化后的支持向量机以及logistic模型分类结果,评价基于MIV的SVM预测分类和变量筛选效果。结果:对样本数据的训练集进行训练构建logistic模型并进预测,模型灵敏度为0.29,特异度为0.85,ROC曲线下面积为0.72,预测准确率75%。没有进行优化的quadratic核函数的支持向量机的ROC曲线下面积为0.63,预测准确率65.63%。经平均影响值优化的quassian核函数支持向量机下的ROC曲线下面积为0.73,预测准确率达到81.25%,经过优化的quadratic核函数的支持向量机的预测准确率更是达到了84.38%。可以看到经过优化的支持向量机有较为明显的优势。结论:基于MIV的SVM能比较有效的在实现遗传数据变量筛选的同时提高分类预测能力,相比其他模型有较为明显的优势。避免了变量间的交互作用,为探索各种疾病发病机制和寻找易感单核多苷酸多态性(Single-nucleotide polymorphism)位点提供线索,具有研究价值和应用价值。"
307,基于机器学习的文本分类技术研究,"随着信息技术的发展网络数据和资源迅速增长,如何有效地对这些信息进行分类、管理和利用,已经成为备受关注的研究课题。文本分类作为信息检索和数据挖掘的重要基础,广泛应用于内容信息过滤、自然语言处理与理解和新闻分类等领域。基于机器学习的文本分类技术,基于统计理论,使用算法对已知的训练数据进行统计分析以获得规律,然后运用该规律对未知数据进行预测和分析。本文对基于机器学习的文本分类技术进行研究,在对文本分类的一般过程以及文本预处理、文本表示、空间降维、分类方法和分类性能评价进行详细研究介绍的基础上,选择机器学习分类算法中的随机森林算法进行重点研究,分析算法存在的问题以及优化空间,并对其进行优化改进。一方面,对于传统随机森林算法投票时存在的忽略强弱分类器的问题,优化算法的投票机制,基于决策树的分类效果对决策树赋予相应权重,之后结合决策树输出的样本属于各个类的概率进行加权概率投票。另一方面,随机森林算法中的超参数取值对算法性能具有很大的影响,而且算法应用于文本分类时超参数个数多且取值范围大,对此提出结合随机搜索算法和网格搜索算法的超参数优化算法,解决超参数的取值优化问题。针对提出的算法设计基于Python的文本分类实验,将优化投票机制的随机森林算法与传统随机森林算法进行对比,并验证优化投票机制和超参数选择的随机森林算法的有效性。本文提出的随机森林优化算法可以提高算法分类性能,其中的超参数优化算法对于机器学习算法的超参数优化问题,尤其是算法用于文本分类时的超参数优化问题具有一定的参考意义。"
308,机器学习在材料热电性能预测中的应用,"近年来,热电材料由于具有能够在热能与电能之间直接转换,体积小,可靠性高,环境友好等特点,成为了目前材料领域内研究的热门方向。但是对热电材料的研究,通过大量实验观察数据,凭借直觉提出假设然后验证假设的传统材料研究方法,已经很明显不适用于当今高速发展的数字智能时代。利用第一性原理,能够不断完善热电理论和进行新型热电材料设计,但是研发周期依旧过长。因此,探寻新的研究方法来辅助加快新型热电材料的研发具有重要意义。针对上述新型热电材料设计研发存在的问题,本文提出了一种基于机器学习进行材料热电性能的预测方法,重点是通过机器学习方法对热电材料塞贝克系数进行预测,帮助后续热电材料研究人员快速筛选出具有理想塞贝克系数的热电材料。同时,我们还借助训练好的机器学习模型找到了影响塞贝克系数的重要特征。因此,本文的工作内容大致分为两个部分:第一部分,本文通过开源材料数据库Materials Project获取了2233 1条半导体材料的塞贝克系数数据,构建了回归模型的数据集。然后从化合物的构成元素性质和空间结构信息两个方面进行特征工程,将选择后的元素类型特征和空间结构型特征组合形成向量,作为数据集每一个化合物的“描述符”,使用它训练出能够预测塞贝克系数的梯度提升决策树(GBDT)模型。模型在测试集预测效果达到R2=0.81,MAE=20.52 μ V/K,RMSE=25.36 μ V/K,MAPE=5.62%。另外利用GBDT模型的可解释性,得到了这部分输入特征变量的重要度。第二部分,为了挖掘出材料能带结构中与塞贝克系数密切相关的特征,本文进一步获取了 516个半导体材料的能带结构数据,首先使用经过处理后的能带数据训练能够预测塞贝克系数的GBDT模型,然后借助该模型结合聚类的方式提取了 4类能带中对塞贝克系数影响大的特征,最后验证了提取特征的有效性。"
309,基于机器学习的老年手机用户中文评论情感分析,"近年来,随着老龄化程度不断加深的同时人工智能时代也随之到来,信息技术的飞跃式发展和人们生活水平的大幅度提升,老年人对高科技智能产品的需求得不到满足的矛盾越来越强烈。在这样的时代背景下,如何更加全面、准确地了解老年人对智能产品的需求特点,从而为产品设计提供参考依据成为一个炙手可热问题。尽管传统统计调查能够直接了解到老年人消费者的需求特点,但时间、劳动成本较大,调查范围也比较局限。早已不能满足企业相关部门的需要,取而代之的是使用文本挖掘相关技术,相对更为简单、便利。本文以京东商城老年人智能手机评论为例,基于网络爬虫及自然语言处理技术,紧紧围绕老年人对智能手机的需求特点,对京东商城20多万相关手机评论文本语料进行数据建模,主要步骤如下:为了提高数据的可建模性,首先根据手机类别将采集到的数据划分为智能机和功能机,并进行数据预处理。其次,为了更加有效、全面地体现老年人手机消费者的需求特点,采用组合模型进行以下的数据挖掘。即基于python中sklearn等数据分析包构建长短记忆神经网络(以下简称LSTM)模型,得到文本语料的情感倾向性并生成4个好坏语料文档;再利用武汉大学ROSTCM6系统构建两类手机语义网络模型,通过重建有价值的高频词之间的关系,并在共现矩阵和评论筛选核对的帮助下,在一定程度上,得到了老年人智能机和功能机的赞点和抱怨点。最后基于LDA主题模型的思想,构建了评论主题模型。通过主题模型对潜在主题的提取,更加清晰明了地展现了两类手机独特的优势和最大的劣势。综合比较分析两者,将功能机消费者的使用习惯结合到智能机的特征中,并在此基础上,对相关手机生产商、运营商及政府部门等提出诸多实践建议,以帮助老年人智能手机更加符合老年人的使用需求,也为推进智慧养老事业出一份力。"
310,基于机器学习的图像标注系统的设计与实现,"随着科技的发展,人类已经迈入了人工智能时代,越来越多的产品走向“智能化”。人工智能算法离不开大规模数据集的构建,因此各种各样的开源数据集应运而生。特定数据集的需求对数据标注系统提出了新要求。此外,数据标注是一项枯燥、费时的工作,如何利用已有技术提升标注的效率,也为标注系统的设计带来了挑战。为了满足特定的标注需求,本文设计并实现了一种基于机器学习的图像标注系统。该系统不仅能够满足手工标注的需求,也可以利用成熟的计算机视觉相关算法,完成初始自动标注,人工修改,从而大大提升标注效率。值得一提的是,该系统还具有较好的扩展性,为图像数据集的准备奠定了良好的基础。本文首先介绍了课题的研究背景和意义,确定了标注系统的主要工作。其次对系统设计与实现过程中应用到的相关技术和开源库进行了介绍与分析。然后介绍了图像辅助标注利用到的算法设计与分析,对现有的人体行为识别算法作出改进,并作出评估。随后本文描述了系统的需求,介绍了系统的总体架构设计,并将系统划分为图片预处理、人体关节点标注和运动阶段分类标注等子模块,结合时序图和流程图,阐述了各子模块的概要设计。在此基础上,介绍了每一个模块内部的详细设计与实现,利用类图和数据表展示了类中的方法实现。紧接着,对标注系统的各个功能进行了测试,描述了预期结果和实际结果。最后,对已完成的工作进行了总结,对下一步图像标注系统的相关工作进行了展望。"
311,基于文本挖掘的笔记本电脑网评分析,"随着互联网的迅速发展、电子商务的快速崛起,网络购物已成为一种趋势。大数据时代的到来,促使着数据呈现爆炸式增长。在这海量的数据中包含着许多有价值的潜在信息,仅仅依靠人工阅读来获取是非常困难的事情。在这种情况下,文本挖掘技术应运而生。文本挖掘主要包括文本情感倾向分析、文本特征挖掘、主观内容识别等,其中情感倾向分析就是对文本数据中用户的主观态度进行判断,常用的方法是情感词典和机器学习。国外在文本挖掘研究领域,已经取得了一些成果,而国内在这一领域的研究起步晚还处于初级阶段。近年来,电子商务的发展,推动了文本挖掘领域相关技术的研究。本文主要使用朴素贝叶斯方法和LDA主题模型,对笔记本电脑评论数据进行挖掘分析。首先使用Spyder软件从京东商城官网爬取联想330C和戴尔灵越14两种电脑品牌的评论数据作为分析对象;其次,对评论进行数据清洗和预处理;然后,对处理后的数据空间向量表示形成文档词条矩阵,并用TF-IDF进行特征提取达到降维目的;接着,利用朴素贝叶斯方法构造分类器对评论数据进行文本分类,划分为好评集和差评集;最后,使用LDA模型分别对好评集和差评集进行主题的提取,进一步分析用户认同商品的哪些优点,不认同商品的哪些缺点。根据分析得出的结果,为生产商进一步提高商品质量满足消费者需求提出指导性建议;同时为潜在消费者购买决策提供合理的参考也具有一定的意义。"
312,数据类岗位招聘需求信息研究,"随着高等教育的发展与普及,我国高校毕业生数量逐年增加,屡创历史新高;在大数据与人工智能的发展进程中,数据类岗位的供需缺口也日渐加大。但是,由于人才招聘中存在结构性招聘矛盾和招聘信息不对称的问题,常出现毕业生难以找到理想工作、企业难以招聘到理想人才的困境。在此背景下,互联网招聘打破了地理空间的限制,扩大了供需双方的范围,成为招聘者发布信息与应聘者获得信息的重要渠道。得益于网络招聘的广泛应用,互联网招聘信息的实时发布使人才招聘中的信息不对称问题得到改善,但招聘文本仍具有海量、非结构化的特点,在文本统计分析中具有一定的技术困难。提取网络招聘文本的主题词,分析大数据时代数据类岗位的招聘需求,对广大数据科学相关专业的高校毕业生更高质量和更充分的就业有积极的促进作用。基于此,本文利用互联网招聘数据对数据类岗位招聘需求信息进行系统研究,文章首先选取互联网招聘平台中全国范围内的数据类岗位招聘数据,运用自然语言处理技术对非结构化的招聘信息进行文本预处理;进而结合LDA主题模型与word2vec词嵌入技术构建了招聘需求主题词提取模型,将招聘需求分解为教育背景、工作经验、知识技能与个人素质四个主题,提取出各数据类岗位基于不同需求主题的招聘需求主题词;最后,通过网络分析方法挖掘招聘需求主题词之间的共现信息,从教育背景、工作经验、知识技能与个人素质的角度对数据类岗位招聘信息中的核心岗位需求进行可视化展示与招聘需求分析,对广大数据类从业人员及在校学生能力培养方向具有导向作用,长远来看,这也有益于为即将到来的AI时代夯实人才储备基础。"
313,基于移动边缘计算的增强现实应用中的能耗最小化研究,"最近,移动增强现实(AR)正成为最迫切的研究内容。AR利用计算机图形学并通过将现实世界与计算机生成的虚拟图像相结合以构建能响应用户输入的现实世界。随着移动应用的进步,用户设备如手机,笔记本电脑,平板电脑变得非常流行和方便。但由于AR应用的密集计算和高电池能耗特征,我们无法充分实现其优势。移动云计算概念虽然可以克服计算和电池能耗问题,但是会引入延迟,因为信息需要以网络拓扑形式从强大服务器发送到远端用户。而且,它不提供高质量的传输,也不能参与实时应用。AR应用对时间敏感,需要高计算能力和电池容量。除了在移动设备上使用整个应用程序之外,AR应用程序可以卸载到微云服务器(Cloudlet)上并消除AR应用程序的延迟问题,由此引入了移动边缘计算(MEC)的新概念。在这种情况下,cloudlet可以最接近移动网络边缘的用户设备。它在无线接入网络中部署存储容量,并在终端用户之间提供直接信息传输,从而为AR应用提供高质量的服务。MEC在基站中部署可以避免系统故障。本论文的主要工作描述如下:首先,论文介绍了AR应用及其背景,研究动机、问题以及本文的贡献,简要介绍了机器学习与Q学习。详细总结了延迟敏感的沉浸式AR应用所面临的挑战,AR应用的种类以及与之相关的技术。其次,利用机器学习算法设计了一种针对基于MEC的协同AR应用的共享资源分配策略。利用AR应用的协作特性将部分应用卸载到MEC服务器上。我们设计了一种Q学习算法来达到协作卸载的目的。利用数值结果验证了所提出算法的有效性。"
314,基于智能算法的TA蛋白靶向预测方法研究,"随着人类基因组计划的实施,以及更多生物基因组测序计划的完成,生物学数据呈爆炸性增长,传统的生化试验方法已经远远不能满足需求。智能算法在生物信息领域有其独特的优势。已有研究表明,智能算法能成功解决生物信息学的这些问题。但是在蛋白质靶向预测上仍然面临着诸多问题和挑战。比如真核生物中末端锚定蛋白质(tail-anchored proteins,TA蛋白)靶向预测尚未有智能算法应用的实现。TA蛋白靶向与CpG岛的低甲基化存在相关性,因此,CpG岛的低甲基化可以作为TA蛋白靶向的相关特征因素。针对上述问题,本文做了大量的调研工作,对CpG岛识别及TA蛋白靶向预测进行深入的研究。大量的研究表明,已有的经典算法识别和分类准确率相对偏低,无法满足CpG岛序列识别和TA蛋白靶向预测等研究所要求的准确率。针对上述问题,本文以CpG岛序列识别为作为研究的切入点,TA蛋白靶向预测作为后续研究。采用智能算法可以很好的解决以上问题,同时提高了识别和预测的准确率。在CpG岛序列识别和TA蛋白靶向预测的研究中取得了不错的成果。本文的主要工作及创新点概括如下:1.本文提出了一种用遗传算法和隐马尔可夫模型结合的CpG岛序列识别方法。该方法通过遗传算法优化隐马尔科夫模型参数,得出的模型可以更好的用于CpG岛序列识别。2.本文通过严格筛选,我们获得了428个真核生物TA蛋白的数据,用于TA蛋白靶向定位预测;采用7种TA蛋白序列特征提取方法;并且增加了疏水性和电荷量这两类特征训练模型,可以有效的提高模型的分类准确率。3.本文构建了一种朴素贝叶斯的特征提取方法来提取TA蛋白序列特征。采用mRMR算法对蛋白质数据进行特征选择;最后,采用支持向量机去训练模型。在训练过程中基于网格方式对参数~?和惩罚系数C进行优化,并对实验结果进行分析。4.本文分别训练并比较了5种机器学习模型在TA蛋白靶向预测的结果。即:随机森林(RF)、逻辑回归(LR)、朴素贝叶斯(NB)、K-最近邻(KNN)和梯度提升树(GBDT)。最后,本文利用遗传算法全局搜索的能力,对HMM参数进行优化。将其改进方案应用到CpG岛序列识别中,可以提高CpG岛序列识别的准确率。对于TA蛋靶向预测,构建了一种朴素贝叶斯特征提取方案,采用SVM可以实现对TA蛋白靶向预测。后续研究中,本文采用了七种特征提取方法来提取蛋白质序列特征,通过集成五种智能算法的分类结果,可以更好的预测TA蛋白在亚细胞器的靶向,预测精度达到84%。"
315,基于大数据的碳源汇估算方法研究,"传统碳源汇估算生态过程模型虽然具有严密的植物生理生态学机制,但过程复杂,关键参数依赖经验设置,从而给区域和全球碳循环模拟带来很大的不确定性。为了提高植被总初级生产力(GPP)的估算精度,本文使用机器学习算法,建立了数据驱动的GPP估算模型。利用GEE平台下的EVI、NDVI、降水、温度等遥感数据,以及站点的通量塔实测GPP数据,采用随机森林回归模型等机器学习算法建立遥感数据与实测数据之间的联系,使用模型对测试组数据进行预测。实验结果表明,机器学习模型的拟合决定系数等参数好于基于生态过程模型的Modis数据,可以获得更为精确的GPP预测结果,为GPP估算提供了新的方法。本文的研究工作主要包括:(1)对国内外的GPP估算方法进行了总结,对相关概念进行解释,以及对大数据和机器学习的发展趋势进行介绍。(2)选取了全国八个具有较强代表性的站点作为研究区域。获取站点的通量塔数据,并使用GEE平台收集研究区域的遥感数据,进行预处理。对GEE平台的使用进行熟悉,充分利用GEE平台的功能,使后续实验得到高质量的数据支撑。(3)使用八个站点的数据建立随机森林模型,并使用模型对站点GPP进行估算。分析输入影响因子的重要性,通过调参等手段提高随机森林模型预测的精准度。最后将随机森林算法与另外三种机器学习算法进行对比,说明随机森林回归模型所具有的优势。(4)最后使用R~2、RMSE等相关精度指标对模型预测效果进行评估,并与全球公认的MODIS数据产品进行对比。通过实验对比分析,验证了随机森林模型预测数据具有更高的可靠性。经过大量的实验分析验证,本文所采取的基于随机森林模型的估算方法的方法在GPP估算方面,相对于其他主流算法有更好的精度。"
316,基于BP神经网络和随机森林算法的冠状动脉狭窄风险识别模型研究,"目的:冠心病是由冠状动脉血管狭窄所致心肌缺血缺氧的一种心血管疾病,其预后情况复杂多变。冠心病已然成为当前威胁人类生命健康的重要原因。冠状动脉造影手术治疗是目前唯一可以直接观察冠状动脉形态的论断方法,被认为是当前诊断冠心病的“金标准”,但由于冠状动脉造影存在创伤性,禁忌症和术后并发症,费用昂贵等诸多缺点,无法开展大规模的人群筛查,因此针对冠心病患者,构建冠状动脉狭窄早期风险识别模型显得尤为重要。本研究基于冠心病心衰患者临床病历资料,构建冠脉狭窄早期风险识别模型,实现高效、无创的识别冠状动脉狭窄,以指导临床医生和患者选择合理的预防性治疗和干预措施,以期降低冠状动脉狭窄的发生率和致死率。方法:根据本课题研究对象的纳入和排除标准,共筛选出符合条件的山西省心血管病医院和山西医科大学第一医院心内科2011年10月至2018年5月期间确诊为冠心病心衰的2926例住院患者作为本研究的研究对象,通过查阅两所医院病案室中相关电子和纸质病历,获取患者的一般人口学资料、既往史、实验室检查、心电图、心脏彩超、冠脉造影、用药等信息。利用卡方检验和基于秩的非参数检验从上述资料中筛选出与冠状动脉狭窄有关的变量。采用分层抽样的方法从冠脉造影手术结果Gensini评分大于等于4的患者和Gensini评分小于4的患者(包括未行冠脉造影手术的患者)两种数据资料中分别抽取四分之三样本作为训练数据集,该部分数据用于训练初始模型,将剩余四分之一样本作为测试数据集,用来评价各模型的分类效果。将从病历资料中筛选出的变量作为输入变量,将冠脉造影手术结果Gensini评分是否大于4作为结局变量,在训练数据集中分别建立logistic回归、BP神经网络和随机森林分类识别模型,在测试数据集中通过准确度、灵敏度、特异度、阳性预测值、阴性预测值和受试者工作特征曲线下面积AUC指标来评价和比较三种模型的综合性能。结果:通过单因素检验(卡方检验和基于秩的非参数检验),从147个变量中初步筛选出与冠状动脉狭窄相关的变量共49个,其中包括心律失常、高血压、血红蛋白、血小板等。通过基于AUC的随机森林自变量筛选方法对上述单因素检验得到的变量进行进一步筛选,最终获得36个变量进入最终模型进行训练。将36个变量作为模型的输入变量,用来训练logistic回归、BP神经网络和随机森林的初始模型。logistic回归模型在测试数据集中的结果:灵敏度为75.76%,特异度为72.95%,准确度为74.05%,阳性预测值为73.95%,阴性预测值为72.07%,AUC值为0.7399。训练BP神经网络之前,首先通过模拟试验,确定隐含层个数,实验结果发现,当神经网络模型的隐含层个数为25时,模型误差相对较小,因此构建模型结构为36-25-1的神经网络模型,BP神经网络模型在测试数据集中的结果:灵敏度为74.30%,特异度为70.00%,准确度为72.30%,阳性预测值为75.05%,阴性预测值为69.18%,AUC值为0.7231。在训练随机森林模型之前,首先对模型参数mtry和ntree进行选择,结果发现,当参数mtry设置为3,ntree设置为1000时,模型性能达到最佳,测试数据集中,随机森林模型的模型效果:灵敏度为93.70%,特异度为62.97%,准确度为79.49%,阳性预测值为74.58%,阴性预测值为89.39%,AUC值为0.7522。结论:随机森林模型在冠状动脉狭窄程度识别中的综合性能最佳,可以在患者发病早期,实现对冠状动脉狭窄的识别,这使得冠状动脉狭窄的发生概率被估计的更加准确,在临床上为医生和患者提供更加精确和高效的意见和建议,对提高诊疗质量具有重要意义。"
317,基于随机森林算法建模的糖尿病预警系统设计与实现,"糖尿病是一种代谢性疾病,是由于人体内胰岛素分泌不足,人体内的糖分无法代谢分解导致高血糖,严重时尿液里会检测出糖分,因此称为糖尿病。日常生活中,生活条件越来越好,人们的饮食习惯发生变化,糖尿病是富贵病的说法也不存在了。人们现在的饮食结构里不单是蛋奶肉类,还有丰富的果蔬和各式饮品甜点,正是这个原因,人们日常摄入的糖分大量增加,也导致了糖尿病发病率的增加。对于青少年也是如此,由于生活质量的提高,现在的青少年从小就是在“蜜罐”中成长的,因为家长对青少年的饮食结构的控制并不是很严格,而青少年的自制力又比较差,而高糖分的食物对青少年的吸引力极高,导致他们日常饮食摄入过多糖分,这也是导致低龄糖尿病患者越来越多的主要原因之一~([1])。另外,高龄糖尿病患者会伴随着潜在的并发症,比如心梗,眼疾等,这会给患者的身体带来更大的负担。良好规律的饮食习惯和健康绿色的生活方式才是保持正常体态以及维持身体机能正常运作的保障。因此,由于各种因素的影响,需要有一个有效机制来督促、警示,会让人们提高预防意识,那么糖尿病预警系统的研究与实现有重要意义。该预警系统的预测分析结果会及时给用户一个重要提示,促使人们及时调整和改变生活习惯或者尽早去医院就医进行更具体的检查。本文研究过程中,咨询了糖尿病专家,利用问卷调查方式收集了大量糖尿病症状属性信息。运用随机森林算法对这些信息进行相应的数据分析,建立预警模型,并将其模型运用到预警系统中。该论文的主要研究内容如下:1、通过问卷星进行问卷调查,收集了一千多份数据信息,其中包括患糖尿病的和未患糖尿病的相关属性信息,然后对这些信息进行一定的数据分析和整理,并以此作为训练样本。2、将数据样本按照3:7的比例分为训练集和测试集,运用随机森林算法对训练集进行分类训练然后通过测试集进行测试得到该随机森林算法分类的准确率,从而得到了一个预警模型,然后根据这个模型,得到一个患病概率。3、设计实现糖尿病预警系统,主要包括三个部分,第一部分是用户信息登录注册和相关个人信息处理部分;第二部分是系统的预测分析功能,分析得到用户的患病概率;第三部分是系统管理员对用户和用户信息的一些基本管理操作。4、进行算法实验和预警系统的相关测试,检验系统的有效性。利用本文研究的糖尿病预警系统,用户可以随时根据个人相关指标数据进行糖尿病的风险预测,能够有效提高糖尿病潜在患者的预防意识,通过预测分析结果,进行积极地调整,改善生活状态。"
318,基于特征选择的结直肠癌预测模型研究,"结直肠癌(colorectal cancer,CRC)是消化系统中最容易发作的癌症之一,据统计,世界上每年患该病的人数多达120万,死于该病的人数大约占据了患者人数的一半,高达60万人,不仅使人类的健康受到严重的威胁,而且使国民经济也遭受了巨大的损失。目前几种方法能够帮助医务人员对结直肠癌进行诊断,它们是:X线检查、血清癌胚抗原、B超扫描、内镜检查等,这些无疑对结直肠癌的诊断起到很大作用,但是这些方法都依赖于医生的经验,难以确保准确性,同时也增加了医务人员的工作强度。针对以上结直肠癌诊断方法的局限性,融入机器学习算法的预测模型逐步成为研究的热点。机器学习算法在疾病预测领域的智能性表现为主动地对医疗数据进行学习,更重要的是根据构建的多个模型做出最终的决策,对提高疾病诊断的准确性、实时性,减轻医务人员的工作强度具有重大意义。尽管如此,单一的机器学习算法对不同的数据分类预测时未必都能得到可观的效果,必须综合考虑多种技术的融合和优化。目前,利用机器学习算法对结直肠癌进行预测主要存在疾病特征因素冗余、特征选取不当、分类器选择不当以及数据样本不平衡等问题,导致一些机器学习算法在诊断结直肠癌的过程中表现的效果并不可观。为了进一步改善所构建模型的预测性能,更好的将其应用在实践当中,需要综合考虑结直肠癌重要特征的选取和分类器的性能问题。在国家自然科学基金项目(项目号:61876102,61272094,61472232)的资助下,我们对结直肠癌的预测模型作了进一步的研究。为了能够更加准确的利用机器学习算法预测结直肠癌,克服结直肠癌预测过程特征选取以及分类器、数据样本不平衡的问题,本文从基于肠道菌群的低维数据特征以及基于基因微阵列的高维数据特征入手,分别建立了支持向量机(SVM)预测模型以及混合支持向量机(MKFSVM)预测模型,为不同维度的数据特征选取以及模型的选择提供了依据,同时也为结直肠癌的预测研究提供了一种新思路。本文的主要工作及创新点有以下几点:1.针对结直肠癌传统低维数据特征选取不当的问题,提出一种基于Logistic回归和ROC曲线的双重特征选取方法。首先从统计学角度,利用Logistic回归模型从结直肠癌相关的因素中选择显著因素(p<0.05),然后利用ROC曲线,根据AUC值的大小选择最能影响疾病的组合因素作为SVM的输入;此外,通过比对SVM中四种不同核函数对分类结果的影响,选择最优核函数,从而提高了预测模型的准确率。2.针对结直肠癌基因微阵列数据特征维度高,存在冗余基因、不相关基因的问题,提出了一种结合差异表达基因和mRMR算法的特征选取方法。在结直肠癌样本的基因微阵列中包括成千上万个基因,但很多基因是冗余的或者与疾病不相关的,这些基因一旦带入分类器中,便会影响分类器的预测性能。因此,本文提出了结合差异表达基因和mRMR算法的特征选取方法,选取差异表达的基因作为影响疾病的显著因素,然后利用mRMR算法从差异表达的基因中选择最优的特征组合,从而提高结直肠癌预测结果。3.针对SVM中单一核函数功能的局限性,构建了基于高斯核函数(RBF)与多项式(Polynomial)核函数的混合核函数的SVM。RBF核函数具有很强的局部寻优功能,Polynomial核函数具有很强的全局搜索能力。但是在已有的基于结直肠癌基因微阵列的SVM预测模型中,大多采用RBF核函数或者Polynomial核函数中的一种来构建支持向量机,这样构建的SVM模型在全局或者局部具有寻优能力,因此,本文提出结合RBF核函数与Polynomial核函数的混合核函数,使得构建的SVM同时具有局部和全局寻优能力;此外利用新型优化算法:鲸鱼优化算法(WOA)对各个参数进行寻优,提高分类器的分类性能。4.针对结直肠癌基因样本分类不平衡的问题,提出了一种结合RUSBoost算法的结直肠癌预测模型。许多研究中选择的样本一般是趋于平衡的(分类比趋近1:1),但是在很多情况下,所获取的样本中不同类别的数量存在很大的差别,对分类结果有很大的影响。为了平衡不同类别中的样本数量,本文利用RUSBoost算法通过为数量少的类别创建适当的合成示例,从而间接改变更新权重并补偿偏差分布来实现样本之间的平衡,对改善预测模型的性能有很大的帮助。综上所述,本文从基于肠道菌群的低维数据特征以及基于基因微阵列的高维数据特征入手,分别提出了结合Logistic回归和ROC曲线双重特征选取的支持向量机预测模型、结合差异表达基因和mRMR算法的特征选取方法的混合核函数支持向量机预测模型。同时,在基因微阵列数据中,充分考虑了不平衡数据对预测结果的影响,将RUSBoost算法运用到预测模型中,通过与其他方法的对比,表明本文的方法可以很好的提高结直肠癌的预测性能,为不同维度的数据特征选取以及模型的选择提供了依据,同时也为结直肠癌的预测研究提供了一种新思路。此外,我们所提出预测模型的目的是提高疾病预测的准确度,可以应用在基于文本数据的不同疾病的诊断领域,协助医务人员,减轻他们的工作强度。"
319,微博谣言识别模型研究,"移动互联网技术与应用平台的出现为社会交往提供了新的模式和渠道。人们可以借助移动设备随时随地访问互联网络,第一时间获取信息资讯,足不出户地与同事朋友交流沟通。近年来,随着微信、微博等社交平台的迅速普及,人们越来越依赖于通过社交平台获取并实时分享信息。社交平台的出现为人们的信息获取与分享提供了便利,同时也成为了谣言信息滋生扩散的温床。与谣言传统的口口相传模式相比,借助于社交平台传播的网络谣言速度更快、范围更广,可能造成的危害程度与范围也远远超过传统的传播方式。因此,如何及时有效地识别谣言信息,并采取行之有效的调控策略阻断其传播,以尽可能地避免谣言大范围传播导致的严重危害,是网络信息安全领域的研究热点。目前,为了解决谣言泛滥的问题,微信、微博等社交应用提供商相继推出了各类辟谣平台或官方账号,以实时监控和用户举报为主要措施,及时发布官方辟谣信息,并采用删博删帖封号等方式以阻断谣言传播。另一方面,研究人员也为谣言识别研究做出了许多努力,采用常见的分类模型把识别问题转化为分类问题,通过提取对谣言和非谣言具有明显区分度的浅层特征和深层特征,结合抽取的特征与分类算法构建分类模型。也有部分学者以现有的模型和理论为基础,通过类比的方法建立谣言识别模型。但是,已有的研究成果仍然存在一定的局限性,识别结果的准确度仍有提升空间。因此,本文以微博谣言为研究对象,以谣言识别为目标,主要完成了以下工作:首先,搜集整理谣言领域内的各类文献资料,了解当前研究中所采用的主要方法及其局限性,梳理谣言的概念演变,定义本文研究中的谣言概念,明确研究对象的范围;其次,提取谣言识别的用户、传播和内容三类基本特征,在浅层特征的基础上,结合信任因素,构建基于信任的微博谣言识别模型;再次,将谣言信息从产生、传播到爆炸的过程类比于爆炸力学中的炸药爆燃爆炸过程,设置微博信息能量参数,结合谣言识别的特征参数,构建微博谣言信息爆炸识别模型。最后,结合本文研究内容,分别从过程角度和主体角度出发,提出了相应的谣言调控策略,并总结本文的研究工作。"
320,隐私保护下的数据处理,"随着互联网的发展,隐私问题获得了越来越多的关注,但是在隐私保护数据处理领域,仍然有问题亟待解决。云服务器有着丰富的计算资源,并且能完成指定的计算任务。随着个人和企业数据的高速增长,有着越来越多的计算任务在本地难以处理,要外包给云服务器进行运算。如果我们的数据直接暴露给云服务器会直接面临隐私泄露的问题,那么如何在实现图像计算的同时保护私有图像数据成为我们的主要关注点。为了解决这一问题,本文就基于同态加密方案加密的数据处理与特征提取的问题进行了研究。本文在前人研究成果的基础上,对基于同态加密方案加密的数据在神经网络中的使用以及基于同态加密方案的隐私图像特征提取进行了研究。本文的研究成果主要包含以下几个内容:1.使用同态加密构造了一个可以对隐私保护数据进行处理的神经网络,设计了一种可以支持同态运算属性的激励函数。对该算法进行分析得知,我们的方案可以在多项式时间内完成计算。2.提出一种在隐私保护图像上提取安全Haar特征的方案。基于同态加密方案,实现了在图像密文域上的安全Haar特征提取。安全Haar特征是Haar特征在密文域上的表现,与原始Haar特征相比,在维持有效性的同时,可以有效保护图像的隐私。通过对算法以及特征值的分析和评估,我们方案得到的安全Haar特征解密后与明文图像提取的Haar特征非常相近,并且可以在多项式时间内完成。3.提出了一种密态数值比较的方案。我们利用同态加密的同态性质,设计了一种双加密方案,该方案由两方参与,可以在1次交互的情况下,以极低的运算资源得到比较结果。4.应用安全Haar特征。使用前面在图像密文域中提取的安全Haar特征,实现隐私保护图像的人脸检测,通过对实验结果进行分析,我们的方案的检测结果与原始Haar特征检测结果非常相近。"
321,基于在线评论的细粒度情感分析,"随着互联网和电子商务在国内的迅猛发展,人们越来越热衷于在网络上进行购物,商品的评论中包含了许多有价值的信息,一方面消费者可以通过商品评论来了解商品的口碑,进而作出相应的购买决策;另一方面生产厂家可以通过评论来发现商品存在的问题,进而改善产品质量。情感分析又称为观点挖掘、情绪分析、情感倾向分析,属于自然语言处理的具体应用,是借助数据挖掘、机器学习等技术对含有感情色彩的主观性文本进行抽取、组织、分析的过程。针对在线评论进行情感分析后,其结果可为潜在的消费者和商家提供必要的决策信息,因此对在线评论进行情感分析具有很显著的应用价值。传统的情感分析一般根据文本所表达的情感信息将文本分为褒义和贬义两种不同的类型,这种粗粒度的结果不能在更加细粒度的层次下帮助消费者减轻信息过滤的负担;此外,有些评论中其评价对象的属性没有在语句中直接显示出来,往往需要依靠上下文的语境来判断,对其的情感理解亦不能通过传统的情感分析来完成。随着研究的深入,现在的情感分析可分为从文本分析的粒度层次划分的粗粒度情感分析和细粒度情感分析,以及从属性特征角度划分的显式情感分析和隐式情感分析。本文针对在线评论的细粒度情感分析进行了较深入的研究,其主要工作和创新点如下所述:(1)针对细粒度情感分析中的量化需求,提出建立领域级细粒度情感词典的方法。首先使用HowNet词典匹配领域通用的情感词,去除掉HowNet词典里与领域无关的情感词,加入网络词典,同时结合属性词、修饰词、否定词共同构建出五元组形式的细粒度情感词典,同时考虑了否定词和修饰词的先后顺序对情感词的不同加权效果,以利于在情感强度计算时,具体化每个属性的情感强度得分,从而使得最终的量化得分更加精准。(2)针对显式特征与隐式特征在评论信息中的特点,提出了多策略挖掘显式特征-观点对的方法,与传统的提取特征-观点对方法相比提高了提取的准确率;同时针对隐式属性和情感词往往并不是成对出现,因此较难挖掘这一难点,对蕴含在评论句中的隐式情感词进行抽取,再利用领域情感词典和机器学习结合的方法寻找与其配对的特征词。最后将显隐式情感结合起来进行量化,得出产品的细粒度情感倾向,通过实验证实结合隐式情感对情感分析结果确有帮助。(3)针对传统的细粒度情感分析多处理正面评论的情况,提出基于痛点视角下的情感分析方法,更加关注于产品评论中的负面评论,给出痛点指数的计算方法,以数值化的信息让消费者更加直观地了解产品各个特征的优劣程度。将该方法应用于不同酒店的在线评论中,以可视化的结果给出不同酒店的商业竞争优势和存在的问题,为商家的后续改进提供帮助。最后,给出了结论并简要地讨论进一步工作的方向。"
322,基于深度学习算法的遮挡行人检测,"近年来,随着人工智能技术的迅猛发展,机器视觉渗透到我们生活中的各个方面,人们的生活发生了日新月异的变化。行人检测作为其中一项较为基础的识别技术,对安防监控、自动驾驶、新零售等多个领域提供技术支持,具有广泛的应用场景。本论文主要以SSD目标检测算法为基础,针对遮挡行人这一特定目标,重新设计其网络结构,使其检测性能得到大幅度的提高。本文主要包括以下内容:论文对行人检测的研究难点及现状做了简单的总结,对传统的基于机器学习的行人检测方法以及基于深度学习目标检测算法的相关知识做了梳理。其中,基于HOG+SVM的行人检测算法是传统方法中最为经典的一种算法,基于深度学习的目标检测算法主要包括RCNN系列、SSD以及YOLO系列三大类。之后,综合考虑检测的速度与性能,采用自建的遮挡行人数据集训练了一个基于SSD目标检测框架的行人检测系统,并用测试集以及重新标注的INRIA测试集对OpenCV中自带的基于HOG+SVM的行人检测系统和训练好的SSD模型进行对比实验。实验结果表明SSD模型的检测效果要明显好于传统的基于HOG+SVM的行人检测系统,通过深度卷积神经网络学习到的特征更具有鲁棒性。最后,针对遮挡行人检测,对SSD模型的网络结构进行了相应的修改。(1)在SSD模型的前置网络中,加入了SE-Inception结构,使其能够更加高效的提取特征;(2)重新设计了网络中的先验框,使其能够更加容易的匹配到行人的形状,并对小尺寸的行人采用了密集采样的策略;(3)针对行人中容易出现环境遮挡和相互遮挡的情况,在模型的训练集中加入了遮挡行人的数据,并采用Repulsion Loss增强模型对遮挡行人的检测能力。最终实验结果表明改进的SSD模型在小幅增加检测时间的情况下,检测性能有了大幅度的提升。"
323,基于核机器学习的阿尔兹海默病早期诊断算法研究,"先前的研究表明,在阿尔兹海默病(AD)的计算机辅助诊断中,可用样本量通常较小,特征维度较高,且组内特征和组间特征关系很复杂,而传统的机器学习方法不能很好地解决这些问题,从而导致判断失误,准确率不高。针对这些问题,本文重点研究了如何将核方法与传统机器学习相结合,来达到一个较好的特征选择效果及较高的分类准确率。第一,提出了基于KPCA-FDA和KSVM的AD早期诊断算法。将核方法与主成分分析(PCA)、Fisher判别分析(FDA)和支持向量机(SVM)相结合,来提高AD的分类性能。首先,将原始特征子集放到核主成分分析(KPCA)模块中,再将原始数据集投影到较高维度的核空间上,降低主分量系数以增加线性可分离性;然后,将KPCA系数投影到更有效的FDA中,从而选择最优特征子集;最后,利用核支持向量机(KSVM)并结合新的特征子集,对AD、NC和MC三组数据进行分类,从而达到一个较好的分类效果。采用被试的sMRI数据进行实验,结果表明,该方法在区分AD和NC时表现了良好的分类性能,获得的分类准确性为92.34%,灵敏度为91.71%,特异性为90.04%,AUC为0.9143;在区分MCI和NC时获得的分类准确率为75.49%,灵敏度为80.45%,特异性为70.23%,AUC为0.8036。第二,提出了基于MK-SVM的多模态AD早期诊断算法。将sMRI和PET数据相结合,获取更多的辅助信息,从而提高AD的分类性能。首先,将FDA、核方法和局部保留投影(LPP)算法相结合,生成内核局部Fisher判别分析(KLFDA)算法,对提取的sMRI和PET数据特征进行降维处理;然后,提出了两种基于多核学习(MKL)的多元分类方法,WTA-KSVM和MWV-KSVM对AD、MCI和NC三组数据进行分类;最后,采用被试的sMRI和PET两种模态数据验证分类算法的性能。结果表明,两种多元分类方法在多模态数据(sMRI+PET)上获得的分类效果,要比在单模态数据(sMRI或PET)上获得的分类效果好。其中,WTA-KSVM方法取得了最好的分类性能,分类准确率为80.41%,灵敏度为81.56%,特异性为80.58%,AUC为0.8175;MWV-KSVM获得的分类准确率为80.07%,灵敏度为81.23%,特异性为80.16%,AUC为0.8114。与其他人的方法相比,本文所提的两种多元分类方法均取得了较好的分类性能。本文在核方法和机器学习的基础上对AD的早期诊断进行了初步的探索和研究,提出了两种基于核机器学习的AD早期诊断算法,为后人的研究提供了一些思路和方向。"
324,基片集成波导带通滤波器小型化研究,"目前,世界各国大力发展的无线通信技术主要集中于微波毫米波集成电路技术,其能实现系统多功能混合集成,减小系统尺寸,提高系统可靠性。在卫星通信、个人移动通信等领域有很大的应用价值。滤波器可以用来对信号中特定频段或该频段以外的频率进行有效滤除,得到或消除一个特定频段的信号。随着无线通信技术的不断发展,作为无线通信系统的重要组成部分,滤波器不仅需要具备功率容量大,品质因数高,损耗低等优点,同时也需要朝着小型化和易加工的方向发展。传统的高频传输形式无法同时满足以上无线通信技术发展的要求,因而近几年提出了一种新型传输结构--基片集成波导(SIW)。基片集成波导继承了传统传输结构的优点,在滤波器、双工器、耦合器及天线等方面有着广泛的应用。当然,基片集成波导结构也有一定的缺点,在频率较低时存在尺寸较大等问题。论文重点研究了基片集成波导带通滤波器的小型化设计及其优化,主要从以下几个方面进行:首先,介绍了基片集成波导的基本理论。由基片集成波导与传统矩形波导的等效原理,给出了基片集成波导尺寸的计算方法。简述了基片集成波导的传输特性和三种与其它元器件的过渡结构;以及介绍了设计基片集成波导带通滤波器过程中需要计算的基本参数和具体实现过程;其次,在滤波器设计的过程中,采用空间映射算法和机器学习算法对滤波器进行设计和优化。利用两种优化方法对同一款四阶基片集成波导带通滤波器进行优化设计,在均保证精确度的前提下,空间映射算法和机器学习算法的计算效率都得到了很大的提升。在实际的优化设计中,根据情况选择合适的优化算法,以达到既能保证计算的精确性又能在一定程度上提高计算效率的目的;然后,设计了一款基于物理耦合的中心频率为24GHz,相对带宽40%的双层基片集成波导带通滤波器。为了进一步提高滤波器的性能,引入了互补开口谐振环(CSRR)和电磁带隙结构(EBG),通过改变互补开口谐振环的大小和旋转角度以及电磁带隙结构的个数,改变传输零点的位置。经仿真证明了该方法的可行性;最后,设计了一款基于模式耦合的中心频率为26GHz,相对带宽25%的双模圆形基片集成波导带通滤波器。为了提高滤波器的性能,引入了传输零点。通过加载两个矩形谐振腔引入两个振幅相等相位相反的模式使滤波器在谐振时产生传输零点。经仿真分析和实物测量,证明了该方法的可行性。"
325,基于深度学习的道路裂缝识别算法研究与实现,"交通系统作为一种大型公共基础设施,其安全性关系着社会的正常运转。路面裂缝是公路系统最常见的缺陷之一,而对路面裂缝进行准确的识别则是排查公路系统中存在的隐患、保障交通系统正常运行的有效手段。目前已提出的裂缝识别算法主要使用传统数字图像处理方法,该类方法识别速度慢且无法有效排除实际环境中的各种干扰因素。本文针对实际环境下采集的路面图像的特征,提出了一种基于卷积神经网络方法的道路裂缝识别算法。本文的主要工作内容如下:(1)使用多尺度特征图的理念优化卷积神经网络模型,从而提升模型在裂缝识别任务中的性能表现。该方法充分利用了卷积神经网络模型的多尺度特征图结构,弥补了传统卷积神经网络模型仅使用单尺度特征图造成的漏识别率较高的问题。(2)提出了使用注意力机制对多尺度特征图进行赋权的方法,从而对各层特征图进行进一步筛选。该部分采用通道间注意力机制对叠合后的多尺度特征图进行处理,对多尺度信息进行进一步筛选,从而提升模型的特征提取效果。(3)设计了一套完整的路面裂缝识别方案。该方案将传统数字图像中的预处理技术与深度学习图像识别相结合,实现路面图像从采集后到输出检测结果的一系列流程。实验证明,该路面裂缝识别系统在实际公路环境采集的数据集上和一些公开数据集上均具有很好的裂缝识别效果,识别准确率明显高于传统数字图像处理方法。"
326,基于Shadowsocks的流量识别研究,"Shadowsocks作为一款新兴的匿名通信工具,因为其出色的通信效率以及其稳定性,逐渐在国内流行。目前国内对于Shadowsocks的研究较少,且对于Shadowsocks运行机制的系统性研究较少,本文分别对Shadowsocks的流量识别开展了以下研究:1、经过对大量Shadowsocks的流量样本数据进行分析研究后,本文对Shadowsocks的运行机制与通信原理进行了系统的描述与总结。2、针对传统流量统计特征集中可能存在高相似依赖性冗余特征,从而导致识别过程中大幅降低分类器性能的问题,本文提出了一种基于主成分分析-皮尔森相关系数的特征提取模型,该模型能对目前已有的传统流量统计特征进行降维,去除与样本相关性较低的特征,最终筛选出相关性强,冗余度低的适用于识别Shadowsocks流量的特征集。同时使用了随机森林、支持向量机(Support Vector Machine,SVM)和极端梯度提升(eXtreme Gradient Boosting,XGBoost)三种算法对该特征集进行建模识别验证,实验结果证明该特征集能在保证识别准确率不大幅度降低的情况下大大提升识别效率。3、针对分类器在Shadowsocks流量占比小的不均衡样本集上识别率低下的问题,本文提出了基于网络流多重过滤的识别模型。经过对大量Shadowsocks流量样本进行分析,根据提取出的字符分布特征,提出了基于字符熵的过滤方法;根据提取出的报文长度序列特征,提出了基于报文长度序列的过滤方法;根据上两步过滤的结果,提出了基于数据包长度熵的过滤方法。最终融合了三个过滤步骤来对混合流进行多重过滤,并结合经过降维后的特征集以及XGBoost算法构建了分类模型。最终实验结果证明,通过对混合流中的Shadowsocks流量与非Shadowsocks流量进行提前筛选过滤,有效的提高了面对不均衡样本集时识别的准确率,同时大大提升了识别的效率。"
327,跨社交网络的用户身份关联技术研究,"为了识别出同一个自然人在不同社交网络平台中的虚拟身份,跨社交网络的用户身份关联技术已经成为当前的研究热点。对于公安工作而言,实现跨社交网络的用户身份关联、形成人员的全息档案意义重大,特别是面向境外或小众的社交网络,公安部门很难掌握此类社交网络平台全面的用户基础数据,该技术可以为用户身份核查、情报线索扩展等业务提供有力的数据支撑。因此该技术的研究具有重要的理论意义和实用价值。论文的主要工作有以下三个方面:(1)提出了融合分类法和赋权法的跨社交网络用户身份关联算法。该算法通过串行处理模式,融合了分层级联的机器学习模型(HCML)和基于信息熵赋权的结果修正模型,不仅充分利用了不同维度的用户属性信息,也考虑了属性综合相似度的统计分布特征,提升了关联准确性。此外,该算法所使用的用户属性特征抽取方法对大部分社交网络具有普适性,面向用户名、地理位置、个人描述和头像进行了多种不同指标的相似度计算,更全面地反映了不同平台用户之间的相似性。(2)提出了基于网络表示学习的跨社交网络用户身份关联算法。面向异构信息网络,改进了传统网络表示学习算法LINE,提出融合跨平台先验关联关系的网络表示学习算法CSN_LINE,将用户关系的网络拓扑信息转化为低维向量进行表示,以此作为跨社交网络用户关系的特征向量。然后构建了基于多层感知机的用户身份关联模型。该算法通过有效的网络表示,提高了用户身份关联的准确性。(3)设计并实现了跨社交网络的用户身份关联原型系统。该系统集成了基于用户属性和用户关系的身份关联算法,形成技术关联子系统,同时也开发了基于用户基础信息的硬匹配关联子系统。该系统可以针对常见类型的社交网络用户数据,提供用户身份关联的功能。目前该系统已作为国家重点研发计划“网络空间安全”重点专项(项目编号:2016YFB0801100)的成果,在某地公安业务部门进行了测试验证。在论文研究中,爬取了来自豆瓣网和新浪微博的用户数据,其中豆瓣网用户量约200万,微博用户量约80万,数据类型包括文本、图像、网络拓扑等。利用真实数据对本文提出的两种用户身份关联算法和原型系统进行了实验测试,两种算法的综合评价指标F1值分别达到0.8720和0.8563,相比传统方法有大幅提高,证明了身份关联算法的有效性,同时原型系统在测试中也能准确关联用户的身份,证明了系统的可用性。"
328,基于自动化测试技术的Android恶意积分墙应用检测系统的设计与实现,"移动互联网近年来高速发展,海量的移动应用给人们带来了便利。但部分开发者为谋取利益,在应用内植入移动广告并通过某些手段欺骗或引诱用户与其产生交互,引发了大量的广告欺诈安全问题。本文关注恶意积分墙应用,它指利用积分墙广告进行广告欺诈的应用。积分墙广告是近年来出现的新广告类型,该类型广告在应用内提供下载应用的任务供用户完成,用户完成任务后会回馈给用户积分(虚拟货币)。该种广告在大部分主流的移动广告平台内都有集成,普及率较高。积分墙广告带有一定的交易属性,较传统移动广告类型,出现恶意广告欺诈行为的频率更高,对用户的利益造成了较大损失。积分墙广告形式特殊,围绕积分墙广告产生的恶意行为也与传统的广告欺诈不同。当前,业内对于Android移动广告欺诈方面的研究较为传统,现有研究一般都集中于条形广告和插屏广告的点击欺诈(Click Fraud)、静态位置欺诈(Static Placement Fraud)和动态交互式欺诈(Dynamic Interactive Fraud)等,而对积分墙广告检测的研究停留在静态分析阶段。但由于广告行为在用户使用应用时动态产生,传统的静态方法例如直接提取API或规则匹配等,无法有效的检测围绕积分墙广告的欺诈行为。本文在现有研究的基础上,设计并实现了一套有效的恶意积分墙广告应用检测系统,本文的主要工作成果如下:(1)针对积分墙广告应用的特点,研究了基于有向状态转换图和积分墙优先遍历策略的Android自动化测试技术。该技术在运行应用的同时构造应用的状态转换图,再通过状态转换图中的信息遍历应用中的状态(界面),同时利用积分墙优先遍历策略提高发现积分墙广告的概率。有效提升了自动化运行带有积分墙广告应用的性能,使自动化测试可以快速稳定运行大批量带有积分墙广告的应用;(2)传统的基于位置特征和字符串匹配技术的移动应用广告识别方法存在准确度低的问题,为此,本文对积分墙广告界面提取控件结构和网络流量信息,形成结构化的特征,并利用LightGBM对结构化特征建模,借助机器学习的方法对移动广告进行识别。该方法具有抗混淆的特点,对于新出现的未知积分墙广告也具有检测能力;(3)本文总结了两类围绕积分墙广告的恶意欺诈行为,包括强制积分墙交互欺诈和积分墙点数奖励欺诈,并利用启发式恶意行为检测方法检测以上两类欺诈行为。其中,针对积分墙点数奖励欺诈,即完成积分墙广告中任务后并无积分返还的恶意行为,本文提出自动化运行模型实时推断和积分墙触发路径回溯方法,在自动化运行过程中实时识别积分墙广告并完成广告中的下载任务,完成对该类型欺诈的精确检测;(4)本文实现了一套半自动化的Android恶意积分墙检测系统,该系统包含四个模块。通过实验表明,本系统在检测性能和资源消耗上已达到实用水平,且相较于传统方法和现有研究有明显提升,解决了目前业内对于恶意积分墙广告的欺诈行为无法有效检测的问题。"
329,SQL注入智能检测工具的设计与实现,"日新月异的互联网Web技术在为人类发展带来便利的同时,也引发了层出不穷的安全问题。SQL注入是蝉联数十年OWASP[1]漏洞排行榜之首的注入漏洞类型中最常见的攻击之一。其数据泄露等的高危害性和SQL样本的多变性,成为近年来攻防专家致力研究的重要原因。对于SQL注入流量的检测,国内外已涌现出许多成熟的商业性防火墙产品(WAF),但存在防护规则状态有限、可读性差和维护成本高等缺点。面对复杂多变的SQL注入攻击,学术界提出基于人工智能的解决方案,通过将文本向量化进而转交给算法模型分类处理以实现检测恶意攻击的目的。然而缺乏丰富多样的数据集和特征向量提取不全等问题导致了分类模型检测性能的瓶颈。基于以上的分析基础,本文主要从如下三个方面开展相关工作:(1)通过深入分析SQL注入漏洞的原理及相关组件脆弱性,提出了SQL样本随机生成算法,结合开源工具SQLMAP进行二次开发,生成高质量的SQL样本,甚至是可定向绕过防火墙的变种样本,有效提升了模型的检测精度。(2)改进了传统的分词提取特征的方法,融合了多维变种样本的特征,引入了差分特征向量以弥补特征提取过程中的信息损失,通过三轮有针对性的特征提取,实现了对传统SQL注入和变种SQL注入流量通用的特征提取方法,增强了特征提取的完整性,从而强化了对未知变种SQL注入的检测能力。(3)基于深度森林分类算法设计并实现了SQL注入智能检测工具。通过多数据源的迭代更新,实现了对模型迭代优化的效果,一定程度缓解了数据集匮乏的问题,并提升了模型的检测精度,有效抑制了模型过拟合的问题。文章最后主要从生成模型性能和检测模型性能两个方面进行实验论证:通过比较本文生成算法生成的样本对抗商业WAF的效果和基于SQLMAP二次开发的定向绕过防火墙的效果,证明样本生成方案的可行性与有效性;通过对比本文特征工程方案与前人的研究方法在多组浅层机器学习模型下的分类性能指标,验证本文特征工程方案的有效性;通过在不同比例黑白样本的训练情形下,分别对比了深度森林与深度学习模型和浅层学习模型的性能与精度差异,验证了本文检测模型的优势,也从侧面验证了本文样本生成算法一定程度上提升了模型的检测精度,有效抑制了模型的过拟合;最后通过多数据源的迭代更新,线下检测模型检测精度整体呈上升的趋势,验证了系统设计的合理性。"
330,Android木马关键技术与检测方法研究,"在快速普及智能手机和大力发展移动互联网的社会热潮下,智能手机已经成为现代社会的必需品,围绕智能手机犯罪日益增多,而木马类电信诈骗案件作为电信诈骗案件的升级版发案数量日益增长,且此类犯罪极具隐蔽性,犯罪分子能在受害者不知情的情况下转移其电子账户和网上银行的资金,社会危害极大。此类犯罪日益成为公安工作打击的重点。而办理此类案件时,需要木马相关的知识才能在传统电信诈骗案件侦办手段基础上利用木马的特征深入挖掘更多的线索。Android手机木马越来越成熟,功能越来越强大,相应的对办案人员的要求也越来越高。本文在总结Android系统框架和安全机制的基础上,研究总结Android系统木马使用的关键技术,包括植入技术、隐藏技术和加固技术,并提出了各个技术的方法要点,重点放在木马APK加固技术,总结APK面临的威胁,研究梳理了反编译,反调试,木马加壳等技术,并给出了具体的实现方法和思路,部分验证了效果。通过对这些技术的研究可以了解木马更多的技术细节,便于在工作中针对性的开展工作。本文结合公安工作在侦办木马类电信诈骗案件时,对木马检测系统的实际需求设计了一款服务公安工作的木马检测系统,该系统采用模块化设计,实现利用MD5对比实现对木马类电信诈骗案件并案,利用特征码检测及将KNN、随机森林、SVM机器学习算法使用表决算法改进后应用到木马检测。最后利用收集到的正常APK和恶意软件APK提取权限特征向量,对检测系统中提出的检测算法进行验证,证明此算法能够满足在公安工作实际应用中高准确率、低误报率的要求,达到预期效果。"
331,近红外光谱分类的深度森林方法及应用研究,"近红外光谱(Near-infrared spectrum,NIRs)分析技术具有速度快、效率高、无损无污染等突出特性,通常结合机器学习方法实现对NIRs检测的定性分析。然而,NIRs数据与测量环境、仪器、实验水平等密切相关,不同批次采集的样本具有显著差异且难以获取大量的定标样本,导致传统方法存在特征学习能力不足、训练困难等问题,其分类效果往往不佳。因此,探索更有效的NIRs分类方法是提升NIRs任务效益的关键。本课题将深度森林算法作为NIRs数据的分析方法,分别从特征集成学习、表示学习两个角度进行研究并构建鉴别模型,在柑橘黄龙病检测和药品精细分类任务上得到验证,提升了NIRs的分类性能。本文的主要研究工作如下:(1)以深度森林的特征集成思想为研究点,本文提出多特征融合的级联森林(Multi-Feature Fusional Cascade Forest,FCForest)算法。首先提取原始数据的有效特征,然后利用级联的集成决策树充分学习特征间的差异与互补信息,并自适应选择最优模型结构。结果表明,在柑橘黄龙病检测和药品鉴别两个不同的NIRs任务下,FCForest的预测准确性和模型稳定性明显优于其他主流算法,并大量减少原始深度森林方法的训练时间,因此是一种有效的近红外光谱鉴别方法。(2)以深度森林的特征分层表示思想为研究点,本文提出自适应特征的多层梯度提升决策树(Multi-Layered Gradient Boosting Decision Trees with Adaptive Feature,FGBDT)方法。通过加入自适应特征机制,大幅降低特征冗余及模型复杂度,并以目标传播的变体优化非可微模块,映射更好的数据特征空间分布。实验表明,FGBDT能够获取优秀的特征分布表示,且相比其他方法具有更高的准确性和鲁棒性。在此基础上引入代价敏感学习,在不均衡数据上表现出优秀的性能,因此是一种准确可靠的近红外光谱分类方法。"
332,基于深度学习的人体特征识别的研究与实现,"随着体育运动在人们生活中的积极开展,越来越需要人体特征识别技术,该技术可以辅助运动领域的专业人员进行三维人体建模,以便分析图像中人的运动过程。同时,当今各种拍摄设备诸如手机、便携运动相机的普及促进了图像数据的蓬勃增长。因此通过计算机视觉技术,图像数据被广泛应用在人体特征识别的实际应用场景中。而且,近些年深度学习技术在计算机视觉领域取得了不小的突破,因此可以研究深度学习技术在人体特征识别上的有关应用。本论文提出了基于深度学习进行人体特征识别的相关方法,论文作者也设计和实现了一种人体特征识别系统,该系统的输入为图片,输出为图片中主体者的相应人体形体特征。在本文中,作者首先介绍了研究背景与意义,并对研究目标和内容做了说明。接着,将研究过程中涉及到的相关技术领域的工作进行了介绍。然后,对所要实现的人体特征识别系统进行了需求分析,确定系统所要完成的功能。根据需求分析,结合深度学习技术,对系统的概要设计以及功能模块划分进行说明,并完成系统的详细设计与实现。随后设计了测试用例对系统进行了白盒测试和黑盒测试,并对系统运行效果进行了分析。最后,对整个论文工作进行了总结,并且对下一步工作进行了思考与展望。本文所提出的人体特征识别系统,采用了基于深度学习的实例分割方法,能够分割出图片中主体者的人体轮廓,并通过无监督学习方法对人体轮廓进行人体形体特征上的识别。同时该系统中还通过监督学习方法,结合人脸检测对图片中的主体者进行人体BMI值的回归预测。根据系统的测试结果,验证了该人体特征识别系统能够达到识别人体特征的功能。"
333,基于深度学习的指针式仪表示数自动识别的研究与应用,"随着科技的不断发展,工业信息化、数字化的不断提升,指针式仪表作为数据测量、数据监控、数据收集的重要工具,在工业生产生活中发挥着巨大的作用,对维持正常的生产生活具有重要的意义。然而,当前仍然存在大量需要人工进行采集和录入的指针式仪表监测数据,这种数据采集方式不仅仅耗费大量的人力、物力,而且也会影响数据的时效性并造成一定的数据误差。同时部分指针式仪表工作环境恶劣,无法进行人工采集和数据信息传输。因此,如何对指针式仪表进行高效的、精确的自动数据录入变得尤为重要。随着近些年来图像采集成本的降低,图像采集质量的提高,图像识别技术也日趋成熟,因此本文采用基于图像处理的方式进行指针式仪表示数自动识别研究。本文通过结合图像处理和深度学习的相关技术,在研究和学习己有指针式仪表自动识别算法的基础上,提出和设计了一种基于深度学习和形态学的指针式仪表自动识别算法。本文设计的指针式仪表自动识别算法主要包含三方面的核心内容:仪表盘及仪表数字的检测和提取、仪表盘指针的定位和拟合、仪表盘数字的识别和仪表示数的判定。在仪表盘及仪表数字的检测和提取中,本文结合深度学习相关知识,提出和设计了对自然场景中仪表有效信息提取的卷积神经网络模型MASKR2CNN,并构建了相应的训练数据集对模型进行训练和测试,从而实现对自然场景中的仪表盘进行图像分割和有效信息提取;在仪表盘指针的定位和拟合,针对本文设计的指针式仪表有效信息特征提取方式,采用Ostu阈值分割法和概率霍夫直线法对指针进行拟合和定位;在最后一部分核心内容中,本文采用KNN对仪表数字区域进行数字识别并采用距离法对最后示数进行判定。经实验结果测试,相对误差在5%以内的示数识别准确率为81.64%。"
334,机器学习方法在期权定价中的应用,"由于市场固有的嘈杂和非线性特征,对市场行为准确预测成为了一项具有挑战性的任务。使用预测值,可以对资产进行定价,并且可以做出战略决策以获得短期或长期的收益。现在市场上已经有了各种统计预测器,并且可以得到不同的结果。本文首先回顾了包含Black-Scholes模型在内的几种期权定价方法,以及几类机器学习算法的基本原理;之后将常见的四种机器学习算法:支持向量机模型;聚类及支持向量机混合模型;输入预测及支持向量机混合模型;强化学习方法,应用于期权定价的数值计算中,并与Black-Scholes期权定价公式得到的理论价格进行比较。本文主要参考了Deoda,A.[11]和Martin,K.[18]的论述,并进一步深入理解,之后利用实际数据对文中提出的方法加以验证。通过不同方法的结果比较发现,采用聚类和SVR方法的混合模型优于单纯的SVM模型。与其他机器学习方法相比,使用预测输入参数的方法的性能较差。有趣的是,大多数模型的性能都随着我们从ITM期权系列转向OTM期权系列而提高。这可以归结为指数在长期价格水平上总是趋于上升的事实。不过现有的程序非常耗时,因为必须为要定价的每个期权都生成模拟。此外,交易者需要更准确的预测价格来降低期权交易中的风险。"
335,基于机器学习的社会安全风险分析研究,"当前,我国正面临着严峻的社会安全形势。针对社会安全事件进行客观、有效、及时的风险分析十分必要。定性的风险分析方法消耗成本高且难以验证,传统的半定量和定量风险分析方法模式固定、灵活性不足,难以刻画动态变化的、不确定性高的、突发性高的社会安全风险的问题,本文以盗窃犯罪和恐怖袭击事件作为常规社会安全事件和非常规突发事件的典型代表事件,提出了基于机器学习的社会安全风险分析方法,主要内容如下:(1)针对常规社会安全事件的风险源及影响因素的分析。以发生概率高、潜在后果损失有限的盗窃犯罪为研究对象,利用实际盗窃犯罪数据,选取作案时间、作案地点、作案手段和损失金额作为特征,基于多种机器学习算法预测盗窃人员的身份类型(初犯\累犯\惯犯)。结果表明,随机森林性能最优,在训练集上进行10-折交叉验证,F1-micro为0.70,测试集上对初犯、累犯和惯犯预测的F1分别达到了0.73、0.75和0.76。选取性别、年龄、文化程度等静态属性和当月网吧上网次数、住店次数、被盘查次数等动态轨迹为特征,对盗窃前科人员进行分类预测,结果表明,随机森林性能最优,F1-micro最高达到了0.88,特征重要度排序表明,当月盘查次数、年龄、受教育程度和作案地距离对前科人员的再犯罪风险具有较强的刻画能力。(2)针对非常规突发事件的风险(可能性及后果)分析。以发生概率低、造成后果极其严重的恐怖袭击事件为研究对象,利用全球恐怖主义数据库1970~2017年的全量样本,选取脆弱国家指数作为特征,预测恐怖袭击发生的次数,结果表明,随机森林和K近邻表现最优,拟合优度R~2在测试集上分别达到了0.75和0.74,其中随机森林的泛化能力更强。基于Prophet算法对武装袭击发生的条件概率进行时间序列分析,模型在2016年和2017年上预测的平均绝对误差为3.7%,季节性趋势分析表明,每年2月初期、6月中旬和10月中旬是武装袭击爆发的热点时期。选取恐怖袭击事件发生的时间、地点、攻击意图、攻击类型、目标类型等12个特征对恐怖袭击造成后果的严重性进行分类预测,结果表明,XGBoost表现最优,在训练集和测试集上预测的F1-micro分别为0.716和0.72。"
336,光载无线网络虚拟化技术研究,"面向高带宽、低时延以及终端大量接入等特性的接入场景成为第五代移动通信技术的研究热点,随着车联网等业务兴起,海量数据处理以及多维资源优化分配加剧了光载无线接入网管理控制复杂性。针对光载无线接入网管控复杂以及资源维度高的问题,虚拟化技术为多业务接入承载以及雾计算与接入网融合提供了一种有效方法,为了提高接入网管控敏捷性以及多维资源统一有效分配,光载无线接入网虚拟化必将成为未来移动通信接入网发展的趋势。本文围绕光载无线接入网向未来移动接入演进需求,研究光载无线接入网虚拟化实现方案及资源优化分配方法,深入研究基于虚拟化技术的接入网架构体系、网络资源切片统一编排方法和面向云雾协同处理的虚拟化映射方法,在实现光载无线接入网管控敏捷化以及资源有效分配的目标中形成架构体系创新及突破。本文主要工作以及创新成果如下:第一,从光载无线接入网架构体系以及资源维度出发,构建光载无线接入网基站虚拟化模型。以协同传输和宏微基站部署为背景,围绕海量终端多基站接入管控复杂、资源维度高问题,借助虚拟化技术对BBU间业务疏导统一处理,减少多BBU间信息交互约束,实现业务有效承载。第二,结合网络切片技术在光载无线接入网中应用,面向多维资源切片编排,构建光载无线接入网网络切片间管理方法,建立切片间关联关系,在多维资源统一分配条件下,提高资源利用率,降低接入网管控复杂性。第三,面向未来雾计算与云化光载无线接入网融合需求,构建云雾协同处理的光载无线接入网控制管理体系,实现计算资源有效分配,完成雾计算节点业务承载。借助机器学习中K-means算法,提出一种基于节点位置信息的虚拟网映射方法,在满足业务计算需求条件下,最大限度降低接入处理时延。"
337,基于复杂网络和机器学习的冷链物流末端共同配送研究,"近年来,随着生活水平的不断提高,民众在解决温饱问题的基础上,越来越追求食物的品质和营养。消费的升级直接推动了我国冷链物流行业的发展。但由于我国冷链物流起步较晚,发展水平比较落后,整体运行效率低,成本长期居高不下。尤其是末端配送环节,往往无法保证服务质量,是造成冷链“断链”、货品受损的主要原因之一。面对这一现状,本文将共同配送思想引入冷链物流中,利用复杂网络和机器学习的相关算法,设计和实现了一套应用于冷链物流的末端共同配送方案,旨在提高物流运行效率、降低配送成本、保证服务质量。本文首先总结了冷链物流及共同配送领域的国内外研究现状,其次在明确冷链物流相关概念及内容的基础上,对末端共同配送的必要性进行分析与描述。然后针对城市末端的实际情况,从共同配送的区域划分、配送服务的模式选择和合作的收益分配三方面设计了一套完整的末端共同配送方案,并以北京“城市副中心”的部分区域为例进行实例分析,验证方案可行性。方案中第一步,通过特定的转换规则建立社区网络模型,在模型构建过程中引入层次分析法,对小区间配送的难易程度进行综合评价,将其值作为网络模型中各边的权重。在此基础上,采用Louvain算法对网络模型的社区发现问题进行求解,最终得到末端配送区域的划分结果。第二步,采用Adaboost分类算法对各配送区域内网点的服务模式进行选择。通过采集相关的特征数据,训练机器学习模型,实现算法分类,得到各区域对应的服务模式。第三步,通过改进的Shapley值法,对共同配送联盟的收益分配问题进行研究。提出一种基于加权Shapley值法的收益分配方案,该方案充分考虑了各企业在合作中的重要程度。最后经过案例数据计算分析,发现方案结果与实际情况吻合,具有较强的可行性,为冷链物流末端共同配送的研究提供了新的思路和方向。"
338,多核学习在储层建模中的应用研究,"储层建模是一种需要对储层地下地质特征和油藏进行精细化描述的技术。其中的重点是描述观察到的空间信息与孔隙度和渗透率等目标变量之间的预测关系。在储层建模过程中,建模结果的不确定性与物性参数的非均质性是影响模型最终精度的关键因素。本文提出数据驱动的机器学习方法,使用该方法对储层中孔隙度等物性参数的空间分布进行建模。该方法采用基于核学习的多核学习方法,整合具有多尺度特征的先验地质信息,使储层的先验知识和物性参数以一种高效的方式结合在一起,从而提升储层模型的现实性。本文展示了如何使用多核学习方法去结合地震数据与先验知识构建储层地质模型。使用图像处理相关技术从地震数据中捕获梯度等大小变化敏感的数据来确定地质特征。利用多个地质特征,使用多个核函数一一对应的方式在高维空间中计算物性参数。根据多核学习中从数据之间学得的依赖关系优于预定义模型这一原则,通过模型参数的变化,灵活地控制了储层物性参数,将预测值以一组加权核函数的方式给出。本文的方法利用油田实际储层数据进行了验证,地质模型效果良好,再现了一个复杂的辫状河储层地质模式。"
339,机器学习在储层参数预测中的应用研究,"储层参数是描述储层特性、流体模式和储层建模的重要指标,也是油气藏精细评价的基础。传统的储层参数预测,都是根据测井曲线来建立一个模型去拟合孔隙度、渗透率等参数,主要有回归分析、经验公式等,其中大部分方法都是基于线性的,而在实际环境中,储层状况复杂,非均质性较强,测井曲线与储层参数之间往往是复杂的非线性关系,利用传统回归分析等方法,所建立的模型预期效果不理想、误差较大,故而寻找一种高效、精确的预测方法显得尤为必要。针对以上存在的问题,本文在研究分析了3种常见储层参数预测模型的基础上,构建了基于粒子群算法优化的支持向量机储层参数预测模型。主要工作包括:首先,分析和研究测井曲线与储层参数之间存在的非线性关系,利用支持向量机适合解决小样本、非线性及高维问题的优势,建立两者之间非线性的预测关系,最大限度利用和挖掘现有测井信息。其次,对影响支持向量机预测效果较大的核参数σ和损失函数参数ε进行优化选择,利用粒子群优化算法收敛速度快、并行性高、全局搜索能力强的优点,寻找全局最优支持向量机参数,建立优化支持向量机储层参数预测模型。最后,为了进一步验证模型的实用性和可靠性,将优化改进后的模型应用到研究区域实际储层参数预测中,对储层孔隙度和渗透率进行预测评估。实验结果表明,经过优化改进的支持向量机预测模型在准确率和运行时间上要优于传统的回归分析和神经网络等方法,模型稳定且有效,在一定范围和条件下是一种可靠、有潜力的储层参数预测方法,可对研究区域其他油井进行测试使用,为后期油气田勘探开发提供一定帮助。"
340,基于Tensorflow的循环神经网络模型在上海市空气质量预测中的应用,"近年来,空气污染日益严重。有效地监控空气质量,准确地预测空气污染物浓度对预防大气污染有重要的指导意义。此外,由于空气质量具有时序性,会受多个难以确定的污染源影响,经常用到的回归预测方法效率和精度都比较低,而循环神经网络模型却能有效利用时序数据中长距离依赖信息的能力,对此类数据进行相关的预测分析。本文将尝试利用上海市空气质量监测站的小时均值数据,基于Google开源Tensorflow机器学习框架并使用长短期记忆单元(longshort-termmemory,LSTM)的循环神经网络建立动态预测模型,同时采用基于时序的反向传播(BPTT)算法逐步更新网络权值进行网络训练,期望能够建立影响空气质量指标的_2,_2,_3,_(10),_(2.5),CO这6种污染物的小时均值级别的空气污染物浓度预测模型。本文的主要工作及贡献如下:利用灰色关联分析法与主成分分析法分别对大气污染物浓度预测模型中的输入变量进行筛选,筛选出对预测监测因子浓度影响较大的污染物并建立相关的预测模型。然后基于测试数据,分别对两种预测模型使用MAE、MSE、~2等评价指标对预测模型进行评价。最终验证了基于Tensorflow训练的循环神经网络能较精准地应用于空气污染物的浓度预测。"
341,基于短期单导联心电图的房颤风险监测算法的研究,"心血管疾病是目前死亡率最高的疾病,全球死亡人数中的五分之二都死于心血管疾病,而机动车司机因为长期暴露在交通堵塞、噪声污染等不良环境中,又因其需要长期超负荷工作等职业特点,更加容易出现心脏健康问题。心房颤动作为心血管疾病中最常见的一类心律失常,与许多心脏病的发病率和死亡率具有显著关系。房颤可以通过心电图进行确诊,因此,利用心电图进行实时自动监测房颤风险成为当前社会迫切的需求和研究的热点。大多数现有的房颤检测算法仅对正常节律和房颤节律进行分类,忽略了现实中可能出现的其他情况,而且只在包含少量受试者的小数据集上进行训练和验证,导致现有房颤检测算法在实用性方面仍然受限。本文提出的基于机器学习和深度卷积神经网络进行房颤检测的算法,充分考虑现实中可能出现的情况,将心电信号分为正常节律、房颤节律、其他节律和噪声四类,并在包含来自不同受试者的8528条心电数据集上进行训练和验证。本文提出的基于机器学习的房颤检测算法同时考虑了心室活动和心房活动,对心电信号进行去噪、基准点识别之后,共提取了38个特征,包括时频特征、熵特征和统计特征等。然后使用支持向量机、K最近邻、决策树和随机森林四种传统机器学习算法对特征进行分类,并进行参数调优。实验结果显示,基于随机森林的算法表现最优:总体准确率为83.83%,平均F1分数为82.23%。本文提出的用于检测房颤的卷积神经网络模型包含一个输入层、四个卷积块、一个全连接层和一个输出层,其中每个卷积块由两个卷积层构成。该算法将心电信号转化为对数频谱图作为卷积神经网络的输入,通过卷积神经网络自动学习数据中的复杂特征,省去了人工设计特征提取规则的复杂工作。模型在GPU计算平台上进行训练,最后得出了比机器学习算法更加优越的分类精度:总体准确率为84.81%,平均F1 分数为82.41%。本文设计并实现的基于短期单导联心电信号的房颤风险监测算法具有较高的准确度和实用性。将该算法运行于可采集心电信号的可穿戴设备或移动设备中,机动车司机便可以实时监测自己的心脏健康状况,从而避免重大交通事故的发生。物流公司也因此可以对司机的健康状况进行监控,从而降低物流成本的支出。同时对社会而言,可实现高度的医疗资源共享,降低公众医疗费用,具有很大的现实意义。"
342,基于机器学习的中文文本分类算法的研究与实现,"随着大数据时代的快速发展,文本信息数据量急剧增加,为了获取有价值的信息,提升信息获取效率,就需对这些文本信息进行分类。因此,文本分类系统的研究与实现具有重要意义。新闻文本是文本信息的一个重要组成部分,也是人们获取信息的重要方式。本文以新闻文本分类为依托,对当下文本分类算法进行改进,以新闻文本分类系统为实例对文本分类系统的设计与实现进行说明,完成文本分类算法的研究工作。本文以大数据时代背景及分类技术的发展为背景,对贝叶斯分类算法以及卷积神经网络分类算法进行了改进,以提升分类的准确度,主要工作内容有以下几个方面:第一,本文针对不同种类的文本分类方法做了调研,通过阅读文献资料,了解了文本分类的发展历史,分析了贝叶斯、KNN、SVM、决策树、Fasttext及CNN等各分类算法的利与弊;第二,对朴素贝叶斯分类算法进行了改进,提出了一种结合特征词分布情况的k-Bayes分类算法,增加了意义突出的特征词的权重,提升文本分类效率;第三,对卷积神经网络分类算法进行了改进,加入了注意力层的特征提取操作,形成基于注意力层的卷积神将网络,重新分配特征词权重值,将特征词进行进一步提炼,符合人们对于分类的理解――专注于有意义的某些词语,这对提升文本分类的准确度有较好的效果;第四,本文以新闻文本分类系统为例说明了文本分类系统的设计与实现。系统可以为用户展示直观的分类结果。分类算法的改进都是从精炼特征词的角度出发,通过实验验证,本文的分类算法确实提升了分类的准确率。"
343,基于机器学习的勘探门户新闻自动分类研究,"随着勘探门户新闻数据量的提升,新闻内容的复杂度增加,导致传统人工进行新闻分类的的方法效率越来越低,并且人工进行新闻分类很容易受到主观因素的影响,使得分类的准确程度不高。这种传统的人工新闻分类方法已经不能满足需求,因此,需要研究一种适用于勘探门户新闻的自动分类方法来解决现存问题。而基于机器学习的方法能够实现勘探门户新闻的自动分类,改善人工进行新闻分类的不足之处。本文深入分析了勘探门户新闻文本特点,在研究了机器学习在文本分类中关键技术的基础上,通过实验对比了几种在新闻文本分类中的常用技术,选择了一套适用于勘探门户新闻自动分类的方法,提出了基于机器学习的勘探门户新闻自动分类系统的设计思路与总体设计方案。首先对新闻文本进行预处理,然后采用CHI的方法进行特征提取,接着使用TF-IDF进行特征的权重计算,然后使用SVM分类算法来建立分类模型。本文对于中国石油勘探与分公司门户,设计并开发了基于机器学习的勘探门户新闻分类系统。通过该系统,从新闻源处获取的新闻可以自动被分类到其所属的类别中。实验结果显示,使用该分类系统对勘探门户新闻分类准确率达到了85.7%,实现了对勘探门户新闻的自动分类,提高了分类效率,降低了企业成本,使分类的准确程度获得了较大的提升。"
344,基于深度学习的多标签场景图像分类研究,"场景分类是图像分类的一种特殊情况,它根据图像的视觉内容为图像赋予相应的语义类别,相对于一般的图像分类,场景分类训练的数据集可能较小,且场景分类往往是多标签的,同时类内差异明显,类间又有很多相似性,使得多标签场景图像的有效分类存在诸多挑战。深度学习在识别图像中的对象方面具有非常优异的表现,基于深度学习的图像分类在特定任务上早就超过了人类的平均水平。本文利用深度学习相关神经网络算法良好的特征提取优势,结合多示例多标记学习(MIML)和迁移学习相关理论建立分类模型,给定一组图像,识别图像中包含的场景或对象来对它们进行多标签分类。基于深度神经网络的多示例多标记学习算法,将BP神经网络和RBF神经网络引入到多示例多标记学习框架中,分别建立MIMLNN算法和MIMLRBF算法的分类模型,能够采用非线性函数为标签相关性建模,描述出更为复杂的标签同现关系,同时将标签的相关性反馈到输入来提高系统的性能。与传统的MIML相关算法相比分类效果优势明显,同时通过改进MIMLRBF算法中Hausdorff距离表达,提出改进的W-MIMLRBF算法,进一步提高多标签场景图像分类效果。基于迁移学习的多标签场景图像分类算法,消耗少量的计算资源与训练时间即可实现场景图像的有效分类。在计算机视觉任务中运用深度学习技术,将已训练的模型作为新模型的起点是一种常用的方法。本文基于已经训练好的Inception-V3网络模型,在其基础上进行参数与知识迁移,保留Inception-V3模型用于图像特征提取的卷积层,修改其全连接层以满足多标签分类输出要求,基于迁移学习训练出的分类模型可以有效地提取出图像的本质特征,在多标签分类评价标准上取得了优异结果。"
345,基于机器学习的城域网流量预测与业务重构技术研究,"近年来随各种宽带业务信息流量势如破竹般增长,光网络运维与资源调度面临着前所未有的挑战。而软件定义光网络技术(SDON)的出现也让计算机技术管控网络更加高效。与此同时,在城域网中用户接入网络位置实时变化,造成了网络负载随时间周期性动态变化的潮汐流量现象,而网络运营商无法对此做出快速灵活的资源调度,给网络运维带来了挑战。如何准确预测城域网中的流量变化以及针对预测结果给出合理的资源调度策略,是当前亟需攻克的关键技术难题。本论文围绕潮汐流量预测问题与城域光网络潮汐效应下的业务疏导问题,主要从建立潮汐流量预测模型、光路提供与业务重构三个方面展开研究。本文的具体工作和创新点如下:(1)针对城域网潮汐流量现象,建立了BP人工神经网络模型预测潮汐流量变化,使其既解决预测潮汐迁移到达的问题,又解决流量变化拟合问题。在模型训练过程中调整模型参数,减小模型预测误差。仿真结果表明该方案可有效预测网络的潮汐流量变化趋势,预测归一化拟合误差控制在0.05以内,预测准确率达到90%以上。(2)基于该BP-ANN流量预测模型,设计了城域网潮汐流量管控机制,将机器学习模型内嵌,运用于流量调度决策过程中。在该机制的基础上提出了基于流量预测的光路提供启发式策略。仿真结果表明该光路提供机制能够缓解潮汐流量现象导致的负载不均,与最短路径策略以及负载自适应路由策略相比阻塞率分别降低11.9%和1.3%。(3)结合设计的管控机制以及BP-ANN流量预测模型,提出了一种面向城域网潮汐流量的业务重构方法,详细描述了如何利用BP-ANN模型的预测结果进行重构的触发以及业务的搬移流程。仿真结果表明,该方案根据预测的链路负载情况,调度运行业务的资源占用,能够降低7.6%的业务阻塞率,但同时会造成1.0%的业务中断。"
346,网络入侵检测中的机器学习方法与应用,"上世纪末以来,我国的互联网产业发展迅猛,全国网民数量逼近惊人的9亿人。然而,随之带来的网络安全问题也层出不穷。病毒软件损害计算机系统、木马后门篡改主机、垃圾广告和邮件充斥在网络邮箱、分布在全球各地的DDos攻击更是数不胜数。小至个人,大至国家,网络安全问题都是迫切需要解决的问题。在20世纪90年代开始兴起的网络入侵检测技术,近年来成为抵御网络入侵的重要手段,各种规模的NIDS网络入侵检测系统广泛应用于企业和政府中。然而,现有的NIDS却普遍存在误报漏报率高、缺乏准确定位和处理机制、性能普遍不足等问题。近年来兴起的机器学习热潮,为更多传统行业,尤其是互联网行业带来了新的生机,机器学习被探索和应用到更多领域中。基于此研究背景,本文提出在网络入侵检测各个环节中加入机器学习算法的可能性,具体研究内容包括以下三个方面:(1)针对网络入侵检测中数据维度高、处理难度大的问题,将机器学习中的特征工程运用到网络入侵检测的事件采集环节,减少入侵检测数据维度,实验对比各类特征选择方法的特征子集。(2)针对事件检测采用固定规则匹配的现状,在事件分析阶段加入部分经典机器学习分类方法,与特征工程得出的特征子集相结合,实验分析不同特征子集和分类方法在降低运行时间和保证一定范围内检测率方面的效果。(3)对于网络入侵检测误报率高的问题,在事件处理阶段采用聚类方法进行消除误报,实验论证聚类方法在误报消除方面的有效性。综上所述,本文的研究目的是探索将典型的机器学习方法应用在网络入侵检测中的有效性和可行性。研究围绕网络入侵检测的事件采集、事件分析、事件响应三个阶段来展开,依次对应机器学习中的预处理和特征工程、分类方法和聚类方法,每个环节中通过仿真实验来论证所采用方法的效果,为实际应用提供了有益参考。"
347,基于强化学习的虚拟网络映射问题的研究与实现,"网络虚拟化技术可以将底层的物理资源抽象为多个虚拟网络,实现多租户对物理资源的共享。不同的租户对虚拟化的网络提出个性化需求,包括节点需求和链路需求等,因此产生了虚拟网络请求。基于对底层物理网络的虚拟化,可以实现将虚拟网络请求映射到物理网络中,这就是虚拟网络映射技术。目前虚拟网络映射技术多采用启发式算法,手工定制一系列的规则和假设,实验结果也不能令人信服。本文提出两种基于强化学习的虚拟网络映射的算法:基于谱理论的强化学习虚拟网络映射算法(A Reinforcement Learning Based on Spectral Method for Virtual Network Embedding,SR-VNE)和基于矩阵摄动的强化学习虚拟网络映射算法(A Reinforcement Learning Based on Matrix Perturbation for Virtual Network Embedding,PR-VNE)。本文的创新点可以归纳为以下三点:(1)传统的物理网络的节点信息使用属性矩阵表示,链路信息使用邻接矩阵表示,但是这两种表示方式不完整并且包含噪音。SR-VNE算法采用物理网络使用谱分析的方式,将属性矩阵和邻接矩阵协同考虑,得到一个能代表物理网络的健壮的共识矩阵。(2)每个虚拟网络请求映射完成以后,物理网络都会发生变化,因此该物理网络特征是高频动态变化的。PR-VNE算法采用矩阵摄动理论捕捉连续时间节点物理网络的变化,完成一种高效的物理网络的特征表示的更新方法。(3)SR-VNE算法和PR-VNE算法使用强化学习的方式对虚拟网络映射模型进行训练,强化学习代理能有效发现物理网络表示和虚拟网络请求之间的关系,从而完成高效的虚拟网络映射算法。根据我们现有的知识,我们SR-VNE算法和PR-VNE算法是第一个将谱分析,矩阵摄动的理论应用到虚拟网络映射中的算法,是能高效地将强化学习应用到虚拟网络映射中的算法。为了验证SR-VNE算法和PR-VNE算法的效果,我们将SR-VNE算法和PR-VNE算法算法与其他三种常用虚拟网络映射算法进行比较,得到结果表明,本文提出的两种算法相比其他三种常用虚拟网络映射算法能在长期平均收益、长期收益消耗比和接受率三个评价指标中得到更优的结果。"
348,基于深度学习的JavaScript恶意代码检测技术研究与实现,"JavaScript(JS)是网络开发中最为广泛应用的脚本语言,也是最常被攻击者利用的语言之一,这使恶意JS代码检测成为了安全领域的热点问题。近年来,机器学习在多个领域取得了令人瞩目的进展,研究者提出了一些基于机器学习的恶意JS代码检测方法。然而,这些方法通常将JS视作一种自然语言而非程序语言,并应用自然语言处理的模型和方法进行研究。虽然自然语言和程序语言存在相似之处,但这些方法忽略了程序语言独有的语法信息和语义信息。本文提出了一个恶意JS代码检测模型JSAC。JSAC模型结合了深度学习技术和程序分析方法以分析JS程序中的语法和语义信息,并依据这两类信息对程序进行恶意性检测。具体来说,对于一个JS程序,JSAC模型生成出它的抽象语法树(Abstract Syntax tree,AST)和控制流图(Control Flow Graph,CFG);再将AST中的结点和CFG中的指令转换为向量表示;接着JSAC模型将这两类向量分别送入基于树结构的卷积神经网络模型和基于图结构的卷积神经网络模型,从中提取语法特征和语义特征;最后,提取出的两类特征向量被合并到一起以用作分类检测。本文在包含有69523个有效JS文件的数据集上进行了充分的实验和评估,结果显示JSAC模型取得了比目前己有的4个机器学习模型更好的效果,包括98.71%的准确率、98.83%的精确率、98.64%的召回率和98.73%的F1分数。评估结果还证明了在分类检测过程中语法特征和语义特征各自的贡献。"
349,基于Spark和PU-learning的分布式机器学习平台的研究与实现,"近年来,随着互联网技术的发展,企业数据总量正逐年增多,在企业内被当做资源核心和财富。为了挖掘数据蕴藏着的潜在价值,机器学习将继续扮演着重要的核心作用。在工业界,大型企业一般会构建分布式机器学习平台,提供更高效的机器学习服务能力。然而目前的分布式机器学习平台还存在着以下问题:1)目前工业界对外服务的商用分布式机器学习平台构建在企业内部的特定的集群环境中且难以对外部署,因此对于数据的保密安全等级要求比较高的国家卫健委等国家级组织和企业来说,将数据放在此类商用平台上进行分析时候存在顾虑,需要一个可以部署在这些国家级组织和企业的内部环境中的机器学习平台。2)在算法层面,卫健委的人口资源数据中存在着的大量未标记的数据,例如在孕前优生数据中,由于需要“随访”才能确定新生儿是否患有缺陷疾病且大量的人群未“随访”,这些未标记人群中存在沉默的患病潜在人群。这正是致力于利用未标记数据的基于正例样本和无标记样本的PU学习算法(Positive and Unlabeled Learning,简称PU-learning,是一种半监督学习算法)所解决的问题,然而目前PU学习算法只有单机版的实现,阻碍了平台对这类数据的分析处理。针对以上问题和需求,本论文对分布式机器学习平台及其相关技术进行深入研究,本论文的主要贡献如下:1)通过对PU学习算法的研究现状和Spark技术框架的深入研究,设计并实现了一种基于Spark的PU学习算法(puSpark),它能高效地处理大规模数据;2)研究并实现了一种PU学习算法扩展框架(igBBPu),进一步提高基于Spark的分布式PU学习算法的准确度,它主要融合Bagging和Boosting技术,并使用基于互信息的权重更新的Wrapper策略做算法优化;3)研究并实现了一个分布式机器学习平台,可以提供完整的一站式算法构建服务,并且平台基于开源的分布式计算框架Spark构建,可以部署在卫健委内部集群之上,有利于更好地保障数据的安全。它主要由资源管理模块、算法实现模块、日志审计模块三大模块组成,并内置了本论文提出并实现的算法和其他基本机器学习算法。基于它,我们可以在前端拖拽式合成不同的机器学习任务流程,实现机器学习算法的模型构建和结果的查询与分析。"
350,基于机器学习与启发式算法的物流调度研究,"近年来,随着人们生活水平的提高,线上购物已经成为人们生活中不可缺少的一部分。电子商务的飞速发展为快递行业带来了前所未有的机遇,但是双十一陡增的巨额订单量容易导致快递爆仓,也极大地超过了物流系统的运载能力,而且短期内巨大的工作量给公司和配送员也带来极大的压力,缓慢的配送也为用户带来较差的服务体验。本文利用机器学习对电商平台用户的操作数据进行分析建模,拟定对预测购买的用户进行提前发货的策略,合理降低运输及配送高峰。本文的工作从以下几个方面展开:(1)对原始数据进行分析,构建样本特征,针对部分样本特征信息量少容易导致模型过拟合问题,设计基于Pearson相关系数与PCA的特征选择法,利用该算法进行特征选择,保留数据中的核心信息,并针对本文中数据的样本不均衡性提出了集成学习方式的解决方案。(2)对已经构建样本数据采用机器学习中的支持向量机、GBDT、逻辑回归等基本学习方法进行拟合,设计了基于Bagging的混合模型,提高购买预测的准确率和模型的泛化能力,并对用户的购买情况进行预测。(3)利用电商平台的储存的用户地理数据,建立物流配送模型,实现对购买用户的提前发货策略。针对经典物流配送模型考虑目标和约束条件不够全面,在实际应用中存在一定的缺陷的问题,笔者在经典模型的基础上构建了考虑时间窗和油耗的取送一体化的物流配送路径优化模型,并设计了一种基于k-medoids动态聚类混合拓扑结构的粒子群算法,解决了经典粒子群算法在求解此类模型时易陷入局部最优解的问题。仿真结果表明,改进型粒子群算法能很好地跳出局部最优解,并快速收敛于全局最优解,可有效求解物流配送路径优化问题。"
351,机器学习在电磁炮系统效能评估中的应用研究,"武器装备的效能评估对装备的发展有至关重要的作用,高射武器是末端防空力量和现代战争的重要组成,电磁炮是新型高射武器系统的研发重点,因此对电磁炮系统进行效能评估是很有必要的。本文对电磁炮效能评估的研究主要分三个部分。首先研究的是电磁炮综合效能指标体系的构建,并对5个综合指标值的求解方法和思路进行了研究。然后研究的是与毁伤相关的命中效能,基于“某型电磁炮方案论证”项目,对电磁炮的命中概率计算相关的目标确定、诸元求解、误差分析等问题进行研究,并用MATLAB编写了电磁炮命中概率计算程序,给出了计算示例,与普通高炮的命中概率进行了对比。最后采用自适应粒子群和支持向量回归机、BP神经网络相结合的机器学习方法,对电磁炮的综合效能进行了研究。机器学习是当前大数据时代和人工智能时代的关键技术,效能评估技术需要紧跟时代的步伐,推陈出新,进行评估方法的创新研究。本文结合自适应粒子群算法的寻优特性,对支持向量机回归模型和BP神经网络进行调参优化,建立新的机器学习模型,作为电磁炮系统综合效能的评估模型,并对电磁炮系统的综合效能进行评估和分析。本文还对效能评估和机器学习的基础理论进行了较为系统的研究,并且介绍了后面机器学习所用数据的来源。数据是机器学习的基础,从数据中学习规律,确定模型的待定参数,从而得到模型用于评估分析。本文由某仿真系统,得到电磁炮的服务概率和毁歼概率主要数据,再结合WSEIAC的经典评估模型ADC法,求得电磁炮的综合效能,作为机器学习训练用到的完整数据集,用来进行监督学习。最后是模型的程序实现。本文采用当下人工智能领域应用最广的语言Python,编写了评估模型的主程序和特征工程的数据处理程序,导入数据并进行训练。并编写了机器学习性能度量指标的求解函数和评估结果的图像输出,用于更直观的观察模型对电磁炮综合效能评估的结果和模型的性能好坏。"
352,机器学习在客户用电行为分析中的应用研究,"随着我国人工智能领域研究的不断深入,机器学习算法作为其重要的研究内容之一,得到了快速的发展。其中异常点检测算法作为机器学习算法中的重要研究分支,具有良好的研究价值。本文基于电力公司真实客户用电数据,利用异常点检测算法分析客户用电行为,进行客户用电异常行为检测,识别异常用电客户。主要研究工作如下:1.总结电力检测从业人员相关工作经验,根据客户原始用电数据,提出一套异常用电评价指标体系,并将其应用于原始数据预处理阶段的特征构建中,验证该体系的实际应用价值。2.整理六类异常点检测算法,并从中选择具有广泛应用前景的三类算法,通过实验对比分析其算法性能,进一步选择性能较优的IF算法进行研究。研究实验表明IF算法依然存在无法识别局部异常点的缺点,故针对IF基于隔离的算法思想结合K-Means聚类算法提出CBIF算法,将异常点统一转换为可以有效识别的全局异常点,进而提升算法精度。3.利用CBIF算法设计客户异常用电行为检测模型,并将其应用于真实客户用电数据中,识别异常用电行为客户。通过实验证明该模型可以更加高效、精确的识别异常用电行为客户,并可以为其它异常点检测应用领域提供借鉴。"
353,储粮害虫图像定位识别算法的研究与实现,"我国每年的储粮损失约为3500万吨,因虫害造成的损失占总损失的5%,造成经济损失巨大。有研究表明,大部分害虫最早是在粮堆表层被发现的,因此及时掌握粮食表层害虫发生发展情况对害虫预警和防治具有重要意义。目前,我国大部分粮库使用粘虫板对粮面害虫进行诱捕并人工统计和识别。但是这种人工识别统计的方式人力成本高、信息获取时效性差且人为影响大。因此行业急需用智能化手段解决粘虫板上害虫计数和识别的难题。本文以粘虫板诱捕的6类主要储粮害虫的定位和识别为目标,开展了如下的研究和实现工作:1.建立了国内储粮行业首个6类主要储粮害虫粘虫板图像数据集,其中包括目标定位图像数据集20,827张和图像恢复分类成对数据集8,134张,分别用于目标定位网络和低分辨率图像恢复分类网络的训练和测试。2.提出了一种基于SSD的储粮害虫图像目标定位网络,实现了对六类害虫粘虫板图像的目标定位和分类识别。针对粘虫板图像的类与类之间相似度高、相机和粘虫板位置固定、定位与分类无关的特点,改进了 SSD的目标框回归策略、损失函数、特征提取网络结构等,测试结果表明改进后的SSD提高了害虫定位的有效性,定位mAP达到91.31%。3.针对六类害虫图像分类识别任务基于生成对抗网络提出了一种低分辨率图像恢复分类网络,在目标定位单头害虫图像测试集上进行分类识别测试,图像分类识别平均F1值为87.3%。4.基于线性支持向量机,实现了对目标定位网络和低分辨率图像恢复分类网络的两种分类识别结果的融合算法,分类识别F1值为95.22%,与目标定位网络的分类识别结果相比提升12.95%,与恢复分类识别结果相比提升7.86%。5.为了解决识别算法在实际应用时客户端与算法的运行环境不同和粮库服务器资源较少的问题,基于本文提出的储粮害虫粘虫板图像目标定位网络和低分辨率图像恢复分类网络,设计并实现了一种算法部署方案,其中包含一套算法服务系统和一套储粮害虫图像识别客户端软件。目前,算法服务系统已为全国11个粮库提供算法支持,通过储粮害虫图像识别系统可帮助保管员尽早发现仓内害虫并进行科学杀虫,本系统可以平均减少单仓熏蒸药量10%左右,平均节省单仓人工130人时/年,提升了我国粮库害虫智能化识别的水平。"
354,基于机器学习的平面足迹起脚特征研究,"在我国公安刑事技术工作中,由于足迹特征表述模糊、成因复杂、机理不明,足迹检验在长期以来始终过度依赖足迹学专家的主观经验,各种足迹检验技术,尤其是足迹步态特征检验技术的现代化发展进程缓慢。为了适应新时代公安刑事侦查工作的需要,提高公安刑事侦查工作效率,同时也为了继承发展传统的足迹步态特征检验理论,本文主要关注平面足迹步态特征中的起脚特征,将模式识别领域的相关技术方法应用于足迹步态特征检验领域,取得了较好的效果。本项研究召集约320名志愿者采集到6000多张平面足迹图片,其中约一半图片足趾区域出现了“月牙状”的痕迹。对这一“月牙状”痕迹分两步进行了检测:首先使用了三种方法进行该平面足迹起脚特征的存在性检测。一是使用了一个6层小型卷积神经网络对其进行检测,测试正确率可以达到约97.0%;二是使用了VGG-16经典卷积神经网络,测试正确率约为84.8%;三是提取Haar-like特征后使用Adaboost分类器对其进行检测,测试正确率约为84.3%。可得,小型卷积神经网络在平面足迹起脚特征的存在性检测中效果最佳。其次是根据这一“月牙状”痕迹与整个足迹的相对位置关系来对其进行方向性检测,主要分为偏内起脚和正起脚两类。该步同样使用了三种方法进行效果对比。一是提取GIST特征后使用支持向量机(Support Vector Machine,SVM)进行检测,左右脚的测试正确率分别约为85.4%和81.1%;二是提取HOG特征(Histograms of Oriented Gradients,HOG)后使用SVM进行检测,左右脚的测试正确率分别约为80.7%和76.3%;三是提取Haar-like特征后使用Adaboost分类器进行检测,左右脚的测试正确率分别为72.7%和80.4%。可得,提取GIST特征后使用SVM进行平面足迹起脚特征的方向性检测效果最佳。最后,对平面足迹起脚特征的方向与足迹遗留人起脚时的动作姿态之间的关系进行了探究。截取志愿者身后摄像机所录下的其起脚瞬间的一帧图像,并对其小腿和足之间的夹角进行测量,得出如下结论:绝大部分在第二步中被研判为偏外起脚的志愿者,其起脚瞬间的腿足夹角要小于正起脚的志愿者。本研究证明使用模式识别相关技术来开展平面足迹步态特征的自动化检验是具有可行性的,为后续利用平面足迹步态特征进行足迹分析和人身鉴别打下了良好基础。"
355,基于安卓APP内容动态采集方法的P2P网贷风险分析系统的设计与实现,"改革开放实施以来,我国经济飞速发展,民间借贷走上了互联网的舞台,形成了新的借贷方式--P2P网络借贷。在传统金融领域,出借资金的一方是贷款机构,这时债权方是贷款机构,平台通过贷款利息盈利,承担贷款风险,而在P2P网贷行业,这种情况发生了改变,出借资金的一方变成了个体,此时出借人成为债权方、承担主要交易风险,平台则通过抽取交易提成获得利益,盈利方式的改变促使平台将重心从交易风险控制转移为促成更多额交易,导致贷款门槛降低,已经造成了许多的社会问题,为维护出借人的切实利益、控制网贷交易风险、保障网贷交易安全,需要对网贷交易中存在的风险进行分析。本文从第三方的角度出发,对网贷交易中存在的信用风险进行了详细的分析,并实现了网贷风险分析系统,详细工作如下:1)为了有效分析网贷交易风险,需要获取真实全面的交易数据,而近年来,随着移动网民数量的提升,移动端成为了网贷平台的主要市场,同一笔贷款交易平台会在移动端公布更多信息,针对这一现象,本文提出了一种安卓APP内容动态采集方法,从移动端着手进行了研究数据的获取工作。2)针对网贷交易中存在的信用风险问题,需要对网贷交易数据进行详细分析、探索违约贷款和非违约贷款之间的差异,本文首先利用相关性检验研究了数据特征之间的关系,发现借款金额和借款人信息额度、月负债金额之间高度相关,本文还利用非参数检验分析了违约贷款和正常贷款交易之间的差异,发现两种样本在借款金额、公司规模、历史逾期次数、还款周期、借款失败次数、利率之间存在显著差异。此外,通过观察实验数据,本文发现在贷款交易中违约贷款占比极小,只有3%。3)本文在上述研究基础上,针对贷款交易中存在的数据极度不平衡现象,通过使用欠采样方法适当的减少了大类样本在训练集合中的占比,达到了平衡数据集的目的,随后本文使用了在不平衡数据上表现良好的随机森林算法构建了网贷风险评估模型,该模型通过预测贷款交易中借款人的违约概率来评估交易风险的高低,违约概率越高则说明交易风险越高。相较于已有文献,结合使用欠采样和集成学习方法后,模型效果明显提升。最后,本文设计并实现了P2P网贷风险分析系统,以微服务的理念实现了网贷风险评估模型的应用落地。"
356,区块链应用系统若干脆弱性分析与评测,"随着区块链技术的飞速发展,从金融到供应链,从版权保护到物联网,区块链逐渐渗透到各行各业。与此同时,区块链自身的安全问题也越来越引起人们的重视,区块链相关安全事故频发,给用户带来极大的经济损失,更体现出了安全的重要性。区块链具有去中心化、不可篡改、匿名性三大特性,由于其利用了公钥签名、哈希算法、梅克尔树等密码学技术,使得区块链一直被认为是安全高效的电子货币。然而事实证明,只要是人类编写的程序,比如区块链客户端、钱包应用、交易所等,难免出现各种各样的被黑客利用的漏洞。例如2015年比特币主程序爆出整数溢出漏洞,造出天价比特币,导致比特币区块回滚;2016年以太坊“The Dao”事件中,黑客利用智能合约的重入攻击漏洞盗走价值六千万美元的以太币,并导致以太坊硬分叉;各大交易所持续不断被黑客入侵,盗走巨额电子货币的事件屡见不鲜。本论文正是基于这样一个背景,研究针对区块链的攻击方法和防御技术,揭露区块链相关系统的脆弱性事实,主要是终端安全、Web交易所安全和智能合约安全,并提出相应的防御技术。本论文研究成果与创新点主要包括:1、本论文通过三个真实案例详细分析了区块链系统的脆弱性和攻击方式。第一个案例是对一款比特币钱包应用(APP,Application)的木马分析,第二个案例是对一个在线运营中的电子货币交易所的Web安全分析,第三个案例是对一款以太坊分布式应用(DAPP,Distributed Application)的安全分析。本论文运用软件逆向、渗透测试、机器学习等方式对这些应用的脆弱性进行分析,并提出相应的利用方式或防护方法。2、本论文针对区块链智能合约的特性提出了对Solidity进行代码审计的防御方案。本论文详细分析了基于以太坊虚拟机(EVM,Etheruem Virtual Machine)的编程语言Solidity的现存漏洞,如重入攻击、整数溢出、变量覆盖、蜜罐合约、拒绝服务等。研究其形成原理、利用方式和危害,大部分漏洞都列出了示例代码和攻击步骤,所有代码均经过测试和验证。由于区块链无中心、不可篡改的特性,部署在区块链上的智能合约一旦出现安全问题,很难通过升级、打补丁等措施来补救。目前比较有效的防护方案是在合约部署前对源代码进行安全审计。本论文深入学习和研究了基于EVM的开源代码审计工具Oyente,然后对其进行了功能扩展,使其支持更多的漏洞类型检测,包括对“变量覆盖”、“隐藏源代码”、“孤立代码块”、“危险函数调用”四种类型的检测。"
357,汽车螺栓打紧质量大数据分析,"汽车生产制造需要大量使用螺栓连接,其连接质量直接影响产品性能。随着工业物联网的迅速普及,具有监测功能的打紧设备在企业中广泛应用。打紧工艺过程涉及扭矩、转角、时间等多类型海量数据,利用大数据分析方法,结合企业螺栓打紧工艺对原始数据进行数据挖掘,建立异常检测模型,实现对潜在异常的模式识别,为企业提供准确的质量管理决策。本文从企业生产实际出发,分析了螺栓打紧的主要控制方法及理论,对螺栓打紧工艺过程及历经阶段进行研究,分析了目前企业应用自动打紧设备的质量控制技术,指出存在的质量评价缺陷。通过对螺栓打紧工艺原始数据特性的分析,总结了数据集存在的几方面问题,针对螺栓打紧数据不均衡特点,在SMOTE算法的基础上进行改进,并通过实验验证改进SMOTE算法的有效性。在对打紧技术分析的基础上,运用了大数据运算框架,完成对原始数据的预处理工作,进一步地提取螺栓打紧工艺直接特征与间接特征。针对螺栓打紧业务特点,基于CART决策树建立异常检测模型对螺栓打紧工艺的特征信息进行数据挖掘,诊断打紧质量,结合网格搜索和交叉验证寻找树深、基尼不纯度阈值参数的全局最优解,提高了模型的泛化能力和诊断精度。利用学习曲线和ROC曲线下面积AUC值对模型性能进行了评价,并对模型树进行了可视化解释。在此基础上,基于KMeans聚类分析打紧过程异常原因及异常模式识别分类,使用“手肘法”确定最优的聚类个数,综合螺栓打紧工艺对打紧过程异常情况进行了分类识别。最后,通过实验,从加速比、可扩展性、规模增长性3方面衡量了Spark平台中并行化聚类算法的运行性能。"
358,基于预测信息的风电场集群调频控制策略,"风力发电是技术最为成熟的可再生能源发电技术之一,也是世界各国能源政策优先发展的方向。随着风电并网规模的增加,风电出力的随机性和波动性给电网的调度和稳定运行带来的负面影响也越来越大,主要体现在发电量与负荷的不平衡导致系统频率的稳定性下降,引发风机大规模脱网事故。为了让风电集群能够对电网提供必要的频率支撑,本文以集中式的风电场集群为研究对象,对风电场集群的有功功率波动特性、风电超短期预测以及风电场集群参与调频的控制策略进行了研究。本文首先通过实测数据分析了风电场集群在时间尺度和空间尺度的波动特性,目的是为了挖掘风电场集群出力波动的规律,从而为降低风电波动给电网带来的影响提供解决思路和方法;分析了大规模风电对系统频率的影响,并讨论了风电预测在解决风电集群调频可能的作用。其次,针对风电预测误差较大的问题,提出了一种基于机器学习算法的混合预测模型。该模型通过改进的模态经验分解和小波分解作为预处理阶段的主要算法用来降低风电功率序列的非平稳性。在预测阶段同时引入了神经网络、极限学习机和最小二乘支持向量机对分解后的序列进行预测。同时,采用了基于粒子群优化的自适应神经网络模型对三种智能预测算法的误差分布进行学习并校正,提高了模型的预测精度和泛化性能。通过实测风电场数据进行了算例分析,验证了所提混合智能算法的精确性和优越性。最后,为了发挥风电场集群在参与系统调频中具有的优势,提出了基于预测信息的风电集群调频控制策略。该策略通过建立风电集群控制中心对各个风电场进行统一管理,并依据预测信息合理调节各个风电场的调频参与深度。在风电集群层面通过各个风电场的预测信息实现风电场的运行模式控制和参考指令分配;在风电场层面,通过预测信息对风电场的调差系数进行调整,实现动态调节风电场调频参与深度。为了证明本文所提调频控制策略的有效性,在MATLAB中建立仿真模型进行了验证。结果表明:本文所提出的基于预测信息的风电集群调频控制策略可充分利用风电场的预测信息优化各个风电场的发电量和调频参与深度。"
359,10kV环网柜机械特性在线监测与绝缘状态诊断的研究,"环网柜是配电网中重要的电气开关设备,负责调节配电网线路的连接方式,保障供电安全。在环网柜运行中,可能会出现机械、绝缘等方面的故障,进而影响配电网的正常工作状态。为了更好地监测环网柜的工作状态,有必要研究先进的技术方法对环网柜的机械特性和绝缘状态等方面进行监测。本课题针对环网柜的机械特性和绝缘状态,研究对象为北京双杰电气公司生产的XGN-12型空气绝缘环网柜。分别搭建了机械特性试验平台与放电声音信号试验平台,并设计出了基于LabVIEW的数据采集系统,对环网柜机械特性参数、内部绝缘子器件放电声音信号进行采集、保存和处理;通过机械特性试验平台,采集分合闸过程加速度信号、位移信号、永磁线圈电流以及断口信号。在绝缘状态试验中,利用试验变压器产生不同等级的电压值。在干燥或者潮湿的环境下,使环网柜中的绝缘子发生放电,并采集放电可见声信号。在机械特性的分析中,针对分、合闸过程的加速度信号,首先通过低通滤波器预处理消除干扰,然后利用小波模极大值法,分解加速度信号得到5、6层高频分量,在高频分量中寻找信号的突变点,作为开关分、合闸的完成时刻,即断口跳变时刻。计算分合闸时间,配合位移传感器求取行程、超程、平均分闸速度、平均合闸速度等机械特性参数。通过小波分析提取了分合闸断口的时刻,解决了环网柜在线运行断口信号难以获取的问题。通过分析环网柜内绝缘子的放电声音信号检测环网柜的绝缘状态。使用短时能量法、自适应陷波器等手段进行预处理;然后通过小波包分析求取6kHz~18kHz的放电声音信号能量分布特征向量,利用Fisher线性降维准则,降维得到6维能量分布特征向量。最后分别使用高斯朴素贝叶斯分类器、单分类支持向量机这两种算法训练放电声音的能量分布特征,对比两种机器学习算法的辨识效果,使用单分类支持向量机对放电声音的能量特征向量辨识效果优于基于高斯朴素贝叶斯分类器的辨识效果。通过分析放电声音信号,能够满足低成本、复杂环境下的环网柜绝缘状态的定性分析。"
360,基于机器学习的癫痫及精神异常脑电信息识别研究,"癫痫和精神分裂症都是常见的脑部疾病,随着生活水平的提高,人们对该两类疾病的发病机理和治疗手段的关注日益增加。脑部疾病EEG(Electroencephalogram)信号处理和识别算法是实现生物电信号智慧医疗的重要手段,医生虽然可以结合先验知识及相关理论对脑电图进行主观判断,制定针对患者的医学治疗方法。但是,这种主观判断方法极易出错,并且效率不高。先进的信号处理技术、深度神经网络技术等为快速精准的智慧医疗提供了新方法和新手段,因此,采用先进的信号处理与机器学习技术,实现脑部疾病的自动检测、识别与诊断治疗具有重要意义。(1)提出了一种基于小波双谱能量熵和颜色矩的信号特征提取算法,用于癫痫信号处理和分类识别。针对脑电信号的特性(非平稳性、非线性、非高斯性等),将小波与双谱分析方法结合,发挥小波变换与高阶谱估计信号处理方法各自的优势,得到小波双谱理论。本文采用小波双谱能量熵和颜色矩的组合特征矢量[En,μ,ζ]作为癫痫脑电信号特征提取的方法,对癫痫信号进行了分类识别。结果显示该算法可以有效的区分癫痫发作期和发作间期的脑电信号,为接下来的自动识别工作做了充足准备。(2)提出了一种使用遗传算法对参数进行优化的双子支持向量机分类算法,通过遗传算法对双子支持向量机进行优化,可以高效的确定惩罚参数和高斯核函数参数,得出最优模型。结果表明新算法将癫痫临床脑电信号的敏感性提高至92.40%,总识别率提高至94.47%,且特异性为84.74%,AUC(Area Under Curve)为96.308%,其中,单个病人的最高识别率则达到99.05%。该方法避免了因主观因素或判断标准的不同而产生诊断结果的偏差,较用于统一数据来源的机器学习方法的AUC提升了约1%,为实用医学中准确判断和预防癫痫疾病创造了坚实的基础。(3)针对精神分裂症患者的脑电信号,提出了基于改进的VGGNet的精神分裂症脑电自动识别算法,构建不同网络层数和不同卷积核大小的VGGNet网络对精神分裂症脑电信号进行自动识别,通过比较,最终选择分类准确率最高的网络模型:卷积核大小为5*5的13层VGG网络。使用该深度学习算法与本文第三、四章提出的新机器学习算法分别对精神分裂症脑电信号进行分类研究。实验结果显示,基于改进的VGG网络深度学习算法所得识别率为84.34%,优于新的机器学习算法,平均识别率为81.45%。综上所述,本文提出的算法均可以及时的发现脑部疾病的隐情,对有癫痫疾病或精神分裂症倾向的测试者进行积极干预,从而实现对脑部疾病EEG信号的自动识别,完成疾病的早期评估,进而实现针对脑部疾病的早预防、早发现、早治疗。脑部疾病的自动检测分析可以对测试者的神经模式进行区分,对具有特定类型脑部疾病数据进行有效分类,更加有效地管理疾病,提升疾病的诊疗水平。"
361,基于深度学习的短文本自动摘要方法研究,"随着新媒体平台的不断涌现,人们日常接触到的信息呈现爆炸式的增长,从而给人们带来信息过载的困扰,并且随着生活节奏的加快,人们无暇梳理接收到的所有信息。通过阅读摘要,人们能够提高理解原文的效率,有效减少浏览信息的时间和精力。随着深度学习的崛起,越来越多的研究者利用深度学习的方法生成文档的摘要,并逐步应用于实际系统中。因此,本文在深度学习基础上研究短文本的语义表示以及基于序列到序列架构的自动摘要方法,并将短文本的语义表示应用于自动摘要任务中。目前无监督的文本表示方法主要包括向量空间模型和doc2vec等。这类方法在语料库规模较大时能够取得很好的效果,却忽略了文本中的词序信息。针对这个问题,本文提出无监督模型RevONet,考虑词序特征,利用卷积神经网络学习文档的语义表示,并在文本分类任务中,与词频、词频逆文档频率、LDA、LSI、doc2vec等进行对比。实验结果表明,RevONet模型能够达到78.7%的准确率,优于向量空间模型和doc2vec等,验证了RevONet模型在语义表示上的有效性,并应用于自动摘要任务中,衡量源文本与目标摘要之间的语义相似性。根据文本摘要的特点,本文在序列到序列架构的基础上提出最大化文档相似度模型DocSNet。DocSNet模型利用RevONet模型提取的源文本语义表示,计算与目标摘要之间的相似性,通过最大化源文本与目标摘要之间的语义相似性优化模型,进一步生成摘要。对于序列到序列架构,DocSNet模型使用双向LSTM作为编码器,单向LSTM为解码器构建模型。不仅如此,DocSNet模型引入注意力机制,进一步提高生成摘要的质量。通过在哈尔滨工业大学发布的大规模中文短文本摘要数据集上的实验,DocSNet模型的ROUGE-1和ROUGE-L指标分别可以达到33.6%和30.4%验证了DocSNet模型的有效性。"
362,基于深度学习的恶意软件识别研究与实现,"随着互联网迅速发展,恶意软件在种类和数量上快速增长,病毒大量的变种使得基于固定特征的恶意软件检测变得越来越困难。恶意样本自动检测技术已经有较多的相关研究,但是目前基于静态检测的方法对于存在系统调用混淆的恶意样本存在局限性,现有的动态检测方法主要从动态调用序列的局部提取特征,并且检测结果的准确率有限。本文针对恶意软件动态行为分析,提出了冗余信息预处理算法,并在此基础上,设计实现了基于双向残差循环神经网络的模型,利用其处理时间序列数据的特性,直接对序列进行检测。本文还基于系统调用关联分析提出了一种新的序列特征提取方法,对序列中系统调用的依赖关系进行功能层面上的分析,提取特征,并使用随机森林进行检测。本文最后尝试了将两种方法进行整合,实验结果显示,两种方法均可有效检测恶意样本,而且整合之后,组合模型的AUC(Area Under the Curve of ROC)达到0.99。本文在现有开源系统的基础上,设计并实现了恶意软件智能检测系统,可以在局域网中自动拦截流量并捕获其中的文件,提交至系统检测,检测报告中包含了利用本文所提出的基于机器学习与深度学习的组合模型进行识别的结果。本文针对在实验过程中发现的问题,我们提出多种针对恶意软件分析系统的优化方法,包括基于生成对抗网络的恶意样本生成技术,针对恶意样本收集困难的问题,利用生成对抗网络,生成恶意软件样本,辅助模型训练;基于模型可解释性技术,提出了一种潜在恶意软件序列搜索算法,利用这种方法导出了在恶意样本分类中起到关键作用的特征模式,来帮助提高现有的恶意样本分析、取证技术。"
363,基于强化学习的文本情感分析算法研究,"随着互联网的普及,人们更频繁的参与到互联网中,同时产生了大量用户原创内容(User Generated Content,UGC)数据。随着计算机相关技术的发展,对于UGC数据的情感分类展现了较大的商业价值和学术价值。作为机器学习算法的一个重要分支,强化学习算法更好地模仿了人类的认知和学习过程,然而强化学习算法在分类任务中的研究较少。基于此背景,本文针对强化学习算法与文本情感分析任务进行研究。本文分析了多个UGC数据集,实现一套完整的文本预处理流程;调研并使用词向量和主题模型作为文本表示,以更好的抽取文本特征;充分利用人类的先验知识,构建情感因子词典并用于模型的训练和验证。本文提出了一个新的强化学习模型――WS-LSTM。通过模拟人类认知方式,将文本情感分析抽象为读入词语并获得情感波动的过程。通过构建动作选择层和动作评价层结构,将强化学习算法引入文本情感分类任务。通过构建状态层和全连接层,实现强化学习和有监督学习的统一。利用情感分析结果作为回报,实现模型参数的训练。本文在多个数据集上实验WS-LSTM并验证了其有效性。针对模型中词语的情感动作选择问题,本文改进了ε-贪心算法,引入情感因子使其更加适用。实验结果证明,该算法可以帮助模型选择符合先验知识的词语情感,进而实现模型效果的提升。针对词语级情感分析结果的评测问题,本文利用词语的情感强度,设计出一套新的词语级情感分析结果评价方案,并且使用模型的实验结果对该方案进行了有效性论证。通过该方案的使用,可以实现对词语级实验结果的效果论证。"
364,基于程序语义的软件缺陷预测技术研究与实现,"软件缺陷预测技术能够辅助开发者发现潜在的软件缺陷,并降低发现缺陷所需的开销。传统软件缺陷预测方法通常利用软件度量元信息(代码行数、控制流圈复杂度等)作为特征来构建机器学习模型,预测有缺陷的软件模块。然而这种方法的缺点在于软件度量元中不包含软件的语法结构信息和语义信息。本文提出了一种使用词嵌入和深度学习技术以学习程序语义信息,进而预测程序中缺陷的方法Seml(Semantic LSTM model)。本方法首先从源码的抽象语法树中按顺序抽取特定结点token,组成一个token序列,然后利用一个无监督训练得到的词嵌入模型,将每个token映射为一个定长的实值向量。在将每个样本的token序列转换为向量序列后,本方法利用训练集的向量序列和它们的标签(是否包含缺陷)来构建基于长短期记忆网络的缺陷预测模型。长短期记忆网络模型能够从序列中自动学习token的顺序关系,从而习得程序的语义信息。在PROMISE数据集的8个开源项目上进行的一系列实验表明,相比于现有的基于深度学习的缺陷预测方法以及目前先进的基于度量元的缺陷预测方法(DBN方法,tb-LSTM方法和ISDA方法),本文提出的方法在项目内和跨项目缺陷预测中均有更好的表现。具体来说,对于项目内缺陷预测,Seml比DBN方法、tb-LSTM方法和ISDA方法的平均F1值分别提高了2.1%,4.3%和9.6%;对于跨项目缺陷预测,Seml分别比上述三种方法的平均F1值提高了3.5%,0.8%和5.6%。此外,对本文token嵌入步骤的评估结果表明,利用词嵌入模型训练得到的token向量能够有效地对程序语义信息进行表示,因此本文的token嵌入步骤有助于Seml缺陷预测效果的提升。"
365,基于Stacking技术的入侵检测系统的设计与实现,"随着近年来互联网的迅猛发展,各种形式的网络攻击层出不穷,如何有效地检测异常行为及其攻击类别已成为网络安全领域的一项重要议题。针对现有入侵检测技术仍然存在准确率不达标、特征提取能力不足的缺陷,文本提出了一种基于Stacking技术的融合深度自编码器和传统机器学习优点的网络入侵检测系统。入侵检测系统的设计主要分五步。第一步,基于libpcap动态库获取需要的数据;第二步,对获取到的数据进行预处理;第三步,利用深度自编码器对数据进行新特征的提取;第四步,将深度自编码器捕获到的新特征与原有特征拼接,训练各个机器学习模型;最后,通过Stacking技术将多个机器学习模型结果融合并产生最终的输出。因此,主要工作如下:1.编写网络协议解析器。网络协议解析器主要用于捕获网络流量并将其解析成固定格式的数据。分析数据集中每个特征的含义,然后根据TCP/IP协议栈通过C++程序对蜜罐系统中数据链路层、网络层、传输层进行解析,最后对需要的特征进行统计。最终,本文得到了高质量的入侵检测数据。2.通过深度自编码器提取数据集的高阶特征。深度自编码器主要目的在于提取更高阶的非线性特征。利用一个2层的深度自编码器对高阶特征进行挖掘,然后与原有数据进行拼接。本文通过深度自编码器,扩展了数据特征,准确率提升了0.6%。因此通过深度自编码器可以提高模型准确率。3.基于Stacking融合模型。Stacking主要用于提升模型的稳定性和准确率。本文选择了一个随机森林模型、两组不同参数设置的LightGBM模型作为Stacking的第一层模型,选择逻辑回归作为第二层的模型,构建起一个2层的Stacking框架。同时,针对数据不均衡的特点,选择宏F1作为模型训练的评估标准。Stacking后的模型较单模型准确率提升了 1.1%,因此恰当的Stacking可以提升模型准确率。本文以入侵检测系统的标准数据集KDD99数据集作为实验数据,用于实验结果分析及与现有入侵检测技术比较性能。实验结果显示,本文所提出的模型准确率达到了 95.8%。因此,本文所设计的基于Stacking技术的入侵检测系统能够有效地检测网络入侵行为。"
366,基于机器学习的威胁情报可信分析系统的研究,"近些年来,随着信息技术的飞速进步与发展,网络安全技术不断演化,无论是以5G通讯,物联网等新型网络形式的出现,还是以在线社交网络等为代表的新型服务模式的出现,都不断呈现出开放性、异构性、移动性和可信性的特点,这些服务方便了人们的生活,但是由于网络的匿名性,人们同时也遭受着非法网络渗透等带来的巨大损失和伤害。针对日益庞大的网络用户的情报数据,如何对这些情报进行合理的分析和研究将成为新时代下社会信任体系与主动安全防御的重中之重。现今的互联网环境下,人们对用户实体的情报数据的主要来源是开放的网络环境,但是网络环境中的情报数据具有数据质量低,同时具有数据规模大,关联关系复杂等特点,如何有效的对这些情报数据进行高效并且合理的研究与利用,是解决网络空间环境下,对网络实体的情报进行可信评估的关键。因此,本文主要针对开放的网络环境中的情报数据的可信评估问题进行研究,主要的工作任务如下:(1)针对大规模网络环境下,情报数据规模大、关联关系复杂的特点,本文提出了―种基于知识抽取和融合算法的海量数据知识图谱构建的方法,以此来作为海量情报数据存储的主要形式。该方法利用网络空间中情报数据的结构化和非结构化特性,对原始的情报数据进行实体、属性和关系的抽取;考虑抽取得到的实体、属性和关系信息之间存在重复、别名问题,再利用知识融合的技术对抽取得到的实体、属性和关系进行加工、整合、消除歧义,得到―系列基于事实表达的情报知识图谱。(2)针对网络环境中用户情报数据中质量低和虚假数据的问题,本文提出了―种基于知识表示和神经网络算法的情报数据的可信评估模型。该模型在情报知识图谱的数据存储形式上,利用知识表示TransE(Translating Embeddings)算法将情报知识图谱中的实体、属性和关系等节点信息映射到连续的低维向量空间,在这个过程中,为了计算具有多级链接关系的两个节点之间的聚合关系,本文提出―种基于循环神经网络(Recurrent Neural Network,RNN)的链接关系聚合算法来计算得到两个节点之间单条路径的聚合链接关系,然后通过路径可靠性算法(Path Reliability Measuring Algorithm,PRM)对两节点之间存在的多条关系路径进行链接关系的加权计算,实验结果表明,基于上述的情报可信评估模型,在开源的大规模知识库Freebase数据集上,当训练集数量达到300000时,准确度达到了91.67%;并且在基于RNN的链接关系聚合算法下,与传统的基于四则运算的算法进行对比发现,随着训练集规模的增大,RNN的性能优势远远大于基于传统的四则运算算法。(3)针对现实网络环境中的用户可信评估的需求,本文基于开放的网络环境,设计并且实现了―套面向人物的情报可信分析系统。该系统分为情报数据采集与解析模块、情报知识图谱构建模块、情报可信分析模块以及情报数据可视化模块。其中情报数据采集模块利用网络爬虫从网络中获取人物情报数据并进行初步的解析;情报知识图谱构建模块利用获取到的经过初步解析的情报数据,利用知识图谱的构建方法,构建高质量的情报知识图谱;情报可信分析模块将利用上述路径聚合算法和路径可靠性算法对情报进行可信关系的可信评估;最后,系统提供可视化平台对构建的用户情报知识图谱以及可信分析的结果进行可视化展示。"
367,基于机器学习的蛋白质亚线粒体定位预测研究,"在大数据时代,蛋白质数据库中序列数据的指数增长蕴含着非常重要的生物学信息。如何使用机器学习精准预测蛋白质亚线粒体的位置已成为生物信息学以及蛋白质组学研究中一项具有挑战性的任务。而且,亚线粒体位置的研究对了解蛋白质的结构和功能发挥重要的作用,同时对生命体进化和疾病发生机理都具有长远的研究意义。本文基于机器学习方法系统地蛋白质亚线粒体位置进行相关研究,主要研究成果如下:1.提出PseAAC-PsePSSM-WD的蛋白质亚线粒体定位预测新方法。首先,将伪氨基酸组成(pseudo-amino acid composition,PseAAC)和伪位置特异性得分矩阵(pseudo-position specific scoring matrix,PsePSSM)融合对亚线粒体蛋白质序列进行特征提取。其次,运用二维小波降噪(wavelet denoising,WD)处理提取的特征向量。最后,将降噪后的最佳特征向量采用支持向量机(support vector machine,SVM)预测蛋白质亚线粒体的位置。运用jackknife检验并和其它预测方法进行比较。结果表明,本文方法显著优于现有研究成果,可为其它的蛋白质亚细胞器定位预测提供一种新方法。2.提出SubMito-XGBoost的蛋白质亚线粒体定位预测新方法。首先,融合g-间隔二肽组分(g-gap deptide composition,g-Gap DC)、PseAAC、自相关函数(auto-correlation function,ACF)和二元特征位置特异性得分矩阵(Bi-gram position specific scoring matrix,Bi-gram PSSM)四种特征提取方法对蛋白质序列进行特征提取。其次,由于基准数据集M317、M983和M495样本不平衡,运用合成少数类过采样技术(synthetic minority oversampling technique,SMOTE)处理三个数据集,再结合ReliefF算法将高维的特征向量降维。最后,运用极限梯度提升机(eXtreme gradient boosting,XGBoost)对最佳的特征向量分类预测蛋白质亚线粒体的位置。运用jackknife检验,同时和现有的预测模型进行比较。结果表明,本文提出SubMito-XGBoost方法的预测结果显著优于现有研究成果,可为其它亚结构定位预测提供一种新工具。"
368,复杂环境下车牌自动识别系统的研究及实现,"随着大数据技术的成熟以及人工智能技术的蓬勃发展,智慧交通逐渐成为相关技术的重要落地点。通过智慧交通技术,可以使道路网络达到更高的运行效率,既节省了人们的时间,又减少了资源的消耗。城市监控系统的应用,使得公安机关能够更快的追踪到车辆与行人,从而使我们的生活变得更加的安全。车牌是车辆的唯一标识物,因此车牌自动识别技术是智慧交通的支撑性技术,有着非常重要的应用价值。本文研究并实现了一个车牌自动识别系统,该系统由车牌定位模块、字符分割模块、字符识别模块和免分割车牌识别模块四个部分组成。本文第一章对车牌自动识别系统的背景信息及研究意义进行了分析。第二章对涉及到的相关理论和车牌自动识别技术的发展情况进行了介绍。第三章介绍了本文所采用的车牌识别各个阶段的算法方案,并将本文采用的方法与其他主流方法进行了实验对比。第四章描述了车牌自动识别系统的需求分析、概要设计与详细设计,该系统在公平的数据集下达到了符合预期的表现。最后在第五章中对本文工作进行了总结归纳,并对后续工作进行了展望。本文的主要工作与创新之处总结如下:1.对车牌自动识别技术的发展现状做了全面深入的调研与总结概括,将其分为车牌定位、字符分割、字符识别、免分割车牌识别四个阶段。明确了每个阶段的主流方法以及它们的优缺点,并使用统一的数据集进行了实验对比。2.对传统的Haar+Adaboost的车牌定位算法进行改进,引入一个CNN二分类器进一步剔除非车牌图像,形成了Haar+Adaboost+CNN的车牌定位方案。3.对字符分割方案进行改进,使用了滑动窗口的方法去分割字符。4.设计并实现了一个简便的车牌自动识别系统,并使用公平的数据集对该系统进行了测试。系统在识别速度和识别准确率两方面都达到了符合预期的表现。"
369,基于IC卡数据的公交客流智能推断方法研究,"城市公交是城市公共交通系统的重要组成部分,发展城市公交可以改善城市发展带来的多种交通问题。公交站点间的客流量反映了乘客出行的时间和空间分布特征,是进行公交系统评价、公交车辆调度和公交线网优化的重要基础数据。公交IC数据包含了海量的乘客出行数据,是获取公交客流的主要数据资源。然而目前多数城市中IC数据只记录了乘客的上车相关信息,缺失了下车相关数据,无法直接获取客流,如何准确地推断出乘客的下车站点,进而获取公交站点间的客流量,是亟需解决的现实问题,对城市公交系统的优化有着重大的意义。本文针对公交客流推断问题,基于公交IC数据,提出了一种结合规则和序列化标注算法的两阶段的公交客流推断方法。首先设计了两种强规则推断方法:换乘推断和往返推断,分别针对两种常见的出行模式,通过引入时间、空间等方面的限制和规则,挖掘出了符合条件的部分乘客和记录,对其进行规则推断,可以得到高准确率的结果;接着,将问题看成是序列化标注问题,抽取出乘客的基本出行特征并加以选择,结合第一阶段得到的结果构造了训练集和测试集,本文采用了循环神经网络嵌套条件随机场的序列化标注模型(Bi-LSTM-CRF),训练完成的模型可以对所有记录的下车站点进行预测;方法的最后为了达到最优的结果,对两阶段产生的结果进行整合。本文分别在三条公交线路上进行了实验,使用了百万级的真实公交IC数据,分别对本文方法的各个步骤都进行了有效性的验证,并与多种方法在多个角度上进行了对比,实验表明本文提出的两种规则推断方法得到的结果准确率高,可以覆盖一定比例的记录,使得低成本应用序列化标注方法进行公交客流推断成为可能,本文提出的结合规则和序列化标注算法的框架在不同线路、不同时段、不同类型乘客上都达到了较高的精度,均远好于传统的行程链模型,其中本文应用的Bi-LSTM-CRF模型的表现最好,本文提出的方法具备低成本、准确性、鲁棒性等特点。"
370,基于机器学习的汽车轮毂智能分类识别系统研究,"近几年来,我国汽车产量持续稳定增长,连续9年蝉联世界第一,这给汽车相关企业带来了机遇和挑战。汽车轮毂作为汽车重要的零部件,其在生产制造运输过程中需要根据实际情况对轮毂进行分类识别。现有的轮毂智能分类系统采用传统的计算机视觉算法,一方面其需要人工确定提取的特征,费时费力且特征的鲁棒性能较差;另一方面,系统的集成度高,很难进行二次开发。因此,本文以机器学习为核心设计了一套汽车轮毂智能分类系统。首先,在对国内外相关技术进行研究的基础上,结合工厂实际情况设计轮毂智能分类识别系统方案,确定了系统的软硬件选型。其次,分别研究了传统的图像特征提取方法与基于卷积神经网络的特征提取方法。在传统的图像特征提取中重点研究了图像去噪,图像分割以及轮毂的半径,中心孔洞,转动惯量特征提取方法。在卷积神经网络中以VGG网络为基础网络进行网络结构与参数设计,并在网络训练中引入并行计算。最后,针对标准轮毂与同类别不同系列轮毂分类分别提出方案。针对标准轮毂分类,本文从预处理复杂度,算法效率,分类准确性,算法鲁棒性四个方面对比了传统轮毂图像分类方案与基于机器学习的卷积神经网络分类方案。最终确定以VGG网络进行图像分类。在检测环境异常,图像背景复杂多变的情况下卷积神经网络分类准确率仍能达到99.43%。对于特定的同类别不同系列轮毂分类,将传统特征的轮毂圆半径,转动惯量与卷积神经网络特征相结合,解决了卷积神经网络在数据集有限的情况下对尺度,镀层特征分类不敏感的问题。将机器学习算法引入轮毂检测不仅能解决传统方法中特征抗干扰性差,鲁棒性差的问题,而且对于轮毂检测系统的二次开发具有重要意义,在利用卷积神经网络进行轮毂图像分类的同时可整合其他检测需求,如进行轮毂缺陷检测,轮毂编号识别等。"
371,基于深度学习的脑电信号分析与模式识别研究,"脑电信号常被用于脑机接口研究、人类情感识别、疲劳驾驶、癫痫、睡眠质量监控等。然而解决这些问题的关键是对脑电信号进行快速有效的特征提取和分类,从而提高脑电信号在这些问题上的识别准确率。为了提高脑电信号识别准确率,本文在脑电信号识别方面所作的工作和创新研究如下:第一,在脑电信号特征提取算法方面,基于脑电信号的直方图和幅度共生矩阵提出了脑电信号的纹理特征提取算法,并在BCI challenge hosted on Kaggle给出的数据集上进行实验。实验结果表明在该比赛第一名方案的基础上加入本文设计的脑电信号纹理特征,使该任务的识别准确率由87.56%提高到了 89.54%,证明了本文提出的脑电信号纹理特征提取算法对脑电信号识别任务是有效的。第二,提出并设计了通道注意力模块,并接于卷积神经网络(CNN)的输入层后,使其自动学习不同通道的脑电信号对于识别任务的贡献程度。同时在此基础上本文又将残差单元和通道注意力模型结合起来,提出了对脑电信号识别非常有效的卷积神经网络结构。最后本文在斯坦福研究项目的EEG数据集进行实验,实验结果表明,本文提出的模型将该任务的识别准确率由ResNet13的82.58%提高到了 85.68%。第三,针对卷积神经网络处理脑电信号无法充分利用脑电信号时间序列信息的问题,提出并设计了卷积循环神经网络架构。该网络将卷积神经网络提取的脑电信号特征送入循环神经网络,充分利用脑电信号的时间序列信息。同时基于循环神经网络每个时刻输出的特征向量,本文设计了注意力集中模型,让模型自动学习循环神经网络每个时刻输出的特征向量对于分类任务的贡献程度。最后为了验证该方法是否有效,本文同样在斯坦福研究项目的EEG数据集上进行了实验,实验结果表明,该算法在第二个创新点的基础上将识别准确率提高到了91.05%。"
372,多角度下车辆品牌识别技术的研究及实现,"随着时代的发展和国民消费水平的不断提高,机动车的数量日益增长;而对于车辆的实时监控和管理仅靠人力已经难以完成,必须借助人工智能等智能交通手段。其中,车辆品牌和子品牌的识别是车辆管理中的一个重要环节,人们可以通过对道路上监控摄像头中的视频图像进行分析,实现车辆品牌识别与分类,进而进行统计与数据分析,对城市车辆进行有效管理。近年来,计算机视觉领域蓬勃发展,在很多视觉处理任务中,计算机的识别水平甚至超过了肉眼的正常水平。但是在实际交通环境下,车辆被监控摄像头拍下的角度是多种多样的,并且拍摄时间、天气、光照角度等外界条件对拍下的车辆图片清晰度影响很大,这对于车辆品牌的识别有较大的难度,对于人工标注来说更是工作量巨大。此外,实际的交通环境千差万别,在一个环境下识别效果较好的模型到了新的环境中可能会有较大的准确率下降。因此,如何在环境改变时仍能保持一个较高的准确率是一个需要解决的问题。本文的目的是在监控视频场景下多角度的车辆图片中识别车辆的品牌和子品牌信息,并且解决新场景下没有大量车辆品牌标注数据的冷启动问题,从而在不同的场景中保持较高的车辆品牌识别准确率。本文所做的主要工作及贡献有:(1)选用不同的卷积神经网络模型对网络来源车辆图片进行微调训练,从方法的层面上证明对卷积神经网络进行微调训练的方法对于解决多角度下车辆品牌识别问题的有效性,并获得网络来源图片的识别模型。(2)收集并制作大数量有车辆品牌标注的监控视频场景下多角度的车辆图片数据集,填补车辆品牌识别领域中监控视频场景车辆图片数据集较少的空缺。(3)使用迁移学习中领域适应的方法,把网络来源车辆图片微调训练的车辆品牌识别模型迁移到监控视频场景下,从而在目标场景缺少品牌标注数据的冷启动时期快速得到一个拥有较高识别准确率的识别模型。"
373,基于深度神经网络的电力负荷分析方法的研究与实现,"随着电力系统信息化程度的不断提高,电网积累的数据量由TB级向PB级发展。研究电力负荷大数据分析算法并建立有效的知识发现模型能够产生巨大的社会价值以及经济效益,因此其对智能电网的发展具有重大意义。例如,提升电力负荷预测结果的准确性关系到电网安全以及可靠供电,并且直接影响电网经营企业的经营决策与经济效益。而异常检测不仅可以提升电力负荷预测的鲁棒性,也有助于降低非技术性损失(Non-Technical Losses,NTL)。本文依托于863计划中智能配用电大数据应用关键技术课题(编号2015AA050203),其主要研究内容如下:1.提出一种基于深度表示学习的电力负荷预测算法。电网系统中的负荷序列通常具有复杂的周期性,对外部特征(例如温度)具有一定的敏感性,且不同用电类型(例如有功功率与无功功率)之间含有隐藏的相关性,这些因素都为预测模型带来了极大的挑战。因此,我们提出了NeuCast,它首次使用深度表示学习的方法来捕捉周期性、外部因素、用电类型与用电需求之间的非线性关系。我们在134个真实世界中的电力负荷序列上验证了算法的有效性。2.提出一种在深度表示学习框架下的异常行为模式检测算法。电力负荷序列中可能含有异常的模式(例如高温负荷与设备故障、调试、检修等),序列中的这些异常模式会直接影响到预测算法的准确性。因此,我们提出了NeuCast-AD,它通过深度神经网络学习序列的隐层表示,并使用Autoplait算法检测隐层表示中的异常区间,从而进一步提升电力负荷序列预测的准确率,降低其对异常区间的敏感性,并且提升算法的鲁棒性。3.设计并实现了一个电力负荷预测的可视分析系统。电力负荷分析的任务不仅需要算法理论的支撑,也需要以大数据可视分析平台为载体落地。本文设计了一套基于可视分析学标准流程系统,来帮助电力系统专家结合自己的领域知识从丰富的用电行为数据中发现未知的趋势和现象,并提供可靠,可理解的结果。本文使用该可视分析系统对中国某南部城市的电力负荷数据进行分析挖掘,得到了有价值的结论,这在一定程度上证明了系统的实用性。"
374,基于混合密度网络的音乐编舞算法研究,"伴随音乐的舞蹈作为一种艺术表现形式,丰富着人类的文化生活,并激发着大众的创作热情。编舞工作通常由专业的编舞家完成,专业性极强且相当耗时,而科技的发展正在改变艺术创作的方式,动作捕捉技术和人工智能的发展为计算机实现基于音乐的自动编舞提供了可能。计算机音乐编舞需要解决两个关键问题:第一,如何不依赖动作捕捉和手工制作得到真实且新颖的舞蹈动作;第二,如何利用适当的音乐和动作特征及匹配算法增强音乐与舞蹈的同步性。为解决以上两个问题,本文基于混合密度网络(MDN),通过动作生成、动作筛选和特征匹配三个步骤,来生成与目标音乐相匹配的舞蹈。与已有研究相比,本文生成的舞蹈在动作连贯性与真实性上有所提升。用户主观评分表明,本文的编舞结果与音乐的匹配程度更高。本文主要工作包含如下三个方面:(1)为了使网络模型生成的动作适用于音乐编舞,提出了一种动作生成过程中的参数控制算法和一种基于连贯性的动作筛选算法,旨在提高生成动作的真实性和连贯性。在动作生成过程中将MDN输出的高斯模型均值作为骨骼位置,在动作筛选时根据相邻帧关节速度变化率衡量动作的连贯程度。实验结果表明,使用均值法生成的动作更真实,对比生成的原始动作数据,筛选后的动作连贯性明显提高。(2)提出一种多层级的音乐与动作特征匹配算法,将整体与局部特征匹配相结合,旨在提高音乐与动作的统一性与合拍性。首先基于常数Q变换提取目标音乐的整体音符密度和每分钟节拍数(BPM),并与动作速度、空间性等特征进行初步匹配,之后再进行基于节奏和强度的音乐与动作片段局部特征匹配。实验结果表明,使用整体与局部特征相结合的多层级特征匹配算法,最终合成结果中各动作片段的速度等特性更加统一,整体编舞更具美感。(3)深入分析了计算机音乐编舞的全过程,并提出了一个计算机音乐编舞框架,为解决该问题提供了一个新的思路。该框架主要由四个模块组成:动作数据集构建、模型训练与动作生成、舞蹈编排与合成、三维角色动画可视化。为了增强框架实用性,在舞蹈编排模块引入用户控制,用户通过设置局部骨骼速度和空间性特征的阈值影响编舞结果。利用本框架可以自动生成与目标音乐相匹配的舞蹈动作。相较于仅利用深度神经网络获得的音乐-动作映射模型,本框架具有更强的稳定性与泛化能力。"
375,基于深度学习的自动作曲编曲研究,"音乐是人类历史上最伟大的发明之一,对人类生活产生重要影响。创作音乐需要专业的领域知识和乐器技能,如何自动创作音乐已成为近年来一个热门研究方向。许多公司和研究机构在这方向做了很多有趣的工作,如Google的Magenta项目,对现有的大量的钢琴曲进行学习,研究如何让机器自动创作钢琴曲。随着深度学习的崛起,深度神经网络应用于音乐生成中,避免了传统机器学习方法中需要大量手工特征的耗费。以往的模型在进行音乐生成时还有许多不足之处,很多影响音乐生成质量的因素都没有很好地考虑进来,诸如和弦进行和节奏型。和弦进行广泛存在于流行音乐中,它可以指导旋律的走向,将其作为输入将有益于音乐生成。同时流行歌曲有着固定的节奏型,但现有的研究采用基于音符级别的生成方式,未考虑到音乐的结构性。此外,流行歌曲通常有着多个音轨和乐器来为旋律进行伴奏,不同的轨道和乐器应该相互协调,而以往的工作并没有考虑到音轨间的和谐性。最后,音乐有着多种风格,如古典,爵士和流行音乐,如何生成特定风格的音乐是值得探索和研究的问题。针对以上问题,本文基于深度学习的技术,对音乐生成中相关问题进行了研究,主要研究内容和贡献有:1.针对流行音乐的生成,本文提出了一个从旋律到编曲的端到端的生成框架(Melody and Arrangement Generation Framework,MAFG),该框架包括两个部分,分别是旋律生成部分和编曲生成部分。在旋律生成部分中,提出基于和弦的节奏和旋律交叉生成的模型(Chord based Rhythm and Melody Cross-Generation Model,CRMCG)来提升音乐音程关系,学习乐段的结构性。在编曲生成部分中,提出基于多任务学习的多乐器联合编曲模型(Multi-Instrument Co-Arrangement Generation Model,MICA),实现多音轨多乐器间的和谐配合。2.针对音乐风格的控制,提出了一个多风格多乐器联合编曲模型(Multi-Style Multi-Instrument Co-Arrangement Generation Model,MSMICA)。该模型包含了编曲生成器和多个判别器,通过生成器和判别器对抗训练生成特定风格的音乐,且保证音乐的和谐性。3.针对以上两个工作,在真实音乐数据集上进行了大量实验,实验结果验证了CRMCG,MICA和MSMICA模型的有效性。"
376,基于FPGA的AES电磁泄露信号分析,"随着信息产业的蓬勃发展,密码设备已经渗透到各行各业,不仅在日常生活中,在国防、政治、金融等领域的应用也越来越丰富。与此同时,密码设备的信息安全问题受到来自各方面的关注。密码芯片运行过程中,电路状态的变化产生电流,变化的电流产生变化的磁场。通过分析无意间泄露出来的磁场信息,能够得到密码芯片的核心数据信息一密钥。本文针对密码芯片电磁泄露信号进行分类来识别不同的密钥,对于评估密码芯片的信息安全具有重要意义。主要有以下三个创新点:第一,本文搭建了一个由Sakura-G开发板、电磁感应探头、放大器、示波器及搭载了 Checker、Transporter程序的计算机组成的全自动的电磁泄露信号采集平台。通过该平台采集分组加密算法AES在运行过程中的电磁泄露信号,节省了人工成本,也使得采集信号的实验环境最大程度地保持一致。第二,本文设计了结合经验模态分解算法(EMD)、信号能量特征、梯度提升树(GBDT)方法的电磁泄露信号分类算法。首先利用时间窗分割原始信号得到AES加密算法每轮对应的子信号,然后利用EMD方法分解各子信号,将分解后特征模函数(IMF)的能量特征组成特征矩阵,随后在特征矩阵的基础上使用梯度提升树(GBDT)方法实现不同密钥电磁泄露信号的分类识别,并对比决策树棵数、参数不同时,识别准确率的变化。通过与主成分分析(PCA)提取信号特征的方法进行对比,实验表明,所设计的算法提高了分类准确率。第三,本文提出将深度学习网络Inception ResNet V2应用到电磁泄露分析,分别使用不同网络层数、不同卷积核种类的Inception ResNet V2网络对电磁泄露信号进行分类实验,研究了网络参数不同时识别准确率的变化,并由此选定最优网络参数。实验结果表明,Inception ResNet V2网络的识别准确率优于梯度提升树的识别准确率。"
377,商品评论情感分析系统的设计与实现,"近几年随着电子商务的不断发展成熟,网上购物越来越普及。消费者在浏览电子商务网站的同时,也可以将对各种商品的评论发表到网站上。如何充分挖掘、高效利用这些商品评论信息显得格外重要,情感分析技术由此产生。目前主流的情感分析研究方法有基于情感知识的方法和基于机器学习的方法。基于情感知识的情感分析方法关键是针对词语的情感倾向进行研究,具有一定的局限性。基于机器学习的情感分析方法目前主要利用传统的机器学习方法。随着深度学习的兴起,越来越多的学者将Deep Learning运用到情感分析领域。因此,本文探究运用深度学习方法进行情感分析研究,提高评论文本情感分类的准确率。本文目标是构建一个高效准确的商品评论情感分析系统。实验所用的商品评论数据集,一部分利用Scrapy框架从京东网站上爬取,一部分来自网上公开的数据集。对中文数据进行分词、词性筛选、去停用词,通过合理改进Word2Vec模型实现将预处理过的评论文本转换成词向量矩阵,输入到后续的情感分析分类器中。本文重点是情感分析分类器的设计。卷积神经网络TextCNN能够降低数据规模和复杂程度,深层次捕捉文本数据的n元语法特征。门控循环单元GRU模型简单、训练时间短,能够有效解决长短时间序列的变化问题,获得全局文本特征。本文提出新模型TextCNN-GRU作为系统的分类器。该模型先进入嵌入层完成词向量化训练,接着CNN部分提取文本局部最优特征,GRU部分获得全局的句子表达,最后输出情感分类。为了提升模型的效果,本文在参数选择上设置很多对比实验,有词向量维度、GRU层层数、滑动窗口大小等。通过TextCNN-GRU混合模型与单一模型TextCNN、GRU以及传统机器学习模型SVM、Naive Bayes、KNN比较,表明TextCNN-GRU在情感分析上比其他5种模型有更高的准确率,很好说明TextCNN-GRU能够综合TextCNN和GRU各自优势,取得更好的分类效果。"
378,融合上下文信息的文本分类算法的研究及应用,"文本分类任务作为文本挖掘的核心,已成为自然语言处理领域的一个关键问题。面对互联网上的文本资源爆炸式增长的趋势,如何有效的利用文本数据,挖掘其背后的商业价值和研究价值,具有非常重要的意义。在此背景下,本文以序列型文本数据作为研究对象,提出了两种融合上下文信息的文本分类算法。近年来,深度学习技术在特征提取和表示方面已经有了很大进展,且在大多数自然语言处理任务中获得了令人满意的成果。但是,结合国内外研究现状,在目前对深度学习的研究中,大多数的文本分类算法没有考虑到文本的上下文句子信息,并将其作为额外信息的补充利用,然而,如果给出一个没有任何语境的句子,即使人为的判断类别也有一定的困难。针对以上问题,本文提出了两种分类算法,一种是基于CNN的注意力机制融合上下文信息的文本分类算法,另外一种的基于BLSTM的注意力机制融合上下文信息的文本分类算法,通过从句子层面和词层面分别设计的注意力结构将上下文信息融合进最终的特征表示中,增加了特征信息的多样性。同时为了验证两种算法的可行性,本文首先使用了开源对话数据集进行实验,验证了两个模型在时间效率和准确性方面各自的优势,然后将分类模型应用于电网故障案例文本数据中,实验的结果充分证明了本文所提模型的有效性和通用性。本文的第一、二章阐述了论文的工作背景、研究意义和相关技术路线。第三章对本文所提的基于CNN的融合上下文信息的文本分类算法进行详细介绍,并对算法涉及到的技术难点和创新点进行分析。第四章对本文所提的基于BLSTM的融合上下文信息的文本分类算法进行详细介绍。第五章是对算法不同模块有效性验证的设计与实验,通过一步步实验证明本文所提创新点的有效性和整体模型的分类效果。第六章用实际的中文文本案例将模型应用于电网场景中,证明模型的通用性和有效性。"
379,基于语义分割的行人属性识别技术的研究与实现,"智慧城市是科技赋予给社会的一个新的名词,而摄像头是建设智慧城市一个重要的基础设备。高效,有效的利用好摄像头信息能够在人们日常生活和维护社会秩序中发挥重要的作用。行人信息在摄像头信息中占有很大的比例,通过摄像头中的行人信息,可以进行行人检索,行人识别和行人重识别。因此,对于行人信息的研究有着很强的现实意义。本文是对自然场景下行人属性信息进行识别。通过总结之前对于行人属性的研究工作,本文发现之前工作主要是探讨行人属性信息的存在性。然而,行人属性的位置信息在行人重识别等领域也有重要的作用,因此本文主要对如何获取行人属性位置信息进行研究。本文利用语义分割模型进行行人属性位置信息的获取。面对当前无可用行人属性语义分割数据集的状况,本文制作了第一个行人属性语义分割数据集。在此数据集基础上,本文利用不同语义分割框架进行实验,首先利用简单的语义分割模型进行可行性验证,验证了可以利用语义分割获取到行人属性的位置信息,之后利用精度更高更复杂的模型训练得出此数据集的miou基准值。针对得到的miou基准值,本文从属性类别、准确率、图片清晰度三个方面与miou进行了相关性分析,得出miou与属性数量占比、准确率、图片清晰度都成正相关。最后,本文从降低模型复杂度和更好的利用特征两个方面对语义框架进行修改,并为之后相关研究提供建议。"
380,基于大数据的用户画像和评级研究,"随着互联网的不断演进和智能设备的不断普及,人们可以通过各种各样的方式接入互联网。互联网在给生活带来便利的同时也积累了大量的数据,如何对这些数据进行挖掘分析从而发挥数据的价值是一个研究的热点问题。另一方面,在目前的形势下,用户扮演着非常重要的角色。有了用户企业才会有收益,才会有长远发展。如何在大数据的基础上分析用户的特点,从而针对不同的用户群体提供定制化服务也是一个非常有意义的研究问题。本文的研究内容如下:首先,研究了金融机构用户画像的问题。针对一个具体的金融机构:A市市中心银行网点,基于用户的储蓄数据使用Elkan k-means算法将用户划分为活跃型用户群、潜力型用户群、稳定型用户群和流失型用户群四类群体。针对不同的用户群体,使用用户属性数据对用户群进行画像,分析用户群特点。进一步,基于用户的储蓄数据,使用SVR回归预测算法对用户的储蓄潜力进行预测。通过在个人层面和整体层面进行评价,预测准确率较高。其次,提出了一个用户评级机制。针对具体的运营商机构:B市运营商分公司,提取包括产生流量、使用时长、不同类型业务流量占比三个维度的用户数据,进而得到用户贡献数据和用户行为数据。使用Elkan k-means算法对用户贡献数据进行划分,根据用户对运营商的贡献程度确定聚类类簇定义,得到用户级别信息。基于用户行为数据和用户级别信息使用随机森林、CART树和逻辑回归进行预测分析,随机森林的分类效果最好,模型准确率为81%左右。最后,开发了一套大数据可视化分析平台。该平台采用MVC系统架构,主要由后台和前端两个部分组成。后台部分通过Django框架搭建,可以实现数据存取、数据分析、数据传输的功能;前端部分通过HTML5、CSS3、JavaScript组合搭建,图表通过ECharts呈现,可以实现对数据的动态展示以及与用户进行实时交互等功能。"
381,基于机器学习的Android应用漏洞检测技术研究,"如今,智能手机的普及带动了手机应用软件的发展,使之成为我们日常生活的一部分。移动应用的多样性使得它们可以为用户生活的各个方面提供很大便利。Android系统作为一款基于Linux的操作系统,连年占据了绝大部分的市场份额,成为移动操作系统领域的主导力量。然而,Android应用程序正面临着来自漏洞的安全威胁。常见的权限提升漏洞使得攻击者能够在用户不知情的情况下获取敏感信息,或进行危险操作,这让用户的隐私和数据安全时刻处于危险中。基于此背景,本文做了相关的研究,内容和成果如下:(1)对Android应用中常见的权限提升漏洞进行研究,分析其漏洞原理及攻击场景,总结出漏洞形成因素表达式(EMPC)。基于此表达式,选择Android应用基础特征中与漏洞成因相关度较高的特征,以备后续的模型训练。(2)根据以上所选择出的特征,本文提出一种基于机器学习的Android应用权限提升漏洞检测方案。该方案根据选择的特征及收集到的样本的特质,制定了相应的预处理策略。基于表达式初步选择的特征维度较高,本文在特征预处理中做的工作包括降维等。由于所收集到的样本数量不均衡,在训练阶段本文采取了两种思路,一是训练二分类器以预测漏洞样本和良性样本,二是训练一分类模型以完成对漏洞样本的异常检测。在训练二分类器的过程中,我们对样本进行了平衡处理,具体包括良性样本的随机降采样,和漏洞样本的生成。本文在此提出一种基于随机森林中特征重要度衡量样本重要性的计算方法,以及基于这些重要样本的SMOTE样本生成方法,然后采用集成学习的思想对基分类器进行合并。实验结果表明,本文所设计并实现的检测框架能够有效的检测出Android应用中存在的漏洞组件。"
382,基于人工智能的网络异常行为分析,"网络技术和互联网的发展和普及,使得网络中的Web服务器随处可见,人们可以通过浏览各种各样的Web网站进行购物或支付生活消费,给生活带来了很大的便利,但是随之而来的网络安全问题层出不穷。对Web服务器的攻击是安全领域最严重的威胁之一。Web服务器具有远程访问和大量安全漏洞等特点,黑客可以利用这些漏洞破坏Web服务器,从数据中收集机密信息,甚至中断或完全瘫痪Web服务器。由于Web日志记录了用户访问网络的行为,因此分析Web日志是识别用户异常行为的最有效方法之一。传统的基于Web日志的异常行为检测技术存在着规则库难以管理、统计模型难以充分提取用户行为中重要特征等问题,导致误报率和漏报率高、泛化能力差、检测速度慢等。因此,进一步分析Web日志对于研究异常检测技术具有重要意义和实用价值。基于这种背景,本文提出将人工智能应用到网络异常行为检测中,主要工作如下:1.提出一种基于Web日志的数据特征建模方法,根据Web日志的HTTP请求字段所具有的隐含统计特征,构造单条HTTP请求特征和攻击类别统计特征,实验验证表明本研究点构造的统计特征具有较好的异常行为识别能力。2.提出一种改进的XGBoost异常行为检测算法,构造双层XGBoost分类模型,首先通过多分类器确定每条HTTP请求的候选攻击类别,然后通过二分类器确定最终攻击类别。3.提出一种基于字符级别的神经网络异常行为检测算法,通过构造字符级别的Char2Vec特征向量表达方法,实现了卷积神经网络和循环神经网络异常检测模型。在真实数据集上进行实验,验证表明,与其他传统机器学习算法相比,研究点二和研究点三提出的检测算法无论在检测率,还是误报率上都表现更好。"
383,基于蚁狮优化SVM的智能家居入侵检测的研究,"现今时代互联网技术快速发展,为了适应时代的发展速度和方向,计算机网络也在不断的普及和生活化,被广泛用于在服务器与移动设备和桌面之间交换机密数据信息。但是随之而来的安全问题也日益严重。在物联网的研究领域,各个物联网相关的组织、智能家居产品的厂商都提出了各自研究的解决方案。不同的标准和协议带来了智能家居产品多样化,但也因为标准和协议的不统一,带来不少问题。而各大物联网组织、智能家居厂商提出的标准和协议对安全问题普遍不够重视。因此研究具备兼容性和高安全性的智能家居系统具有实际意义和实用价值。本文为了解决上述问题而设计了基于Alljoyn技术的瘦客户端智能家居系统平台。所设计的平台总共由标准客户端,设备系统桥和瘦客户机三个主要部分组成。实验结果表明该系统可以通过标准客户端应用对瘦客户端设备进行发现、访问、配置、生成统一控制界面并控制的操作。之后,针对该智能家居系统平台潜在的网络攻击的安全问题,引入入侵检测方法。首先是分类器的选择。近年来机器学习已经成为网络安全和入侵检测领域的重要部分,也产生了很多算法来解决各种的问题。但是这些算法哪一个会增强会解决智能家居环境的入侵检测系统就成了本文要解决的问题。最终在第四章通过实验对支持向量机(Support Vector Machine,SVM)相较于其他分类器更适用于于智能家居环境进行了佐证。根据所选择出的SVM分类器,在agent技术的基础上提出了一种基于蚁狮优化算法优化SVM的入侵检测模型。首先是蚁狮优化算法对SVM惩罚因子和核函数这两个参数的优化,利用得到的最优惩罚因子和核函数来建立最优的分类模型,以此来达到提高网络入侵检测分类准确率的目的。该入侵检测方法共包括数据的收集以及预处理,优化参数,训练学习等部分。分类器的选择测试和基于蚁狮优化算法优化SVM的入侵检测方法的测试都是在UNSW-NB15网络数据集上进行的。首先,分类器的选择实验是选择了五种分类器进行实验,然后利用五种评价标准进行评估。第四章结果表明SVM相较于其他分类器更适用于智能家居环境。最后,基于蚁狮优化算法优化SVM入侵检测方法与基于粒子群优化算法优化SVM,基于蜻蜓优化算法优化SVM进行了实验对比。根据实验结果总结得出,蚁狮优化算法优化SVM的网络入侵检测方法在降低了误报率的基础上有更高的效率和检测率。"
384,基于机器学习的配电网络拓扑生成及重构优化研究,"随着智能电网的深化建设,一方面,智能电表等设备接入配电网,并实时采集运行数据,海量数据蕴含巨大的价值有待开发。另一方面,配电网与外界交互日益增多,如分布式供电储能等。新模式对配电网的物理特性产生重要影响,传统物理理论建模方法难以满足复杂系统的需求。因此,配电网亟需新方案应对复杂环境。机器学习等新技术能够挖掘海量运行数据的潜在价值,并探索新的认知关系,辅助现有方法优化运行。配电网的拓扑分析是其安全稳定运行的基础,拓扑生成和重构优化又是拓扑分析的核心。因此,本文重点探索机器学习方法在拓扑生成和重构优化的基础问题。1)为实现实时准确地监测配电网络的拓扑结构,提出基于Lasso及其补充规则的拓扑生成算法。算法首先利用Lasso模型计算各节点的关联系数矩阵,然后利用“and”规则和补充判据修正该矩阵,最后通过准确的关联系数矩阵生成拓扑。实验验证,该算法在获取720个时序电压值的情况下,生成119-bus及更低复杂度的无环和有环拓扑的误差率低于6.14%,且随着电压时长增加,误差率逐步下降。本算法性能优于传统的Chow-Liu和Lasso+“and”算法。2)为实现高效经济地优化配电网络的拓扑结构,提出基于LSTM预测机制的动态拓扑重构算法。算法首先构建LSTM模型预测各节点各时段的负荷,然后利用优化的BPSO模型生成各时段的重构方案,最后基于综合费用最优的判据生成全局优化的动态重构策略。利用英格兰某配电网2004-2009年真实数据测试LSTM模型性能,结果显示模型预测的平均绝对误差率为1.59%,且80%分布在[0,2%],在不同时段下均无明显误差异常点;其预测性能优于传统的人工神经网络和支持向量回归模型。利用IEEE33-bus仿真算例测试重构算法性能,算法生成的动态策略将1个运行周期重新划分为7个时段,并进行20次开关操作。算法共减少线损费用1152.42元,且提升各节点电压质量。对比分析验证该算法的性能均优于传统的在线计算重构算法。实验结果表明,拓扑生成算法具有较高的准确率和较低的计算复杂度,可用于实时监测拓扑结构,保障配电网拓扑运行的准确性和安全性;拓扑重构算法能够为重构操作提供更多的时间裕度,并且减少更多的线路损耗费用,可用于重构优化拓扑结构,保障配电网运行的稳定性和经济性。算法均无需新增专用的拓扑监测设备,可作为物理模型方法的辅助决策方法,提升配电网的智能化程度,具有一定的前沿性和实用性。"
385,新兴科技全球治理研究,"人类社会进入二十一世纪以来,人工智能技术的发展取得了突破性进展,它丰富的应用场景和与各产业的深度融合有望成为下一轮产业革命的关键节点,深刻地改变人们的经济生产、政治文化与行为方式。知识产业的发展背后,是大国在科技与资本实力上的长期较量和抢占结构性权力战略高地的激烈角逐,人工智能技术的发展对于世界经济、政治格局潜移默化的影响将推动整个国际体系的改变。新兴科技在给人类社会带来机遇的同时,也带来严峻的安全和治理挑战,而资本和技术在全球范围内的流动和扩散对全球新兴科技治理提出更高要求。本文旨在探讨当代人工智能技术领域全球科技治理之中的权力扩散问题,尝试在新兴科技对国际关系的影响以及全球治理的权力扩散问题的研究二者之间建立紧密和准确的联系。学界在国际体系中的权力扩散问题上形成了一定的研究成果,对全球治理的责任、权力来源和形式进行了广泛讨论。这其中争论的焦点之一是科技的进步对全球治理的影响究竟是加强权力的集中还是最终导致权力的扩散,以及治理行为主体是否由国家政府部分地扩散乃至完全转移至以跨国企业、国际组织、公民社会为代表的非主权国家行为体手中这一衍生问题。但现有研究或对全球科技治理中的主体性语焉不详,也对人工智能领域全球治理体系中行为能动者之间的互动关系缺乏深入的讨论。本文认为,要真正理解新兴科技对国际关系的影响,更好地推进全球科技治理机制的建设,就必须深入研究治理权力的来源、归属以及权力的形式问题。为了达到上述目标,本文具体以人工智能技术为例,从全球治理中权力扩散的角度,分析新兴科技对国际秩序和治理权力形式的影响。首先本文讨论了人工智能产业的历史概况和发展现状,对主要国家发展战略和规划政策作对比性综述,随后从治理的主体性、客体性、机制性三个维度对全球治理权力进行合理解构,分别分析当下人工智能全球治理秩序在行为能动者、治理议题和治理机制三个层面中已发生或可能发生的权力扩散及其动因和形式,总结当前全球科技治理规范与机制的重要特征和总体模式,初步探索全球数据治理的内涵、规范与挑战。综合上述三个层次的分析,本文认为目前阶段的人工智能全球治理在行为能动者、议题范围、治理机制这三个维度上都出现了一定程度的权力扩散。国家政府、跨国科技企业以及知识型行业组织是人工智能全球治理体系中最重要的行为能动者,它们之间相互支持又相互制约,分别在全球治理体系中发挥着各自独特的作用。政府立法和国际规范制定离不开跨国企业作为技术创新者和服务提供者的持续知识输入,而企业在一国范围以及国际范围的商业活动会受到国家政府公共权力和立法地方化的制约,对于多边治理机制和国际准则而言,主权国家仍是首要参与主体。随着人工智能技术的发展和进步,数据所有权问题凸显了数据信息保护的责任和权力问题,亟待填补现有国家法律和国际规范体系中的法律空白,因此成为人工智能全球治理体系中的重要新兴议题。最后,国家立法和多边治理机制是当今人工智能全球治理在确立规则方面最重要的机制形式,国家政府和市场力量之间、国家与超国家机构及国际规范之间将展开旷日持久的博弈。本文的创新之处是比较深入地探讨新兴科技对国际关系的影响和全球科技治理权力扩散这一前人较少涉及的交叉领域,具体以人工智能技术这一新兴领域为例,对全球人工智能科技治理的权力扩散进行合理解构和再重构,从治理主体性、客体性、机制性三个维度对全球治理权力的扩散动因、形式和影响作合理推断和分析。本文还讨论了人工智能产业的总体发展现状和主要国家发展战略,总结了当前全球科技治理规范与国际机制的重要特征和总体范式,初步探索了全球新兴科技和数据治理的内涵、规范与挑战,相较于现有研究有了一定的角度创新和实例分析突破。"
386,基于机器学习的蜂窝网络基站流量分析与预测研究,"随着移动通信技术不断发展,移动蜂窝网络应用日益增多,社会生活越来越依赖于移动通信,蜂窝网络流量的需求也越来越大。而蜂窝网络产生了海量的数据,这些数据蕴含了用户、网络甚至是社会发展的信息,对这些信息进行挖掘,可以为通信技术的进一步发展、运营商公司战略的部署、社会行业的进步提供重要的参考意见。本论文选题于企业科研项目,着重进行蜂窝网络基站流量数据的分析与预测研究。由于不同基站流量序列之间具有时空相关性,本论文对基站进行聚类分析研究,得到每类基站的流量变化特性;在此基础上,利用神经网络算法进行基站流量预测研究。主要工作内容如下:1)本论文综述了蜂窝网络数据挖掘相关研究,总结了蜂窝网络数据的特征及相关研究方向,梳理了数据挖掘常用方法以及数据挖掘方法应用于蜂窝网络流量分析与预测领域的相关研究现状。2)针对不同基站的流量序列之间具有时空相关性的特征,本论文利用聚类算法对基站进行聚类分析。将基站流量序列包含的趋势信息融入到聚类算法的距离度量中,得到新的距离度量TBD(Trend-Based Distance)。由于距离度量可表征序列间的时空相关性,进而提出基站流量时间序列的K趋势(K-Trend)聚类算法,将基站按照流量序列间的时空相关程度聚成不同类簇,并结合地理位置信息对每个类簇的基站进行流量变化特性分析。利用实际基站流量数据集对所提算法进行性能验证,结果表明,所提算法比传统K均值(K-Means)算法的聚类性能更优。3)针对单基站与全局基站的流量预测问题,本论文提出了两种基于长短时记忆(Long-Short Time Memory,LSTM)神经网络的基站流量预测算法。第一种是TBD-LSTM单基站流量预测算法,该算法在预测单基站的未来流量时,计算该基站与其他基站的流量序列时空相关性,选取相关性较高的基站,将这些基站的流量值与待预测基站的流量值共同作为预测模型的输入,训练神经网络,最终得到单基站的流量预测模型;第二种是K-Trend-LSTM全局基站流量预测算法,该算法对K-Trend聚类后的每个类簇都训练一个预测模型,将类簇内所有基站流量序列作为该类簇预测模型的输入,每个类簇的预测模型可以预测出这个类簇中所有单基站的未来流量值。将所提算法应用于实际数据集中预测基站的未来流量,结果表明,所提两种算法比传统LSTM算法的预测精度更高。"
387,基于机器学习的轨迹预测方法研究,"随着互联网和定位技术的高速发展,智能化移动设备逐渐成为生活中不可或缺的一部分,产生了海量的轨迹数据。国内外学者利用这些数据展开了不同的研究。而轨迹预测作为轨迹研究的重要部分,具有广泛的应用场景,可以为用户提供更好的服务,为政企各界的决策提供重要依据,例如:各种基于位置的用户服务、人群拥塞预警、网络资源分配与移动性管理等,有助于社会和谐发展,实现经济效益的增长。近年来,对于轨迹预测的研究持续升温,有关方法被相继提出与应用。然而,目前的许多研究挖掘出的轨迹点仅通过一系列难以理解的数字标号表示,对于停留点的提取也缺乏时间一致性。另一方面,常规的轨迹预测模型没有充分利用轨迹的上下文信息,并且只预测下一个停留的位置,研究成果的预测准确性仍有提高的空间。针对以上问题,本文对基于机器学习的轨迹预测方法进行研究,主要完成了如下工作:(1)研究了轨迹信息的处理方法。通过轨迹预处理、空间信息提取、时间和方向信息添加等一系列流程,将轨迹数据转换成更易理解的语义信息。提出了一种基于多级聚类的空间信息提取方法。首先基于时空一致性扩展的停留点提取方法,利用滑动窗口与区域一致性扩展算法,提取出具有时空相对一致性的停留点。再基于启发式的增长聚类方法,提取停留区域点。之后与移动点合并,最终转换为生活中的地点名称,使轨迹数据能表示出用户的活动场所及移动过程。(2)研究了基于深度学习的轨迹预测方法。对处理后的轨迹信息进行特征向量提取、构建预测模型,充分利用上下文信息,提高预测准确率。本文运用自然语言处理中的Word2Vec模型将空间信息转换为词向量,结合时间、方向特征构建特征向量序列。根据特征序列内部的时序关系,基于深度学习中的LSTM模型和双向LSTM模型预测轨迹的下一个位置,包含停留区域点和移动点。(3)利用真实生活中的GPS数据进行仿真实验,分析了不同参数情况下的模型性能。实验结果表明,本文所提的方法可以有效地预测轨迹的下一个位置。本文的研究成果可以更好地表示轨迹的语义信息,同时提高预测效果,具有有效性和实用性。"
388,基于学生校园数据的学业预警与社交分析系统的设计与实现,"数据挖掘技术与人工智能算法的发展日新月异,为我们从海量的数据中挖掘有价值的信息并且加以利用奠定了坚实的理论和应用基础,与此同时,对于探索隐藏于数据背后的信息的需求也与日俱增。无线网络和智能手机的蓬勃发展,以及校园数字管理系统的普及,使得我们可以获取并分析学生丰富多彩的校园生活中产生的轨迹和行为数据,挖掘有价值的信息从而为更科学有效地管理学生提供数据驱动的指导方针。教育大数据(Educational Data Mining)近些年来已经成为了许多高校研究的热点内容。本论文基于校园多源异构数据,结合Wi-Fi定位技术、轨迹数据挖掘技术、社交网络分析技术、机器学习以及深度学习技术,构建学生个人行为画像以及社交行为画像,设计深度学习网络结合多方面因素对学生的学习成绩进行预测,设计并实现学业预警与社交分析系统。首先对包含Wi-Fi探针定位、校园网使用数据、校园卡使用数据等的多源异构数据进行预处理并基于时空信息进行融合从而构建学生的校园轨迹,接着设计算法和规则构建学生的个人用户画像,对画像与学生学业成绩的相关性进行展示和分析并基于用户画像对学生成绩进行预测。然后基于学生校园轨迹设计学生向量嵌入算法,生成学生的表征向量,从而对学生的社交行为画像进行构建,并设计深度学习网络结合学生画像和轨迹行为模式对学习成绩进行预测。实验中使用精准率、召回率、准确率以及AUC等相关指标对预测结果进行衡量。最后基于以上成果,设计并实现学业预警与社交分析系统,提供学生画像的展现、社交关系的展现以及异常学生的预警等功能。"
389,基于机器学习的网络流量预测与应用研究,"随着计算机信息技术的发展,网络的功能场景及架构越来越复杂,网络流量爆炸性增长,展现出许多新的特征,这些对网络的性能提高和稳定性维护提出了新的挑战。为了增强网络运行速率和提高网络资源利用率,本文在流量分场景建模的基础上结合机器学习算法对流量进行分类预测研究,同时搭建SDN仿真平台进行算法实现,具有理论与实践意义。首先,针对骨干网、数据中心、边缘网及大突发情况这四种典型的流量场景结合前人的研究工作分别建立泊松、MMPP、自相似及Pareto数学模型,深入研究流量特征的同时得出路由缓存的参考大小,并进行现网流量分析与SDN网络仿真双重验证。其次,在流量建模的基础上,使用lightBGM多分类算法对泊松、MMPP和自相似流量数据进行分类,数据预处理提取特征,在训练中对参数不断优化以达到较好的分类效果;接下来针对已分类的突发性较强的自相似流量进行数据处理与预测研究,采用能够捕捉到流量序列中长距离依赖的LSTM算法进行预测,通过研究不同参数取值对预测准确度的影响以得到最佳的流量预测模型。最后,使用ONOS控制器搭建SDN网络平台,分别建立信息采集、流量分类、流量预测与路由调整的功能模块,完成从信息采集到流量分类预测及网络优化的全过程,对算法应用进行探索实践。"
390,基于机器学习的SDN流量调优系统,"随着互联网深入人们生活,网络流量爆炸式增长,传统的IP网络流量分配机制面临诸多挑战。如何灵活调度网络流量,避免网络流量过分汇集造成网络拥塞,对保障网络发挥正常通信功能具有重要意义。分析已有的流量分配方式后,发现对链路拥塞风险的判断可辅助决策流量分配,以较小的额外通信开销实现拥塞避免。链路拥塞风险可理解为未来一段时间内链路上的流量负载是否会增加,并超出链路额定带宽。近年来,机器学习中的长短期记忆循环神经网络(LSTM)技术在序列预测问题上展现出良好效果。本文针对利用流量预测序列判断链路拥塞风险的具体场景,采用间隔采样的样本提取方式和利用全连接层扩展输入向量长度方式,实现了便于预测链路拥塞风险的LSTM流量预测模型。软件定义网络(Software defined networking,SDN)是正在蓬勃发展的下一代网络技术,它将控制平面与转发平面分离,并提供统一的应用编程接口。在SDN平台上,网络实时流量信息收集、全网络拓扑内的流量调度易于实现,这为上述考虑链路拥塞风险的网络流量调优机制的实现提供了基础。本文在SDN控制平面上实现了信息采集模块、路由决策模块和信息协同模块,并在外部实现了流量预测模块。由这四个模块组成一个完整的系统,实现了论文标题中提到的“基于机器学习的SDN流量调优系统”。为测试所搭建系统可用性及上述流量调优机制的有效性,基于仿真软件Mininet搭建了仿真平台。仿真平台包括一个部分连接网状拓扑,两种流量仿真场景(包括网络分发流量仿真场景)。在不同的流量场景下分别测试了路由决策模块和流量预测模块,发现路由决策模块能够实现最短路径流量部署和备选路径部署,流量预测模块能在线上较好预测网络分发仿真流量。最后在网络分发流量场景下进行系统完整测试,发现本文提出的基于链路拥塞风险的流量调优机制能够以尽可能少的额外通信开销避免网络拥塞发生。"
391,基于深度学习的分类预测算法研究及实现,"信息检索领域中的点击率预测和个性化推荐问题中存在大量多字段分类数据。这类型的数据主要呈现以下特征:有多个不同字段,且每个字段与其他字段间没有明确依赖关系。与图像和语音的连续数据不同,这类数据在处理之后通常具有高维稀疏性,且不同字段的特征之间存在组合关系。如何提取这种复杂的组合特征对于提升广告点击率预测与推荐系统的性能至关重要。传统的机器学习方法在处理这类问题时依赖繁琐且复杂的人工设计组合特征。深度学习凭借强大的表示学习能力,擅长学习高维数据中的复杂关系,可以用端到端的方式更好地提取高质量的特征。本文研究基于点击率预测的深度学习模型,并对其进行改进,设计了一种基于注意力机制的因子分解机模型和残差网络并行的网络结构,并在公开数据集上进行了验证。主要研究内容如下:(1)对宽深度模型Wide&Deep及其变体进行研究及仿真。研究发现其核心思想都是通过融合线性模型和深度模型分别提取低阶和高阶的组合特征。通过实验,得出了这类模型目前存在的不足,为后续模型的优化提供研究思路。(2)为进一步提高宽深度模型对复杂组合特征提取的能力,本文设计并实现了因子分解机与残差网络并行的模型结构FM&ResNet。模型在因子分解机中引入注意力机制为不同组合特征自适应赋予权重;在残差网络部分引入自注意力机制建模组合特征;引入残差连接的结构,使得模型的收敛性更好。(3)本文模型在公开数据集上的实验验证。实验表明,在不显著增加训练时间的基础上,模型的AUC(Area Under Curve)性能指标在Criteo数据集上有0.1%的提升,在Frappe数据集上有2%的提升;引入注意力机制能够有效提升模型性能。最后,本文算法模型在快手公司短视频数据集上的点击率预测也取得了良好的效果。"
392,基于群体的深度强化学习超参数自适应方法研究,"机器博弈是人类智能行为的模仿与提升,是人工智能技术理想的实验床,被称为“人工智能的果蝇”,具有广泛的应用前景。深度强化学习是目前求解机器博弈问题的有效手段和主流方法,但是深度强化学习方法目前还存在一些问题,其中,超参数设定问题由于直接影响学习的效率,因而具有重要的研究价值。本文研究深度强化学习的超参数自适应方法,主要工作和研究成果如下:一、对面向机器博弈的深度强化学习方法进行了系统地调研。针对领域base-line失效问题,本文依据领域标准实验方法和评估方式,给出了最新的baseline结果。此外,对主流深度强化学习算法进行了实验研究和分析,包括算法样本效率、算法采样效率等,并由此发现了一些新的现象,得出了一些新的结论。二、提出了一种基于群体的高效在线深度强化学习超参数自适应训练方法。区别于传统的有监督学习,深度强化学习是一个高动态-非平稳的优化过程。深度强化学习的性能对其超参数配置的选择十分敏感,例如学习率,折扣系数和步长等。对深度强化学习而言,超参数最理想的状态应该是随着学习过程的推进,进行自适应地调整,而不是从始至终使用一组固定的超参数配置。对此本文提出了一种基于群体的高效在线深度强化学习超参数自适应训练方法,该方法是PBT的一种改进版本。受遗传算法的启发,重组操作被引入到群体中以加速群体向更好的临时最优超参数配置收敛。通过一系列的实验研究证明,本文所述方法可以使模型性能获得进一步的提升。三、提出了一种基于群体的两阶段超参数自适应训练方法。在先前研究的基础上,本文提出了一个猜想:在学习模型对环境知之甚少的早期阶段,频繁的超参数变化对模型的有效学习没有帮助,而使用一组合理的固定超参数配置进行学习将有助于模型尽可能快速稳定地获得必要的知识。本文认为这对于强化学习的早期阶段尤为重要。我们首先通过实验验证了所提出猜想的合理性,在此基础上提出了一种基于群体的两阶段超参数自适应训练方法。实验结果表明,本文提出的方法可以使基于群体的超参数自适应方法获得显著的性能提升。"
393,基于深度学习的遥感图像林地识别技术的研究与应用,"遥感图像来自非接触式传感器对地面的远程探测。基于遥感图像上的光谱等低级特征,可以生成专题图以直观反映地物的空间分布,这一过程称为“遥感识别”或“解译”。由于具有实时性、低成本的优点,遥感识别技术在农业、林业、军事、环境等领域得到广泛应用。林地是一种重要的遥感识别目标,但是其准确识别仍面临一定的困难。首先,由于林种和生长环境的差异,不同地域的林地呈现出不同的图像特征,产生同物异谱现象;其次,受到孤立树木和林地间隙的干扰,细小错分频繁出现。这种现象一方面降低了识别准确性,另一方面使得生成的专题图图斑变得破碎,充满噪声。针对同物异谱现象和图斑破碎现象,本文提出基于深度学习的多林种遥感识别方法,主要工作如下:首先,分析中国林种分布特点并采集多林种数据集,该数据集涵盖了中国常见林种的图像特征。其次,设计基于深度学习的林地识别模型。模型由res-net和res-u-net两个网络级联组成,在对res-u-net的输出进行二值化以生成专题图时,所用阈值根据res-net的输出动态计算得到,从而提升专题图的准确性和连续性。为进一步提升专题图连续性,本文在res-u-net中引入了“多尺度连接”结构,从而提升图像识别的感受野。最后,使用多林种数据集训练模型进行林地识别,并选取度量指标评价林地识别结果的准确性和连续性。实验结果表明,本文模型经过训练能够识别不同地域、不同林种的林地,且所生成的专题图在准确性、连续性方面优于单一 res-u-net模型。因此,数据采集方法及级联模型结构具有可行性,适用于多林种的遥感识别。本文方法能够有效消除专题图上的孤立图斑和空洞,对于林地等面状地物的遥感识别具有参考意义。"
394,基于FPGA的主动式双目匹配算法研究,"随着计算机视觉和人工智能技术的持续发展,3D视觉逐渐成为计算机视觉领域的一个研究热点,如何提供准确、可靠的深度信息是3D视觉技术的一个核心问题。3D视觉技术广泛应用于移动机器人导航、物体识别以及行人跟踪等领域,这些应用领域除了对深度信息有较高的精度要求外,还需要算法具有实时性。本论文以主动式双目匹配算法为研究对象,以提升深度相机输出深度信息的鲁棒性和精度为目标,重点针对聚类算法、双目匹配算法以及算法的FPGA(Field Programmable Gate Array,现场可编程门阵列)设计进行了深入的分析与研究,本文的主要工作如下:1.聚类算法研究。使用机器学习中的聚类算法对双目图像中每个像素点进行分类,提取特征,并映射成二值化的特征向量,再利用特征向量计算代价值。根据双目匹配的具体应用选择合适的算法框架,设计聚类算法流程,优化算法参数,并设计相应的聚类效果评估方法。2.主动式双目匹配算法研究。针对主动式双目匹配算法的特点,选择局部匹配算法作为算法基础,利用视差传播算法提高算法在结构光纹理较弱处(图像边缘、远处物体)的匹配完整度,改进传统亚像素插值使用的双线性插值方法,减少三维点云的分布不均匀情况。3.匹配算法的FPGA设计与实现。主动式双目匹配算法的运算量比较大,一般的运算平台无法达到实时输出深度信息的要求,FPGA有强大的并行运算能力,可以对算法进行加速。针对FPGA运算的特点,对算法进行重新设计,使匹配算法在嵌入式平台上实现实时输出。4.匹配算法精度评估方案设计与实验研究。设计、搭建主动式双目相机图像采集装置,采集数据集。设计能够有效评估主动式双目匹配算法精度的评估方法,评估、对比几种匹配算法的效果与精度。"
395,基于深度神经网络的商品评论短文本情感分析研究,"商品评论的情感走向,直接反映了商品在市场中受欢迎的程度,情感分析可以为公司销售等方面提供了可靠的分析数据。文字表达方式的复杂性导致传统机器学习在文本情感领域的特征提取效果并不尽如人意,需要更优秀的模型来提升性能。论文完成的主要工作如下:1.对数据进行预处理,将汉字符号数字信息化,通过基于多语义的词训练方法修正一词多义的问题。基于TF-IDF方法提取主题词为子任务提供输入支持。经过实验证明该方法可以有效数字化文本信息。2.本文提出了多级Attention机制模型,在模型中主要针对文字级的Attention层,句子级Attention以及段落级的Attention层进行特征提取。实验结果表明模型有效提升了情感分类的准确度。3.模型学习很容易进入局部最优并且在大型语料库中模型训练速度很慢。为了解决这些问题,采用基于Fine-tuning的迁移机制。将已训练成熟的模型参数迁移到本次模型中进行迭代训练,并基于STLR算法对学习率算法进行改进,使模型能够快速收敛。4.评论文本存在重点信息多,表达方式复杂等特性。本文为此搭建了基于Sluice的参数共享网络,进行多任务特征共享,首先在不同数据集上构建多任务模型,然后将隐层学习到的参数进行分块共享,从而使得模型可以学习到不明显或者被忽略的特征信息。融合上述提出的模型结构与提高方法,本文提出了基于TS-BiGRU的深度神经网络模型。经过实验证明该模型在情感分类任务中可以有效提高训练速度和预测结果。"
396,基于深度学习理论的电机故障诊断方法研究,"电机作为工农业生产必不可少的设备,具有十分重要的地位。若电机运行过程中出现故障,不仅造成经济损失,甚至威胁人的生命安全。目前传统的故障诊断方法大多数采用信号处理提取特征向量,提取过程需人为掌握大量的信号处理方法和诊断经验,使诊断过程相对复杂,导致结果误判的可能性增加。因此,将原先对电机的定期检修转变为预知维修,减少维修费用,研究先进的电机故障诊断方法具有重要意义。近年来,由于人工智能发展迅速,深度学习在多个领域彰显了处理复杂任务的能力。本文着重研究深度学习的两种模型,以及该模型在故障诊断领域的应用。主要研究工作和内容如下:(1)系统学习了深度学习的基本理论及常用方法,由于浅层机器学习方法需要大量的先验知识和信号处理理论,泛化能力较弱等,重点研究深度学习中长短时记忆网络与堆栈稀疏自编码器两种模型,论述该模型的基本理论与算法,并通过这两个模型所应用的算法均有效改善传统方法存在的局限性。(2)研究了长短时记忆神经网络:由于在电机故障诊断中采用传统神经网络时存在忽略不同数据之间的相关性,无法学习长期依赖关系,并且在回馈信息的过程中出现梯度消失等问题,将长短时记忆神经网络与Softmax多分类器结合,构建故障诊断模型。根据该网络在提取时间序列特征方面的良好特性,有效提取故障数据特征,并将具有强泛化能力和鲁棒性的Softmax多分类器对其分类,从而识别出三种常见电机故障。通过TensorFlow进行仿真试验,试验结果表明所采用模型的诊断方法优于传统的电机故障诊断方法。(3)研究了堆栈稀疏自编码器:针对采用传统网络易陷入局部最优等问题,根据有标签数据提取故障特征,且实验样本数据量较小,而在电机监测的大数据背景下,浅层网络对于复杂分类问题受到一定约束。因此,应用一种堆栈稀疏自编码器的特征学习方法,该模型由稀疏自编码器组合构建深层次的神经网络,提取故障信号特征,对采集到的数据经过频域变换后作为堆栈稀疏自编码器的输入,与Softmax多分类器结合。最后,通过仿真验证了所应用方法的有效性,且提高了诊断的准确率。"
397,基于机器学习的糖尿病性视网膜病变图像分级研究,"近几年以来,随着人工智能技术的日益成熟,深度学习技术被广泛的应用到人们的日常生活中。其中人工智能与医疗领域的结合成为了研究人员关注的重点,利用人工智能手段帮助医生进行诊断是智能医疗的重要分支。视网膜眼底图作为诊断眼部疾病的重要判断依据,蕴含着许多细微的病症信息,对图片进行准确的分析可以使患者得到及时的救治。利用人工智能手段分析图象不但可以节省培养一位经验丰富的眼科医生所需耗费的大量时间和精力,还可以减轻医患数量不匹配等问题,是一项十分有意义的课题。本文提出了基于机器学习算法的针对糖尿病性视网膜病变图像的分级方法。设计并实现了针对不同容量和不同数据源的两个数据集的眼底图像库的模型分类算法。通过引入分割算法中的形态学从处理方法,改进了小数据集下分类模型的训练效果。利用支持向量机和集成学习的方法对小数据集进行训练。将迁移学习提取的特征运用支持向量机进行训练,实现了神经网络与传统机器学习方法的结合。通过在卷积神经网络模型中引入RMSProp优化算法,解决有偏大数据集的眼底图分级问题。实验内容将针对小数据集分别进行支持向量机和迁移网络的学习训练,并辅以集成学习模型进行补充实验。对于较大的数据集采用深度神经网络模型进行训练,并分为针对经过数据处理后的无偏数据集和未经处理的有偏数据集进训练学习。本实验通过以上模型训练达到对糖尿病性视网膜病变分类的目的。"
398,认知无线电中基于协方差检测的盲感知算法的研究,"随着通信技术和传感器技术的快速发展和广泛应用,可用的频谱资源日益枯竭。认知无线电技术是一种重用可用频谱空洞的方法,能够有效地提高网络的吞吐量,提升频谱的利用率。频谱感知在认知无线电技术中起着重要作用,要求认知用户实时检测授权用户的状态,以便在授权用户不受干扰的情况下,有效使用频谱资源。本文深入研究盲感知算法,从协方差感知的角度出发,提出了优化特征值的感知算法和结合拟合优度检验的协方差矩阵检测算法。本文的主要创新点如下:1、本文分析了典型的基于特征值和协方差矩阵的感知方法。针对传统的特征值感知方法未能充分利用协方差矩阵特征值的信息,限制了其在低信噪比下的检测性能这一问题,本文提出了一种优化的感知方案。该检测方案基于协方差矩阵的最大、最小以及平均特征值来构造新的统计量,其获取到的特征值信息更加完备。与现有方案相比,所提算法的检测性能更优,并且没有增加计算复杂度。2、结合拟合优度算法,本文提出了优化的协方差矩阵感知方法。相比于特征值感知算法,基于协方差矩阵的检测技术具有较好的感知性能。但是,阈值求解过程中的多次近似计算导致了其理论阈值和实际阈值的偏差,影响了其检测效果。为优化这一问题,本文将非参数统计方法应用于协方差矩阵的检测方案中。利用简单处理形成新的矩阵来计算矩阵元素的统计信息;进而,构造新的判决统计量并对统计信息做相应处理;然后,利用拟合优度检验来判定授权用户的状态。与固有的协方差矩阵感知技术相比,本文提出的优化协方差矩阵感知算法更加稳定、有效,但复杂度略有上升。"
399,基于卷积神经网络的车牌识别关键技术的研究与应用,"作为智能交通系统的重要组成部分,自然场景下的车牌识别技术能够为智能交通提供高效、实用的管理方法。对于传统的车牌识别系统而言,算法抗干扰能力有限、鲁棒性不高,在自然场景下出现的光照不均、车牌倾斜、污损以及具有复杂背景的车牌图像等,不能够准确地进行车牌定位与识别。本文针对这些问题进行深入研究。首先,本文提出基于卷积神经网络的目标检测方法对车牌进行定位,并结合车牌定位实际应用对网络拓扑结构进行改进,显著减少了网络参数。手工标注8000张自然场景下车牌图像位置坐标用于网络训练,测试结果表明基于改进卷积神经网络的车牌定位算法具有高准确率和召回率。针对未能成功定位的车牌图像,进行二次强化训练,不断提高网络泛化能力和算法鲁棒性。其次,本文利用改进的车牌定位算法裁剪出车牌图像,同时利用生成对抗网络对车牌图像进行数据增强,避免训练集过少导致网络模型出现过拟合,也提高了网络的泛化能力。算法无需车牌字符分割,直接将车牌图像整体送入识别网络进行特征提取和分类识别。然后,本文结合高阶循环神经网络深入研究ResNet和DenseNet网络拓扑结构,进而提出一个简单、高效和模块化的网络拓扑结构,并基于此拓扑结构提出基于深度卷积神经网络的车牌识别方案。识别网络引入ResNeXt分组卷积结构,同时基于DenseNet的网络拓扑实现密集连接。这种新的网络结构继承了残差和密集连接的优点,并且实现了高效的特征重用和灵活的特征探索。测试结果表明RDNet在复杂自然场景中车牌识别准确率高达99.34%,并且网络具有较强的泛化能力和鲁棒性。最后,本文将训练优化后的定位网络和识别网络串接,进行整体车牌识别测试。整体测试表明自然场景下车牌图像定位成功率可达99.98%,识别准确率可达99.34%,并且每张车牌图像平均识别时间小于0.1秒,可以充分满足实际系统的应用需求。"
400,多卫星导航系统实时精密单点定位数据处理模型与方法,"实时精密单点定位技术(Real Time Precise Point Positioning,RT-PPP)是当前全球导航卫星系统(Global Navigation Satellite System,GNSS)领域的研究热点,也是GNSS技术的重要发展方向。本文围绕RT-PPP数据处理模型精化与方法优化问题,重点开展了RT-PPP周跳探测与修复方法、实时卫星钟差估计与预报模型、区域对流层与电离层误差实时估计与建模方法研究,并研制了一套以RT-PPP为核心的实时精密定位服务原型系统。主要研究内容和成果如下:1)分析了RT-PPP中周跳探测与修复的主要难点,即电离层延迟具有时变特性,导致电离层延迟活跃条件下,窄巷观测值的周跳较难修复。对此提出了基于方差分量估计的自适应Kalman滤波历元间电离层延迟(DID)在线建模与预测方法,通过DID预测值辅助进行周跳探测与修复。利用该方法对双/三频的实际观测数据进行实时周跳探测,结果表明:相对于传统GF与MW周跳探测方法,利用预测的DID值可有效辅助小周跳、大周跳、连续周跳和不敏感周跳的探测与修复,尤其是对窄巷观测值的周跳修复效果更加显著。2)考虑地面监测站(分布与数量)对GNSS卫星超快速轨道确定和实时钟差估计精度和计算效率的影响,论文基于选站构型优劣评价指标,利用格网控制理论与蒙特卡洛随机抽样方法,提出了一种基于监测站空间构型的随机优化选站算法,该算法可实现几何分布和测站质量均占优的测站列表快速自动选取。利用201个IGS站进行实验,结果表明:本文提出的方法较传统格网法可平均提高GPS超快速观测、预报轨道以及实时钟差精度17.15%、19.30%与31.55%;同时,在随机抽样实验次数设置为100000的条件下,当测站数分别为10、50、90个时,相应的选站耗时低于2.22、6.65、14.15min。3)针对RT-PPP中实时数据流存在中断、延迟等问题,提出基于方差分量估计的自适应kalman滤波钟差预报超短期/短期模型;同时,顾及卫星钟差存在的空间和时间相关性,发展了一种利用星间相关性的Kalman钟差预报策略。为验证所提方法的有效性,利用连续27天GBM事后和CLK93实时钟差产品进行预报实验,结果表明:顾及卫星钟差间相关性,在事后钟差预报中可获得较优的结果,如:预报6小时北斗卫星钟差,较传统方法(顾及周期项与趋势项)精度可提高约50.00%。由于实时钟差中卫星间相关性较弱,基于方差分量估计的自适应kalman滤波钟差预报模型在实时钟差预报中性能更优,实时预报1分钟的北斗卫星钟差,较传统Kalman滤波预报精度可提升11.19%。4)针对RT-PPP中天顶对流层延迟(ZTD)参数估计易受水汽变化影响问题,提出了基于方差分量估计的自适应Kalman滤波方法来提高实时ZTD估计精度。基于中国矿业大学北斗分析中心(CUM)平台,利用实时估计的北斗/GPS钟差产品进行了ZTD解算实验,结果表明:(1)方差分量估计方法可动态调整ZTD参数估计中的随机模型,实现待估参数误差的自适应修正;(2)针对对流层延迟变化较快的情况,可抑制异常值的硬性,改善了ZTD估计精度,在实时ZTD解算中更加显著;(3)较传统ZTD估计方法,论文所提方法可提升实时ZTD精度20.7%(GC)、20.2%(G),事后ZTD精度22.1%(GRCE)、21.9%(GRC),18.4%(GR),15.9%(GC),15.2%(GE),12.1%(G)。5)为实现ZTD实时建模,基于上述方法实时估计的ZTD产品,论文利用机器学习方法(神经网络和支持向量机),进行区域实时ZTD建模。利用香港CORS网连续5天北斗/GPS观测数据,构建了该区域实时ZTD模型。以四参数模型为参考对构建的ZTD模型进行了精度评价,结果表明:支持向量机可实现与四参数模型相当的ZTD建模效果(mm级);神经网络、支持向量机、四参数模型建模的平均偏差与均方根误差分别为-2.25mm与9.17mm;对于处于测区平均高程面站点的建模,支持向量机法较四参数模型具有更高的精度和稳定性。6)针对RT-PPP的电离层延迟误差建模问题,本文基于球谐函数模型构建了全球实时电离层延迟误差模型,分析了时间分辨率为5min、15min、30min、1h、2h的小区域(经度差5°、纬度差2.5°)实时电离层变化特征。实验结果显示:电离层在纬度方向上的变化大于经度上的变化;时间分辨率成增倍数增大时,电离层变化量呈相同趋势。同时,为了提高实时电离层延迟误差提取精度,本文对比分析了传统的载波平滑技术与RT-PPP技术,并利用神经网络,支持向量机模型进行了区域电离层延迟误差实时建模。利用香港CORS网连续5天GPS观测数据进行实时电离层建模实验,结果表明:RT-PPP技术较载波平滑技术在提取实时电离层延迟误差方面具有显著优势,且人工智能技术在实时电离层建模方面具有较高的精度。7)为了验证本文提出的RT-PPP数据处理模型和方法,基于CUM平台,设计研制了一套以RT-PPP为核心的实时精密定位服务原型系统。利用i GMAS、MGEX/IGS观测数据实时流,CUM、CNES实时精密产品数据流,对系统的实时位置、大气误差增强服务能力进行了检验,结果表明:系统实现了本文研究的主要模型与算法,运行稳定、可靠。该论文有图114幅图,表37个,参考文献224篇。"
401,基于机器学习的认证码攻击与防御方法研究,"互联网技术的进步促进了信息系统的智能化、自动化的发展,身份认证作为保障信息系统安全的重要防线,被普遍应用于几乎所有的信息系统中。当前,应用于智能手机的图形密码和应用于网站的文本验证码伴随着智能移动终端设备、图像处理技术的进步应运而生,在本文中我们统称为认证码。虽然当前存在众多的新型认证技术,但由于认证码部署简单、成本低廉、易于维护、简单易用等特点,在当前或可预见的未来仍将是最主要的认证方式,尤其在高安全需求的信息系统中,其已成为多因子认证方案中的基础认证方式。自提出以来,认证码的安全性便受到了安全研究人员的高度关注,目前仍然是一个热门的研究课题。虽然有大量的研究工作分析和评估认证码的安全性,但当前认证码在安全性上面临的问题越来越多、安全威胁日趋严重。产生这一现状主要有如下几个原因:(1)现有的研究方法过多地关注于某一种特定的认证码方案,并没有提出通用的安全性评测方法,亦是所需要的条件比较苛刻,难以在真实的攻击场景中生效,因此并没有推动工业界的改变;(2)认证码的安全性研究通常涉及多种学科的知识,如图像处理、机器学习、社会工程学、几何学等;(3)机器学习技术近十年来的发展与突破,给认证码的安全性带来了新的挑战和机遇,而以往的研究工作并没有充分利用机器学习技术的优势,导致研究方法没有很好的与认证码本质问题结合。针对上述问题,本文充分利用了机器学习技术的优势,基于图像处理技术、几何学、深度学习和迁移学习技术,从新的角度和思路对认证码的安全性开展了以下四个方面的研究,主要工作如下:(1)发现了一种新的针对图形密码的视频侧信道攻击方法。视频侧信道攻击由于攻击成本小、攻击能力强、成功率高等优点,受到安全研究人员的青睐。而现有的攻击方法条件苛刻、需要专业设备等缺点,并在真实的攻击场景难以成功实施攻击过程。为此,本文提出根据解锁视频中指尖的运动轨迹来推断用户输入的图形密码。具体地,首先使用智能手机摄像头在任意隐蔽角度拍摄用户解锁视频片段,然后利用目标追踪算法追踪到解锁视频中用户指尖的运动轨迹,最后通过提取运动轨迹的几何特征信息确定用户输入的图形密码。大量实验结果表明,该方法的有效攻击距离在2-3米,并且攻击成功率在95%以上。我们还发现,此类攻击方法更容易破解复杂的图形密码,颠覆了人们对于图形密码安全性的认知,为图形密码的安全性研究提供了新的思路。(2)提出了一种新的基于字符分割的文本验证码攻击方法。现有的基于字符分割的攻击方法只对特定类型的验证码有效,而且需要大量的专家知识用于调整分割参数,这大大降低了攻击效率,并且验证码的微小改进便能够使其失效。本文利用生成式对抗网络,提出了一种字符分割模型。该模型能够使验证码中相邻字符的间距扩大,从而可以对验证码中的字符进行有效地分割。基于字符分割模型,使用不同的机器学习方法构建验证码识别模型。实验结果表明,该字符分割方法能够有效地分割验证码中粘连、扭曲的字符,并且基于字符分割算法所构建的识别模型,能够攻破所有实验中的6种主流网站所使用的验证码方案。(3)提出了一种端到端的基于迁移学习的验证码攻击方法。深度学习技术的突破,使验证码面临新的安全挑战。而现有基于深度学习的攻击方法需要数百万目标网站的真实数据,而收集和标记如此巨大数量的数据变得非常困难,尤其当前几乎所有的主流网站都使用了防爬机制。为了降低攻击成本,本文构建了一种数据生成模型,可以生成任意数量且与目标网站风格类似的验证码,利用生成模型所合成的数据,学习验证码求解器。为进一步缩小生成数据所导致模型过拟合问题,利用迁移学习技术,使用少量的目标网站验证码,对验证码求解器进行微调。实验结果表明,所构建的求解器能够破解当前主流网站所使用的所有验证码方案,并且比现有的方法的破解率平均高40%以上。(4)探索了对于认证码的安全性保护方案。对于图形密码,通过分析当前基于视频侧信道攻击方法成功的关键因素,设计了对应的保护方法。对于文本验证码,提出了一种基于对抗性样本的保护方案,通过在文本验证码中加入不可见干扰噪声,使基于深度学习模型的攻击方法失效。实验结果表明,所设计的认证码保护方案在不影响可用性的同时,能够有效地抵抗现有方法的攻击。"
402,基于深度学习的淡水湿地遥感精细分类研究,"湿地是地球上水陆相互作用形成的生态系统,在维持生态平衡、改善区域气候、调节径流等方面都有不可取代的作用。我国湿地资源丰富,分布着约占世界湿地面积10%的湿地。黑龙江省自然湿地面积约为556万公顷,占全国自然湿地总面积的1/8。随着农业扩张和城市发展以及全球气候变化对水文状况的改变等影响因素的加剧,对湿地生态系统产生了显著的影响,尤其是对淡水湿地的影响更为明显。借助先进的技术手段对湿地植被及其周围的土地利用类型进行适时、动态的监测是十分必要的。本文在总结和评述了国内外在湿地分类方面研究进展的基础上,以黑龙江省的洪河自然保护区和五大连池自然保护区为研究对象,采用高分辨率遥感影像,应用深度学习和复合分类等方法,对淡水湿地进行精细分类。探讨适合在高分辨率遥感影像中分类的最佳模型方法,分析深度学习方法在湿地分类中的优势和不足。论文研究内容和结论如下:(1)卷积神经网络(CNN)在淡水湿地分类中的研究。构建了适合淡水湿地分类的卷积神经网络结构,并与浅层的分类方法在分类精度与分类结果上进行了对比。研究结果表明:CNN作为深层结构的分类器挖掘到了隐藏在高分辨率遥感影像中的复杂空间模式,能够提取到更加丰富的地物语义特征,这些空间模式在浅层结构中不能被发现。但是,CNN分类器对于边界的处理精度不及SVM分类器,分类中会有沿着对象边界的不确定性的现象,从而在一定程度上导致过度平滑。另一方面,在使用CNN分类器中,即使光谱特征显著的物体,但是空间信息很少,也可能会被错误分类。CNN在两个研究分区域的分类精度较浅层的分类方法都有4%-6%的提高,对复杂的湿地植被的识别明显优于浅层分类方法。(2)复合分类器在淡水湿地分类中的研究。对已有的卷积神经网络进行了改进,在全连接层构建多层感知器(MLP),实现CNN特征与MLP在分类模型中的复合,提高模型运行效率。采用决策融合的方法构建SVM-CNN复合分类器,通过对复合分类器阈值的研究使分类结果达到最佳。研究结果表明:SVM-CNN的方法,综合了SVM方法和CNN方法优势。支持向量机法在地物类型边界清晰的分类中表现出极大的优势;例如耕地呈块状分布,它与其他地物之间可以找到明确的边界。相反,沼泽与水生植被之间存在大面积的过渡带,支持向量机很难在这两种地物之间找到严格的分类界限,因而水生植被的分类精度相对较低。CNN方法通过使用多个卷积和池化操作,来模拟人类视觉皮层的工作方式,并通过平移不变性来实现权重共享,从而能够从图像块中提取到丰富而准确的空间特征。因此,CNN分类方法在草地和沼泽的分类精度上都高于SVM方法。且实验结果表明:与CNN分类方法相比较,SVM-CNN对于连续分布的地物类型的分类具有更大的优势。(3)深度学习在不同分辨率影像中的分类研究。通过应用深度学习的方法,对高分辨遥感影像Sentinel-2A在湿地遥感影像的分类研究,进一步验证深度学习分类方法在高分辨率遥感影像分类中的有效性。另外由于Sentinel-2A和GF-2影像的分辨率的差异,研究适宜应用深度学习方法的遥感影像分辨率。研究结果表明:对Sentinel-2A影像直接应用深度学习的方法和提取纹理特征的SVM方法进行分类,深度学习方法并没有体现出较强的优势,主要是由于Sentinel-2A的分辨率不及GF-2分辨率高,不能直接从影像中获得清晰的上下文语义和纹理特征。(4)梳理了深度学习的相关理论,研究适合于湿地遥感影像分类的最佳模型结构和参数,并对过拟合的问题进行了分析。研究了缓解过拟合问题的三种方式――Dropout、全局平均池化层和Dither。研究结果表明:卷积神经网络同时使用Dropout和Dither对分类精度有所提升,并能够有效的防止过拟合。(5)高分二号遥感影像的图像融合方法研究。为了实现湿地植被的精细分类,对GF-2遥感影像分别应用Gram-Schmidt方法、NND方法和HPF方法进行了图像融合,获得适合高分二号影像湿地植被的最佳融合方法,为后续的精细分类奠定基础。实验结果表明:G-S图像融合方法的信息量最大,空间细节的提取更加细致明显。"
403,基于知识图谱的城市轨道交通建设安全管理智能知识支持研究,"城市轨道交通建设工程是一项复杂的、高风险的系统工程,具有建设规模大、参与人员多、技术工艺复杂、施工环境多变等特点,极易产生安全事故。由于安全事故是由各种风险因素共同作用的结果,因此,安全管理需要全面、综合性的知识支持。尽管城市轨道交通建设行业已经积累了大量的数据资料,但是在面临具体安全问题时,如何从众多的数据资料中快速、准确获取所需知识,至今还缺乏有效的解决途径。为了解决上述问题,本文立足于城市轨道交通建设安全管理(URTCSM),从知识支持的角度,引入人工智能领域相关技术和方法,研究基于知识图谱的安全管理智能知识支持理论模型和方法体系。具体内容包括:以系统论为指导,分析城市轨道交通建设安全管理核心任务和管理流程,提出智能知识支持的概念和内涵,研究人工智能领域的知识图谱等技术对城市轨道交通建设安全管理的知识支持作用,构建基于知识图谱的城市轨道交通建设安全管理智能知识支持理论模型。对URTCSM领域知识范围进行界定,从过程、组织、对象、管理等维度对领域知识进行分解,形成多维分层的知识分类体系。在领域概念建模方面,基于领域知识体系结构内容和特点,构建多维分层的专业领域概念模型;根据标准规范自身结构和使用需求,构建混合粒度的标准规范概念模型;根据事故分析对事故知识的需求,构建多主体关联的事故概念模型。在实体关系建模方面,基于领域知识分类体系结构进行概念之间层级关系建模,并对影响城市轨道交通建设工程安全实施的核心要素之间的关系进行建模,形成URTCSM领域知识结构模式,为领域知识图谱的构建提供规范化的知识框架。分析了URTCSM领域知识主要来源,重点对标准规范和事故案例数据进行搜集和整理。在领域实体知识元抽取方面,根据数据结构化程度以及自然语言描述特点,对不同类型实体知识元的抽取分别采用人工抽取、基于映射关系的转化、基于规则的提取、基于深度学习的实体识别等方法。在关系知识元抽取方面,分别采用基于映射关系的转化、基于规则的关系抽取、基于实体共现的关系抽取、基于机器学习的关系抽取等方法。在实体属性识别过程中采用类似的知识元抽取方法。抽取出来的知识元需要与已有知识进行融合,通过分析不同情形下知识融合需求,提出相应的融合方法。知识图谱中各类实体和关系知识元最后以图结构的形式存入图数据库Neo4j中,形成URTCSM领域知识图谱。提出URTCSM智能知识支持实现框架。针对标准规范知识,提出混合粒度规范知识获取的三种方式:知识导航,智能搜索,知识推荐。针对安全事故知识的应用主要以支持安全知识智能分析为主,提出三类事故分析任务:以事故画像的形式全面可视化的展示事故认知结构,根据统计分析指标自动构建查询语句的事故统计分析,以及基于关联路径的事故深度分析。根据URTCSM领域知识图谱中各知识要素之间的联系,对不同管理情境下的安全风险进行分析,为安全风险识别与预防提供知识支持。最后,开发了基于URTCSM领域知识图谱的智能知识支持系统,用于领域知识图谱维护和管理、标准规范知识智能获取、安全事故智能分析、安全管理决策分析等,为安全管理决策提供智能知识支持平台。该论文有图107幅,表23个,参考文献209篇。"
404,基于值函数估计偏差修正的强化学习方法研究,"强化学习是求解马尔科夫决策过程问题的重要方法。强化学习的研究已取得了丰富的成果,特别是自深度强化学习出现以来,强化学习在诸多领域都获得了相当成功的应用。基于值函数的强化学习是其中的一个重要分支,出现了以深度Q网络为代表的一大批经典算法。在迭代求解动作值函数的过程中,都会涉及到最大期望动作值函数的估计问题,与此相伴的是存在其中的估计偏差问题。这个问题同样也存在于机器学习的其它领域中。因此,对最大期望值的准确估计是个非常重要的问题。本文围绕值函数估计偏差修正问题展开研究,主要内容如下:(1)针对Q类学习算法高估、DQ类学习算法低估的问题,研究了最大期望值估计偏差产生的原因,并提出了相应的偏差修正思路。首先,提出了次序估计量,并对次序估计量的估计偏差进行了分析,使得现有的最大期望值估计方法均可视为次序估计量的组合形式。其次,分析了现有估计方法存在高估低估的原因,重点对最大估计量和双估计量的优势与不足进行了分析。最后,得出结论:单纯用某一个次序估计量参与值函数更新都会带来不同程度的估计偏差,有控制地随机组合多个次序估计量能有效修正估计偏差。本部分内容为后续研究工作提供了直接的理论指导。(2)以构造无偏估计量为目标,从随机并可控这个角度入手,提出一种基于集成双估计的偏差修正强化学习方法。首先,设计了一个集成双估计量,并从理论上证明存在合适的参数使该估计量无偏。其次,将集成双估计量用于强化学习值函数更新算法,分别提出了集成双Q学习算法和集成双深度Q网络算法,并从理论上证明了集成双Q学习算法的无偏性和收敛性。所提算法基于有随机特点的双估计框架,在使用最大化估计操作去评估动作的同时可控地加入双估计操作,避免了单独使用一个估计量时存在的高估或低估现象。(3)针对由于确定性选择值函数进行估计所导致的估计偏差问题,从随机选择的角度入手,将最大期望动作值的估计问题视为估计量的“选择”问题,提出一种基于随机选择估计策略的偏差修正强化学习方法。首先,设计了随机选择估计量,并从理论上证明了该估计量的无偏性。其次,将该估计量应用于强化学习算法设计,分别提出了基于随机选择估计策略的双Q学习和随机双深度Q网络。然后,对所提算法中的关键参数进行了研究,分别针对期望可求和期望不可求两种情况设计了参数的计算公式。最后,从幕随机选择估计的角度提出了幕随机双深度Q网络。(4)动作的探索和利用一直是强化学习的关键问题。智能体既要充分利用最大值动作,又要探索潜在的最优动作。通过分析,值函数估计也存在类似于动作选择的不确定性,既要利用已有的最优值函数,也要探索未知的值函数,以达到修正估计偏差的目的。因此,受动作的探索和利用启发,把对最大期望值的估计问题转化为对值函数的有效探索问题。从值函数有效探索这一全新的角度展开研究,提出了基于值函数探索奖励的贝叶斯深度Q网络。首先,以捕获值函数的不确定性为目的,在深度Q网络最后一层使用贝叶斯线性回归,构造一个值函数探索奖励项。然后,将该探索奖励项加入原值函数,构造出具有探索特点的新值函数。最后,在估计最大期望值时,用新值函数进行动作选择,用原来的值函数作为最大期望的估计。所提算法兼具了动作探索和值函数探索,有效平衡了估计偏差。(5)在贝叶斯深度Q网络中,用于计算目标值的动作来自后验分布的随机抽样,导致目标值的计算具有较大的波动性。为了增加贝叶斯深度Q网络的稳定性,将集成双估计方法及随机选择策略方法分别用于贝叶斯深度Q网络中目标值的计算,将后验分布均值用于目标值的计算以提高目标值的稳定性。基于此,分别提出了基于集成双估计的贝叶斯深度Q网络和基于随机选择估计策略的贝叶斯深度Q网络。在格子世界和雅达利游戏上的仿真结果表明,所提新算法能有效消除值函数估计偏差,提高学习性能,稳定学习进程。该论文有图28幅,表5个,参考文献114篇。"
405,稳健的特征表示学习方法及应用,"近年来,大数据话题备受人们关注。大数据不局限于数据量之大,而在于隐藏在数据背后的数据价值。如何挖掘大数据中存在的规律,为人们提供有价值的信息,是大数据研究领域面临的挑战之一。为在给定的数据样本上准确地进行推理和预测,需要找到数据合适的特征表示,从而有效地对数据的底层结构进行建模。模型应能反映简洁的全局结构,捕捉数据的表现,并对噪声具有较强的稳健性。寻求数据特征表示的前提是现实世界中的大多数数据具有各自丰富而特有的结构,而如果数据分布是任意的,那么特征表示学习将是不可行的。同时,现实中采样的数据总是有限而且通常含有噪声,这就需要解决如何选择和设计合适的模型和正则化技术。本文通过结合图嵌入,低秩分析,自表示学习,类内与类间关系方法,以描述样本关系为核心,提出了两种无监督特征表示学习方法和一种监督特征表示学习方法,并将其应用在模拟数据、图像数据和生物数据中。通过与最先进的方法对比,验证了本文提出的特征表示方法的有效性。本文主要工作包含以下几个方面:1.提出基于低秩图优化的多视角数据维数约简(Low-Rank Graph Optimiza-tion for Multi-View Dimensionality Reduction,LRGO-MVDR)。基于 图的降维方法在分类和聚类等任务中得到了广泛关注和应用,然而,大多数该类方法只适用于一个视角中的数据。虽然研究者们提出了各种基于多视角的降维算法,但其中使用的图构造策略没有充分考虑到噪声和多个视角间的不同重要性,这将会大大降低算法的性能。LRGO-MVDR方法首先以单个视角的数据样本构建相似度矩阵,并基于构建的多个相似度矩阵构造了一个低秩共享矩阵,以及分别对应于每个视角潜在的噪声的稀疏误差矩阵。其次,通过学习自适应非负权向量来探索各视角之间的互补性。此外,基于交替方向乘子法(Alternating Direction Method of Multipliers,ADMM),提出了一种有效的优化策略。最后,基于低秩共享矩阵采用图嵌入技术对数据进行降维,得到了关于数据特征新表示。2.提出稳健的内积正则化无监督特征选择(Robust Inner Product Regularized Unsupervised Feature Selection,RIRUFS)模型。该模型利用自表示学习描述样本间的相似度关系,以样本相似度关系和样本标签指示向量的差异构造谱聚类模型,并将自表示学习、谱聚类和特征选择结合到统一的框架中。这样,RIRUFS可以很好地揭示数据的底层多子空间结构,并迭代学习最优相似矩阵和标签矩阵。其次,通过在目标函数中引入内积正则化项,使得我们所选择的特征具有独立性和低冗余性。此外,提出了一种有效的迭代更新优化算法来求解RIRUFS模型。此模型得到的特征选择矩阵能够反应出数据的特征重要程度,因此按照重要程度进行特征选择可以忽略对聚类性能影响较小的特征和噪声,起到对噪声的稳健性作用。3.提出了一种新的基于类的局部特征选择(Class-Specific Guided Local Fea-ture Selection,CSGLFS)模型。该模型源于高维数据的每个类样本构成的区域都有独特的最优判别特征子集。现有方法简单地为所有类选择相同的特征子集来表示高维数据。CSGLFS方法中,特征子集学习了局部的变化,使得高维数据在最优特征子集对应的投影空间上更加清晰的描述了类内样本和类间样本的关系。我们还出了适合于此方法的弱分类器来描述测试数据与每个类的相似性,更加准确的对测试数据分类。此外,我们的CSGLFS方法被有效地表示为一个线性规划问题,极大的简化了求解过程。通过观察所选择特征的数量对模型过拟合问题讨论。对于分类问题无关的特征,我们以低概率选择该特征,并且分类准确率在会随着维数的增加达到一个稳定值。"
406,精神分裂症脑网络与模式识别,"作为临床上的一种慢性且致残率高的精神疾病,精神分裂症给患者及其家庭乃至社会带来了沉重的经济负担。精神分裂症的临床表现包括了以幻觉妄想为主的阳性症状和动机缺失认知损伤为主的阴性症状。目前的发病机制尚不清楚,临床上没有可靠的生物学标记物来及时发现和诊断患者,对患者的治疗也缺乏可靠的参考标准。近年来,功能磁共振技术为研究精神分裂症的发病机制提供了一个有力的工具。当前静息态功能磁共振的研究发现,精神分裂症是一种弥散至全脑的功能连接异常的疾病。但是,目前的研究结论并不十分一致。本文利用静息态功能连接来研究精神分裂症异常的脑网络,借此来研究精神分裂症的发病机理,并探究功能网络的异常是否能作为生物学标记物来辅助临床诊断疾病。除此之外,研究当前的药物治疗对这些异常功能连接的作用,探究功能网络的异常能否预测药物治疗的疗效。本文的主要内容包括:1.精神分裂症被认为是全脑范围内的功能连接出现异常,不同的大脑子网络的异常是不同的,究竟是哪个网络的异常最显著以及脑功能网络能否作为生物学标记物来辅助临床诊断病人还不清楚。在本章中,我们结合机器学习中的集成学习算法,利用静息态全脑功能网络作为特征区分精神分裂症患者和正常对照,并且得到患者相比较于正常对照差异最显著的脑网络。相比较于传统的机器学习方法,集成学习表现出更好的分类能力(分类正确率84.7%,敏感性91.9%,特异性74.5%,置换检验p"
407,基于集成机器学习模型的分子激发能含时密度泛函理论计算精度研究,"分子激发能的研究是理论计算化学研究中的热点和难点之一。由于激发能包含分子的内在结构信息和电子性质,精确地预测包括电子跃迁吸收能与发射波长在内的分子激发态性质已然成为理论计算化学领域的关键问题研究关注之所在。经过多年研究和应用,量子化学方法现今已经超过仅能在理论上定量验证实验现象的水平,并发展成为可以在某些分子属性实验值无法获取或不准确的条件下准确预测物质基态、激发态性质和化学反应现象等。然而,并非全部计算结果均可与真实实验值精准相符,特别是对于较大分子的激发态有关的计算。这是由于对于复杂分子或大分子体系的激发态性质的计算复杂度高,尤其是当要保证一定精确度时的计算尤为耗时。实际实验条件下计算资源的局限性以及计算方法自身的固有近似性成为导致这种现象的主要原因。人工智能方法为解决这些问题,提供了一些简单而有效的策略来校正理论计算的误差,从而提高理论计算方法的准确性并拓展其应用范围。本论文将机器学习集成算法与量子化学计算方法相结合针对分子激发态的计算效率和准确性对计算结果加以改善。首先,基于AdaBoost和Bagging两种典型的机器学习集成架构建模,并将其应用于包含433个有机分子的数据集以期提高密度泛函理论计算电子光谱吸收能的精度。然后,再次将此二种集成模型应用于包含了113个荧光分子的数据集以提高荧光发射波长的回归精度。上述研究工作采用的方法,为分子性质的准确预测提供了一种有效且高效的替代途径,提高了理论方法的可靠性并扩展了其适用范围。本论文的研究工作可概括描述为如下几个部分:1.采用含时密度泛函理论(Time-Dependent Density Functional Theory,TDDFT)量子化学方法和机器学习结合的策略,提出了准确、稳健、高效的吸收能计算集成校正模型。该模型由集成了支持向量机(SVM)、广义回归神经网络(GRNN)和随机森林(RF)为基学习器回归方法的AdaBoost框架建立。通过该集成模型的校正,吸收能的TDDFT(TDB3LYP/STO-3G,6-31G*,6-311G**)计算结果精度得以明显改善。其中,最小STO-3G基组上的计算吸收能平均绝对误差(Mean Absolute Error,MAE)和均方根误差(Root Mean Square Error,RMSE)分别由0.62和0.79 eV降至0.11和0.14 eV。校正模型的验证参数可达R~2(0.97)、Q~2(0.98)、Q_c~2 _v(0.99),说明了较好的拟合性和预测性能。研究显示,所提出的集成校正模型仅需基于最小基组的TDDFT计算,就可以达到较高的大基组水平的精度,同时模型的计算时间与TDDFT计算时间相比,花费极小。2.探究基于线性拟合余弦夹角距离集成规则的回归模型,该模型建立在Bagging框架上,集成了包括GBDT、GRNN、ELM、RF与SVM在内的多种基机器回归学习方法。在该Bagging框架下,集成校正模型具有处理高维数据和较强泛化能力的优点,可以显著改进TDDFT的激发态计算。为求取高精度计算结果,同样仅需最小的计算资源(TD-B3LYP/STO-3G),吸收能(λ_(max))回归结果的MAE和RMSE即可分别从0.62减少到0.09 eV和从0.79到0.12 eV。此外,由于本研究提出的集成方法是基于加权平均Bagging算法将多种基学习器回归模型结果集成,其时间复杂度实际上与单基学习器算法相同,在保证极高精确度的同时亦具有高效性,比AdaBoost模型更为简洁。这表明Bagging集成可以作为降低昂贵计算成本而建立的较好校正模型工具之一。3.鉴于以上AdaBoost与Bagging集成模型对于吸收能计算结果的成功校正,尝试进一步将二者应用于包含113个近红外荧光分子的162个样本的数据集,对发射波长的计算精度进行校正。实验结果表明,集成模型可将TDDFT/STO-3G计算的发射波长的MAE值与RMSE值分别从1.094降低到0.014eV和从1.375降低到0.017eV。进一步证明了集成模型的适用性与有效性。"
408,基于机器学习的非共价相互作用计算精度研究,"非共价相互作用(Non-covalent Interactions,NCIs)又称弱相互作用,这些弱相互作用几乎无处不在,并且在环境、化学、材料以及生命等多个学科领域的研究中扮演着极为重要的角色。非共价键是与共价键相对而言的,不同之处在于其形成过程中不存在电子的共用,但包含了不同属性的、复杂的相互作用,常见的如氢键、范德华力、色散力、π-π相互作用以及卤键等。NCIs涉及到广泛的、与不同尺度分子体系有关的实验现象,特别是对于存在着大量NCIs的大分子体系的研究非常重要。因此,研究非共价相互作用,对环境污染的预防和治理、超分子化学的研究、分子的识别和组装、材料的光电性及导电性和生物大分子稳定性和识别过程等方面具有重要的理论和现实意义。由于NCIs的复杂本质,我们对NCIs认识还相当有限,对精准的NCIs的实验和理论研究工具的需求依然迫切。目前,获得非共价相互作用的方法有实验方法和理论计算方法。实验方法包括红外光谱法,核磁共振法等。通常实验方法准确度较高,但都需要精密昂贵的实验仪器,复杂的实验过程和较多的人力资源,对于大分子来说不易操作。理论计算方法中较为准确地计算方法是基于第一性原理的量子化学计算方法,它包括从头计算、密度泛函理论、微扰理论等。理论计算方法与实验相比,可以大幅节省时间和资源,但目前要达到准确计算的花费也是非常昂贵的,尤其对于大分子来说。近年来,人工智能的再次兴起,为理论化学计算方法的提高和改进提供了新途径,从而为解决非共价相互作用理论计算中难度比较大的问题提出相对简单、高效的新方案。本文针对非共价相互作用的量子化学方法计算精度的提高和预测模型进行了研究,主要成果如下:(1)提出了一种针对小型化学分子数据库的“基于相关性和差异性混合距离的数据集划分方法(HSPXY)”。数据集划分方法的使用,对于基于规模较小数据库建立的模型性能影响很大。数据集划分方法主要分为两类:基于聚类和基于统一分布的方法。通常情况下,基于统一分布的数据集划分方法简单易用,但不考虑样本之间的相关性。因此,有可能不能正确地分配距离较远但相关性很大的样本。在常用的联合x-y距离的数据划分方法(SPXY)的差异距离基础上,充分考虑选取的数据集中样本之间相关性对模型构建的影响,本文提出了一种改进的基于相关性和差异性混合距离的数据集划分方法HSPXY。为了验证其有效性,该方法在小型化学数据库上与一些现有的经典数据划分方法进行比较,使用偏最小二乘方法建立回归模型。与其他同类划分方法相比,基于HSPXY数据划分方法选取了最具有代表性的训练集,构建的回归模型获得了更小的均方根误差和更高的相关系数。这表明该方法为获得具有代表性的训练集提供了一个新的思路。(2)提出了一种“基于非共价相互作用数据库的集成学习通用框架”。准确的NCIs计算对于第一性原理方法要求很高,对于这些方法,合理的机器学习模型可以成为以最少计算资源获得高精度NCIs值的有效解决方案。因此,本研究通过对量子化学计算得到的非共价相互作用分子的化学性质构建定量构效关系(QSAR)模型,探讨了三种不同类型的集成学习对NCIs校正和预测问题的研究。针对Bagging和Boosting类型,我们选择已有的且具有代表性的集成学习方法,随机森林和梯度提升树构建回归模型。在Stacking类型中,我们首先使用五种不同类型的特征选择方法构建特征子集,用于构建多样性的基学习器,然后将基学习器的输出作为元学习器的输入进行回归建模。根据选择的基学习器的差异,得到同质Stacking(Homo-SE)和异质Stacking(Hete-SE)两种集成模型。考虑到模型性能对基学习器数量和类型的敏感性,我们通过构建多个回归模型对其分析并优化该参数。经过实验分析表明,集成模型在基准数据集上的结果明显优于单一机器学习方法。尤其是Hete-SE方法,在所有方法中表现最好。最后,根据实验结果总结设计出一种针对非共价相互作用数据库的通用集成学习框架。(3)为了进一步提高非共价相互作用的预测精度和减少人为干预的特征选择,首次提出了“融合策略的3D-CNN深度学习框架DeepNCI”并开发了DeepNCI工具包。DeepNCI以分子的电子密度和传统量子化学计算的化学性质作为输入,分别通过多层卷积神经网络和普通神经网络进行特征抽象,避免了人工干预的特征选择。对输出的两种抽象特征进行融合输入到全连接的神经网络层用于最终NCIs的预测。我们在基准数据集上对DeepNCI进行了测试,实验结果表明DeepNCI方法优于现有最优方法。通过对原始特征和抽象特征T-SNE可视化对比,显示出DeepNCI网络可以检测到非共价相互作用相似样本的相似特征和不同样本的判别性特征,即卷积神经网络可以在一定程度上捕获与非共价相互作用相关的特征。具有电子密度输入的深度神经网络结构突破了大分子预测NCIs的泛化极限,为外推分子系统获得合理的NCIs提供了可能。此外,为进一步的应用程序定义了DeepNCI模型的适用性领域,并且判断了基准数据库中所有测试样本都属于应用程序领域。为了测试DeepNCI的可迁移性,使用迁移学习方法将DeepNCI框架应用于只包含几十个样本的均裂能小数据库上。利用均裂能与非共价相互作用问题的性质一致性,迁移学习方法很容易应用于DeepNCI框架。实验结果显示,采用迁移学习训练的DeepNCI模型实现了与其他方法相当的预测能力,验证了该模型的可迁移性。"
409,基于机器学习的赖氨酸翻译后修饰位点的计算预测与分析,"蛋白质是一种有机大分子,是生命的物质基础,是构成细胞、承载生命活动的基本有机物。在蛋白质翻译过程中,氨基酸相互连接形成肽链,肽链经过螺旋、卷曲、折叠,形成前体蛋白。然而前体蛋白不具有活性,只有通过一系列的翻译后加工及修饰,才能获取生物学功能,这种化学修饰叫蛋白质翻译后修饰。蛋白质翻译后修饰类型多种多样,例如在蛋白质中加入各种官能团,化学键或者其他肽链等,蛋白质翻译后修饰在细胞功能和生物进程中起着重要的调控作用,例如蛋白质翻译后修饰可以调控细胞对外界环境的应答。一些研究表明,翻译后修饰的蛋白质所处细胞环境不同,其功能也有所不同,且翻译后修饰位点的异常和变异与疾病和癌症有密切的联系,因此对翻译后修饰位点的预测分析,了解不同细胞环境下其生物进程和机制是蛋白质组学研究中的重要课题。相较于传统的实验预测方法,计算预测方法因其简便、快速的特性,成为在蛋白质翻译后修饰识别问题中常用的方法。赖氨酸是一种由密码子AAA和AAG编码的α-氨基酸,化学式为HO_2CCH(NH_2)(CH_2)_4NH_2,它是人体20种常见氨基酸中的一种。由于赖氨酸的特殊分子结构,它在翻译后很容易被修饰,并且发生在赖氨酸上的翻译后修饰类型有很多。针对赖氨酸上可发生的三种翻译后修饰(琥珀酰化修饰,甲酰化修饰和戊二酰化修饰),提出并创建新的基于机器学习的计算预测方法,有效地提升了对三种翻译后修饰位点的预测准确率,并对这三种翻译后修饰蛋白质数据进行蛋白质组学分析,挖掘其潜在的功能及特性。主要研究内容如下:(1)提出两种新的琥珀酰化位点预测方法,其中一种基于双层支持向量机分类器的集成学习的琥珀酰化位点预测方法―PSuccE,另一种为结合半监督学习方法和K均值聚类算法的琥珀酰化位点预测方法―SSKM_Suc。为了解决正负样本不平衡问题,PSuccE使用Bootstrap Sampling策略提取不同的负样本子集,与正样本集结合,形成多个不同的训练样本子集。在每个数据子集内,融合多种序列特征编码方式,采取基于信息增益的两步特征选择方法,从整体特征空间中筛选最优特征子集进行建模。然后以所有预测模型的预测结果为新的特征,训练一个新的支持向量机分类器,作为最终的预测分类器。与其他预测器在独立测试集上进行预测性能比较,结果表明PSuccE的预测能力明显优于现有方法。对特征及方法步骤的分析表明,本研究采用的特征可以有效地反应琥珀酰化位点的特性且双层支持向量机分类器的集成学习可以全方面有效地提高分类器的预测性能。SSKM_Suc通过融合邻近翻译后修饰信息和多种序列特征,建立新的赖氨酸琥珀酰化预测工具。采取K均值聚类算法对数据集进行处理,将数据分成5个聚类,对每个聚类采用基于随机森林的两步特征选择策略去除冗余特征,获取最优特征子集。在每个聚类内,基于半监督学习方法根据正样本信息从非琥珀酰化样本中选择与正样本数量相同的可靠负样本,最后利用支持向量机分类器进行建模。同现有预测器的预测性能比较分析表明SSKM_Suc具有更良好的预测性能。邻近翻译后修饰信息的分析结果显示琥珀酰化修饰和乙酰化修饰及泛素化修饰可能存在相互依赖关系,且+7位置和-4位置的琥珀酰化修饰可能对中间赖氨酸位点琥珀酰化的形成产生一定的影响。通过对琥珀酰化蛋白质的KEGG分析,进一步验证了蛋白质琥珀酰化修饰对氨基酸降解和脂肪酸代谢有潜在影响,并且分析推测蛋白质琥珀酰化可能与亨廷顿疾病、帕金森疾病、阿尔兹海默症疾病等神经退行性疾病的发生有密切的关系。(2)针对蛋白质甲酰化位点预测问题提出一种结合半监督学习与K近邻算法的预测方法―dForml(KNN)-PseAAC。赖氨酸甲酰化是一种重要的翻译后修饰,由于现今数据库中记录的赖氨酸甲酰化数据数量较少,因此还没有建立对其预测的计算方法,据此提出一种基于半监督学习与K近邻算法的预测方法。dForml(KNN)-PseAAC根据信息熵,选择离散窗口对蛋白质序列进行截取,并采用三种有效的序列特征编码方法提取蛋白质甲酰化位点及非甲酰化位点周围的特征信息。该方法提出一种半监督学习方法选择更可靠的非甲酰化样本作为负样本进行建模,既准确地解决了正样本与负样本之间的严重失衡问题,也保证了预测模型的性能。对预测结果的比较分析验证了K近邻算法比其他常用机器学习算法更适合甲酰化位点预测,并且可以高效地从蛋白质中预测出甲酰化位点。通过对甲酰化蛋白的Gene Ontology分析,推测蛋白质甲酰化与蛋白质合成之间可能存在关联性。(3)提出一种新的蛋白质戊二酰化位点预测方法―DEXGB_Glu。DEXGB_Glu以极端梯度提升算法(XGBoost)作为分类器,并且用差分进化算法(DE)对XGBoost算法中的参数进行寻优。该方法采用多种序列特征提取蛋白质中赖氨酸位点周围能有效区分戊二酰化位点和非戊二酰化位点的信息。针对正负样本比例不平衡问题,首先应用Borderline-SMOTE(Borderline-Synthetic Minority Oversampling Technique)过采样方法合成正样本,扩充正样本的数量,使之与负样本数量相同,然后采用Tomeklinks方法对合并后的训练集做数据清洗,去除可能为噪音的数据。对预测方法及预测结果的分析表明差分进化算法提升了XGBoost的分类效果,Borderline-SMOTE结合Tomeklinks方法既解决了正负样本不平衡问题,也提高了DEXGB_Glu的预测准确性,显著优于现有的其他几种蛋白质戊二酰化预测工具。"
410,基于机器学习的煤岩显微图像分析研究,"我国能源富煤、贫油、少气的基本特点决定了短期内难以改变以煤炭为主体的能源结构。同时迫于环境污染和能源枯竭的双重压力,使煤炭的清洁、高效利用成为当下研究的热门问题。其中,针对煤岩显微组分分析、分离的研究日益增多。煤岩显微组分与煤的物理、化学及工艺性质等有直接关系,影响着煤的气化、液化、焦化等性能,也是分析煤的成因和地质条件的重要依据。因此,煤岩显微组分分析具有重要研究意义和应用价值。然而,目前煤岩显微组分分析存在着主观性强、耗时、耗力、专业化程度高等问题,严重制约了煤岩学在各领域的应用。本文针对上述问题,在机器学习和图像处理最新研究成果的基础上,研究了煤岩显微图像质量提升、煤岩显微组分识别、平均最大镜质组反射率估计以及基于深度学习的煤岩显微图像语义分割等问题。具体内容如下:针对低对比度和模糊的煤岩显微图像,采用基于Gamma校正的图像增强算法,有效提升图像对比度和视觉效果,同时有利于后续的图像分割和图像识别。针对煤光片制作过程中因研磨、抛光等操作导致的划痕问题,提出一种基于Hough变换和Criminisi算法的划痕检测和修复方法,有效修复煤岩显微图像中的划痕并保持纹理信息的完整性。针对煤岩显微组分识别主观性强且需要测定者具有较好的煤岩学基础的问题,提出一种基于图像分割和图像分类的煤岩显微组分识别框架。鉴于煤岩显微结构的复杂性和非均质性,首先采用由粗及细的煤岩显微图像聚类分割算法将图像分割成一系列只包含单一组分的区域,然后采用随机森林并结合几何、灰度和纹理特征实现对背景树脂以及7种显微组分的自动识别,这些组分包括镜质体、丝质体、半丝质体、角质体、孢子体、碎屑惰质体和微粒体。实验结果显示所提方法的识别准确率达到90.44%,为后续煤岩显微组分分析奠定了基础。另外,为了协助煤岩工作者进行煤岩分析,发布了首款公开的煤岩显微组分识别软件,下载地址为:https:/github.com/GuyooGu/MISC-Master。针对镜质组反射率测量操作过程繁琐、耗时耗力和对测定条件要求高等问题,提出一种基于机器学习的全自动平均最大镜质组反射率估计方法。考虑到煤岩显微图像中显微组分种类不确定的问题,首先采用自适应K-means聚类分割算法自动检测聚类个数并完成分割,然后利用SVM结合复合特征完成镜质组区域的识别,对每幅图像中识别出的最大镜质组区域进行网格化处理,得到一系列方形镜质组区域,并进行后续的回归分析。实验结果显示该方法能准确快速地测定平均最大镜质组反射率,预测结果和参考值之间存在较强的相关性,验证了基于机器学习的平均最大镜质组反射率估计方法的有效性。为了协助煤岩工作者开展镜质组反射率分析,发布首款免费公开的镜质组反射率分析软件,下载地址为:https://github.com/GuyooGu/MMVRML。针对传统图像分割算法适用性有待提高的问题,将基于深度学习的图像语义分割算法引入到煤岩显微图像分割中,该类算法能够自动学习合适的特征进行分割,可以实现端到端的学习。实验共对4种基于深度学习的语义分割模型进行评估,结果显示基于Unet系列的语义分割方法在煤岩显微图像分割中性能最优,分割效果接近于人工标注结果,验证了基于深度学习的语义分割算法在煤岩显微图像分割中的有效性。本文的研究综合了煤岩学、图像处理和机器学习等多门学科,产生的研究成果能够丰富图像处理和机器学习在煤岩显微图像分析中的相关理论和应用,能够有效提高煤岩自动分析的效率和准确性,极大推动煤岩学在煤加工等各领域的推广和应用,具有重要的理论意义和实践意义。该论文有图69幅,表15个,参考文献145篇。"
411,基于内镜图像的消化道病变自动识别与注释方法研究,"消化道病变的内镜诊断一直是临床上的一个难题。人工诊断过程易受多种负面因素的影响,例如医生的经验不足、疲劳、诊断时间的限制、巨大的图像基数以及复杂多变的病灶外观等。因此,借助计算机技术,基于内镜提供的影像信息发展消化道病变辅助诊断方法,将对现有内镜诊断提供有力的补充,有利于降低消化道病变的漏诊和误诊,提高诊断效率,具有十分重要的科学意义。为此,本文对病变图像自动识别和病变区域自动注释方法进行了深入研究。主要研究内容如下:(1)基于机器学习特征和传统特征结合的消化道内镜病变图像自动识别方法研究。提出了结合机器学习特征和传统特征识别病变图像的新思路。在机器学习特征的提取上,设计了一种新的联合对角化算法,该算法无需迭代、求逆和取近似等操作,解决了传统联合对角化算法速度慢和精度低的问题,大幅提升了对角化运算的精准度与速度。以上述联合对角化算法为基础,对非对称主成分分析算法(一种传统的机器学习算法)进行了改进,在充分保留其特征提取性能的同时大幅减少了原有算法的计算量。此外,使用了颜色聚合向量算法提取图像的传统颜色特征。结合上述两种特征,发展了一种从大量内镜图像中自动识别病变图像的方法,并在具有1330张内镜图像的数据集上进行了实验验证。结果表明,该方法识别食管早癌和胃早癌图像的受试者工作特性曲线下面积分别达到了0.9471和0.9532,识别小肠出血图像的曲线下面积达到0.9776,优于基于颜色纹理特征的传统识别方法。(2)基于两级视觉显著性的消化道早癌区域自动注释方法研究。首先对传统注释方法采用的注释框架进行了改进,提出了利用内镜图像的两级视觉显著性对上消化道早癌区域进行“两步注释”的新思路。同时,对传统的图像分割算法SLIC(Simple Linear Iterative Clustering)进行了改进,减少了其计算量并使其能够适应任意形状区域的分割。基于上述改进,发展了一种消化道早癌病变区域注释方法。该方法在具有871张食管早癌内镜图像的数据集上达到了97.24%的早癌检出率,注释结果与医生标注结果的平均Dice相似度系数达到了75.15%,优于现有其他方法。而且该方法还具有更少的假阳性输出以及更快的运行速度。此外,该方法还能够较好地改善传统方法在小病灶上检出率和注释准确率偏低的问题。(3)基于深度信息与深度学习技术的消化道早癌区域自动注释方法研究。首先提出了将原始RGB图像与深度信息结合辅助语义分割的新思路,并将现有的语义分割网络:Deeplabv3+改进为4通道模式,增强了其语义分割能力。然后根据上消化道早癌诊断的实际临床需求,设计了一个后处理步骤对注释结果进行优化,使最终结果获得了更好的视觉效果,更容易被医生所接受。基于上述改进,最终发展了一种基于深度信息与深度学习算法的早癌病灶区自动注释方法。采用4231张食管早癌内镜图像对该方法进行了实验验证,得到了97.54%的早癌检出率以及74.43%的平均Dice相似度系数。与其他基于深度学习的方法相比较,该方法具有更好的注释性能和更少的假阳性输出,证实了该方法的有效性和可行性。本文设计的消化道内镜病变图像识别方法和早癌区域注释方法具有良好的性能,有利于减少上消化道早癌等病变的漏诊率,提高临床内镜诊断的效率和准确率。其中的早癌病变区域注释方法还能够辅助临床上的内镜黏膜切除术和内镜下黏膜剥离术。因此本文方法具有良好的临床应用价值。"
412,无线通信射频发射机非线性特性研究,"移动通信系统持续向高速率、大容量和超宽带方向发展,随之产生的新技术所处理的信号都具有多载波、多电平、超高带宽及高峰均比等诸多特点,对所使用的射频发射机提出了巨大的挑战。一方面,大带宽信号激励下的发射机呈现出更强更深的非线性记忆特性。另一方面,射频发射机系统不可避免地会同时受到调制器I/Q支路不平衡、本振泄漏和功放非线性失真等非线性特性的影响,同时这些不同的非线性特性相互交叉作用,会严重降低通信系统的性能。因此,研究新型宽带高效线性发射机,使无线宽带传输射频前端在满足系统严格的线性等指标下高效率工作,是解决未来无线通信可靠传输的核心技术。针对上述要求,本文首先运用信号处理领域的压缩感知理论和自适应信号处理算法以及人工智能领域的机器学习理论,围绕宽带发射机非线性特性辨识及联合补偿的若干问题进行了深入的研究和具体的探讨。其次,为提升大带宽信号激励下的发射机线性和效率,提出了一种基于三输入联合模型的发射机联合补偿方案,充分提升了发射机联合补偿的失真抑制能力。本文主要工作和贡献如下:1、提出了一种基于压缩感知理论和自适应信号处理算法的自适应稀疏预失真器设计方法。针对传统的压缩感知功放模型简化算法固有的批处理操作模式,研究了压缩感知贪婪算法和自适应信号处理理论的融合方法,构建了一种宽带自适应稀疏预失真系统,并分别使用共轭梯度和随机梯度下降算法结合子空间追踪贪婪算法设计了稀疏自适应参数更新算法。仿真和实验结果表明,所提算法能够有效地构造只有少量参数的稀疏自适应预失真器,在预失真系统中功放的非线性失真和记忆效应可以自适应地获得补偿。与非稀疏全模型预失真技术和批处理模型删减方法的比较证明,所提算法具有更快的收敛速度,在提高了跟踪能力的同时降低了原始模型60%以上的参数个数,充分验证了所提自适应稀疏方法的优越性。2、提出了一种基于机器学习理论中稀疏主成分分析方法的功放模型简化方法。该方法可以在不损失信息的情况下对发射机行为模型进行线性变换实现数据矩阵降维,并通过对模型从高维到低维的变换实现模型系数的减少,同时引入稀疏算法来减少数据降维过程中的计算量。该方法一方面可以最大程度地保留原始模型结构的重要信息;另一方面,稀疏主成分分析方法通过对载荷向量的稀疏处理,大大降低了传统主成分分析方法中数据降维线性变换过程中的计算复杂度,其模型参数可降低到原始全模型的三分之一。仿真和实验结果表明,简化后的模型不仅具有与原始全模型相当的精度,同时具有更高的数值稳定性。3、为了提升射频发射机在建模时的精确度,提出了一种基于稀疏最小二乘支持向量机的发射机行为建模方法。该方法利用机器学习理论中的支持向量机模型取代传统的以Voltterra级数基础的功率放大器行为模型,提出了求解大规模数据训练的稀疏最小二乘支持向量机算法模型,并给出了稀疏最小二乘支持向量机模型的基本原理和详细的参数提取算法。该模型仅利用有限的训练样本进行训练,就可以对包含I/Q不平衡和直流偏置的发射机进行高精度行为建模。仿真和实验结果表明,该模型在综合考虑I/Q不平衡、直流偏置和功放非线性失真等因素的情况下可获得-36.76 dB的归一化均方误差,取得了比普通广义记忆多项式模型(-18.3dB)、共轭广义记忆多项式模型(-27.91 dB)、普通支持向量递归模型(-31.2 dB)和普通最小二乘支持向量机模型(-35.12 dB)更好的模型性能,并且其训练时间和运行时间比同类模型降低了90%以上。4、为了克服发射机射频损伤等各种非线性特性相互作用的影响,提出了由I/Q支路间的非线性频率相关交叉项和输入信号幅度所构成的三输入联合补偿模型。在这种新的模型结构中,所增加的发射机输入信号幅度项所生成的增强模型基集可以用来表征功放子模块的动态调幅/调幅(AM/AM)和调幅/调相(AM/PM)特性,其模型总体性能明显优于传统的I/Q不平衡模型。在此基础上,进一步使用鲁棒准牛顿基础的自适应贪婪算法进行模型参数在线删减,在不降低系统性能的同时模型系数可缩减到全模型的38%以下。仿真和实验结果表明,所构造的稀疏模型预失真器可以给出比其他常用的联合补偿模型更高的线性化性能,为直接变频发射机提供了非常高效和精度极高的线性化解决方案。"
413,基于概率推理的煤矿瓦斯事故致因分析及其管控研究,"我国煤炭开采是一个高风险的行业。煤矿事故灾害严重,给国家和人民带来了巨大的生命和财产损失。在煤矿各类事故中,瓦斯事故危害最为严重,一直被认为是煤矿生产的“头号杀手”。作为一个复杂的社会技术系统,导致煤矿瓦斯事故发生的各类影响因素众多,事故致因及条件发生的不确定性对瓦斯事故的管控带来了困难。本文从概率推理角度对导致煤矿瓦斯事故发生的不确定性因素、条件以及概率变化进行分析,运用概率图模型和情景分析方法进行研究,深入挖掘煤矿瓦斯事故潜在规律,研究新形势下煤矿瓦斯事故的管控对策。研究内容主要包含如下几个方面:(1)论文从历史的角度对我国煤矿事故总体概况进行分析,阐述了我国自建国以来各阶段煤矿事故的发生特点、变化趋势及原因,重点从多维度对瓦斯事故特征进行了统计剖析,指出瓦斯事故在事故类型、矿井类型、发生地域、发生时间等属性中所表现的特点及原因;结合当前煤矿安全形势和趋势,指出瓦斯事故在环境、人员、装备和管理方面存在的问题。从分析结果来看,瓦斯事故具有灾害后果的严重性、地域分布的广泛性、发生时间的随机性等不确定性特点。致因要素的动态变化和不确定性给煤矿安全管理带来了难度。在煤矿安全投入和管理资源有限的情况下,需要充分利用数据信息研究瓦斯事故致因及条件的不确定性,从而改善传统安全管理模式,提高事故管控的针对性。(2)论文以煤矿系统在生产过程中瓦斯事故发生的不确定性作为研究对象,根据瓦斯事故发生的物理机理,结合事故致因分类模型进行研究。首先,运用事故树方法从大量最新瓦斯事故案例中探究人员、机器、环境、管理等方面导致事故发生的内外部因素及其之间的逻辑条件,建立瓦斯事故致因条件依赖模型,明确事故发生的主要因素;其次,运用收集的案例数据采用机器学习和专家经验相结合的方法构建具有煤矿瓦斯事故特征的贝叶斯网络模型,并进行模型有效性的验证;最后,基于瓦斯事故概率图模型进行事故推理,找到煤矿瓦斯事故发生的最大致因链和敏感性因素排序。通过确定不同因素影响下的事故节点的后验概率,进而有效地确定瓦斯事故发生的概率;根据瓦斯事故发生的最大致因链,可以快速找到导致瓦斯事故的因果链;对事故因果链上的敏感性因素进行分级管控,可以有效降低事故发生的概率。分析结果表明:瓦斯事故发生的随机性规律可以从概率角度进行认知。贝叶斯网络较传统事故分析方法,在复杂不确定性问题的表达和推理方面具有优势,将贝叶斯网络运用到瓦斯事故不确定性研究中,构建瓦斯事故特征的贝叶斯网络模型,能够有效融合瓦斯事故先验知识和当前信息,实现基于概率推理的瓦斯事故风险预判和致因分析,为事故的有效防治与管控明确重点和途径。(3)为了将构建的瓦斯事故贝叶斯网络模型应用到事故分析和预防中,本文依据条件变化和煤矿生产可能出现的情况建立情景。结合瓦斯事故特征,本文提出了基于“煤矿特性-影响因素-因素状态-事件”的瓦斯事故情景网络模型(CFSE),并进行概率情景分析,以此确定了区别于传统方式的瓦斯事故管控流程,并从决策层、管理层和操作层提出了融合贝叶斯思想的瓦斯事故管控策略。分析结果表明:通过构建瓦斯事故情景网络模型,可以确定事故预防中所对应的每个情景,在任何一个情景下,借助贝叶斯网络研究在不同情景条件下事故发生的概率。在瓦斯管控策略中,本文提出基于概率推理和情景分析的瓦斯事故管控模式。充分利用瓦斯事故贝叶斯网络的推理和信息更新机制,建立瓦斯事故概率推理预警平台,细化瓦斯事故危险源的可能性度量,充分感知系统致因要素及条件的变化,从全局的角度进行决策和判断进而采取针对性的措施提高管控效果。综上所述,本文研究以数据为驱动,基于贝叶斯网络和情景分析等理论,通过概率推理方法定量研究瓦斯事故的不确定性,系统提出不同情景条件下瓦斯事故的管控策略,以提高我国瓦斯事故管控的针对性和有效性,最大程度上遏制我国瓦斯事故的发生。该论文有图63幅,表32个,参考文献201篇。"
414,基于无线信道特征和智能算法的物理层安全技术研究,"无线通信技术由于其传输介质的开放性与其广播特性,使得其面临各种安全问题。例如,窃听攻击(Eavesdropping Attack,EA)、干扰攻击(Jamming Attack,JA)和欺骗攻击(Spoofing Attack,SA)等。另外,无线通信中网络高度异构,而且其动态拓扑特性使得传统基于密码学的安全体制难以进行统一的安全加密或进行安全管理,无线通信中的终端向着小型化、低功耗的方向发展,使得传统的基于密码学的安全加密体制或者安全加密算法难以在终端上执行,或取得应有的安全性能。物理层安全技术利用物理层信道信息对发射信号进行处理或执行相应安全策略,具有轻重量和高安全性的特点,一直被学界所关注与研究。本文研究了无线通信的基于无线信道特征的物理层认证(Physical Layer Authentication,PLA),提出了在无线通信场景下的多用户轻重量认证机制。通过结合深度学习算法,解决了传统认证方法依赖门限的问题,不仅实现了门限自由,还能实现多用户的轻重量认证。并通过通用软件无线电外设(Universal Software Radio Peripheral,USRP)模拟真实的多用户无线通信场景,对提出的算法性能进行了验证与分析。此外,本文还研究了基于信道预测的物理层安全传输机制,提出了多种基于反向传播神经网络的信道预测算法。详细的研究内容和创新点如下:(1)针对多用户无线通信中的安全威胁,提出了一种基于深度神经网络(Deep Neural Networks,DNN)的物理层认证方案,该方案利用信道状态信息(Channel State Information,CSI)检测无线网络中的欺骗攻击,从而增强无线通信的安全性。给出了具体的物理层认证机制和一种包含合法节点、窃听节点和恶意节点的物理层认证场景。其次,提出了三种不同梯度下降算法下的深度神经网络多用户认证算法,其能加速深度神经网络的训练,实现更小的计算开销和更低的能量消耗。此外,通过推导出多用户认证方法的最大似然函数,解释了选择交叉熵作为代价函数的原因,还给出了其矢量化代价函数。采用小批量(mini batch)方案和L_2正则化分别提高训练精度和避免过拟合。最后,通过与传统的基于假设检验(hypothesis test)方法的比较,得出了所提出的方法有着更好性能的结论。(2)针对动态环境对环境自适应认证的需求,提出了基于深度学习(Deep Learning,DL)的自适应多用户物理层认证方案,以便更能适应动态的认证环境。给出了基于深度神经网络的自适应多用户物理层认证算法、基于卷积神经网络(Convolutional Neural Networks,CNN)的自适应多用户物理层认证算法和基于半盲卷积预处理网络(Semi-blind Convolution Preprocessing Networks,SCPN)的自适应多用户物理层认证算法。另外,加速梯度下降、小批量方案以及L_2正则化同样用于加速神经网络的训练并防止其出现过拟合。通过数字仿真,以及采用USRP在一个真实的工厂环境下的边缘计算(Edge Computing,EC)场景进行了模拟,对所提出的算法的认证性能进行了分析与评估,并对其在多用户无线通信中的实际意义进行了分析与讨论。(3)基于机器学习类算法的物理层认证的训练需要大量的训练样本,这使得训练过程样本采集耗时且在有的场景难于进行大量数据的采集。因此,我们提出了数据增强下的多用户物理层认证方案,给出了三种数据增强算法,利用采集到的少量信号样本生成大量训练数据,加快认证模型的训练,提高认证率。通过将深度神经网络与数据增强方法相结合,即使在较少的训练样本的情况下,基于深度神经网络的多用户物理层认证方案的性能也得到改善,并缩短数据采集所耗费的时间。在美国国家标准技术研究所(National Institute of Standards and Technology,NIST)数据集下进行了相应的仿真与模拟,对基于深度神经网络的多用户物理层认证算法在真实的工业物联网环境下进行了验证,并对三种数据增强算法进行了测试,最终结果表明所提出的方法具有很强的实用性与有效性。(4)最后研究了在时变信道环境下,基于信道预测的安全编码传输策略以及波束成形设计。提出了一种基于反向传播神经网络(Back Propagation Neural Network,BPNN)的信道预测方案,给出了单时刻信道预测算法和多时刻信道预测算法。然后对Jakes模型下的Rayleigh信道时域响应值进行了预测,并分析其性能,与传统信道预测算法和不同神经网络隐层数量下的性能分别进行了对比。进而,提出了一种基于信道预测的安全编码传输策略和波束成形设计方案。本论文所提出的物理层安全认证方法除了软件仿真分析,部分在模拟的边缘计算场景下进行性能验证。在边缘计算场景下,边缘服务器在物理上接近终端用户,有利于提取终端用户的物理信道特征参数,它还可以提供强大的计算资源,用于完成深度神经网络的训练学习;且对终端节点来说,几乎不增加额外的通信开销和计算开销,具有轻量级的特点,所以边缘计算场景适合执行物理层认证。而本文实景模拟的无线信道特征数据均为实际信道下的数据采集,是真实环境下的物理层安全性能验证,其为物理层安全从理论分析走向实际应用提供了重要的参考。"
415,移动通信网络高效内容分发机制与策略,"伴随着移动通信技术的高速发展,移动互联网中多媒体服务以及数据业务流量急剧升高。爆发式增长的海量移动网络流量给第五代移动通信系统(5G)带来了极大的挑战。通过对流量爆炸式增长问题的研究发现,移动网络流量主要部分来自于从远端服务器重复下载一些流行度较高的内容。因此,将内容事先缓存在离终端用户较近处是解决移动网络中流量指数式增长的有效方式。通过采用内容缓存和有效传输策略,流行的内容被缓存在中间或地方服务器,需要相同内容的用户可以直接被本地缓存满足,而不需要重复地从远端服务器下载,从而消除冗余的网络流量。尽管内容分发技术在传统有线网中已经得到了较深入的研究和广泛应用,但是无线移动网络与有线网络在架构上有很大差别,并且无线移动网络中的网络资源受限,例如无线链路容量,移动回程网路和缓存空间等都受到一定限制,因此传统的内容分发网络技术并不能简单地应用到无线移动网络中。而且,由于内容的动态变化、用户的移动性以及单个蜂窝内有限的用户数,使得移动无线网络中缓存内容的缓存命中率低。另外,内容提供商所提供的内容量不断迅速增长,即使缓存的花销越来越便宜,也不可能缓存所有的内容。因此,设计有效的内容缓存和传输机制来减少冗余内容的传输以及提高内容传输效率迫在眉睫。众所周知,由于异构蜂窝网络(Heterogeneous Network,HetNet)能够大大提高网络容量,成为了5G通信系统的关键架构。在HetNet中,微基站以及终端直通通信(Device-to-Device,D2D)都被引入。直觉上,本地缓存一些流行的内容在微基站上能够大大减少用户下载时延,同时减少微基站与宏基站的回程网路的压力。而且,随着D2D通信技术的提出,在用户设备上进行内容缓存,并且通过D2D链路进行内容的传输,能够更进一步地减少基站的高代价传输、减少用户下载时延和提高用户体验。另外,基于5G演进架构,国际标准化组织提出了一种将基站与互联网业务深度融合的一种技术,即移动边缘计算(Mobile Edge Computing,MEC)。由于MEC服务器具有强大的数据存储和计算能力,因此自然地可以在MEC服务器上进行内容的智能化部署,进一步加速网络中各项内容、服务及应用的分发和下载,让用户享有更高质量网络体验。由于最优化理论在解决复杂的最优化问题方面存在天然的优势。同时,机器学习算法可以对移动数据流量进行动态的学习及预测,从而作出相应的决策来获得最大化长期缓存增益。本论文基于这些技术手段对5G系统异构蜂窝网络场景下的内容缓存及传输以及移动边缘计算架构下的缓存问题进行了深入研究,主要内容包含以下四个部分:(1)异构蜂窝网络架构下的最优协作内容缓存及传输机制;(2)支持D2D通信的异构网络中基于多智体强化学习的内容缓存策略;(3)移动边缘计算架构下基于机器学习的协作缓存机制;(4)移动边缘云架构下基于执行-评价(Actor-Critic,AC)算法的动态缓存机制。论文首先研究了异构蜂窝网络场景下家庭基站(Femto Base Stations,FBS)与用户设备(User Equipment,UE)间的最优协作内容缓存及传输机制。本文将FBS和UE间的联合内容缓存机制定义成一个最优化问题,目标是最小化用户总的下载时延。本文采用了拉格朗日松弛以及原始-对偶分解将所定义的问题分解成两层的最优化问题,并采用次梯度算法分别求解。而且,为了达到用户总的下载速度最大的目的,本文设计了一种最优的内容传输策略来决定传送用户所请求的内容的源节点。本文将最优的内容传输问题定义成非平衡的分配问题,然后转化为平衡的分配问题,并采用匈牙利算法进行求解。仿真结果表明本文所提出的协作缓存及传输机制相较于其他现有的缓存机制能够大大提高异构蜂窝网络的缓存效率。论文接着研究了支持D2D通信的异构网络中基于多智体强化学习的内容缓存策略。本文通过设计有效的内容缓存机制,将流行的内容缓存在用户设备中,并且通过D2D链路进行内容传输,从而达到减少基站流量负载和提高用户体验的目的。在本文中,将用户看作学习智体,并且将D2D缓存问题设计成多智体的无休多臂机问题。本文提出了基于多智体强化学习的算法来解决该问题。特别地,本文采用了组合置信上界算法来降低动作空间。更进一步的,本文采用基于信任的方式来处理其他智体同时在做决策的情况。并且,本文还提供了算法的复杂度和收敛性分析。仿真结果表明,本文所提出的算法相较于其他传统缓存算法能够大大提高缓存命中率,减少用户平均下载时延。论文第三部分研究了移动边缘计算架构下基于机器学习的协作缓存机制。本文将多媒体服务提前部署到本地的移动边缘计算服务器,用户就可以直接进行下载,从而减少用户请求内容在网络中重复冗余的传输,以减少网络流量以及用户下载时延。本文研究在内容流行度以及用户喜好未知的情况下移动边缘计算服务器间的协同内容缓存机制。本文将内容提供商的目标考虑在内,即内容提供商可以根据用户的不同等级,提供有分别的用户体验。本文从机器学习的角度对移动边缘计算服务器间最优的协作缓存问题进行了建模及求解。另外,本文在仿真实验中采用收集到的真实数据,验证了所提出的基于机器学习的协作内容缓存机制的性能,也分析了系统模型各项参数对缓存增益的影响。论文最后研究了移动边缘云架构下基于AC算法的动态内容缓存机制。在移动边缘云架构下,内容提供商可以根据用户需求的变化对所购买的缓存资源大小进行弹性调整。本文考虑缓存空间大小弹性可变的情况下,如何设计有效的内容缓存策略来达到缓存开销最小化的目的。本文采用AC算法对用户内容需求进行在线学习并做出决策,同时根据实时缓存开销对现阶段的缓存决策进行动态修正。最后,仿真实验结果验证了基于AC算法的动态内容缓存机制的有效性,也分析了系统模型各项参数对缓存增益的影响。"
416,白带显微图像中有型成分自动识别理论与技术的研究,"白带常规是女性生理检查的常规手段之一。白带常规的主要检查方式是通过对白带分泌物进行显微成像,通过镜下有型成分的识别与计数等方式得到相应的指标参数,从而分析待检测样本的病理特性。由于白带常规具有无创的特点,患者易接受。在中国,每天都有数以万计的女性进行白带常规检查。然而,目前,白带常规的检测由医生手动完成,易造成交叉污染,并且检测的效率极低。此外,具有炎症的样本一般具有浓烈的气味,严重影响医务人员的工作环境。随着机器学习和深度学习技术的发展,白带常规向自动化和智能化发展,而其中最关键的就是显微图像的有型成分自动检测和识别算法。关于白带显微图像中的多类别有型成分识别,国内外还没有相关的研究。而对于显微图像中细胞或细菌的识别也仅限于在特定环境下的识别。本文针对白带显微图像中有型成分的特点,对其进行检测所涉及的相关理论和关键技术进行了深入研究,主要成果及研究内容如下所述:1.基于组合生物纹理特征的白带显微图像中上皮细胞检测方法白带显微图像中的上皮细胞是白带显微图像中的重要有型成分。针对白带显微图像中上皮细胞的面积大且具有网状纹理结构的特点,提出了一种应用于上皮细胞前景目标位置检测的数字图像处理方法,该方法用于提取显微图像中上皮细胞及类上皮细胞的杂质等前景目标。根据提取的前景目标,通过分析并比较前景目标的各类纹理特征(二值模式(LBP),Gabor特征和梯度方向直方图(HOG)特征),用支持向量机对目标的纹理特征进行分类。本文创新性的提出采用局部二值模式(LBP)组合梯度方向直方图(HOG)特征实现上皮细胞等网状生物细胞的分类识别。实验表明,所提方法检测速度快(304 ms),检测精确率高(86.9%),漏检少(召回率:88.9%),满足白带常规中的实时检测需求。2.基于改进R-CNN的小细胞快速目标检测和识别方法对于白带中的小细胞有型成分,例如白细胞、红细胞和霉菌等有型成分的识别,本文在R-CNN模型的基础上,提出了一种基于改进R-CNN的白带有型成分目标检测方法。首先,提出了一种应用于白带显微图像小目标的区域建议方法,该方法较R-CNN模型中的选择性搜索方法效率提升50倍,并且产生的前景目标少,极大的缩减了R-CNN中前景目标提取的复杂度。其次,提出了基于Inception-ResNet-V2网络的前景目标识别和位置回归方法。通过收集的数据进行实验证明,该方法实现了对上述有型成分的高精确率和召回率的检测,平均检测精确率mAP(Mean Average Precison)为:79.75%。3.基于改进Faster R-CNN的白带显微图像粘连细胞检测方法对于清洁度较高的白带样本,其显微图像中细胞等有型成分较多,各成分之间相互粘连,采用上述前景目标提取方法无法实现这些粘连细胞的分割。本文针对这类问题提出了基于改进Faster R-CNN的白带显微图像的目标检测方法。首先,在分析有型成分形态特征的基础上,提出了一种改进的区域建议网络,该网络具有较少的Anchor,因而训练和测试的效率更高;其次,提出了基于PCA的特征图降维方法,用于实现对特征图的降维和维度的归一化,并输入到全连接层进行分类和位置回归。通过实验数据的测试,该方法对于粘连的细胞能够实现有效的分割和识别,算法执行效率快,准确率高。4.基于VIBE改进模型的滴虫运动目标检测方法由于新鲜的白带样本中滴虫仍然具有活性的特点,而从形态学方面很难直接提取到滴虫,因此本文从运动目标的检测角度出发,提出了一种基于VIBE改进模型的滴虫检测方法。算法改进了VIBE模型中的背景模型更新方式以及邻域背景模型的散播机制,同时提出了一系列的杂质过滤措施,最终实现了对白带显微图像中滴虫的检测。通过对采集的视频帧进行实验,结果证明该算法有效的提升了滴虫检测的精确率等指标,并与其他运动目标检测算法相比较,取得了最好的检测效果。"
417,面向多源异构数据的矩阵分解算法研究及应用,"矩阵分解算法因其高效、易于实现、可扩展性强等优点在机器学习中得到了广泛应用。同时,由于数据采集方式越来越多样化,使得大量的多源异构数据能够被轻易获取。例如,在图像数据的采集过程中,人们既可以用灰度值来表示图像,也可以用边缘分布等特征描述图像。每一种类型的描述特征都可以表达数据的某一特性。如何充分挖掘单源数据(由某一类型特征表示的数据)的信息,并将多个源信息有机结合以提高模型最终的学习性能,近年来已成为基础研究热点之一。正是在这样的时代背景下,面向多源异构数据的算法设计与应用的需求应运而生。本文在归纳当前主流矩阵分解算法的基础上,将研究面向多源异构数据的矩阵分解算法的设计与应用。具体来讲,本文将重点关注矩阵分解算法在无监督学习框架下处理多源异构数据时存在的如下问题:1.传统矩阵分解算法通常对噪声和离群点特别敏感,尤其是多源异构数据中常常存在较多的噪声和离群点,使得算法在实际应用中性能受到极大影响;在数据的采集及后续预处理过程中,由于人工操作的随机误差及数据采集设备本身存在的性能、精度等方面的问题,收集来的数据难免会存在由这些问题而造成的噪声。多源异构数据本身又是通过多个采集渠道和方式而生成,因此多源异构数据所蕴含的噪声通常会多于其他类型的数据,这使得在处理多源异构数据时,如何有效的处理噪声显得尤为重要。为了解决这类问题,本文基于capped范数提出了一个具有鲁棒性的聚类方法来处理多源异构数据。由于采用capped范数来度量目标函数的重构误差,因此本文方法对噪声和离群点更具鲁棒性,特别是极端离群点。此外,本文方法的时间复杂度较低,并且与经典k-means算法的时间复杂度处于同一水平。2.由于矩阵分解算法本身通常是一个非凸问题,因此目前面向多源异构数据的矩阵分解算法大多也都是一个非凸问题,从而导致现有的算法都容易陷入不良的局部解。矩阵分解算法通常是将原始数据矩阵分解两个或多个低维的矩阵。在优化过程中,单对某一个低维矩阵来讲,算法是一个凸问题;但针对多个低维矩阵,算法是非凸的,即矩阵分解算法是一个联合非凸问题。本文基于自步学习框架,提出了面向多源异构数据的自步学习聚类算法,以便应对模型中的非凸问题。现有的文献表明,自步学习能够有效地缓解算法的非凸问题。自步学习通过样本数据点自身的特点来加以训练模型。具体来讲,针对较为干净的样本点(离类中心较近、含噪声较少的样本点),将率先加入模型的训练,然后在后续的迭代训练过程中逐步加入更多的样本点。由于模型最先训练干净的样本点,因此模型的鲁棒性有较好的保证,在一定程度上缓解了算法的非凸问题。3.矩阵分解算法通常都是作用在基于欧氏距离的数据空间上,这就使得其不能很好地处理基于几何结构的数据。此外,流形结构在多源异构数据中反而更常见。本文通过增强矩阵分解算法对于数据空间几何结构的分析能力,使得算法的性能能够进一步得到提升。图正则化矩阵分解算法通过构建谱图的方式将几何距离度量引入矩阵分解算法中。但基于图论的矩阵分解算法通常是在某一谱图上展开,因此构建的谱图对于算法性能有极大的影响。由于构建谱图可以在不同的参数条件下进行,这就使得算法性能直接受到参数设置的影响。本文基于多核学习框架,提出了面向多源异构数据并能够融合不同谱图的聚类算法。该算法对于不同参数的情境并不那么敏感,从而提升了算法的稳定性和鲁棒性。4.多源异构数据本身所具有的特性使得其天然具有多层语义和多样性,而传统矩阵分解算法都是基于单层结构思想,因此不能很好地分析含有多层语义的数据。受到深度学习的启发,扩展传统的矩阵分解算法使其具有层次语义分析能力,能够进一步提升算法处理多源异构数据的性能。本文基于多层结构的矩阵分解算法,将深度学习的思想有效地引入到这一传统的算法框架中,提出了面向多源异构数据的深度矩阵分解算法。由于传统的矩阵分解算法采用的是单层分解结构,多源异构数据天然具有的多层语义得不到充分的挖掘。本文则采用深度多层分解的思想,将前一次分解得到的表征矩阵进行再一次的分解,进而使得数据的潜在语义得到进一步的挖掘。"
418,基于人工神经网络的低功耗射频收发系统研究,"随着物联网、人工智能和半导体制造技术的快速发展,人类正逐步进入信息化与智能化的社会,数以十亿计的无线设备正在不间断地发送和接收数据。射频收发机是无线通信设备的基础性零部件,是电子设备间无线通信的必要媒介,其性能直接决定了无线设备间的通信质量、通信模式、稳定性与待机时间。本文从使用经济高效的CMOS技术节点的角度,回顾了超低功耗射频收发机和集成电路设计的发展历程,结合射频收发机前端的基础理论,以降低系统功耗和提高全局效率为目标,对射频收发机及其关键模块设计进行了广泛和深入的研究。得益于近年来机器学习技术的发展,本文首次将神经网络集成到射频收发机中,研究并实现了基于机器学习技术的自动功率调节与信道切换。主要研究成果如下:1.超低功耗接收机的设计:植入设备的电池往往是不可能或者极难更换的,这严重限制了无线收发器的功耗。超低功耗射频接收机通常采用极端的低功耗工作模式来节省电力,在这种情况下,本振的锁定时间决定了占空比的下限,本文首先分析了接收机设计的关键制约因素,进而提出了一种基于噪声消除技术的低功耗LNA,将差分信号中同相位的噪声相互抵消,实现噪声优化;接下来,提出了一种具有倍频功能的低功耗频率综合器,这使得振荡器可以工作于载波频率的1/9,相对于常规振荡器,其起振时间短,工作频率低,功耗更低;本超低功耗接收机采用180 nm CMOS工艺流片,测试结果显示,本接收机的增益为61.2 dB,噪声系数为16.8 dB,IIP_3为-15.8 dBm,消耗功率为73W。2.低压工艺下发射机的设计:高集成度的射频发射机可以降低无线通信系统的制造成本,但是,功率放大器大多仍需采用高压工艺实现。低击穿电压和高拐点电压是现代纳米及深亚微米CMOS工艺主要缺陷,限制了负载端的可用电压摆幅,也限制了输出功率。本文首先研究和分析了发射机设计中的非线性问题和效率问题;在此基础上,提出了在低压工艺中通过使用功率合成器来提升发射机的输出功率的方法,研究并对比了威尔金森功率合成器和变压器结构功率合成器,设计了一个高转换效率的变压器结构的功率合成器;最后,使用变压器结构的功率合成器设计并实现了一个低压工艺下高集成度的,高效率高输出功率射频发射机。仿真结果显示,本发射机在5.2-5.8 GHz范围内输出功率大于23.3 dBm,PA的漏极效率为25.7%。3.基于机器学习技术的低功耗射频发射机设计:全球有不计其数的无线设备被使用,每小时的功耗约为61万亿瓦特。传统的发射机“不知道”发射距离和目标,所以PA通常需要使用全功率以确保接收端可以接收到信号。人工神经网络也可用于RF电路设计,在本文将前馈多层感知机集成到发射机中,实现了数据传输智能化。本文首先介绍了机器学习算法的关键问题以及解决方法;然后,研究并设计了一个具有数据识别能力,能自动切换发射机发射信道和发射功率的多层感知机;设计并实现了一个可编程控制输出频率的压控振荡器和一个可变输出功率的高效率的功率放大器;最后,对本文提出的智能发射机进行了整体仿真和流片验证。测试结果表明,该发射机的MLP网络能识别数据并自动调整发射机的发射功率和传输信道,识别准确率为95.1%。该发射机的峰值输出功率为14.9dBm,工作电压为1.5 V,功耗为34.3 mW。"
419,基于群体智能进化算法的对抗样本生成研究,"近年来,随着人工智能技术的飞速发展,加上计算机算力的大幅提升,机器学习算法尤其是深度学习算法开始被广泛应用于我们的生产和生活当中。最常见的应用场景包括人脸识别、自动驾驶、恶意应用检测、智能语音交互等。正如传统软件开发中会存在安全问题一样,机器学习算法同样存在安全性问题。然而在当前机器学习发展的浪潮中,大部分的开发者和研究者都把视线放在提高机器的“智能性”上,很少有人关注到算法的“安全性”。当这些机器学习算法被应用在自动驾驶、语音控制等重要场景中时,算法的安全甚至会关系到用户的生命财产安全。对抗样本是目前已知的、最为严重的机器学习算法安全性问题之一。一个精心构造的对抗样本可以直接误导算法的决策和判断,从而带来不可估量的严重后果。因此,对机器学习算法安全性的研究,尤其是对对抗样本攻击的研究,有着重要的社会意义和应用价值。本文首先对以对抗样本攻击为代表的机器学习安全性问题进行了系统调研,分析了常见的对抗样本攻击方法,并对当前现状进行了概括总结。本文以对抗样本生成方法为研究课题,希望通过对攻击技术的研究,为如何防御对抗样本攻击提供思路;结合群体智能进化算法高效、灵活的搜索特性,重点研究如何针对图像数据进行黑盒对抗样本生成、如何基于对抗样本技术进行网络流量混淆、如何生成针对Android应用的对抗样本以及如何构造针对音频数据的对抗样本。本论文各部分的主要研究内容具体如下:第一部分首先对现有的对抗样本生成技术进行了综述,对比分析了各方法的优缺点,为该领域进一步的研究工作给出建议。其次对群体智能进化算法进行了综述,概括总结了群体智能进化算法的一般框架流程及特点,解释了这类算法适用于构造对抗样本的原因。最后,针对传统群体智能进化算法收敛速度慢、容易陷入局部最优的问题,提出一种基于t分布的改进遗传算法,该改进遗传算法具有收敛速度快、搜索效率高的特点。该部分的研究内容为后续的对抗样本生成技术研究提供了理论依据和技术支撑。第二部分提出一种新的针对图像数据的对抗样本生成方法。该研究针对传统图像对抗样本在构造过程中存在的模型依赖性高、构造效率低、鲁棒性差等问题,提出了基于群体进化算法的图像对抗样本生成方法。该研究在MNIST、CIFAR-10和ImageNet等测试数据集上都实现了100%的攻击成功率;同时对经过“蒸馏防御”方法加强的网络模型也实现了成功率为100%的攻击。第三部分提出一种基于遗传算法的对抗样本生成方法,通过迁移深度学习中存在的对抗样本问题,针对更广泛的机器学习检测模型,采用对抗样本来做流量混淆,进而达到绕过模型检测的目的。该研究在基于CNN的流量检测模型和Profile HMM网站指纹检测模型上,在无需知道检测模型参数的情况下,生成的对抗样本都可以改变两种检测模型的判别结果,成功达到流量混淆的目的。相比于传统的流量混淆方法,该方法具有96%以上的成功率。第四部分提出一种针对Android应用的对抗样本生成方法。与针对数值为连续的图像对抗样本不同,Android应用本质上是离散的二进制串,所以不能直接使用图像对抗样本领域的方法。为了解决这个问题,该研究提出一种基于遗传算法的Android应用对抗样本生成方法,能够在不影响Android应用自身正常运行且保留所有功能的情况下,构造出相应的对抗样本。实验结果表明,该方法可以针对黑盒检测模型生成Android应用的对抗样本,并且成功率接近100%。第五部分提出一种针对音频数据的对抗样本生成方法。研究表明基于机器学习算法的自动语音识别模型也会受到对抗样本的威胁,对音频对抗样本的进一步研究是阻止潜在攻击威胁的必要途径之一。尽管一些学者已经进行了这方面的研究,但是音频对抗样本的有效性和鲁棒性仍然不令人满意。该研究提出一种基于加权和微取样的音频对抗样本攻击方法,同时还将一种降噪方法应用在损失函数的构造中,使得生成的音频对抗样本更不容易被分辨。实验表明,该方法可以在分钟级时间损耗内生成低噪声、高鲁棒性音频对抗样本。"
420,北京市水库温室气体碳排放估算方法研究,"水库温室气体碳排放日益受到国内外研究的关注。本研究基于北京市三座水库甲烷与二氧化碳排放数据,针对区域层级(密云、玉渡山和白河堡三座水库,数据源S1)和样地层级(密云水库,数据源S2),探求环境参数在两种层级上,对水库温室气体碳排放影响的差异。采用统计模型(经验方程和机器学习法),基于模型迁移学习能力、减少过拟合风险,建立评价和验证模型适应性方法;采用机理模型(CH4MODwetland),验证其对水库消落带甲烷排放的预测效果;探求建立和筛选水库温室气体碳排放预测模型的方法。最后,采用排放因子法、实测值法和模型法,探求不同方法对水库温室气体碳排放估算的影响。主要结论如下:(1)温室气体与环境参数间的关系受温室气体类型、空间分布和研究层级的影响而不尽相同。气温(T)、风速(WS)、植物生物量(Bio)、土壤有机碳(SOC)均可促进甲烷和二氧化碳排放;气压(AP)、pH、溶解氧(DO)均可抑制两种温室气体排放。相较于区域层级(S1),甲烷和二氧化排放在样地层级中(S2)更易受气温(T)、气压(AP)、风速(WS)、溶解氧(DO)等环境参数的显著影响。(2)相关性和回归分析是否显著,并非模型参数选择的必要条件。在条件允许的情况下,采用可获得的所有环境参数,作为模型备选参数最佳。否则,采用相关性分析和回归分析相结合的方法筛选环境参数,可减少遗漏提高模型精度参数的风险。(3)相较于经验方程等其他五种模型,采用机器学习法的决策树(DT)模型迁移学习能力和表现最佳。数据源由S2变为S1时,模型迁移学习能力(r2为指标)在密云测试集中变化不大;在玉渡山和白河堡测试集中常得以提高。同时,可提高水域区和消落带甲烷DT模型的表现;但降低水域区和消落带二氧化碳DT模型的表现(以R2为例)。(4)与实测值法相比,采用IPCC默认排放因子法估算的甲烷排放值最高,可能会高估我国水库甲烷碳排放;其估算的密云水库为二氧化碳的汇,可能会误判我国水库二氧化碳年度碳汇/源属性。CH4MODwetland与实测值法二差异小于DT模型,但所需参数更多。在估算逐年温室气体碳排放但缺乏实测数据时,DT模型可能更优于IPCC默认排放因子法;而当数据充分时,CH4MODwetland可能更优于DT模型法。本研究建立了包含评估模型迁移学习能力,以及降低模型过拟合的统计模型适应性评价与验证方法。依据IPCC推荐的最高两级精度(Tier2,统计模型法;Tier3,机理模型法),对不同估算方法可能造成的不确定性进行评估。对促进水库温室气体排放估算方法的改善具有指导意义。对我国水库温室气体碳排放估算,以及水库温室气体清单编制具有参考价值。"
421,星系尺度强引力透镜的寻找及应用,"当背景天体的光线经过大质量前景天体的时候,会在前景天体的引力下发生偏折,并在前景天体周围形成多个像。我们将这种现象称作强引力透镜现象。本文主要研究星系尺度的强引力透镜现象,包括这种强引力透镜系统的寻找及应用。(1).基于光谱选择法,我们使用机器学习来搜寻星系尺度的强引力透镜系统候选体。我们要搜寻的透镜系统候选体的前景星系为中等红移(z～0.5)的椭圆星系,背景星系为高红移(2<z"
422,基于多元生物分子网络寻找癌症miRNA/lncRNA标志物,"随着精准医学概念的提出,癌症非编码RNA标志物成为近年来研究的热点问题。其中,微小 RNA(MicroRNA,miRNA)和长链非编码 RNA(Long non-coding RNA,lncRNA)在癌症演化过程中发挥重要功能。特别地,lncRNA可以作为竞争性内源RNA(Competing endogenous RNA,ceRNA)与 miRNA 相互作用调控靶基因表达。在大数据和生物医学信息学时代,计算机辅助生物标志物识别逐渐成为一种新兴的研究方式。基于多元生物分子网络分析,有利于从系统生物学角度寻找癌症等复杂疾病发生发展过程中的驱动或关键因素,推动疾病的精准诊断和个性化治疗。本论文首先系统综述计算机辅助生物标志物识别的最新研究进展,包括数据资源、计算模型和相关应用等。研究发现,大多数生物信息学模型缺少普适性的理论或规则指导。由于数据和样本的异质性,某些机器学习模型中“训练-测试”的模式往往导致过拟合的结果。针对以上问题,我们整合不同来源的“miRNA-靶标”关系数据,分别构建miRNA-mRNA二元和lncRNA-miRNA-mRNA三元网络,分析已报道癌症miRNA和lncRNA标志物的网络结构和生物功能特征。由于健康到疾病以及疾病的阶段发展可以抽象为某一生物状态向另一种状态转变的过程,相比较疾病相关因子,生物标志物能够指示不同生物过程中系统状态的动态变化。基于这种观点,我们进一步关注网络中的脆弱结构,通过构建系统生物学模型预测癌症miRNA、lncRNA分子标志物。结合课题组的研究基础,我们选择前列腺癌及其转移作为主要的应用和研究对象。目前,临床转移仍然是影响癌症患者预后和生存的主要原因,因此,寻找前列腺癌转移的miRNA、lncRNA标志物具有重要意义。基于网络的子结构分析,研究表明,miRNA-mRNA网络中某些mRNA可以被唯一的miRNA独立调控,我们将这种独立调控特征定义为miRNA的单线调控模式。结合统计检验结果,作为标志物的miRNA具有显著强的单线调控mRNA的能力。由于单线调控是网络中一类特殊的调控模式,相比较多线协同调控,单线调控结构更加脆弱,它们的异常可能导致系统层次的功能紊乱,从而造成生物状态的改变。因此,该结构特征可以作为miRNA标志物识别的重要理论依据。在此基础上,通过miRNA靶基因的网络结构和生物功能分析,我们发现miRNA标志物能够调控和单线调控较多的转录因子基因。据此,我们整合miRNA、mRNA表达谱数据,提取前列腺癌转移特异的miRNA-mRNA子网络,构建并优化生物信息学模型,寻找前列腺癌转移相关的miRNA标志物。结果表明,miR-204-5p、miR-101-3p、miR-145-5p、miR-198和miR-152可以作为潜在的分子标志物。接下来,我们将上述理论拓展至miRNA介导的三元网络,结合ceRNA假说,进一步研究lncRNA-miRNA-mRNA网络中miRNA的调控以及lncRNA的竞争规律。相比较其它miRNA,参与lncRNA和mRNA竞争的miRNA具有显著强的调控能力,能够调控更多的转录因子基因、必需基因、管家基因和肿瘤相关基因。同时,网络中存在某些miRNA单线调控mRNA、lncRNA以及lncRNA竞争较多miRNA的情况。基于统计学证据,我们构建新的系统生物学模型预测、筛选前列腺癌转移相关的miRNA、lncRNA单个和组合标志物。研究发现,前列腺癌转移特异的lncRNA-miRNA-mRNA子网络中,miR-23b-3p、miR-204-5p、miR-26b-5p、miR-27b-3p、miR-145-5p、miR-29b-3p、miR-143-3p、miR-130a-3p、miR-363-3p、miR-218-5p、miR-30c-5p、miR-101-3p 以及XIST、CTA-204B4.6、HCG18、TUG1、MALAT1具有显著强的调控或竞争能力。同时,考虑到mRNA的生物学功能,这些分子可以形成三元lncRNA-miRNA-mRNA组合标志物指示前列腺癌的发展和侵袭状态。生物信息学分析结果表明,候选标志物参与前列腺癌发展和转移的重要信号过程,如前列腺癌、TGF-β通路等。通过细胞系qRT-PCR实验验证,相比较原发未转移细胞22RV1,候选分子在转移性前列腺癌细胞LNCaP、PC3或DU145中具有显著的表达差异。通过比较分析,我们发现不同版本模型预测结果的一致性较好,特别地,共同预测到的miR-204-5p、miR-145-5p和miR-101-3p在转移性前列腺癌细胞中均显著下调,在一定程度上体现出它们的功能重要性。同时,新的模型预测精度更高、功能更强,表明模型构建和改进的合理性和可靠性。本论文基于多元生物网络分析,从网络的结构和功能角度提出miRNA、lncRNA标志物识别的理论依据,构建癌症miRNA、lncRNA标志物识别的系统生物学模型,发现前列腺癌转移关键的miRNA、lncRNA信号。本论文的相关成果适用于其它癌症以及复杂疾病的生物标志物研究,具有重要的理论和临床意义。"
423,蛋白质序列的深度建模及其应用,"蛋白质的生物功能由蛋白质的三维结构决定,而三维结构是由蛋白质序列决定的。在三维结构未知的情况下,分析预测蛋白质分子结构,可帮助人们快速认识蛋白质功能、研究生物病理原因、减少生物实验量等。深度学习方法已在多个领域成功应用,本课题用深度学习方法,从蛋白质一级序列出发,建立深度学习模型,对蛋白质结构相关的典型属性:溶剂可及性、二级结构、骨架二面角和相互作用位点开展预测研究。本文主要工作如下:1.蛋白质溶剂可及性预测。提出一个两阶段的单模型策略:先训练回归模型,预测相对可及表面积;再根据指定阈值,对预测结果再进行分类划分。在双向递归神经网络节点信息融合时,提出了双向节点的融合算子,提升了信息融合能力。实验表明使用三个不同融合算子的SDBRNN模型提高了溶剂可及性预测性能。2.蛋白质二级结构识别。结合递归神经网络长范围特征提取优势和卷积神经网络局部特征提取特点,面向多分类问题,设计深度学习模型CRRNN,捕获序列隐含的局部特性和长程特性。为了解决残差网络跨层合并输入带来模型参数激增的问题,用一维一卷积步的卷积神经网络转换降维。本文中还训练了 10个独立训练的单模型,组合成多模型集成学习。3.蛋白质相互作用位点预测。蛋白质链上作用位点残基稀少,针对该不平衡分类问题,本文提出了三个改进策略来调整不平衡性:面向蛋白质链整体选择的策略来调整训练集;结合代价敏感性学习在分类函数中增加惩罚因子;联合溶剂可及性预测进行共同学习。对LSTM模型进行简化,提出轻量级的SLSTM网络作为双向递归网络计算节点,改善训练样本偏少问题。DLPred模型在平衡性指标F-measure提升的同时,提升了预测准确率。4.蛋白质溶剂可及性、二级结构、骨架二面角的多任务联合学习。基于上述研究基础,提出了一个双通道策略的深度学习模型CRRNN2,多任务联合学习,同时预测溶剂可及性、二级结构、骨架二面角等多个结构属性。用简化的GRU网络,作为双向递归神经网络的网络节点,用DenseNet结构搭建三层的双向递归神经网络通道,用改进的Google Inception搭建卷积神经网络通道。本文的主要贡献在于面向蛋白质序列建立深度学习模型,针对结构属性预测需要,面向计算问题,建立了回归模型、分类模型、不平衡数据下的深度学习模型、多任务学习模型等。在建模过程中,提出了面向双向递归神经网络的融合算子,融合算子成功应用在本文多个深度学习模型中;基于模型泛化能力和参数规模的考量,设计出改进的SLSTM网络和GRU2网络,并改进了残差网络的连接方式;验证了集成学习在深度学习中的有效性。这些方法的研究和所取得的成果有助于深度学习在蛋白质结构方面进一步研究,对今后基于深度学习的生物信息学问题的建模同样具有重要的参考价值。"
424,基于机器学习的软件缺陷预测方法研究,"随着信息技术的不断发展,信息安全面临的挑战日益严峻,其中软件安全引起人们越来越多的重视。作为软件安全风险的主要根源之一,软件缺陷不仅可威胁计算机信息系统的安全性和稳定性,甚至可能被黑客利用而恶意入侵。软件缺陷预测是软件工程领域中与软件质量保证密切相关的重要的研究课题,它对提高软件系统质量和优化测试资源分配都有重要意义。在软件工程数据挖掘领域中,基于机器学习的静态软件缺陷预测根据软件历史仓库数据,采用缺陷相关的度量对软件代码或开发过程进行分析,利用机器学习方法来预测软件项目中待测试程序模块的缺陷倾向性或缺陷数量。影响缺陷预测性能的主要因素有:度量元的设计、缺陷预测模型的构建以及缺陷预测数据集的相关处理。本文从机器学习的角度针对上述影响因素对软件缺陷预测方法进行了系统的研究,主要研究成果总结如下:(一)基于联合表示的软件缺陷数据特征选择与分类提出了基于联合表示值的过滤型软件缺陷数据特征选择方法(CRS)和基于联合表示的软件缺陷预测分类方法(CSDP)。为消除软件缺陷数据集中缺陷度量元间的冗余性和提高特征选择方法的计算效率,CRS利用联合表示和l_2图构建缺陷数据关系图的邻接关系和权重,在考虑联合表示保留能力的同时考虑数据方差,通过联合表示值的大小排序并迭代选择缺陷数据特征。CSDP首先对无缺陷训练数据集进行Laplace Score采样以构建类别平衡的训练数据,接着利用联合表示求得查询样本的投影矩阵,最后利用基于正则化最小二乘的联合表示分类方法构建软件缺陷预测器。CSDP采用_2l范数正则化取代_1l范数正则化,进一步增强稀疏分类的效率、降低计算复杂度;CSDP中的联合表示分类器既利用类特定的表示残差的鉴别能力,又利用l_2模“稀疏项”的鉴别信息,分类性能得到提升。在广泛使用的软件缺陷预测数据集上的实验结果表明了两种方法的有效性。(二)基于字典学习的软件缺陷预测将以预测缺陷倾向性为目标的软件缺陷预测看成是一个二分类问题,在分类预测时引入字典学习技术,针对软件缺陷预测的代价敏感性与类不平衡性特征、缺陷数据的逐步积累增量式学习和半监督场景下的缺陷预测的问题,分别提出了三个字典学习软件缺陷预测方法,即代价敏感鉴别字典学习(CDDL)、类特定增量字典学习(CIDL)和基于二次学习的半监督字典学习(TLSDL)。CDDL在构造初始字典原子时,通过PCA处理消除了类不平衡问题,利用软件模块间的相似性,设计出有鉴别能力的字典,同时考虑软件缺陷预测的风险成本,在鉴别字典学习缺陷预测模型中引入代价敏感学习。CIDL针对传统字典学习在大数据集上批量学习时计算代价过高的问题,设计了增量式字典学习方法。在初始集上采用类特定字典学习,学得的有监督字典有利于分类预测,在增量集上采用互信息最大原则选取增量字典原子,有利于充分利用增量数据的互补信息。为了解决在有标记样本较少而无标记样本丰富的半监督场景下构建有效的缺陷字典学习模型困难的问题,TLSDL采用二次学习框架,在第一阶段学习中,大量无标记样本通过概率软标记标注扩充到有标记训练样本集中,实现半监督学习的扩展,在第二阶段学习中,通过鉴别字典学习,实现稀疏表示分类和预测性能的提升。实验结果表明了三种字典学习方法的有效性。(三)基于图学习的半监督软件缺陷预测为了充分表示软件缺陷数据间潜在的聚类关系,提出了一个具备稀疏性、高鉴别能力和自适应近邻的信息图――非负稀疏图(NSG)的构建方法,NSG在稀疏图的学习过程中加入了非负限制,图上结点的连接关系和权重在非负稀疏编码时同时得到。在NSG上提出了两个基于图学习的半监督缺陷预测方法:基于非负稀疏图的协同训练缺陷预测方法(NSGCT)和基于非负稀疏图的标记扩散缺陷预测方法(NSGLP)。NSGCT方法结合基于图学习的方法和基于分歧的方法的优点,对无标记数据进行显式置信度估计,减少了噪声数据的引入,提高了半监督协同训练算法的性能。NSGLP方法采用拉普拉斯采样技术对数据集进行不平衡处理,利用NSG表示缺陷数据间的关系,在NSG上利用标记扩散半监督学习方法迭代预测无标记模块的类型标记,NSGLP通过不平衡处理和有效构建信息图提升了半监督缺陷预测的性能。实验结果表明了两种基于图的半监督方法的有效性。"
425,分布式地震数据智能感知采集方法研究,"地震勘探因其具有较强的地层穿透能力,成为油气矿产勘探领域的有效手段。在我国油气资源对外依存度逐渐升高以及“向地球深部进军”被确定为必须解决的战略科技问题的大背景下,如何实现大规模地震数据采集已成为当前工业界和学术界研究的热点问题。目前,由于勘探成本和野外环境等因素的限制,提升硬件资源的使用效率是实现更大规模地震数据采集工作的一个新思路。因地震数据具有非线性特征多样化的特点,现有的地震数据高效采集方法在自适应性、特征关系提取等方面均有不足之处。针对现有方法的不足之处,本文结合压缩感知、稀疏表示、机器学习三种理论,提出了智能感知采集方法。根据两种常见的地震数据采集工作场景(常规地震勘探和压裂微地震监测)的特点,设计了两种不同的分布式地震数据智能采集方法:基于多跳网络的地震数据智能感知采集方法和基于微地震事件检测的智能感知采集方法,并且通过数值试验证明了两种方法对采集效率的提升水平。论文的主要研究内容如下:(1)研究了地震数据高效采集方法的相关理论:包括压缩感知、稀疏表示、机器学习,针对这几种理论的优缺点,结合地震数据采集的特点,以互补的方式对三种理论进行融合,提出了智能感知采集方法。具体而言,智能感知采集方法以压缩感知理论为基本框架,通过引入稀疏表示与机器学习算法实现稀疏性约束条件下基于数据驱动方式的非线性特征提取与拟合能力,从而既能保证该方法具有较强的自适应性,又能同时解决传统高效采集算法忽略输入数据稀疏性特征、非线性特征的问题。(2)针对地震数据的特征和采集系统网络结构特点,设计了分布式地震数据智能感知采集方法的总体方案。通过从地震波动方程和信息熵理论两个方面对地震数据稀疏性进行分析,论证了地震数据满足进行高效采集方法研究的前提条件。结合地震数据采集工作的两类主要应用场景:常规地震勘探和压裂微地震监测,分析了二者的网络结构特点。根据智能感知采集方法的基本思想,将数据采集策略与应用场景的特有规律(地震数据特征、网络结构特点)相结合,提出了这两种应用场景所对应的智能感知方案:基于多跳网络的地震数据智能感知方案和基于微地震事件检测的智能感知方案,完成了地震数据智能感知采集方法的总体设计。(3)根据基于多跳网络的地震数据智能感知方案和常规地震勘探数据采集工作的特点,提出了基于多跳网络的地震数据智能感知采集方法。针对常规地震勘探中存在的多跳数据传输不平衡问题,设计了基于多跳网络的压缩编码框架。该编码框架将压缩感知的观测过程与网络拓扑结构进行结合,在数据传输的同时进行基于测量矩阵的压缩编码。针对测量矩阵优化问题和数据重构问题,提出了基于生成对抗网络的压缩感知算法。该项关键技术将生成对抗网络与压缩感知理论相结合,根据压缩感知过程设计生成对抗网络的基本结构,以压缩感知理论约束生成对抗学习过程,通过生成对抗机制和卷积神经网络为压缩感知算法自适应地提取信号特征,从而实现高质量的数据重构。根据数值试验结果,基于多跳网络的地震数据智能感知采集方法能够在只引入信号能量的~1_(1000)左右的噪声水平下,将测线能够支持的最大采集规模扩大为原来的16倍,而且还将整条测线中数据传输的能耗降为原来的_8~1。(4)根据基于微地震事件检测的智能感知方案和压裂微地震监测数据采集工作的特点,提出了基于微地震事件检测的智能感知采集方法。针对压裂微地震监测中存在大量无关数据被传输的现象,提出了基于微地震事件检测的压缩采样技术。该项关键技术将基于机器学习的分类算法与压缩采样结合,根据地震信号在时间域的尺度和随机采样理论,设计了广义抖动随机采样方法在时间域对地震数据进行欠采样;然后根据微地震信号在局部形态、时序关系、概率分布三个方面的特征,设计了融合卷积神经网络、递归神经网络和概率图模型的机器学习算法来识别微地震事件,进而减少微地震数据在时间域的冗余度。针对微地震数据的稀疏表示问题,提出了基于奇异值分解的聚类字典学习算法。该算法通过奇异值分解提取信号的特征作为初始稀疏基,然后通过更新位置限制和聚类方法进行近似值优化以不断更新稀疏基。最后通过SPGL1算法使用该稀疏基将欠采样数据恢复成微地震信号。根据数值试验结果,基于微地震事件检测的智能感知采集方法能够在引入噪声的功率为原始信号的~1_(100)时,减少30%的数据记录能耗,且在低信噪比(-15dB)环境下维持高准确率(96.83%)的微地震检测,以减少大量无关数据的传输(通常减少90%以上),即在同等通信水平下,大幅度提高系统支持的最大采集规模(10倍)。综上所述,本文研究的分布式地震数据智能感知采集方法能够大幅度提高采集系统对带宽、能量的使用效率,从而能够在硬件条件不变的情况下,容纳更多的采集节点,实现更大规模的数据采集工作,进而为大规模地震数据采集系统的发展提供了新的思路,也为深部油气资源勘查装备的智能化研究提供了理论参考。"
426,基于遥感大数据和机器学习方法的地下水资源量动态评价模型研究,"地下水资源量表示地下水饱和含水层逐年更新的动态水量,即降水和地表水入渗对地下水的补给量。对地下水资源量进行评价,有利于为地下水资源保护和合理配置提供依据,有利于为合理高效开发地下水资源提供重要的技术支撑,有利于减少不合理开发利用地下水引起的生态及环境地质问题,还有利于经济社会的可持续发展和生态环境建设。利用遥感数据反演地下水资源量时,由于遥感数据属于大数据,具有不同的时间、空间尺度,而作为真值数据的地下水资源量公报数据获取成本高、周期长,因此数据量十分有限,这导致遥感数据与地下水资源量公报数据之间尺度不匹配。常用的解决数据尺度不匹配问题的方法是降低遥感数据尺度到与公报数据尺度相同的水平。但这又会导致遥感数据利用不够充分,且生成的模型的精度受到限制。基于此,本文提出了一种建立地下水资源量动态评价模型的方法,该方法保持遥感数据尺度不变,能够有效地匹配不同尺度的数据,并采用机器学习方法揭示遥感数据与地下水资源量公报数据之间的关联,从而实现对地下水资源量的动态评价。文中以广东省为例,建立了该地区的地下水资源量动态评价模型,并对该模型进行精度检验,且利用该模型实现了广东省以地下水资源量分级标准为依据的自然分区的划分,以及广东省短时间间隔的地下水资源量的实时变化监测。本文主要取得了如下成果和认识:1、本文提出基于遥感大数据和机器学习方法建立地下水资源量动态评价模型的方法,并利用该方法建立广东省地下水资源量动态评价模型,该模型具有较好的精度。研究中利用多源(MODIS、TRMM、Landsat ETM+/OLI、SRTM等数据)、多时相(2004-2015年)、多尺度的遥感数据及图文资料提取与地下水相关要素(按其随时间变化的频率分为动态要素和静态要素)的栅格数据。随后对地下水资源量公报数据进行栅格化处理,使之与要素数据具有相同的坐标系和空间分辨率,以获取大数据学习样本。然后将学习样本输入神经网络进行多次学习,每次学习完成后剔除部分误差较大的学习样本,最终利用比较符合规律的学习样本建立广东省地下水资源量动态评价模型。文中利用两个级别的行政分区(地级市和区县)的地下水资源量公报数据对模型进行检验,检验结果表明模型具有较好的精度:大行政分区(地级市)的地下水资源量公报数据共252个,其中相对误差小于20%的数据占66.4%,小于30%的数据占79.5%;小行政分区(区县)的地下水资源量公报数据共235个,其中相对误差小于20%的数据占60.9%,小于30%的数据占79.6%。2、本文提出的建模方法通过对地下水资源量公报数据进行栅格化处理,解决了要素栅格数据与地下水资源量公报数据之间尺度不匹配的问题。为了提高模型精度,在每次学习完成后剔除部分误差较大的样本,并经过多次学习,最终利用比较符合规律的学习样本建立地下水资源量动态评价模型。采用常用方法解决数据尺度不匹配的问题需要降低要素数据尺度到与地下水资源量公报数据尺度相同的水平。基于常用方法,学习样本数量有限(仅252个),利用这些样本建立的地下水资源量动态评价模型比利用本研究方法建立的地下水资源量动态评价模型的精度更低。3、利用地下水资源量动态评价模型计算广东省各行政区中各个像元的地下水资源量值,该值可以反映各行政区域内部地下水资源量不均匀分布的特征,弥补了一个地下水资源量公报数据表示一个区域的地下水资源量的整体状况的不足。4、利用地下水资源量动态评价模型计算广东省的地下水资源量,并制定地下水资源量分级标准,成功划定研究区以地下水资源量分级标准为依据的自然分区(文中以2007年和2009年为例)。这种自然分区比行政分区能更好地反映各个要素与地下水资源量的关系,能够更客观地评价地下水资源量,从而为各种科学研究提供更好的支撑。5、利用地下水资源量动态评价模型可以实现短时间间隔的地下水资源量动态变化监测。研究利用地下水资源量动态评价模型计算广东省三个时间段内不同时相(以天为间隔)的地下水资源量,并对各时段内地下水资源量的变化情况进行分析。"
427,面向板式产品定制生产的组批与排样协同优化方法,"板式产品是指以板材为主要原料,以平面加工为主要加工形式,由多种板式配件经过装配而形成的一类产品,常见于PCB电路板、板式家具、3C家电、玻璃、钣金、建材与印刷等诸多产品。板式产品制造企业常面临着“多品种小批量”的定制生产需求,生产订单变更频繁、交货期紧迫,这一生产特征导致生产过程批次多、换产频繁,进而导致原材料利用率与生产效率低下、设备稼动率不平衡、资源配置不合理、交期保障困难等一系列问题,迫切需要提高订单组批能力,降低生产批次。下料排样是板式产品制造过程的首道工序,直接影响生产批次构成和后续工艺流程的执行,进行订单组批与排样的协同优化有利于实现板式产品定制生产过程的系统性优化,同步提高原材料利用率和减少生产批次,降低生产成本,提高生产效率,研究订单组批与排样的协同优化问题具有重要的理论研究价值和实际工程意义。论文重点研究板式产品定制化生产中排样优化问题、订单组批问题以及组批与排样协同优化方法。主要的研究工作如下:(1)研究与分析了板式产品定制化生产的共性需求与优化问题。对板式家具、中空玻璃、PCB样品板三类主要板式类产品生产的定制设计需要与优化问题进行了深入的分析,研究了板式产品生产特征的相似性传递过程(几何-工艺-运动-优化),揭示了这一类定制产品生产过程的共性耦合优化问题“组批-排样-X优化”,并提出了涵盖子问题求解算法和解耦算法的求解思路。(2)针对满足“一刀切”板材长度可变的二维矩形排样优化问题,提出了基于组化的改进型启发式搜索算法BBHSA。在BBHSA中,矩形件被合拼成块,这些块提供了良好的布局元素,并作为启发式搜索过程中构造树的基本组成部分。排样过程中使用了排放和分割、放宽和收缩以及在线组块三个基本操作进行搜索,以加快搜索速度,提高解的质量。该算法对Benchmark上零浪费情况下案例具有较好的计算效率,能够对文献中提及的几乎所有的零废料标准案例得到最优解。(3)针对考虑叠板组批的切割与排样协同优化问题,提出了一种基于叠板数分层的多叉树递归搜索算法。建立了使用原材料和切割加工时间造成总成本最小化的数学模型;提出了一种基于叠板数分层的排样递归搜索方法;采用基于多叉树结构的分层迭代式协同优化机制,并利用多个利用率阀值进行多叉树分层迭代。与行业主流软件计算对比表明,该方法能提高原材料利用率和切割效率,降低生产总成本。(4)针对大规模排样优化计算时间长等问题,提出了一种基于机器学习的排样下料率预测代理模型。通过学习实际生产订单中的排样历史数据,运用RandomForest模型、XGBboost模型与Lightgbm模型对历史订单排样经验数据进行分析与学习,能快速的对新订单任务的排样优化结果进行精准预测。(5)针对板式产品定制化生产中订单组批与排样协同优化问题,提出了一种基于下料率代理模型的订单组批与排样迭代优化方法。提出了一种满足交货期与生产工艺约束的凝聚层次聚类算法进行订单组批优化,利用代理模型对组批方案进行排样利用率预测与方案评估,通过代理模型对组批方案筛选,再进行组批与排样问题的迭代优化,能大幅缩短搜索时间。基于上述订单组批与排样协同优化方法,开发了相关系统并在企业开展实际应用,验证了算法的工程应用价值。论文相关方法/算法能够为板式类产品相关企业提供高效的订单组批与排样优化服务。"
428,基于普适计算的降雨探测和度量问题研究,"如果能够便捷和低成本地获得实时的并且在空间上细粒度的降雨信息,对于气候研究,天气预测,水资源管理,农业生产,城市规划以及自然灾害监控,比如洪水、侵蚀、内涝、山体滑坡和泥石流,将有极大的帮助。同时,精确的降雨信息对于人们的日常生活同样也具有重要的意义。一方面,降雨无论是在时间上还是在空间上,都具有高度的多变性。另一方面,现在被广泛使用的降雨探测和度量技术,比如,雨量计、气象雷达和卫星、摄像机以及无线链路等,都会具有一定的局限性,比如数据采集过程需要参与者的帮助,数据处理过程需要大量的计算能力和能量,探测和度量的结果不具备实时性,无法获得精确的降雨观察数据等。近些年以来,随着移动智能设备的不断更新换代以及移动网络的大规模部署和不断地升级,以人为中心,各种设备渐渐开始组成网络围绕着人运行。计算开始融入人们的生活里,变得无处不在。普适计算又重新回到了我们的视野当中。基于上述两点,本文将普适计算技术应用于降雨的探测和度量,这将有助于实时精确地获取某一区域的降雨数据。论文的主要研究工作和贡献如下:一、针对户外并且远离道路的场景,研究了基于环境声音识别的降雨探测和度量问题,利用了众包所得到的声音片段,从段和帧两个不同的粒度进行了特征提取,设计了基于高斯混合模型的特征融合算法,给出了一套全新的降雨探测和度量系统,并且进行了实验验证,证明了系统可以有效地探测当前是否正在下雨以及对当前的降雨强度进行度量。二、针对户外并且靠近道路的场景,研究了基于多普勒效应的道路积水度量问题,描述了对于经过车辆识别系统的设计和实现细节,在时频谱上提取了多普勒效应的轮廓曲线,采用了不同的算法,对当前时间和位置的道路积水进行了度量。实验结果验证了该研究的可行性。三、针对车内的场景,研究了基于车联网的降雨探测和度量以及道路拥塞度量问题,在车辆内部的复杂环境中,识别了雨刷刮擦车辆玻璃所产生的声音,设计了平均幅度差算法,提取了雨刷刮擦的轮廓曲线并且计算了其出现的不同频率,以此为基础给出了降雨强度,并且进行了实验验证,证明了该研究的有效性。"
429,基于机器学习的测井曲线补全与生成研究,"机器学习算法尤其是神经网络,已经成为工程领域建模的有力工具。这些方法可以从更高维度拟合不同变量之间的高度非线性映射关系,尤其适用于工程中有观测数据,但是变量间映射关系过于复杂,导致传统物理模型或者经验模型无法有效解决的问题。神经网络在工程中的一个重要的应用领域是石油工程,尤其是可以应用于对勘探开发至关重要的测井。测井是一种用来描述并分析地下情况的物理测量手段,对于油气勘探和开发具有重要意义。地质学家和工程师可以基于测井数据建立精确的地质模型,并设计勘探开发策略。然而,测井曲线的采集往往是昂贵且耗时的,在实际测量中由于各种客观原因,经常出现测井数据缺失的问题,也可能出于成本考虑而放弃测量某些整条测井曲线。因此,测井曲线的补全与生成是一个具有学术和工程价值的研究。然而,由于地层情况复杂且存在各向异性,所以不同测井曲线之间的映射关系极为复杂,无论是传统的物理模型还是经验模型,都难以准确描述测井曲线之间的关系,无法对残缺测井曲线进行补全或者对未测量的测井曲线进行生成。在本论文中,我们针对测井曲线补全和生成的问题,提出了利用机器学习方法的高效解决方案。同时,我们发现机器学习算法直接应用于工程领域的过程中,普遍存在四个问题。针对这些问题,本论文将物理约束作为先验知识引入到模型中,并将历史拟合领域中的算法融合到神经网络中,提出了一类新型的集合神经网络和集合长短期记忆神经网络。利用新构建的模型,我们成功将领域知识融合到机器学习算法中,使得模型更符合物理机理,进一步提升了模型的预测准确度。具体而言,第一个问题是目前神经网络与工程问题的结合过于直接,多是单向的应用过程,缺少与具体领域知识的结合。实际上,将领域知识引入到神经网络中,相当于为模型提供了丰富且有价值的先验知识,有利于构建出更符合物理机理的模型,打破模型效果提升的瓶颈,进一步提升模型的预测准确度。简单直接地应用神经网络并不能保证模型的预测效果。神经网络与应用场景的结合需要充分考虑领域知识,不能简单的单向应用,而应该将领域知识与神经网络有机融合、双向耦合。一方面利用神经网络描述复杂映射关系的能力,另一方面利用问题本身的特点反哺算法与模型,才能使得模型与问题更加全面有效地结合,并改善模型性能。第二个问题是缺少对预测结果不确定性的量化分析。在工程应用中,由于判断结果往往会产生较大的经济甚至社会影响,所以对于预测结果的不确定性分析是极其重要的。任何模型预测结果中的不确定性是无法避免的,包括由于噪声数据引起的数据不确定性,以及来自于模型参数和模型结构的模型不确定性。因此,神经网络的预测结果也不可能永远是准确的,如果模型能够对预测结果提供不确定性分析,则可以在预测结果不确定性高的时候将问题交由人工判断处理。通过这种手段,能够有效降低由于预测有误所带来的损失。因此,对于拥有较大经济价值或关乎生命的应用场景而言,模型输出结果的不确定性信息极其重要。第三个问题是数据的易得性和数据量。高质量数据对于训练机器学习模型而言极其重要。然而对于大多数工程问题的数据而言,往往存在两个特点:有些情况是数据量巨大,但是数据非结构化且缺失值和异常值比例较高,真正可用数据较少;另一些情况下数据质量较高,但是数据的采集往往是耗时且昂贵的。数据易得性和数据量的问题极大地制约了机器学习在工程中的实际应用。最后一个问题是缺少无梯度算法。目前神经网络的激活函数和损失函数必须易于求导,否则无法通过反向传播算法进行迭代优化。虽然机器学习领域中提供了许多易于求导的损失函数,但是在工程应用中,许多直接有效的损失函数往往是结合领域知识且难以求导的。此外,这一特点也约束了神经元的结构,限制了对预测能力更强的新型网络的探索。为了解决上述问题,本研究主要完成了如下工作:1.将机器学习算法应用于能源工程中,解决测井曲线补全与生成的问题。考虑到储层具有地质连续性,选择善于处理序列数据且可以学习长期相关性的长短期记忆神经网络(LSTM)作为预测模型的基础。进一步基于LSTM构建了串级长短期记忆神经网络(Cascaded LSTM),并用于生成人工测井曲线。2.将物理约束和领域知识引入机器学习算法,通过在LSTM中增加机理模拟网络结构和自适应分层归一化两种约束,构造了物理约束长短期记忆神经网络(PCLSTM)。利用PC-LSTM基于常规测井曲线预测地质力学测井曲线,并成功构建地质力学模型。这一方法有利于根据易于获得的常规测井曲线构建精确地质模型,对实际勘探开发具有重要意义。3.将能源工程领域中的集合随机最大似然法(En RML)用于全连接神经网络(FCNN)和LSTM,通过将传统网络(FCNN和LSTM)的前馈过程与En RML结合,构造出基于协方差矩阵进行迭代优化的集合神经网络(ENN)和集合长短期记忆神经网络(En LSTM)。该类网络基于贝叶斯定理构建,可以提供不确定性分析,可以针对小数据量训练,且不依赖于导数计算,更适合于工程实际应用。在En LSTM中,通过引入模型参数扰动方法,有效解决了过度收敛问题,同时引入了标准化观测值的保比例扰动方法。最后,将En LSTM应用于测井曲线生成问题,并取得了较好的效果。"
430,基于机器学习的多元辅助肿瘤诊断相关研究,"近年来,肿瘤给人类健康带来越来越严峻的挑战,而且随着医疗数据的积累和人工智能技术的突破性发展,如何高效地辅助肿瘤诊断已经成为生物信息和计算机等学科所面临的挑战性难题。对肿瘤患者的临床、基因、代谢和医疗影像等数据构建机器学习模型,可以从不同角度理解和分析肿瘤发生发展的状态,从而达到高效地辅助肿瘤诊断的目标。为此,本文基于机器学习理论,针对肿瘤发生发展不同阶段的特点和多种模态医疗数据,围绕辅助肿瘤诊断中的四个关键问题进行了相关研究。本文研究的第一个问题是如何选择合适的配对特征选择算法(Matched-Pairs Feature Selection,MPFS)用于筛选肿瘤差异表达基因。肿瘤发生发展过程中只有很少的基因会发生差异性表达,筛选出这些基因将有助于在更深层次上理解肿瘤的形成机制,从而实现更精确的辅助肿瘤诊断。目前研究者利用特征选择方法在筛选差异表达基因上取得了大量的研究成果,然而考虑了基因表达数据的病例-对照配对特性的配对特征选择方法却尚未得到广泛的开发和研究。因此,本文第3章对近十年的配对特征选择方法进行了整理总结,给出了其一般性定义,并将其归纳为三大类型,分别为统计假设检验类、条件逻辑斯特回归类和提升策略类,最后构建大量实验在性能和运行时间上对这三类方法进行了全面的对比分析,为研究者选择合适的算法提供一些参考依据。本文研究的第二个问题是如何更精确地筛选出基因配对数据中的肿瘤差异表达基因。肿瘤组织中不仅含有肿瘤细胞,还包含其它非肿瘤细胞,其肿瘤纯度对基因差异表达分析具有重要的影响。但是目前的配对特征选择算法在对配对数据之间的差异进行建模时,却没有考虑到病例实验数据中的肿瘤纯度问题。因此,本文第4章提出了一种新的配对特征选择方法用于筛选肿瘤差异表达基因,该方法基于配对t检验方法,首先估计出每个样本病例实验数据中的肿瘤纯度,然后估计出病例实验数据的真实基因表达值,最后计算出优化后的配对t检验统计量,并根据阈值筛选出差异表达基因。实验结果表明该方法具有较高的灵敏度和特异度,而且筛选出的基因也具有较强的生物学意义。本文研究的第三个问题是如何更高效地利用医疗影像数据预测基因突变。针对已筛选出的肿瘤标志基因,判断其是否发生基因突变,具有重要的辅助肿瘤诊断价值。医疗影像是最常用的辅助肿瘤诊断方式之一,具有容易获取、非侵入性和成本低的优点,而且研究者们发现影像特征与基因突变之间存在关联,并开始利用医疗影像数据预测基因是否发生突变。但是目前的算法具有人工提取特征、两阶段建模以及无法融合多种模态医疗影像数据等缺点。因此,本文第5章提出了一种多模态三维卷积神经网络预测算法(Multimodal 3D Dense Net,M3D-Dense Net)用于利用医疗影像数据预测脑神经胶质瘤患者的异柠檬酸脱氢酶基因(Isocitrate Dehydrogenas,IDH)是否发生突变。该方法使用三维卷积神经网络自动提取影像特征,并利用多通道技术融合多种模态影像信息,端到端地实现了基因突变的预测。该方法具有良好的预测性能和泛化能力,而且结合了医疗影像和基因数据,使辅助肿瘤诊断更加多元化,并降低了其成本。本文研究的第四个问题是如何更准确地检测出医疗影像中的肿瘤病灶。检测出医疗影像中的肿瘤病灶是肿瘤诊断的重要步骤,也是基因测序、基因与医疗影像结合分析的基本前提,具有重要的临床意义。目前对乳腺X线影像中的肿瘤病灶进行检测的算法只是基于单个视图进行建模,并没有考虑到肿瘤病灶在影像的两个视图中存在相互联系。因此,本文第6章提出了一种双视图关系区域卷积神经网络检测算法(Cross-view Relation Region Convolutional Neural Network,CVR-RCNN)用于自动检测乳腺X线影像中的肿瘤病灶。该算法是第一个考虑双视图信息的乳腺X线影像肿瘤病灶检测算法,采用了两路目标检测架构同时对两个视图中的病灶进行检测,并提出了一个双视图关系模块对两个视图中肿瘤病灶间的关系进行建模。该算法具有较高灵敏度和较低假阳率,而且能够辅助临床医生筛查肿瘤,具有一定的临床应用价值。本文的主要贡献是基于机器学习理论,围绕辅助肿瘤诊断中的四个关键问题,从不同的角度进行了相关算法研究:在基因的角度对比分析了配对特征选择方法,并提出了一种基于肿瘤纯度信息的配对特征选择方法;在医疗影像的角度提出了CVR-RCNN算法用于自动检测医疗影像中的肿瘤病灶;在两者结合的角度提出了M3D-Dense Net算法用于融合多种模态的医疗影像数据预测基因突变。本文的研究工作具有较强的前沿性、理论意义和临床应用价值,而且相互之间存在联系和支撑,共同构成了一个初步的多元辅助肿瘤诊断体系,为未来研究工作中实现更精准的多模态数据辅助肿瘤诊断体系提供了良好的技术储备。"
431,急性胰腺炎相关并发症人工智能预测模型建立及效能探讨的研究,"急性胰腺炎(acute pancreatitis,AP)是消化科常见的急危重症之一,其发病率逐年升高。重症急性胰腺炎(severe acute pancreatitis,SAP)病情危重,死亡率高,而持续性器官衰竭和胰腺感染坏死是决定AP预后、增加病死率最重要的两个因素。与SAP相比,中度重症急性胰腺炎(moderately severe acute pancreatitis,MSAP)预后相对较好。若能尽早明确AP分度、预测并发症发生的风险,有利于制定最佳的治疗方案,改善预后。对于高风险人群给予加强监护、控制全身炎症反应综合征(systemic inflammatory response syndrome,SIRS)、保护心肺肾等重要脏器以阻断器官功能衰竭等严重并发症的发生。目前最常用的评价AP严重程度及预后的单个指标是C反应蛋白(C-reactive protein,CRP),评分系统则包括急性生理与慢性健康评分(Acute Physiology and Chronic Health EvaluationⅡ,APACHEⅡ)、Ranson评分、床旁急性胰腺炎严重度评分(bedside index for severity in acute pancreatitis,BISAP)和CT严重程度指数(CT severity index,CTSI)等。这些评价指标或系统对于预测AP严重程度、并发症或预后有一定价值,但仍存在局限性,如及时性较差、操作繁琐、准确性有待提高等,临床工作者极需一种更及时、准确、简便的模型来预测AP的并发症及预后。由于近年来研究者逐渐认识到凝血功能异常在AP的病理生理过程中有重要作用,凝血系统激活和炎症是两个相互促进的病理过程,故有研究者提出凝血指标可能预测AP的严重程度、并发症或预后,如D-二聚体预测SAP的敏感性和特异性均较高,但凝血指标是否能预测AP的严重程度或并发症还需要高质量的临床研究来证实。相比于凝血象,血栓弹力图更能反映凝血状态全貌,是一种准确、快速的凝血监测工具,血栓弹力图中R值、K值和MA值分别反映了凝血因子活性、纤维蛋白原水平和血小板的数量与功能。在定性和定量评估凝血状况方面,血栓弹力图较凝血象更有优势,但目前血栓弹力图用于预测AP并发症的研究极少。鉴于人工智能中的机器学习算法具有强大的数据处理和分析能力,能从众多的特征中甄别出与结局指标关联性较强的特征来获得稳定、高效的预测模型。因此本课题较全面地筛选AP患者的临床指标,利用机器学习算法来建立预测AP并发症的模型,并获得与AP并发症关系紧密的临床指标,从而探讨凝血指标在预测模型中的作用。首先,我们对轻症急性胰腺炎(mild acute pancreatitis,MAP)和SAP患者凝血指标的差异进行了Meta分析,以明确凝血指标是否与AP的病情严重程度相关,从而获得凝血指标有助于预测AP并发症的证据,为后面的研究奠定基础;然后,我们较全面地回顾性分析了263例MSAP和SAP患者入院时的血常规、凝血(包括凝血象和血栓弹力图)及炎症等指标,基于人工智能中的机器学习算法建立支持向量机(support vector machine,SVM)、逻辑回归分析(logistic regression analysis,LRA)和人工神经网络(artificial neural network,ANN)三种模型预测多器官功能衰竭(multiple organ failure,MOF)发生的风险,分析三种模型的预测效能,并与临床工作中所使用的APACHEⅡ、BISAP评分比较预测效能;最后,我们还建立了ANN模型预测腹腔内感染,比较其与LRA的预测效能,期望获得较好的预测腹腔内感染的模型。研究内容:1.MAP和SAP凝血指标比较的Meta分析本研究应用Pubmed/Medline数据库、Embase数据库、Cochrane对照试验中心数据库共3个国际上公认度较高的数据库检索关于AP患者凝血指标水平的临床研究,对报告MAP与SAP凝血指标有无差异的13篇文献进行了Meta分析。2.建立并验证人工智能中机器学习模型对MSAP和SAP多器官功能衰竭的预测本研究对2014年7月1日至2017年6月30日期间陆军军医大学的附属医院(大坪医院、西南医院和新桥医院)所收治的凝血指标检查完整的MSAP和SAP患者进行了回顾性分析,AP的诊断标准参考了2012年修正的亚特兰大指南。收集患者入院时的一般资料包括性别、年龄、身高、体重、体重指数、高血压和糖尿病病史、病因、临床指标包括血常规、凝血象、血栓弹力图、炎症指标、肾功、APACHEⅡ和BISAP评分,根据入院48h后的改良Marshall评分判断是否存在MOF。然后根据患者有无MOF,分为MOF组和无MOF组,使用SPSS 23.0软件进行单因素分析以筛选出两组间有差异的指标;使用Matlab 2014软件编写程序SVM、LRA和ANN,将筛选出有差异的指标作为机器学习的特征,利用5折交叉验证得到曲线下面积(area under the ROC curve,AUC)值最大的最佳特征组合,从而获得预测MOF的SVM、LRA和ANN模型,并比较这三种模型与APACHEⅡ和BISAP评分的预测效能。3.人工智能中ANN模型对MSAP和SAP腹腔内感染的预测研究对象及收集的临床数据同第三部分研究,腹腔内感染的诊断标准参考胰腺感染坏死的诊断标准即增强CT检查出现气泡征或腹水培养细菌或真菌阳性,且判断患者入院时是否存在SIRS。使用SPSS 23.0软件进行统计学分析及模型建立。首先,将MSAP和SAP患者分为有腹腔内感染组和无腹腔内感染组,单因素分析筛选出两组间有差异的指标进入向后LRA。然后,LRA评价出哪些指标是腹腔内感染的独立预测因子,并且得出逻辑回归方程;同时建立ANN模型,输入层为有腹腔内感染组和无腹腔内感染组经单因素分析结果显示为有差异的指标,输出层为有腹腔内感染和无腹腔内感染,整组MSAP和SAP人群被随机分为训练集(70%)和验证集(30%)进行ANN建模。最后,比较ANN和LRA两种模型的预测效能。研究结果:1.MAP和SAP凝血指标比较的Meta分析1.1本次Meta分析共纳入13项研究,其中11项为前瞻性队列研究,2项为病例对照研究。总共包括1175例AP患者,其中MAP 684例,SAP 491例。研究人群来自中国、波兰、意大利、瑞典、英国、印度、葡萄牙和塞尔维亚。1.2本研究较全面地比较了MAP和SAP患者入院24h内的凝血指标的差异,6项研究比较了333例MAP和199例SAP患者凝血酶原时间的差异,5项研究比较了258例MAP和164例SAP患者活化部分凝血活酶时间的差异,4项研究比较了203例MAP与180例SAP患者国际标准化比值的差异,9项研究比较了475例MAP与308例SAP患者纤维蛋白原水平的差异,7项研究比较了407例MAP与324例SAP患者D-二聚体水平的差异。1.3 Meta分析结果显示,SAP患者入院24h内的血浆凝血酶原时间较MAP患者平均延长1.76秒,纤维蛋白原水平较MAP患者平均高0.82 g/L,D-二聚体水平较MAP患者平均高1.37 mg/L,两组间活化部分凝血活酶时间和国际标准化比值无显著差异。1.4 SAP患者的凝血酶原时间、纤维蛋白原和D-二聚体水平改变较MAP明显,提示SAP的凝血系统和纤溶系统激活程度较MAP更显著,凝血指标或许可能成为AP严重程度的预测因子。2.建立并验证人工智能中机器学习模型对MSAP和SAP多器官功能衰竭的预测2.1 SVM、LRA和ANN三种人工智能模型用于预测MSAP和SAP患者发生MOF的风险准确性均较高,与APACHEⅡ评分无显著差异,SVM的准确性高于BISAP评分,它们预测MOF的AUC值分别为0.840(0.783-0.896)、0.832(0.773-0.890)、0.834(0.777-0.890)、0.814(0.759-0.869)和0.774(0.716-0.833)。2.2血栓弹力图中K值、HCT、IL-6和肌酐是这三种模型共同的预测指标,提示凝血和炎症指标对于预测MOF有重要作用。2.3 SVM、LRA和ANN三种人工智能模型对于预测AP诱发的MOF有较好的前景,因为它们的评分效能与APACHEⅡ评分相当,SVM优于BISAP评分,但机器学习模型应用更简便;三种人工智能模型中我们推荐ANN模型,因其仅需4项指标即可做出评估,易于获得。3.人工智能中ANN模型对MSAP和SAP腹腔内感染的预测3.1 ANN模型预测MSAP和SAP腹腔内感染比LRA模型有更好的特异性(89.44%vs 77.46%,P<0.05)、阳性预测值(86.73%vs72.65%,P"
432,面向蛋白互作预测的序列数据特征识别研究,"蛋白质是所有生物体的基石,除少数以单体的形式发挥作用外,大部分都与其他蛋白质协同发挥作用。基于机器学习的蛋白互作预测结合蛋白序列特征提取方法和机器学习算法,采用大规模数据统计方式,从整体水平上揭示蛋白质功能、了解蛋白间相互作用机制以及发现新的蛋白结合规律,对“破译分子机制”、“构建蛋白相互作用网络”、“开发药物”和“治疗优化”等蛋白质研究领域具有非常重要的指导意义。蛋白序列特征提取是蛋白互作预测首要解决问题之一,其性能的优劣直接影响机器学习算法处理蛋白序列数据的性能。因此,如何改进特征提取方法和如何优化机器学习算法是目前机器学习在生物信息领域研究中亟待解决的问题。目前,人们在采用蛋白序列特征提取与机器学习模型训练分步开展的方式研究蛋白互作预测方面取得一系列的进展。但是,这种割裂蛋白序列特征提取与机器学习模型训练关系的方式,未能有效提取蛋白序列的全序信息及长距效应,导致难以提高蛋白互作预测性能。本文从改进蛋白序列特征提取方法、引进机器学习模型优化技术以及端对端蛋白互作预测等方面开展研究,以有效提高蛋白互作预测性能,促进蛋白互作预测技术在蛋白相互作用相关研究领域的应用推广。主要工作概括如下:1、针对现有蛋白序列特征提取方法未考虑整个氨基酸序列的有序关系这一问题,提出一种新的特征提取方法-序列矩阵(Matrix of Sequence,MOS)。该方法在基于偶极子和侧链体积的氨基酸分类的基础上,将蛋白序列抽象成维数不一致的向量,并充分利用蛋白序列中每个元素的前后顺序关系,将蛋白序列编码成维数一致的向量,以解决不能直接把蛋白序列输入机器学习算法中进行分类识别的问题。2、以提高蛋白互作预测性能为目标,采用K-近邻算法(K-Nearest Neighbor,KNN)、决策树(Decision Tree,DT)和随机森林(Random Forest,RF)等三个传统机器学习模型以及深度神经网络(Deep Neural Network DNN)来研究基于氨基酸序列的蛋白互作预测,同时结合三元组(Conjoint Triad,CT)、自协方差(Auto Covari-ance,AC)、局部描述符(Local Descriptor,LD)以及序列矩阵(Matrix of Sequence,MOS)等方法,构建了十六种蛋白互作预测模型。结果表明,引入了 Dropout等网络优化技术的深度神经网络模型取得最佳评价指标,和现有结果相比,提高了蛋白互作预测性能。其中,CT、AC、LD在基准数据集上分别获得98.12%、98.17%和95.60%的最优准确率,MOS获得了 96.34%的准确率、99.28%的召回率和98.79%的受试者工作特征曲线下面积(Area Under the Receiver Operating Characteristic Curve,AUC),和现有特征提取方法相比,MOS可减少损失率,大幅节省训练时间。3、针对蛋白互作预测过程中存在的蛋白序列特征提取方法与机器学习模型训练过程割裂问题,提出基于长短时记忆网络(Long Short-Term Memory,LSTM)的端对端蛋白互作预测模型。该模型将蛋白序列特征提取作为机器学习模型的一部分,使特征提取与模型训练融为一体,通过训练获得较优的蛋白序列特征提取方法,以提高蛋白互作预测性能。结果表明,端对端蛋白互作预测模型获得了97.46%的最优准确率,提高了蛋白互作预测性能。"
433,毫米波大规模MIMO系统中的混合预编码技术研究,"随着宽带移动无线设备的大数据量需求,在低于5G系统的频率下已无法满足比4G系统更高速率、更大系统容量、更大的带宽需求。为了解决频谱资源短缺的问题,毫米波通信技术成为学术界研究的热点。但在毫米波频段中,信号具有很大的路径损失,且信道具有空间选择性,为克服毫米波技术的缺点,研究人员近年来将毫米波通信系统和Massive MIMO系统相结合,可以有效实现两种技术的优势互补,提升系统频谱效率,提高系统的容量,是5G研究不断推进的一个重要的方向。毫米波大规模MIMO通过混合收发器来实现,混合收发器将高维模拟信号处理单元和低维数字信号处理单元结合在一起,基于混合收发器的混合预编码技术因具有抗多径衰落、抗干扰、高频谱效率、高能量效率等特性,并且能降低系统的硬件成本和功耗,成为毫米波大规模MIMO系统中重要的信号处理技术。本文针对毫米波大规模MIMO系统中的混合预编码技术开展研究,提出了基于不同毫米波大规模MIMO发射机架构的混合预编码方法,解决了现有预编码方法硬件成本高、能耗高、系统复杂度高、能量效率低等问题。本文的主要工作归纳如下:1.提出了一种基于改进矩阵广义低秩逼近算法的混合预编码方法。首先将混合预编码算法转化为模拟预编码和数字预编码两级预编码联合设计,模拟预编码算法采用改进的矩阵广义低秩逼近(Generalized Low Rank Approximations of Matrices,GLRAM)算法来获取模拟预编码矩阵/组合矩阵,以获取大规模MIMO系统所提供的高阵列增益。具体地,在基带预编码器/组合器设计阶段,利用系统的射频等效信道,考虑期望用户接收信号的空域特性,在消除用户间干扰的同时增强期望用户的信号功率,采用改进的块对角化算法获取数字预编码矩阵,得到系统性能最佳的混合预编码方案;最后,建立仿真环境对所提混合预编码算法进行数值仿真和对比。仿真结果表明,所提出的混合预编码算法,能减少迭代计算次数,与现有的基于重叠子阵的混合预编码算法相比,具有更高的频谱效率和较低的实现和复杂度,具有较高的应用价值。2.针对现有的基于透镜阵列的毫米波大规模MIMO系统只考虑了波束选择算法,没有将波束选择算法与数字预编码算法相结合,以及实际部署中移相器的分辨率有限的问题,受雷达中重叠天线阵列的启发,提出了一种带透镜阵列的低分辨率重叠移相器网络的混合预编码架构,基于此架构提出了一种基于量化波束对准和维纳滤波的两级联合混合预编码算法,具体地,模拟预编码算法采用量化的波束对准方法获得阵列增益较高的模拟预编码。数字域采用基于最小均方误差准则的维纳滤波器预编码算法以获得多路复用增益。仿真结果表明,所提出的基于低分辨率的重叠移相器波束选择网络的混合预编码方案不仅能有效地获得满意的和速率性能,而且在能量效率方面优于传统方案。3.针对现有部分毫米波大规模MIMO系统存在硬件功耗大,复杂度高,能量效率不高的问题,提出了一种基于机器学习的毫米波Beamspace MIMO混合预编码方法。首先,提出了一种透镜阵列和部分连接开关选择网络的毫米波Beamspace MIMO发射机架构,其中波束空间MIMO系统的模拟部分是由一个部分连接的开关选择网络来实现的,而不是由一个子连接的移相器选择网络来实现的。其次,基于此新型混合架构,提出了一种基于机器学习中的交叉互熵(Cross Entropy,CE)算法的混合互熵(Hybrid Cross Entropy,HCE)预编码方法,使混合预编码的概率分布达到最大,从而使系统的和速率达到最大。最后,仿真结果表明,所提出的基于HCE的混合预编码不仅能有效地获得满意的和速率性能,而且在能量效率方面优于基于其它混合预编码方案。"
434,面向多任务模式学习与外推的自适应高斯过程算法研究,"在机器学习中,自适应多任务模式学习和外推算法可以广泛应用在气候预测、市场波动预警、环境监测、河流流量变化估计等物联网场景中。近年来,多任务高斯过程MTGPs(Multi-task Gaussian Processes)在学习任务间的协同关系和多任务并发预测上取得了显著的进展,比如:从线性结合相互独立的单任务高斯过程模型到直接对任务间的交叉协方差结构建模,使其可以有效地同时对多任务进行自适应模式学习,因而提高了多任务并发预测的精度。值得注意的是,所有这些具有代表性的MTPGs都必须对任意变量间两层相关关系进行编码,分别是单任务输入空间内随机变量的相关关系和任务间的协同关系,但是现有方法SM(Spectral Mixture)、GPRN(Gaussian Process Regression Network)、CSM(Cross Spectral Mixture)在可表达性和可解释性上还需进一步提升,MOSM(Multi-output Spectral Mixture)则存在多任务与单任务的兼容性问题,而这些问题都影响了自适应多任务模式学习和外推预测的准确率。为了纠正和更好地数学描述这两层相关关系,本论文提出了一种结构化可解释的通用卷积谱混合成分核函数GCSM(Generalized Convolution Spectral Mixture)来构造单任务高斯过程,然后利用这种核函数的交叉卷积机制将其平滑扩展到多任务高斯过程学习的场景中,从而得到了MOCSM(Multi-output Convolution Spectral Mixture)和GCSM-CC(Generalized Convolution Spectral Mixture with Cross Coregionalization)。首先,在高斯过程(Gaussian Processes,GP)机器学习中,表示能力较强的谱混合成分核函数SM可以自适应地从数据中发现模式、进行外推甚至描述变量间的负协方差。由于SM仅仅只是准周期高斯成分的线性加权级数,使得SM难以明确地表示这些成分间的依赖关系。本论文研究了SM成分间的依赖关系、依赖关系的时延和相位特点以及这些依赖关系的作用。通过分析后验协方差和代表性的实例,本论文提出了一种框架来分析这种依赖关系的存在性。进一步扩展SM使其可以明确地表示SM成分间的依赖关系,在本论文称之为GCSM。构造满足正定条件的GCSM可以分为两个步骤:1.改造SM成分成为使其可以包含时延θ和相位?,然后利用卷积将改造后的SM成分开根号分解为基成分;2.构造基成分之间交叉相关系数,本质上等同于交叉卷积,该交叉相关系数经过傅里叶变换后成为交叉谱密度。在该方法中,SM仅仅考虑到了基成分的自卷积。如果不考虑时延和相位,相比SM,GCSM没有额外增加超参数的数量。无论是在合成数据集还是在真实数据集上,全面的实验分析和比较表明对SM成分的依赖进行表示可以有效提高GP的自适应学习能力和外推性能,同时还可以利用交叉验证技术来设置依赖关系中是否包含时延和相位。这种性能提升在对自然现象的建模中特别明显,因为自然现象往往较少受到人类活动的干扰,而受到物理因素的相干干涉影响较大。其次,受到GCSM的启发,本论文利用交叉卷积来构造了一个新的多通道多输出卷积谱混合成分核MOCSM来解决多通道多输出高斯过程的自适应学习,在这里多通道多输出高斯过程和多任务高斯过程本质一样,一个通道输出对应于一个任务。在MOCSM中,利用交叉卷积来表示不同通道间的依赖关系,该依赖关系也具有时延和相位特点。MOCSM可以同时预测多个输出通道,并且具有更好的性能和兼容性。通过在合成数据集和实际物联网数据集上的全面实验表明MOCSM在自适应学习能力上具有明显的优势并且超过当前的最新模型。特别是,考虑一种特殊情况,即当只有一种输出通道需要拟合时,MOCSM可以完美的降级为SM,这是其他的模型所不具备的。与最近提出的MOSM模型做全面对比,在MOSM的幅度信息中混合了信号方差(signal variance)和距离缩放因子(length scale),当不同通道中的谱密度比较相似时,MOSM会产生不合理的局部协方差缩放效果。因此,显然MOCSM具有更好的自适应兼容性和普适性。然后,本论文进一步分析了MTGPs中的高斯过程回归网络框架GPRN,并且针对任务间的协同关系提出了一种参数化解释。GPRN用神经网络来表示多任务建模的协同关系,而在所有基于GPRN的方法中,全部使用了多个通道(神经元)的线性加权和来描述单个任务输入空间的变量关系和任务间的协同关系,而忽略了通道间的交互耦合。鉴于此,本论文赋予该神经网络的多个通道间存在依赖关系并对其进行编码。本论文提出了一种新的基于神经网络的多任务高斯过程模型,该模型可以同时模拟两层依赖关系,分别是单任务输入空间内随机变量内在成分间的依赖(即变量内在依赖)和任务间不同协同关系通道的依赖(任务交叉依赖),该模型提升了现有方法的可表达性和可解释性。具体而言,本论文利用交叉卷积来描述GPRN神经网络中各独立通道(神经元)之间的变量内在依赖,其中每个通道都由一个SM成分来描述,再利用耦合区域协同来描述任务间交叉依赖。这两个层次的依赖建立了一种信息管道使得GPRN神经网络中不同的神经元之间可以通信。本论文把这种对GPRN神经网络中神经元之间依赖关系进行显式建模的方法称为通道交叉卷积和耦合区域协同的高斯过程回归网络GCSM-CC。以上方法兼顾了单任务和多任务高斯过程的不同特点,具有很好的兼容性、可解释性、可表达性、普适性和自适应模式学习能力。在合成数据集和物联网数据集上的大量实验表明,本论文提出的方法可以有效地实现单任务和多任务的未来趋势外推预测,相比于现有最新的方法,均表现出了更优的预测性能。"
435,基于机载激光雷达的森林参数反演研究,"机载激光雷达脉冲能够穿透部分森林冠层,获取森林的三维结构信息,是目前林业遥感当中最具应用潜力的主动遥感技术之一。尽管目前国内外学者已经在机载激光雷达森林参数反演方面取得了一些不错的科研成果,然而理论和实践远未成熟,核心算法仍有待提高,技术体系仍有待完善。因此,本文以黑河综合遥感联合试验获取的张掖市大野口流域的机载激光雷达数据和样地调查数据为研究对象,系统化的研究了机载激光雷达森林参数提取的技术流程,针对各个重要环节均做了深入的比较和分析,找出了反演过程当中最优的算法和参数设置,提出了一个反演森林参数的激光雷达指标。研究取得的主要结论如下:(1)布料模拟滤波算法(CSF,Cloth Simulation Filter)在本研究区滤波效果好于常用的不规则三角网滤波算法(TIN,Triangular Irregular Networks)和渐进形态滤波算法(PMF,Progressive Morphological Filter)。通过三种滤波算法生成的DEM和试验区差分GPS测量的结果对比,CSF算法可以获取最大误差1.9m,平均误差0.138m/m~2的DEM,可以满足森林参数反演的需要。(2)使用归一化点云(NPC,Normalized Point Cloud)生成的树冠高度模型(CHM,Canopy Height Model)无论是在树冠三维结构的表现上,还是在CHM“孔洞”的消除效果上均优于传统的CHM生成方法。同时,本研究对比了CHM生成过程中常用的三种插值算法,距离倒权法(IDW,Inverse Distance Weighted)、不规则三角网插值(TIN)和克里金插值(Kriging),发现由于树冠尺寸不大但形状多变,简单的IDW算法更适合CHM的插值。(3)对比分析了基于CHM的分水岭单木分割算法和基于点云的空间聚类算法,发现后者由于点云密度不够,不能用于本研究。通过有序对比分水岭算法的参数配置,确定了0.5m像素大小的CHM可以获取最佳的单木分割效果,单木分割率达到68.55%,分割准确率达到57.46%。尽管算法的参数值需要根据点云密度和林分情况变动,但是本研究提出的方法具备一定的参考价值。(4)用单木分割的思路反演林分参数,在无法单木匹配的情况下,本研究提出了用简单的线性回归模型来拟合林分实测值与单木分割估测值的方法。使用冠幅面积加权平均高估测值来拟合实测的胸高断面积加权平均高(LorH),相关系数(R~2)为0.375,均方根误差(RMSE)为2.16m。利用估测的平均树高和平均冠幅两个指标经自然对数变换后线性拟合胸高断面积(BA,Base Area)和地上生物量(AGB,Aboveground Biomass),R~2分别达到了0.571和0.639。(5)用基于样地的思路反演林分参数,本研究从点云中提取了43个指标,通过多元线性回归、支持向量机和人工神经网络三种机器学习算法来回归实测林分参数,结果表明后两者优于常用的多元线性回归模型,原因主要是提取指标之间的共线性问题所致。通过LASSO回归特征选择后,对LorH和AGB的预测,支持向量机最优,R~2分别为0.784和0.849,RMSE分别为1.256m和21.298t/ha;对于BA的预测,神经网络模型最优,R~2为0.859,RMSE为3.134m~2/ha。(6)本文提出了一个基于样地的激光雷达提取指标――冠层高度指标(TCH,Top of Canopy Height),在假设林分具备和单木相似的异速生长规律的前提下,利用已有的异速生长模型的形式预测各林分参数,其中对LorH、BA和AGB的拟合系数分别为0.129,0.696和0.706,预测精度高于基于单木分割的林分反演精度,低于基于点云分位数的林分反演精度。同时,本文对于影响TCH预测精度的CHM高度阈值和CHM像素大小做了科学的分析,方法具备一定的借鉴意义。总之,本文对基于机载激光雷达的森林参数反演方法进行了系统的研究,对核心算法进行了细致入微的比较和分析,得到的结论可靠有效,将有力推动机载激光雷达技术在我国林业中的深入应用与普及。"
436,面向高维数据的特征学习算法研究,"高维数据的处理一直是机器学习领域的热点问题。由于直接对高维数据进行处理会面临“维数灾难”、“算法失效”等问题,因此学者们针对这些问题提出了一系列有效的特征学习方法,如主成分分析、线性判别分析等,但这些方法在复杂、高度非线性及多特征等场景下仍然存在各种问题,如何充分利用原有特征信息,实现高维特征的约简及融合仍然是一个十分具有挑战性的问题。针对这些问题,本文通过设计科学有效的特征学习方法降低数据的维度并且保留数据的有效特征,主要工作分为以下几个方面:第一,扩展了传统的判别分析算法,提出了一种有序回归的核判别分析方法。该方法以全局方式使用数据信息,在考虑了不同类的分布信息的情况下,利用类的序列信息进行有序回归,克服了现有有序回归算法中存在的忽略全局信息和高计算复杂度等缺陷。以此为基础,结合正交投影矢量思想,提出一种基于多投影向量组合的特征提取方案。该方案分为两个阶段:第一阶段是通过正交空间递归得到投影向量,并在所得投影向量的正交子空间中搜索最优投影向量;第二阶段采用不同的组合策略将投影向量的决策规则进行组合,从而形成最终的决策方式,这使得该算法能够利用更多的原始信息提取出更有效的特征。通过与经典算法在有序回归实验上的多项指标进行对比,充分验证该算法具有非常好的性能。第二,针对使用单一的特征对样本进行分类很难获得令人满意的性能这一问题,提出一种基于流形学习的特征融合方法,将多特征集成到单个嵌入方向中,找到一个维数约简后的低维子空间,消除了冗余和无关信息从而提高特征融合的性能,并从监督学习与半监督学习两方面对算法进行讨论。通过在经典数据集上的全面实验,结果表明提出的方法在分类性能和算法稳定性上均好于其他特征融合方法。第三,提出一种基于组合核的特征融合方法。该方法同时利用多个高维特征,用不同的核函数分别提取对应的特征;再利用核技巧将多种核函数进行组合,实现多特征空间融合,并只需训练一个分类器,得到最终分类结果,大大减少计算复杂度。该方法克服了传统方法需训练多个分类器,导致计算量增加的问题。本文给出了两种组合核方式:一种是基于简单平均的特征融合方法,一种是基于加权平均的的特征融合方法。实验分析表明,本文提出的组合核的特征融合方法在算法精度和稳定性上超过其他单核分类方法。"
437,机器学习在放射治疗中若干关键应用的研究,"放射治疗是治疗恶性肿瘤的常用手段之一,据统计,约有超过70%的恶性肿瘤患者需要进行放射治疗。放射治疗的主要目标是在杀灭靶区恶性肿瘤细胞的同时,尽可能地减少对于周围正常组织器官的照射。尽管当前放射治疗技术日益成熟,并取得良好的治疗效果,但仍然存在许多关键技术问题需要解决。首先,准确预测患者总生存期对于医生制定放射治疗方案非常重要,临床医生对总生存期的预测往往因医疗技术手段的不足而不够准确。因此,能够准确预测患者总生存期的关键技术和预后模型对于放射治疗至关重要,也是本论文研究的关键内容之一。其次,在实际治疗过程中,许多器官中的肿瘤靶区(肿瘤区域)会随着呼吸运动而发生巨大变化,从而导致治疗时靶向不准确,影响治疗效果。针对这个问题,临床上勾画靶区时,一般会采用画大肿瘤靶区的方式来减少呼吸运动对于肿瘤靶区的影响。这样会加大对于正常组织器官的非必要照射。另外,由于剂量传输系统需要时间来与照射目标的位置同步,我们便需要提前获知肿瘤靶区随呼吸运动的位置。因此,对呼吸信号进行准确的预测成为本论文研究的关键内容之一。最后,对于放射治疗效果的评估也同样需要重视。这是因为经过手术之后,肿瘤可能在影像学上消失,肿瘤标记物可能也会很快恢复正常。而相比之下,经过放射治疗后的肿瘤标记物是逐渐变化的。因此,定期监测这些变化的特征,并将这些定性变化的特征配合临床经验以及机器学习模型,提供精准的治疗效果评估标准是极具临床意义的,也是本论文的关键研究内容之一。近年来,随着数据集的扩大与共享,计算能力的提高,机器学习(Machine Learning,ML)技术正在迅速改变着世界。大量研究表明,ML在放射治疗领域拥有巨大的潜力。因此,本论文针对上述问题,使用ML方法,进行了呼吸信号预测、非小细胞肺癌(non small cell lung cancer,NSCLC)患者总生存期(overall survival,OS)预测、立体放射治疗(stereotactic radiosurgery,SRS)与贝伐单抗(Bevacizumab,BVZ)综合治疗脑癌方案的评估三方面共四部分的关键技术应用研究。其中,第一部分为总生存期预测方面研究,第二三部分为呼吸信号预测方面研究,第四部分为治疗方案评估方面研究:一、基于影像组学分析的机器学习方法对NSCLC患者总生存期(overall survival,OS)预测的影响。研究了基于影像组学分析的不同ML方法对NSCLC患者OS预测的影响。从经过分割的CT图像中提取339个影像组学特征,这些影像组学特征使用肿瘤形状、大小、强度统计和纹理来量化医学图像上的肿瘤表型特征。总共研究了 5种特征选择方法和8种ML方法对OS预测的影响,使用一致性参数(concordance index,CI)来评估各个ML方法对NSCLC患者OS的预测效果。采用CI的特征选择方法以及基于Cox偏似然法的梯度提升线性模型(gradient boosting linear models based on Cox's partial likelihood,GB-Cox)获得 了最佳的预测效果。结果表明,适当的ML和影像组学分析方法可以较准确地预测NSCLC患者的OS。二、基于自适应增强与神经网络的呼吸信号预测。提出一种综合使用自适应增强与多层感知器神经网络(ADMLP-NN)的算法,对放射治疗呼吸门控技术中的运动目标位置进行预测,提高呼吸信号的预测精度。在这项研究中,使用实时位置管理系统(real-time position management,RPM)从先前采集的138名患者的四维计算机断层扫描(four dimensional computed tomography,4D-CT)中获得呼吸信号。ADMLP-NN 算法由数组多层感知器神经网络(multilayer perceptron neural network,MLP-NN)组成,这些MLP-NN会作为弱预测器来组成强预测器。我们首先使用Savitzky-Golay平滑滤波器对呼吸信号进行平滑处理。然后,依据前后呼吸信号间的关系建立数组MLP-NN。最后,基于每个MLP-NN的样本预测误差,采用自适应增强(adaptive boosting,AdaBoost)决策算法对每个MLP-NN的权值进行设置。本论文通过计算真实信号和预测信号之间的均方根误差(root mean square error,RMSE)、相关系数(correlation coefficient,CC)以及最大误差(maximum error,ME),对两种预测方法(MLP-NN和ADMLP-NN)进行评价。针对500毫秒的预测时间,均方根平均误差(相对单位)与最大误差的平均值分别降低了 27.9%以及22.2%,使用ADMLP-NN方法的平均相关系数则从0.83(MLP-NN)提高到0.89(ADMLP-NN)。实验结果表明,所提ADMLP-NN方法可以大幅提高呼吸信号预测的准确性。此外,近年来,AdaBoost方法的几种变体在回归预测问题上显示出了巨大的潜力。因此,我们在验证了 ADMLP-NN算法的有效性的同时,还研究了 8种流行的基于MLP-NN的AdaBoost算法变形(即ADMLP-NN算法变形)对呼吸运动问题的预测性能。最终,ADMLP-NN方法与基于MLP-NN的AdaBoost.RT方法(幂系数为1)方法得到了最佳的RMSE以及CC,而AdaBoost.BCC方法则得到了最好的ME。实验结果表明,依据不同的放射治疗应用场景,来选择基于MLP-NN的不同AdaBoost方法可更加准确地对患者进行放射治疗。三、基于交替神经网络的自适应呼吸信号预测的研究。为了提高长时间呼吸信号预测的准确性,论文提出一种利用更新后的呼吸信号进行持续学习的方法。也就是当一个MLP-NN对呼吸信号进行预测时,另一个使用更新后的数据进行重新训练,反之亦然。为满足临床的应用要求,本论文研究了4种不同的网络自适应架构对呼吸信号预测精度的影响,包括:单一 MLP-NN、双高计算量的MLP-NN(U1自适应方法)、高计算量和低计算量组合的MLP-NN(U2自适应和U3自适应方法)。其中,U2自适应方法采用高计算量MLP-NN(HC-MLP-NN)对预测模型进行重新训练,而采用低计算量MLP-NN(LC-MLP-NN)对预测模型进行实时更新(微调);U3自适应方法使用HC-MLP-NN完全训练模型,然后将所得到的权值和偏置传递给LC-MLP-NN,之后LC-MLP-NN将用于预测所有呼吸信号。此外,本论文还探索了呼吸不规则度对呼吸信号预测精度的影响。通过计算204名患者真实信号和预测信号之间的RMSE,来评估提出算法的有效性。与使用MLP-NN、U2以及U3自适应方法相比,使用U1自适应方法得到的RMSE分别减少了 34%、19%和10%。实验表明与使用固定信号的MLP-NN一次性训练相比,所提基于交替MLP-NN配置的连续再训练方法可以大幅提高预测精度。四、综合利用多模态MRI与影像组学技术评价SRS与BVZ治疗脑瘤的效果。论文采用多模态MRI和影像组学分析技术来评估同时接受BVZ及SRS的脑胶质瘤患者治疗效果,寻找与OS相关的影像组学特征,并利用相关性较高的特征对脑瘤患者治疗后OS进行预测。我们对多例脑胶质瘤患者进行研究,采用所提方法,动态对比增强磁共振成像(dynamiccontrast-enhancement,DCE-MRI)结果显示微血管传输常数(micro-vascular transfer constant,Ktrans)和血容量(blood volume,VB)在SRS治疗之后2个月显著下降,血流量(blood flow,FB)在SRS治疗后1周内便显著下降(p=0.017),功能MRI提取的放射学参数在SRS治疗后1周的变化均无统计学意义。总共提取888个影像组学特征,31组特征在SRS治疗后1周有显著变化,126组特征在2个月后有显著变化。另外,发现多组影像组学特征变化与OS呈线性相关,选取相关性最大的5组特征利用针对删失数据的支持向量回归模型(support vector regression for censored data model,SVRC)模型进行OS预测,得到的一致性参数为0.68。实验结果表明综合使用影像组学分析与多模态MRI定量评估SRS与BVZ的早期治疗效果具有非常大的潜力,可及时为进一步的治疗提供依据,具有十分重要的临床诊断价值。在论文中,我们对神经网络、AdaBoost、随机生存树、针对删失数据的支持向量回归等等ML方法在放射治疗中的若干关键应用进行了研究。论文的主要创新点如下:1、研究了多种基于影像组学的可以处理连续时间-事件数据的机器学习模型对NSCLC患者OS预测的影响。克服了多数此类研究将OS预测转化为二分类问题(即OS的长与短)而导致的预测精度偏差问题。这对于基于影像组学分析的预后模型使用是一个重要的补充参考。此外,这种比较也有助于选择最优的基于影像组学分析的ML方法,用于NSCLC患者OS预测,具有重要的临床使用价值。2、提出了一种新的算法ADMLP-NN来准确预测呼吸信号。AdaBoost方法的引入可以有效地降低MLP-NN算法中出现局部极小值和过拟合的风险,从而提高了预测精度,具有重要的临床使用价值。此外,ADMLP-NN比传统MLP-NN的鲁棒性更好,预测异常值更少。这对于放射治疗也是非常重要的,因为瞬时运动定位的大幅度偏差(异常值)可能导致对目标区域(肿瘤)周围高敏感度器官的较大辐射。3、比较了多种AdaBoost算法变形对于ADMLP-NN算法进行呼吸信号预测的影响。发现我们应该针对在放射治疗中不同的应用场景选择合适的AdaBoost算法,具有较高的临床使用价值。4、针对患者治疗过程中呼吸信号随时间而变化的问题(由于患者当时的情绪以及身体状况等原因),提出了两种使用交替MLP-NN(U1-adaptation以及U2-adaptation方法)来精确预测呼吸信号的新方法。论文提出的新方法利用在线采集的呼吸信号不断训练和更新MLP-NN模型,克服了传统实时神经网络预测算法长期训练不充分,误差积累的问题,提升了预测的精度。因此,论文提出的方法具有非常高的临床价值,可作为一种有价值的长时间呼吸运动预测工具,用于放射治疗过程中运动目标的动态跟踪。5、为提高评估治疗效果的能力,论文提出了使用多时间段内多模态MRI的多种感兴趣区域(特别是肿瘤周围正常组织区域)与影像组学技术联合评估BVZ以及SRS治疗效果的新方法。在医学成像的标准分析方面,在发现FB可作为治疗效果的早期评估指标,用于可能的适应性治疗。在医学成像的影像组学分析方面,发现从解剖影像MRI中提取的影像组学特征有捕获治疗效果的潜在价值。另外,使用我们发现的与OS相关性较大的影像组学特征可以较为准确的预测脑胶质瘤患者OS。论文所提方法,为评估同时使用SRS和BVZ治疗恶性脑胶质瘤的治疗反应提供了新思路,具有重要的临床使用价值。实验结果表明,本论文所提以上创新方法在放射治疗临床应用中表现优异,具有良好的临床应用前景。"
438,美国媒体对华报道偏差形成机理与影响研究,"随着科技的进步,媒体信息呈现出爆炸式增长,受众的注意力日益成为稀缺资源,这使得媒体越来越多地通过极具话题感、非中立性的表述来吸引读者的关注,学者普遍将这种现象称为媒体偏差或媒体报道偏差。作为一种特殊的媒体偏差形式,西方媒体,尤其是美国媒体在报道中国新闻时存在的对华报道偏差一直以来都是大众、研究者甚至是政府普遍关心的话题,这是源于这种偏差的存在往往会影响到美国民众对于中国的整体看法,从而影响到两国之间的经济、政治、文化等各方面的交流和互动。由于前置文献大多基于传播学、政治学等学科的理论和方法,本文的主要目的是在媒体经济学的研究框架下,重新审视美国媒体对华报道偏差,并在此基础上探究其形成机理和影响因素。首先,本文构建一般化的国际新闻媒体偏差模型来分析美国媒体对华报道偏差。研究发现,媒体需要权衡媒体偏差的程度,因为媒体偏差一方面能够弥补媒体获取信息能力的不足,另一方面则会降低新闻的准确性而影响受众的新闻需求。有别于普通的媒体偏差,媒体在报道国际新闻时更加关注意识形态差异而非竞争对手策略,这导致国际新闻报道市场更接近于完全垄断市场。而新闻需求的多样性和纠偏机制的缺失使得媒体内部的不同记者容易出现差异化的报道选择。模型主要探究了对华报道偏差的成因和影响,研究结论显示:(1)记者的媒体关联度会影响媒体偏差,当记者的工资水平较高或是受众的转换成本较低时,媒体关联度越高的记者所报道的新闻越容易出现媒体偏差;(2)媒体偏差会影响受众行为选择,当报纸的订阅价格较低或者受众的转换成本较高时,媒体偏差能够引导受众采取保险行为,即存在说服效应。其次,本文通过经验证据进一步证实上述模型的结论。(1)为检验记者的媒体关联度对对华报道偏差的影响,本文通过网络爬虫、手动抓取的方法收集整理2010年至2016年New York Times对华新闻报道数据和对应的记者信息,并在此基础上,从理论角度构建了对华报道偏差指数。实证回归的结果发现,相较非New York Times记者,New York Times记者的报道中更易出现对华报道偏差,而相较自由记者,新闻工作者的报道更容易出现对华报道偏差。同时,作者发现这种媒体内部差异性的报道选择仅存在于国际新闻领域,这与理论模型的讨论是一致的。在控制了记者的个人信息后,结论显示性别、经历、专业都可能影响到记者对对华报道偏差的选择。其中,有海外学习经历或者高学历的记者更容易报道中立新闻,这也从另一方面佐证了对华报道偏差的存在。(2)为检验对华报道偏差对受众行为选择的影响,本文收集了不同媒体对“中美贸易战”事件的新闻报道数据和代表美国民意倾向的选民支持率。在该部分中,作者通过LDA主题分类的机器学习算法对同一语境下美国媒体和其他西方媒体的新闻报道内容进行自动分类,结果显示美国媒体更倾向于报道公司主题新闻,而不倾向于报道市场主题新闻。基于构建的新闻报道指数,作者通过SVAR模型发现,不存在媒体偏差的关税主题新闻能够在长期中解释42.3%的选民支持率,这表明政府行为是民意倾向的重要考量。而存在媒体偏差的公司主题新闻能够在短期内提高选民对总统的支持程度,这表明媒体偏差确实能够在短期内引导受众的行为决策,即存在说服效应。鉴于媒体偏差可以不断出现,该说服效应能够产生持续性的效果。本研究的创新主要体现在以下四个方面。第一,大多数从经济学角度入手的媒体偏差文献着眼于政治新闻领域的媒体偏差,关注国际新闻领域媒体偏差的文献相对较少。基于理论模型,作者发现在报道国际新闻时,记者的媒体关联度是解释媒体偏差的一个重要原因,这进一步丰富了对媒体偏差成因的讨论。第二,前置文献大多从政治角度解释对华报道偏差,本文的研究结论表明,对华报道偏差源于他国民众的先验偏见,且需求效应比捕获效应能更好地解释偏差的产生,这为从需求角度理解对华报道偏差提供新思路。第三,少有研究关注对华报道偏差的影响,本文基于机器学习算法识别量化对华报道偏差并进行实证检验,研究发现带有偏差的新闻内容能够在短期内改变民意倾向,这为对华报道偏差引导受众行为决策提供经验证据。第四,本文的结论显示,提高中国产品的独特性,改善他国民众对于中国及中国产品的认识,能够有效缓解美国媒体对华报道偏差的程度。该结论从报道对象的角度入手,以报道客体的变化来影响报道主体的新闻选择,这为削弱对华报道偏差提供了一种新视角。"
439,概念漂移数据流分类算法研究,"数据流分类问题是数据挖掘领域中重要的研究方向之一,其主要特征为数据序列以流的形式不断地产生,如传感器网络异常检测、信用卡欺诈行为监测、天气预报和电价预测等实际问题中,新的数据序列都以快速、实时、连续的形式不断地到达.存在于数据流中的核心问题之一是数据流中往往存在概念漂移现象,即数据分布会随着时间的推移而发生改变.这种数据分布的不稳定特性大大影响了分类模型的性能和更新代价.在概念漂移数据流环境中,概念经过一段时间之后可能重复出现,这种概念重现现象导致算法不断地在相同的概念上学习新模型,浪费模型训练时间甚至降低其总体性能.另外,数据类分布不平衡以及实例属于多标签等问题也影响着模型在概念漂移数据流上的分类性能,其中前者期望模型能更准确预测少数类实例,而后者期望模型能准确预测实例所属的标签集合.针对以上问题,本文在深入分析包含概念漂移的数据流特性及相关理论的基础上,研究并提出新的面向概念漂移数据流问题的分类算法.主要贡献和创新点如下.(1)提出一种基于自适应滑动窗口的数据流集成算法(AWDE).不同于传统集成算法,AWDE使用自适应滑动窗口检测方法为每个基分类器自适应地构建相应训练数据集,具体过程如下:首先,使用自适应滑动窗口检测算法显式地捕获概念漂移;然后,根据捕获的概念漂移信息,选择滑动窗口中的部分数据构建基分类器,解决基于数据块集成对块大小依赖的问题;最后,通过兼顾准确率和差异性的指标监督基分类器选择和加权,以提升分类器的泛化能力.实验结果表明,AWDE能有效地解决多种类型概念漂移问题,在保证较高分类准确率前提下,有效地减少模型的训练时间及内存消耗.(2)提出一种基于概念转移图模型的重复概念发现算法(RDP).与传统数据流分类算法不同,所提出的图模型中每个结点存储一个基分类器(历史概念),边上的权重能有效反映概念的重复性问题.在学习阶段,采用基于Jensen-Shannon散度的检测方法来发现概念漂移和重复概念,并以此来指导图模型的更新;在预测阶段,根据建立的图模型,采用单分类器或者集成方式预测未知实例.此外,为了加速概念转移图模型的学习效率和压缩图模型的存储空间,采用基于对称不确定性的特征选择方法对数据进行预处理.在人工合成和真实数据集的实验结果表明,较之于传统面向重复概念发现的算法,RDP在保持更优分类性能的前提下,大幅度降低模型训练、更新及预测时间.(3)提出一种基于双重代价敏感的概念漂移数据流分类算法(TSCS).与方法(1)和(2)不同,TSCS用于解决概念漂移数据流环境下的类不平衡问题,其训练过程包含两个阶段:预处理阶段和模型构建阶段.在预处理阶段,TSCS采用基于代价敏感的特征选择策略,选择能有效平衡样本分布的特征子集空间;在模型构建阶段,若有概念漂移现象,在特征子空间中学习一个新的基分类器,则搜索并置换集成分类器中最差的分类器.在预测过程中,TSCS采用基于代价敏感加权的集成方式对未知类别的实例进行预测.与已有算法相比,TSCS能够在人工合成及真实的类不平衡概念漂移数据流上取得更好的分类效果.(4)提出一种基于多标签划分和依赖关系的概念漂移数据流分类算法(LPLDC).该算法主要用于解决概念漂移数据流中实例属于多个标签的问题,其基本思想是:在模型训练过程中,将原始较大的标签集随机地划分为多个互不相交的标签子集,并使用概率分类器链算法在每个标签子集上训练一个分类器;当发生概念漂移时,根据每个基分类器在最新数据块上的性能更新相应权值,并采用动态加权策略预测待分类实例.随机划分标签集的作用是充分利用标签间依赖关系并降低概率分类器链的学习时间复杂度;同时,在算法中嵌入了自适应滑动窗口检测算法来处理概念漂移.实验结果表明,LPLDC在大多数数据集上能够更有效地预测实例的标签集合,且更适合概念漂移的环境.本文研究工作针对数据流学习过程中亟待解决的问题,提出一系列行之有效的解决方案,构造更加完善的概念漂移数据流学习模式.所提方案在保持算法的分类效率同时,降低了时空开销,提升了算法的概念漂移适应能力,从而为概念漂移的理论研究和实用化,提供新的研究思路和理论依据."
440,情感词典构建方法及其应用研究,"在信息时代,随着近年来移动互联网的飞速发展,分享生活点滴已经成为人与人之间交流的重要沟通方式,这些数据的数量极其庞大且杂乱,但它们同样又包含大量用户对于当今时事、购买的商品的评价信息,这些评价信息或褒或贬,包含着用户对这些事件或商品的观点、看法,而这些反馈信息对公司、机构来说都是非常宝贵的,因为它们可以让公司从用户的角度了解产品的缺点、用户的喜好等等,因此,理解并分析这些文本数据中蕴含的情感倾向有着非常重要的现实意义和研究价值。情感分析作为自然语言处理技术中一个重要的研究方向,涵盖文档级、段落级、句子级等研究内容,但随着近年来无监督数据的指数级增长和语料标注成本的提高,基于词典的非监督情感分析得到了研究人员的关注,情感词典构建也成为情感分析中非常重要的一个研究内容。传统情感词典构建方法比较依赖人工标注和现有语义网中词语间的语义关系,虽然精度较高,但词典覆盖率低、耗费巨大,对于如今极速膨胀的数据量与应用场景来说,已经不能满足现实的需要;与此同时,这些急速增长的数据(如微博、评论、微信空间动态等)相比传统长文本数据(如小说文章、新闻内容、百度百科页面等)更显杂乱,这阻碍了传统情感词典在实践中的应用,因此,研究情感词典构建方法及其应用是非常重要的。本文的研究内容是基于文本数据研究情感词典构建方法并将其应用于推荐系统中的评分预测任务中。本文的主要研究内容如下:(1)针对词在不同的主题或上下文环境下,它的情感可能会发生变化的问题,本文提出了一种基于主题识别的情感词典构建算法(Topic Detection based Sentiment Lexicon Construction,本文简称TDSLC)。该算法在传统概率主题模型的基础上,通过额外引入情感隐因子,在文档和词的生成过程中,同时考虑潜在主题和情感对词的影响;此外,TDSLC算法还利用了文档级别和词级别的情感监督信息,在利用文档级别的情感监督信息来得到在不同主题下词的情感变化的同时,保证已知情感倾向的词不受文档情感监督信息的干扰。实验结果表明,考虑词在不同的主题环境下的变化性可以挖掘出更多隐含的情感词,提升情感词典在情感分类任务中的准确率。(2)针对有情感倾向的词对文档整体情感倾向的贡献权重不同且具有稀疏特性的问题,本文提出了一种基于稀疏自注意力机制的情感词典构建算法(Sparse Self-Attention Neural Network for Sentiment Lexicon Construction,本文简称SSANNSLC)。目前大部分基于语料的情感词典构建方法都非常依赖于文档级别的情感标签,它们通常将文档中每个词的情感倾向通过求和的方式来表示整个文档的情感倾向,但在自然语言中,通常只有少数有情感倾向的词对文档的整体情感倾向有影响,即大部分情况下,文档中有情感倾向的词具有稀疏性,本文提出的SSANNSLC算法利用自注意力机制充分考虑了文档中每个词对文档整体情感倾向的权重,同时用L1范数来约束这些权重以保证上述的稀疏性,过滤掉大部分无情感倾向的词对情感词典构建的影响。实验结果表明,充分考虑文档中不同词对文档整体情感倾向的权重有利于构建情感词典,可以提高情感词典在情感分类任务中的准确率。(3)针对目前大部分基于语料的情感词典构建方法在处理有情感标签的文档时,都没有明确考虑位置信息对情感词典构建的影响的问题,本文提出了一种基于位置敏感的情感词典自动构建算法(Automatical Position-Sensitive Sentiment Lexicon Construction,本文简称APSSLC)。在自然语言中,由于人们写作的习惯,通常把结论性的话语、情感倾向都放到文档的末尾或者接近末尾的地方,特别是有情感倾向的词出现在文档的末尾时,通常具有很重要的作用,与此同时,目前很多基于深度神经网络的情感词典构建方法都很依赖于词级别的情感监督信息,因此,如何从神经网络中自动构建出不依赖词级别的情感监督信息的情感词典也十分重要。本文提出的APSSLC算法将一个文档中每个词的语义表示为一个低维稠密的词向量,词的情感倾向表示为一个二维的向量,文档的每一个位置映射到一个低维稠密的向量中,本文将这个向量简称为“位置向量”,然后,将一个文档表示成这三个向量的序列输入到一个深度神经网络中来预测整个文档的情感倾向;APSSLC是一种自动学习情感词典构建的方法,它不需要任何的词级别的情感监督信息。实验结果表明,位置信息同样对情感词典构建有着一定的积极作用,与此同时,不利用词级别的情感监督信息自动构建的情感词典在情感分类任务上也表现出了非常不错的效果。(4)本文将情感词典应用到推荐系统的评分预测任务中,提出了一种基于情感词典的神经高斯混合模型(Sentiment Lexicon based Neural Gaussian Mixture Model,本文简称为SLNGMM)。推荐系统中的评分预测任务和情感分析中的情感分类任务有着一定的相似性,评分的目的是将用户对物品的喜好程度分到1,2,3,4,5的评分上,而这些评分基本正好与情感五分类对应;与此同时,用户对物品的喜好信息大部分都集中在用户评论中的那些有情感倾向的词上,本章提出的神经高斯混合模型首先应用在基于评论的评分预测任务中,构建基于评论的神经混合高斯模型(Review based Neural Gaussian Mixture Model,本文简称为RNGMM),然后,我们将评论数据经过情感词典后得到输入文档中每个词的情感倾向,将情感倾向输入到上述神经高斯混合模型中,构建基于情感词典的神经高斯混合模型,最后我们在五个亚马逊商品评论数据集上对比测试上述两个模型的效果。实验结果表明,情感词典能有效的提升评分预测的性能,降低预测误差。"
441,青海明长城防御体系及典型遗址易损性评价,"作为世界文明古国之一,中国拥有悠久的历史和丰富的文化遗产。这些珍贵的文化遗产蕴含了中华民族所特有的精神价值、思维方式和想象力,具有极高的历史价值、艺术价值、文化价值、社会价值和科学价值,体现了中华民族伟大的创造力和生命力。明长城作为世界文化遗产,是中国历史上工程规模最大且保存最为完善的长城工程,因建造原则之科学、建造工艺之精湛被视为长城的代表。谈及明长城,“东起山海关,西至嘉峪关”的说法众人皆知,然而青海境内明长城的遗存却鲜有人知。历经数百年的自然侵蚀及人为破坏,青海明长城主体目前以夯土遗址的形式赋存。由夯土版筑构建而成的明长城遗址作为直接接受环境影响的特殊岩土体,在大气圈、水圈、生物圈和岩石圈漫长的相互作用进程中,其安全赋存受到温度、降雨、携沙风、盐渍化以及人类活动等因素的严重威胁,进而导致其正经历由裂隙、冲沟、掏蚀、片状剥离、坍塌等典型病害的大量发育到快速消亡这一量变到质变的过程。由于青海明长城地处高寒、高海拔地区且地处一隅,其赋存环境和布防体系具有特殊性。因此探索归纳青海明长城防御体系并对典型遗址进行易损性评价,不仅能补充完善该地区明长城科学研究体系,进而表征青藏高原特殊环境影响下土遗址病害的发生、演化规律和过程,而且对制定科学有效的保护对策以及开展系统规划工作具有重要的指导意义和应用价值。鉴于以上认识,本文以青海明长城遗址作为研究对象,从遗址赋存环境和夯土材料特性研究入手,系统探究遗址各类型建筑的保存规模、建筑形制及分布特点,明晰了其军事防御体系构建特征;全面调查总结遗址病害发育类型及规模,结合遗址赋存环境、建造工艺及建筑材料特性,初步建立了青海明长城遗址病害框架体系;运用多准则决策方法对典型遗址进行易损性评价,建立了明长城遗址易损性评价模型,而后借助机器学习方法对典型遗址点的易损性评价结果进行训练学习、检验,构建了青海明长城遗址易损性预测模型。本文的主要研究内容及成果如下:(1)基于前人研究成果并经过大量现场调查,系统总结青海明长城遗址的赋存环境及其保存规模,分析得出明长城遗址所处分布区域海拔较高且终年气温较低,其赋存环境具有“高寒”的特点。详细探究主线墙体、烽火台、堡等明长城类型建筑的形制规律与布局特点,得出明长城主线以西宁卫为中心呈拱形紧密环绕;烽火台具有呈点状及以烽燧线为主要形式的线状分布特点;同时依据军事功能特点将堡划分为卫城、所城、驿城、驻军堡寨、土司衙门或居所、牧马苑、民堡等7种类型,通过查阅文献资料并结合堡周长阈值、建筑形制以及分布位置特点,推测得出46座堡的具体功能分类。(2)基于明长城各类型建筑的形制特点和军事功能,对以堡为核心的军事聚落空间分布、兵力布局、防守区域划分以及军力可达域等4方面开展研究,从时空角度分析明长城防御体系军力部署及调度情况,并进一步得出青海明长城军事防御体系是由长城主线、堡军事聚落、烽传系统以及驿路系统等4部分组成的紧密的防御网络,该体系能高效协同多个功能建筑开展防御、进攻以及传递重要信息、文件、专人等任务。(3)通过对青海明长城典型遗址病害发育进行详细调查和统计,归纳认为裂隙、冲沟、掏蚀、片状剥离、坍塌是最为普遍且具有代表性的病害类型。在定性判断遗址病害与其赋存环境、建筑材料工程特性及建造工艺联系的基础之上,对病害特征值与气象数据、夯土工程特性指标进行定量分析,得出遗址病害发育的内部联系及演化规律;同时得出影响遗址病害发育的主要因素包括夯土材料的物理、水理及力学性质、遗址赋存环境(具体表现在降雨及风等外营力)以及明长城建造工艺等,结合以上研究成果初步建立青海明长城遗址病害框架体系。(4)基于青海明长城遗址病害框架体系建立遗址易损性评价递阶层次结构模型,通过应用层次分析法(AHP)计算各评价指标权重,进而运用模糊层次分析法(FAHP)及AHP-TOPSIS对18处典型遗址点进行易损性评价,得出明长城遗址相应的易损性分值及坍塌破坏等级;通过对比遗址点的实际病害发育规模,确定AHP-TOPSIS更加适用于青海明长城遗址易损性评价,且其计算结果与遗址由于病害发育而造成的实际坍塌破坏程度具有一致性,进而验证了青海明长城遗址易损性评价模型及方法的合理性。(5)运用支持向量机(SVM)和BP神经网络两种典型且高效的机器学习方法对已获得的典型遗址点易损性数据划分训练样本和检验样本,经过调参、样本训练及检验等步骤,实现明长城遗址易损性预测,通过对比预测结果和遗址实际破坏程度,并计算相关精度参数,确定SVM具有更好的预测效果,以此为基础构建青海明长城遗址易损性预测模型。"
442,新一代静止卫星葵花-8的云分类研究及其应用,"云在天气系统演变以及气候变化等方面发挥着极其重要的作用,它不仅决定性地影响全球辐射能量平衡,也影响全球水汽输送。云的类型对于天气的状况和未来的发展变化有着明确的指示意义,如积雨云之类的对流云与大气不稳定性、湍流和雷暴有关。准确的云检测和云分类对水文、气候、天气等研究和应用有着重要意义。为有效提升保障华南区域航空安全与效率的能力,需要实现全天时高时空分辨率客观化定量化的云类和降水反演。随着计算性能的提升和海量数据的不断积累,反演算法已从线性数学、数理统计向人工智能的机器学习、深度学习发展。近年来投入业务使用的新一代静止卫星如葵花-8提供了更精细的时空分辨率和更多的光谱通道,是否有利于云类和降水的反演值得深入研究。有如下几个问题需要尝试解决:1)机器学习算法高度依赖于已标记好的真值样本,但云型分类真值样本稀缺;2)过去使用旧代卫星反演夜间云和降水的效果明显不如白天,使用葵花-8能否得到改善;3)现有的一些静止卫星云分类产品所需外部依赖资料繁多、耗时长,业务应用困难。基于葵花-8的光谱通道对于云的辐射特性,本文研究实现了如何结合CloudSat的云类别廓线产品反演全天时云类,和如何结合地面雨量站反演降水强度的方法。通过与独立数据的对比检验,表明本文得到的全天时云分类和降水分布结果合理可靠,夜间效果与白天基本一致,而且最终得到的算法外部资料依赖少,运算速度极快,非常适合应用于业务监测。不过算法对于大雨尤其是暴雨存在低估,需要在以后的研究中改进。全文主要内容如下:1、将CloudSat的云类别廓线产品作为云分类的真值,通过和葵花-8图像匹配样本、基于最大似然估计和随机森林等统计和机器学习算法、检验Nida台风案例结果,并讨论分析定量和定性存在矛盾的原因,得到了4个可分别用于白天和夜间的分类器。结果表明,有可见光的情况下的两种算法整体准确率都要比不使用可见光高出许多,最大似然估计算法从夜间最佳的78.95%提升到白天最佳的87.38%,而随机森林算法则从85.23%提升到94.23%。单纯从定量分析的角度看,随机森林比最大似然估计算法明显准确率要更高,夜间随机森林的准确率甚至已经和白天的最大似然估计效果相近。尤其是对于卷云的识别,随机森林的表现明显更为优秀。然而,从云分类结果图上看,明显最大似然法更合理。分析表明随机森林算法严格按照训练样本的自身分布去拟合决策树模型,因此对数据的质量更为敏感,如实反映样本缺陷。2、考虑到云类本身在光谱空间的聚类特性,而最大似然估计分类器通过多次聚类迭代运算――事实上对错误样本进行了纠偏订正――是合理的。提出了结合最大似然估计算法和随机森林算法的全天时云分类方法。通过与美国海洋和大气管理局业务云类产品的对比检验证明,该方法能充分发挥新一代静止卫星更多光谱通道的优势,也对样本本身可能存在的错误具备较高的容忍度,尤其是夜间云分类能做到接近白天的水平。该分类器运算速度极快,而且使用时只需要用葵花-8的数据,便于业务化推广应用。3、使用地面雨量计降水量作为真值来估计葵花-8降水等级,并与GPM(Global Precipitation Measurement)降水反演产品和地面雨量计进行了验证。由于用于建模、反演和检验的资料是高时空分辨率的(卫星图像保持0.025°的分辨率信息,实测降雨资料为10分钟雨量计降水),保证了该方法可以实现高精度的降雨反演。通过充足样本建立了较为合理的降水概率判识矩阵,因而能够比较准确地划分雨区与非雨区。结合云分类的结果进一步分析降水样本和云类的关系,实现了基于云分类结果和随机森林来反演降水等级的方法,得到了全天时一致的降水强度分类器。该分类器使用基于样本雨量平均值得到的判据来反演降水等级,分布与GPM产品大致一致,部分等级降水甚至比GPM产品略好。GPM校准降水资料一般要比探测时间落后3―4个月才发布,无法用于业务应用,分辨率也较粗,而本文提出的方法在时空分辨率和及时性上都是很大的优势。"
443,基于计算机视觉的桥梁结构局部损伤识别方法研究,"桥梁结构是一个国家和地区的重要经济命脉。桥梁结构在全寿命服役周期中,不可避免地遭受到环境侵蚀、往复荷载及突发灾害(如地震)等复杂因素的耦合作用,产生结构渐变损伤的萌生、发展和累积,导致服役性能不断劣化。目前,国内外学者一般采用基于动力反演的模态方法进行结构损伤识别、模型修正和安全评估。然而,此类方法往往只处理有限测点的不完备加速度监测信息,并且依赖对早期微小损伤不敏感的频率这一结构整体属性。另外,结构损伤往往伴随着复杂的非均质背景干扰,常规识别方法在实际场景中的普适性较差。实际工程中的目视巡检结果严重依赖于主观意识、量化不准确,成本昂贵。针对以上难题,本文研究基于计算机视觉的不同类型桥梁结构局部损伤自主智能识别方法,包括研究局部像素信息阈值处理、统计特征无监督高斯聚类建模、基于深度受限玻尔兹曼机高层次特征提取、基于深度有向无环图卷积神经网络多层次特征融合以及基于区域推荐机制的目标检测算法,发展拉索腐蚀疲劳退化评估、钢箱梁微小疲劳裂纹识别、钢筋混凝土桥墩结构多类型地震损伤识别定位等方法。主要研究内容如下:提出基于图像的在役拉索腐蚀状态识别及疲劳寿命评估方法。研究基于腐蚀过程和表观图像统计特征的概率建模方法,建立腐蚀特征空间与疲劳寿命控制参数统计学映射关系;基于上述方法对某桥服役18年的腐蚀钢丝疲劳寿命进行预测,结果表明各类应力幅下疲劳寿命预测误差均小于16%。提出基于计算机视觉的强干扰背景下钢箱梁微小疲劳裂纹自主智能识别方法。构建深度堆栈受限玻尔兹曼机和有向无环图卷积神经网络,提取并融合图像初级细部特征至高级抽象特征的多层次特征;将实际桥梁钢箱梁内部采集的350幅图像用于训练和验证网络模型,预测结果表明,构建的深度神经网络对多座跨海大桥各类样本的迁移识别准确率均大于93%。针对复杂非均质背景下多分类地震损伤的识别定位难题,提出基于计算机视觉的钢筋混凝土桥墩多类型地震损伤分类识别和区域定位方法。构建基于区域推荐注意力机制的深度卷积神经网络,采用具有一定概率保证率的矩形识别框实现多类型地震损伤分类定位,对混凝土开裂和剥落、钢筋暴露和屈曲的平均识别准确率大于80%,平均覆盖率大于88%。"
444,基于原型监测和机器学习的大跨度桥梁涡激振动研究,"近年来,为满足交通发展需求,我国建造了多座大跨度桥梁。跨度增大使得桥梁柔性增大,对风作用愈发敏感,因而抗风设计成为桥梁设计的控制因素之一。尽管在桥梁设计中已通过提高颤振临界风速避免了发散颤振,但无法避免涡激振动的发生。此外,跨度的增大减小了桥梁结构自振频率,因而减小了涡激振动临界风速,增加了低风速下涡激振动发生的频率。近些年,人们已在多座大跨度桥梁上多次观测到涡激振动,大幅涡激振动造成桥梁结构疲劳损伤,还威胁行车安全。因此,研究大跨度桥梁涡激振动具有十分重要的意义。尽管前人基于风洞试验对涡激振动机理和建模进行了大量研究,但是由于风洞试验难以模拟真实风环境的时空特性和足尺结构高雷诺数效应,风洞试验结果与真实原型桥梁风致效应并不完全一致。因此,本文基于原型监测大数据和机器学习算法研究原型桥梁在真实复杂风环境下的涡激振动。首先,提出基于聚类算法的桥梁涡激振动自动识别方法。构建以加速度均方根值和振动单频特性为特征的桥梁涡激振动识别特征空间,提出基于聚类算法的桥梁涡激振动自动识别方法,对某大跨度桥梁长期振动监测数据识别分析,自动准确识别出166次涡激振动事件,其中包括6种单模态涡激振动;进一步对涡激振动风速场聚类分析,发现6个风速场模式及其与涡激振动模态之间的对应关系,揭示风速场对桥梁涡激振动模态的影响机理和风场展向非均匀性对桥梁涡激振动模态的影响。其次,提出基于决策树算法的桥梁涡激振动模态预测建模方法和基于支持向量回归机的桥梁涡激振动统计响应时程预测建模方法。建立以1分钟平均风速风向为输入、以桥梁涡激振动模态标签为输出的桥梁涡激振动模态决策树预测模型,通过某大跨度桥梁风场监测数据准确预测该桥梁涡激振动模态;建立以1分钟平均风速风向为外输入、以主梁1分钟位移均方根值为输出的桥梁涡激振动统计响应时程支持向量回归机预测模型,通过某大跨度桥梁风场监测数据准确预测该桥梁在时空变化来流风下的涡激振动全过程位移均方根幅值时程(1分钟为基本时距),该模型识别出涡振风速区间和风向区间,并可揭示风场展向非均匀性对涡激振动响应的影响规律。再次,提出基于神经网络的桥梁涡激振动位移幅值微分方程建模方法。建立以平均正交风速为外输入、以桥梁位移幅值时间导数为输出的桥梁涡激振动位移幅值微分方程前馈神经网络模型和循环神经网络模型,通过某大跨度桥梁风场监测数据准确预测该桥梁在时空变化来流风作用下的涡激振动全过程瞬时位移幅值时程;对比分析前馈神经网络模型和循环神经网络模型的网络架构和预测表现,揭示循环神经网络在桥梁涡激振动位移幅微分方程建模上的优势及其原因。最后,提出桥梁涡激振动时变动力特性稀疏识别方法。提出基于非线性动力系统稀疏识别算法的桥梁涡激振时变动力特性识别方法,对某大跨度桥梁涡激振动及风场监测数据分析,建立各次涡激振动事件的桥梁位移幅值时变微分方程,揭示桥梁涡激振动动力特性的时变过程和时变机理;进一步对微分方程函数项系数聚类分析,发现7个函数项系数模式,揭示桥梁涡激振动的动力特性模式特征。"
445,基于计算机视觉的高铁接触网支持装置零部件分类提取与缺陷检测,"接触网系统是高速铁路牵引供电系统的重要组成部分,负责将牵引变电所输出的电能传送至动车组。动车组运行过程中,受电弓与接触网之间通常存在复杂的机械与电气作用,可能导致接触网支持装置零部件出现破损、松脱、断裂等缺陷,造成接触网机械结构稳定性下降,严重时会引发严重的安全事故(如定位器脱落、接触网坍塌等),直接影响列车的安全运行。因此,对接触网支持装置零部件进行准确、高效的缺陷检测与状态监控,对高速铁路运营与维护工作具有重要意义。随着高速铁路6C检测系统的提出,基于图像的非接触式检测方法日益取代传统的人工巡线成为接触网检修与维护的主要手段被各路局采用。然而,现有的检测系统依然存在图像理解能力差,自动化程度低,缺陷识别过分依赖人工辅助等问题,检测效率依然较低。为解决以上问题,论文提出一系列基于计算机视觉技术的高速铁路接触网支持装置零部件分类提取与缺陷检测方法,以提高现有检测系统的智能化水平,主要工作如下:1)针对接触网支持装置零部件识别问题,提出一种基于梯度方向直方图特征与改进的级联分类器的识别算法,通过改变级联分类器的结构实现接触网支持装置零部件识别精度的提升。该方法利用支持向量机对训练前期产生的困难样本进行区分,替换传统级联Adaboost分类器中的高层级分类器。利用支持向量机在处理小样本、高维数分类问题中的优势,解决了传统级联Adaboost分类器训练后期由于高质量负样本获取困难而导致的模型性能提升缓慢问题。实验结果表明,改进后的级联分类器具有更高的零部件识别精度。2)结合深度学习技术,利用卷积神经网络实现多种接触网支持装置零部件的同时识别。通过对基于Faster R-CNN、SSD、YOLO等现有目标检测框架的支持装置零部件识别结果进行分析,选择Faster R-CNN框架作为网络的基本结构。为进一步提高接触网支持装置零部件的识别精度,提出一种改进的Faster R-CNN模型。该模型在多个特征层上引入多尺度候选区域采样,利用候选区域的上下文信息对零部件种类进行辅助判别。实验结果表明改进后的Faster R-CNN模型能够有效提升体积较小的零部件(如斜拉线定位钩、防风拉线固定环、斜撑套筒顶紧、绝缘子底座等)的识别精度。3)针对绝缘子瓷片破损与夹杂异物,提出一种基于局部周期异常变化的缺陷检测方法。该方法首先基于信号处理技术对绝缘子表面的纹理信息进行局部周期估计,进而根据各像素点的局部周期估计结果生成绝缘子表面局部周期强度图,通过对局部周期强度图进行异常值检测实现绝缘子破损与夹杂异物等缺陷的诊断;针对旋转双耳耳片断裂缺陷,提出一种基于二维Gabor小波与距离变换的检测方法,该方法首先对待检测图像的二维Gabor小波能量极值区域进行骨架提取,进而利用形状上下文将上述骨架区域映射至标准旋转双耳图像上,最后利用距离变换计算映射后的骨架区域与旋转双耳轮廓曲线的相对距离,实现断裂处裂痕的检测。4)针对旋转双耳表面不易检测的细微裂纹,提出一种图像处理技术与深度学习相结合的检测方法。该方法首先利用Mask R-CNN对旋转双耳耳片区域进行精确分割,进而将耳片区域划分为单尺度栅格并利用轻量级卷积神经网络对栅格内是否存在裂纹进行判别,生成裂纹候选区域,最后利用一致性敏感哈希算法对裂纹候选区域进行重识别,消除其中的误报。与单纯依靠深度学习的检测方法相比,该方法在达到同等检测精度的同时具有更高的检测效率。"
446,基于机器学习的软件故障预测,"用于软件测试的资源通常是有限的,但是软件测试往往需要消耗大量费时昂贵的软件模块。此外,由于软件开发过程中测试往往并不充分,导致传统的软件测试手段并不足以保证软件的质量。因此,早期软件产业发展阶段中的软件故障自动预测技术在当前仍然存在。现今软件故障预测主要用于设定与优化软件测试的优先级,以充分利用有限的测试资源并尽可能地提升软件质量。在这方面,机器学习方法得到了较为广泛的应用。然而,将机器学习方法应用于精确的软件故障预测对数据质量有较高的要求。遗憾的是,真实的数据集却质量欠佳。在软件故障预测中,人们可以借助已标注的实例来构建一个模型以预测迄今尚未发现的新实例的类别。如果用于训练预测模型的数据集受到污染,则会给训练阶段和最终得到的模型都带来不利影响。一个可预期的结果是最终得到的模型精度必然不高。因此,提升数据集质量的一个有效策略是对带有缺陷数据的数据集进行清洗,主要是通过侦测数据集中可能存在的问题并消除这些问题来实现的。通过对现有软件故障预测领域相关文献的综述我们发现,分类在此领域中的大多数场合有着不可替代的重要作用。在一些特殊的场合,一些辅助的策略在应对数据质量挑战中也不可或缺。一些无足轻重的软件指标、类别不平衡问题、分类噪声、无用实例及异常数据等的存在降低了分类精度,给软件故障预测带来越来越多的挑战,这进一步导致推理能力差和资源管理效率低下。因此,如何确定数据质量和重要软件度量以实现软件故障预测迄今仍是一个开放性问题。本文的目的在于研究新的组合式方法以应对软件故障预测面临的这些挑战,并提升软件故障预测的性能。本文首先提出了一个新的基于组合学习的框架。该方法独立地检验软件度量,包括采用多特征选择技术以解决特征冗余和不相关问题,并通过合成少数类过采样技术实现数据均衡以解决类别不均衡问题。因此,本文开发了一个新的框架,该框架以面向对象度量(OOM)和静态代码度量(SCM)的组合形式来有效地应对这些挑战。在实验中,本文使用了朴素贝叶斯、神经网络、支持向量机、随机森林、K最近邻、决策表、决策树及随机树等多种不同的机器学习方法,并采用接收者操作特征(ROC)曲线来对软件度量的性能进行评价。实验结果表明,在不采用合适的特征选择技术的情况下,软件故障预测的性能可能会受到影响。为了降低这种影响,并获得准确、无偏的预测结果,必须先实现数据均衡。通过这些操作,我们所提出的框架将获得更高的预测性能。当使用静态代码度量时,将随机森林与信息增益特征选择结合起来,得到了最高的ROC结果,这是目前最优的组合策略。此外,当使用面向对象度量时,将随机森林与基于相关性的特征选择结合起来,也得到了最高的ROC结果,也被证明是目前最优的组合策略。其次,本文提出了一个更为全面的框架,称为一种基于三阶段集成学习的软件故障预测框架。此框架先解决由于类噪声的影响而带来的大多数软件故障预测挑战,再进一步集成其他方法以解决导致软件故障预测性能偏弱的特征特征和数据偏态问题。在第一阶段,借助最高的信息增益来选取高阶特征,主要是通过计算实现特征分裂所需要的平均信息熵与期望信息熵的差值来实现的。在第二阶段,针对存在故障倾向的实例,使用线性插值操作,通过对存在故障倾向的实例进行K最近邻聚类以产生一个新的存在故障倾向的实例类,从而实现对软件故障类别分布的处理。在第三阶段,通过对所得到的故障分类器的预测结果进行数据融合,实现了对故障数据的噪声滤除,主要是通过迭代使用噪声过滤对噪声进行侦测实现的。在基于数据融合的噪声滤除中,使用了C4.5、3最近邻、Logistic回归等多种机器学习方法,并进行了大规模的综合性实验以对所提出的框架进行验证。通过13种通用的集成学习算法来对该框架各个阶段的性能进行评价。再通过单因素方差分析和Tukey HSD检验对各个阶段的性能进行较为全面而深入且统计意义上较为合理的对比分析,实验结果验证了所提出方法的卓越性能。特别地,移除噪声数据后,在分布良好数据的重要特征上使用集成学习算法(ELA)可达到较高性能的故障预测结果。此外,分别使用均方根误差(RMSE)和耗时训练(ETT)两种不同的评价指标,在大多数情况下,移除噪声数据可以大大降低故障预测的误差,同时降低了计算开销。最后,本文提出了一个新的混合数据约简方法用来提升软件故障预测的性能。该方法解决了由异常数据、冗余实例及冗余特征等带来的三类主要的软件故障预测挑战。通常情况下,软件故障数据集带有噪声数据及冗余数据等无效实例,这对软件故障分类的性能产生了负面影响。于是,通过对数据集中的邻域进行采样处理,并进行概率分布估计,实现了对软件故障数据实例的选取。进而,一个给定的采样数据归属一个特定类的概率取决于该采样数据归属于K最近邻算法所产生类别的平均概率。对异常数据的判别而言,先计算该异常数据的所有特征与对应的数据分布均值之间的距离,再综合考虑每个特征中的每个数据实例,最终实现对异常数据的判别。如果所选取的数据实例中其一个或多个特征偏离均值过远,该数据实例即被视为异常数据并将从数据集中移除。对重要特征的选取而言,需要全面考虑所有的特征-类别相关性及特征-特征相关性的综合影响。为实现重要特征的选取,需要将基于相关性的特征选择与最佳优先搜索与进化搜索二者结合起来。最终得到了混合数据约简方法。将所提出的数据约简算法与套袋算法、随机森林、决策树、朴素贝叶斯、决策表等机器学习算法进行对比,并给出了较为全面而深入且统计意义上较为合理的分析结果。实验结果表明,通过剔除异常数据,并对重要特征进行分析,进而选择有用的实例,所提出的数据约简算法可以得到优异的软件故障预测结果。因此,通过有效应对软件故障预测面临的上述挑战,所提出的方法可提升软件故障预测的性能,并为软件质量保障提供了可行的方法。"
447,基于轨迹数据的城市居民出行模式分析与挖掘,"随着城市化进程的不断加快,城市的地域结构和空间布局发生着动态演变,居民的出行模式也发生了巨大变化,随之产生一些诸如交通拥堵、空气污染和资源枯竭等问题。为了应对城市化所带来的挑战,深入理解人类出行行为与城市经济发展之间的潜在关联,城市居民出行模式研究得到了多领域学者的广泛关注,成为一个涉及复杂网络科学、计算社会科学、统计物理学和社会经济学等多个重要学科的跨学科研究领域。现有的城市居民出行模式研究已有二十余年,主要基于出行轨迹数据集的实证统计分析。如今正处在各种数据爆炸式增长的“大数据时代”,手机等移动智能终端使人们能够便捷地获取各种出行轨迹,这些多源异构数据给深入分析居民的出行模式带来了前所未有的机遇。但是,居民出行行为的动态演化也给轨迹数据的分析挖掘工作带来诸多挑战,如节点语义功能的动态表征、节点重要度的科学评价和多维特征的高效提取等问题。针对上述三个关键问题,本文基于人类出行模式的研究现状,充分利用机器学习、人工智能及大数据领域的前沿理论及方法,研究城市背景下居民出行模式的演变机制,挖掘其内在规律,主要贡献如下:1.基于语义向量表征的地铁站点功能识别方法设计。本文针对地铁站点静态语义和动态语义的动态表征问题,提出一种识别地铁站点语义功能的表征框架IS2Fun。该框架通过分析并表征站点周围的POI分布和乘客出行模式,利用Station2vec方法对站点的语义功能进行识别,最终获得10种不同功能的聚类,提升了站点语义功能识别的准确性。2.基于宏观和微观指标的地铁站点重要度排序方法设计。本文针对地铁站点重要度的科学评价问题,提出基于宏观指标和微观指标联合的地铁站点重要度排序方法SIRank。该方法通过分析两种网络拓扑结构(SSSN和SSPN)下站点的度中心性、聚类系数和接近中心性特征,挖掘站点间的客流时空演变规律,识别出重要的地铁站点,提高了站点重要度排序的准确性。3.基于时空忠诚度的地铁站点客流预测方法设计。本文针对居民出行多维特征的高效提取问题,提出一种基于乘客时空忠诚度的地铁站点客流预测方法STLoyal。该方法首次提出了忠诚度的定义,并验证了忠诚度特征指标在预测精度方面的重要贡献。通过乘客忠诚度、天气、时间和位置等多维出行特征对地铁客流量进行预测,提升了站点客流的预测精度。"
448,机器学习理论在径流智能预报中的应用研究,"流域水文预报一直是水文学领域的重点研究内容与方向之一,可为流域水旱灾害防治、库群安全经济运行、水资源科学分配及社会可持续发展等提供重要决策支撑。然而,全球和区域气候异常、流域大规模水电开发及其他各种人类活动的综合作用,深刻改变了流域气象水文关键要素的演化特性,加剧了水资源时空分布不均匀性,导致流域水旱极端事件发生频次及水资源优化配置难度显著增加,这对流域水文预报研究提出了更高的要求和新的挑战。因此,亟需研究并探索新的水文预报理论与方法,充分挖掘水文气象时间序列蕴含的有效信息,进一步提升径流预报的准确性和可靠性,以期为水旱灾害预报预警及流域水资源统筹规划提供科学依据。本文重点围绕变化环境下流域水旱灾害预报预警及水资源优化配置中面临的关键科学问题和技术难题,选取长江上游为主要研究对象,采用先进的机器学习方法和特征选择与智能优化算法等技术,研究流域非线性水文智能预报的先进理论与技术手段。研究工作对流域极端水文事件预报预警、库群安全经济运行与水资源高效利用的实现具有极其重要的指导意义和实际工程应用价值。相关研究成果可进一步推动水文智能预报在实际工程问题中的深化应用与深入发展,可为流域管理部门提供可靠决策信息,具有良好的工程应用前景。本文研究的主要内容和创新性成果包括:(1)以变化环境下流域水文气象关键要素时空演变规律解析为切入点,综合采用探索性数据分析、数理统计及时频多尺度分析方法,全面分析了金沙江流域近50年以来水循环关键要素径流、降水的年内季节变化特征与年际趋势、周期和突变等演变规律,并首次采用累积量斜率变化率比较法定量评估了气候因子降水和非自然因素人类活动对径流变化的影响。研究表明金沙江流域年降水量和年径流总体呈上升趋势,且该时期气候变化相比人类活动对径流变化的影响更显著。分析结果表明多种特性分析方法综合应用有助于充分认识流域水文气象过程的年内与年际变化特征,并揭示其长期变化趋势及演变规律,为非线性径流智能预报提供科学依据。(2)在洪水预报中,基于机器学习的预报模型由于不需要深入理解水循环系统下渗、蒸发、产流、汇流等各个关键环节的物理机理,且其具有较强非线性拟合能力、数据需求量少、模型搭建简单而备受关注。然而,受气候异常变化和人类活动等综合影响,单一机器学习方法难以全面刻画不同量级径流的固有内在特性和气候气象因子与人类活动造成的外部干扰。针对强非线性特征引发的洪水难以准确预报的问题,研究了基于智能优化算法、机器学习方法的非线性智能洪水预报理论,设计了正交初始化种群和自适应变异尺度系数两种策略对标准回溯搜索算法进行改进,进而建立了改进回溯搜索算法优化极限学习机的洪水预报模型(ELM-IBSA)。研究表明,与传统的GRNN、单一极限学习机和ELM-BSA相比,ELM-IBSA模型具有更佳的稳定性和泛化能力,设计的正交初始化种群策略和自适应变异尺度系数策略能够有效提升BSA算法收敛性能,得到稳定性更佳且全局搜索能力更强的洪水预报模型,从而获得更为可靠的洪水预报结果。该模型既能有效提高预报性能,又保留了数据驱动模型数据需求少、非线性拟合能力强的优势,可为流域库群实时防洪调度提供数据支撑。(3)基于信号分解、人工智能的分解-集成预报模型已被证明是提高中长期水文预报的一种有效手段。针对基于“捆绑分解”的分解-集成水文预报方法在建模与预报过程中,使用了实际未知的未来信息,易导致预报结果“虚高”,不适用于工程实际的问题。为此,设计了能有效避免采用未知信息的自适应动态分解策略,进而引入变分模态分解、回溯搜索算法与正则极限学习机等先进理论与方法,提出了自适应动态分解-优化-集成预报模型(AVMD-BSA-RELM),并在金沙江流域关键控制断面月径流预报中进行了论证。为全面评价模型的预报性能,基于传统的误差统计指标,引入常用于经济学领域的Diebold-Mariano统计检验方法,提出了一种从预报整体误差、预报结果相关性及与基准模型对比预报优势显著性等多方面全方位综合评价体系。研究表明,与四种常用单一机器学习模型相比,该模型能有效捕捉历史径流序列的长期演变趋势,提高了径流中长期预报精度;且设计的自适应动态分解策略能够根据新息不断调整分解方法参数,可有效克服捆绑分解引入未来预报信息的不足,进而增强了分解-集成预报模型在实际工程中的适用性。(4)为弥补确定性水文预报方法不能刻画预报结果内在不确定性及其演化特征的局限性,同时为提高数据驱动径流预报方法的物理基础与预报精度,研究了基于随机森林、高斯过程回归理论的不确定性径流预报方法,采用随机森林算法解析了太阳活动、环流因子、区域海温等遥相关变量和区域气象因子与区域径流的高维、滞后非线性映射关系,揭示了不同大气-海洋遥相关因子及区域气象要素对不同时间尺度径流过程的影响程度和作用强度,提出了气-海-陆多尺度因子联合驱动的高斯过程回归径流预报模型,以获得高精度的径流预报结果及其不确定性演化特征。实例研究表明,大尺度气候因子的加入能够有效提高预报精度,气-海-陆因子联合驱动的高斯过程回归径流预报模型可一次性同时提供确定性预报结果及其不确定性演化过程,与其他后处理概率区间径流预报方法相比,具有更为广阔的应用前景。"
449,基于核对齐的若干学习问题研究,"核方法是一种常用的模式分析方法,其原理是通过一个非线性映射把线性不可分的问题转化为高维特征空间中的线性可分问题,从而可以使用线性算法处理问题,且空间中的内积可以直接利用核函数来计算。核方法性能的优劣很大程度上取决于核函数的选择正确与否,因为不同的核函数在映入的高维空间中生成不同的结构。此外,当核函数的类型选定后,核参数的选择也对算法的性能有很大影响。因此,如何选择核函数以及核参数一直是机器学习领域内广为关注的热点问题。核对齐旨在度量两个核函数之间一致性的程度,是一种核函数选择方法,常用来为特定的学习问题选择合适的核函数。用核对齐选择核函数的优点在于只需要计算对齐值以使核函数适用于学习问题,而与具体的分类器训练过程无关。在核对齐概念被提出来以后,很多学者对核对齐进行了改进、扩展和应用。本文基于核对齐主要研究了模糊核的选择及其在异构数据属性约简中的应用,多标记数据的核函数选择及其特征选择等问题。主要研究内容如下:(1)提出了基于核对齐选择模糊核的新方法。在模糊决策系统中定义了一种新的理想核,并构建了一种模糊核对齐模型。通过最小化定义的理想核和属性空间中的模糊核之间的模糊对齐值选择模糊核。为了验证有效性,证明了支持向量机分类误差的上界随着模糊核对齐值的减小而减小。另外,进一步将提出的模糊核选择方法应用于异构数据的属性约简中。实验结果表明,提出的基于模糊核对齐的异构数据属性约简方法是有效的。(2)基于核化的模糊粗糙集提出了一种新的分类算法。把核化的模糊粗糙集中的正域转化为样本到分类超平面的距离之和,通过最大化正域得到一个求解分类超平面的优化问题。实验结果表明,提出的基于核化模糊粗糙集的分类算法是有效的。(3)基于核对齐提出了一种为多标记学习选择核函数的方法以及一种改进的分类器链多标记学习算法。首先,为多标记学习数据集定义了一个合适的理想核,并通过最大化特征空间中定义的线性组合核和理想核之间的对齐值确定组合核中的权重系数来选择核函数。另外,通过考虑局部核对齐标准对我们提出的方法进一步进行了改进。其次,在给定核函数的情况下,分别通过最大化核函数和标记空间中每个标记对应的理想核的凸组合之间的对齐值,和直接计算核函数与每个理想核间的对齐值给出分类器链的顺序。实验结果证明了基于核对齐提出的这两种算法的有效性。(4)提出了一种基于核对齐的多标记数据的特征选择方法。首先,将标记空间中的理想核定义为由每个标记定义的理想核的凸组合,特征空间中的核函数定义为每个特征对应的核函数的线性组合。其次,通过最大化线性组合核与理想核之间的核对齐值同时学习两个核函数中的权重,并将学到的标记权重作为标记重要性的程度。最后,根据线性组合核中的权重对特征进行排序,并删除权重很小的特征。提出的特征选择方法可以自动学习标记的重要性程度,并通过实验比较证明了该方法的有效性。"
450,基于有向无环图的层级多标签数据分类方法研究,"多标签分类广泛应用于图像分类、信息处理、故障诊断、基因功能预测等领域。若样本的标签间符合预先定义的层级结构关系,则多标签分类问题变为更加复杂的层级多标签分类问题。有向无环图中的每个节点可以有多个父节点,针对树形图设计的相关算法并不适用。现有研究主要针对树形图,对求解有向无环图层级多标签分类问题的数学模型等理论分析工作研究不足。此外,层级结构的存在所导致的不平衡数据集问题会影响分类的效果。在当前研究中,针对有向无环图设计的算法较少、精度较低,无法满足应用需求。层级多标签分类问题的一个重要应用领域为基因功能预测领域,由于在该领域被广泛应用的Gene Ontology(GO)注释方案为有向无环图结构,基于此方案的基因功能预测问题可以转化为有向无环图层级多标签分类问题。因此,对有向无环图层级多标签分类问题进行研究,在提升分类问题的理论研究水平、加速基因功能验证和注释工作等方面都有重要意义,并且对解决其他领域的相关问题也有借鉴意义。本文的主要研究工作如下:首先,针对当前研究对有向无环图层级多标签分类问题的理论分析工作较少,对求解该问题的数学模型研究不足这一问题,本文基于贝叶斯决策理论,构建了一种求解有向无环图层级多标签分类问题的数学模型。为了构建这一数学模型,首先设计一个新的损失函数――DAGH损失函数,该损失函数将有向无环图层级结构的信息加以考虑,对层级多标签分类问题中父子节点可能发生的不同预测错误的情况进行区别对待。而后,本文利用DAGH损失函数给出了求解层级多标签分类问题的条件风险,并利用基于最小风险原则的贝叶斯决策原理,将求解层级多标签分类问题转化为条件风险最小化问题。最后,本文将优化问题进行进一步的数学推导和化简,构建了求解层级多标签分类问题的数学模型,并且给出了层级多标签分类问题的具体求解过程和主要步骤。本文提出的数学模型将复杂的有向无环图层级多标签分类问题转化为一组二元分类问题进行处理,可以为设计有向无环图层级多标签分类算法、求解有向无环图层级多标签分类问题提供理论基础。其次,针对在层级多标签分类问题中存在数据集不平衡问题,并且层级越深入,不平衡数据集问题越明显这一具体情况,提出了在利用本文所提出的数学模型对层级多标签分类问题进行求解时,有向无环图中各节点训练集的生成方法。在针对一个节点生成训练集时,首先采用改进的兄弟节点策略选择正负样本,生成原始训练集;该策略在构建训练集时考虑了层级结构的相关信息,可以在一定程度上缓解不平衡数据集现象。而后利用提出的基于聚类的混合采样方法――CHS方法对原始训练集进行处理,使之变成平衡的训练集。本文提出的方法可以在各节点生成平衡的训练集,可以有效缓解不平衡数据集问题对分类结果的影响。第三,针对当前适用于有向无环图结构层级多标签分类问题的算法较少、精度较低、无法满足应用需求的问题,基于本文构建的求解层级多标签分类问题的数学模型,提出了一种用于有向无环图结构的层级多标签分类算法――HMC-DAG算法。该算法采用本文所提出的训练集生成方法来构建各节点的训练集,可以有效地在数据层面缓解不平衡数据集问题。HMC-DAG算法对其使用的二元分类器没有特别要求,可以根据需求灵活地选择二元分类器,有效利用机器学习领域关于分类研究的最新成果。本文给出了选用支持向量机以及多层神经网络作为基础分类器的两种HMC-DAG算法实现方式,分别为HMC-DAG-SVM算法和HMC-DAG-MLP算法。在求解本文所提数学模型所描述的优化问题时,HMC-DAG算法中设计并添加了DAGLabel贪婪算法,DAGLabel贪婪算法可以在保证算法的分类结果满足层级约束要求的前提下,求得最优的分类结果。实验结果表明,本文提出的算法可以有效求解有向无环图层级多标签分类问题,与同类算法相比具有一定的精度优势。"
451,基于深度学习的我国矿业境外投资风险评价研究,"风险是我国重要矿产资源“走出去”进行境外投资面临的一大难题。矿业企业境外投资项目的建设期和投资回收期很长,面临着多方面不确定性因素,所以采用科学方法开展重要矿产资源境外投资风险评价,对于国内企业开展境外业务,减少损失,保障我国境外资源权益具有重要战略意义。以往的研究在风险的量化综合评价中做出了有益的尝试,但是对投资风险的提示和评价本质上是一个复杂度较高的高维分类问题,传统模型难以处理如此复杂的数据。同时在风险指标的赋值方面大多仍偏于定性分析,在建立科学客观的量化考核指标方面仍有较大的探索空间。基于此,本文尝试引入深度学习思想,就“如何采用科学方法对我国矿业境外投资风险进行量化综合评价”这一科学问题展开了实证研究。本文的研究工作和创新贡献主要体现在以下几个方面:(1)构建了我国矿业境外投资风险评价指标体系,设定量化方法和赋值标准,采集得到两个数据集――境外矿业投资风险特征数据集和风险标签数据集,其中前者可作为开源数据集,为后续研究提供数据基础。本文深入研究了34个风险因子的特质和属性,根据科学性原则设定计量方法,反映各项指标的经济特质;根据可靠性原则,数据均采自世界银行、国际货币基金组织等权威数据库;根据可比性原则,对计算结果进行分级风险分值评定。这一工作为后续风险综合评价奠定了数据基础。(2)根据矿业境外投资风险评价的特点,构建了基于深度学习的风险评价模型。以Fraser研究所风险评价结果作为学习标签,21个主要矿业国家2009-2016年的34维风险特征值作为深度学习模型的输入量,五个风险等级作为输出量,利用深层架构寻找风险特性与风险综合评价之间的映射关系,训练并确定了基于深度学习的矿业境外投资风险评价模型。其中,为解决样本数据量不足给网络训练带来的困扰,本文采用基于参数的迁移学习方式对模型进行了改进,以上市公司财务风险评价深度学习模型为对象,将在源域中通过大量数据训练好的模型参数应用到目标域中。训练后的模型能充分利用深层架构的特征提取优势,通过非线性模块实现多层转换组合,学习非常复杂的函数,有助于提高评价客观性。(3)提出了一个复合聚类分析算法,对主要矿业国家基于投资风险相似度进行地区分类。本文结合皮尔逊相关系数对变量波动趋势相似性判断的优势,和欧几里得距离对量级的更好表达,提出了一个复合风险相关系数算法,以此对风险指标评价结果进行相关性检验,将投资风险要素结构特征相似的国家聚类在同一群簇中进行考察,为有针对性地优选投资目标提供更为清晰的参考依据。(4)设计了基于深度学习的指标贡献度全局分析方法,定量考察各风险指标对模型输出结果不确定性的贡献率,并据此对指标进行重要性排序。基本思路是从前述经过验证的深度学习模型中取得每一层降维的权重分布构造矩阵,设计适当的算法,得到指标的最终贡献度系数矩阵。经过研究,我们意外地发现,经由机器学习确定的模型,在不同风险层级上,各风险指标对评价结果的贡献度是动态变化的。这显然更加符合经济现实,也从另一角度证明了深度学习方法在风险评价领域,对复杂关系处理的优越性。针对这一发现,我们区分不同风险域,根据贡献度对指标进行优选,量化测试重要指标不确定性对风险等级的影响,并据此进行投资风险变化的局部动态监测,及时发现接近或超过风险临界值的国家,为投资提供有价值的风险参考。总体而言,本研究探索性地把深度学习思想运用于风险评价领域,不仅拓展了深度学习的使用边界,丰富了其经济意义,同时也为矿业境外投资风险的评判和解构提供了新的解决方案,为经济学实证分析范式的发展作出了有益尝试。"
452,基于CSI的煤矿井下定位方法研究,"煤炭是我国主要的能源,保障煤矿安全生产一直是国家关注的重点,井下人员定位系统在提高煤矿安全生产水平过程中发挥着重要作用。基于接收信号强度的指纹定位方法因其易实现性,成为井下定位技术发展的主要方向。然而信号强度易受环境干扰,定位精度不高,无法满足未来井下应用的精度需求。因此,研究井下高精度指纹定位方法具有十分重要的理论价值和实际意义。当前井下指纹定位面临三个主要问题:(1)缺少用于生成高精度指纹的特征;(2)缺少适用于无线接入点带状稀疏分布的指纹;(3)单个指纹对位置描述不准确。本文针对以上问题开展研究工作。(1)研究影响井下指纹定位的因素,验证接收信号强度不适用于生成高精度指纹。通过研究信道状态信息与传输路径的关系,提出了基于信道状态信息的路径传输模型,为将信道状态信息用于构造指纹提供理论支撑。通过与接收信号强度进行对比验证了信道状态信息具备细粒度特性,可以从幅度和相位两个维度描绘不同位置的差异性,更适合用于井下高精度指纹定位。(2)信道状态信息由幅度和相位两部分组成。针对幅度指纹构造,首先分析幅度噪声来源,提出使用多种滤波器来抑制噪声对幅度的干扰,然后结合多天线特性,生成幅度指纹;针对相位指纹构造,分析造成相位测量误差的因素,提出一种线性变换算法对相位误差进行处理,然后通过研究传输路径与信道状态信息相位的关系,建立由子载波相位构造成的汉克尔矩阵,最后通过利用范德蒙德矩阵分解方法分解汉克尔矩阵进而得到路径相位,将得到的路径相位生成相位指纹。分别在井下视距和非视距和场景中进行实验,实验结果表明基于信道状态信息的指纹定位方法的平均定位误差要比基于接收信号强度指纹定位方法降低约55%。(3)为了进一步提高指纹定位精度,研究指纹定位中离线训练阶段网格划分对定位精度的影响,综合模糊C均值聚类(Fuzzy C-means,FCM)算法和线性判别分析(Linear Discriminant Analysis,LDA)算法的优点,并利用量子遗传算法快速准确的寻优特性,提出一种基于量子遗传算法的模糊LDA指纹融合方法,利用量子遗传算法寻找最优的模糊因子实现对指纹特征波动的抑制。实验结果表明该方法能够有助于细化网格,平均定位误差相对于处理前指纹下降约20%。(4)传统指纹定位方法中都是使用单个指纹对位置进行描述,由于指纹是时变的,单个指纹不能准确表示出位置和指纹特征的关系,因此针对单个指纹对位置描述不准确问题,提出将单个指纹变成序列指纹对位置进行描述,并借助深度学习网络,提出了一种针对可变长度序列的时差长短期记忆网络的序列指纹匹配方法,实验结果表明,在视距场景中,序列指纹的平均定位误差为1.48米,相比于单个指纹定位方法平均误差约降低25%,相比于基于接收信号强度的指纹定位方法平均误差下降约72%;在非视距场景中,序列指纹的平均定位误差为1.71米,相比于单个指纹定位方法平均误差约降低28%,相比于基于接收信号强度的指纹定位方法平均误差下降约71%。该论文有图89幅,表24个,参考文献147篇。"
453,基于深度学习的采空区卸压瓦斯抽采智能评价方法研究,"采空区卸压瓦斯抽采是矿井瓦斯治理的主要手段。安全高效的瓦斯抽采效果评价对于矿井瓦斯精准抽采有着至关重要的作用,采空区卸压瓦斯抽采的智能评价对采空区卸压瓦斯抽采工程具有重要的指导意义。本文通过工程资料收集、理论分析、模型搭建与训练、原型系统设计开发及现场试验等方法,提出了采空区卸压瓦斯抽采评价指标体系,构建了基于LSTM(Long Short Term Memory长短期记忆网络)的采空区卸压瓦斯抽采评价指标预测模型,形成了采空区卸压瓦斯抽采智能评价方法,开发了采空区卸压瓦斯抽采评价系统。论文主要研究工作如下:(1)在采空区卸压瓦斯抽采原理及技术综合分析的基础上,对钻孔因素、风流瓦斯浓度因素、抽采浓度因素等关键影响因素分析,考虑各个指标间相互耦合作用及对采空区卸压瓦斯抽采综合评价的影响,基于层次分析法和关系矩阵法选取了瓦斯抽采浓度、抽采流量、风流瓦斯浓度等采空区卸压瓦斯抽采评价指标,利用模糊综合评价建立指标满意度模型,提出了采空区卸压瓦斯抽采评价指标体系,对采空区卸压瓦斯抽采效果进行等级评价。(2)针对采空区卸压瓦斯抽采评价指标预测精度问题,对矿井瓦斯抽采计量数据采用One-hot编码对抽采计量数据进行预处理、降低数据维度、构造数据时间窗,并按8:1:1的比例划分数据集,构建了四层LSTM评价指标体系预测模型。通过调整时间步长、损失函数和优化函数等参数提高了模型的准确率和鲁棒性,对比其他预测模型算法,LSTM模型能够解决梯度消失问题并具有更快的收敛速度和更高的准确率。(3)针对采空区卸压瓦斯抽采评价智能等级划分问题,采用拉格朗日插值法和平均值修正法对抽采计量数据进行数据预处理。采用支持向量机的浅层机器学习评价方法和基于卷积神经网络的深度学习评价方法,构建了采空区卸压瓦斯抽采智能评价模型。相比于浅层神经网络的支持向量机分类模型,卷积神经网络分类模型凭借深层神经网络优越的学习能力,更适合采空区卸压瓦斯抽采智能评价且准确率更高。(4)为实现采空区卸压瓦斯抽采高效智能评价及可视化显示,设计了采空区卸压瓦斯抽采智能评价系统前端界面和后台数据结构,并在云平台上进行算法集成、模型封装及抽采评价与智能调控系统的开发部署,解决了系统开发过程中数据查询和缓存的关键问题,为采空区卸压瓦斯的精准抽采提供软件模型及技术支持。(5)针对采空区卸压瓦斯抽采评价效果问题,结合试验矿井高位钻孔瓦斯抽采试验数据,分析了采空区卸压瓦斯抽采效果,对瓦斯抽采评价等级进行划分。根据评价结果提出钻孔封孔质量和调整抽采负压等调控建议措施,实现采空区卸压瓦斯抽采监测、效果评价和智能调控一体化流程,从而保证卸压瓦斯的精准高效抽采。基于以上研究成果进行了现场试验验证,形成了一种准确高效的采空区卸压瓦斯抽采智能评价方法,为采空区卸压瓦斯抽采效果评价提供了有力依据。"
454,基于局部特征的光学遥感影像目标检测研究,"目标检测是机器视觉和数字图像处理技术的一个重要研究方向,主要包含特征提取、描述和匹配,同时也是图像拼接、目标跟踪、运动分析、目标识别、视觉导航研究领域的基础。这些应用处理需求不同,包括对处理时间(在线、离线或实时)、遮挡的鲁棒性、旋转的不变性以及多角度的最优检测。然而,光学遥感图像的目标检测依然存在诸多局限性,因此本文针对这些不足进行分析与改进。在计算机视觉领域,现今最优秀的特征提取方法主要根据待检测对象的类别和结构进行识别,此外特征匹配也是其检测过程的核心步骤。在目标检测过程,由于光学遥感图像尺寸大、背景环境复杂、受遮挡和色彩变化影响,对光学遥感图像的目标检测方法提出了更高的要求。现今的训练过程不仅耗时而且需要大量的内存来存储训练图像,使许多传统的、先进的方法都面临着计算时间过长的问题。同时边界框回归(BBR)也在目标检测中起着重要作用。在低分辨率图像的训练过程中,由于目标方向的不确定性以及复杂的目标表面会产生许多无用边界框。此外,候选区域筛选也对目标检测有很大影响,研究人员提出了许多先进的搜索算法(例如选择性搜索(SS)),这些候选区域筛选算法克服了早期算法的不足,如处理速度慢、精度低以及计算复杂度高问题。通常,这些方法通过降低单个目标提取区域的精度来满足多目标提取需求。卫星图像处理依赖于图像的质量,由于低分辨率的限制,阴影区域很难提取出准确的信息。根据光学遥感图像处理的这些局限性,我们提出如下解决方案:(1)通过研究不同类型的图像对BRISK、SIFT、SURF、FAST、HOG和LBP特征提取方法的性能进行评估。提出了基于SURF与FAST和BRISK特征联合的特征提取方法,并将该方法用于特征匹配以提供最优解。此外,利用RANSAC和MSAC对离群点进行剔除,目的是得到最优特征匹配。(2)本文提出了一种有效的区域提取方法,并与选择性搜索区域建议方法进行了对比。本文算法主要分为两步:第一步是使用级联系统提取候选区域。第二步是基于提取区域建议的分类,利用卷积神经网络(CNN)和AlexNet结构进行迁移学习。同时,利用快速搜索组合提取特征并用支持向量机对提取的建议区域进行分类。简要对比和分析了AlexNet与传统组合特征,提出了一种基于场景的目标检测方法。首先,将特定场景划分为多个场景。其次,根据分类后的场景进行目标检测。场景分类采用基于AlexNet的迁移学习,目标检测采用Faster-RCNN算法,训练和测试图像采用DOTA数据集和GoogleEarth截取图像。(3)为了提高目标检测准确率,首先评估和分析了传统基于区域的边界框回归(BBR)方法在目标检测中的应用,进而提出了本文方法,共包含两个阶段。第一阶段,在边界框回归中,估计每个边界框的尺寸,然后根据被检测到物体的尺寸去除不符合要求的边界框。通过与基于区域的方法即RCNN、Fast-RCNN和Faster-RCNN进行对比分析,从而对本文提出方法的有效性进行验证。第二阶段,提出了基于压缩和下采样的图像训练方法,大幅降低了训练时间。为了验证本文算法,我们首先将RCNN、Fast-RCNN、Faster-RCNN和级联检测器在三种类型训练图像集进行训练,最后在VEDAI数据集上进行验证对比实验。(4)为了对阴影区域的车辆进行检测,我们使用HOG进行局部特征提取和SVM进行分类。阴影图像检测不仅检测过程困难、复杂,而且检测率非常低,因此通过对图像进行预处理来提高阴影区域下的车辆检测率,因为通常非阴影区域比阴影区域具有更高的检测率。"
455,基于智能算法的列车驾驶策略优化若干关键问题研究,"铁路具有运输效率高、单位成本低等突出优势,是国民经济发展与综合交通运输的大动脉,具有重要的社会和经济效益。目前我国铁路系统中的高速列车和普速列车均采取由列车驾驶员在车载安全设备监督与防护下驾驶列车的人工驾驶控制模式,而随着路网规模的扩大、列车跨线运行的常态化、列车运行间隔的缩短、列车运行速度的提高,现代铁路对列车驾驶员的驾驶经验、操纵决策等提出了越来越高的要求,列车驾驶员的驾驶工作负担越来越重,现行人工驾驶模式已逐渐难以充分满足列车运行控制系统对提升其自动化、智能化水平的需求。因此,基于智能方法的列车驾驶策略优化方法已成为近年来的研究热点,其对于提升列车运行表现、减轻列车驾驶员工作负担等方面均具有重要的现实意义。本文针对基于智能算法的列车驾驶策略优化这一研究热点与难点,分别针对人工驾驶条件下列车驾驶策略优化模型的建立、基于智能算法的列车驾驶策略优化问题求解、考虑实时调度信息的智能列车辅助驾驶方法等若干关键问题展开相关研究。具体来说,本文的主要研究工作如下:首先,建立人工驾驶条件下的列车驾驶策略优化模型。考虑列车运行过程中受到的影响因素,对列车运行过程进行受力分析,加入折算列车长度、制动空走时间与距离、列车自用电能耗等因素,建立基于列车牵引计算的列车动力学模型。结合列车人工驾驶的独有特点,建立基于各子区间内牵引距离的列车驾驶策略优化模型,对列车站间驾驶策略的最优性进行分析讨论,给出用于解决列车准点、舒适、节能驾驶策略优化问题的目标函数及相应约束条件。其次,提出基于智能算法的列车驾驶策略离线在线结合优化方法。在所建立的列车动力学模型与列车驾驶策略优化模型基础上,研究基于启发式算法的列车驾驶策略离线优化方法和基于Pareto寻优准则与数值迭代方法的列车驾驶策略在线优化方法,之后分别针对仅离线优化和离线在线结合优化的列车驾驶策略优化进行仿真实验与分析,验证所提出的算法的有效性和适应性。然后,提出基于机器学习和进化计算的列车驾驶策略特征学习与列车驾驶策略优化方法。构建深度神经网络并利用大量实验数据对所构建的深度神经网络进行训练,以对列车驾驶策略进行特征学习,之后结合进化计算方法中的自适应差分进化算法对列车驾驶策略优化问题进行求解,通过多组对比仿真实验对所提出的方法在拟合精度、收敛速度、列车运行指标等方面的实验结果进行对比,分析所提出的方法的实用性。最后,提出考虑实时调度信息的智能列车辅助驾驶方法。首先对既有铁路调度指挥与列车运行控制之间所存在的信息分离、分层控制现状展开分析,之后以考虑实时调度信息的智能列车辅助驾驶系统为典型实现方式,进行系统架构设计、功能需求分析与核心功能模块开发,并进行半实物仿真实验以验证所提出的方法的有效性。"
456,基于脑电数据分析的驾驶行为研究,"近年来,随着我国汽车保有量的逐年增长,汽车交通事故数以及引发的伤亡和直接经济损失居高不下,如何提高道路交通安全水平成为交通运输领域的一项重要研究课题。汽车驾驶是一项包含感知、判断、决策和操作的复杂活动,需要大脑协调指挥驾驶员的驾驶操作。脑电信号可以反映驾驶人的心理生理状态,进而表征驾驶员感知活动。将脑电数据分析应用到驾驶行为研究有助于从认知神经科学这一新的视角解释驾驶行为产生机理,为交通安全问题带来新的解决办法。驾驶行为研究是道路交通安全领域的核心研究内容,驾驶行为状态的识别与预测对智能辅助驾驶系统的开发以及道路交通安全水平的提升具有重要意义。本文通过驾驶模拟实验,同步采集驾驶员脑电数据以及驾驶行为数据,借助认知神经科学与机器学习的相关知识,对微观驾驶行为特性、驾驶员脑电活动与驾驶行为之间的相关性以及驾驶行为状态分类识别与预测进行了深入的研究。本文的主要研究内容如下:(1)微观驾驶行为分析及影响因素研究建立驾驶员在日常跟车、换道、超车过程中的驾驶模拟实验场景,通过驾驶模拟实验采集驾驶行为数据并提取驾驶员跟车、换道和超车过程中的关键变量。以交通状态、交通密度和方向选择作为影响因素,利用重复测量方差分析、Friedman检验等统计学方法研究不同因素对换道、超车和跟车行为的影响。研究结果表明随着交通密度的增加,驾驶员换道和超车频率增加,换道和超车意图增强;且驾驶员超车行为的初始车头间距与车头时距随交通密度增加而减小,从而影响超车的安全性。在换道和超车方向选择方面,驾驶员无显著偏好,但研究数据表明右侧超车需要较短的超车时长,较小的初始车头间距和车头时距以及更大的初始加速度,并且视野受到限制,从而造成安全隐患。(2)脑电与驾驶行为的相关性研究通过常规驾驶场景下的驾驶模拟实验采集脑电和驾驶行为数据,并采用功率谱分析等方法提取特征。其中,提取的脑电特征量包括各个脑区各个脑电波频段的幅值、功率对数以及功率谱密度；驾驶行为特征量则包括加速度、速度、车头间距、车头时距、车道偏距和方向盘转角。本文采用Pearson相关系数建立相关分析评价指标体系,分别从脑区、脑电波频段、脑电特征量、驾驶行为特征量四个方面对脑电与驾驶行为的相关性进行探索。研究结果表明驾驶活动是一项需要大脑四个主要脑区协调参与的复杂行为,尤其与颞区、枕区和额区密切相关。其次,研究表明代表警觉程度的β波与驾驶行为密切相关,且β波功率对数是最能体现驾驶员脑电活动与驾驶行为关联的关键脑电变量。最后,在本文研究的驾驶行为变量中,加速度、速度和车头间距与驾驶员的脑电活动相关性最强,是建立脑电与驾驶行为关联的关键驾驶行为变量。(3)基于脑电数据的驾驶行为状态分类模型通过跟车驾驶模拟实验采集驾驶员在不同交通状态下的驾驶行为数据和脑电数据,以二者作为数据基础,结合机器学习相关算法建立基于脑电数据的驾驶行为状态分类模型。该模型具有两层结构框架,Layer I采用K-means聚类分析、支持向量机以及递归特征消除法,从初始驾驶行为变量中提取驾驶风格(驾驶激进程度)特征量和驾驶稳定性特征量,将驾驶行为划分为五类,依次为激进稳定型、保守稳定型、保守不稳定型、激进不稳定型和一般型。Layer II以初始脑电变量和Layer I得出的分类编号作为输入,采用自适应综合抽样法、线性判别分析法提取关键脑电特征量。最后,通过KNN算法进行有监督学习,以留一法交叉验证作为分类评价方法,得出基于脑电数据的驾驶行为状态分类识别模型平均精确度为69.5%,最高精确度为83.5%。(4)基于脑电特征提取的驾驶行为状态短时预测将基于脑电数据的驾驶行为状态分类模型扩展为驾驶行为状态短时预测模型,重点研究多种脑电数据特征提取方法,包括脑电分析方法(独立成分分析法和脑区源定位法)和信号处理方法(快速傅里叶变换和小波包变换),并对比分析不同脑电特征量、驾驶行为特征量以及二者混合特征量对驾驶状态的预测效果。研究结果表明,脑电功率对数、功率谱密度、相对能量和能量熵四种转换后的脑电特征量能比脑电幅值和能量更好的反映驾驶员的驾驶行为状态变化情况。其次,基于完整脑区提取的脑电特征量对驾驶行为状态的预测效果优于单一脑区提取的脑电特征量以及独立成分特征量。最后,在所有输入特征量的对比结果中,脑电特征量的预测效果优于驾驶行为特征量(即,83.84%vs.71.59%),且脑电和驾驶行为混合特征量对驾驶行为状态的预测效果最好,其预测精度为86.27%。"
457,区域综合能源系统供需预测及优化运行技术研究,"21世纪以来,随着科技和经济的快速发展,能源工业已发生了翻天覆地的变化。化石能源的逐渐枯竭,可再生能源的蓬勃发展,环境污染问题的日益凸显,提高对多种类型能源的综合利用效率、降低污染物的排放已成为我国构建清洁、低碳、安全、高效的现代能源体系所需要解决的关键问题。然而,传统的电力系统、热力系统和天然气系统是单独规划、单独设计和独立运行的,这种方式忽略了不同能源类型之间的耦合关系,极大地限制了能源系统的灵活性。在此背景下,综合能源系统应运而生,区域型综合能源系统作为能源互联网与泛在电力物联网的重要组成单元,综合运用先进的电力电子技术、信息技术和智能管理技术,涵盖了供电、供热和供气等能源系统,在源、网、荷等环节实现了不同类型能源的耦合,具有运行方式灵活、低碳高效、可再生能源消纳率高等优点,受到人们的高度重视。本文以区域型综合能源系统为研究主体,针对区域型综合能源系统的相关标准,供能侧与用能侧的预测技术、电-热-气多能流计算方法、区域型综合能源系统优化调度方法等方面展开研究。针对于供能侧与用能侧的预测技术,精确的能源需求预测将成为综合能源系统经济调度和优化运行中重要的一环。本文以分布式光伏功率预测为例,提出一种特征筛选与深度学习的光伏短期功率预测方法,基于随机森林中各分叉的增益情况对特征进行筛选,采用基于受限玻尔兹曼机的深度置信网络提取深层特征完成无监督学习过程。并利用光伏发电系统的实际运行数据进行仿真,验证算法准确性和有效性。针对于用能侧的预测技术。本文提出了基于深度结构多任务学习的短期电、热、气负荷联合预测方法。介绍了底层深度置信网络和顶层多任务回归的深度模型结构,其中深度置信网络作为无监督学习方法提取了抽象高级特征,多任务回归层作为有监督学习方法输出预测结果。其次建立含离线训练和在线预测的多元负荷预测系统,提出验证模型预测精度的指标。采用某综合能源系统的实际负荷数据对算法的有效性进行了验证。针对电力系统短期负荷预测问题,机器学习、人工智能领域的技术进步为提高负荷预测精度提供了有效途径,本文提出一种基于多模型融合Stacking集成学习方式的负荷预测方法。阐述了基于Stacking的集成学习机理,介绍了以树模型构造的XGBoost算法和长短记忆网络为代表的深度学习算法。考虑不同算法的数据观测与训练原理差异,充分发挥各个模型优势,构建多个机器学习算法嵌入的Stacking集成学习的负荷预测模型。使用ENTSO中瑞士负荷数据对算法有效性进行了验证,算例表明XGBoost、梯度决策树、随机森林模型能够通过自身模型的增益情况对输入数据的特征贡献度进行量化分析。Stacking中各个基学习器的学习能力越强,关联程度越低,模型预测效果越好。与传统单模型预测相比,基于多模型融合的Stacking集成学习方式的负荷预测方法有着较高的预测精度。针对电力系统连续多日负荷预测问题,连续多天的日高峰负荷的预判往往对电网的优化运行与安全稳定起到重要作用。本文深入分析了统计学习类算法的误差分布,提出一种基于串-并行集成学习的连续多日高峰负荷预测方法。介绍了统计学习类算法的泛化误差的分解情况,阐述了 XGBoost串行集成算法与Bagging并行集成学习的训练机理,分析了粒子群算法的基本原理。在综合考量模型偏差与方差分布的基础上,提出Bagging框架下基于XGBoost算法的负荷预测模型,并采用粒子群算法交叉验证XGBoost模型最优超参数。使用EUNITE竞赛数据对算法有效性进行了验证,算例表明XGBoost模型对特征贡献度的量化分析有效的辅助了特征选择的过程,粒子群算法缩短了 XGBoost超参数寻优的时间。与传统模型相比,基学习器为树模型的Bagging-XGBoost算法有着较高的预测精度。针对于多能流计算问题,本文提出了一种适用于含电、热、气的综合能源系统的扩展牛顿-拉夫逊多能流计算方法。分别建立了区域综合能源系统中电力、热力和天然气网络的能量流模型。针对现有方法对含压缩机的天然气网络建模的繁冗性问题,提出了改进的实用化处理方法。在此基础上,构建了区域综合能源系统中多能流计算模型,考虑其中电力子系统并网和孤岛两种运行方式,推导并得出了反映多能源耦合关系的雅可比矩阵,验证了该方法在不同运行场景下对多能流进行计算和互动特性分析的有效性。针对于区域综合能源系统优化调度问题,本文考虑各子区域由不同的能源供应商负责运营的实际场景,首先提出了一种含多个能源集线器的综合能源系统基本框架,分析了不同主体的运行特性和运行约束,并引入了交替方向乘子法,构建了计及C02排放水平的综合能源系统分布式日前低碳经济调度模型。并运用实际数据进行仿真,从各个子区域能源集线器的供能注入功率和储能设备调度结果、低碳减排经济性惩罚对系统的作用以及分布式算法的有效性3个方面进行分析,验证了所提模型和求解方法的实用性和准确性。"
458,基于红外紫外成像检测技术的绝缘子运行状态分析与评估,"输变电绝缘子在长期的电、热、环境和机械应力的作用下,可能会出现绝缘劣化、老化甚至缺陷等问题,危及电力系统的安全稳定运行。绝缘子的放电或发热现象一定程度上表征着绝缘子的运行状态,因此,以往的研究主要采用紫外成像仪和红外热成像仪对绝缘子开展带电检测试验,通过研究人员设定并提取相关特征参量与试验现象进行数据分析和比对,挖掘相关诊断判据。随着人工智能技术的不断发展,当前以深度学习为典型应用的理论及方法正在引领多个行业突破发展。因此本文在红外和紫外对绝缘子带电检测技术的基础上,研究并应用图像分类、目标识别、图像分割等多个人工智能与深度学习方法。本文的研究成果努力打破红外紫外检测“人工设定复杂算法流程”的困局,实现模型端对端的训练与检测,推动红外紫外成像检测方法的评估诊断智能化。本文研究的主要内容如下:采用BP神经网络、BOA-SVM、卷积神经网络三种算法对劣化绝缘子红外图谱的评估诊断进行研究,开展输电线路劣化绝缘子在多种环境因素影响下的发热红外检测试验,简明分析了劣化绝缘子在不同的湿度、绝缘子串不同位置、不同污秽度等条件下的发热特性,整理构建劣化绝缘子与正常绝缘子的红外热成像检测图像库;采用BP神经网络算法,对比颜色直方图、颜色矩、中心线颜色向量矩阵三种特征参量对劣化绝缘子的模型训练过程及检测效果;采用贝叶斯优化的支持向量机分类评估诊断算法,实现对劣化绝缘子红外图像的分类评估诊断;改进并训练基于深度的监督学习下的机器学习模型――Lenet卷积神经网络模型,以更高的检测准确率实现对劣化绝缘子红外图像的评估诊断,并在章节小节综合分析对比以上三种算法的特点。研究基于深度学习的红外热成像的绝缘子发热目标识别算法,收集整理现场大量的异常发热红外图像,对红外图像中的异常发热点进行逐一人工标注,构建符合目标识别深度学习的可训练图像数据集。采用Faster-RCNN和YOLO-V3目标识别算法,实现对绝缘子异常发热目标点的识别并框选,可有效的屏蔽大部分无须关注的非故障发热点干扰,为红外发热异常带电检测的智能精益化巡检,提供新的思路和实现方法。研究深度卷积神经网络在绝缘子紫外放电图谱分类评估,采用FILIN紫外成像仪对瓷质绝缘子开展绝缘子工频闪络试验,建立紫外成像仪所拍摄的不同放电状态阶段类别的图谱库,改进Alexnet深度卷积神经网络模型,实现对瓷质绝缘子紫外成像检测的高准确率智能化分类评估,为绝缘子紫外闪络评估提供深度学习算法评估诊断的解决方案。研究全卷积神经网络与卷积神经网络针对绝缘子紫外污秽度检测的复合评估诊断模型。利用瓷质绝缘子污秽度紫外成像检测试验建立南非CoroCAM紫外成像仪所拍摄的不同状态类别的紫外图像库,研究全卷积神经网络模型对紫外成像仪图像的预处理算法,实现对紫外成像图谱对主光斑的分割提取以及背景噪声干扰的滤除,而后利用深度卷积神经网络模型对瓷质绝缘子紫外成像污秽度检测评估,最终形成基于全卷积与卷积复合神经网络模型的绝缘子串污秽度评估方法。研发多光路多传感的集成样机,该样机集成紫外成像、红外成像、可见光相机多光路集成一体的设计布局,结合多种微气象环境、激光测距等传感器,为多光路检测的数据修正提供更为全面的单设备多传感样机解决方案。开发绝缘子红外紫外后台诊断软件,可与多光路样机设备配合对接,使多光路检测设备具备初步诊断功能。在软件中部署本文研究的红外紫外评估相关诊断算法,实现红外紫外对绝缘子运行状态的诊断评估算法的应用。"
459,建立知识驱动的迁移学习方法比较多物种的精子功能生物学特性,"随着社会经济的不断发展,动物繁殖在畜牧业和动物生产中变的越来越重要。提高动物繁殖率可以不断扩大良种覆盖率,提高动物生产效率以及增加经济效益。其中精子生物学特性研究是动物繁殖学的核心内容,与物种的延续和遗传进化紧密相关。随着高通量测序技术以及生物信息技术的发展,基于已发表的海量文献,我们已经获得了较为详细的精子生物学基因功能、基因表达以及突变检测位点等基因组数据信息。但这些基因功能和细胞生物学先验知识主要集中在人类或者一些模式动物中,在不同物种的知识分布上却不平衡。当我们将研究对象确定为某一种畜牧动物时,却发现并没有可靠和足够的数据信息支持该物种的生物学研究。本研究针对这一问题,基于已发表的精子生物学海量文献、比较基因组学数据、功能基因组学数据以及知识驱动的自动化文献挖掘方法,构建多个物种的精子生物学特性的知识图谱,实现物种间精子生物学特性的知识迁移。具体的研究内容与结果如下:(1)以“公共健康”关键词的文献摘要作为对照组,构建“精子”生物学特性知识图谱。基于知识驱动的自动化文献挖掘统计方法,获得精子生物学特性相关的特异性基因1195个,特异性实体2162个,以及1195个基因与2162个实体之间的关联矩阵,作为标准模型。同时基于标准化知识分类,获得89个精子生物学特性实体类别,以及与该实体类别最相关的文献摘要信息。(2)结合IPA、KEGG数据库的信号通路的通路特征(pathway signatures)数据信息,获得精子生物学特性实体类别显著相关的信号通路(即精子生物学特性类别信号通路),以及该信号通路所富集的基因。进一步分析,我们获得每一个精子生物学特性类别中被显著激活和被显著抑制的信号通路。以及187个信号通路中每一个信号通路被显著激活和被显著抑制所对应的精子生物学特性类别。(3)基于物种基因组学数据和同源基因组数据信息,构建蒙古族五畜“山羊、绵羊、双峰驼、马、牛”的精子生物学特性知识图谱。结合人类精子生物学特性的标准知识数据库和信号通路功能数据库,进行物种间精子生物学特性的知识迁移。我们发现11个精子生物学特性类别信号通路在5个物种中是显著保守的(z-score>5),以及获得不同物种中特异性保守的精子生物学特性类别信号通路(z-score>3)。同时,在相对保守的110个精子生物学特性类别信号通路所富集的基因网络中(z-score>3),发现RAF1、和EGF基因是网络中的枢纽基因。(4)在“马和驴、山羊和绵羊”两对近缘物种之间进行精物生物学特性的可迁移性评估。分别获得每对近缘物种之间显著保守且可以互相进行迁移的精子生物学特性类别_信号通路,以及单个物种显著特异性保守且不可迁移的精子生物学特性类别_信号通路(Z-score>5)。(5)在“单峰驼、双峰驼、羊驼、野生双峰驼”4个骆驼科物种之间进行精子生物学特性的可迁移性评估。获得4个物种之间显著保守且可以迁移的13个精子生物学特性类别_信号通路,以及单个物种特异性保守且不可迁移的精子生物学特性类别_信号通路(Z-score>3)。同样,还获得只在某一物种的精子生物学特性类别中没有被显著激活的信号通路,如“Toll-like Receptor Signaling”信号通路在羊驼的精子细胞DNA和蛋白质结构相关的生物学特性中没有被显著激活,而在单峰驼、双峰驼和野生双峰驼中被显著激活。因此,我们以精子生物学文献摘要作为知识背景,构建知识驱动的自动化文献统计挖掘方法绘制了精子生物学标准知识图谱。同时,采用迁移学习方法构建多物种精子比较功能生物学组,进而实现物种间精子生物学特性的可迁移性评估,为深入了解不同物种的精子生物学特性提供了一定的数据和理论基础。"
460,病理图像精细化分析算法研究,"病理切片是临床疾病诊断的金标准,病理医生通过对病理切片进行镜检,完成病理诊断和预后评估,整个过程对于病理医生而言既费时费力又富有挑战。近年来,随着数字病理切片在病理诊断中的不断应用,机器学习方法走进了病理领域,并且推动着病理分析逐渐从定性分析向定量分析转变。计算机辅助数字病理分析能够帮助病理医生克服人工诊断易受认知能力、主观经验、疲劳程度等诸多因素影响的情况,同时可以有效提高病理诊断的准确率和稳定性,减少误诊和漏诊,对病情诊断和治疗方案的选择都有着重大意义。目前,无论是传统的机器学习还是最近发展的深度学习在病理图像分析中均展现出了巨大潜力,但由于计算机辅助病理诊断临床应用需满足各种更为精细化的要求和缺少标注数据等挑战,多数已有研究方法仍然无法满足临床应用的要求。本文基于这一现状,进一步探究了病理图像的精细化分析,主要内容包含如下:(1)针对临床病理诊断的高效性要求,本文提出了一种新的分布式并行方法,即采用数据和模型同时并行的方法来完成骨骼肌病理图像的快速分割。基于Spark云平台,采用master-worker并行的方式,并在每个worker节点上,首先采用具有快速并行预测功能的结构化随机森林边缘检测器检测边缘,然后使用超像素方法生成候选区域,最后利用条件随机场算法提出了一种基于层次树的区域选择算法,同时利用多核编程技术做了进一步并行化。通过实验证明,本文所提出的并行方法相较于单机模式在大尺度骨骼肌病理图像分割中实现了10倍的速度提升。(2)针对临床病理诊断的高精确性要求,本文提出了一种基于深层次连接网络的全场骨骼肌病理图像精细分割算法。所提出的深层次连接网络通过在编码器模块的不同层加入具有独立损失函数的解码器来实现多尺度预测,并将多尺度预测结果组合后生成更鲁棒的精细分割,有效地解决了现有端到端卷积神经网络在细胞分割时输出相对粗糙的问题,最后采用一种两阶段学习策略来有效地训练所提出的深层网络。通过在骨骼肌病理图像数据集上的实验证明了与其他现有方法相比,本文的方法在分割效率和准确率上均有显著的提高。(3)针对缺乏大量已标注病理图像这一挑战,本文提出了一种新的基于半监督深度线性判别分析的组织病理图像分类算法。首先将深度神经网络的损失函数替换为线性判别分析的损失函数,目的是生成具有最小化类内距离和最大化类间距离的特征,同时构建一个鲁棒且有效的图拉普拉斯;然后利用已标注和未标注图像特征构造的图(Graph)来设计一个新的损失函数,并将其作为深度神经网络的损失函数;最后利用网络所生成的特征完成分类。通过在骨骼肌和肺癌病理图像上的验证实验证明了本文方法优于多数现有方法。(4)针对临床病理诊断的高实用性要求,本文提出了一种基于深度学习的肺癌生存分析模型。首先提出采用带有全局平均池化的深度神经网络构建端到端的细胞特征学习模块,并使用基于局部约束线性编码和词袋编码算法将细胞级特征聚合到患者级的特征向量;然后提出基于弹性网络惩罚的Cox比例风险模型,并将其应用于特征选择和生存分析;最后还提出了一种生物标志物的可视化方法来帮助医生定位那些有助于生存分析模型决策的图像区域。通过大量的验证实验证明了所提出的生存分析模型对TCGA肺癌数据集具有良好的预测能力。"
461,聋哑人手语识别关键技术研究,"残障人士这一特殊群体的数量非常庞大,伴随着教育需求的日益增长,让教育发展的成果更多、更公平地惠及残障人士是构建开放融合式现代教育体系的必然趋势。科技馆作为残障人士非正式学习的主要场所,是他们接受教育的重要途径之一。其中,听力受损及语言残障人群面临的交流障碍主要包括获取展品信息困难和科技馆工作人员无法理解作为聋哑人主要沟通方式的手语。因此,利用新兴信息技术对手语进行识别有助于聋哑人群与健听人之间进行顺畅的沟通,对于构建和谐社会以及完善全民教育体系具有重要的现实意义。同时,作为人类身体最直观的表达,手语的应用有助于人机交互向更加自然、便捷的方式升级。因此手语识别是当今人工智能领域的研究热点。近年来,作为新一波人工智能浪潮的排头兵,深度学习为模式识别和计算机视觉领域注入了新的活力。伴随着Kinect V2等新型体感交互设备的普及应用,手语识别研究也迎来了新的契机。当前手语的识别主要存在以下几个具有挑战性的关键问题:(1)聋哑人手语数据集的有效性难以保证。一方面,为了使训练的模型能够适应面向非特定人的手语识别,需要大量采集不同人的演示数据;另一方面,很少有研究能够使用真正的聋人数据集,在使用规范手语数据的情况下,采集到的数据规模较小、容错能力差,差异性实际上又被忽略。(2)手语的实际应用场景往往比较复杂,背景和光照等客观因素对算法的识别效果有较大的干扰。(3)与传统的手势相比,手语序列存在着表意词丰富、动作灵活多变等特点,并且严重的肢体遮挡现象也较为常见,这就使得设计有辨识性的手语表征较为困难。(4)手语识别的最终目标是实现连续手语的识别,然而,连续手语的词与词之间存在不属于任何一个手语词的过渡冗余数据,这会严重影响连续手语识别的精度。基于上述背景,本文紧扣深度学习聋哑人手语识别这一研究立足点,对三维卷积神经网络、循环神经网络、残差网络、注意力机制以及多模式融合等模型进行了重点的探索,并基于这些模型具体实现了动态手语关键词和连续手语序列的识别,取得了一些富有实际意义的研究成果:1.针对问题(1),本文对手语识别方法随着交互设备的不断演变所经历的几个阶段进行了梳理,对识别精确度和交互体验等要素综合考量后,提出了基于计算机视觉和新一代体感交互设备的手语识别方案。针对特殊的光照和背景噪声干扰等条件,使用Kinect V2传感器探索出了多模态同源数据采集方案,并构建了自主的聋哑人手语公开数据集。2.针对问题(2),本文提出了一种融合多模态同源数据的三维卷积神经网络手语识别方法。该方法借助深层架构强大的端到端自主学习能力来取代传统的人工特征选取;通过构建双列深度神经网络,分别从红外图像和轮廓图像中逐层抽取和学习动态手语中具有区分性的时空特征,并利用骨骼数据对两种图像数据中的上肢运动轨迹进行准确的定位。最后,采用深度学习的融合策略对两列子网络的分类结果进行加权融合,从而有效避免单列网络分类器由于数据丢失所引起的分类错误,使模型对背景噪声和因不同光照条件而产生的干扰具有较高的准确性。3.针对问题(3),本文提出了一种基于宽残差和可卷积长短时记忆网络的融合式框架对手语序列进行精确的表征。该框架首先以三维卷积神经网络作为视频数据的特征提取器,以产生能够反映手语特点的短时空特征。而后,以双向可卷积长短时记忆网络对这些固定长度的短时空特征进行充分的时空编码,进一步形成手语的全局关联信息。在模型的后半段,引入堆叠的宽残差模块对特征进准确的分类,并最终通过融合策略对两种独立的数据分类结果进行融合,从而有效提高了模型对手语的辨识能力。4.针对问题(4),文本提出了一种基于可卷积长短时记忆网络注意力机制的连续手语识别方法。面对需要处理的连续手语,该方法使用伪三维残差网络结合平衡铰链损失函数对长序列中的过渡帧进行检测,判定出手语关键词的时间边界。在手语识别阶段,以伪残差网络从视频流中提取手语的空间特征和短时动态特征:使用融合注意力机制的可卷积长短时记忆网络对短时空特征进行编码,以充分获取手语的上下文长时空信息;在特征分类部分,引入了宽残差模块对空间特征进行精确表征从而得到连续手语的最终识别结果。"
462,大规模跨场景无线行为识别与隐私保护研究,"基于无线信号的感知技术以其部署简便且无需携带任何设备、超视距、不受光线限制等优势,成为近年来学术界和工业界广泛关注的研究热点。其中,基于CSI的感知技术以其细粒度及高精度在智能家居、医疗监测等方面有着重要的应用前景,成为无线感知中的主流技术。然而,在实际应用中,现有方法仍然存在以下问题。第一,在识别目标规模较大的情况下,由于不同行为会对信号的影响比较相似进而导致识别精度下降,制约了系统在实际应用中的大规模部署。第二,在跨场景情况下,由于同一行为在不同场景下的信号差异较大,现有方法需要在多个不同的场景下都采集训练数据,造成人力资源的浪费,代价较大,制约了系统在真实环境中的可用性。第三,随着无线感知技术的发展以及无线设备的普及,在系统逐渐应用到实际环境的过程中,安全问题也随之出现,用户的隐私信息,如图案解锁密码、数字支付密码等可能会泄露。本文从基于CSI的感知技术出发,分析其在大规模、跨场景以及在实际应用中遇到的安全性问题,以高精度、低代价、强鲁棒性、安全性为目标,提出了两种在真实场景下的感知方法以及两种在公共场所下保护用户隐私信息的方法。本文的主要创新研究如下:(i)提出了一种大规模条件下的无线行为识别方法。该方法利用集成学习的思想,为每个测试样本找到准确识别该测试样本的模型。具体地,通过先前采集的训练数据训练一个模型选择器,当给定测试样本时,模型选择器会为该测试样本选择适合其的模型。真实实验表明,该方法不仅提升了现有方法在面对大规模识别时的识别精度,而且具有较强的稳定性,即识别精度不会随着识别规模的增大而降低。(ii)提出了一种跨场景条件下的无线行为识别方法。该方法利用人工神经网络训练两个场景之间的转换函数。具体地,根据两个场景下已有的训练数据训练两个场景之间的转换函数,转换函数训练好之后,源场景下的训练数据可通过训练好的转换函数转换到目标场景下使用而不需要在目标场景下重新采集训练数据。真实实验表明,该方法在保证了高精度的前提下降低了训练开销。(iii)提出了一种基于信道干扰的用户隐私行为保护方法。该方法通过破坏CSI攻击成功的必要条件,利用相邻信道干扰影响攻击者所使用的无线设备进而抵御了CSI攻击。具体地,在用户进入公共场所之后,系统通过分析网络状态不断地监测环境中是否存在CSI攻击,当监测到CSI攻击存在时,启动信道干扰保护机制,即利用已有的无线设备来影响攻击者的无线设备。真实实验表明,该保护方法在一定程度上抵御了CSI攻击,保护了用户的隐私信息。(iv)提出了一种基于安全区域引导的用户隐私行为保护方法。通过分析可知,CSI攻击成功的条件之一是需要用户距离攻击者的恶意设备较近,该方法通过将用户引导至安全区域来保护用户的隐私信息。具体地,智能手机的传感器不断地收集用户的行走信息,在监测到CSI攻击之后,首先使用已有的较为成熟的定位技术对攻击者所用的无线设备进行位置获取,然后结合这些恶意设备的位置信息引导用户进入安全区域。真实实验表明,该方法可以成功抵御CSI攻击。"
463,基于机器学习的医疗文本分析挖掘技术研究,"随着医疗行业信息技术的引入,该行业的信息化和自动化水准不断提高。医学文本信息处理技术正逐渐成为一个新的研究热点。医疗文本,以电子病历为代表,包含了大量丰富的医疗信息,是进行疾病预测、个性化信息推荐、临床决策支持、用药模式挖掘等的重要资源,并且可以以此为基础进行医院机构服务价值的衡量。医学文本中尽管蕴藏着丰富的医疗知识,但处理起来也更加困难。由于以电子病历为主的医疗文本中包括大量非结构化的自由文本以及图像影像信息,且医生自行录入可能导致文本的拼写错误、医学名词简写以及不同医生不同地区的惯用语,电子病历中所包含的医疗信息还不能被计算机有效利用。因此,机器学习和自然语言处理相关技术将在医学文本的分析和挖掘中发挥重要作用。为了更好地探索和利用医学文本,特别是电子病历的半结构化和非结构化信息,对其中非结构化自由文本进行标准化和结构化非常的重要,而医疗信息对时间特征具有较高的敏感性,使得时间信息也成为了更好分析医疗文本必不可少的因素。传统的文本分类需要先进行一系列预处理和特征工程的建模,在医疗文本中存在大量的专业术语和知识、不准确的分词或难以理解的语义特征会影响分类的正确性。医疗文本被分析处理,最终需要产生有价值的信息和知识提供辅助决策,如从电子病历中挖掘患者的用药模式,从而为医生的诊断和用药决策甚至提供个性化临床路径提供帮助。且依据循证医学,所有的过程和结果是透明和可解释的,而不是一个黑盒,这也是一个具有挑战性和实际意义的问题。本文主要研究医学文本的分析与挖掘技术。在深入研究医疗文本的特点并广泛分析相关研究工作的基础之上,本论文提出了一系列用于知识抽取、建模、分类、挖掘的算法和模型,并在数据集上进行了性能评估与验证。具体来说,本文的主要研究工作和成果包括:(1)结合医学领域知识,研究了一种医学领域词典自动构建方法,能从医学文本语料库中提取有效的医学术语。在现有中文分词算法基础上,对医学文本语料库拆分、标注,并识别医学新词、区分医学术语歧义,进一步提高面向医学领域的中文分词精度。基于对电子病历文本精确有效的分词拆分和词性标注,分别从病程发展和时间线角度对电子病历文本进行结构化建模研究,对电子病历中病历文本的时间表述规则进行研究,结合语义分析技术,从文本中抽象出基于时间的患者疾病发展模型,实现基于规则的电子病历的结构化分析。通过将构建后的领域词典应用在不同病历的筛选分类中,验证构建的领域词典对医学文本分类器的性能影响。实验表明,结合医学领域知识的构建词典更好地识别医学新词以及改善机器学习的文本分类算法。电子病历一般会记录患者患病的时间和情况,而这些信息一般存在于以自然语言描述的文本中,相关规则的挖掘是研究的重点。一般的信息系统难以对其进行多维度的分析,而本文提出基于时间信息的电子病历文本结构化模型,通过基于规则匹配的语义分析技术,自动从电子病历中现病史、家族史结合相关的医疗记录中,提取患者的病情发展时间线,用于疾病分析和预测。该模型的提出,能解决非结构化的电子病历内容患者信息难以定量分析的问题,对有效利用电子病历的非结构化数据具有借鉴意义。(2)借鉴深度学习技术在图像识别领域的巨大成功,针对中文医疗文本分类问题设计了字符级深度神经网络模型。并引入双向长短时记忆和注意力池化操作层,使模型更好地结合上下文进行分类判断。模型采用Google的Tensorflow框架实现并训练调参,实验表明模型具有良好的收敛速度和准确率,并在不同主题领域的文本分类中都有不错的表现。传统中文文本分类方案通常离不开对文本的预处理,例如分词、特征抽取,然后结合语义分析使计算机一定程度上理解文本。本文提出的字符级卷积神经网络可以直接以字符为最小单位进行学习训练,不需要分词或基于单词的特征提取器,也不需要语法或语义结构方面的知识,训练完成后就可以直接对高层的目标进行分析和推断。这也推翻了之前普遍认为的结构化预测和语言模型对于高层次文本理解是必要的假设。通过本研究发现,深度学习可以处理文本理解问题,并且可以不事先了解任何关于单词、短语、句子或任何的知识与语言相关的其他句法或语义结构。从而解决由于医学领域存在大量的专业术语和知识,分词不准确或语义特征理解不到位而影响整个模型分类效果的问题。(3)提出了一个基于机器学习的框架来挖掘电子病历文本中隐藏的药物模式。该框架系统地集成了Tanimoto相似性评估,谱聚类,改进的LDA主题模型和多个特征之间的交叉匹配,以找到描述隐藏在高度复杂的药物模式的多个视角中的额外知识和聚类的残差。通过这些方法,一步一步地一起工作以揭示出潜在的用药模式。然后,本文使用来自中国某大型医院的电子病历文本(的实际数据来评估该方法。实验发现该框架优于其他药物模式发现的方法,特别是对于这种疾病,具有微妙的药物治疗差异。结果还显示发现的模式之间几乎没有重叠。因此,通过提出的框架很好地研究了每种模式的独特特征。对比其他已有的机器学习方法,该方法有效地发现了电子病历文本中针对高度复杂疾病和混合药物模式的主要药物模式;将高度混合的药物治疗分为不同的聚类药物模式,而不是模糊的聚类,把每个项目分类为一种治疗模式,尽管相似性较弱;与无监督的基于深度学习的治疗模式发现方法不同,该分类方法导致框架的每个步骤都是可解释的而不是黑盒子。这种方法对于临床知识发现(因为它是基于证据和可解释的)来理解用于临床目的的某些药物的分类过程是重要的。"
464,基于深度神经网络的Android恶意软件检测,"Android操作系统普遍存在,几乎可以在官方Google Play商店或十几个其他第三方市场中轻松访问所有应用程序。此外,智能手机在现代生活中的重要作用使得可以在设备上存储任何重要信息,不仅包括个人信息,还包括公司信息等。这些大量关键信息引起了非法者的广泛兴趣,他们可以通过Android恶意软件来获取信息。恶意软件可能会增加电话费用,向联系人列表发送未经认证的消息,收集用户信息或提供攻击者对设备的控制权等,近年来已成为移动安全领域关注的重要问题之一。针对Android恶意软件的第一道防御机制是官方Google Play商店中的Play Protect,它可以在使用Google官方商店或第三方商店下载应用程序和APK文件时进行验证。另一种防御机制是Android Antivirus,它依赖于基于签名的数据库进行恶意软件检测。虽然基于签名的防病毒软件可以有效识别已知的恶意软件,但它们无法区分新的恶意软件。为了抵制基于签名的限制,开发了启发式扫描来研究可能暗示恶意意图的命令。但恶意软件通过屏蔽其恶意行为,则可能会逃脱启发式扫描。Android恶意软件的日益复杂性需要新的检测策略,本文提出采用深度学习来检测Android恶意软件,通过深度学习找到某些模式来识别以前未观察到的恶意软件,得到了一种针对Android恶意软件检测的新型有效解决方案。具体研究工作包括:1、特征指标体系的建立。采用静态恶意软件分析方法从AndroidManifest.xml文件和java文件中抽取五个不同的特征,即:权限组合,意图过滤器,API调用,无效证书,以及资源文件夹中将要输入深层的APK文件,建立了特征指标体系,作为后续恶意代码检测的依据。2、为了充分利用特征向量的信息,提出了基于三隐层深度神经网络的Android恶意软件检测算法,通过将Android软件的特征向量作为样本对神经网络进行训练,从而得到能够鉴别Android软件是否为恶意软件的分类器,实验结果表明,本文方法的准确率为95.31%,比现有的浅层学习方法和9种基于深度神经网络的Android恶意软件监测算法的准确率要高。3、为了解决被标注的Android恶意软件的样本数量较少的问题,进一步提出了基于AutoEncoder的半监督学习Android恶意软件检测算法,不同于其他研究者的方法,本文将AutoEncoder作为分类器,采用已标注的样本和未标注的样本对AutoEncoder进行训练,从而将准确率提升至96.81%,高于采用三层深度神经网络的方法。4、最后收集了包含属于Google Play商店中不同类别的良性应用程序和代表不同恶意软件类型的恶意应用程序的最新数据集。对本文采用的方法进行全面测试,包括使用不同的功能集评估系统性能,将DNN的性能与常见的机器学习方法进行比较,实验结果表明,所提出的方法可以高精度地识别恶意软件,比许多近期工作得到了更高的准确性。"
465,面向商品评论的文本智能理解,"手机等智能终端设备的快速普及给用户提供了快捷的信息传播渠道,使得互联网信息的产生方式从Web2.0时代以网站雇员为主转变为现在以用户为主。得益于信息传播的便捷性,网络购物已成为多数人生活的一部分。在网购过程中,电商网站的在线评论系统和问答系统为消费者提供了信息互动平台:用户可以在评论系统上描述自己的购物体验,也可以通过在线问答系统向商家或其他用户咨询某一款商品的相关信息。分析并挖掘上述用户产生的评论中的潜在信息并利用这些信息设计智能回复、即时推荐等互动功能可以有效提升用户的体验和购物效率。但上述互动平台产生的文本数据与政府新闻等正式文体不同,这种消费者在购物前后所产生的评论文本带有强烈的个人主观情感取向。因此,面向评论的情感分析就成为了评论文本智能理解的基石。其中,面向商品评论的情感极性识别是情感分析的核心问题。深度学习方法近年来在文本情感分类问题上表现优秀,但缺乏大规模高质量的标注数据是其瓶颈问题。为解决该问题,本文提出了一种弱监督深度学习方法,利用用户评分作为弱标注数据来预训练深度模型,再利用少量标注数据微调整个模型的参数。实验表明该方法在商品评论数据的情感分类任务上表现优秀。在文本的情感分析基础之上,为了进一步提升用户的购物效率,本文提出了一种基于用户提问的快速回复算法。传统在线问答系统存在即时性差的问题,用户提问之后仍需要耐心等待他人的回复。而已有商品评论则是一个巨大的信息宝库,从中可以找寻问题的答案。基于这种思考,本文提出了一种多任务深度模型来解决面向商品评论的智能问答问题。该模型利用在线问答系统中已有的问答数据来辅助学习问题与相关评论语句之间的映射关系。此外,提问中还暗含用户的购买需求信息,根据购买需求向提问用户进行即时推荐可以有效提升用户的购物体验,同时还能刺激消费从而满足商家对利益诉求。基于这种思考,本文提出了一种新颖的推荐问题:用户提问驱动的商品推荐。为解决该问题,本文设计了一种问题驱动的注意力神经网络来预测用户的购买倾向。该方法分析用户提问中的即时性需求和用户历史评论中的个人偏好来预测用户的购买倾向,进而推荐合适的产品。综上所述,本文的主要创新点如下:(1)面向商品评论的情感极性识别任务,提出了一种弱监督深度学习方法。该方法利用评论的评分作为弱监督信号来预训练模型,再利用少量标注数据来微调整个模型的参数。本文设计了一种抗噪声的三元准则来减小弱标注数据中的噪声数据对模型训练过程的影响。(2)面向商品评论的智能问答任务,提出了一种基于多任务学习的注意力模型。该模型利用电商网站在线问答系统中已有的问答数据来辅助学习问题与相关评论语句之间的映射关系。在模型的训练策略方面,本文提出了一种结合主任务先验知识的部分共享式迁移学习策略来实现任务之间的知识迁移。(3)面向问题驱动的商品推荐任务,提出了一种问题驱动的注意力神经网络来预测用户的购买倾向。该网络利用用户提问中的即时性需求及其历史评论中的个人偏好来分析用户的购买行为。商品评论中的相关性信息和正面情感极性信息是支撑用户购买行为的基本要素。所采用的注意力机制可以从评论中寻找到推荐理由。最后,本文综合用户的购买倾向和推荐理由实现了解释性推荐。文本在亚马逊公开数据集和淘宝数据集上评估了上述方法。结果证明了本文所提出的方法在相应的文本智能理解任务上的有效性和超出同类算法的优越性。"
466,基于深度学习的中文零指代消解技术研究,"零指代消解是自然语言处理任务中的一个重要研究方向,其目的是对文本中的不完整的表述进行补充,进而形成符合要求的没有成分缺失的“完整”文本。在自然语言构成的文本中,同一个相同的实体的表述方式往往是不同的,例如有很多实体以代词的形式存在于文本中。指代消解可以对分散在文本中各个地方的有着不同表述形式的实体或事件之间的关系进行识别,从而更好地对文本中的相关信息进行抽取。指代消解在信息抽取等自然语言理解任务中扮演着关键的角色。零指代是一种特殊的指代现象,广泛存在于中文等代词缺失的文本中。对于这些存在省略(零代词)的自然语言处理表述,人由于有着彼此类似的知识背景是能够很容易理解其中的含义的,但是对于机器来说则十分困难。因此,零指代消解在中文自然语言理解中十分重要。传统的中文零指代消解方法主要采用离散的特征向量作为输入,通过机器学习算法训练分类器,进而对零代词的先行语进行判断。这些方法对人工选择的特征有很大的依赖性,而且由于零代词语义缺失的特性,现有方法在选取先行语的过程中都忽略了语义信息。近些年,随着深度神经网络模型被不断的被成功的应用在自然语言处理领域,分布式的特征表示方法也获得了更多的重视。同传统的机器学习方法相比,分布式表示能够利用深度神经系统,逐层抽象,进而得到适用于指定任务的高层语义表示。本课题旨在通过深度神经网络,针对中文零指代消解任务的特点,提出四种深度学习模型(循环神经网络模型,记忆神经网络模型,注意力模型和深度强化学习模型),从不同角度出发提升中文零指代消解的性能。本课题针对中文零指代消解问题提出以下四个研究点:1.基于循环神经网络模型的零指代消解系统。传统的零指代消解系统主要通过提取句法词法等特征来构建消解器,而往往忽略了语义信息。这主要是因为零代词是没有描述性信息(如性别信息、数目信息等)的,这种信息的不完备性对获取先行语和零代词语义层面的相似度产生了较大的影响。例如,在代词的指代消解中被证明最有效的特征如性别匹配特征、数目匹配特征是无法使用的。针对这一问题,本文提出一种基于循环神经网络的零指代消解模型,利用零代词的上下文的语义信息,将零代词映射到分布式的表示,进而得到其深层语义表示。在对候选先行语的建模过程中,本文的方法能够有效获取其对应的全局信息与局部信息,并利用这些信息帮助零代词进行消解。在国际通用的中文零指代消解数据集OntoNotes 5.0上的实验结果显示,我们提出的基于循环神经网络模型的零指代消解系统的表现明显优于现有的基准系统。2.基于记忆神经网络的零指代消解系统。由于零代词有着天然的描述性信息缺失问题,如何从语义层面表示零代词是十分重要的。在众多的可利用的资源中,零代词的先行语是一种最自然的,携带最多信息的可以用来表示零代词的成分。本文通过引入一个深层记忆神经网络来从候选先行语中学习出潜在的零代词表示信息,并利用这些信息更新零代词的分布式表示,最终得到不同候选先行语的权重,选出零代词的先行语。通过实验,我们证明了记忆神经网络的有效性。3.基于注意力模型的零指代消解系统。在对零代词建模的过程中,常用的方法不能够有效获取不同词对零代词表示的重要程度。但是,在实际情况中,一部分词往往能够携带更多的表示零代词的信息,而另一些词在表示零代词方面并没有贡献。基于这一发现,本文提出了一种基于注意力模型的零指代消解系统,通过注意力机制学习到了不同词在表示零代词时的重要程度,并利用不同权重对零代词进行建模。在标准数据集OntoNotes 5.0数据集上的实验结果表明了添加注意力机制的必要性,我们的基于注意力模型的零指代消解在整体效果上超越所有的基准系统。4.基于深度强化学习框架的零指代消解系统。传统的零指代消解系统都是基于分类的模型。这些分类模型每次只考虑到当前候选词-零代词对的关系,并不能利用其它候选词的决策来帮助分类。同时,对当前词的分类结果并不能对后续先行语的判断有影响。为了解决上述问题,本文提出了一种基于深度强化学习框架的零指代消解系统,将传统的基于分类的系统扩展为序列决策标注过程。本文把一个零代词的所有候选先行语当做序列,利用深度强化学习模型按照候选词的出现顺序选择所有的可能的先行语。实验表明,基于深度强化学习的零指代消解系统相比较基于分类的系统能够大幅提高其表现。综上所述,本文针对中文零指代消解的几方面挑战给出了相应解决方法,深入研究了该任务亟需解决的问题,并在国际标准数据集上提高了消解模型的性能。具体而言,我们探究了利用循环神经网络不同先行语之间关系的建模;利用零代词的上下文信息和潜在的先行语对其进行语义表示;利用注意力机制获取不同词在表意上的权重;在深度强化学习的框架下将传统分类模型扩展为序列决策模型,增量化地判断一个零代词的先行语。最后,希望本研究能够对中文零指代消解等相关问题和自然语言处理领域的学者提供一些参考和帮助。"
467,基于心电图和指纹的多生物识别方法,"传统的身份验证策略(如密码和智能卡)因为它们可以被共享、遗忘、复制、操纵或伪造,其安全性存在隐患。与传统方法不同,生物识别是基于人的生理或行为特征进行身份识别的科学,已成为确定个体身份的合法方法。如今,生物识别技术已不再局限于刑事执法,更多企业使用生物识别技术来管理对建筑物和信息的访问。然而,大多数单模态生物特征识别受到诸如噪声数据,非普遍性和欺骗攻击之类的限制,使得它无法达到现实世界应用的性能要求。为了克服单模态方法的这些缺点,本文提出了一种新颖的安全多模态生物识别方法,使用不同的融合方法将心电图(ECG)与指纹相结合。该方法克服了单一方法的局限性,提高了整体方法的性能并增强了安全性,对欺骗攻击具有更好的鲁棒性。与其他多模态生物识别方法(例如,面部,耳朵和基于指纹的多模态生物识别系统)相比,ECG信号可以容易地从手指获取,这使得系统非常方便和有效。此外,ECG信号只能从活人身体获取,因此还可以据此进行活体检测,使系统具有更强的抗攻击能力。本文的第一部分研究了心电图和指纹作为单模态生物识别的方法。为此,我们首先提出一种改进的生物哈希和矩阵运算方法,为生物识别系统生成了一种新的可取消的心电图模板,这种方法比其他可取消的方法更安全;其次,我们提出了一种Q-Gaussian多类支持向量机(QG-MSVM)作为指纹认证的分类器,在指纹分类精度方面优于其他MSVM方法。在本论文的第二部分,我们提出了一种安全的多模态生物识别方法,该方法使用基于心电图和指纹的不同级别融合的卷积神经网络(CNN)和QG-MSVM。首先,我们提出了两种不同级别融合算法的认证方法:特征级别融合和决策级别融合。使用CNN执行针对各个模态的特征提取。在此步骤中,我们从CNN中选择了两个实现最高精度的层,其中每个层都被视为分离的特征描述符。之后,我们使用提出的内部融合将它们组合在一起以生成生物识别模板。在下一步中,我们应用改进的生物哈希技术来保护这些模板并提高其安全性。在身份验证阶段,我们提出QG-MSVM作为身份验证的分类器以进一步提高性能。其次,我们提出了一种基于CNN融合心电图和指纹的安全多模态生物识别方法。先使用CNN执行各个模态的特征提取,然后从这些特征生成生物特征模板,再应用矩阵运算技术来保护这些模板。在身份验证阶段,我们使用QG-MSVM作为分类器来提高身份验证性能。最后,我们使用评分水平融合来做出最终决定。本文提出的所有方法在几个公开的心电图和指纹数据库上进行了测试。实验结果表明,所提出的多模态方法比现有的多模态认证算法高效、鲁棒、可靠、它可以部署在实际应用中。"
468,监督学习算法预测性能比较的正则化交叉验证方法研究,"在数据驱动的智能信息系统中,机器学习模型是必用的。模型通常是由一个算法在大量数据上学习得到的。选择一个性能高的算法是系统不断升级的关键技术。事实上,算法比较是机器学习建模中基本问题之一。一个新发明的算法其性能是否优于旧算法,需要经过合理的统计检验才能得出可靠的结论。算法比较任务贯穿于建模过程中的算法选择、特征选择、模型选择及评估等各个阶段,是建模中关键环节。本文仅关注两个有监督学习算法的比较问题。算法比较任务通常被描述为:给定一个数据集及两个机器学习算法,哪个算法可以产生性能更为优良的模型?算法比较任务可形式化为统计显著性检验问题,并采用经过精心设计的交叉验证以及合理的显著性检验方法来解决。基于5折(10折)交叉验证的t检验,因简单易用,被研究者广泛采用。然而,该方法采用的方差估计偏小,难以有效控制检验的第一类错误,易导致假阳性的结论。尽管其第一类错误在5×2交叉验证t检验及F检验中得到改进,但5×2交叉验证受随机数据切分的影响,也常常得到不可靠的结论。为此,面向算法比较任务,本文对给定的一个IID数据集,首先从数据的切分方式入手,构建了正则化交叉验证方法,给出了较为合理的方差估计,然后构造了合理的序贯检验方法,理论分析和实验验证其减小了检验的第一类错误,可以得到可靠的结论。进一步,将正则化交叉验证拓展到文本数据集,对预测标签的分布增加正则化条件,并给出了准确率、召回率和F_1值的后验分布,构建了算法比较的贝叶斯检验方法。本文研究了正则化交叉验证的理论性质及构建方法。首先,从泛化误差的repeated learning-testing(RLT)估计入手,分析了RLT的随机切分对该估计的方差的影响,发现较差的切分方式会造成RLT中训练集间样本重叠过多,从而增大RLT估计的方差。因此,本文引入正则化条件约束重叠样本个数,优化RLT方法的切分方式,减小RLT估计的方差,构建正则化RLT方法。本文给出了正则化RLT方法的几种简易构造方法。作为RLT方法的一种特殊情形,m×2交叉验证在算法比较中使用更为广泛。为此,本文进一步考虑m×2交叉验证的优化问题。本文分析重叠样本个数对泛化误差的m×2交叉验证估计方差的影响,引入正则化条件将m×2交叉验证的重叠样本个数约束至n/4左右(n为数据集大小),提出正则化m×2交叉验证,证明了正则化m×2交叉验证可有效地减少泛化误差估计的方差,开发了正则化m×2交叉验证的高效增量式构造算法。针对文本数据集,本文进一步引入卡方统计量来度量训练集和验证集上多种频次分布的差异,提出关于该差异度量的多种正则化条件,进一步优化正则化m×2交叉验证,以构建适用于文本数据的正则化m×2交叉验证方法。本文使用IID数据集和文本数据集上的大量实验,说明上述正则化交叉验证方法的优良性。本文将算法比较任务形式化为假设检验问题,研究了基于正则化m×2交叉验证的统计推断方法。针对泛化误差,因训练集间存在重叠样本,正则化m×2交叉验证中多个hold-out估计间存在相关性,使基于正则化m×2交叉验证统计推断不同于IID观测上的传统统计推断方法。本文从理论上确定了正则化m×2交叉验证估计中相关系数的上下界,给出正则化m×2交叉验证估计的合理方差估计,严格证明所采用的统计量服从t分布。通过合理设置相关系数,构造了一个相对保守的序贯t检验统计量,并给出序贯置信区间。区别于传统的IID序贯检验,当重复次数m趋于无穷时,该序贯置信区间的期望长度收敛于一个正值,可能导致序贯t检验在有限时刻内无法停止。为此,本文使用序贯置信区间期望长度的缩减率作为准则,选取序贯t检验的最大停止时刻。本文从理论分析和模拟实验两方面比较了现有的一些检验与本文提出的序贯t检验。实验结果表明该序贯t检验为保守统计推断,可有效控制第一类错误且具有更优的势函数,并可给出可靠的结论。实验结果也说明,在许多情形下,不宜采用固定的m,而采用序贯的做法是必要的。针对文本数据,算法性能指标多为准确率、召回率和F_1值。它们的分布是偏峰的。因此,采用t检验不妥。针对准确率,召回率和F_1值,本文分析了正则化m×2交叉验证估计中的相关性与准确率、召回率和F_1值的后验分布间的关系,给出了它们的精确后验分布,构造了合理的后验置信区间,进而提出了算法比较的贝叶斯检验方法,并在文本数据上的分词及命名实体识别实验证实了该贝叶斯检验的有效性。本文以软件缺陷预测任务为例,针对缺陷数预测模型,将正则化m×2交叉验证序贯t检验用于检验各聚合特征对模型性能是否有显著影响的问题中。针对缺陷倾向性预测模型,文本将基于正则化m×2交叉验证的贝叶斯检验,用于比较logistic回归和随机森林两种分类算法在模型的准确率、召回率和F_1值上谁更优良。本文提出的正则化交叉验证及其统计推断方法,提高了算法比较结论的可靠性,对有监督学习算法的建模具有重要意义。关于优化数据切分的正则化思想,可扩展到大规模数据的子抽样上,为分布式学习和建模提供新的思路和方法。"
469,面向不平衡数据的集成学习算法研究,"在人们的日常生产、生活中,由于数据本身或抽样过程中人为因素的影响,不平衡数据集是广泛存在的。在这些不平衡数据集中,数量比较稀少的少数类样本往往与一些异常且重要的情况关系比较密切。在很多现实应用中,传统方法对这些少数类样本进行有效分类、识别是比较困难的。集成学习作为目前数据挖掘领域中的一个重要研究分支,受到研究者的广泛关注。集成学习通过把多个子学习器集成起来对机器学习问题进行研究,显著提高学习系统的泛化能力,比传统单一的数据挖掘算法更有优势。本文的主要研究对象为不平衡数据的分类和聚类问题,把集成学习方法作为工具,分别从使用抽样技术对原始不平衡数据样本集的样本分布进行调整、从数据抽样技术与改进的算法相结合等方面出发,以提高不平衡数据集分类和聚类的性能为目标,围绕数据层面如何合理有效地调整样本分布、在算法层面对已有算法的参数进行优化改进,提出了一些改进的算法,本文的主要研究内容如下:(1)基于欠抽样技术的K-AdaBoost聚类集成算法结合AdaBoost算法和K-means技术,面向不平衡数据集提出了一种站于欠抽样的K-AdaBoost算法。算法首先使用基于K-means聚类的欠抽样技术,在不破坏多数类样本结构的基础上,减少多数类样本的数量,提高数据集的平衡度;其次,在新的训练样本集上再次应用K-means算法得到多个类簇,通过计算测试样本到各类簇中心的距离,基于相似度和各类簇对基学习器的权重进行加权组合,得到测试样本对各基学习器的权重;最后,按照权重把各基学习器组合成强学习器,最终对测试样本进行预测。(2)基于ADASYN的R-AdaBoost分类集成算法面向不平衡数据集提出了一种基于ADASYN的R-AdaBoost分类集成算法。首先,算法基于ADASYN技术生成m个合成样本,对原始数据集起到平衡作用;其次,使用基学习器对新的数据集进行分类并得到每个子分类器的分类结果。在对样本的权重值进行更新时,引入Focal Loss损失函数的思想,增加了难分类样本的权重;最后,使用AdaBoost算法对测试样本进行分类,得到最终的分类结果。(3)基于进化过抽样的EOS-Bagging集成学习算法面向不平衡数据集,基于改进的SMOTE抽样技术,提出了EOS-Bagging(Evolutionary Over-sampling)算法。首先,EOS-Bagging算法对原始数据集中的少数类样本进行随机过抽样;其次,基于SMOTE算法和遗传算法通过对新样本集中的少数类样本进行选择操作,交叉操作,变异操作,通过进化抽样获取一个新的数据集;最后,在算法层面上,结合Bagging集成学习框架,使用基学习器对包含合成样本的新数据集进行分类,实现对测试样本的分类结果预测。通过实验表明,论文提出的算法在处理不平衡数据集聚类和分类的性能上有所提高。"
470,机器学习中的稀疏算法和非凸优化问题研究,"随着数据采集和存储技术的进步,金融、医学、网络等领域每天都产生着大量的数据,如何设计快速有效的算法从中挖掘出有价值的信息,成为大数据处理中迫切需要解决的问题.稀疏学习是处理大数据的重要方法.针对数据量较多的大样本数据,已有的基于核学习的算法需要利用所有样本计算核矩阵,且模型的解缺乏稀疏性,这无疑导致较大的内存和时间消耗,使算法难以处理大数据.对于高维大数据,特征中存在着冗余特征,已有的基于随机投影的特征稀疏方法快速且有效,然而由于稀疏随机投影矩阵生成方式的完全随机性,导致矩阵中非零元在列中分布不均,进而导致降维后更多的数据信息丢失.此外,机器学习中存在着很多非凸优化模型,如何为模型设计高效的算法来快速寻找到“全局”最优解是另一个值得研究的课题.本文围绕大数据的稀疏学习算法和机器学习中的非凸优化问题进行研究,主要包括下面几部分内容:(1)为了解决鲁棒最小二乘支持向量机(R-LSSVM)的解不具有稀疏性,难以处理大数据的问题,提出了稀疏R-LSSVM算法(SR-LSSVM).首先从重新加权的角度解释了R-LSSVM具有鲁棒性的原因.然后,利用表示定理得到了基于原空间的R-LSSVM模型,新模型可能具有稀疏解,并利用核矩阵的低秩近似,设计出了一种收敛的稀疏R-LSSVM算法(SR-LSSVM)来得到基于原空间的R-LSSVM模型的稀疏解.新算法的计算复杂度低于已有算法,能高效训练大数据.实验结果表明:与已有算法相比,SR-LSSVM能用更少的时间得到更高的准确率,在处理大数据方面效果显著.(2)为了解决核c-均值聚类算法需要计算全核矩阵,难以处理大数据聚类的问题,提出了基于不完全Cholesky分解的快速核c-均值聚类算法.该算法利用不完全Cholesky分解方法得到全核矩阵的近似矩阵,即一个低秩矩阵及其转置的乘积,然后将该低秩矩阵转置的列向量做为输入数据运行线性c-均值聚类算法.理论分析表明当核矩阵的特征值指数下降时,新算法与标准核c-均值算法得到的聚类结果之间的差异指数阶下降.实验验证了新算法的性能与标准核c-均值聚类算法相似,但新方法可以减少内存,加快运行速度,适合处理大规模数据集.(3)为了快速求解核模糊c-均值聚类模型(KFCM),基于凸函数的差算法(DCA)提出了三种KFCM求解算法.首先证明了在满足一定条件下KFCM模型可以进行DC分解,并提出两种基于DCA的求解算法.然后,为了提高第二种新算法的计算效率,采用了核矩阵的近似策略,避免了计算整个核矩阵,且使得聚类中心的计算是随机选定的几个样本的线性组合而不是全部样本.最后,采用了经典KFCM算法和新算法交替运行若干次的策略,为新算法寻找初始点.实验结果表明新算法在聚类精度,运行时间和迭代次数方面均优于传统的KFCM算法.(4)为了求解一类具有多个局部最优点的非凸优化问题的“全局”最优解,基于逐步优化算法(GOA)和随机方差缩减梯度(SVRG)方法,提出了SVRG-GOA算法.首先,设计了一种更接近原函数的新光滑化方法将原始非凸函数光滑化成一系列的局部强凸函数.然后,采用SVRG方法来迭代地求解这些局部强凸函数,得到一类非凸优化问题的“全局”最优解.理论上证明了新算法中更新规则的方差是有界的,算法是收敛的,且迭代复杂度低于已有算法.接下来,对于凸函数部分的梯度难以求解的问题,基于近端SVRG(PSVRG)方法,提出了PSVRG-GOA算法,此算法避免了求解凸函数部分的梯度,算法是收敛的且具有与SVRG-GOA相同的迭代复杂度.此外,为了防止算法过早限制在小范围内搜索而导致无法寻找到全局最优点的问题,为算法设置了较大的收缩因子;为进一步加快收敛速度,设置了相对较大的固定的投影步长;为进一步缩减方差,采用了小批量技巧;最后,将算法推广到了最小化有限个非凸函数的和的优化问题.实验结果表明新算法比已有算法能更快地收敛到非凸问题的“全局”最优解.(5)为了对高维数据进行降维,提高后续机器学习算法的效率,提出了稳定稀疏子空间嵌入算法(S-SSE).新算法基于统计学中的无放回抽样的思想,使得生成的稀疏矩阵中,每列只有一个非零元,且非零元均匀分布于各行.理论分析表明构造的S-SSE矩阵比已有的矩阵更稳定,且新方法可达到较好的欧氏距离近似精度.克服了现有稀疏随机投影矩阵中非零元行标的完全随机选取而导致的矩阵的行之间的非零元分布不均,矩阵变化较大等缺陷.实验证实了理论结果,并显示了新方法与现有算法相比的优越性."
471,满足差分隐私的多方数据发布技术研究,"随着网络技术的发展和智能设备的普及,人们产生和收集数据的能力不断增强。现实生活中,大量的相关数据往往分布在多个不同的节点(即数据拥有者)。将多方数据作为整体统一发布,有助于数据分析者更加深入地挖掘数据中蕴含的价值,从而提供更好的数据服务。然而,数据中往往包含大量的用户个人敏感信息,未对数据进行有效的隐私处理而直接发布,将不可避免地造成严重的隐私泄露。因此,本文研究满足差分隐私的多方数据发布问题。相比于满足差分隐私的单方数据发布,满足差分隐私的多方数据发布中个人隐私保护要求更加严格。另外,满足差分隐私的多方数据发布要考虑如何提高整体发布数据的效用和降低数据发布过程中数据拥有者之间的通信开销。为解决上述问题,本文针对三种典型的多方数据发布场景(水平分割关系数据集、垂直分割关系数据集和多方序列数据集),对满足差分隐私的多方数据发布问题进行了深入的研究,并取得了以下创新性成果:(1)针对满足差分隐私的水平分割关系数据集发布问题,基于贝叶斯网络模型,提出了一种满足差分隐私的水平分割关系数据集发布方法DP-SUBN。在该方法中,数据拥有者和第三方共同在差分隐私条件下以串行的方式构建贝叶斯网络。然后,第三方利用该贝叶斯网络生成一组新的发布数据。利用串行方式构建贝叶斯网络,可使得数据拥有者将先前数据拥有者的统计信息作为先验知识指导自己的学习过程,从而提高学习结果的准确度,并降低学习算法的复杂度和敏感度。为了保证串行学习的效果,提出了属性对关联强度感知的边界构造方法,在保证传递足够多的有效信息的同时,尽可能地降低数据拥有者之间的通信开销。此外,为减少属性对关联强度度量过程中噪音的摄入量,提出了无重叠属性划分方法,并提出一种动态规划方法确定无重叠属性划分方法中最优的参数。理论证明,DP-SUBN满足差分隐私保护要求。实验结果表明,该方法生成的整体数据具有较高的数据效用,且生成过程造成较低的通信开销。(2)针对满足差分隐私的垂直分割关系数据集发布问题,基于隐树模型,提出了一种满足差分隐私的垂直分割关系数据集发布方法DPLT。在该方法中,数据拥有者和第三方首先在差分隐私条件下共同构建一棵隐树。然后,第三方利用该隐树生成一组新的数据集。采用隐树模型,可以利用少量的隐属性度量大量的显属性之间的依赖关系,从而显著降低度量函数的敏感度和度量过程中数据拥有者之间的通信开销。为了提高生成的隐属性的准确度,提出两阶段的隐属性生成方法,降低了生成的隐属性中注入的噪音量。为了减少隐属性对关联强度度量过程中摄入的噪音量和造成的通信开销,提出了基于树状索引的关联强度度量方法。为了保证度量过程满足差分隐私保护要求,提出分布式拉普拉斯扰动协议。理论证明,DPLT满足差分隐私保护要求。实验结果表明,该方法生成的整合数据具有较高的数据效用,且生成过程造成较低的通信开销。(3)针对满足差分隐私的多方序列数据集发布问题,基于预测后缀树模型,提出了一种满足差分隐私的多方序列数据方法DPST。在该方法中,数据拥有者和第三方首先在差分隐私条件下,从根节点出发,依次对节点判断并将评分大于一定阈值的节点进行拆分,最终构建一棵预测后缀树。然后,第三方利用构建的预测后缀树,生成一组新的序列数据。为满足差分隐私保护要求,在对节点进行判断时,不能泄露节点的评分信息。为解决该问题,基于同态加密技术和姚氏比较协议,提出一种基本的节点拆分判别协议。为了进一步降低协议通信开销,提出了一种改进的节点拆分判别协议。理论证明,DPST满足差分隐私保护要求。实验结果表明,该方法生成的整体数据具有较高的数据效用,而且生成过程造成较低的通信开销。"
472,5G移动通信网络中的呼叫记录分析,"随着移动物联网技术(internet of things,IoT))的迅猛发展,可以预见,在下一代网络(fifth generation networkS,5G)中,将会实现万物互联。随着向5G发展迈出的每一步,智能手机、平板电脑和可穿戴设备移动设备的数量呈指数级增长。大量无线设备的连接和移动网络技术的进步将大大增加数据流量。这些大数据通常包含丰富的有用信息。然而,从如此大的数据中提取有用的信息是具有挑战性的。本论文主要针对蜂窝网络数据进行分析,以提高下 一代网络的性能。特别的,我们关注呼叫详细记录(call details record,CDR)数据。每当用户使用诸如语音呼叫、短信或互联网连接服务时,都会生成一个由网络运营商记录的CDR。移动网络CDR中包含的信息可以用来研究移动网络的运营效率和移动用户的行为模式。本文首先强调了 5G网络大数据分析的意义。为了克服挑战并满足5G 网络的关键要求,大数据驱动的分析框架至关重要。然后,我们利用呼叫细节数据记录来检测网络中的异常情况。对于异常的认证和验证,我们使用K-均值聚类算法,这是一种无监督的机器学习算法。通过对异常情况的有效检测,可以对资源分布进行合理设计,并进行故障检测和规避。此外,我们通过训练一个神经网络模型和去除异常活动,来准备无异常数据。将异常和无异常数据通过该模型,观察异常活动对模型训练的影响,并观察异常和无异常数据的均方误差。最后,我们使用自回归整合移动平均模型来预测用户的未来的数据量。通过简单的可视化,我们发现无异常数据能更好地训练学习模型,在预测任务上表现得更好。第三,我们从CDR数据中提取出可操作的结果,并能说明它在真实的网络流量模式中存在很强的时空可预测性。移动运营商可以利用这些知识进行有效的网络规划,如资源管理和优化。在此基础上,我们对意大利电信集团的CDR数据进行了时空分析。因此,基于时空视角,我们提出了一个移动交通分类框架。实验结果表明,基于机器学习技术的网络流量模型能够对网络流量模式进行准确的建模和分类。此外,我们还演示了这些结果在资源优化中的应用。最后,我们分别对网络活动记录数据进行分析,以便于理解和划分网络流量。移动蜂窝网络的互联网活动记录(internet activity records,IAR)具有重要的信息,可以用来识别网络的效能和移动用户的行为。我们从IAR数据中提取有用的信息,并确定网络流量中时空模式的正确可预测性。提取的信息有助于网络运营商规划有效的网络配置,并对网络资源进行管理和优化。本文展示了意大利电信IAR数据的时空分析实验。在此基础上,提出了移动业务划分方案。该模型的实验结果有助于网络流量模式的建模和划分。"
473,面向车联网的安全机制与关键技术研究,"近年来,汽车的数量急剧增加,给现有的交通系统带来了严峻的挑战。例如,交通拥堵和交通事故频发,严重威胁到人们的生命和财产安全。车联网被认为是解决上述问题的有效途径,通过在车与车之间、车与网络设施之间建立通信,使得车辆能够有效获取交通环境信息,提前做出驾驶决策,从而提升交通的安全和效率。然而,作为一个包含人、车、基站等多个元素的复杂网络,车联网中有可能存在各种安全隐患,危及网络的正常运行乃至交通的安全。本文重点关注车联网应用中的安全问题,旨在充分利用车联网中的各类数据(例如,车辆感知数据、通信数据、用户数据等),实现对特定安全隐患的消除或恶意行为的抑制。具体而言,本文首先提出了面向车联网应用的数据驱动安全架构,概括性地介绍基本的方法和思路;然后,分别针对网约车、自动驾驶和共享汽车三类典型车联网应用,分析其可能存在的安全问题,并通过对车联网数据的分析和利用来解决这些问题。本文主要的研究内容和创新点可归纳为:1.面向车联网应用的数据驱动安全架构大数据在无线网络优化、用户体验提升等领域发挥的重要作用已被充分验证。除此之外,对数据的充分利用也可以在很大程度上保障网络安全。因此,本部分首先对车联网中存在的主要数据类型进行归纳和总结,列举其对于维护网络安全所发挥的作用;在此基础上,提出了面向车联网应用的数据驱动安全架构,详细介绍车辆、基站等网络实体在本架构中的主要功能以及相互之间的交互流程;然后,通过分析本架构在安全、性能等方面的需求,明确主要的目标和挑战;最后,对典型应用案例进行简要介绍,以说明本架构的可行性。本部分内容为后续具体安全问题的研究和解决提供了基本的思路和方法。2.基于移动行为的车联网Sybil攻击检测算法本部分内容主要针对网约车应用中可能存在的Sybil攻击问题,提出基于移动行为分析的解决方案。具体而言,本研究首先根据攻击者能力的不同,将车联网中的Sybil攻击分为三个层级,包括普通攻击、伪造位置和合谋攻击,并对其各自的行为特征进行分别建模;其次,针对不同级别攻击行为的具体特征,设计不同的检测方法:(1)通过对车辆移动轨迹相似性进行分析,获得轨迹的相似度特征向量,然后利用机器学习分类算法检测移动行为过于接近的两条轨迹,以应对普通攻击;(2)利用基站向车辆签发位置证书,然后基于主观逻辑理论,评估车辆上传位置的可信程度与不确定性,以应对可以伪造位置的Sybil攻击者;(3)根据车辆共同出现在同一个基站附近的次数和时间间隔,建模车辆之间的亲密程度,然后利用社区发现算法实现对合谋Sybil攻击的有效检测。最后,利用真实的车辆移动轨迹数据对这些算法进行仿真和验证,结果表明本算法可以有效抑制各级Sybil攻击行为。3.基于区块链的车辆信任管理机制本部分主要针对自动驾驶应用中存在的车辆信任问题展开研究。在自动驾驶场景下,车辆可以接收周围车发送的消息以提前获知道路交通状况。然而,临近车辆之间的陌生关系使得这些消息的可信程度很难确定。本部分内容首先利用贝叶斯推理模型,使得消息的接收者可以综合多个来源的信息对收到消息的可信程度做出判断,并根据判断结果对消息进行评分。然后,车辆将评分数据上传到附近基站中,由基站构成的区块链网络来负责信任数据的存储、更新和维护工作,以保证数据的安全性与一致性;此外,设计了适用于车联网具体特点的区块链共识机制,使得收到评分较多的基站能够更加高效地产生新的区块并发布出去,从而在数据的安全性与时效性之间达到平衡。仿真结果表明本方法可以有效地帮助消息接收方评估消息的可信程度,并满足车联网对于时延等性能指标的需求。4.基于智能合约车辆访问控制策略针对共享汽车应用中可能存在的单点故障、信任缺失等问题,本研究将智能合约技术引入到车辆的访问控制中,由分布式的区块链网络以及运行在区块链上的智能合约来完成身份验证、授权等工作。相对于传统的中心式方法,本策略由多个矿工节点共同负责数据存储与维护、代码执行等功能,降低了系统被攻击者所控制的可能性,从而实现透明、安全、互信的车辆权限管理与访问控制。在此基础上,本研究还利用强化学习算法对订单选择策略进行优化,使得车辆可以根据收益率、剩余时间等状态灵活选择是否接受某订单请求,从而实现车主收益的最大化。最后,对提出的访问控制策略进行仿真并评估其时延性能,利用Q学习算法对订单选择优化问题进行了求解,并证明了本算法相比于传统贪心算法的优越性。"
474,智慧学习环境中学习画面的情感识别及其应用,"普通数字学习环境已不能满足“数字土著”的需求,人工智能、大数据、区块链等技术迅猛发展,将深刻改变人才需求和教育形态,作为数字学习环境高端形态的智慧学习环境便应运而生。智慧学习环境注重培养学习者的创新能力、问题求解能力、决策力和批判性思维能力等高阶思维能力,认知活动在培养过程中起着至关重要的协调与控制作用。情感是由外界刺激引起的心理反应,能够影响和调节注意、知觉、表象、记忆、思维和语言等认知活动。学习过程中的积极情感有助于激发学习动机、培养学习兴趣,促进认知过程;而消极情感则会影响耐心度、注意力,阻碍认知过程。现有智慧学习环境研究重“知”轻“情”,注重学习者认知层面的适应性和个性化,即根据学习者的认知能力和知识状态提供合适的学习内容、学习路径和问题解答等,而较少考虑情感、兴趣、动机、意志等非智力因素在学习活动中的作用,忽视智慧学习环境中和谐情感交互的理论和实践研究,以致其缺少情感层面的适应性和个性化,学习者在智慧学习过程中缺少情感支持。智慧学习环境中学习者主要通过智能学习终端观看学习内容的信息呈现画面即学习画面进行学习,学习画面是学习者学习的主要环境,并且是学习者与学习内容间信息交互的主通道。学习画面的色彩搭配、排版布局、图形装饰、背景纹理等对学习者智慧学习过程中的情感、兴趣、动机和效果都有不可忽视的影响。另一方面,学习者情感的准确识别是构建智慧学习环境和谐情感交互的基础,更是判断学习者学习状态的重要手段,对促进学习者的智慧学习具有重要意义。学习画面以直观的视觉特征和隐含的艺术特征影响学习者的情感状态和认知活动,智慧学习环境除为学习者提供个性化的学习内容和学习路径外,所呈现的学习画面还应与学习者的情感状态、视觉情感偏好相适应,并能对学习者的学习情感起调节和激发作用。本研究以学习画面隐含的情感属性为切入点,关注智慧学习环境中的“情感缺失”问题,为智慧学习环境情感层面自适应交互的实现提供了新的思路与方法。本研究通过访谈和调查,将学习画面情感分为温馨、欢快、活泼、搞笑、夸张、幽默、有趣、凄凉、枯燥、沉闷、繁乱、虚幻、惊险、恐怖等14种类型;通过文献梳理和实地观察,发现学习者的学习情感主要包括常态、高兴、愤怒、悲伤、惊恐、专注、走神等7种类型。然后,通过采集程序和网络爬虫,建设了拥有17456幅图像的学习画面图像数据库和拥有85085幅图像的学习者表情图像数据库。本研究综合考虑准确率、训练速度和内存消耗等因素,根据学习画面图像的特点,设计了9层卷积神经网络模型以识别学习画面的情感,该模型包括4个卷积层、4个池化层和1个全连接层,并在自主建设的学习画面图像数据库上进行了模型训练和实验;根据学习者表情图像的特点,设计了7层卷积神经网络模型以识别学习者的学习表情,进而判断学习者的情感状态,该模型包括3个卷积层、3个池化层和1个全连接层,并在自主建设的学习者表情图像数据库上进行了模型训练和实验。实验结果表明,本研究设计的卷积神经网络模型能够较为准确的识别学习画面的情感和学习者的学习表情。本研究通过实验探究学习画面情感对学习者情感的影响,实验对象为济南市某学校7、8年级的学生,使用具有不同情感的学习画面进行实际教学,并同时采集学习画面图像及其对应的学习者表情图像,整个实验共持续15周时间。实验结果表明,具有温馨、欢快、活泼、搞笑、幽默和有趣等情感的学习画面能够引起学习者常态、高兴、专注等积极情感,具有凄凉、枯燥、沉闷和繁乱等情感的学习画面能够引起学习者愤怒、悲伤、惊恐、走神等消极情感,而具有夸张、虚幻、惊险和恐怖等情感的学习画面则较为特殊。本研究通过实验探索学习画面自适应调整对学习者情感的影响,实验对象仍为济南市某学校7、8年级的学生,实验组观看自适应调整后的学习画面进行学习,对照组观看未经调整的原学习画面进行学习,同时采集实验组和对照组学习者的学习表情,整个实验共持续2周时间。实验结果表明,根据学习者的表情、视觉情感偏好以及学习画面的情感自适应调整学习画面的关键视觉特征,能够调节学习者的学习情感,激发学习者的学习兴趣。本研究为智慧学习环境情感层面自适应交互的研究与实现带来了新的发展,具有相当的创新性和实际应用价值。"
475,用于聚变电源的故障诊断算法研究,"聚变装置是一个复杂的系统,而聚变电源则是装置能够稳定运行的重要支持系统。电力变换器作为聚变脉冲功率电源的关键组成部分,会影响电源的正常运行。因此,精准快速的故障诊断对电力变换器的健康运行非常重要。随着计算机技术的高速发展,运用深度学习理论来提高故障诊断的智能化水平已逐渐成为一个重要的研究方向。本文首先分析了深度神经网络在电气系统故障诊断的优势,阐述了卷积神经网络(CNN)的特点。基于磁压缩理论分析出EAST#41195托克马克放电的电气参数,为高性能等离子体垂直场设计提供参考,引出磁压缩线圈电源(Magnetic Compression Coil Power Supply,MCPS)的需求。电源变换器的故障诊断对实现该电源的正常运行和良好控制至关重要。而基于深度卷积神经网络的电源变换器故障诊断方法需要大量的故障工况数据。本文以经典聚变电源变换器模型为参照搭建了Simulink模型,插入相应短路故障以获取故障数据,并通过Overlap的方法实现数据增强。给出了用于工况分类的1D-CNN模型,对电源变换器运行工况进行了分类,精确率达98%。以环流工况为研究对象,给出了适用于电源变换器故障诊断的1D-CNN模型,可以自动完成故障信号特征提取,故障识别率达到91%。利用数据可视化技术,展示了1D-CNN模型诊断短路故障信号的过程。根据短路故障信号特点,针对1D-CNN模型训练速度慢的问题,进一步给出了 1D-BNCNN模型。该模型加入批量归一化处理(Batch Normalization)层,使每一个卷积层输入数据的统计分布比较接近,有利于网络训练速度和精度的提升。结果显示,经过20步迭代,模型收敛,故障识别率达到95%。针对聚变垂直磁场电源实测数据统计信息的不足,给出了基于1D-BNCNN的迁移学习模型。该模型采用了小样本测试数据对模型参数微调,实现了模型迁移的方法。将迁移模型用于LHD装置线圈电源变换器仿真的故障诊断问题,测试结果显示精度为91%,从而说明了此类模型对于聚变电源中多信号输入问题的泛化潜力。"
476,非合作模式下微弱信号识别技术研究,"随着“中国制造2025”战略的推进,通信技术得到了长足发展。新环境、新需求和新目标对信号检测技术带来了重大挑战,对各种无线环境的监测,尤其是非合作模式下微弱信号的监测,具有非常重要的意义。然而,现有的信号检测理论只能对特定环境下的信号进行有效识别和监测,对非合作模式下的微弱信号进行快速检测和深度认知的能力不足,这严重制约了无线通信管理和检测技术的发展和应用。因此,研究非合作模式下微弱信号的监测和识别技术具有重大的理论和工程意义。该问题首先需要对微弱信号进行预处理,从而降低微弱信号受到的干扰,然后分别对各种应用场景进行研究:针对单个种类微弱信号识别问题,如果数据量较少,那么需要研究小数据样本下微弱信号识别问题;如果数据量较大,那么需要研究大数据样本下微弱信号识别问题;另一方面,如果识别微弱混合信号,则需要研究微弱混合信号分离和识别问题。针对上述问题,本文创新性地提出了各种解决方法和策略,其主要的贡献和创新点如下:1.非合作模式下微弱信号的预处理技术。收发信机之间的频率偏移会严重影响识别精度,而且频率偏移在实际通信系统中是无法完全消除的。然而,传统的频率偏移估计算法在非合作模式下的估计效果较差,无法有效地消除频率偏移。针对该问题,我们提出了一种基于聚类的频率偏移纠正算法,和传统的频率偏移纠正方法相比,本文提出的方法具有更高的精度,能够有效地消除频率偏移。另外,本文提出了基于谱聚类算法的调制方式粗估计技术。谱聚类算法是一种广泛使用的聚类算法,但是传统的谱聚类算法对信噪比较低的信号聚类效果较差,本文发现该缺陷出现的原因在于其距离矩阵构建方式存在缺陷。针对传统谱聚类算法的缺陷,本文提出了一种改进的谱聚类算法,经过实际通信系统的验证,该方法能够有效地识别星座图中的调制方式。然后根据识别后可能的结果构造调制方式候选集,方便微弱信号的精细识别。2.小数据样本下微弱信号精细识别技术。现有的非合作模式下微弱信号的识别方法通常分为两种:基于最大似然的方法和基于特征的方法。针对现有识别方法的不足,本文提出了一种基于字典学习的调制方式识别框架。而且基于该框架,提出了一种名为FBCDDL的新型字典学习算法,该算法有效地解决了现有方法的缺陷:(1).现有方法对干扰的鲁棒性较差,而FBCDDL对干扰的鲁棒性较强;(2).现有方法的复杂度较高,而FBCDDL复杂度较低;(3).现有方法无法保证收敛性,而本文证明FBCDDL能够保证收敛到全局最优解。仿真结果验证了本文提出的方法对噪声、相位偏移以及频率偏移等干扰有较强的鲁棒性,而且具有更低的复杂度和更快的收敛速度。3.大数据样本下的微弱信号精细识别技术。随着业务量的上升,通信系统越来越需要对大数据样本条件下的微弱信号进行处理。本文提出了一种基于卷积神经网络的微弱信号识别框架。该方法首先计算微弱信号的循环谱图,然后利用卷积神经网络对信号的循环谱图进行分类和识别。针对微弱信号的特点,本文在卷积神经网络的代价函数中加入了新的惩罚项。该方法的能够解决现有方法的缺陷:(1).现有方法需要人工提取特征并进行识别,而该方法可以自动地提取特征;(2).现有方法的准确度较低,而本文提出的方法具有较高的正确率。仿真表明,在数据样本量较大的情况下,本文提出的方法具有更高的识别精度。4.非合作模式下微弱混合信号分离和识别方法研究。日益紧张的频谱资源导致一些频段由不同通信系统共用,这使得不同的信号相互混合的情况越来越普遍。本文提出了一种新型的微弱混合信号分离和识别方法,该方法解决了现有非合作模式下微弱混合信号的分离和识别方法的缺陷:(1).现有方法应用场景受限,而本文提出的方法应用场景更广;(2).现有信号识别方法分类精度较低,而本文提出的方法具有更高的分类精度。"
477,基于机器学习的低剂量CT成像关键问题研究,"X射线计算机断层成像技术(X-Ray Computed Tomography,X-CT)因其超高的时空分辨率特性在临床中的应用越来越广泛,它能够以无损的方式对人体内部的超微信息进行结构成像,也能对运动的器官进行高维度成像,如4DCT。然而有研究表明,X射线辐射会在人体内部沉积,当沉积量超过人体器官耐受剂量的时候,会引起人体内部器官结构的改变,甚至局部基因的突变。因此降低CT扫描过程中病人所承受的X射线辐射剂量刻不容缓,但是降低CT扫描过程中病人所承受的X射线辐射剂量会极大地降低CT影像质量,影响临床诊断。如何平衡CT扫描过程中病人所承受的X射线辐射剂量和CT影像质量之间的关系是一个迫切而又有复杂的问题。影响CT扫描过程中病人所承受的X射线辐射剂量的方式多种多样,从广义上可以分为X射线源输出端:降低X射线源单次曝光剂量,提高X射线源单次曝光剂量的利用率,降低扫描过程中的投影采集率等;X射线探测器接收端:提高X射线探测器的探测效率,增加X射线探测器像元的尺寸等;不同的操作对于CT影像质量的影响不同,降低X射线源单次曝光剂量会使得投影中充满噪声,降低了重建后CT影像的信噪比;降低扫描过程中的投影采集率会使得投影空间数据不完备,导致重建后CT影像充满条形伪影;增加X射线探测器像元的尺寸会降低投影图像的分辨率,使得重建后的图像细节不清晰等。在本文中,我们从三个方面去降低CT扫描过程中病人所承受的X射线辐射剂量;第一个方面是降低扫描过程中的投影采集率,根据傅里叶切片定理可知,降低扫描过程中采集的投影数目,会使得投影空间中的数据不完备,导致重建后CT影像充满条形伪影。但是条形伪影在CT影像中具有相对固定的形态和位置,它不随扫描病人的改变而发生大幅度变化,因此我们设计一个基于深度学习的框架从大量数据中提取条形伪影的特征,然后反馈给重建后的CT影像,改善CT影像的质量,该方法以滤波反投影后的CT影像作为输入,以端到端的方式进行训练,且该网络的参数量只有同样深度同样宽度的网络1/3左右,这使得在医学数据量不是很大的情况下,减轻了网络过拟合的倾向。第二种降低CT扫描过程中病人所承受的X射线辐射剂量方式是增加X射线探测器像元的尺寸,在X射线源输出小于正常剂量的情况下,增大X射线探测器像元的尺寸,提高了单个X射线探测器像元的X射线光子的接收面积,从而增加了投影图像的信噪比,但是这直接影响了投影图像的分辨率,使得重建后的CT影像对人体内微小结构的分辨不清。为此本文充分分析了高低分辨率投影和CT影像之间的关系,结合超分辨重建模型,图像去模糊模型和CT重建模型,提出了基于模型融合的高分辨率CT重建技术,为了提高模型的精度,我们将该模型展开并用卷积神经网络的形式去表达,利用一个小数目的训练集去学习模型中的模糊核和惩罚函数等超参数,经过大量的实验验证,该模型具有很好的泛化性和鲁棒性,该模型不仅能够大幅提高CT系统的空间分辨率,还能间接地降低CT系统的硬件成本。第三种降低CT扫描过程中病人所承受的X射线辐射剂量方式是提高X射线源单次曝光剂量的利用率,传统的X射线源由于在运行过程中其阴极需要大量的热量去激发,导致X射线源无法瞬时启停,也就无法精准控制单次X射线源的曝光剂量。基于碳纳米管的X射线源在场致发射的原理下能够做到X射线源在纳秒级别的启停,我们通过控制栅极电压的大小控制单次X射线曝光剂量。由于冷阴极的特性,X射线源的体积可以小型化,在此基础上,我们可以设计多源多探测器的CT系统架构,通过电子开关激活不同位置的碳纳米管X射线源替代传统CT机械架构的旋转,极大地的加快了传统CT的扫描过程,降低了CT扫描过程中病人所承受的X射线辐射剂量。但是第三种方法中涉及到的多源多探测器系统会减少投影的采集数量,提高了探测器的成本,甚至在某些机械设计中会限制CT系统的扫描视野的大小,不同的缺陷会引起不同的伪影,但是由于CT系统架构固定,CT影像中伪影的特征相对固定,为了获得与传统CT系统同等质量的CT影像,我们可以利用前两种基于数据驱动的模型从低分辨率且稀疏的投影数据中恢复出高清CT影像,改善因系统架构的改变而带来的CT影像降质的问题。在本文中,我们综合分析了CT扫描过程中X射线剂量对CT影像的影响,从不同的角度提出了降低CT扫描过程中病人所承受的X射线辐射剂量的方式,根据相应的方式,我们提出了对应的算法去解决因X射线剂量的降低而导致的CT影像质量降低的问题,并通过大量的实验验证了我们算法的有效性和高效性。"
478,基于机器学习的医学影像分割关键问题研究及其在肿瘤诊疗中的应用,"医学影像分割是从二维或三维医学影像中检测出目标对象的边界,获取正常组织器官及肿瘤病变区域,其分割技术在诊断的形态和解剖分析、治疗前的活检引导与路径规划、治疗中的跟踪与定位、预后的病情进展变化等方面有着重要的临床意义。虽然基于机器学习的全自动分割算法目前在多模态医学影像分割上取得了众多的研究成果,并展示出其优秀的分割性能。然而,不同模态的成像技术受噪声、部分容积效应和图像强度信息不均匀等因素影响,严重降低了图像质量而引起边界定位困难。加之,肿瘤及组织器官解剖多样性和在不同模态图像上的特异性表达及空间与时间分辨率各有不同,从而增加了目标对象的复杂性,因此,全自动、稳定、鲁棒和准确的医学影像分割依然具有较大的挑战。为解决上述难题,本论文进行了如下研究:从边界识别和形状多变自适应能力的角度研究提升分割算法精度的方法;研究数据驱动的乳腺超声(Breast Ultrasound,BUS)、肝脏计算断层成像(Computed Tomography,CT)、前列腺磁共振(Magnetic Resonance Imaging,MRI)的跨模态图像精准分割算法;调研分析和验证分割算法在肿瘤诊疗中的应用场景和价值。本论文研究贡献及创新点主要包括针对高噪声、强度分布不均匀的乳腺肿瘤US图像,研究了基于边界约束的主动轮廓模型,引入边界指示算子克服边缘曲线的吸附能力;提出一种超像素边界感知的卷积网络(SBBS-CNN)实现肝脏CT全自动分割,有效解决了训练样本不足和容积效应导致的目标边界定位不准确;为克服前列腺MRI强度分布不均匀和周围组织重叠,提出了一种多层级边界感知的残差全卷积网络(HBS-RUnet)实现前列腺组织的准确分割,并采用多层级自学习策略提升学习特征鲁棒性和网络收敛性能;初步验证了基于级联2.5D残差全卷积网络(2.5D RUNet)的肝段与肿瘤分割在肝肿瘤外科手术前功能评估分析应用。最后,通过详细的实验对比分析,本论文所研究的分割算法和模型训练策略方法不仅可以全自动、准确、鲁棒和稳定的对组织器官和肿瘤目标完成分割和检测,而且该成果易于扩展至其他影像模态和肿瘤部位,为临床对肿瘤疾病的精准诊疗提供参考性的技术方案。"
479,高分辨X射线光谱仪原理与设计,"X射线光栅光谱仪除了实现对同步辐射设施或自由电子激光装置等先进光源的推动和快速发展,还被广泛用于探索各种有趣的研究课题。其中采集效率和分辨能力是光栅光谱仪最重要的两个参数指标。凹面变线距光栅作为一个高性能光谱仪的核心,通过配合不同的前置镜或前置镜组合便能实现像散的消除和分辨能力的提升。本文在软X射线的“水窗”波段设计了两款光栅光谱仪,实现了像散的消除和分辨能力的提升,主要工作包括:1.为了消除像散,首先在凹面变线距光栅的基础上通过优化光栅子午半径和变线距系数D_1实现子午方向聚焦曲线的控制;对聚焦曲线的“平坦”程度进行量化,实现子午方向的平场和优化。在目标分辨能力不变的前提下,得到光栅入射角和光栅物距之间的对应关系,并由此找到不同光栅物距条件下对应的最佳子午“平场”的倾角;以消除光谱成像中的像散为目的对光栅的弧矢聚焦进行优化。先是提出了光栅子午、弧矢方向光源分离的概念,证明了在光栅弧矢虚光源的前提下,可以通过同时优化光栅弧矢虚物距和光栅弧矢半径来实现弧矢聚焦曲线和子午聚焦曲线的重合,消除像散。2.在消像散型光谱仪的实际设计中,将一面凹柱面镜放在凹面变线距光栅上游,构成类似K-B聚焦镜的结构,来实现光栅弧矢虚光源的条件。通过计算得到了四个不同子午物距条件下的系统参数,将每个系统进行像差分析,并考察了包括光源尺寸,初级像差(离焦、慧差和球差)和倾斜误差几个因素对分辨能力的影响。将追迹软件得到分辨能力与根据像差理论计算得到的分辨能力进行比较,得到了良好的验证。通过观察SHADOW追迹结果,弧矢方向宽度结果均匀等大,并符合系统的弧矢放大率,证明了光谱成像中的像散得到消除。3.为了增强分辨能力,首先比较了四个不同光栅光谱仪系统的理想分辨能力,包括了单凹面光栅系统、前置凹面镜-光栅实光源系统、前置凹面镜-光栅虚光源系统和前置凸面镜-光栅实光源系统,并比较验证了凸面镜前置是提升系统分辨能力更好的选择。还研究了当前置镜被插入到系统中时,光程函数考虑它带来的像差影响的方法。另外还提出使用点列图中光线子午坐标的标准偏差与对应波长的理想线宽的商来表示成像质量,并且根据标准差的定义,这个商值越大,表示成像光束越离散,像差越大,成像越差;引入支持向量机SVM进行数据的学习和预测方程的重构,配合上非线性规划算法,探索具有良好成像质量的最优光谱仪系统参数。4.在分辨能力增强型光谱仪的实际设计中,根据优化结果计算了凸面镜前置光谱仪系统的详细参数。针对优化后的系统同样进行了像差分析,考察了包括光源尺寸,初级像差(离焦、慧差和球差)和倾斜误差几个因素对分辨能力的影响;提出了实现光谱仪超高分辨能力倾斜误差需要满足的条件。提出了像差分布中连续光学镜面的倾斜误差贡献的叠加方法。同样将SHADOW追迹软件的结果和像差理论计算得到的分辨能力进行比较和验证,在“水窗”波段内实现了100,000~200,000的分辨能力。还考察了当光源发生位置抖动和发射角抖动时对光谱仪性能的影响。5.利用两块独立的,能实现不同目的的提前放置镜,在0.6~1.5keV能量范围设计了光谱仪,同时实现像散消除和分辨能力的提升。追迹验证了在弧矢虚光源的条件下,光栅基底采用子午凹柱面的可行性;给出了多块前置镜的倾斜误差在色散方向上积累的计算方法;计算并比较了在不同尺寸的系统中前置凸面镜提升分辨能力的效果的差别。"
480,基于星载主被动微波盐度计的海面盐度反演方法研究,"海洋盐度是联系全球水循环和海洋环流的重要动力学参数。2015年,我国首次提出了海洋盐度探测卫星计划,用于完成对全球海面盐度的观测。主被动微波盐度计(MICAP)是海洋盐度探测卫星上计划搭载的有效载荷之一。借鉴SMOS和Aquarius/SAC-D卫星的技术经验,MICAP首次采用了L/C/K多频段一维综合孔径辐射计和L波段数字波数合成散射计相结合的技术方案,具有多频段主被动联合探测的能力,目前国内外尚无载荷具备此能力。考虑到仪器配置不同,现存的海面盐度反演算法都无法直接用于MICAP的海面盐度反演。为此,本文开展了无降雨情况下的MICAP海面盐度物理反演算法和机器学习反演方法的研究,并结合国外卫星实测数据验证了本文所提算法的有效性,以期为未来我国海洋盐度卫星的应用提供相应的理论和算法支撑。首先,基于微波辐射传输方程和地物模式函数,建立了MICAP海面盐度反演算法所涉及的粗糙海面辐射亮温和后向散射系数模型。通过对比不同海水相对介电常数模型的差异及其对平静海面辐射亮温的影响,选择了适用于MICAP的海水介电常数模型,建立了MICAP的L/C/K波段粗糙海面辐射亮温模型。结合外推法和PALSAR的地物模式函数获得了43°-55°大入射角的后向散射系数,建立了MICAP的L波段外推地物模式函数。同时,分析了不同海浪谱模型及有无泡沫对L波段粗糙海面辐射亮温的影响,为海浪谱和泡沫模型的选择提供参考。其次,基于建立的粗糙海面辐射亮温模型、后向散射系数模型、L/C/K波段无降雨大气衰减模型以及宇宙辐射和法拉第旋转修正方法,针对无降雨情况,提出了一种适用于MICAP的多频段、多入射角主被动联合海面盐度物理反演算法。使用蒙特卡罗仿真方法,验证了所提算法的反演精度,评估了MICAP反演海面参数的性能。仿真结果表明,卫星单次过境时,在中低纬度,所提算法获得的海面盐度、温度和风速的均方根误差分别为0.6 psu、1.2℃和0.8 m/s。假设接收机的稳定度近似等于仪器的灵敏度,在中低纬度,使用所提算法获得的月平均(30天和200 km×200 km时空平均)海面盐度均方根误差小于0.13 psu。此外,还对比了MICAP不同频段配置对海面参数反演精度的影响。比较发现,使用不包含23.8 GHz频段配置反演的海面盐度、温度和风速均方根误差分别为0.6 psu、1.2℃和0.9 m/s。可见,在无降雨情况下,23.8 GHz频段的有无对海面盐度、温度和风速的反演精度影响较小,为MICAP频段配置的优化提供了参考。再次,使用Aquarius和AMSR2测量数据及相关辅助数据构建了算法验证数据集,验证了所提算法用于实测数据的有效性。在反演之前,使用建立的正演模型模拟了L/C/K波段的辐射亮温,并基于回归方法修正了测量亮温和模拟亮温之间的系统偏差。结果表明,相比于斯克里普斯海洋学研究所的Argo盐度插值数据以及遥感系统的AMSR2的温度、风速和云液水产品,所提算法获得的海面盐度、温度、风速和云液水的均方根误差分别约为0.61 psu、0.73℃、0.90 m/s和0.038 mm,证明了所提算法的可行性和合理性。同时,也说明了所提算法具有同步反演多个海气参数的能力。最后,将机器学习中的深度神经网络、高斯过程回归、支持向量机回归和核岭回归引入到海面盐度和风速的反演中,并使用Aquarius卫星在中国南海的测量数据和相关辅助数据验证了机器学习海面参数反演方法的可行性,对比了四种机器学习方法获得的海面盐度和风速的反演精度。进而,比较了深度神经网络反演方法和Aquarius两种物理算法获得的海面盐度反演结果。通过比较发现,相比于HYCOM的盐度,深度神经网络方法获得的海面盐度偏差和均方根误差均小于两种物理算法;相比于斯克里普斯海洋学研究所的月Argo盐度插值数据,深度神经网络方法获得的盐度均方根误差小于两种物理算法;相比于Argo浮标的盐度,深度神经网络方法获得的盐度均方根误差小于CAP算法,偏差小于两种物理算法。但深度神经网络方法对参考样本的质量和样本数量的依赖性较大,对小样本数据的反演精度不理想。"
481,基于张量的多光谱图像云检测与在轨实时处理研究,"遥感图像处理技术广泛应用于军事国防和民用经济建设领域,得益于航天遥感对地观测技术的迅猛发展。如今的光学成像卫星的遥感图像具有分辨率高、覆盖面宽、细节丰富等优点,同时这些优势也意味着成像的数据量非常巨大,海量的数据会造成更大的数传压力,极大地延误了遥感信息的时效性。云通常覆盖了地球的近三分之二的区域,海洋比陆地上有更多的云层覆盖。云层阻挡地面特征的光线到达传感器系统,严重阻碍了光学遥感卫星获取有效信息,造成星上存储资源冗余,增加了数传压力。随着集成芯片产业的快速发展,人工智能、深度学习与基于嵌入式系统的实时识别已经在地面应用中得到实现。具有人工智能识别功能的嵌入式实时处理相机是未来星载相机发展的重要方向。智能相机可以对数据进行在轨实时处理,比如实现星上目标实时检测功能,剔除被厚云层覆盖或者平静海面等无效信息,提取舰船或者飞机等有效军事目标信息。在一个数传窗口内,大幅度缩减冗余信息量,提高数据使用效率,减少数传压力,从而实现如下目的:大型军事目标实时侦察,跟踪监视其活动情况,掌握敏感地区海上大型军事力量的部署与目标动向。所以,实现在轨实时云检测处理在军事或商业卫星领域均有重要的实际应用价值。为了提高星上在轨遥感图像自动云检测处理的速度和准确性,缓解在轨传输与存储数据压力,保障遥感信息的时效性,本文围绕多光谱遥感图像的本质和云检测问题展开了研究。根据遥感图像的成像特点,设计了一整套基于张量的在轨实时云检测处理的方法,和基于可编程逻辑阵列(FPGA)与多核数字信号处理器(DSP)的在轨处理硬件平台。本文详细阐述了在轨实时云检测处理的算法流程中涉及到的各项关键技术,包括超像素分割,目标区域特征的选择与提取、基于张量的机器学习方法、硬件平台上的高效运算架构等,改善了在复杂背景下多光谱幅面遥感图像中云检测算法运算速度慢、检测率低和通用性差的问题。主要研究内容归纳如下:多光谱图像可看作由高度、宽度、光谱构成的三维数据,通常将多光谱图像展开成多个二维矩阵进行运算处理,平坦化或展开操作破坏了内部数据间结构,而该结构作为多维空间中信息的反映是非常重要的,张量能够描述具有三维及以上的数据结构。本文介绍和分析了张量运算和支持张量机存在的问题,由于支持张量机的权重函数是由投影得到,这种方法不能捕获多光谱图像数据结构之间的耦合。为了保持数据结构的完整性,本文提出了支持规范张量训练机(SCTTM),实验结果表明,该算法能保持张量的数据结构信息,在小样本的训练集下,得到高效的识别分类结果。在轨云检测处理首先需要进行图像分割步骤,结合在轨硬件平台并行处理的优势和精确分割目标与背景需求,本文分析了当前主流的超像素分割方法及其优缺点。由于超像素分割主要针对彩色(RGB)图像,超像素分割用于多光谱遥感图像时,无法充分利用多光谱图像的谱段信息和丰富的灰度信息。本文提出了基于特征加权小波融合的超像素分割方法,该方法充分利用多光谱的所有谱段信息和灰度信息。实验表明,本文提出的方法相对于现今的超像素分割方法,对复杂的多光谱图像进行超像素分割后,能准确的分割海洋与陆地、船只与海洋和云区域。遥感图像经过本文提出基于特征加权小波融合的超像素分割后,根据场景被聚类分割成若干超像素子切片。本文设计了基于张量的Gabor能量云检测方法,突出一种新的特征,Gabor纹理能量特征图结合光谱信息特征图构成三阶张量,带入支持规范张量训练机进行训练识别。本方法不受限于图像的成像参数,可在不同轨道高度、不同分辨率、不同校正等级的多光谱图像进行云检测,并且得到的结果相对于现有云检测方法有更高的准确率和更低的误报率。根据在轨处理的需求和本文算法流程的张量运算,本文提出了基于FPGA的快速张量运算架构,设计了基于FPGA的张量内积、外积和核心张量运算架构。实验表明,本文提出的方法在FPGA上运算的效率比CPU有明显的优势,在数据规模增大时,相对于GPU也有明显的优势,为后续工程实现轨实时处理提供了保证。在轨多光谱相机成像模块在成像时,会对在轨处理模块产生非常可观的数据速率传输,并在规定Cameralink接口的项目需求下,设计了一套基于FPGA的超高速Cameralink接口。仅利用成像模块和在轨处理模块的FPGA片内资源实现了超高速Cameralink传输,不仅摆脱对Cameralink专用转换芯片的依赖,并且在数据格式不变的情况下,显著突破了专用转换芯片的Cameralink传输速率瓶颈,大幅度缩减线路板布线需求和面积,降低硬件设计成本。最终,本文搭建FPGA与多核DSP在轨处理平台,并对云检测算法进行优化和嵌入式系统移植。在保证系统通用性及可扩展性的同时,提高算法的处理效率,减小了星上遥感数据的传输压力,为在轨云检测奠定了基础。"
482,基于深度卷积神经网络的光学遥感目标检测技术研究,"光学遥感图像中的目标检测技术在民用方面和军事方面都有着十分重要的意义。在民用方面,高精度的目标检测可以辅助城市交通管理,帮助城市进行规划建设;在军事方面,高精度的目标检测有利于精确地锁定入侵目标,保护国家安全。光学遥感图像中传统的目标检测算法――边缘检测算法、阈值分割法、基于视觉显著性的方法和基于浅层机器学习的算法已经很难满足今天光学遥感图像中目标检测的要求。随着深度学习特别是深度卷积神经网络在图像处理领域的巨大发展,利用深度卷积神经网络在光学遥感图像中进行目标检测已经成为不可阻挡的趋势。相较于浅层机器学习进行目标检测时复杂且低效的工作流程:首先必须依据特定目标设计特定的特征提取算法然后再将得到的特征送入分类器进行分类,深度学习特别是深度卷积神经网络则可以直接提取目标的有效特征。另外,深度卷积神经网络能够提取目标更加本质的特征而浅层机器学习只能提取初级或者中级的特征如纹理特征、边缘特征等。目前,基于深度卷积神经网络的目标检测算法大体上可以分为俩种:一种是以Faster RCNN为代表的双阶段检测器,另一种是以YOLO和SSD为代表的单阶段检测器。相较于双阶段的目标检测器,单阶段的目标检测器在速度上更具有优势,但是在精度上表现不佳,尤其在检测小尺度目标的时候其结果并不令人满意。特别是YOLO系列,在小尺度目标上的检测精度尤为糟糕。而双阶段检测器虽然在速度上慢于单阶段检测器但是其在小尺度目标上的检测精度要优于单阶段检测器。相比较而言,双阶段检测器更加适合光学遥感类的目标检测。因此,本文依据已经公开的具有国际认可度的光学遥感数据集进行有关研究。基于Faster RCNN检测器,在俩个具有代表性的数据集上,“微调”多种主流深度卷积神经网络进行目标检测,并对各个深度卷积神经网络的性能进行全面的分析。从详细的实验分析中,了解各个深度卷积神经网络的优缺点,了解何种结构的深度卷积神经网络更加适合光学遥感图像中的目标检测,了解直接“微调”深度卷积神经网络在光学遥感图像中进行目标检测的注意点和不足。同时,为了减少深度卷积神经网络所需要的存储空间,我们提出了子网卷积化的方法,初步探索网络轻型化。研究发现,直接D微调‖深度卷积神经网络在光学遥感图像中进行目标检测存在着很多的不足。因此,我们提出了一系列的改进。首先,在光学遥感图像的目标检测中,周围环境复杂,干扰较多。因此,利用深度卷积神经网络进行目标检测时存在大量难以识别的目标。在训练的过程中为保证网络在整个数据集上取得较好的结果,往往会忽视“难样本”的特征。针对这种情况,我们采用D在线难例解析‖,即将难以识别的目标作为网络训练的主要对象进行目标检测与识别,D在线难例解析‖有效地提高了网络的整体能力。其次,光学遥感图像中部分目标摆放非常密集,尺度较小,这些目标的有效特征在深度卷积神经网络传播过程中会严重丢失,针对这种情况,我们提出了提高分辨率来减少特征的丢失。但是,直接提高网络结构的分辨率会导致感受野的下降从而导致全局信息的丢失,所以我们采用D空洞卷积‖来提高感受野。除此之外,深层次网络得到的特征包含较少的定位信息,而定位信息对于光学遥感图像中的目标检测是十分重要的,因此本人提出了一种多尺度特征结合的方法。该方法结合了深层网络所包含的有利于分类的高级语义特征和浅层网络包含的有利于定位的边缘、纹理等特征。最后,为了减小深度卷积神经网络模型所需要的存储空间,增加网络的可移植性,本人又提出了一种网络轻型化的方法。通过实验证明,我们提出的方法是可行的,相较于目前流行的基于深度卷积神经网络的目标检测方法,我们的方法在精度和召回率上存在较大的优势。综上所述,我们深度研究了如何在光学遥感图像中利用深度卷积神经网络进行目标检测。在分析了多种主流深度卷积神经网络在光学遥感图像中进行目标检测的优缺点的基础上,提出一系列的改进从而达到高精度目标检测的目的。我们的研究对于光学遥感图像中的目标检测具有很深的指导意义。"
483,基于智能监测的火电机组节能优化,"纵观全球能源技术发展动态和主要能源大国推动能源科技创新的举措,火力发电技术向深度节能和智慧电厂发展。本文以开发火力发电机组热力设备状态性能在线监测和节能优化技术、形成基于过程数据的电厂节能优化监测监控运行平台为目标,以数据挖掘和热力计算为手段,主要开展了以下研究:1.建立了基于深度学习的氮氧化物排放浓度软测量模型。针对目前多数模型直接以影响氮氧化物生成的因素为输入变量,采用基于互信息的封装式特征选择方法对NO_X预测模型进行变量筛选,确定最优输入变量集合。为了获得高质量样本数据,利用稳态检测方法提取机组稳态运行数据、小波变换方法去除数据中的噪声。最后,以深度信念网络(Deep Belief Network,DBN)为基础构造NO_X排放浓度预测模型,通过与其它排放预测模型的对比,证明了DBN模型的有效性。2.建立了基于改进随机森林的飞灰含碳量软测量模型。针对建模过程中以热工试验数据为样本数据时数据量小、而直接以机组历史运行数据为样本数据时数据准确率不定的问题,提出了以热工试验数据为基础、Fluent模拟数据为特征、机组历史运行数据为集群的样本数据选取方法。在建模方法上,提出了基于融合特征选择和偏最小二乘回归的改进随机森林(partial least squares regression-based random forest with hybrid feature selection,HFS-PLSRF)以及基于BP神经网络的改进随机森林(back propagation based-random forest,BP-RF),并通过6组数据集验证了两种改进模型的有效性。将改进随机森林应用于飞灰含碳量软测量并对比两种改进模型,确定了基于HFS-PLSRF的飞灰含碳量预测模型具有更好的预测效果。3.建立了基于软测量和元素平衡法的锅炉热效率在线计算模型。以NO_X浓度和飞灰含碳量软测量结果为基础,采用元素平衡法计算得到烟气中三原子气体的体积分数、锅炉灰渣含碳量,实时计算锅炉热效率。4.实施了空冷岛冬季防冻监测。针对多数在役空冷岛只监测每排的凝结水温而不是每个空冷单元的凝结水温,本文设计了基于空冷单元的多点多参数监测系统。以系统提供的实时数据为基础,提出了基于空冷单元供需传热平衡的冻结预测方法。该方法从冻结的本质出发,以空冷岛内的各散热单元为监测对象,通过比较空冷管束内、外工质的传热强度实时监测各单元的冬季冻结状态。5.开展了机组热力设备状态性能监测。针对机组各个燃烧器出口煤粉参数不均匀、尾部受热面积灰以及空冷岛脏污监测等存在的问题,实施了煤粉参数输送测控、对流受热面积灰厚度在线监测及空冷岛清洁因子实时监测等设备状态监测方法,实现机组从能量输入、转化以及传递到冷端的全流程性能监测。6.研发了600MW亚临界机组节能监测系统。该系统包含了机组性能在线计算、热力设备状态性能监测、机组性能优化等多个功能。本监测系统已在大同二电厂600MW机组投入运行。本文研究的节能监测技术是智慧电厂的重要内容。"
484,基于中华05标准的数字化骨龄X光片自动化识别算法的研究,"手腕部骨龄是评估青少年儿童生物年龄的主要方法。手腕骨骨龄的判读方法一直以来采用人工判读,判读过程主观性强、耗时费力,因此自动判读算法研究成为热点,目前自动骨龄判读系统与专家判读结果相比平均错误率已低于0.6岁。但随着机器学习,特别是深度学习算法的发展,大量学者仍然在尝试应用新方法进一步提高自动判读算法的准确度。本研究基于中国应用最广泛的“中华05 RUS-CHN”人工记分法骨龄判读标准,以多种图像处理算法、卷积神经网络、学习迁移等理论为基础,研究了多项生理学先验经验、多种机器学习算法、以及算法调优手段对判读平均误差(MAE,机器判读:专家判读)的影响。基于研究结果完成了一套自动骨龄判读模型的工程实现,该模型判读骨龄和专家判读骨龄相比平均误差仅为0.460岁。基于人工骨龄判读的先验经验,本研究主要包括三方面重要算法的研究:1重要骨化中心识别算法、2各骨化中心发育水平评价算法、3根据骨化中心发育水平的骨龄计算算法。主要取得的理论研究成果如下所示:(1)为了准确有效的从手腕骨X光片中提取各个骨化中心(ROI,中华05RUS-CHN标准规定为13块),本研究提出了一种基于手腕部生理结构拟合和Gabor纹理分析的骨化中心提取算法。首先,针对手骨和软组织分割的难点,提出了基于两者边缘纹理和灰度特征的“骨-软组织分割算法”。然后,基于手腕部骨生理结构,提出了手腕部骨结构的骨架拟合算法。最后,提出了基于Gabor纹理分析,并结合小波滤波的多参数骨化中心识别算法。骨化中心识别分割算法的工程实现最终取得了99.2%的识别分割成功率。(2)在骨化中心发育水平评价的自动算法研究中,针对骨化中心发育等级的标准模糊性,本研究对比了多种卷积神经网络(CNN)分类方法在骨化中心发育等级分类问题上的效果,同时,针对骨龄图片数据集的稀缺性问题,基于卷积神经网络的迁移学习(CNN-TL)理论,创新性的提出了骨发育水平分类器的新训练方法。最终得到13块重要骨的“骨发育中心发育等级分类器”,准确率有显著性提高。(3)鉴于由骨化中心发育水平计算骨龄的传统记分法的操作复杂性,本研究提出了基于传统记分方法的浮点化改良算法,以及生理发育异常骨的替代算法。比较无改进骨龄计算方法,自动判读骨龄和专家骨龄的平均误差降低了0.005岁。综上所述,本研究通过Gabor纹理分析、多项式拟合、小波滤波等图像处理算法提出了骨化中心识别分割算法;同时综合运用卷积神经网络(CNN)、迁移学习(Transfer Learning)等算法和理论,完成了骨化中心发育水平评价算法;并对传统计分法骨龄计算进行了发育异常骨的替换,使用上述多种方法降低了自动识别算法的平均误差率。平均误差(MAE)0.46岁,均方误差(MSE)0.451岁。"
485,基于集成学习的工业过程监测,"随着现代化工业的发展,对工业生产过程安全、产品质量、经济效益等多方面的要求不断提高,过程监测已经成为自动化领域的重要研究问题之一。随着工业生产过程不断地复杂化、规模化,大量的传感器被广泛地部署在生产设备上,使得海量的生产过程数据得以被采集。同时,随着云计算、大数据、人工智能等信息技术的不断发展,数据驱动方法逐步成为过程监测领域的研究热点。近年来,大量的数据驱动过程监测方法被提出,但是这些单一方法都基于一定的数据假设,存在局限性,难以在不同条件下都得到满意的监测性能。针对上述问题,本文基于集成学习方法,在研究基模型性能差异、基模型数量以及集成模型精度等基础上,提出了多种有效的过程监测方法和整体模型集成框架,具体内容包括:(1)大部分集成模型都没有考虑基模型性能差异对集成效果的影响,在融合决策结果过程中,通常给予不同模型相同的权重。针对上述问题,本文提出了一种基于层次分析法的模型评价方法,综合考虑多种评价指标对多个模型进行优先级评价,并将此评价结果作为模型权重与贝叶斯后验概率相结合,用于故障检测和故障分类。通过在田纳西伊斯曼过程进行验证,得到了比单一模型更好的监测效果。(2)在模型集成过程中,并不是基模型数量越多,集成的效果就越好。反之,如果加入性能较差的单一模型,可能会对最终结果产生负面影响。针对该问题,本文提出了基于集成选择的改进随机森林方法,用于工业过程的故障分类。首先,考虑基模型之间多样性以及单一模型性能,提出了一种静态集成选择方法,选取原始随机森林中的部分决策树构造一个新的随机森林模型用于在线故障分类。其次,考虑到在线样本之间的差异性,提出了一种动态集成选择方法,针对每一个在线样本构造一个新的随进森林模型进行分类,并提出一种加权概率融合方法取代原有的多数投票法。通过仿真试验平台验证了所提方法的有效性。(3)为了进一步提升集成模型精度,本文将深度学习模型与集成学习模型相结合,提出了一种基于深度集成森林的故障分类方法。该方法将单层集成模型拓展为多层集成模型,能够有效地提取特征信息,从而提高分类准确率。在该模型每一层中构建三种树集成模型也就是森林模型,然后将每层的信息提取结果与经过特征选择的原始数据堆叠作为下一层的输入向量,以此类推,直到某层模型性能不再提升,模型训练终止。通过在田纳西伊斯曼平台进行对比试验,验证了方法的有效性。(4)提出了一个系统性的集成模型框架用于工业过程监测。首先,针对不同的过程数据特性和目标任务,进行模型选择。然后,针对已选模型通过多准则决策方法进行模型评价,最终通过决策融合方法将多个模型的结果融合得到最终的结果。此框架为过程操作人员和工程师提供了一个系统的数据驱动工业过程监测操作流程,通过仿真研究验证,该集成方法能够有效提升监测性能。最后,在总结全文的基础上对集成学习方法在过程监测领域的未来研究工作进行了展望。"
486,基于张量网络的机器学习模型,"强关联电子体系一直是凝聚态领域近半个世纪以来的中心问题之一。很多有趣而尚待深入理解的现象都与之息息相关,例如高温超导,莫特绝缘体,分数化激发,自旋液体等。它的本质困难在于其不可用微扰论、平均场等方法做单体近似的相互作用。不可忽略的强相互作用使得一般的多体波函数需要通过单体波函数的直积来构造。这样的构造办法将使希尔伯特空间的维度随着系统尺寸指数地往上涨,很快超过现实计算机能够承受的范围。研究多体波函数,近似是必要的,在单体近似不可用的情况下,基于系统局域性近似的密度矩阵重正化与张量网络重正化方法成为一种实际有效的量子多体数值算法。近年来,物理学家开始注意到机器学习领域面临着类似的挑战。图片的构型空间随着图片的尺寸指数增长,机器学习模型需要利用有限参数的模型近似给定自然图片集在构型空间中的特征分布。这与多体波函数建模的思想是一致的。因此,通过对两个领域的深入比较和研究,我们期待物理算法可以为机器学习领域带来更多可解释性的学习理论及模型,同时机器学习模型也将可能为物理学研究带来全新的方法。具体来说,两者的比较研究可分为数据,模型及算法三部分。数据部分检验量子波函数与经典自然图片的复杂性是否一致。寻找自然图片集近似的理论依据,为机器学习的成功提供物理解释,同时也为将量子算法应用于自然图片集提供了动机。模型部分考察传统的机器学习模型,例如概率图模型等,是否与量子多体的模型,例如张量网络等,存在对应关系。是否可将张量网络算法作为概率图算法的拓展,如何基于张量网络构造量子机器学习算法。算法部分通过构造实际可计算的新模型,研究常见的多体算法如DMRG等,是否可以用于对自然图片的建模。机器学习中的方法,如后向反馈等,是否可以进一步优化现有的量子多体算法。以下是本文的具体安排:在第一章我们首先分别对张量网络态与机器学习特别是生成型学习做必要的介绍。包括张量网络态所依赖的面积律,常见的张量网络态如矩阵乘积态,树状张量网络,投影纠缠对态等;常见的张量网络算法,如重整化算法,变分算法等;机器学习的常见范式,如监督学习,非监督学习,判别型学习与生成型学习等;常见的监督学习模型与生成型学习模型等。我们还会简要讨论机器学习算法成功的原因及机器学习领域研究的问题与量子多体领域研究的问题的相似性。在第二章,我们首先从信息论的角度考察张量网络态处理机器学习问题的动机与可行性。具体来说,我们指出量子态中的Renyi熵与经典图片的互信息之间形式上的相似性。我们估算了图片集的互信息,发现自然图片集的互信息远小于其理论上界。表明自然图片的特征分布是一种可有效近似的函数。通过构造只有近邻连接的限制玻尔兹曼机,我们指出自然图片集的关联由近邻关联占主导,同时又少量稀疏的长程关系。这暗示着基于局域性近似的张量网络模型是适用于自然图片集的。同时,我们也发现张量网络与概率图模型有着密切的对应关系。我们给出了限制玻尔兹曼机与矩阵乘积态的严格映射。在第三章,我们将对基于张量网络的监督学习算法做一个简要的回顾。我们会介绍张量网络在监督学习算法中使用到的各种模型,算法,图片到张量网络的映射方法,张量网络监督学习算法现有的结果及其未来可能的发展方向。除此之外,我们还会在这一章讨论张量网络态与机器学习中的概率图模型与因子图模型的对偶关系。在第四章,基于对前述自然图片集局域性的观察与验证,我们尝试用最简单的张量网络,也就是矩阵乘积态与矩阵乘积算符来优化在分类监督学习中非常成功的残差神经网络和Dense网络。我们用矩阵乘积算符代替这些深层网络中的全连接层。这样做之后,整个学习模型的参数个数可以显著下降,同时模型的学习效果几乎不受任何影响。这也表明了机器学习模型中绝大多数刻画长程关联的连接是完全冗余的。第五章我们将张量网络应用于无监督的生成型学习,我们在前面矩阵乘积态生成型学习模型的基础上,提出了基于树状张量网络的生成型模型。树状张量网络模型可以保有矩阵乘积态模型的所有优点,同时可以实现二维化建模。同时模型学习的效率不受图片尺寸的影响。对相同的数据集,将二值化MNIST数据集的test NLL降到了更低。把基于张量网络的生成型模型往前继续推进了一步。第六章我们将对这个新兴领域做一个总结与展望。重点将探讨1,基于张量网络的生成型模型的未来发展潜力与具体的发展方向。2,基于张量网络的机器学习对量子机器学习的启发。3,张量网络算法在除图片以外的其它类型机器学习问题中的前景。4,机器学习算法在未来对包括传统张量网络在内的各种量子多体算法可能带来的改进与优化。"
487,六角CaFe_2As_2的可能超导电性和生成对抗量子线路,"理解非常规超导的微观配对机制是凝聚态物理主要挑战之一。自铜氧化物超导体和铁基超导体被发现以来,虽然有大量的实验和理论研究,但导致非常规超导的配对机制至今没有达成共识。这两类不同的超导体在相图,电子结构,磁性等方面都表现出共性。基于这些共性去统一理解非常规超导的配对机制,对发现和设计新的高温超导材料具有重要的指导意义。而反过来,基于统一的配对机制指导规则下发现的新超导材料如果被实验证实,将有助于我们深刻理解非常规超导的微观机理。本论文第一个工作基于现有的两类非常规超导体配对机制的理解下,预测六角CaFe2As2可能具有非常规超导电性。我们研究了 122六角体系过渡金属磷族化合物的磁性和电学性质,发现该体系与122四方格子过渡金属磷族化合物体系有类似的磁学和电学性质。其中122四方格子中包含了铁基超导体。我们预测在六角体系中,CaFe2As2通过掺杂也可能变成新的非常规超导体。通过第一性原理计算,我们发现在两类体系中,铁基材料有最大的次近邻反铁磁交换相互作用。次近邻反铁磁交换相互作用是导致铁基超导体母体化合物有C-型反铁磁基态和s-波超导态的原因。通过计算,我们发现在六角体系中,CaFe2As2有很强的次近邻反铁磁交换相互作用。这导致该材料处于强阻挫磁态。我们计算通过参杂之后,该材料可能处于时间反演对称破缺的d+id超导配对基态。六角铁基材料为我们提供了很好的一个平台去理解和验证非常规超导的原理,我们期望实验能够合成材料并发现超导电性。近几年来机器学习,特别是深度学习引起了学术研究和工业应用的热潮。机器学习是一种能够从数据中学习的算法。作为机器学习的一个分支,深度学习利用神经网络强大的表达能力在很多应用中有着优异的表现,比如图像识别与生成、自然语言处理等。根据数据集中是否有标签,机器学习大致可以分为监督学习算法和非监督学习算法。监督学习是学习从输入变量到另一个输出变量的映射或者学习一个条件概率分布。而非监督学习的生成模型需要对训练数据的联合概率分布进行建模。生成模型除了能够处理分类和回归之外还能应用到更广泛的任务中,比如生成新的样本,进行密度估计等。而基于深度学习的生成模型困难在于被建模的随机变量维度太高,这极大地提高了计算量。本论文的第二个工作,我们尝试用量子计算去解决生成模型的计算挑战。根据玻恩对波函数概率的解释,我们知道量子力学具有天然的概率特性。用量子线路对经典数据建模,这样的生成模型充分利用了高维希尔伯特空间的强大表达能力和量子线路有效的直接抽样能力。我们称为量子线路玻恩机。然而因为在量子线路中我们无法得到波函数的表达式,使得量子线路玻恩机缺乏有效的基于梯度的训练方法。我们设计了一个由量子线路生成器和经典的神经网络判别器组成的量子-经典混合的对抗训练框架。同时我们针对量子线路设计了一个代价函数对量子线路参数梯度的无偏估计。我们在Bars-and-Stripes数据集上成功地进行了数值模拟。我们的生成对抗量子线路模型能够在近期的含噪声的中型量子设备中运行。"
488,金属玻璃应力弛豫及结构与重排事件关系的研究,"金属玻璃是一种新的无序结构材料,相较于晶体材料,它有着诸多优异的力学性能,比如极高的弹性极限和强度等。然而在室温下,金属玻璃的塑性变形主要集中在剪切带中,导致缺少明显的宏观拉伸塑性,这也严重制约了它的工程应用。因此我们需要更加深入地理解金属玻璃的塑性形变机制。由于非晶体系结构无序的本质特性,使得晶体中位错调制塑性变形的机制难以用在非晶体系中,至今为止,非晶体系的变形载体的形变机制仍不清晰。金属玻璃也为研究无序体系的塑性变形机制提供了模型材料体系。结合分子动力学模拟,我们研究了在外加恒定应变下,金属玻璃的变形载体的激活模式与系统宏观物理量的联系;同时利用机器学习的方法,我们分别研究了在静态以及绝热剪切下,金属玻璃的重排与局域结构参量的联系。在静态情况下,金属玻璃的变形载体很难探测到,本文中我们对金属玻璃施加恒定拉伸应变,进而探测变形载体的特征与动力学行为。我们使用分子动力学模拟了应力弛豫的过程。我们直接观测到应变加速了金属玻璃的弛豫行为,主要来源于金属玻璃中的变形载体-流变单元的激活。同时我们还观测到在临界的外加应变附近,应力弛豫过程中的应力衰减度以及弛豫时间达到饱和,这对应了流变单元的激活模式由随机激活到协同性运动的转变。在静态条件下,我们成功地使用机器学习的方法探测金属玻璃以及过冷液体的局域结构,并识别出易于发生结构重排的类液原子。同时我们还发现这些类液原子与其他原子在结构上的区别超越了短程序。我们进一步通过改变截断距离重新定义了结构熵,证实了该结构参量定义时截断距离需要超过第一近邻才是合理的。我们的结果显示金属玻璃体系中的结构重排事件是具有结构起源的,同时预测重排事件的结构参数在定义时需要包含超越短程序的原子。在绝热剪切条件下,为了表征局域结构参量预测塑性重排的能力,我们使用机器学习的方法定量化了局域结构参量对重排事件的预测能力。我们发现能够反应动力学信息的结构参量具有最好的预测重排的能力,这些结构参量包括“参与度”以及“振动均方位移”。同时我们还发现使用机器学习方法仅从结构定义的“软度”也具有很强的预测变形载体的能力。"
489,复杂交通场景下车牌检测算法的研究,"车牌检测是现代智能交通系统的一项基础支撑技术,其使用光学成像设备抓拍车辆图像,随后应用计算机视觉、机器学习等相关技术,从抓拍到的车辆图像中自动确定车牌位置坐标,并分割出车牌区域。经过长期发展,车牌检测技术已经广泛应用到智能交通的各领域,如:停车场收费系统、交通道路流量监控、交通违章车辆抓拍、车辆智能跟踪及定位等。目前,针对车牌检测任务已经有很多理论研究成果和成型的商用系统,表面上看车牌检测技术相当完善,可以获得令人满意的效果,实际上此类技术有很多前提条件,局限性相当大。例如应用广泛的停车场收费系统,必须配备良好的图像采集环境,光照、拍摄角度、图像的稳定性等都需处于理想状态,一旦去除这些前提条件,现有技术的检测效果将大打折扣。因此,研究复杂交通场景下的车牌检测技术仍然具有很高的实用价值。本文从日常拍摄的非理想环境出发,研究复杂交通场景下的车牌检测算法,针对非理想拍摄环境、实时检测、多角度、模糊修复等目前车牌检测技术存在的问题,结合深度学习算法展开研究,主要有以下几点创新工作:(1)提出一种适应非理想光照场景的车牌检测算法,其基于深度学习图像语义分割技术,抽取鲁棒的图像特征,生成车牌显著性区域的分割图。该算法将普通卷积神经网络的全连接层替换为卷积层;网络中设计了4个空洞卷积的分支,每个分支可独立抽取不同感受野的视觉特征;将不同分支、网络不同层次的特征融合在一起,生成与原图相同尺寸的分割图。上述网络自动抽取鲁棒的视觉特征,加上网络的非线性分类效果,算法精确分割出车牌和背景区域,在两个公开的车牌数据集上的验证结果表明,与其它算法相比,在非理想光照场景下本算法有更好的检测能力。(2)针对实时车牌检测任务提出一种高效率车牌检测算法,其目标是:提供高速分割运算同时把分割精度的下降程度控制在可接受范围内,解决普通分割算法运算效率不高的问题。设计该分割算法的主要思路是:通过降低每个卷积层的输出通道数,减少计算量,降低资源消耗;资源消耗下降必然带来精度的损失,该网络使用了一个并行结构弥补这个问题,不同分支处理不同感受野的图像特征,只有消耗最小的一个分支通过了完整的卷积层,在网络末端几个分支叠加,可以获得不同感受野的特征。经验证,算法达到了效率和精度的平衡。(3)提出一种任意抓拍场景下非规则形状车牌四角定位算法。该算法包含一个角点预测网络、角点匹配算法和一个角点回归网络,适用于检测非正面拍摄角度引起的有旋转、透视畸变的车牌图像。角点预测时使用图像语义分割网络输出不同尺度下的车牌4角点热力图,经平滑叠加后,求热力图灰度的峰值,可得到每个车牌4角点的坐标。对于多车牌情况,预测的角点数为4的倍数,角点匹配算法根据多角点间连线相互跨立的比例,对不同车牌的4角点分组。角点回归网络使用相对距离进一步对角点进行微调,用以得到更精确的坐标。上述算法解决了目前车牌检测算法常用的滑动窗体不能有效检测不规则四边形的问题。(4)提出一种非稳定抓拍场景下车牌图像的去模糊算法,有效提升检测能力。该算法使用生成对抗网络进行训练,算法的判别模型使用了带惩罚项的损失函数,将训练损失限定在可控范围内,使模型可以加速收敛。算法的生成模型采用了多重放大结构,有效利用各结构生成去模糊后图像的细节;生成模型的损失函数使用两种结构:生成图像与清晰图像在特征空间里的均方误差和二者在直观像素空间里的改进均方误差,这两种结构使生成模型可以比较两个空间的差异,有助于生成更加逼真的清晰图像。经验证,在经过去模糊的图像上进行车牌检测和车牌识别,各项衡量指标比直接检测原图有了显著提升。"
490,电力实时信息优化处理关键技术研究与应用,"电力是经济、政治、文化、科技等发展的基础,国内电网智能化水平已经达到了一定水平,但相对于近期提出的泛在电力物联网建设要求仍然存在不足,目前电力实时信息存在错误多、同步性差、误差较大等问题,对电网实时信息进行深入研究,解决目前存在的问题,提高电网智能化、泛在化水平具有重要意义。通过梳理电力实时信息目前存在问题,从基础原理入手,力求根本性解决问题,主要包括以下四个方面。(1)深入研究了网络对时存在不准确的影响因素,结合国内外最新的1588对时技术,将网络对时与影响因素建立幂函数关系,提出了基于机器学习的高精度网络对时算法,大幅提升网络对时精度。(2)基于主流的同异步交流采样技术,提出了多点校验和加权仿真插值算法,发明了低频同步和高频异步的阈值切换采集方法,通过最小二乘曲线拟合技术,解决了变频交流采样不准确性的问题,提升电力实时信息采样准确性。(3)分析了CRC数据校验的漏检原理,提出了三维信息传输数据校验技术和多级信息传输校验技术,建立了信息传输试验模型,通过长时间大流量的信息传输模拟试验,证实了三维信息传输数据校验技术和多级信息传输校验技术在不影响信息传输效率的情况下,大幅降低信息错误漏检率。(4)基于机器学习的降噪自编码技术,消除错误与大误差,通过深度支持向量机技术,将状态估计算法降维,再将电网根据弱连接关系区域化,提出了基于CPU+GPU并行状态估计算法,大幅提升了状态估计精度和效率。针对电力实时信息存在的问题,在研究期间,得到了十七个国家和企业科技项目支持,分别是一个国家科技项目《高压电制热储热提升可再生能源消纳关键技术》,九个国家电网有限公司科技项目《面向全网统一分析的高性能网络分析关键计算服务研究》、《以数据为中心的调控云广域服务平台及典型应用服务研究》、《基于时空运行数据的大电网安全评估及决策技术研究》、《调控云平台支撑关键技术研究》、《电力系统宽频广域同步测量关键技术研究及应用》、《柔性负荷参与地区电网调度的关键技术研究与应用》、《基于历史数据的电网精细化建模和基础数据诊断技术研究》、《提升新能源消纳的多源协同控制与市场激励互动关键技术研究及示范》、《图计算技术在电网中的应用研究》,七个国网辽宁省电力有限公司科技项目《基于云计算多元电网动态参数的研发及应用》、《清洁能源全过程消纳的综合调度策略与示范》、《基于电网三态数据融合校验技术的深入研究》、《基于现货电力交易的新能源接纳关键技术研究》、《考虑源、荷波动特征的电网无功电压优化策略和评价指标研究》、《基于新能源接纳的电网调度支持技术研究应用》、《多源多荷多域协调调度运行技术与应用研究》。"
491,面向精准医学知识库的基因―变异―疾病关系抽取技术研究,"精准医学时代背景下,伴随生物医学领域数据爆发式增长与技术跨越式发展,单纯依赖人工编审的传统知识库构建策略已不合时宜且不切实际,从海量文献中抽取信息和挖掘知识成为近年研究重点与应用热点。经过学术和产业界的积极探索,命名实体识别、术语抽取、关系抽取、事件抽取和共指消解等文本挖掘技术已取得重要进展,然而当面向精准医学知识库构建中的“基因-变异-疾病”关系抽取特定研究任务时,现有的关系抽取方法、模型和算法仍存在诸多局限和不足,难以满足实际需求,主要表现在以下五个方面:(1)命名实体识别算法高度依赖特征工程,特征选择、特征表达和特征预处理过程耗时费力,重要词法特征与句法特征湮没于词性特征、依存特征和上下文特征集合中;(2)关系类型定义单纯考虑医学背景,基于关联强弱或概率高低的分类无法表达上下位关系,缺少顶层关系类型指导关系映射,缺乏底层关系触发指示词表辅助关系定位;(3)缺乏用于“基因-变异-疾病”关系抽取算法研究的标准语料库和易用的语料库构建工具,关系抽取语料库构建主要依靠专家人工编审,专家需要在理解语境内容的基础上,结合先验知识判断不同位置与不同表述实体组合的关系状态与关系类型,语料规模和质量受时效性与主观性制约;(4)关系抽取算法主要面向简单关系,二元、句内、二分类算法虽通过实体拓展、共指消解、层次分类过程可解决多元、跨句、多分类问题,但引入级联误差与额外噪声将影响表现性能与预测效率;(5)知识图谱构建与展示重点聚焦单一来源,知识表达丰富度与知识证据说服力难以保证,网络可视化展示与来源追溯功能不足,不能完全满足指导用户理解与辅助科研工作的需求。本论文的研究目标,是结合自然语言处理技术和生物医学文献及知识库资源,优化基因、变异和疾病命名实体识别算法,构建满足“基因-变异-疾病”文献挖掘任务需求的关系类型和关系抽取语料库,设计适用于“基因-变异-疾病”关系抽取的新算法,开发可集成不同来源知识的“基因-变异-疾病”知识图谱构建、编审、可视化检索利用和展示的平台。本文的主要研究结果如下:1.提出并实现了一种深度神经网络与传统识别方法相结合的疾病命名实体识别算法。该算法以双向长短期记忆模型为核心,串联自然语言预处理、字符/词汇空间向量表示、深度神经网络预测、维特比解码优化、字典匹配校正过程,综合解决命名实体识别算法高度依赖特征工程,难以提升构建效率的问题。经NCBI Disease公开语料库训练、验证及测试,查准率、查全率和F值分别达89.16%、90.00%和89.58%,高于已知模型评测结果。2.提出并实现了一种无监督聚类与本体指导相结合的“基因-变异-疾病”关系类型定义方法和处理流程。该方法以UMLS语义网络为指导,包括源数据筛选获取、自然语言预处理、生物医学领域命名实体识别、开放关系抽取、人工编审、聚类分析、顶层本体映射等步骤,充分发挥“开放关系类型”覆盖广泛、层次聚类语义高度归并、顶层本体严格限定领域优势,有效解决关系类型定义单纯考虑医学背景,难以实际用于文本语义抽取的问题。建立了5层16类语义关系类型与58项常用语义关系触发词表,覆盖度分别达94.12%与95.08%,能够表达主要“基因-变异-疾病”语义关系。3.提出并实现了一种远程监督与专家编审相结合的“基因-变异-疾病”关系抽取语料库构建方法,开发了关系抽取语料库加工编审软件平台,构建了关系抽取语料库。该方法利用ClinVar数据库作为远程监督知识来源,整合文献全文获取、自然语言预处理、生物医学领域命名实体识别、开放关系抽取、关系类型映射、专家编审过程,充分发挥远程监督权威知识指导优势,保证准入文献可靠性与编审知识可信度,有效解决关系抽取语料库构建主要依靠专家编审,规模和质量受限的问题。语料库涵盖全文文献527篇,实体表述3,366项,关系实例963项,知识库相符实例、相悖实例和不存在实例分别占比61.83%、4.84%和33.33%,关系实例平均标注一致度达85.14%,数据规模与质量水平初步满足语料库构建要求。4.提出并实现了一种领域先验信息与语言预训练模型相结合的“基因-变异-疾病”关系抽取算法。该算法基于谷歌BERT模型,整合领域词表拓展、无监督预训练、有监督微调整、依存句法分析、知识库远程指导等过程,充分发挥深度神经网络动态特征捕获与先验知识精准定位指示的优势,有效解决目前“基因-变异-疾病”关系抽取算法主要面向简单相关关系,难以抽取多实体、跨语句、多分类关系问题。经自建语料库测试,“无关系/相关关系/风险关系/因果关系”四分类查准率、查全率和F值分别达到71.46%、73.21%和72.32%,高于通用BERT模型与常用关系抽取模型的性能结果。5.提出并实现了一种实体链接与关系映射相结合的多来源知识集成构建“基因-变异-疾病”知识图谱的方法,开发了知识图谱构建与展示系统。该系统利用Gene、MedGen、ClinVar、PubMed Central作为知识库数据来源,具备数据获取、数据融合、数据存储、知识检索与知识可视化展示等功能,充分发挥知识、语料、文献数据深度融合与文本、表格、图形形式全面展现优势,有效解决知识图谱构建来源单一,知识表达与证据说服力不足的问题。系统目前覆盖基因名称1,463项、变异名称21,711项、疾病名称2,201项、关系知识590项、文献全文527篇。以基因筛查与鉴别诊断为模拟应用场景进行的测试表明,该系统具有指导科研活动与辅助临床决策的能力。"
492,智能手机Wi-Fi/PDR室内混合定位优化问题研究,"无线保真(Wireless Fidelity,Wi-Fi)定位、行人航位推算(Pedestrian Dead Reckoning,PDR)以及智能手机Wi-Fi/PDR混合定位是国内外研究热点,也是最普适、最值得大面积推广的室内技术,这些技术都存在一系列瓶颈,譬如,Wi-Fi指纹库快速构建、复杂活动快速准确识别、复杂活动下航位推算以及混合定位策略等。研究Wi-Fi/PDR室内混合定位优化问题,有助于提升室内定位系统可用性和稳定性,既能丰富和完善室内多源混合定位方法与理论,又能为室内多源混合定位提供技术支撑。本文以智能手机为研究载体,以机器学习方法和最优化理论为基础,通过理论研究、仿真计算和现场测试,系统研究距离相似度、指纹库快速构建、自适应指纹定位、复杂活动快速准确识别、顾及活动识别的改进行人航位推算以及Wi-Fi/PDR混合定位方法优化,主要贡献如下:(1)揭示了Wi-Fi信号缺失现象,针对此类现象以及参考指纹与测试指纹的遍历方式,提出了改进信号域距离相似度和归一化混合距离。通过实验发现,归一化混合距离能够提升聚类效果,改进信号域距离能够提高聚类识别准确率和定位精度,与采用-100dBm替代信号缺失值的信号域距离相比,无聚类时定位精度提高了22.6%~38%,有聚类时定位精度提高了2%~22.8%,在一定程度上说明了信号缺失现象对指纹定位的影响。(2)对比了动/静态指纹的优劣,提出了基于静态众包指纹和自适应路径损耗模型插值的指纹库构建方法。通过与完全人工指纹库、反距离权重(Inverse Distance Weighted,IDW)和克里金(Kriging)插值指纹库进行比较发现,本文所提方法构建的指纹库定位精度要优于IDW和Kriging插值方法,而且仅需少于15.4%的参考点数据即可实现与完全人工指纹库相同的定位精度,可节省约85%的时间和工作量。同时,本文提出的方法也可以用于指纹库的快速更新。(3)针对无线信号动态变化、Wi-Fi指纹信息尚未深入挖掘、固定K值易产生误差等问题,离线阶段基于归一化混合距离和仿射传播聚类算法进行聚类分析,并改进顾及过渡区域的聚类结果,提出了基于位置域距离和仿射传播聚类的AWKNN定位方法。采用改进指纹并集信号域距离开展AWKNN定位测试,平均定位误差约为2.4米,均方根误差约为1.9米,与基于遍历参考指纹求和信号域距离的WKNN方法相比,平均定位误差减小了1.4米,均方根误差减小了1.53米,定位精度提高了37%,稳定性有很大改善。同时,本文所提方法弱化了K值选择对定位精度的影响,避免了不同K值定位精度的重复评估,只需设定较大K值就可以实现较高精度定位。(4)针对现有活动识别研究实时性差、大量使用频域特征以及未考虑室内定位干扰活动等问题,在大量传感器数据分析的基础上,对室内行人常见复杂活动进行细化并定义,将竖直和水平晃动等运动模式引入室内活动识别,对静止和运动时的活动进行细分,以减少静止站立时摇摆、晃动等活动对室内定位的干扰;建立了顾及活动识别实时性的时间窗口选择依据,将航向角余弦差值引入活动识别,为了避免大量频率计算,提出了仅利用时域特征基于随机森林快速准确识别室内复杂活动的方法。通过比较分析朴素贝叶斯、决策树、支持向量机、随机森林和神经网络分类算法的分类结果发现,本文提出的时域特征在个性化和普适化活动识别上都具有很高的精度,其中,基于随机森林进行个性化活动识别和普适化活动识别的精度分别为99.78%和99.5%。实验结果表明,本文提出的时域特征可以用于准确识别室内复杂活动。(5)针对行人航位推算抗干扰能力弱、实时性差和航向估计不准等问题,着重分析了不同活动下传感器数据的波动变化情况,提出了不同活动下顾及时间同步的步态探测方法、基于随机森林回归的步长估计模型以及波形校准航向估计方法,形成了顾及活动识别的改进行人航位推算方法体系。在距离约为211米的走廊分别开展步行平端和步行口袋活动下行人航位推算实验,对这两种活动分别进行步态探测、步长估计和航向估计,两种活动下的计步准确率达99.6%,步长累计误差小于2.2米,航向估计误差小于6度,闭合误差小于2.4米,位置发散率低于1.2%,平均定位误差小于1.8米,均方根误差小于1.4米,方法具有较高精度。实验结果表明,本文提出的顾及活动识别的改进行人航位推算方法抗干扰能力强、航向估计准、定位精度高。(6)针对Wi-Fi指纹定位结果变化大、更新频率低、聚类识别易出错以及Wi-Fi/PDR混合定位结果产生回跳等问题,提出了基于位置约束、位移约束和方向约束的Wi-Fi/PDR混合定位优化方法。分别在步行平端和步行口袋活动下开展混合定位优化实验,两种活动下的定位结果与真实轨迹重合度较高,步行平端活动的平均定位误差小于1.6米,均方根误差约为1米,步行口袋活动的平均定位误差约为1.62米,均方根误差为约1.4米;与优化前步行平端活动下Wi-Fi/PDR混合定位方法相比,优化后混合定位结果的平均定位误差减小了0.91米,定位精度提高了36.5%,均方根误差减小了至少1.9米。实验结果表明,所提方法能够大幅度提高混合定位精度,解决Wi-Fi指纹定位结果变化大、更新频率低和聚类识别易出错等问题,避免混合定位结果回跳现象出现,优化混合定位系统性能。"
493,基于双目视觉的三维重建关键技术研究,"随着我国国民经济迅速发展,人们生活质量的提高,国家对智能制造,智能城市,智能园区等一系列智能技术越来越重视,体现人工智能的双目立体视觉越显重要,它在智能生产,交通监控,机器导航,航空航天,医学建模,视觉仿真,文物复原,非接触高精度测量等方面,提供包括虚拟视觉仿真,视觉识别与定位等技术,能够有效地提高生产效率和产品质量,降低运营成本和资源能源消耗。基于双目视觉的三维重建,是图形图像处理与机器视觉的重要组成部分。因为单目相机拍摄的单幅图像是二维的,没有第三维信息,所以采用双目摄像机仿真人类视觉系统,拍摄两张二维图像,并根据这两张图像匹配点对的视差,利用相似三角形原理计算出目标物体表面点到两镜头光心连线的距离,以及物体表面点云三维坐标。三维重建,是根据物体表面全部或部分点云的三维坐标,对目标物体全部或者部分表面进行重建。三维重建可以恢复场景的3D信息,协助机器人完成目标的识别、定位、测量、导航、抓取与跟踪等特定任务。基于双目视觉的三维重建,模仿人类的两只眼睛同时观察场景的方法,更加经济实用。本课题目的是通过双目视觉图像匹配,计算视差,根据视差计算物体表面点云并建立目标物体的三维模型,辅助机器人进行工件等物体的识别、定位与抓取。意义在于能够加快生产的速度,提高产品的质量,使工业制造智能化。本课题依托国家项目:国家重点研发计划“基于工业物联网的智能产线实时故障诊断关键技术研究及应用”(YS2017YFGH001945)。论文的主要贡献是提出以下几个方法:1.圆周二进制特征提取算法现有梯度特征与二进制特征提取方法,存在计算量大和入围率低的问题,针对这些问题,提出一种图像关键点局部区域的圆周二进制特征提取的方法。提取特征时,使用高斯金字塔仿真人眼小孔成像模型:近处目标成像大,远处目标成像小,近目标成像清晰,远处目标成像模糊,确保特征的光照、尺度、模糊不变性;使用FAST算子检测关键点;使用图像特征点邻域灰度重心法,计算关键点特征方向,确保特征的旋转不变性;提出镜像不变性规律和圆周二进制特征提取算法,提升二进制特征的镜像不变性。提取的圆周二进制特征适应性强,对比速率快。2.位图局部敏感哈希的匹配二进制特征搜索算法针对现有的匹配二进制特征搜索算法存在效率低和入围点少的问题,提出快速计算位图算法以及位图局部敏感哈希算法,搜索图像的匹配二进制特征。首先,计算左图特征位向量的关键字;然后,使用快速计算位图算法计算位向量的位图,将位图按照掩码提取出关键字,并与二进制特征的标识作为映射构建局部敏感哈希表,同时将关键字存入位集;最后,根据右图提取的二进制特征对应关键字,使用位图快速判断特征ID是否存在于哈希表中,以优化查询哈希表中的匹配二进制特征,提高匹配二进制特征的搜索效率和质量。实验证明,位图局部敏感哈希算法提高了二进制特征近邻搜索的效率、增加了入围点数。3.圆周二进制特征提取与匹配搜索方法二进制特征在图像匹配识别与定位中,具有计算简单快速、匹配效率高和存储简单的优点。现有二进制特征提取算法镜像不变性较差,匹配二进制特征搜索算法入围率低,针对这两个问题,结合圆周二进制特征提取算法和位图局部敏感哈希算法,提出圆周二进制特征提取与匹配搜索方法。4.内外相似度聚集的立体匹配算法针对现有立体匹配方法提取视差图像的非闭塞区域错误率高和效率低的问题,提出内外相似度聚集的立体匹配算法:首先,给出参考彩色图像近邻像素的内部相似度;然后,在图像彩色与亚像素空间,给出左图像与右图像之间候选匹配像素的外部相似度;接着,提出内外相似度聚集方法,聚集左右图像匹配点的相似度,使用赢者通吃算法计算视差图;最后,提出盒图滤波算法,提纯和平滑视差图像,并给出八方向内外相似度聚集的立体匹配算法,实验结果证明,内外相似度聚集的立体匹配算法提取视差图的非闭塞区域错误率低,效率高。5.基于视差图像的物体表面的三维重建方法根据双目相机获取的两幅图,提取视差图像,提出基于视差直方图的图像分割算法,在视差图像中分割出目标区域,将目标区域图像分成5*5的方块,将每个方块按其角点划分成两个三角形。根据相似三角形,计算目标物体或者情景的图像的每块的角点的三维坐标,得到目标物体或者情景表面的点云,将目标区域每块的角点对应的三维点,按照顺序连线构成三维的三角形,这样目标区域就被分割成了三角形网格,对目标物体进行建模。该方法对目标物体三维重建的精度高,计算量小。6.估计目标物体姿态的方法建立目标物体表面的三维模型后,分割出视差图的参考图像的目标区域,以参考图像目标区域作为匹配模板,提供目标自身相对形状;在模板图像上检测关键点并提取特征,且在待姿态估计的图像提取点特征,使用匹配特征搜索算法,查询两张图像的匹配特征,根据特征标签找到特征点坐标;根据模板图像匹配点像素坐标及模板视差图像,获取目标区域点的三维坐标,这样得到了3D到2D坐标的映射,使用PNP算法,对目标物体进行姿态估计。"
494,地质大数据功能分析及其分类算法研究,"在数字地质科学研究中,地质大数据已经成为地学空间分析不可或缺的基础素材。地质大数据分析的科学本质是在数据海洋中提取对地学目标有重大贡献或重要作用的地质变量。因此,对地质变量的内涵与外延做精准分析构成了地质变量自身研究的主要内容,也是确保地学空间信息模型可靠性与精准性的关键所在。按照这一要求,本文将地质大数据及地质变量功能分析作为主体研究内容,通过对地质变量功能分类、作用性质以及作用方向的讨论,在算法研究上提出地质变量建模分析的适用条件、建模标准及目标要求,并在理论上阐明地质大数据的精准分类与空间建模依据,为地质大数据空间建模质量提供基础保证。为分析地质变量在地质建模中所发挥的全部效能,将模型中变量作用能力的总体性评价称为地质变量的功能,所谓功能即地质变量所承载的作用性质及作用方向、变量的连接力在整个空间分析中所呈现的一种度量。本文将地质变量的功能划分为信息转换、程度度量、判别分类、组合关联、结构优化五项功能,并逐一讨论。在地质变量功能讨论的基础上,针对变量的模型应用,将机器学习和深度学习应用于地球化学观测数据的分类研究中,并给出了计算流程与精度分析,最终达到地质变量功能分类的效果,从而提高地质大数据的精准性。事实上,地质变量的每项功能研究均可进行细分研究,前人已经积累了大量的研究成果。鉴于分类是科学研究的首选性课题,本文将地质变量分类判别功能作为重点问题进行讨论,将地质大数据功能分析模型及分类算法作为主要研究内容,以云南哀牢山矿集区地球化学元素观测数据为研究对象,分别运用支持向量机、k最近邻、随机森林、梯度提升、朴素贝叶斯和集成学习分类器等方法,通过模拟实验对比的方式,选择出相对最优的学习类型及其对应的分类效果。论文的主要研究成果如下:1.讨论了地质大数据及地质变量功能的内涵与外延,阐述地质大数据与地质变量的逻辑关系,给出了从地质大数据集合中提取地质变量的普适性原则、构置条件、地质变量赋值的一般性方法。2.详细论述了地质变量的五项功能,并针对每项功能分别建立数学模型,从定量分析的角度确立各项功能模型的定义范围及应用前提。3.在应用案例分析中,针对云南哀牢山地区的地球化学观测数据进行分类研究,采用两种无监督学习方法进行层次聚类和k均值聚类,从中得出离差平方和法与k均值聚类法计算结果具有相对一致性,均出现三类划分结果,表明云南哀牢山地区地球化学元素数据划分为三个类别是合理的。4.基于层次聚类与k均值聚类法得出的分类标准,继续建立“高精度”的分类模型,分别采用不同核函数的支持向量机、k最近邻、随机森林、梯度提升、朴素贝叶斯和集成学习等方法,进行重复模拟实验分析。结果显示随机森林分类法精度最高,达到99.83%;而朴素贝叶斯分类效果相对较差,达到97.74%。这说明在地球化学类数据分类中,随机森林的分类效果要优于其他方法。尝试进一步提高数据量的分类精度,论文提出将多“分类器”进行融合的集成学习分类法。在实验分析中具体构建了三个集成学习模型,包括基于随机森林、支持向量机和神经网络三个基本分类器的融合模型,结果显示分类精度最高达到99.83%。5.运用深度神经网络、Elman神经网络及Jordan神经网络进行数据分类。其中深度神经网络法,获得4个隐藏层数的分类结果,精度达到最高的99.65%。Elman神经网络法获得4个隐藏层数,分类精度为99.3%。Jordan神经网络法获得6个隐藏层数,分类精度为99.48%。证明深度神经网络的分类效果要优于Elman和Jordan神经网络分类效果。"
495,基于机器学习的加纳摩托车碰撞事故严重性分析,"在加纳,摩托车注册数量差不多占机动车注册数量的四分之一。在加纳北部农村地区,骑摩托车已成为一种常见又便宜的出行方式。近年来,作为拥堵道路下经济可行的交通模式,摩托车在加纳的城市中也越来越流行。摩托车碰撞事故通常发生在共用道路上,而与其相关的伤害与死亡是道路交通安全的重要问题,在近些年显得尤为突出。目前,摩托车碰撞事故在加纳的行人死亡原因中排名第二位。因此,有必要对导致摩托车碰撞事故的因素进行研究。摩托车碰撞事故分析在全球范围内是一个重要的研究领域。而在加纳,还没有关于摩托车碰撞事故严重性及其影响因素的研究。目前,关于预测摩托车碰撞事故严重性的经典统计模型,相关文献较多。传统的统计模型有基本的假设和预定义关系,但如果它们不满足条件,将产生不准确的结果。鉴于统计模型的缺点,本文采用基于机器学习的算法来预测摩托车碰撞事故严重性。机器学习技术采用非参数模型,其没有预测变量和响应变量之间的关系推定。本文对不同的机器学习算法进行比较和评价。本文研究的事故数据来自加纳建筑与道路研究院(BRRI)的国家道路交通碰撞数据库中2011至2015年间的摩托车碰撞数据。该数据被划分为4种损伤严重性类型:致命,住院就医,受伤和车辆受损。选择机器学习的分类算法是因为目标变量(摩托车碰撞事故严重性)有4种可能的结果(致命,住院就医,受伤和车辆受损)。考虑准确度因素,选择5种分类算法:多层感知机(MLP),规则归纳(PART),分类与回归树(CART),J48决策树分类器,以及基于实例的学习(IBk),在WEKA(Waikato Environment for Knowledge Analysis)机器学习软件中建立摩托车碰撞事故损伤严重性模型。这些机器学习算法通过十层交叉验证技术进行验证。此外,分别研究了4种集成学习策略(AdaBoosting算法,Bagging算法,随机森林算法和多数投票算法),以改善普通单个分类器的分类准确度。同时,进行了属性的相对重要性分析以确定这些属性对损伤严重性结果的影响。研究结果表明:MLP分类算法对预测摩托车碰撞事故严重性的准确度为80.84%,对4种损伤严重性类型的分类精度分别为0.867、0.802、0.791和0.736;PART算法对预测摩托车碰撞事故严重性的准确度为82.1%,对4种损伤严重性类型的分类精度分别为0.905、0.794、0.818和0.846;CART算法对预测摩托车碰撞事故严重性的准确度为82.34%,对4种损伤严重性类型的分类精度分别为0.901、0.8、0.816和0.858;J48算法对预测摩托车碰撞事故严重性的准确度为81.55%,对4种损伤严重性类型的分类精度分别为0.905、0.787、0.81和0.888;IBk算法对预测摩托车碰撞事故严重性的准确度为82.41%,对4种损伤严重性类型的分类精度分别为0.902、0.799、0.819和0.856。在5种分类算法中,IBk算法因具有全局优化和外推能力,与试验数据有最好的吻合度。此外,针对集成学习策略,研究结果表明:AdaBoosting算法改善了MLP、PART、J48和IBk算法的性能度量;Bagging算法改善了MLP、PART、J48和IBk算法的性能度量;而AdaBoosting和Bagging算法均未改善CART算法的性能度量;随机森林算法和多数投票算法的性能优于单个分类器。在4种集成学习策略中,随机森林算法在改善单个分类器性能方面优于其他技术。高峰时间、碰撞位置类型、醉酒驾驶、年龄、性别、碰撞时间和生活区类型是加纳摩托车碰撞事故损伤严重性的重要决定因素。"
496,基于深度学习的自动驾驶单目视觉目标识别技术研究,"随着汽车保有量的迅猛增加,人民群众的日常生活便利性得到了提升。然而交通拥堵、环境污染和交通事故也越来越得到人们的广泛关注。近些年电子信息和计算机技术得到了快速发展。伴随着人工智能技术在车辆上的应用,自动驾驶车辆将成为减少交通事故的有效途径之一。自动驾驶车辆关键技术包括环境感知、精确定位、路径规划和线控执行四类,其中环境感知技术为其它关键技术提供数据支撑。环境感知技术主要负责完成车辆周围环境信息采集和目标识别工作。单目相机由于具备结构简单和计算量小等优点而被广泛使用。由于传统单目视觉环境感知算法主要依靠先验知识来设计模型,因此这类算法的泛化能力不强。而基于深度学习的单目视觉环境感知算法生成的模型却可以适用于多类目标,泛化能力得到显著提升。所以本文着重研究基于深度学习的自动驾驶单目视觉目标识别技术。近年来,极速区域卷积神经网络(Faster Region-based Convolutional Network,Faster R-CNN)在解决目标识别问题方面取得了优异的实验结果。该算法提出了区域候选框网络(Region Proposal Network,RPN),RPN能够通过不同缩放面积和宽高比的锚框来有效地生成区域候选框。本文基于Faster R-CNN算法提出了3种单目视觉目标识别算法,主要工作和创新点如下:(1)本文提出了一个基于多策略区域候选框网络(Multi-strategy Region Proposal Network,MSRPN)的目标识别算法。MSRPN包括4个改进点:首先为了加强卷积网络的特征采样和池化能力,设计了跨层连接网络特征提取方法。其次引入具备自适应宽高比和均匀分布缩放面积特性的锚框,通过使用该锚框来减少区域候选框数量并提高算法目标定位能力。特别是通过应用改进锚框提升了小目标识别能力。随后将框分类层和框回归层合并为一个卷积层来减少输出层模型参数,因而提升了RPN训练和测试速度。最后为了改善框回归性能,对RPN中多任务损失函数的框回归部分进行了优化。(2)以MSRPN部分设计理念为基础,本文提出了一种基于增强型区域候选框网络(Enhanced Region Proposal Network,ERPN)的目标识别算法。ERPN改进内容包括:首先通过反卷积特征金字塔网络将卷积网络上下文信息引入卷机网络顶层输出特征中,从而提高了输出区域候选框质量。其次设计了具有间隔缩放面积和自适应宽高比的改进锚框,提高了区域候选框的目标定位能力。再次使用支持向量机(Support Vector Machine,SVM)分类器对正区域候选框和负区域候选框进行分类来提升分类精度。同时使用粒子群优化算法(Particle Swarm Optimization,PSO)对SVM参数进行优化,简称为PSO-SVM分类器。ERPN基于该分类器的分类能力得到显著提高。最后通过对RPN中多任务损失函数的分类部分进行改进,提高了分类损失函数的性能。(3)RPN中的部分参数数值是通过先验知识进行选取,因此在RPN的训练模型中很可能出现欠拟合问题,换句话说RPN的泛化能力不足。在RPN中增加参数是解决该问题的有效方法。为此设计了一个强化区域候选框网络(Strengthened Region Proposal Network,SRPN)来扩展RPN的探索空间,然而获取SRPN的最优参数值不是一个确定多项式时间内可解决的问题。为了解决该问题,本文引入基于PSO和细菌觅食优化算法(Bacterial Foraging Optimization,BFO)的学习策略来完成对SRPN参数的优化工作。为验证本文提出目标识别算法的有效性,分别使用通用目标识别数据集和自动驾驶目标识别数据集对这些算法进行训练和测试。本文提出的算法在目标识别速度和准确率方面均取得了较好的结果。说明这些算法既适用于通用物体识别,也适用于自动驾驶领域。因此本文提出的基于深度学习的自动驾驶单目视觉目标识别技术具有一定的理论意义和应用价值。"
497,基于SVM学习模型的换挡决策研究,"换挡决策问题是车辆自动变速理论的核心问题,是保证换挡控制品质提升的基础,其解决的是在复杂的行驶工况条件下选择合理的换挡时机或换挡点的问题,何时换挡是换挡控制的先决条件,直接影响车辆行驶的动力、经济和驾驶性。两参数到三参数的理论设计方法证明,引入更多有效控制参数会有效提升换挡规律对典型工况的适应性,但是按照换挡规律MAP的设计方法,设计人员除了要标定数据以外还要进行大量的策略制定工作来解决实用过程中以适应性为代表的种种问题,设计工作量和人为设计因素都很大;而且这种标定修正一般都是将驾驶员风格和意图与环境因素分开考虑,通过逐个的辨识进行叠加修正,但是驾驶员在驾驶车辆行驶时的风格和意图实际上是根据环境做出的,比如坡道的修正叠加就会造成动力需求的叠加增大;同时随着人工智能技术的全面发展,人们对于智能化的需求不断提高,挡位决策的方法也要不断的进行智能化的发展以适应时代和市场的需要。利用人工智能技术解决上述问题是一种有效的途径和尝试。支持向量机(Support Vector Machines,SVM)是一种自动进行模拟和实现的数据挖掘技术,本质是通过有限的实例(数据)来学习整个系统的知识,摆脱了传统统计优化方法对于数据量的假设。SVM能够在多维控制参数的空间中按照严格的数学原理自动优化出分类超平面,提升换挡决策适应性的同时还能够大大降低设计人员的工作量和设计人为因素;机器学习算法的黑盒特性能够将驾驶风格和意图变成行驶参数的映射知识进行学习,不需要再将其分离,而是作为对其他控制参数的应对知识进行学习,更加符合驾驶员操作驾驶的自然行为;同时依靠其增量学习技术解决了一次性样本训练的要求,还提供了在线持续学习的能力,为个人化的学习提供了接口,奠定智能化基础。本文结合国家自然基金基于动力需求的自动变速器档位实时优化与在线决策技术(51575220),围绕SVM学习换挡决策问题进行了如下研究:1)换挡理论基础研究,分析了换挡决策问题的理论基础和基础方法,以及适应性能,传统换挡决策方法在解析多参数时过于复杂难以实用,因而适应性不佳,利用大量的修正和策略制定来改善适应性造成设计人员工作量大的负担,且无持续学习能力;而SVM具有严格的理论基础,在处理多维度问题时性能优越且泛化能力强,不会像神经网络一样陷入局部最优解并且能摆脱设计人员的先验限制。同时建立了自动变速器车辆的动力传动系统仿真模型,为后续换挡决策模型的挡位试验提供支持,经过目标车辆的路试试验数据验证了所建模型。2)换挡决策SVM模型的构建。选择了SVM模型结构,分析了影响SVM模型性能的因素,包括核函数、特征参数和模型参数的选择。基于核方法变换理论,分析并选择了适合换挡决策问题的核函数;根据换挡决策问题的物理意义确定了特征选择的候选目标;为了避免特征选择和模型参数优化过程中互相依赖而造成的学习机性能难以把握的弊端,利用一种改进的遗传算法来对特征选择和模型参数进行联合优化,通过对遗传算子的改进,提高了算法的优化效率和全局收敛能力,给出适合换挡决策标定数据的模型参数,同时确定了换挡决策问题的特征参数。3)多分类换挡决策SVM决策树结构的构造。由于换挡决策问题是一个多分类问题,因此SVM多分类结构是影响模型性能的关键,通过对现有多分类方法的分析,基于提高模型性能和分类器数量的前提选择二叉树结构作为挡位决策SVM模型的多分类结构,将每一组SVM分类器数量降低到n-1个,同时为了解决二叉树结构的误差累积问题,提出了一种改进的粒子群优化算法来对二叉树结构进行优化,从根节点开始选择最优的分类次序,提高了整个模型对于换挡决策准确性的稳定性。4)一般环境特征和工况识别。换挡决策问题在车辆行驶过程中面临很多环境特征的影响和工况影响,通过负荷度计算将一般环境特征数值化,作为特征参数加入到SVM模型的输入特征参数列表中,以提高模型的适应性。能够映射高维度空间特征是机器学习算法取得成功的重要因素,但是对于换挡决策这样的实际问题,在不同的工况下,在环境特征加入特征的情况下工况条件影响更多的是驾驶员本身,因此存在大量的数据交叉样本,需要训练各自的SVM模型来适应这种分布改变。利用ART2学习神经网络对四种典型的工况进行识别作为分类器的标号,使整个模型更进一步适应工况条件。5)换挡决策增量学习方法。为了改善机器学习机需要一次训练整个数据集的弊端,顺应分阶段的挡位决策标定的工作特点,同时使得模型具备超越生产阶段的在线学习能力,引入增量学习SVM求解算法。首先提出基于换挡决策问题的物理意义,提出一种确定增量候选集的策略,提高了模型性能;利用LSVM将求解问题优化,通过利用继承迭代结果的算法大幅提高SVM增量算法的运算速度,并保持性能不变;同时为了避免增量训练集爆炸问题,本文结合壳向量的概念提出一种样本淘汰算法,通过壳向量计算和计数淘汰策略提高了减量学习的性能。6)实车试验验证。首先通过整车模型验证了换挡决策SVM模型挡位决策的合理性;搭建实车据采集平台和试验平台,利用自主开发的软、硬件自动变速器系统,对SVM挡位决策方法进行了试验验证,多种试验工况表面基于SVM的换挡决策具有很好的人车路行驶适应性。增量学习能够对驾驶员风格的改变作出相应的调整。"
498,异构健康大数据诊疗模型的特征优化算法研究与开发,"健康大数据时代的来临,极大的推动了医疗诊断模型的建立,实现了更快更好更准确的精准医疗,但同时给机器学习和数据挖掘研究人员带来了运算时间和学习效率的新挑战。医学领域生物标志物检测问题等同于机器学习领域中的特征选择问题。健康大数据挖掘是大数据挖掘技术的重要研究方向,是计算机领域和医学领域的研究热点。生物医学数据固有“大p小n”、特征高度相关以及医学研究员对于数据挖掘结果的可理解性要求的特点,使得传统的数据挖掘算法难以直接应用于生物健康大数据挖掘任务。所谓“大p小n”就是“高维度小样本”指现有数据集的特征很多而样本非常少,针对这种情况,通常采用特征选择来减少大量与表型无关的生物医学特征,从而减少模型运行的时间,降低模型的时间和空间复杂度,实现稳定的与特定数据集无关的分类或回归模型,提高模型的泛化能力。本文针对上述问题开展了多层次整合建模算法及异构健康大数据的特征融合研究。由于生物组学、影像组学和电子病历数据描述了生物系统的不同时间和空间尺度的状态,具有显著的异构和多模态特点,是医学建模的主要生物医学信息来源。因此,针对三种类别健康大数据开展了特征提取、特征选择、数据融合算法研究,建立了分类和回归模型,开发了大数据可视化系统。主要研究内容如下:针对生物组学数据分类问题,提出了层次化分类建模思想,研究了乳腺癌和自闭症这两种疾病的生物标志物检测问题。针对乳腺癌的研究,将乳腺癌的转录组组学和甲基化组学数据集分成多个年龄组,通过为不同年龄组的患者应用个体模型,改善了疾病诊断模型的准确率,证明了年龄对于乳腺癌分期建模的重要性;针对自闭症的研究,利用外周血样本的甲基化数据,采用基于降序特征筛选策略,发现了678个与自闭症检测相关的最佳甲基组学的生物标志物。针对生物组学数据回归问题,提出了一种新型特征选择算法,可以直接优化回归模型性能,用回归的方法找到了与癌症分期阶段相关的生物标志物,实现了癌症分期标志物的准确预测,弥补了现阶段许多连续价值表型如癌症发展阶段的连续关系被忽略的问题。通过对比拟合优度、分类准确率等评价指标,提出的回归生物标志物检测算法优于现有的10种生物标志物检测算法。针对医学影像数据,提出了具有旋转不变性的Triz算法和识别疲劳状态的REDE算法。Triz算法实现了计算机辅助诊断的胃部疾病识别,能够有效地识别胃息肉、胃癌、胃溃疡和正常无病的四分类问题。REDE算法整合了人脸区域的眼睛和嘴巴形态特征,从特征数、分类器和建模参数等方面对疲劳检测问题进行了研究与探讨,实验结果表明,REDE算法在疲劳检测准确度和运行时间方面优于近期公开的4项疲劳检测算法。此外,开发了一种基于Python的健康相关图像可视化工程系统――pyHIVE。在Outex纹理数据库和萨尔瓦多胃肠视频内窥镜数据库中验证了pyHIVE的有效性和泛化性。针对临床电子病历数据,提出了用化疗的肿块面积多分类整合建模思想,采用个性化回归模型对临床前三次肿块面积数据进行处理,实现了后三次肿块面积数据的预测。利用后三次预测肿块面积对临床乳腺癌新辅助化疗病理完全缓解(pCR)分类模型进行了细化,实现了较高的pCR预测准确率。最后,开发了健康大数据可视化系统―kSolutionVis,并探索了多组学数据融合建模方法。大数据的可视化的结果可以帮助医学研究人员理解数据挖掘的结果并且发现新规律、新算法。kSolutionVis提供了用户友好的图形化界面,可以协助生物医学研究检测多个特征子集,为生物医学研究人员探索生物标志物检测的多种解决方案铺平了道路。在研究生物组学数据的特征选择算法建模后,探索了融合多组学数据融合建模分析,证明了对于乳腺癌分期的多分类问题,多组学融合分类效果优于单个组学分类效果。"
499,机器学习在计算机视觉和癌症生物信息学中的若干关键问题研究,"本文着重于研究将机器学习相关算法,技巧,以及框架解决计算机视觉和癌症生物信息学中的若干关键问题。在计算机视觉领域,本文重点研究了人脸识别、自然环境图像分类、静态图像行为识别问题。在癌症生物信息学中,重点研究了乳腺癌亚型分类、癌症分期分类问题。计算机视觉属于计算机应用技术二级学科,癌症生物信息学属于生物信息学二级学科。因此在研究内容上会有一定的跨度,本文采用的机器学习方法在这两个研究领域的侧重点会有所不同,但是两者在分类器学习上具有共性。在人脸识别中的非监督线性子空间学习算法研究中。提出基于改进的EMD度量的LPP算法和基于改进的EMD度量的BSLPP算法。这两个方法解决了人脸图像的不相似度度量问题和人脸图像空间结构保持问题。第二个算法相比于第一个算法,更加注重了人脸图像的空间结构信息,先在人脸的blocks上构建子近邻图,然后合并为最后的近邻图;在采用两层视觉词典学习的自然环境图像分类算法研究中。提出了一个数据驱动的两层视觉词典学习框架。将视觉词典划分为属性层和细节层,使得采用本文构建的视觉词典既具有一般性又具有判别性;基于深度学习模型在静态图像行为识别中的算法研究中,提出了一个非顺序卷积神经网络(CNN)模型,该NCNN模型具有更少的可训练参数、端到端结构、非顺序的拓扑结构。因此,可以在小样本数据集上训练出具有较高泛化能力的深度CNN模型,并且有效地避免了过拟合问题的影响。基于机器学习方法在乳腺癌亚型分类中的问题研究中。本文提出基于高权重DEGs的乳腺癌亚型二分类器构造方法,通过该二分类器验证了高权重DEGs的有效性。本文提出了一种新的通路富集分析方法PEGCN,在基因共表达对是否被激活或抑制的层面上进行通路富集分析。基于机器学习方法在癌症分期分类中的问题研究中,提出了显著性差异共表达网络(SDCN)和带有稀疏性的显著性差异共表达网络(SDCNS)。通过SDCN揭示对照组和实验组上具有的显著差异的交互网络结构,通过SDCNS模型用来提取稀疏的特征增强癌症分期分类模型的有效性。最后,提出PEUCGP富集分析方法,分别在广义上调和下调的共表达角度开展通路富集分析。"
500,基于网络流量的Android恶意应用检测方法及其系统,"随着移动互联网的快速发展,越来越多的人使用智能手机通信和办公。尽管现在的移动操作系统已经尽最大可能为用户提供安全的上网环境,但由于Android的开源特性,它仍然无法完全阻止Android恶意软件的大规模感染和爆发。基于代码段的静态检测和基于行为的动态检测虽然可以一定程度上识别恶意软件,但仍存在许多问题,例如检测未知恶意变种效率低和部署困难等。调查研究发现,目前市场上对恶意应用的审查机制主要有两种,第一种为服务端和云平台的恶意应用检测,第二种为移动智能终端的恶意应用检测。事实证明,虽然通过严密的机器和人工审查,仍然有大量的用户被恶意变种应用所感染。而大多数的恶意应用都是以经济利益为目的,在恶意行为执行过程中,恶意应用往往会表现出明显的网络交互特征。因此,这就为高效、轻量级的恶意应用检测平台的探索提供了可能。本文对Android恶意应用检测领域的问题,做了如下的研究工作:(1)研究了Android平台网络流量采集方法。利用Android SDK开发工具包提供的VPNService类,完成了在手机本地自建的VPN通道内捕获移动终端应用程序的网络流量,为模型的构建提供了基础流量数据支持。(2)实现了基于网络连接信息的流量与APP的映射。通过对Android系统文件/proc/net/tcp|tcp6和网络流量数据端口的分析,利用Android UID来区分网络流量数据包应用来源,有效的过滤掉移动终端的背景流量,保证了数据预处理工作的进一步开展。(3)构建了Android恶意应用检测模型。在完成数据预处理的基础之上,对每一条流进行特征选择和包序列规整,使用TCP流前8个包长度和4个统计特征并结合SVM算法实现了94.65%的恶意应用检测准确率,最终将离线恶意应用检测模型部署在本文系统的服务端,用于监测终端的Android应用程序。(4)设计并实现了一套基于网络流量的Android恶意应用检测系统。该系统基于网络流量的分析方法,在真实网络环境下,通过采集Android终端应用程序的网络流量,提取有效网络流量的统计特征,利用部署在服务端的离线恶意应用检测模型达到Android恶意应用检测的目的。这种方法既弥补了静态检测发现新变种能力弱,又解决了动态检测资源耗费大、部署困难等问题。"
501,基于机器学习的内部延迟估计网络层析成像,"随着互联网渗透到人们生活的方方面面(物联网),计算机网络变得日渐庞大、复杂。在这种情况下,用不影响监测网络性能的方式获得指标和度量值,并进行及时有效的网络监测和分析就变得至关重要。然而,测量网络中所有节点的网络流量是不切实际的,一种有前景的替代方案是仅在网络边缘进行测量,并从这些测量值中推断网络的内部行为。为了解决内部链路参数测量(例如时延和丢包率)的问题,本文采用网络层析(NT)技术,收集基于端到端测量的路径性能数据,然后使用统计计算的方法推断逻辑链路性能的概率分布。这种从端到端估计链路性能的技术既不需要内部网络的协作,也不依赖通信协议。此外,本文在网络层析成像技术上融合了一种新的统计方法,使得建模网络更容易估计内部链路性能参数的性能。这种方法就是机器学习(ML),尤其是线性回归模型。该技术能够在给定输入值(例如路径时延)后预测真实值(例如链路时延),比如说让模型从给定的样本数据(学习数据大约占总数据的80%)中学习,然后使用20%的数据(测试数据)验证模型。将估计得到的时延值与使用网络模拟器NS2对一个有线网络仿真生成的实际时延值进行比较,以两者的计算误差值(均方误差MSE)评估模型的性能。"
502,基于深度神经网络的高校贫困生精准识别研究,"国家精准扶贫政策的提出,对高校学生资助提出了新要求,精准资助也逐渐成为教育扶贫的核心任务,借助于人工智能实现高校精准资助是一个很好的思路。应用人工智能需要以海量数据为基础,现阶段,智慧校园的不断建设和发展为其提供了条件。作为智慧校园的一部分,校园一卡通产生了大量的数据,记录着学生在校的消费、学习和生活情况,以及学生在上网和使用各管理系统过程中产生的数据,对更有效的识别贫困生具有很大的研究价值。本文分析了传统贫困生认定分类工作中存在的问题,并结合目前现有的高校精准资助研究成果,以深度学习方法为技术依托,构建高校贫困生精准认定识别新模型。作者在模型研究过程中,以某高校学生信息为基础,对其进行分析处理,然后构建样本库,并利用深度学习方法,最终设计和实现了学生资助评定模型的构建,与传统算法相比,准确性和速度都得到大幅度提升。本文的研究的目的一方面是可以精准的认定识别贫困生,并实现精准的贫困分级,给予相对应的资助,最终达到隐式的精准的学生贫困资助;另一方面是利用人工智能等先进技术代替传统的手工数据分析方法,简化贫困资助工作程序,提高资助的工作效率和准确率,为实现学生的精准资助提供保障。"
503,偏移类中心的自调整模糊支持向量机算法研究,"支持向量机(Support Vector Machine,SVM)作为一种优良的机器学习算法,已被人们大量应用于工业生产、生活应用当中。但是,SVM存在着不能处理带有模糊信息、以及对噪声敏感的特性,因此学者们期望通过引入模糊支持向量机(Fuzzy Support Vector Machine,FSVM)来解决以上问题。FSVM对SVM的改进是通过对样本数据集特性的分析得到隶属度函数(Membership Function,MBSF),通过MBSF为每个样本赋予隶属度(Membership,MBS)。因此FSVM算法的核心在于如何构造良好的MBSF。根据MBSF构造的不同学者们提出大体可分为两类FSVM模型:基于样本和和类中心距离(Distance between Sample and Class Center,DSC)设计 MBSF 的 FSVM 和基于样本和类中心超平面距离(Distance Between Sample and Class Center Hyperplane,DSCH)设计 MBSF的FSVM。基于DSC设计MlBS的FSVM作为最先提出的算法以其简单易于操作的特点而被大量应用,但是这样设计MBSF难免会导致支持向量的MBS大小不一从而影响分类精度。基于DSCH设计MBS的FSVM算法虽然能有一定程度上解决以上问题,但是,基于DSCH的算法由于需要计算得到DSCH因而其时间复杂度相对较高而且这样强制的使用DSCH来反映MBS算法普适性较差。在分析学者们提出的一些基于两类传统FSVM模型的改进算法后,本文通过对潜在支持向量样本(Potential Support Vector Samples,PSVS)进行分析后引入调整因子,使得类中心沿着靠近分类超平面方向调整。这样在使用调整后的类中心的基础上使用传统的两类FSVM模型得到本文的两类自调整FSVM算法。这样得到的改进算法可以综合两类传统模型的优点,而且不会带来较大的时间开销。同时本文同时对传统的FSVM实验部分进行了改进:本文通过综合核参数和惩罚系数两个变量,以主要变量核参数作为自变量,以对次要变量惩罚系数得到的分类准确率的平均值作为因变量,通过二维曲线的变化来比较算法间的差异,这样,得到的实验结果更令人信服。在实验部分,本文通过对两类改进模型进行实验分析得到其对应的最佳偏移比例系数,在此基础上对本文提出的两类改进FSVM算法和SVM以及其他FSVM算法在分类精度和分类时间上对比。实验表明本文提出的两类自调整模糊支持向量在保证时间复杂度适当的条件下算法稳定性和分类精度上均得到了一定的优化。同时对实验结果进行分析后得到对两类改进模型的各自使用场景。图27表5参58"
504,基于机器学习的内容处理与监控系统的设计与实现,"现如今,随着移动产品的发展与普及,人们对内容资讯类产品的需求迫切度与日俱增,与之相对的便是内容量的巨大提升,给编辑以及审核人员带来了前所未有的压力。为了适应大数据时代的需求,项目组决定研发一套基于机器学习的内容处理与监控系统,以此来完成内容的自动化过滤与分发,从而为公司的多种内容形态提供高效化、智能化的数据处理流程。论文讲述的是项目组针对当前信息化时代背景,结合当前具有实际应用潜力的机器学习理论设计而成的内容处理与监控系统。文中首先介绍了项目的背景及国内外发展现状,并对整个系统进行功能性需求和非功能性需求的需求分析。之后根据需求分析设计系统架构、划分功能模块、设计系统数据库。接着对具体模块进行详细设计与实现。最后对系统进行测试与验证以确保达到上线要求。笔者独立建立了模块中用到的机器模型,并通过优化算法及损失函数等对模型进行了调整优化。之后测试并验证了机器模型以及核心功能模块,以确保系统达到上线标准。除此以外,笔者参与了系统核心的三大模块的开发,分别为:内容处理(内容过滤与建模)、内容审核、内容监控。在内容过滤中,主要通过N-Gram语言模型对字符进行匹配,利用决策树及Center-Loss函数对模型进行参数的调优;在内容建模中,利用SVM(Support Vector Machine,支持向量机)算法与GRU(Gated Recurrent Unit,门循环单元)模型对数据进行初步的分类与监督,根据不同的内容类型分别采用了 TEXT-CNN以及FAST-RCNN模型进行划分;在内容监控中,为了得到实时数据结果,采用Spark实时框架及MemCache缓存等技术,以此达到监控的性能要求。目前该系统已上线,对于图文的平均判定精确率达到了 95%以上,对于视频的平均判定精确率达到了 80%以上。内容处理速度控制在单篇平均耗时在120s内,实时监控查询速度控制在2s内。"
505,基于机器学习的股票指数预测研究,"股票指数是一个非线性的动态时间序列,它具有高波动、低稳定、噪声大、易受外界因素干扰等特性,这些特性使得股票指数准确预测成为一个非常有挑战性的问题。研究发现股票指数基础数据特征间存在多重共线性与噪音干扰等问题,这些问题往往导致股票指数预测模型精度的严重下降;此外,研究还显示不同结构的机器学习模型性能存在较大差异性,这些差异性导致不同模型在同一支股票指数预测中的表现大相径庭。本文在股票指数价格短时预测的问题中,针对输入特征与预测模型这两种对股票指数预测影响最大的因素,分别提出了基于Xgboost模型的特征生成方法及动态加权集成学习模型。本文的主要研究内容如下:(1)基于Xgboost模型的特征生成方法研究。研究发现输入特征对股票指数预测模型的性能具有重大影响。现有特征选择与特征提取方法在利用基础数据信息方面存在着部分丢失与不充分的问题。本文在研究中发现Xgboost模型将股票指数基础数据特征投影到叶子节点所表示的高维空间的过程中,叶子节点是否参与表达对预测性能具有重要影响。本文仅提取样本在Xgboot中参与表达的叶子节点信息,对其进行one-hot编码通过将参与表达叶子节点映射到高维空间中提高该特征的表达能力。将编码后特征与样本原始特征组合作为最终的输入特征。实验结果表明,该方法生成的组合特征可以有效的提高股票指数回归预测的精度。(2)基于动态加权集成学习的股票指数回归预测方法研究。研究发现预测模型对股票指数的预测同样具有重大影响。传统的集成学习模型在股票指数回归预测中,存在忽略基础学习器性能的贡献度,对高性能的基础分类器利用有限等问题。由于基础分类器间结构各不相同,导致其在不同股票指数预测中表现各异。本文在研究中发现基础分类器间存在一定程度的互补性,通过动态加权的方式对不同结构的基础分类器进行组合,可以合理的利用互补性提高高性能分类器的贡献度。基于此研究本文提出了适用于股票指数预测的动态加权集成学习模型。实验结果表明,本文提出的动态加权集成学习模型同单一预测模型相比精确度更高,且适用于不同股票指数的回归预测。"
506,基于机器学习的问卷可信度审核系统,"入户问卷调查是国民普查的主要方式,每年国家财政花费巨额经费用于这些活动,期望获得准确调查数据,以把握真实情况和做出合理决策,为国民经济生活服务。但是,由于调查过程中的各种原因,导致调查问卷中存在大量不合格问卷(如问卷造假),影响了调查数据的准确性,进而影响了决策的科学性。识别不合格问卷,目前的做法是靠人工逐个审核问卷,存在效率低、成本高,主观性大等问题。随着调查活动的频率和范围的逐年增长,不合格问卷的识别需求与日俱增,亟需一种自动化甄别调查问卷系统,以解放人力、提高审核效率、降低成本,提升审核的客观性。目前,关于自动问卷审核的相关研究还不多见,基于简单规则可以审核问卷,但是需要人工定义规则,灵活性较差。近年来,机器学习在图像处理、语音处理等领域广泛应用并取得了突破性进展,为自动化审核问卷提供了可借鉴的技术和经验。因此,本研究有重要的实际意义,并拓展机器学习的应用空间。为此,本文设计并实现了基于机器学习的问卷审核系统,以自动化审核调查问卷。系统设计的关键问题是,特征工程问题,即如何从高维特征中挑选出对可信度识别贡献最大的特征,以及模型选择问题,即选择怎样的机器学习模型以(从准确率和召回率角度)更好的识别出不合格问卷。本文从音频、图像等多维度挖掘问卷复杂特征,从中提取最有价值的特征,并对比选择在数据集上表现最优的机器学习模型来训练和审核调查问卷。7万份真实问卷的训练/审核表明,本文提出的自动审核系统,AUC为0.88,F1值为0.71,满足审核需求,而且在审核效率、审核的特征维度和评分的精细程度上,远远高于人工审核,且审核过程公正客观。具体来说,本文贡献如下:(1)设计了一套基于机器学习的问卷审核系统,实现对问卷的自动审核。该系统包括有音频、图像等各个分析模块,挖掘提取问卷的高维特征,送入机器学习模型,得到问卷可信度得分。(2)设计了海量特征信息挖掘方法并完成了特征筛选,以实现特征降维和提高模型的识别性能。针对调查问卷的信息,该系统从多维度评估问卷,挖掘出上千维特征,并对高维特征进行了相关性分析和特征工程,筛选出最有价值的特征。(3)比较/评估了不同机器学习模型,以选择在测试数据集上表现最优的模型,进一步提高问卷审核系统的性能。本文比较了几种经典的机器学习模型,找到在现有数据集上表现最优的模型。"
507,基于ARMA模型与GRU模型集成学习在量化投资中的应用,"能够预测一件事情的发生,一直是人们想要探讨的问题,通过细致而又精确的预测,可以提前做一些准备,有较好的事情发生,则积极准备让它变得更好。如果预测到一些较为不好的事情即将发生,则提前做好准备,尽量减少损失。随着科学技术,人类社会等各个方面的不断进步,人们越发想要根据现在的状况预判未来事情的发展,为此,时间序列预测方法得到了飞跃的发展。目前主要有两种预测的方法。第一为传统经典的时间序列预测方法,例如GARCH、ARMA等。经过长时间的发展,时间序列在各个行业得到了非常广泛的应用,但是这种方法对数据要求很大,甚至很多时候需要很多假设,所以实际应用常会浪费很多时间,且有时并不能得到一个比较满意的结果,尤其是面对股票市场长时间走势不断地突变;第二为机器学习中的集中预测方法,最典型的为神经网络模型,神经网络由于其不拘泥于假设而且应用范围宽广,所以自从产生开始便得到了很高的重视,但是其很多模型过于复杂而导致运算时间过长甚至产生过拟合现象。在股市中,随着时间的推移,上市公司增多,国内经济跟国外联系更加紧密,数据越来越多,也越来越复杂,预测的难度也随之增大,出现了量化投资概念。为此现在有很多的学者想办法将二者结合起来,在保证二者优点的同时避免其缺点,然后在量化投资的使用中提高预测的精度。本文首先运用机器学习中集成学习的方法将时间序列中的自回归模型(AR模型)与门限回归模型(GRU模型)结合起来,得到AR-GRU模型。并将其运用于2005年1月至2018年7月上证指数日数据中进行学习,然后根据学习得到的结果对之后的数据进行预测,对比真实结果以及预测结果,分析其偏差情况。本文还提出了另一种集成学习模型,将时间序列中移动平均模型(MA模型)与门限回归模型(GRU模型)集成起来,得到GRU-MA模型。同样将其运用于2005年1月至2018年7月上证指数日数据中进行学习,然后根据学习得到的结果对之后的数据进行预测,对比真实结果以及预测结果,分析其偏差情况。最后将AR-GRU模型、GRU-MA模型、ARMA模型、GRU模型的预测结果进行对比,得出新模型在预测精度上比原模型均高。"
508,基于神经网络的中小企业偿债风险预警研究,"我国中小企业融资难问题成为热点后,不少学者从企业的偿债能力出发探索解决中小企业融资难的途径和方法。而偿债风险预警技术为客观评价中小企业偿债能力提高参考。中小企业的偿债风险状态的预警是判断偿债风险等级的前提和偿债风险管理控制的起点。通过大量的文献阅读发现,国内外从偿债风险角度进行企业风险预警的研究少,并且缺乏对中小企业偿债风险预警的定量研究。因此本文首先通过分析我国上市的中小企业偿债风险现状分析,并结合文献研究,构建中小企业偿债风险预警指标体系。之后运用BP神经网络模型对我国中小企业的偿债风险进行预警研究。随后对预警结果分析得到的决定性指标进行检验。得出下面三个结论:―是本文构建的中小企业偿债风险模型能够使中小企业偿债风险预警效果最好;二是通过与大型企业的偿债风险预警对比,本文构建的中小企业偿债风险模型能够较为科学地为中小企业提供偿债风险预警方法。三是本文模型结果分析发现,净资产收益率是影响我国中小企业偿债风险预警模型预测准确率的最重要的指标。最后,为我国中小企业降低偿债风险提出相应地建议。"
509,基于神经网络与自适应分形分析的股评情感分析,"经典金融学以有效性市场为假说,认为金融市场的价值始终等于其基本价值,但却无法解释现实生活中的“异象”,行为金融学强调市场投资者的认知与情绪会对其决策产生影响,从而引起资本市场价格波动。股市作为投资市场的重要组成部分,其指数变动也会受到投资者情绪的影响。有很多学者利用机器学习方法对与股市投资者相关的文本进行过情感挖掘,但鲜有人提及现实应用环境下由于文本噪声过多产生的不均衡文本分类问题。本文针对此问题采用序列生成对抗网络算法作为文本生成器,对不均衡的股民评论等数据集完成过采样工作,通过在随机森林分类器上进行分类比较得出,利用序列生成对抗网络算法进行文本过采样的方法要比传统的基于插值的SMOTE、Borderline-SMOTE、ADASYN等过采样方法有效,更适合用于不均衡文本分类任务。其次针对传统的卷积神经网络不能捕捉到语料中的长期的上下文关系以及非连续词之间的关系,本文将注意力机制引入到经典的短文本分类卷积神经网络模型,并通过实验证明改进结构的有效性。最后本文利用随机分形理论里的自适应分形分析(AFA),结合构建出的投资者情绪指数与股市对数收益率,对已经分出了情感倾向的股民评论进行情感分析,从而发现投资者情绪与股市对数收益率是高度正相关的,且投资者情绪具有长程相关性,可为后续制定合适的投资策略提供参考。"
510,基于机器学习的O2O优惠券转化率研究,"随着通信技术迅猛发展,移动网络和宽带网络快速普及到每家每户,这极大地促使电子商务的发展。目前,基于大数据、云计算的新的电子商务应运而生,线上渠道和线下渠道有机结合的商务模式O2O(Online To Offline)发展迅猛,随之而来的各种营销手段层出不穷,譬如,优惠券。分析O2O优惠券转化客流情况,实现快速精准预测用户是否在规定时间使用领取的优惠券,不仅能够赋予商家更强的销售能力,帮助商家有效投放优惠券,也可以让具有一定偏好的消费者得到真正的实惠。本文基于O2O优惠券转化情况的研究主要包括以下三个方面:(1)基于天池公开数据集,分析了某电商平台2016年1月1日到2016年6月30日的用户历史数据,包含领券时间、券面优惠情况、用户距离线下商家最近的距离和用户在某商家消费的时间,通过对这些维度的数据可视化分析,挖掘数据蕴含的潜在规律,构建了58个特征,包含用户、商家、优惠券、用户-商家、用户-优惠券和其他因素六个维度。(2)基于构建的特征集,利用随机森林、梯度提升树、XGBoost和LightGBM四个单模型和Stacking融合模型对O2O优惠券转化率进行预测,通过实验验证了特征选取的有效性和所用算法的合理性。(3)考虑到用户具有相似性的消费心理、商家具有相似的营销策略,本文进一步对用户和商家进行K均值聚类,将用户分为三类,商家归为四类,再进行Stacking融合模型预测。实验证明,基于聚类的融合模型预测准确性得到了较大的提升。"
511,Spark环境下半参数支持向量机的研究与优化,"大数据技术的快速发展带动了海景数据分析处理技术的不断进步,一些在小样本上表现出色的机器学习算法逐步应用到大数据学习场景中。半参数支持向量机是一种兼备参数型与非参数型优势的计算模型,能够很好地控制分类器的复杂性,且具有较高的训练效率,但是在而对大型数据时,其运算时间也相对较长。论文在大数据环境下研究了半参数支持向量机算法,采用Spark计算框架实现并行化研究,并进行优化改进。论文研究了一种采用稀疏贪婪矩阵近似算法作为预定义模型,利用迭代重加权最小二乘过程计算权的半参数支持向量机算法。针对其在大数据场景中运行速度慢的问题,提出了两种方法来迭代优化该算法的计算效率:(1)提出在Spark计算框架下实现半参数支持向量机并行化的方法提高算法效率,采用Spark RDD技术共享内存,减少网络传输和磁盘读写,利用Cholesky矩阵分解方法将矩阵计算任务分解成一系列可以并行执行的子任务;(2)在并行化半参数支持向量机的基础上,提出采用kmeans算法与稀疏贪婪矩阵近似算法相结合的方式构建半参数支持向量机的预定义模型,利用kmeans算法的聚类中心求解稀疏贪婪矩阵近似算法中的核矩阵,缩减了矩阵的规模和计算量以提高算法的计算效率。实验证明,Spark框架下并行化的半参数支持向量机算法相对于单机算法在计算效率上有明显的提高,维持原始算法分类性能;优化后的并行半参数支持向量机相对于优化前的算法,分类的准确性和AUC值保持原始优势,算法运行时间得到大幅度缩短,同时聚类中心的数目对算法的性能影响较小;通过与BPPGD、P-PackSVM和SVMwithSGD算法进行比较,证明最终优化后的算法在分类准确率、模型AUC值以及训练时间和分类时间上都有明显的优势。"
512,基于深度学习的广告点击预测研究,"广告点击事件的准确预测是实时竞价算法中的重要因素之一,关系着广告主的成本与收益。当前在线广告的业务场景下,数据规模巨大且具有高维、非线性、稀疏性等特点,如何高效地设计算法以减少迭代是优化算法中要考虑的关键因素。同时,深度学习也为大规模非线性特征的学习及预测提供了有效手段。针对上述问题,本文将主要分为两部分来开展对广告点击预测算法的研究工作。(1)在研究FTRL(Follow-the-regularized-Leader)优化算法的基础上,提出了基于FTRL优化算法的因子分解机模型。在特征提取阶段,使用基于梯度提升决策树算法的特征提取代替了人工特征提取。FTRL算法在梯度下降算法的基础上进行改进,加入了混合正则项防止过拟合,在保持梯度下降类算法高精确度的同时提高了稀疏性。因子分解机可以更好地学习到互异特征分量之间的关系,比传统逻辑回归更有效。实验结果显示,改进后的算法有效地提高了广告点击事件的预测准确率。(2)针对人工特征提取费时费力、浅层模型无法充分考虑到数据之间的非线性关系等问题,提出一种基于 CNN(Convolutional Neural Networks)-LSTM(Long Short Term Memory)混合神经网络模型。卷积神经网络的稀疏连接和权值共享特性能够自动提取高影响力特征,避免了繁琐的人工特征提取。与普通递归神经网络相比,LSTM神经网络通过输入门、遗忘门、输出门、细胞状态四个特性克服了网络训练过程中梯度爆炸或梯度消失的问题,通过时序性进行分类预测。实验结果显示,改进后的混合神经网络比单一结构的神经网络更加有效。"
513,基于深度网络的MOOC辍学预测算法研究,"随着互联网在各个领域的不断普及,传统的教育教学模式正在发生改变。自2012年大规模开放在线课程――慕课(Massive Open Online Courses,MOOC)诞生以来,吸引了越来越多的人参与学习,但高辍学率却给MOOC平台教学的管理带来不便。预测学习者的辍学行为,有助于提升学习者的学习效果以及实现MOOC平台更多的价值。本文从MOOC学习者的学习行为特征出发,提出了3种基于深度网络的辍学预测算法,主要研究内容如下:(1)提出了一种基于卷积神经网络和长短期记忆(Long Short-Term Memory based on Convolutional Neural Network,CNN-LSTM)网络的辍学预测模型。针对现有的MOOC辍学预测模型依赖于特征工程提取特征,预测效果存在不稳定、性能欠佳等问题,该模型采用一种自动特征提取策略,无需特定领域知识和人工干预,同时考虑了学生行为特征的长期依赖信息,提高了模型的预测能力。实验结果表明,该模型与基于LSTM、CNN-RNN的辍学预测方法相比,分别将AUC提高了2.7%、1.4%。(2)提出了一种基于丰富卷积特征的长短期记忆(Long Short-Term Memory based on Richer Convolutional Features,RCF-LSTM)网络的辍学预测模型。针对时间跨度大、特征粗粒度、未能充分利用CNN丰富的层次特征等问题,该模型将粒度更精细的行为特征作为输入,同时还有效地融合每个CNN层的细粒度特征。实验结果表明,相较于CNN-RNN和CNN-LSTM辍学预测模型,该模型的AUC值分别提高了0.29%和0.25%。(3)提出了一种基于CNN-LSTM-SVM网络的辍学预测模型。针对训练参数多、耗费内存以及数据类别非均衡等问题,综合考虑了学生行为的局部特征和序列化特征,同时对不同类别设置不同的权重,解决了非均衡数据对预测结果的影响。该模型结构简单,相较于RCF-LSTM网络模型的辍学预测算法,AUC提升了5.54%。本文的研究表明基于深度网络的辍学预测模型,可以预测学生不同时刻的行为状态变化,有助于教师提供及时的干预措施,提升学习者的学习效果,对促进我国教育信息化快速发展具有重要的指导意义。"
514,基于深度神经网络的股票智能预测系统的设计与实现,"股票市场受经济市场、政策等因素的影响,其内部变化规律极其复杂。随着中国股票市场的快速发展和投资者规模的扩大,股票市场产生了大量的交易数据,使获取有价值的信息变得更加困难。由于深度神经网络善于处理数据量大,非线性映射关系复杂的预测问题,本文基于深度神经网络设计了一个股票智能预测系统。主要工作内容如下:(1)股票选股模型研究:从股票财务指标和股票变化趋势层面,研究了多因子量化选股的问题,提出一种基于股票趋势识别算法构建选股模型的方法。该方法根据改进的股票趋势识别算法,对由财务指标和技术指标构建的选股指标集进行趋势标识,并使用主成分分析法对选股指标进行相关性处理,将处理后的股票数据输入BP神经网络中,训练出股票选股模型。相比于现有的选股方法,提出的选股模型在选股精度上平均提高了5.09%。(2)股票价格预测模型研究:针对股票交易数据量大,非线性关系复杂,难以准确预测股票价格的问题,基于LSTM(Long Short Term Memory)深度神经网络对股票价格的预测进行研究。从股票选股模型的输出结果中选择可投资的股票。通过研究影响股票价格变动的因素,选取股票交易基本数据和股票技术指标数据,融合成股票训练数据。采用LSTM深度神经网络构建股票价格预测模型,对影响模型效果时间序列长度和网络结构等参数进行调优。相比于选取股票交易基本数据训练的股票价格预测模型,决定系数提高了2.4%,均方根误差降低了0.12。(3)股票智能预测系统的设计与实现:基于股票选股模型和股票价格预测模型,设计并实现了股票智能预测系统。运用Django框架、Scikit-learn机器学习库和Keras深度学习库完成股票智能预测系统各个功能。该系统可以实时地进行股票选股和股票价格预测,给投资者提供实时、有效的投资决策建议,从而降低投资者投资的风险,并获得稳定投资收益。"
515,大数据下媒体关注、媒体情绪与股票量价关系研究,"随着我国金融市场不断开放,财经媒体报道对资本的定价功能已逐步凸显出来。财经新闻是投资者获取宏观经济金融信息和搜集上市公司动态消息的主要媒介,我国资本市场中的独立第三方财经媒体在服务投资者的同时也影响了股市表现。相应的,移动互联时代下的财经媒体报道与股票量价的联动关系也已成为金融学领域中的学者们广泛关注的研究热点。与此同时,计算机科学领域中的大数据和人工智能技术也为自动化和智能化地挖掘与分析海量的财经信息提供了有利的条件,特别是中文自然语言处理技术的日渐成熟,使得行为金融学领域的学者可以更加系统和细致的研究财经媒体报道与资产定价的关系。基于此,本文首先应用网络爬虫技术从我国主流财经网站及媒体获取了与A股沪深300指数成份股对应的上市公司在2014年初至2017年末被媒体报道的160多万条财经新闻,并用支持向量机的机器学习分类方法和基于文本情感词典构建的文本情感分析技术对其进行分类统计与情感分析。然后,本文基于新闻数量和新闻情感倾向两个属性构建周度的“媒体关注”和“媒体情绪”的代理指标,应用动态面板逐步回归模型分类探究我国财经媒体新闻报道与股票量价的联动关系。此外,本文还将全样本按照股票市场状态划分为牛市时段和熊市时段,分类探究了不同市场状态下的媒体报道与股市表现的关系。本文通过研究发现,在我国弱势有效的资本市场环境下,财经媒体的新闻报道整体比较乐观,媒体报道引发的“媒体关注”和“媒体情绪”短期内能够激发市场交易热情并且对市场价格形成一定压力,媒体关注对股票交易量的影响较大,而媒体情绪对股票价格的影响较大。其中,正面的媒体报道更能激发市场的交易热情促进股价提升,而负面的媒体报道更容易引起股票价格发生较大偏离且对后续的市场交易影响时间更长。交易时段和非交易时段的媒体报道都会激发市场的交易情绪,但是交易时段发布的新闻对股票交易量的影响更大,而非交易时段发布的新闻对之后首个交易日的开盘价格影响较大。此外,本文还发现,牛市中的媒体报道比熊市更为乐观,媒体报道更容易刺激市场进行交易进而推动股价上涨,而且市场对正面新闻报道更为敏感。本文基于财经新闻的发布属性,利用财经新闻文本大数据创新性地构建了“媒体关注”和“媒体情绪”的分类代理指标,为刻画媒体报道的影响提供了新的思路;并且,本文同时从“媒体关注”和“媒体情绪”两个视角,系统而详致地研究了我国主流财经媒体报道与股票量价的联动关系,为行为金融学领域中“媒体报道与资产定价”的研究提供了新的观点和证据,也为投资者更加高效地挖掘财经新闻信息辅助投资决策提供了新的方向。"
516,基于分类法自动映射的众包实现,"分类法作为重要的知识组织工具,在图书馆书目资源、文献资源按类组织、分类排架以及多种网络信息资源的导航和检索等方面发挥着重要作用。目前,不同国家地区,不同性质的机构采用不同的分类法标引各自的信息资源,不同分类系统之间未明确建立对应关系,从而影响了互访效率。随着图书馆之间馆际互借及其资源共享运动的推动,图书馆书目数据库之间的互访成为发展趋势。建立不同词表之间的映射是实现分类系统互操作的一种重要方法,对不同分类法之间的映射研究具有重要意义。目前,国内外学术界针对分类法的映射做了积极地探索和实践,分类法映射模式分为人工映射和自动映射。人工映射的映射结果准确、完整,但是工作量大、完成周期长;自动映射提高了映射效率,仍存在结果不准确、有些类目无法建立映射等问题,无法实现完全自动映射。结合人工映射和自动映射的方式可以有效提高分类法映射的准确率和效率。众包是一种创新模式,利用计算机和用户的经验及知识来解决机器难以单独完成的任务。将众包引入分类法的映射实践,其实质是利用大众的知识背景和智慧完成映射工作,可以提高映射的准确性并发现更多的映射类目。基于以上背景,本文提出基于分类法自动映射的众包实现方法,依据分类法特点构建自动映射模型,在自动映射结果的基础上,通过设计众包映射组织模式,最终实现分类法之间的匹配。本文首先对分类法映射基础理论、映射方法进行简要概述。选择CLC、DDC、LCC这三部世界范围内使用广泛的图书分类法,构建CLC与DDC、LCC两种国外分类法之间的映射。本文分析了三种分类法各自的特点,采用基于类目相似度的方法实现CLC与DDC类号映射,映射过程中对类目特征词进行词素切分。在CLC与LCC映射中,引入DDC与LCC的映射,提出基于关联书目数据的DDC与LCC映射实现,并且以DDC类表为中介,间接建立CLC与LCC之间部分类目的映射关系。之后以自动映射的结果为基础,通过设计众包分类法映射框架、众包映射任务模块、众包映射质量控制方案等构建众包分类法映射模式。最后,通过具体的应用实例验证该方法的准确性和有效性,为其他分类法的映射提供参考。"
517,江西省精准扶贫中的贫困户识别研究,"自1986年以来,中国不断推进扶贫开发工作,经过这些年的努力,已经在扶贫成效方面取得了巨大的成就。为了更深入解决新时期的贫困问题,2013年十八届五中全会又提出了“精准扶贫”的思想,并出台了一系列精准扶贫政策,全国各省市也积极响应国家的号召,致力于打好脱贫攻坚战。革命老区江西省是我国农村人口大省之一,也是我国扶贫开发工作的主战场,为了确保扶贫工作能够精准执行,江西省政府实施了相应的措施,致力于使得政策落实到村到户。然而在实践中发现,由于很难从家庭和住户的层面去获取到可靠的收入和支出信息,并且长期以来贫困投资项目的实施主要依赖区域目标的瞄准。由此导致严重的覆盖不完全和漏出问题,需要一种更简单和更有效的贫困瞄准方法来识别贫困家庭。目前已有一些学者将识别模型运用到贫困户识别的过程中,但我国的贫困户识别模型大部分还是运用Logistic回归来建立模型,但这种建立在假设基础上的回归模型很容易产生误差,导致识别不精准。对此,本文在前人研究的基础上,对江西省精准扶贫中贫困户识别模型做了进一步的探讨。在理论上,介绍了当前精准扶贫的相关研究和将机器学习算法应用于各大领域的相关研究,并探讨了随机森林和支持向量机在分类方面的一些优势,这些研究为后文将机器学习方法运用在贫困户识别上做了铺垫。在指标上,结合江西省的实际情况扩充了现有的指标体系,以期能更好地反映农户的贫困状况。在方法上,本文将机器学习方法运用到贫困识别的问题上,并运用了学习曲线、Brier分数以及概率校准来度量几种模型的有效性和稳定性。通过实证分析分析发现支持向量机模型优于Logistic模型和随机森林模型,并运用测试集数据证明该模型的预测效果的稳定性,可以为贫困户识别工作带来一定的参考价值。正文主要分为六章,第一章介绍了论文的背景和意义、相关研究现状,其次介绍了研究思路、方法和内容,最后指出本文的创新之处。第二章介绍了模型的相关理论,包括了模型的基本思想和评估分类器性能的度量。第三章主要进行了贫困指标的选取和贫困数据的描述性统计。第四章中,本文在训练集上运用了以往学者常用的logistic和新引入的机器学习方法(随机森林、支持向量机)来建立模型,为后文模型之间的比较打好基础。在第五章中,使用测试集的数据对建立的模型进行检验,结果表明支持向量机模型在准确度、召回率以及预测能力等方面都要优于随机森林模型和logistic模型,而且支持向量机模型的分类效果以及稳定性更为理想。最后在小结中简要分析了支持向量机没有识别正确的农户,找出其中可能存在的问题,提出在今后的贫困识别时不仅要关注收入指标,还需要考虑收入构成的建议。在第六章中,总结了本文的结论,指出不足之处并提出展望,最后根据本文研究的结果提出若干的政策建议。"
518,企业管理层语调与其经营业绩关系研究,"随着我国资本市场的迅猛发展,投资者对资本市场信息的关注不再仅仅局限于传统的财务信息,对于非财务信息的关注与日俱增,其中上市公司年度报告中管理层讨论与分析作为包含企业对当期经营情况的回顾和对未来发展展望的重要非财务信息,自然而然受到广泛关注。计算机文本挖掘技术的发展使得在大样本下对管理层讨论与分析文本进行文本分析成为可能,国外研究者很早就开始利用计算机文本挖掘技术对上市公司披露的文本信息进行研究,但是由于汉语的特殊性,国内在这方面的研究目前还相对较少。本文将“语调”引入到上市公司年度报告中的管理层讨论与分析文本的研究当中,运用目前主流的文本分析方法“字典法”研究我国上市公司年度报告中管理层讨论与分析文本语调与企业经营业绩的关系。具体而言,本文通过年报采集、文本预处理、字典构建、分词与词频统计等过程先将2015-2017年8000多份上市公司年报中管理层讨论与分析文本进行语调量化,在文本处理过程中将管理层讨论与分析文本分为回顾部分与展望部分,之后建立回归模型,分别研究管理层讨论与分析回顾部分文本语调与企业当年业绩的关系和管理层讨论与分析展望部分文本语调与企业下一年度业绩的关系。本文研究发现,管理层讨论与分析回顾部分文本的积极语调与企业当年业绩显著正相关,消极语调与企业当年业绩显著负相关,积极语调和消极语调都具有关于企业当期经营情况的信息增量,且消极语调相比积极语调含有更为丰富的信息含量,而管理层讨论与分析展望部分文本语调与企业下一年度业绩无显著相关关系。实证结果表明我国上市公司年度报告中管理层讨论与分析回顾部分文本语调能有效反映企业当年的经营情况,回顾部分内容较为真实客观,而展望部分内容质量有待提高。本文进一步指出了我国上市公司年报管理层讨论与分析信息披露中存在的一些问题并给出了一些针对性的建议。"
519,金融科技在供应链金融风险控制中的应用研究,"供应链金融作为一种重要的产融结合金融服务领域,近些年来得到了快速的发展,作为连接产业实体与金融的“桥梁”,供应链金融可以有效的解决依附于核心企业的上下游小微企业融资难题,是国家现阶段推行的金融供给侧改革、金融服务实体,尤其是破解中小企业融资困境的重要途径。但由于先前金融机构在开展供应链金融中出现了诸多风险问题,而且这些风险问题通过传统的风险控制手段无法有效控制,导致供应链金融业务一直未获得充分的发展。随着近些年新兴信息技术的蓬勃发展,多种科技手段在金融中得到应用并推广,尤其是大数据、云计算、区块链、物联网及人工智能金融科技手段应用到供应链中,促进了传统供应链的升级、打造出智慧化的供应链系统,智慧化的供应链体系一方面优化了供应链体系,促进了供应链业务的发展,与之同时,由于信息技术的应用,增强了金融机构对供应链金融业务中的物流、信息流、资金流的把控能力,尤其体现在解决信息不对称、贸易真实性、存货质押监管等方面,一定程度上解决了原有供应链金融风控难题,降低了供应链金融的风险。本文对金融科技的概念、主要技术和供应链金融、供应链金融风险控制相关理论进行阐述,聚焦金融科技技术在供应链金融风险控制中的应用,揭示金融科技如何提升供应链金融的风险控制能力,介绍供应链金融应用金融科技进行风险控制的现状,并结合案例对相关的观点进行论证,针对现状提出供应链金融风控应用金融科技面临的挑战,并提出相应的解决对策。最后,对文章进行总结,并对供应链金融风险控制应用金融科技的未来发展进行展望。本文研究的意义在于,通过研究金融科技在供应链金融风险控制中的应用问题,揭示随着供应链金融风险控制与金融科技技术融合程度越来越高,通过综合运用金融科技手段,金融机构在供应链金融风险控制中实现了智能化授信决策、可视化贷后管理等优化,风险防控能力得到了较大的提升,实现了科技助力金融,金融推动产业发展的目的。笔者通过介绍各种金融科技技术在供应链金融风险控制的应用,并辅之以实务案例,为供应链中金融服务的提供者应用金融科技进行风险控制提供理论支撑和案例指导,笔者重点分析了目前供应链金融风险控制在应用金融科技中面临的挑战,并给出了相应的对策,为供应链金融服务的提供者在应用金融科技进行供应链金融风险控制、监管机构对金融科技进行监管时,提供了思路和框架,以期通过多方的努力,共同促进金融科技在供应链金融风险控制领域更好的发展。"
520,银行贷款行业结构对系统性金融风险的影响研究,"近年来,系统性金融风险逐渐成为中国经济中一个不容忽视的问题,国内外也涌现出了大量关于系统性金融风险的研究,其中很多文献探讨了如何测度银行的系统性金融风险。然而,这些文献大多都集中在上市银行,缺乏对非上市银行的讨论。此外,近年来我国经济步入新常态,许多落后行业的企业运行困难增加,使得银行贷款违约率增加,因此若银行不及时调整贷款行业结构,将极有可能造成损失形成风险。可见,贷款的行业结构是影响商业银行系统性金融风险的一个重要因素,在中国推行供给侧改革、实施去产能推动产业结构升级转型、从“十二五”时期步入“十三五”时期的背景下,研究贷款的行业结构对商业银行系统性金融风险的影响具有十分现实的意义。因此,本文利用Brownlees and Engle(2017)提出的SRISK的指标,结合K近邻算法,来测算了2011-2017年中国120家上市与非上市商业银行的系统性金融风险。同时,本文还从商业银行的角度出发,考察近年来银行贷款行业结构的变化,并建立了回归模型考察了商业银行的贷款行业结构对系统性金融风险的影响。具体而言,本文主要提出并回答了如下几个问题:(1)如何测度非上市银行的系统性金融风险?考虑了非上市银行的系统性金融风险后,中国商业银行系统性金融风险又会呈现怎样的分布?利用经K近邻算法改进的SRISK指标对中国商业银行的系统性金融风险进行测算后,本文发现:(1)中国系统性金融风险的风险目前仍然集中在上市银行,但非上市银行的系统性金融风险不容忽视。(2)国有银行的系统性金融风险占比最高,其次是股份制银行,最后是城商行。但近年来国有银行的系统性金融风险占比不断下滑,股份制银行保持稳定,城商行的系统性金融风险占比不断上升,因此城商行的系统性金融风险尤为值得关注。(2)从“十二五”到“十三五”,商业银行的系统性金融风险和贷款行业结构是否有显著变化?通过建立回归模型,本文发现“十三五”期间商业银行的系统性金融风险相比“十二五”期间有显著的提升,这意味着从“十二五”到“十三五”,政府在制定产业政策实施产业结构的升级转型的同时也要注意系统性金融风险的问题。此外,从“十二五”到“十三五”,制造业、批发零售业、商务服务业和水利环境公共设施管理业的贷款比重发生了显著改变,其中制造业、批发零售业的比重显著下降,商务服务业和水利环境公共设施管理业的贷款比重显著上升,其他行业的贷款比重没有显著改变。(3)商业银行的贷款行业结构是否会对系统性金融风险产生影响?目前我国商业银行的公司类贷款主要集中于造业,电力、燃气及水的生产和供应业,建筑业,交通运输、仓储和邮政业,批发和零售业,房地产业,租赁和商务服务业,水利、环境和公共设施管理业等八大行业。通过建立回归模型,本文发现制造业的贷款比例增加会降低商业银行的系统性金融风险,而房地产业、租赁和商务服务业贷款比例的增加会导致商业银行系统性金融风险的增加。(4)如果商业银行的贷款行业结构确实会对系统性金融风险产生影响,由于“十二五”和“十三五”期间国家出台了大量政策,那么“十二五”到“十三五”的过渡是否会增强或减弱这种影响?通过在模型中添加交互项,本文发现“十二五”到“十三五”的过渡加强了制造业贷款对系统性金融风险的抑制作用,但“十二五”到“十三五”的过渡减弱了房地产业贷款对系统性金融风险的促进作用。最后,本文还研究了区域系统性金融风险的相关问题。本文发现从“十二五”到“十三五”各省的系统性金融风险水平有显著提升,且我国的系统性分布呈现出由东向西逐渐递减的趋势。省份的总GDP增长率和第三产业增长率的提升会降低系统性金融风险水平,省份产业结构的“服务化”水平的提高也有助于降低系统性金融风险水平。因此,防范区域金融风险的一个重要举措是大力发展本省经济特别是重视服务业的发展。"
521,基于机器学习组合模型的个人信用评估,"随着国家经济实力的增强,人们的可支配收入不断增加,信用经济市场也在不断发展。居民的消费观念也慢慢地从存钱理财转向了预支未来消费,在这样的背景下,我国的消费信贷在整体上呈现一个良好上升的趋势。而个人信用评估在信用经济市场发挥着及其重要的基础作用,它促进了信用经济的发展,稳定了经济市场。伴随着消费信贷业务井喷式的发展,个人信用体系的建立需要不断得完善,此时利用新技术,推动个人信用评估体系的发展显得尤为重要。互联网的不断发展使得人们的生活也离不开互联网,大数据时代的到来告诉我们科学的数据可以客观反映我们的信用水平。生活中每个人的行为产生的信息都能通过数据记录下来,在个人信用上的信息主要有个人基本信息、还款能力和还款意愿,个人基本信息主要由年龄、性别、地区等特征构成,主要反应了这个人的基本属性,还款能力主要由资产、工资、社会关系等特征构成,还款意愿主要考察的是该人是否有相应的违约事件、违约事件的严重程度等信息,所以个人信用评估系统根据这三个因素构成,完整地包含了有关一个人信用违约的所有数据。而个人信用评估问题是个分类问题,利用统计学方法对个人信用问题研究已经趋于成熟,在对个人信用问题进行研究时,将机器学习技术运用到其中,可以提高很多效率,并且在对大量数据的处理过程中也发挥着重要的作用。而在机器学习中存在各种分类算法都能对个人信用评估模型进行处理,鉴于学者们对单一的个人信用评估模型研究已经非常完善,本文通过比较单一模型和组合模型的优劣来开展研究。文中的数据来自于国外某信贷机构提供在Kaggle数据平台上的个人信用数据,数据量达到15万条,涵盖了个人信用体系构建的全部特征,是能够客观反映一个人信用评分的数据。文章先对数据进行了预处理,将删除法和填补法互相结合,对数据中的缺失值进行处理,再将数据中的异常值删除,得到了完整的数据集。再将数据集的四分之三作为训练集学习出模型,四分之一作为测试集来评估模型的优劣,确保训练每个模型的数据集相同,测试每个模型的数据集相同,让对比各模型泛化能力的结果具有科学性。本文选取决策树算法和Logistic回归算法来构建两种单一模型,再进行单一模型之间准确性的对比。先研究了两种算法的基本原理,再利用各算法在完整的数据集学习出个人信用评估模型,将两个单一模型在同一个测试集上进行测试,再对比两个单一模型的分类评估结果,发现Logistic回归模型要优于决策树模型。而组合模型在个人信用评估领域中主要有两种方法:串行结构组合和并行结构组合。文章先将策树算法和Logistic回归算法分别进行串行组合,将决策树的输出结果作为解释变量,加入到Logistic回归模型的特征之中,输出一个串行组合模型,再利用测试集去对该模型测试,得出分类评估指标,研究发现,串行组合模型的分类效果都优于两个单一模型。在得到串行组合模型之后,再将两个单一模型进行并行组合。并行组合模型让两个模型的输出结果,根据不同的权重组合成一个新的输出结果,选取合适的权重,构建成一个最优的组合模型。再将构建好的组合模型在测试集上进行测试,得到分类结果,发现,最优的组合模型的分类效果要优于串行组合模型。本次研究结果表明,单一的决策树模型对个人信用评估问题的预测精度要差于Logistic回归模型,而相比于单一模型来说,组合模型中无论是串行模型还是并行组合模型对个人信用评估的研究都要更优,预测精度都要更高,在个人信用评估领域有着分类效果更准确、解释性更强等优点,显然降低了信用风险。在由决策树和Logistic回归构建的组合模型中,最优并行组合模型的分类效果要优于串行组合模型。而对于未来的个人信用评估研究来说,在组合模型研究领域,还可以利用很多方法研究出基于不同单一模型的不同结构的组合,还有很大的研究空间,是未来个人信用评估模型的研究方向。"
522,基于支持向量机（SVM）股票择时策略的研究,"量化投资作为新兴的一种投资思想和投资方式,以数据为基础、投资策略为脉络、以模型为核心,正以其严谨的客观逻辑、精确、快速的交易方式的特点,获取总体稳定的收益和出色的风险控制能力赢得研究人员和市场越来越多的关注。而近年来,随着我国经济的快速发展,证券市场不断壮大,股票市场也越加的繁荣。投资者不仅面临着巨大的机遇,同时也面临着高风险。股票市场具有的复杂、非线性的特点,使得传统投资分析方法面临不小的挑战。而量化投资结合大数据形成的投资策略和方法在证券市场上优势也日益凸显。本文选取自2013年07月01日至2018年07月10日的平安银行股票数据作为研究对象,共有1228个股票交易日,选取共三十八个特征因子作为研究对象,结合数据标准化和主成分分析法,将特征因子进行降维处理,以第二天涨跌为输出数据,进行模式识别,最终建立针对该只股票数据的时间序列支持向量机预测模型。在处理过程中,对PCA-SVM模型通过网格搜索法进行参数优化。针对建立的模型,本文选取样本内外数据的预测准确率、精确率、召回率和f1-score作为衡量指标,对模型进行比较。根据模型形成的投资策略进行回测,结果表明量化投资策略能获取较市场更高的收益,同时在风险控制上表现出更好的优越性。"
523,股票场外期权交易策略研究,"期权作为一种重要的金融衍生产品,在金融市场上起着重要的作用,作为套期保值的一种重要工具,能很好的规避风险,指导市场参与者进行投资。2015年2月,我国首只场内期权――上证50ETF期权正式上市。2015年9月,监会出台了新的管理办法,将场外期权交易由审核制改为了备案制,使得场外期权的交易更为合法化与规范化,也提高了证券公司,期货公司,私募公司与个人投资者对场外期权的投资的兴趣。场内与场外期权交易市场在我国开始建立与不断发展。随着我国金融市场的不断发展完善,中国的期权市场也在不断的完善中。本文主要从两方面研究现在场外股票期权的常用期权――沪深300,上证50与中证500的30天,90天和180天的欧式期权。一方面是通过构建贝叶斯长短时间神经网络集成来对Black-Scholes期权定价模型中的隐波动率进行预测,实验证明贝叶斯长短时间神经网络集成的效果要优于传统的循环神经网络集成与长短时间神经网络集成。另一方面是对现实的场外期权进行投资分析,以财通证券的场外期权报价为例,结论是沪深300与上证50场外期权适合投资而中证500由于其成分股导致的不稳定性,不适合场外期权投资。"
524,Spark自动调优系统的设计与实现,"随着大数据时代的到来,计算机需要处理的数据量与日俱增,面对互联网、工业物联网等领域不断增长的数据规模和计算需求,单个计算节点不再能有效地满足数据存储和处理的需要。在这样的背景下,Apache Spark作为一种具有良好计算性能和环境适应性的分布式计算框架,得到了广泛地使用。Spark有数十个可以影响系统行为的参数,这些参数可以通过改变计算任务的并行度和使用的内存大小等方式,显著地影响Spark应用的性能。目前这些参数通常由系统管理员手动调整,然而人工调参方法对于使用者的专业能力有一定的要求,并且由于可调参数数量众多以及集群环境之间的差异,具有较大的局限性,难以满足所有Spark应用场景下的需要。为解决上述问题,本文对如何自动化地进行Spark应用参数调整做了研究。本文分别研究了如何利用应用历史运行数据来进行自动参数调优的问题和在缺少应用历史数据的情况下如何自动优化参数的问题。除此以外,本文还探讨了如何基于统计方法进一步提升参数优化效果,并且对这种方法的适用性进行了探讨,最后在前述方法的基础上,实现了一个自动在Spark on yarn部署模式下工作的参数优化系统。在应用运行历史记录充足的场景下,本文基于机器学习方法对系统参数和性能之间的回归关系进行建模,并使用这一模型的预测结果判断候选参数的优劣,最后在指定的搜索空间寻找一个适合的优化参数以达到应用性能优化的目的。在这一过程中,本文使用了更加实用的应用性能预测模型建模方法以求得准确的回归效果。在缺乏应用历史记录的场景下,本文通过启发式方法,根据系统的硬件配置调整应用参数,使应用能够获得一个相对于默认参数而言性能更好的配置。另外,为了使这两种方法能够顺利结合在同一个系统中工作,本文设计可将两者结合起来的策略。最后本文利用统计学方法,对应用性能预测模型的准确性和速度对参数优化结果的影响做了讨论,并根据实验结果提出了一种应用性能预测模型优化策略以进一步提升优化效果。实验结果显示,无论是否有充足的历史数据,本文提出的性能优化方法均能通过调整系统参数对应用性能起到良好的优化效果。在有历史数据集的情况下,本文所述方法可以使得来自性能测试基准程序集的四个应用平均运行时间减少约59.92%。"
525,股票市场程序化投资模型的研究,"随着我国计算机、互联网和大数据技术的迅速发展和股票等证券市场的蓬勃发展,程序化智能化投资模式正在快速地兴起和发展。人工智能技术的发展极大地提高了机器学习能力。计算机可以快速处理大量数据,总结有价值的信息和规律,制定新的投资策略并修改和完善现有的投资模型。本文通过机器学习算法和物理模型建立一个应用在股票市场中的程序化投资模型。通过数据挖掘方法和机器学习算法对影响股票价格的因子进行分类与筛选,运用决策树算法分析基本面候选因子所带来的复合收益,超额收益以及相关性,运用逻辑回归算法分析技术面候选因子的预测准确情况,进而选取对股票价格有显著影响的市场有效因子。考虑股票市场的实际情况以及国内宏观经济状况等对股票价格的影响,引入经典物理模型卡尔曼滤波模型对股票市场的技术面有效因子进行改进,主要应用到空间状态模型、新息过程以及卡尔曼增益计算等,以期使股票市场技术面有效因子可以更加显著地表现股票价格的变化趋势。通过多因子模型从基本面和技术面角度对股票进行程序化筛选组成股票池,建立具有优势的股票投资对象。并构建投资模型的投资思路与风险控制方法。最后实现投资策略模型的程序化。在实证研究中,使用股票池的历史数据对程序化投资模型进行回测,并将程序化投资模型用于实时模拟盘中进行测试,从净收益率与最大回撤等方面对程序化投资模型加以改进。本文通过机器学习算法和物理模型进行研究并建立一个应用在股票市场上的程序化投资模型,通过历史数据以及实盘模拟对程序化投资模型不断测试与改进,以期通过概率优势获得超额收益,帮助投资者在股票市场中获得更高的回报。"
526,基于机器学习的链路预测相关问题研究,"现实世界中很多系统都可以用复杂网络来表示,其中节点代表实体,连边代表实体间的联系。链路预测作为复杂网络领域的基础且重要的问题之一,目前仍然是一个开放性的问题,而且其相关问题也不断涌现。近年来,随着机器学习特别是深度学习在欧式结构的数据上取得突破,使用深度模型处理非欧结构的网络数据在学术界方兴未艾。本文就链路预测及其相关问题做了较为深入地研究,分别从如下三个方面入手,提出了一系列基于机器学习的改进方法:(1)基于层次注意力机制的链路预测算法:传统的基于相似性指标的链路预测算法在网络连边稀疏的情况下,难以提取有效的结构信息。受注意力机制的启发,本文提出一个基于层次注意力机制的端到端链路预测算法。该模型包括节点以及连边等两种层次的注意力机制,能自适应地学习到有效的局部拓扑信息。在多个实际网络中实验验证,尤其是在路由器、电力等稀疏网络里,本文提出的算法相比相似性指标以及图嵌入算法,具有明显提升。同时通过限制训练集大小,证明了本文方法的鲁棒性。(2)基于多元网络特征融合的链路权重预测算法:不同于预测连边是否存在,在加权网络里,由于信息缺失等原因,需要预测连边的权重。本文提出一个基于多元网络特征融合的链路权重预测算法。具体地,通过网络变换将原始网络转化为连边网络,然后用连边网络的节点中心性定义原始网络的连边中心性,最后融合原始网络的节点相似性特征以及连边网络的节点重要性特征,预测原始网络的连边权重。通过多个实际网络的实验验证,本文提出的方法较对比算法具有更好的预测效果。进一步的,本文也验证了连边网络对于权重预测的互补作用。(3)基于进化计算的链路隐匿算法:出于隐私安全的角度出发,本文提出链路预测的反问题,即链路隐匿。本文将链路预测视为攻击方获取隐私连边的手段,防守方需要采取一些保护措施避免隐私连边泄露。具体地,本文提出两种基于进化计算的链路扰动机制。为了加速适应度函数的计算,本文也提出一种增量更新的方法。多个实际网络中的实验验证表明,本文的算法相比于对比算法具有最好的防御效果。同时通过不同的链路预测算法验证,本文的方法具有良好的迁移性。"
527,基于机器学习和WRF模式的近地大气光学湍流强度估算,"激光在大气中传输时会受到大气湍流的影响,产生光束漂移、扩展和光强闪烁等湍流效应,严重制约了大气环境下各种激光应用系统的性能。大气折射率结构常数C_n~2是大气光学湍流强度的重要描述参量。实测手段获取C_n~2的方法不仅耗费大量资源,而且对于复杂情形的下垫面测量难度较大。因此,由常规气象参数估算C_n~2的光学湍流参数化模型研究受到重视。然而,使用Monin-Obukhov相似理论估算近地面层C_n~2的传统方法在稳定大气层结的情况下是失效的。针对这一局限性,基于机器学习方法建立近地面层光学湍流参数化模型便具有重要的研究意义与价值。本文利用大量实测数据,基于后向传播神经网络(BP)、支持向量回归机(SVR)和K-近邻(KNN)三种机器学习回归算法,开展了内陆戈壁地区近地面层C_n~2的估算研究。三种算法均使用温度、相对湿度和风速三个常规气象参数以及时间因子作为输入特征量,C_n~2作为单一输出。训练结果表明,三种估算模型在趋势和量级上均能较好地表现出该地区光学湍流的日变化特征;正午强湍流时刻、日出日落转换时刻以及正午强湍流值的估算结果与实测结果均能够较好地吻合。对lg(C_n~2)进行统计分析表明,BP、SVR和KNN三种模型估算结果与实测结果的平均绝对误差分别为0.27、0.30、0.31,均方误差分别为0.13、0.16、0.17,整体皮尔逊相关系数分别为85%、81%、80%。总体来讲,BP模型的平均绝对误差和均方误差最小且整体皮尔逊相关系数最大,模型估算性能最佳。为了实现对未来时刻C_n~2的预报,本文开展了BP模型结合天气研究与预报模式(WRF)估算C_n~2的初步研究。将WRF模式数值模拟得到的常规气象参数作为输入,代入到建立的BP模型中进行C_n~2的估算。结果表明,利用该方法估算的C_n~2在整体上符合该地区光学湍流的日变化特征。对lg(C_n~2)进行统计分析表明,BP模型结合WRF模式的估算结果与实测结果的平均绝对误差为0.33,均方误差为0.21,整体皮尔逊相关系数为76%。研究表明,基于机器学习建立的光学湍流参数化模型和WRF模式对强湍流和中等强度湍流情况下的C_n~2进行估算的方法是可行的。"
528,联合残基和残基对特征预测蛋白内部翻译后修饰位点间的相互作用,"蛋白质翻译后修饰(Post-translational modification,PTM)之间的相互作用在调节蛋白质活性、细胞信号转导、基因表达以及蛋白质-蛋白质相互作用等生物学过程中发挥着至关重要的作用,研究这类相互作用有利于深入阐明由PTM介导的调控机制。通过实验方法检测PTM相互作用耗时费力,而计算方法的开发则有望弥补实验技术的不足。现有大多数的计算研究主要依赖于序列层面的残基关联特征来开发预测模型,忽略了PTM相互作用位点的结构信息和单个残基的特性,从而阻碍了预测精度的提升。因此,开发新算法以克服现有研究中的局限性显得至关重要。本研究提出了一种基于结构信息的算法(PTM Cross-Talk predictor,PCTpred)来提高预测PTM相互作用的准确性。该算法首先在蛋白质序列和结构层面设计了一系列残基关联特征(如共进化信息、共定位信息等)和独立残基特征(如致病性分数、拉普拉斯拓扑指标等),通过比较分析发现正负样本在基于残基对和残基的特征上均具有显著的差异。然后,利用前向特征选择技术保留了23个新引入的描述符和3个传统描述符,在此基础上分别开发了序列分类器PCTseq和结构分类器PCTstr,并通过权重联合构建了最终的预测模型。基于样本和蛋白层面的评价,PCTpred获得的曲线下面积分别为0.903和0.804。即使在去除样本中的距离偏好或使用模拟的蛋白结构作为输入,本算法的预测性能仍能得到维持或适度降低。对不同类型的PTM相互作用子集和文献收集的共修饰肽段进行测试,PCTpred依旧获得了良好的预测效果,从而展现出较强的泛化能力。与目前最优秀的算法相比,PCTpred在各种类型的评测中均能获得较高的预测精度。PCTpred的源代码和数据集可从以下链接获取https://github.com/Liulab-HZAU/PCTpred。"
529,K-means聚类和随机森林算法在血红素模型多自旋态力场电荷预测中的应用,"血红素与氧气的结合与解离过程是重要的生命现象。在氧气靠近的过程中,血红素电荷极化效应明显,且底物对血红素自旋态影响显著,使体系存在自旋交叉的现象。但是传统力场的固定点电荷模型,不适合应用到血红素体系中,且当前针对血红素自旋交叉这一特点开发力场的工作较少。本课题组针对这一问题提出了多自旋态可变电荷力场的设想,这一设想的核心是能够根据构型变化准确的预测各个自旋态的电荷,从而正确的描述由于构象变化导致的各组态的能量变化。近年来,在电荷预测中基于K-means聚类和随机森林的方法逐渐受到重视并有成功应用。本论文的核心思想是将这些方法用于多自旋态可变电荷力场的开发,测试这些方法在血红素体系多自旋态电荷力场中的表现。论文的具体研究思路如下:首先,我们对血红素模型体系和氧气分子复合物进行了非绝热动力学模拟,从轨迹中提取了近40000个血红素模型结构,采用密度泛函方法计算得到体系在各个自旋态下的静电势电荷。然后,论文采用基于K-means聚类和随机森林的方法进行电荷预测测试。针对每种测试方法,我们都构建了两个数据集。一是未进行几何构型优化,体系处于能量较高的状态;二是进行几何构型优化,体系处于局域能量最小点。为了优化预测方法,我们分别引入了距离矩阵,对称函数和人工筛选结构参数作为描述符并进行了系统比较。在基于K-means聚类的方法中,我们加入距离矩阵,比较了基于结构参数和基于距离矩阵两种预测方式,找到了描述血红素模型体系的11个结构参数,使两种预测方式呈现同样好的预测效果。随机森林的方法中,我们不仅应用描述原子周围化学环境的对称函数与随机森林回归算法结合,进行电荷预测,也尝试了采用11个结构参数作为描述符进行电荷预测。本论文得到以下主要结论:1.基于K-means聚类的方法不需要构建复杂的分析模型就可以给出各自旋态下不同结构对应的电荷。且基于K-means聚类的方法采用的是系综平均的思想,比单一模型的描述容错率要更高。2.随机森林回归模型不仅计算效率高,还可实现单一原子的预测,实时更新重要原子的电荷,提供所需原子的多自旋态可变电荷力场参数。3.通过平均绝对误差、均方根误差、相关性系数等参数,展现了两个方法都可以获得较为准确的预测结果,是得到多自旋态可变电荷力场参数的有效方法。总之,本论文使用基于K-means聚类和随机森林的方法分别预测了各个自旋态下血红素模型的电荷,以及几何构型优化后体系的多组态电荷,且比较分析了两种方法的预测效果。当然,本论文的工作只是对血红素力场研究的初步尝试,尚有很多缺点。在未来的工作中我们将进一步完善多自旋态可变电荷力场参数的计算方法。我们相信,本论文也可以为其它基于机器学习的力场开发工作提供借鉴。"
530,多测度融合的海陆分割算法研究,"工作在扫描模式的海用警戒雷达需要监视方圆近百公里的海洋、陆地、岛礁混合的复杂区域。雷达接收的探测场景的回波由地杂波、海杂波、海面目标回波、岛礁回波混合雷达接收机的噪声构成。在小擦地角或者较高空间分辨率情况下,在一些海洋区域海杂波有时会比噪声功率水平低。因此,海用警戒雷达海陆分割的目的就是按照探测场景的雷达回波把探测场景分割为陆地区域、海杂波占优区域和噪声占优区域。而海陆分割的质量直接影响到后续的检测方法选择和检测性能。已有的海陆分割方法主要是基于从雷达回波中提取的单一测度进行场景分割,存在分割质量不高的问题。本文中,我们将致力于利用从雷达回波中提取的多个体现海洋、陆地和噪声差异的测度,通过多个测度的融合实现探测场景的海-陆-噪声三元分割。本论文的主要内容如下:首先,对本文涉及到的图像处理理论进行简单介绍。回顾了机器学习在图像处理中的应用,着重对监督学习中的K-NN算法进行了详细介绍,分析了其优缺点。随后介绍了图像处理中的数学形态学方法,简述了二值形态学、灰度形态学在图像处理中的应用并通过实例演示了各算子的作用和处理效果。其次,本文实现了一种有效的海陆分割方法。结合雷达工作原理和实测数据分析了海杂波和地杂波之间的本质差异,表明了多普勒偏移和初相不是其本质差异,多普勒带宽是其本质差异。因此,我们提出了初相-多普勒偏移不变距离刻画各空间分辨单元回波之间的差异。在该距离下,按照先验信息选择部分陆地区域和海面区域的回波向量作为训练样本并利用K-NN分类器对探测场景进行初分类。最后采用数学形态学处理对初分类结果进一步处理得到海陆分割结果。提出的方法不需要设置任何门限就能够将探测场景正确地分割为海洋区域和陆地区域。最后,本文提出了一种基于K-NN分类器的特征域海-陆-噪三元分割方法。该方法根据海杂波、地杂波、噪声各自特性的不同,利用非高斯性、白化度、多普勒带宽、回波功率以及杂噪比五个特征构成特征向量,并用特征向量间的马氏距离刻画分辨单元间的差异。在该距离下,利用K-NN分类器对探测场景进行初分割,其分割结果进一步经过形态学滤波得到最终的场景三元分割。成功地将噪声区域从探测场景中剔除,实现了更精细化的场景分割。实测数据的分割结果表明提出的特征域K-NN分割方法是有效的。"
531,机器学习在热电材料中的应用,"热电材料是一种可以实现热能和电能直接转换的功能材料,在航空航天中的原子能电池,电子通讯领域的固态制冷,汽车尾气废热发电,以及物联网自供能等领域都有重要的应用价值。新型热电材料的发现对推动热电转换技术的进步有重要意义。回顾热电材料的发展历程,最早可以追溯到Seebeck通过试错法所做出的探索性研究。上世纪50年代,凝聚态物理理论的应用发现了经典的Bi_2Te_3和PbTe等热电材料。近年来,第一性原理计算的发展也极大地促进了如Mg_3Sb_2等新型热电材料的发现。然而,与已知的化合物相比,未知化合物的数量更为庞大,本论文借助机器学习的方法来筛选还没有确定结构的未知化合物中潜在的热电材料。根据经典的Bi_2Te_3材料,我们利用等价电子元素取代构建了一个含有720种化合物的M_2X_3型热电材料库,其中在ICSD数据库中发现了80种具有晶体结构的化合物。我们选用组成元素的物理性质(例如原子尺寸,电负性,密度等)来定义具有通式M~1M~2X~1X~2X~3(M~1+M~2:X~1+X~2+X~3=2:3)的化合物的特征,并利用随机森林+贝叶斯优化方法构建机器学习预测模型。通过模型学习已知结构的80种化合物,获取结构分类的规律,并进一步用来预测未知化合物。研究发现由于用于生成规则的学习样本太少,对于完整预测七大晶系的多任务预测准确度不高。因此,本文进一步修改策略,仅通过已知样本获取是否是与Bi_2Te_3材料一致的三方结构。基于机器学习的交叉验证结果显示,仅判断一个化合物是否是三方结构化合物的单任务预测模型的准确率可以高达0.94。利用参考文献中10种已知结构M_2X_3型化合物数据进一步验证模型,可实现0.90的准确度。因此,本文最终使用该模型来筛选材料库中具有类似三方结构的新化合物,并获得70+个潜在和Bi_2Te_3结构相近的新化合物。本文通过特征选择和探索性数据分析发现了影响M_2X_3型热电材料结构的敏感参数,进一步提出基于电负性、离子半径、熔点等特征构成的规则,此规则也能获得与机器学习模型相当的准确度。然而,仅具有结构相似,尚无法说明该材料就一定是一个好的热电材料。禁带宽度是人们判断一个化合物是否是一个潜在热电材料的重要指标。本文基于Slack关于禁带宽度与阳离子(M)和阴离子(X)之间电负性差值绝对值的经验关系,提出了双重相似性的标准,即将结构相似和阴阳离子平均电负性差相似作为新型热电材料筛选的判决指标,并发现有潜力的新型热电材料如Sb_2TeSeS、Sb_2S_2Te、SbFeTe_3等。"
532,基于svr的Heusler合金的居里温度预测,"由于在能源和医疗等领域潜在的巨大应用价值,高性能磁热材料的开发成为近几十年来科学家和工程师们探索的重要方向。目前已知的具有较大磁熵变的磁热材料,包括Gd及其合金、Mn基合金、镧系化合物等,在实际应用上都存在着一些限制。有别于传统的“试错式”、“炒菜式”费时费力的材料研究,本课题利用机器学习方法计划寻找成本低廉、环境友好的居里温度在室温附近的新型磁热材料。Heusler型磁热材料由于其优异的电学、磁学、力学等物理性能而受到广泛关注。本文通过收集文献中实验测得的Heusler合金的居里温度的数据和构成Heusler合金的不同元素的性质的物理参数,得到用于机器学习的数据集。通过该数据集训练对岭回归、弹性网络、回归树、支持向量回归四种模型进行训练,寻找材料性能-结构之间的关联关系。基于特征的权重分析及筛选实现对四种模型的优化,得到可靠性最高的模型――支持向量回归模型。最后基于支持向量回归模型预测所有可能存在的Heusler合金的居里温度。本次实验共收集了65种不同组分的Heusler合金的居里温度,并从中挑出38种NiMn基Heulser合金数据组成新的数据集,通过两个数据集训练结果的对比,提升模型可靠性。同时对于每种Heusler合金共收集了39种特征,通过特征的权重分析以及验证特征数与拟合结果的关系,筛选出了13个与居里温度相关性较大的特征。利用已有的材料数据,采用机器学习方法研究Heusler磁性合金的居里温度与特征的内在关联。使用优化后的模型,我们对1078种不同组分的Heusler合金的居里温度进行预测,得到了50种不同组分的Heusler合金居里温度均在室温附近。考虑到材料的成本和毒性,最终获得33种潜在的具有应用前景的Heusler合金,大幅度缩短研究周期,为进一步的实验和理论研究,提供了参考和方向。"
533,基于自组织增量学习神经网络的FSW质量评价研究,"搅拌摩擦焊技术自问世以来,由于生产率高、接头强度高等优点,在航空、航天、高铁等领域得到了广泛应用。但由于焊接过程复杂、参数多等特点,在实际生产中尚且存在一定的质量问题。另一方面,随着人工智能的崛起,机器学习在焊接领域中的应用逐渐发展成为一个热门研究方向。在这样的大背景下,为提高搅拌摩擦焊焊接铝合金结构件的质量的稳定性,提升搅拌摩擦焊焊接工艺数字化和信息化的程度,本文设计了一套搭载多种传感器的数据采集系统,建立了一套基于自组织增量学习神经网络的质量评价系统。采用双色红外测温的原理,获得了搅拌头轴肩工件结合处的温度;采用激光测距的原理,获得了搅拌头下压量;采用电容微型摆锤的原理,获得了搅拌头倾角;通过OPC系统对搅拌摩擦焊机床的授权,读取了搅拌头转速以及焊接速度两个参数。在上述方法的基础上,建立了搅拌摩擦焊焊接参数采集系统,为后续的机器学习提供了数据来源。研究了自组织增量学习神经网络的基本原理,利用MATLAB软件编程实现了这种算法,并建立起了相应的模型。为验证该算法的性能,利用一些人工数据集对建立的机器学习模型进行了仿真分析。针对自组织增量学习神经网络的一些不足,提出了改进的自组织增量学习神经网络算法。为进一步验证改进的自组织增量学习神经网络算法的可靠性,通过研究双支持向量回归机算法的原理,利用MATLAB编程软件,对改进的自组织增量学习神经网络和双支持向量回归机建立了各自相应的模型,对两种算法进行性能对比。实验结果表明,改进的自组织增量学习神经网络在模拟效果上与双支持向量回归机的仿真效果相近,但自组织增量学习神经网络算法的训练时间远小于双支持向量回归机。基于不断累积的仿真训练结果,建立起了搅拌摩擦焊质量评价系统,初步实现了从焊接参数到焊接质量的非线性映射关系。并利用从生产中采集到的实际数据,验证了质量评价系统的可行性。"
534,高通量实验和机器学习结合加速硬质高熵合金成分优化,"对于多组元合金,由于存在大量的潜在成分组合,采用传统的经验与试错法使得研发过程缓慢而昂贵。为应对多组元合金成分设计的挑战,我们发展了高通量实验(HTE)结合机器学习(ML)的研发方法加速合金成分优化,并将THE-ML方法用于发展新型非等摩尔比硬质高熵合金(HEA)Co_xCr_yTi_zMo_u W_v。我们设计研发了系列高通量合金制备设备,包含了从原料配置用的多工位粉料分配系统到合金化用的多工位自动电弧熔炼系统以及后续的金相样品制备设备。我们使用高通量实验设备分两步制备潜在成分空间中约1/28的合金样本,期间利用机器学习方法指导实验方案设计。首先,我们单独调整难熔合金元素W或Mo成分,以及通过相结构的特征描述因子选定成分,共计制备111个合金样品。通过三种机器学习算法与四种特征描述因子组合构建12个机器学习方法和120个机器学习模型进行多方法和多模型统计预测。第二步高通量实验针对初始的机器学习模型按照硬度区间预测选择的27个合金成分进行。最终的机器学习模型构建使用了全部138个实验数据,预测的硬度在高(HV>800)、中(HV∈(600~800))、低(HV<600)硬度区域的平均误差分别为5.3%、6.3%和15.4%,相对应区域实验测量偏差分别为1.69%、1.88%、1.87%。此外,我们利用机器学习模型预测了Co_xCr_yTi_zMo_uW_v体系内潜在3876个合金的硬度,构建了全局成分范围内的“成分-硬度”与“描述因子-硬度”关系,讨论了合金成分和物理描述因子对合金硬度的影响规律。通过分析CoCrTiMoW的微观组织结构,理解该合金体系的硬度强化机制和各元素的作用。本工作证实机器学习指导下的高通量实验(ML-HTE)方法为多组元合金的成分设计提供了一种新的有效策略:通过高通量实验和机器学习的双重手段,可以更低的成本加速材料研发速度达百倍以上。"
535,基于机器学习的空间多碎片清除策略研究,"日益增多的空间碎片不断恶化着地球周围的空间环境,也将会是人类在今后进行近地太空行为活动中面临最大的危险之一。主动碎片清除措施(Active Debris Removal,ADR)可以在减少航天器执行任务时与碎片碰撞次数同时降低产生二次碎片概率。本文以空间碎片清除任务中的初始清除范围确定、碎片间转移燃耗估计和空间碎片的质量特性辨识三个问题为研究对象,分别采用机器学习算法中的聚类、集成学习和线性神经网络对以上三个问题的解决策略开展研究。针对多碎片清除任务中的初始范围确定问题,本文利用基于密度的聚类算法(Density-Based Spatial Clustering of Applications with Noise,DBSCAN)对多碎片清除任务初始标范围进行确定。首先阐述了聚类任务的定义、与分类的区别和聚类效果的衡量标准,分析了4种常见的聚类算法的特点;然后通过对空间碎片的运动规律进行分析后采用一种改进的轨道指示器作为衡量空间碎片转移难度的标准,将本问题完全转化为一个聚类任务;仿真结果证明了聚类算法对于解决本章问题的有效性。针对空间碎片间的转移燃料估计问题,本文在权衡估计精度和估计时间这两个指标后提出将集成学习(Ensemble Learning)算法作为航天器在碎片间转移燃料消耗量的估计方法。首先建立碎片间转移动力学模型,求解燃料最优控制问题获取数据集;然后从学习器获取和习得模型结合策略两方面对集成学习算法思想进行探究;最终选用随机森林和梯度提升树两种集成算法进行仿真。仿真结果表明与兰伯特估计法相比集成学习算法估计精度更高且运行时间在可接受的范围内。针对捕获空间碎片后对空间碎片质量特性的辨识问题,首先采用n自由度空间机械臂连接组合体进行数学建模;然后将关于待辨识参数的线性方程组的系数矩阵作为线性神经网络的输入,将各待辨识参数作为网络的权重,基于最小均方算法实现辨识;最终在Adams/Matlab仿真平台上进行仿真,仿真结果表明线性神经网络辨识是一种辨识非合作空间碎片质量特性参数的有效方法。"
536,基于大数据的污染源普查清查方法学研究,"为了加强对环境污染的监督管理,及时了解及记录各企事业单位潜在的环境污染基本信息,我国于2008年开展了第一次全国污染源普查。在第一次全国污染源普查工作中,囿于我国当时的认识及技术手段和数据分析能力有限,存在许多不足之处。当时在污染源普查清查阶段,政府部门仅根据企业的行业分类代码进行筛选,形成一份基本单位名录作为清查阶段的入户依据。但政府部门数据的不完整以及筛选所用的行业类别代码存在大量错误,致使清查基本单位名录存在相当数量的漏失企业,造成工业污染源基本单位名录不准确。我国第二次污染源普查于2018年开始,因此,本研究希望利用大数据及相关技术,以工商数据中的企业经营范围作为基础,识别并纠正行业类别,同时利用互联网大数据技术对基本单位名录进行增补,最终优化污染源普查清查阶段数据处理流程、提升基本单位名录的构建效率和准确度。首先,本研究对可使用的方法进行比较,对政府部门所提供的数据进行评价和筛选,在海量数据处理的背景下,构建机器学习分类模型。以此为基础,按照机器学习处理实际问题的基本思路,首先构造标准数据集并验证其准确性及可用性,利用多种分类算法进行比较分析,择优使用。随后以此构建的标定数据集为训练集,对政府部门所提供的国家工商数据、省工商数据和市工商数据进行预测分类,同时为保证可靠性,利用清查实际入户反馈及其他补充实验进行准确性检验,最终验证本研究建立的机器学习模型的可用性。针对机器学习的模型建立,我们通过几种算法比较后可知朴素贝叶斯分类算法为最佳算法,且经过清查实际反馈检验显示,若以F_1值(准确率和召回率的调和平均数,F_1值越高,代表分类结果越好)为评价指标进行衡量,各数据集F_1值分别相对提升32.92%,21.42%,14.91%。补充实验所得结果相比于原始政府部门数据集,F_1值分别相对提升151.06%、213.45%和132.13%,提升效果较显著。从而验证了标定数据集的准确性以及该机器学习模型通过企业经营范围识别并纠正错误行业类别的可用性。其次,为进一步使得第二次普查更准确,本研究探讨了利用互联网大数据对于基本单位名录增补的可行性。以互联网多源大数据为基础,通过大数据可用性的一般分析原则对数据进行评价和筛选。利用以上经过验证可用的机器学习分类预测模型,对筛选后的互联网数据进行分类预测。使用清查实际入户反馈及其他补充实验进行准确性检验,并分析数据质量。最终互联网增补数据准确率为17.26%,同市工商数据近似。结合实际工作情况,通过补充实验分析,确定互联网增补数据对于企业基本名录的增补贡献度应在4.54%-16.85%。对所得分类结果进行横向及纵向比较,互联网数据相比部门数据,存在较为明显的同质化现象,且在互联网数据中低比例数据同质化更为明显,这是由于互联网数据对企业经营范围的描述相对单一。对于具体行业分类准确程度,部门数据整体较高。互联网高比例数据准确率相比低比例数据更高,低比例数据同部门数据相比,差距较大,可用性也较低。结合清查阶段具体目标,互联网增补数据可在检索缺漏企业中起到重要作用,能够有效拓宽数据获取途径。最后,本研究依据上述利用企业经营范围对相应行业分类进行纠正和利用互联网多源大数据对缺失企业信息进行增补的效果,结合污染源普查实际工作中的部门要求,创新性地提出了基于大数据技术的污染源普查清查阶段基本单位名录编制流程的优化方法,进而为我国第二次全国污染源普查及未来其他环境统计工作提供了方法借鉴。"
537,基于CNN的光学遥感图像分类方法研究,"深度学习技术(如卷积神经网络(CNN))可以在面向大量数据集及其标签时提供准确的分类结果。尽管如此,使用很少的标记数据时,CNN可能会出现各种问题,因为这可能会导致广泛过度拟合的问题。训练CNN,导致接近数以百万计的参数,并需要大量的注释图像样本。在这篇论文中,我们提出使用少量训练数据如何在大量附加注释的数据集中与CNN学习的标签能够有效地将其转移到其他分类任务。本研究计划将应用迁移学习对遥感深层卷积神经网络(CNN)图像的设计、实现和测试进行完整的研究。本文对最新的CNN架构的图像分类进行精细化的表现进行了评价,这些架构在ImageNet大规模视觉识别挑战(ILSVRC)上获得了最佳效果之一,与从零开始的训练相比,这些建筑的图像分类表现如何。尤其VGG和DenseNet。这些预先训练的模型是从互联网上下载的。VGG-16在图像分类方面继DenseNet之后表现出了最好的结果。本文研究了一种基于卷积神经网络(CNN)的模型。数据增强包括所有数据集的标准化和规范化,然后将它们用作训练集。利用迁移学习,采用16层(VGG-16)和Densenet模型的视觉几何架构构建神经网络的基本特征提取。在CNN模型实现中,使用UC Merced,RS19和Eurosat三个数据集图像来训练所提出的模型。本文所提出的分类模型获得了优良的分类精度。此外,本研究表明在数据集有限的情况下迁移学习在光学遥感图像分类中能产生更好的分类结果。"
538,基于机器学习的数据驱动故障诊断方法研究,"随着现代设备的复杂化和大型化,系统的异常检测和故障诊断一直是学术界关注的重点问题。若不能及时发现并处理系统故障,将造成巨大的人员伤亡和经济损失。如果能及时检测出早期故障并隔离报警,将有效避免异常事故的发生。因此,对复杂系统进行合理的故障诊断成为关键手段。目前故障诊断的研究热点主要为基于智能学习方法的数据驱动故障诊断方法,但是传统的智能学习方法尚不能充分挖掘数据中隐含故障特征信息,存在逼近精度不足的问题,且故障诊断模型中参数不确定性的情况大量存在,导致故障诊断精度波动大及精度不够的问题。为此,本文从故障诊断的特征提取角度及智能故障诊断模型构建角度,分别提出基于机器学习算法的隐含故障特征提取方法以及集成多种机器学习算法的故障诊断模型,以提高故障诊断的精度。基于UCI机器学习数据库中的数据集对上述方法及模型进行了分析验证,并通过注塑机拉杆的故障诊断实例来验证所提方法的有效性。本文的主要工作如下:(1)提出基于极限梯度提升(eXtreme Gradient Boosting,XGBoost)算法的隐含故障特征提取方法。研究此方法的深层次特征提取能力,并分析使用提取的隐含故障特征前后所构建的支持向量机(Support Vector Machine,SVM)、神经网络、随机森林故障诊断模型在测试数据上的诊断预测准确度变化,验证方法的有效性及通用性。(2)提出基于LightGBM算法的故障诊断模型。研究该模型在复杂数据背景下,对故障诊断问题的分类识别能力,对比该诊断模型与几种传统故障诊断模型及深度学习模型的故障诊断性能。研究不同参数下,基于LightGBM算法的故障模型诊断识别能力的变化情况。考虑参数不确定性对模型诊断预测性能的影响,对贝叶斯优化算法的高斯过程(Gaussian Process,GP)及采集函数进行改进,提出基于改进贝叶斯优化(Bayesian Optimization Algorithm,BOA)的LightGBM故障诊断模型,并研究了改进BOA-LightGBM故障诊断模型与网格搜索LightGBM故障诊断模型与随机搜索LightGBM故障模型的诊断预测性能。(3)将机器学习算法应用于拉杆的故障诊断,使用XGB-BOA-LightGBM模型对拉杆故障进行诊断识别,解决拉杆的实时故障诊断预测问题。讨论分析了不同数据特征下的拉杆故障诊断效果,并研究分析XGB-BOA-LightGBM故障诊断模型对拉杆故障的实时诊断预测效果。"
539,密封电子设备活动多余物定位方法研究,"密封电子设备是指卫星、导弹、发动机和无人机等这些具有特定功能的系统或系统内部的重要组件。多余物问题一直是影响密封电子设备可靠运行的重要原因。随着被测设备的体积越来越大,检测出的多余物的清理工作变得非常困难,多余物的定位问题开始受到越来越多研究人员的关注,多余物的定位既可以帮助工作人员清理多余物,也能指导研究人员对多余物进行预防和控制。本文针对密封电子设备的多余物定位方法展开了深入的研究。首先,搭建多余物定位实验系统,包括对声发射传感器的选型和布局;设计密封电子设备实验模型,以模拟实际电子设备的结构;研制多通道声音采集装置,实时同步采集多路多余物检测信号;确保采集的多余物检测信号能充分反映多余物的位置信息;研究传统声发射源定位方法和机器学习领域的分类算法,对比两种方法的优缺点和用于多余物定位的可行性。其次,对多余物信号进行分类,研究由多余物位移引起的声发射波在介质中的传播特性,分析多通道检测信号的时频域特性,验证利用波的衰减特性进行多余物定位的可行性;对多余物检测信号进行预处理,针对本文实验的多余物信号的特点,设计两级双门限脉冲提取算法;然后对多余物脉冲信号进行时频域分析,提取表征多余物位置的特征量,并从信息增益和分类精确度的角度对定位特征进行分析,选择对多余物的定位价值最大的特征作为定位特征。最后,针对传统多余物定位方法定位精度低,应用受限等问题,提出基于机器学习的多余物定位方法。从单分类器的定位研究扩展到多分类器集成学习的定位研究,设计基于支持向量机和随机森林的多余物定位模型;在基本模型确定之后,进一步对定位模型进行优化,提高模型的定位性能。与单个分类器的多余物定位模型相比,基于随机森林的多余物定位模型有更好的泛化能力。实验结果表明,与前人的多余物定位研究相比,基于机器学习的多余物定位方法解决了传统多余物定位精度低,普适性差的问题。"
540,基于北斗导航卫星的前向散射波飞行器探测方法研究,"现代战争已经从以前的兵戎相见向着高科技含量方向发展。高科技战争中,雷达扮演越来越重要的角色。现在常用的雷达大部分是有源单基地雷达,有源雷达发射信号功率大,容易被敌方发现,单基地雷达对隐形飞行器探测能力有限,这些使其在雷达应用遇到了不小的挑战。为了提高雷达对目标的探测准确性和自身安全的考虑,研究雷达接收机为无源的双基地雷达具有重要意义。本文研究基于北斗导航卫星的前向散射波飞行器探测方法研究,以北斗导航卫星信号为雷达发射机信号源,实现雷达接收机和雷达发射机收发分离的天地双基栅栏雷达系统。人们对使用人造卫星作为辐射源的应用只是有少量以GPS卫星信号作为辐射源的报道。从实验中可以看到以人造卫星为辐射源的双基雷达的诸多优点,架设位置灵活,有效探测范围大,生存能力强,目标侧视轮廓可信度高等优点。本文在基于北斗导航卫星前向散射波隐形飞行器探测方法研究中主要研究了三个内容,分别是传统双基地雷达系统,基于卫星辐射源的天地双基雷达系统和基于机器学习的飞行器目标识别与分类。本文首先介绍了课题的研究背景和意义,国内外研究现状等背景信息。然后介绍了传统双基地雷达的工作原理,目标全息信号的形式以及推导化简得出改进的全息信号的形式,目标多普勒频率像和目标侧影轮廓的关系,改进全息信号和目标侧影像中相位和高度差的对应关系从而实现当目标飞行器穿越双基地雷达基线时,雷达对目标的检测,识别与跟踪。对传统双基地雷达系统仿真实验和性能分析。接着,本文研究了北斗导航卫星信号作为雷达外辐射源的性能分析,对全球四大卫星导航系统的广播信号作为双基地雷达辐射源的优势进行对比,并建立北斗导航卫星出站信号模型以及北斗信号模糊函数分析。之后,本文建立基于北斗导航卫星辐射源的双基雷达系统方案并对其进行仿真实现和性能分析,观测目标飞行器飞越雷达基线时前向散射信号的变化情况。最后,本文对观测到的目标飞行器的全息信号要素进行特征提取和特征分类,使用稀疏自动编码器和卷积神经网络两种方法对目标飞行器进行分类并对两种方法进行比较提高分类准确率。"
541,基于支持向量机和深度学习的车牌识别技术研究,"车牌识别是一种计算机视觉技术,其运用数字图像处理和模式识别的相关知识完成汽车牌照的识别,汽车牌照相当于汽车的身份证,通过与车辆绑定的唯一标识对其进行监管,能够让交通管理更加高效和便捷。本文在调研传统车牌识别技术的基础上,分别对车牌定位、有效车牌判断、字符分割和字符识别四大技术进行了完整且详细的论述,旨在解决目前传统车牌识别算法存在的问题。其主要研究内容如下:1.论述了单一特征如边缘或颜色特征定位算法的局限,并引入文字特征定位的方法,文字特征定位的方法可以很好的弥补边缘和颜色特征定位的不足,在综合考虑应用场景以及算法效率等方面之后,最终采用边缘、颜色和文字等特征相结合的方法进行车牌定位。2.无论使用边缘、颜色和文字等特征结合还是其他的车牌定位方法,都不可能滤除现实场景中的所有干扰,在定位出车牌的同时可能会产生一些类似车牌的干扰图像。为了在候选图像中筛选出有效车牌,使用机器学习领域中的支持向量机模型进行分类训练以判断候选图像是否为车牌,从而得到最后的车牌图像。3.由于我国车牌包含特殊的中文字符,这也要求字符分割算法需要很好的适应中文。在调研相关资料后,使用轮廓和先验知识相结合的方法实现车牌字符分割,并通过特殊字符平移的方式定位中文字符的位置,从而弥补传统分割算法对中文支持较差的不足。同时,把所有分割好的车牌字符图像处理成20×20像素大小,该像素大小的图片可以正常且清晰地显示车牌字符,还可以在不影响车牌字符识别率的情况下减小网络的计算量。4.本文应用了深度学习的相关技术,并提出了一种改进的卷积神经网络LeNet-5模型用于车牌字符识别。通过TensorFlow深度学习框架以及可视化工具TensorBoard绘制网络模型的训练准确率和损失函数对比曲线,对原始卷积神经网络LeNet-5模型中的参数进行了多项修改,根据本文数据集的测试结果可以发现,最终改进的卷积神经网络LeNet-5模型与传统人工神经网络模型相比,其具有更高的字符识别率,更好的特征分类效果和更少的训练迭代步数。在上述研究的基础的上,本文主要算法的辨识效果为:在车牌定位部分,使用边缘、颜色、文字特征结合SVM模型的车牌定位方法,在常规环境下车牌定位率可达96.8%,在相对复杂环境下车牌定位率可达89.9%以上,其中训练的SVM模型FScore指标达96.84%;在车牌字符分割部分,使用字符轮廓结合先验知识的车牌字符分割方法,对中文字符的有效分割率达96.6%,英文字母和数字的有效分割率达97.8%;在车牌字符识别部分,使用改进的卷积神经网络LeNet-5模型,最后的中文识别率达99.2%,英文字母和数字的识别率达99.6%。"
542,基于协作式道钉的车流量检测方法研究,"交通信息的采集是智能交通系统运作的基础,数据处理关乎交通信息的准确性与合理性。本文研究基于智能道钉(Smart Road Stud,简称SRS)系统的多车道车流量检测方法,SRS系统在检测设备的成本、功耗、安装与维修费用、检测准确度、设备对环境的普适性等因素上都有其优势。本文介绍了车辆检测原理以及智能道钉系统,提出了多种检测车流量的方法,包括车辆波形提取算法、分别基于地磁理论和机器学习的车辆位置识别算法、协作式道钉车辆检测方法等,利用道钉结合上述算法可以实现多车道车流量的检测,包括存在不规范驾驶车辆的道路(越线、压线)、交通流较大的道路(存在多车并行)、多车道道路等。首先,介绍智能道钉系统的主要结构,以及智能道钉采集与传输数据的方式和应用场景;从原理方面分析车辆周围地磁场的空间分布状况,完成车辆周围磁场分布建模,得出车辆周围磁场分布的仿真波形。地磁理论及车辆周围磁场分布仿真为车流量检测提供理论依据;其次,基于地磁检测原理设计单道钉双车道车辆检测算法,借助团队基于各向异性磁阻传感器(Anisotropic Magnetoresistance sensor,简称AMR传感器)研发的的智能道钉系统,采集车辆经过位于车道线上的SRS时的地磁数据,结合地磁仿真结果获取车辆位置判别特征,设计数据预处理、波形提取、单点车辆位置判别、基于地磁理论的双车道车辆检测算法;再次,研究监督学习方式决策树的构建原理与剪枝原理,在提取波形的基础上提炼有效波形特征,构建决策树完成对车辆位置的判别;研究无监督学习自组织神经网络的原理,训练出判别车辆位置的自组织映射网络,二者均可准确判断车辆位置,完成基于机器学习的双车道车辆位置判别算法的设计;最后,通过多道钉协作判别的方式提高多车道车辆检测精度。为解决单道钉检测双车道车流量时准确度受限较多的问题,如多车并行、非正常驾驶等工况,基于多个地磁道钉互相校准提高检测精度以检测断面车流量,此外,协作式道钉可判别车辆越车道线行驶、多车并行等情况,也使得算法可以适应拥堵的交通环境。本文提出的车流量检测方法弥补了交通量检测方法的缺陷,可准确检测多车道车流量,可为智能交通系统提供可靠的车流量信息。"
543,基于强化学习的汽车涂装线作业优化排序研究,"我国于2015年5月提出的《中国制造2025》十年行动纲领,旨在寻求制造业的转型升级,其中,制造智能化是我国迈入制造强国的重要途径之一。汽车工业是制造业的重要组成部分。近年来,汽车制造业由过去的大规模、高增量的生产模式逐渐转向柔性生产模式,更加注重对客户的个性化服务,因此,如何灵活应对客户个性化需求、如何进一步降低生产成本成为汽车制造企业面临的难题。本文针对汽车涂装线的作业优化排序问题开展研究。在汽车涂装线作业优化排序问题上,国内外学者提出了各类算法进行求解。目前针对此问题的优化算法以启发式算法为主,且大多数只关注降低颜色切换次数这一单一目标。由于启发式算法结构较为固定,导致其寻优效果常常受到限制,尤其是在大规模或复杂问题域中。本研究中,为使涂装线作业优化排序问题更加贴近实际生产,考虑降低颜色切换次数和降低总装需求延误两个目标,同时在算法上寻求新的尝试,提出基于强化学习的优化算法。具体工作如下:首先,分析汽车涂装线作业优化排序问题以及现有优化算法的解决思路,梳理本问题流程,明确涂装线作业优化排序问题范围,掌握本问题的关键点,提出本研究要解决的问题。其次,对汽车涂装线作业优化排序问题进行抽象提炼,明确本问题的目标函数和限制条件,提出本问题的数学模型。然后,将汽车涂装线作业优化排序过程抽象为马尔可夫过程,设计基于强化学习的两种优化算法,传统Q学习算法和启发式Q学习算法,同时设计遗传算法作为对比算法。最后,设计对比实验,通过实验算例对比各类算法在汽车涂装线作业优化排序问题上的表现,比较各类算法的优劣,验证了强化学习算法在汽车涂装线作业优化排序问题上的实用性。本研究为解决涂装车间作业排序问题做出新的算法尝试,并试图为大数据时代基于数据驱动的涂装车间生产调度问题提供新的解决方案。"
544,基于无人机玉米出苗率估算与光谱特性的氮素诊断,"基于无人机遥感作物长势监测与光谱特性的营养诊断技术研究,是现代农业生产实现过程化管理与数字化决策的重要手段,也是近年来智慧农业研究的热点。本研究针对宁夏滴灌玉米生长发育进程中存在的数字化信息获取手段单一、信息采集基础设施薄弱、田间动态管理不精准等问题进行研究与探讨。采用无人机获取玉米苗期田间数字图像信息,运用数字图像处理技术提取玉米出苗状况,建立基于无人机遥感的玉米出苗率预测模型;采用高光谱成像系统获取玉米各生育时期功能叶片的光谱信息,同步测定玉米功能叶片的含氮量,通过机器学习等算法建立玉米氮素营养的高光谱反演模型,为玉米高产和氮素状况准确评估提供技术支持,对优化玉米滴灌水肥一体化精准种植技术有着极其重要的意义。具体研究内容如下:(1)无人机搭载数码相机对玉米出苗率的估测。通过获取玉米苗期高清图像,运用MATLAB中ORB算法与距离加权融合算法合成无人机图像,通过二值化、腐蚀膨胀等深度优化处理技术得出玉米苗期图像轮廓,然后运用MATLAB八位连通域和ARCMAP 10.3计算方法自动规划路线并计算出玉米的出苗数量。同时,结合田间人工调查数据,采用线性回归分析方法,建立了人工计数和无人机获取玉米出苗株数之间的线性关系模型。结果表明,线性回归关系模型的决定系数R2、RMSE和nRMSE分别为0.895,4.359和2.436%。(2)基于400nm-1OOOnm全波段高光谱玉米氮素营养诊断。根据偏最小二乘法(PLS)建模集和预测集得出的结论,PLS模型结合De-trending预处理方法与原始模型建模集相比决定系数R2从0.527降低至0.519,均方根误差RMSE从0.372增加至0.374;而预测集的决定系数R2从0.578增加到0.621,预测集的均方根误差RMSE从0.383降低到0.362。根据1种原始处理(RAW)与平滑滤波器(SG)、变量量标准化校正(SNV)、附加散射校正(MSC)、去趋势算法(De-trending)、基线算法(Baseline)一阶导数算法(1-Der)和二阶导数算法(2-Der)等7种预处理方法在PLS进行建模,得出PLS-De-trending预处理模型是7种预处理方法最优模型。在通过连续投影算法(SPA)对De-trending预处理进行特征波段优选,获取到 420.551nm、425.352nm、444.558nm、468.566nm、506.978nm、511.780nm、843.086nm、895.903nm、919.911nm等9个波段。该算法不仅有效提升精准性与计算速度,又使全光谱的波长数量下降了 92.8%。在波段提取过程中减少了计算工作量的同时,还有效提高建模效率和稳定性。(3)反向传播神经网络(BP)搭建的回归模型相对于PLS-SPA-De-trending模型的建模的精确度明显提高。通过BP神经网络构建搭载7种预处理全光谱波段与原始全光谱波段的建模集模型决定系数R2都能达到0.778以上,平均决定系数R2从PLS-SPA-De-trending模型的0.523提升到0.893;其中SNV、MSC、Baseline、1-Der、2-Der等5种预处理建模集模型精度都达到0.905以上,而预测集模型RAW、SG、MSC、De-trending、Baseline等预处理建模集模型决定系数R2都达到0.543以上。(4)支持向量机(SVM)搭建的回归模型相对于PLS模型的建模精度也有明显提高。通过SVM构建搭载7种预处理全光谱波段与原始全光谱波段的建模集模型决定系数R2都为0.529以上,平均的决定系数R2更是根据PLS-SPA-De-trending模型的0.523提升到0.612。其中,预测集模型1-Der、2-Der决定系数R2均达0.637以上。(5)利用随机森林(RF)算法对不同预处理下的180个玉米叶片的全波段光谱,建立氮素营养诊断估测模型。预测集在7种预处理中,拟合优度最大值为59.63%,均方误差RMSE最小值为0.352(拟合优度的作用类似于回归分析中的R2)。预测集模型均方误差RMSE平均范围为0.352-0.602。本文研究表明:精度高、可靠性强的SVM模型结合二阶导数(2-Der)预处理所建模型(预测集R2=0.710,RMSE=0.363)为最佳玉米氮营养光谱预测模型。"
545,基于机器学习的水稻病害识别和叶龄检测算法研究,"随着农业信息智能化的高速发展,传统的靠天吃饭模式演变成为由智能设备监控生产过程并进行自动调控的新型农业模式。如何对这些智能设备采集的数据特别是其中的图像数据进行处理,从中提取出其中的有用信息,并与实际的生产调控措施相结合,从而推动农业生产的高效、快速运作,具有重要意义。本研究将图像处理和机器学习应用于水稻的病害自动识别和叶龄自动检测中,这一方法相比于传统的人工识别和诊断方法更高效、准确。主要内容包括:首先,介绍了机器学习算法和图像处理的基本理论,为后续的病害识别算法研究和叶龄诊断算法研究提供了相应的理论指导和技术方案。接着,在对水稻病害进行识别的算法研究中,采用了机器学习方法进行水稻病害识别。本文主要研究三种水稻常见病害,即稻瘟病、白叶枯病和细菌性条斑病。具体内容包括:首先,对水稻病害图像进行预处理,然后分割出水稻病斑,建立对应的水稻病害图像集。然后,针对不同病斑的病理外在表现,提取多个方面的特征,再采用主成分分析法对提取的特征进行了优化。之后,分别采用BP神经网络和支持向量机建立模型,对优化后的特征进行分类测试,选择了其中识别准确率更高的BP神经网络作为最终的分类模型。最后,对BP分类模型提出改进,用遗传算法来对BP算法中的权值和阈值的初始选择过程进行优化。实验结果表明GA-BP改进算法具有可行性,提高了病害识别准确率。然后,在对水稻叶龄进行诊断的算法研究中,首先采用传统的图像处理方法对水稻叶脉进行提取,在传统算法对叶脉的提取效果不佳的情况下,提出一种新的基于聚类均值判断的方法用于提取水稻叶脉,改善之后的叶脉提取算法可以成功地提取出水稻主叶脉。并且使用该算法分别对有病害的水稻叶片和无病害的水稻叶片进行验证,算法提取效果良好。同时以该算法为基础,再结合叶脉偏向法,经过实际测试实现了叶龄诊断。最后,结合水稻病害识别结果和水稻叶龄诊断结果,在识别病害的基础上,以叶龄诊断技术为核心,针对不同的病害,然后根据不同叶龄阶段对稻田及时采取相应的管理措施,进行寒地水稻智慧调控。"
546,面向医疗领域的智能诊断模型研究,"近年来,各个医院的就诊人数不断增加,2018年,全国医疗卫生机构总诊疗人次达83.1亿人次,平均每人至医疗卫生机构就诊6.0次,以至于很多患者不能够获得及时和高质量的诊疗,该问题在基层医院尤其突出。基层医院医疗资源的匮乏是目前医疗资源与需求极为不平衡的典型表现,很多患者由于床位限制、医疗水平有限等原因不能够及时地就诊并且基层医院的医务人员专业水平的参差不齐,使得治疗效果难以保证。随着近几年计算机的不断普及以及计算机技术的不断进步,越来越多的医院开始重视电子病历的记录从而产生了大量有价值的医疗数据。同时,自然语言处理和其他机器学习模型近几年也获得了突飞猛进,这些都为电子病历的处理和智能诊断提供了数据和技术的支持。所以本文主要针对的是电子病历的诊断模型构建,本文的具体工作包括以下几个部分:(1)语料库以及实体识别模型的构建:本文首先构建了实体识别的语料库,语料中包含五种类型的实体,包括症状、治疗、异常检查结果、疾病、检查。接着在实体识别的技术上进行了调研,并且在调研的基础上对比了不同模型在电子病历上实体识别的表现。本文将实体识别任务看作为序列标注的典型任务,所以主要对比了CRF、Bidirectional Encoder Representations from Transformers(BERT)、LSTM、LSTM-CRF三种实体识别模型。LSTM能够记忆更长的句子的上下文知识,CRF能够很好的描述序列标签之间的相关性,进一步提高实体识别的效果。并且针对LSTM-CRF模型改进了词向量并获得了最优的效果,我们将基于词的向量和基于字符的向量相结合。在本文我们使用LSTM和CNN来抽取字符特征,其中LSTM主要抽取每个词中字符的序列特征,CNN用来提取每个词中字符的局部特征也就是n-gram特征。(2)再入院诊断模型的构建,现如今有大量的再入院病人的出现,这些病人大大增加了医疗支出。我们提出了再入院风险诊断模型的构建,使用LSTM来抽取按照时间排列的医疗实体的特征,并且加入了病人的基本信息来诊断病人是否有再次入院的可能。我们还对比了基于CNN的再入院的模型。(3)疾病诊断模型的构建,在基于大量关于疾病诊断模型的调研之后,对比了不同模型在疾病诊断上的表现。包括传统机器学习模型和深度学习模型。在传统的机器学习中采用了决策树,随机森林,贝叶斯网络,感知机,k-近邻以及多模型融合的方法。在深度学习中,我们对比了深度信念网络、卷积神经网络和深度神经网络三种方法,并且介绍了不同的图表示学习方法,除此之外还加入了attention机制,并针对不同的embedding做了对比实验。"
547,深度学习乳腺超声图像分类器及其可解释性研究,"乳腺癌疾病诱发因素众多,致死率高,严重危害女性身体健康。超声检测操作简单、无痛无创、无辐射是乳腺肿瘤前期诊断的主要影像学方法。超声检测的数据形式是乳腺超声图像和超声报告,美国放射学会制定的乳腺影像学报告及数据系统BI-RADS对超声报告进行了严格的规范。依据超声数据和医生专业知识的诊断方式主观性强,高度依赖医生个人能力,计算机辅诊系统CAD结合人工智能和医学诊断技术,辅助发现病灶,分类病灶,有助于降低漏诊率和提高医生工作效率。早期的辅诊系统在乳腺超声图像上通过人工或算法提取图像的纹理和形态的特征,组成特征向量,训练机器学习模型。近几年,以“深度神经网络”为代表的深度学习理论逐渐成熟,其表征空间维度高,提取出的特征比人为设定的特征有更强的泛化性能,不断应用在健康和医疗领域。为了探索深度学习在乳腺癌诊断上的应用,本论文在乳腺超声数据集上有针对性的设计了基于CNN的分类器,依据专业医师的标准病灶分割,在训练集准确率ACC为0.7866,验证集为0.8。此外,超声样本天然存在的正负样本不均衡问题,导致相对重要灵敏度偏低,论文试验了两种优化损失函数的方法并取得了良好的效果,验证集上Bias-Loss方法ACC为0.8222,敏感度为0.8667,特异性为0.7556;Am-Loss方法ACC为0.86,灵敏度为0.9565,特异性为0.78,两种方法都有效的提高了准确率和灵敏度。应用深度学习方法来辅助决策,尤其是对医学影像进行辅助诊断时,决策过程和输出结果的可解释性不足,与循证医学理念存在较大的差异。限制了医生和患者对算法的信任度。为了提高模型的可解释性,推进深度学习算法在乳腺肿瘤诊断上的应用,论文在设计诊断系统的同时尝试通过热度图和语义回归两种方法对模型进行可解释的评价,热度图有效的发现了模型关注区域,语义回归帮助发现了模型的重要特征。最后,论文整合上述工作,开发了具有自动分割病灶,分类病灶,可解释描述功能的乳腺超声辅诊系统的客户端程序。"
548,基于机器学习的球形肿瘤中光场分布预测及优化方案研究,"在大健康时代,医学领域正在蓬勃发展。人们也正在尝试运用物理手段来进行疾病的治疗,例如对病灶部位进行光照。光动力疗法就是一种通过光照产生活性氧,进而杀死癌细胞的方法。光动力疗法在肿瘤治疗方面相对于传统方法体现了巨大的优势,但光动力疗法却依然存在治疗效果不稳定的问题,究其原因主要是缺少精准化治疗的标准。光动力疗法中光分布是一项重要的研究内容,本文开展了基于蒙特卡罗方法及机器学习算法对球体肿瘤内部光通量分布进行预测和优化的研究。应用蒙特卡罗方法建立了波长为640nm的红光照射下的球体肿瘤模型,并对其内部光通量分布进行研究发现了:入射光子的数目对于肿瘤内部光通量分布影响很小;光源到肿瘤的距离越小,肿瘤内部光通量分布越均匀;肿瘤半径越小,肿瘤内部光通量分布越均匀;将光源对称放置在肿瘤周围时,随着光源数目增多,肿瘤内部光通量分布越来越均匀。将采集的不同光照条件及不同肿瘤大小时肿瘤内部光通量分布建立成数据集,构建机器学习中的CART决策树算法使用单光源条件下光通量分布数据集进行学习,发现对肿瘤内部光通量分布的影响从大到小的顺序为:肿瘤半径、光源到肿瘤的距离、光子数和光源位置。随后构建机器学习中的GDBT决策树算法并使用多光源条件下光通量分布数据集进行学习,解决了多光源照射情况下光源的放置问题,通过精准计算对光源放置方案进行了优化。本文将蒙特卡罗组织光学模型与机器学习方法相结合,运用蒙特卡罗方法构建模型,研究了各物理量对肿瘤内部光通量分布的影响;产生训练数据集,运用机器学习对各物理量的重要性进行排序,并且对理想光分布下的光源放置方案给出建议,对于精准化剂量光动力疗法中光分布的控制具有重要的指导意义。"
549,基于网络分析和机器学习的肝癌中糖链相关基因筛选,"中国癌症发病率和死亡率均较高,随着二代测序的飞速发展,运用生物统计学和计算机语言对生物学问题的挖掘也变得如火如荼。因此,应用生物信息学揭示并解决生物学问题,在科学研究中扮有越来越重要的角色。糖链相关基因如糖基转移酶、糖苷水解酶,已被证实与肿瘤的迁移、复发、抗化疗药物等密切相关。已有众多针对癌症发生发展的糖链相关基因及其功能对癌症表型的影响与分子机制的研究。本课题组前期发现TCGA数据库的RNA-seq数据显示,在多种癌症组织中,多种糖链相关基因的表达量都有显著改变。基于以上发现,本实验将聚焦于肝癌中差异表达的糖链相关基因,运用机器学习和加权基因共表达网络(WGCNA,Weighted Correlation Network Analysis)网络进行分析,旨在找到在癌症的发生和发展中发挥着重要作用的糖链相关基因,及与其协同变化的其它基因,从更大的尺度去整体把握糖链相关基因的变化,进一步找到关键基因(hub gene),并对其功能进行生物信息分析。本课题选取TCGA和GTEx数据库中糖链相关基因的肝癌表达谱,比较了三种机器学习模型(随机森林,支持向量机,逻辑回归)预测癌症发生的能力,发现三者的AUC值分别为0.9836,0.9903,0.9986。结合混淆矩阵的结果,发现三种模型对癌症样本预测能力比正常样本强。综合比较三个模型的AUC、混淆矩阵和误差率,发现逻辑回归是三种模型中效果最好的模型。利用逻辑回归,共筛选到16个和肝癌发生发展密切相关的有统计学意义的基因,分别为FUT7、FUT8、HYAL3、CHI3L1、PIGM、MGAT2、GLT6D1、AMY2B、A4GALT、LFNG、MAN1C1、PIGB、HEXB、NEU4、GALNT13、FUT9。同时,为了进一步研究糖链相关基因的相互作用网络,对TCGA和GTEx数据库中肝癌表达谱进行WGCNA的构建。通过计算任意两对基因之间的皮尔森相关系数的绝对值,选择最佳加权系数6时,R~2最大并接近0.9,做出模型拟合效果最好的WGCNA。在此基础上,将遗传相似性矩阵转换为邻接矩阵,最后获得13个基因表达相关性模块。运用验证集对对每个模块进行保守性验证,发现gold、turquoise和blue模块的保守性最好(Z>10)。通过模块与表型的相关性分析,发现turquoise模块和blue模块和表型的相关性最高,高达0.8,0.73,这表明其在癌症发生发展中发挥着重要的作用。对这两个模块进行GO和KEGG富集分析,发现富集到很多重要的生物学通路,如蛋白质运输,RNA定位等。在以上结果的基础上,本研究利用机器学习和turquoise模块中共有的重要基因NEU4进行了转录组验证。在NEU4基因过表达的转录组中发现,83个潜在转录因子中有15个发生差异表达,且这些转录因子均在turquoise模块中,验证了turquoise模块的可信度以及相关基因在癌症发生发展中的重要性。同时在NEU4基因过表达的转录组中,显示有差异的B4GALT2和PLOD3基因也发生了差异表达,证明了网络构建的准确性和可重复性。本研究基于机器学习和WGCNA,构建了一个与肝癌密切相关的糖链相关基因互作网络,并筛选出重要的糖链相关基因,为下一步探索这些基因的生物学功能和意义提供思路,同时也为肝癌糖生物学的发展提供一定的线索,为肝癌的诊断和治疗提供了理论依据和数据支持。"
550,基于概率关系自编码器的药靶关系预测研究,"药物的设计与研发是依据对生物靶标和分子活性的知识寻找有效治疗药物的过程。药物小分子大多是一种有机小分子或化合物,它通过激活或抑制生物分子功能,对多种被称为靶标的蛋白质产生特殊的影响,从而对疾病产生治疗效果。药物与蛋白质靶标之间的相互作用在药物研究中具有重要意义,如促进药物发现过程、药物副作用预测和药物再利用等。最初的研究方法主要采用临床生物实验方法,保证了实验结果的有效性。而实验中想找出与目标靶蛋白有结合作用且具有高亲和力的化合物是很具有挑战性且成本昂贵的过程,这就需要开发设计出更有效和更高效的生物计算方法来预测药物-靶标的相互作用。生物计算方法能够从积累的大量数据中挖掘出潜在特征。同时,计算方法的预测结果能够使生物实验更有针对性,节约成本。目前用于预测药物靶标关系的计算方法主要分为三类:(1)基于配体的预测方法;(2)基于靶标的预测方法;(3)机器学习方法。基于配体的预测方法通常用于蛋白质的三维结构信息未知时,依赖于配体的结构和活性之间的关系设计发现药物。基于靶标的方法可以获得较为精确的结果,但是需要有蛋白质靶标的三维结构,通过计算模拟出药物和蛋白质结合的空间大小,形状和结合样式,进而预测药物和靶标之间的结合亲和力。机器学习方法尤其深度学习技术在各个领域取得不错的效果,越来越多的研究者使用机器学习方法在药物靶标关系预测问题上提出了很多创新性的思路。基于上述说明,本文提出了一种基于概率图模型的方法,设计了对应的变分自编码器用于预测药物靶标关系。根据数据集的特点,设置了两类对比实验:结合关系预测和结合亲和力预测。我们在几个常用数据集上做了不同的实验对比,结果显示,我们的方法在各个实验中都有不错的表现,甚至在一些实验中达到最优的结果。另外,利用概率图模型的特性,后续工作中还可以扩展我们的方法,使得模型对于给定的蛋白质,能够直接计算出与其结合的药物特征。"
551,基于图表示学习的药物组合预测研究,"复杂疾病的致病机理复杂,如果使用单种药物进行治疗,容易产生抗药性。药物组合治疗具有高效和低毒等特性,正在成为一种新的复杂疾病治疗手段。尽管人们开发了高通量药物组合筛选平台,但是进行药物组合实验所需的金钱和时间代价很大。因此需要一种算法帮助找到潜在的协同的药物组合,进一步的缩小药物组合实验范围。目前药物组合预测模型可以分为四类:基于表达数据的药物组合预测模型、基于PPI网络的药物组合预测模型、基于代谢路径的药物组合预测模型和基于药物相似性的机器学习药物组合预测模型。这些模型存在数据有偏、结果差和可用数据少等缺点。本文提出一种基于图表示学习的药物组合预测算法NEMNDC(Network Embedding framework in Multiplex Networks for Drug Combinations),改进了现有的基于药物相似性的机器学习药物组合预测模型。首先,通过部分的药物组合数据对每层药物相似性网络进行重要性评估;然后,使用二阶有偏随机游走进行网络采样,得到随机游走的路径,并根据路径生成训练模型所需的正负样本;随后,通过构建SkipGram模型学习药物节点的向量表示;最后,使用随机森林分类器进行药物组合预测。在药物组合预测任务上,本文评估了多层网络和单层网络对NEMNDC算法的影响,结果说明NEMNDC算法可以有效整合数据,并且对于每层网络的信息没有强的偏向性。使用NEMNDC算法预测的药物组合结果中,前6对未包含在已知药物组合数据集中的药物组合已经有5对被生物和临床实验验证是协同的药物组合。对另一对药物组合通过药物靶标、GO和Pathway分析,发现极有可能是协同的药物组合。本文还将NEMNDC算法应用在药物-药物关系预测任务上,通过比较INDI、PSL和Mashup算法,说明了NEMNDC算法在药物-药物关系预测上也很准确和适用。NEMNDC算法不仅解决了之前基于药物相似性的机器学习药物组合预测方法中存在的特征维度固定的问题,而且构建的药物节点向量中包含了多层网络的拓扑信息。本文提出的多层网络重要性评估策略可以更好地为多层网络数据整合工作提供指导。同时在药物-药物关系预测上使用NEMNDC算法得到很好的结果,说明其适用性,不仅仅适用于药物组合预测,也适用于药物-药物关系预测和药物重定位等。"
552,基于分词统计模型的绝句创作系统的研究与实现,"人工智能技术发展日新月异,其应用领域也越来越广泛.为扩大人工智能在人类文化领域的应用,“微软小冰”通过不断的提升,于2017年5月,发布了一部100%由人工智能创作的现代诗集――《阳光失了玻璃窗》,体现了人工智能人文,艺术领域的强大创作能力。然而,目前对于中国古代诗词的创作,还未形成比较成熟的方案.本文在人工智能用于中国古代诗词的创作方面,进行较为大胆的尝试。通过研究,并且,实现了一套完整的基于分词统计模型的绝句创作系统(Chinese poetry creation system,CPCS)。本文的主要创新工作,如下:在研究,分析了中国古代诗词的文字、章法和机器学习相关算法的基础上,设计实现了一个具有人机交互、中国诗词文章分析、中国诗词文章学习,中国诗词文章规则匹配、机器个性塑造和诗词创作等几大功能的智能系统。通过对上百篇的中国诗词文章的学习,使系统基本具备了,创作五言绝句和七言绝句的功能。以极简主义为原则,设计了人机交互方式.用户只需简单地输入一条带主题的创作指令,即可得到系统的创作结果;在系统进行中国诗词文章分析和学习时,通过对文章进行断句、基于统计的方法进行分词,即可得到待学习的词汇集合;之后,采用基于关联规则的词汇分类算法,将待学习词汇进行分类,得出词语的词性、声调、平仄、常用搭配、感情色彩等,便可以使机器轻松“掌握”词汇。在系统的自主创新创作阶段,结合指定的中国古代诗词的文字,章法等规则,设计了比较准确的规则匹配算法。并在Lucene开源工具包的基础上,实现了基于索引的全文检索功能,使得系统所创作出的作品,在语义和表达习惯上,具有一定合理性。最后,通过设计了一系列功能测试案例,对系统进行了测试。测试结果表明,该系统基本具备了创作五言绝句和七言绝句的能力。对于中国诗的其他形式作品,比如词曲歌赋等,希望今后能作进一步的研究。"
553,基于变邻域搜索的音乐生成方法研究,"随着社会的飞速发展,人们对音乐的需求也越来越丰富,音乐的使用场景也在不断的在拓宽。人们不仅仅满足于聆听优美的旋律、享受音乐带给我们的感动,同时也对现代作曲提出了更高的要求。随着计算机的计算能力逐步提升,研究人员希望寻找到一种方法,使其能够协助作曲家完成可重复的部分工作,并降低作曲的门槛,使普通音乐爱好者也能享受作曲这一过程。本文首先研究了音乐生成方法的目的与意义,分析了基于传统方法的音乐生成方法以及基于机器学习的音乐生成方法的国内外研究现状。其次,分析了基于音高显著度的旋律提取与变邻域搜索算法等相关理论基础在音乐生成领域的应用。除此之外,本文针对传统与机器学习音乐生成方法存在的一系列问题完成了如下研究:(1)根据训练样本易获取、紧贴时代的要求,规定预处理前的输入格式为WAV或MP3,随后进行单声道提取与分节。接下来经过离散傅立叶变换后对各帧进行基于音高显著度的旋律提取,初步获得旋律线,同时在时域基于掩蔽效应和等响曲线对能量分块,判断存在音符的帧和存在休止符的帧。映射到音符域后进行对数加权模糊处理,有意使旋律线出现虚假音高,在后续的步骤中锻炼操作者的音感。随后将乐谱表格通过GUI可视化,可根据偏好认为对乐谱进行增删。随后将乐谱输入依据乐理知识设定的训练模型中,获得训练参数矩阵,并可与已训练参数相结合,更新训练数据库。(2)研究了基于变邻域搜索的音乐生成算法。根据本文的音乐生成问题对传统的变邻域搜索算法中的某些步骤进行修改。随后由于大量乐器难以获得,同时系统对乐谱存在着人耳试听的需求,研究了模拟乐音生成算法。对现有的乐器与人声生成模型进行总结和归纳,将参数化乐音模拟算法结构分为激励源和共振腔两部分,并分为弦乐器与体乐器进行简单实现,可为旋律添加乐器,也可反过来指导乐器的结构设计。(3)以读取一段音乐片段为例对训练系统进行测试,基本实现了系统要求,体现了人机交互的思想,证明了二次折叠参数的有效性,验证了系统的便捷性与可行性;并对音乐迭代生成系统进行测试与分析。系统基本满足了本研究对便捷性和灵活性的要求,界面直观,迭代生成流程清晰,测试生成结果也具备一定的艺术性,最后输出的音乐片段较为理想。"
554,基于人工智能对未来戏剧语言艺术的理想范本,"“戏剧”发展到今天,就像一棵参天大树,最早的戏剧来自简单的模仿,比如“优孟衣冠”。随着人类社会历史与文明的发展,戏剧艺术经历不断的成长,裂变与更新。艺术家们不断地尝试如何在戏剧领域融入更多先进的技术手段,以便快速达到前所未有的艺术效果。比如布莱希特对投影的使用,使舞台呈现更为丰富。除了看得见的改变,有更多看不见的改变正在影响着戏剧创作。当我们还没有意识到的时候,人工智能技术AI(Artificial intelligence)就已经成为我们生活的一部分。人工智能介于“戏剧语言艺术”的意义在于,它不仅可以使机器帮助我们快速的分析或者破解台词背后的含义,台词与台词之间的关系;更是基于人物角色上的分析,是基于舞台上演员对角色的理解的语言表达所进行的分析。通常情况下,这一行为对于人类艺术家并不困难。但培养一个戏剧语言领域的专家,除了需要耗费大量的人力,物力更需要漫长的培养周期。如果有了人工智能技术的介入,可以将这一分析能力快速且廉价的提高到一个相对较高的水平。这将会极大地降低戏剧创作的人员与时间成本。戏剧的根本是“人”,以及他当下与生活的关系。人工智能技术的出现不仅不会对这一根本原则产生影响,而且可以帮助艺术家们更快的达到自己的创作目的。希望经过计划和努力,我们能利用这种强大的科技,创造出我们的祖先做梦也无法想象的美好未来。将“戏剧艺术”带向更加美好和繁荣。"
555,基于机器学习的红外目标跟踪算法研究,"红外成像系统因其可全天时工作、隐秘性好、抗干扰性能强和穿透烟尘能力强等优点,被广泛应用于红外制导、智能安防和夜间导航等军事与民用领域。红外目标跟踪技术作为红外成像系统的关键技术,在现代防御和告警任务中具有十分重要的地位。但是由于红外图像具有信噪比低、背景杂波较严重和分辨率低等局限性,使得红外目标跟踪技术成为了一项富有挑战性的课题,对其深入研究有着重要的理论意义和实用价值。本文对红外目标跟踪算法进行了深入的探讨和研究,首先分析了红外图像预处理技术,然后研究了两种基于机器学习理论的红外目标跟踪算法,并分析和验证了两种跟踪算法的有效性。针对红外图像分辨率低、对比度低、纹理细节特征缺乏等问题,分析了五种典型红外图像增强算法,通过仿真实验从直观效果、失真度、细节增强性与处理速度四个方面对比分析了这五种算法,选用效果相对较好的引导滤波作为跟踪器的图像预处理算法。针对红外图像灰度特征丰富性不足和随温度变化的问题,采用了有效对抗温度变化及目标形变的方向梯度直方图(HOG)特征在红外图像特征提取中。在分析传统相关滤波的精确性和核相关滤波跟踪算法的实时性的基础上,本文研究实现了基于上下文感知的尺度估计跟踪算法,其在上下文感知的跟踪框架中将精确尺度估计算法与核相关滤波算法相结合,为滤波器提供了更多的负样本,从而抑制了背景中与目标相似物体的干扰,提高了跟踪算法精度。针对相关滤波类算法模型简单、泛化能力差的问题,本文研究实现了一种基于深度学习的端到端跟踪算法。该算法将全卷积孪生网络的卷积层进行金字塔式融合,再将融合后的各个尺度特征层输入到区域选取子网络,通过并行计算模板帧和待检测帧的相似性,来确定待检测帧的目标位置并输出目标尺度提议,最后采用非极大值抑制方法选取得分最高的尺度提议,从而获得了精确度更好的跟踪效果。"
556,基于机器学习的卫星认知网络频谱感知技术研究,"随着5G时代的到来,一直期待着的以万物互联为基础的智能生活,也即将成为可能。万物互联也就意味着网络中终端数目的暴涨,与此同时带来的是端与端之间通信业务的频繁,这在一定程度上造成频谱资源的短缺。如果能够将卫星网络与地面网络相结合,不仅能够提高网络稳定性,同时也改善了原有网络的性能。将认知无线电技术应用于卫星网络与地面网络,不仅可以令卫星网络与地面网络相结合,而且可以缓解本来就短缺的频谱资源问题,这就是卫星地面认知网络。本文的目的是研究认知无线电中频谱感知技术在卫星地面认知网络的应用。首先对课题的研究背景及意义以及国内外研究现状进行了简单介绍,从原理上介绍了几种频谱感知技术,随后描述了卫星认知网络的基本模型,并且分析了不同波段在卫星认知网络模型中的应用。最后通过卫星认知网络的不同需求,分别结合了卫星认知通信不同波段的实际情况,构建了卫星认知网络的应用场景。建立了集中式卫星认知网络架构的模型,该模型在提高频谱感知性能的同时也使得网络便于优化与管理。并且通过以能量检测为例的感知过程的理论推导,得到了集中式卫星认知网络的频谱感知性能,该感知过程基于地面认知用户感知授权卫星下行链路信号。在上述研究的基础上,将机器学习中无监督聚类中的K均值聚类与高斯混合模型应用于能量检测算法中。通过研究发现,在能量检测中应用K均值聚类与高斯混合模型,不仅提高了检测性能,而且避免传统能量检测中由于噪声不确定导致的门限推导过程。随后提出基于聚类的最大最小特征值检测算法,该算法采用K均值聚类与高斯混合模型,与原有算法相比,免于繁琐的门限值推导过程,通过仿真发现改进的最大最小特征值算法在相同条件下检测性能优于能量检测。最后本文提出将CURE层次聚类应用于能量检测与最大最小特征值检测,并与传统的K均值聚类以及高斯混合模型进行对比,通过仿真验证,发现CURE层次聚类检测性能略逊于高斯混合模型但优于K均值聚类,而且与高斯混合模型相比具有算法复杂度低、过程迅速的优点。"
557,基于主观听觉反馈的机器学习语音增强模型优化研究,"语音信号是人类相互沟通的重要方式之一,但是其易受到传输过程中各种噪声的侵扰,特别是在当今电子通讯技术发达的社会,无线传输时各类噪声对语音信号可懂度的影响非常大,因此在现代语音信号处理领域中,语音增强技术成为不可或缺的环节。现如今结合机器学习的语音增强技术效果得到了大幅提升,尤其是使用深度神经网络的语音增强技术,但是网络模型存储需求和计算量大,计算复杂度和计算功耗高,难以部署到常用的可移动设备和嵌入式设备中。因此本研究旨在对神经网络语音增强模型压缩优化,减少模型参数以降低模型的冗余度。本研究使用深度降噪自编码器构建语音增强模型,在两种非平稳噪声条件下分别训练出对应的神经网络语音增强模型。基于幅值剪枝的模型压缩方法,提出了迭代修剪+重新训练的压缩方法,与迭代修剪无重训练和直接修剪+重新训练这两种对照方法进行了对比,显示了重新训练和迭代渐近式修剪的重要性。此外,本研究对迭代修剪方法进行优化,多次重复迭代修剪+重新训练方法,多次重复迭代使得稀疏网络模型重新收敛。模型压缩过程中使用字正确率作为主观听觉反馈,对每个压缩模型的语音增强性能进行评估,最终拟合模型参数修剪比例与字正确率的平衡曲线,以此寻找每种模型压缩方法的最大临界修剪比例。本文首先对单通道的语音增强方法进行介绍,尤其是其中的神经网络语音增强方法,接着对神经网络模型压缩的方法进行介绍,最后搭建神经网络语音增强模型,通过主观测听实验对比测试提出的网络模型压缩方法。其中使用迭代修剪+重新训练的模型压缩方法可以在不影响模型语音增强性能的情况下,将模型参数减少50%,优化后的多次重复迭代修剪方法最大临界修剪比例可达80%,实现对模型参数量压缩5倍而不影响其语音增强性能。"
558,基于CSI的人体入侵检测及室内定位研究,"随着信息科技的不断进步,无线局域网被越来越多的个人和单位部署在各种室内场景中。这也使得越来越多的科研人员将视线投向了它,并利用其开展了一些相关的应用研究。在许多的室内应用场景中,人体的入侵检测和室内定位是极有应用研究价值的。传统的人体入侵检测和室内定位主要利用射频识别、超声波、视频图像、红外线等,但是上述技术在精度上或者在成本控制上都存在着一些问题。然而无线局域网中的信道状态信息(Channel State Information,CSI)凭借其自身的特点和优势能较好的克服许多问题,因此逐渐成为许多研究人员的首选参考量。此外,为了实现效果更优的人体入侵检测及室内定位研究,本文还引入了可视图(Visiblity Graph,VG)方法来获取常规方法所不能提取的网络特征来实施入侵检测和提升定位效果。而且通过这种可视图网络化映射的方法将基于CSI的人体感知研究引入了一个全新的领域,为该研究方向的进一步发展做出了一定的贡献。本文的研究工作主要包括:(1)对传统的人体入侵检测及定位技术进行总结分析,指出传统方法的不足,并分析了CSI和复杂网络的研究进展;(2)介绍了CSI具体原理和获取方法以及可视图网络方法的具体原理,并简单介绍了几个常用的机器学习算法;(3)用可视图方法与CSI时间序列结合进行人体入侵检测的实现;(4)将可视图方法经类比推理从时间序列推广到子载波序列信号上,构建可视图网络获取更多有效特征用于提升室内定位;(5)进行不同的对比实验,探讨和分析相关因素对入侵检测和室内定位的影响,并通过实例具体说明经可视图建网方法所提取的特征对定位效果提升有帮助;(6)分析比较了不同机器学习算法定位下的时间和准确率关系,给出了一些在不同场景和不同需求下的算法选择意见。"
559,面向深度图像的3D-HEVC帧内编码模式决策快速算法研究,"近年来随着影视工业、新兴智能视觉交互技术的快速发展,三维视频处理研究迅速成为热点。国际视频编码标准的两大制定组织ITU-T和ISO/IET联合制定了新一代的高效率三维视频编码标准(3D-HEVC)。为了显著减少视点个数,3D-HEVC增加了包含视频场景几何信息的深度图像,显著提高了三维视频压缩效率和合成视点的图像质量,但深度图像编码的计算复杂度非常高,其编码时间是彩色图像的六倍左右。因此,为了降低3D-HEVC中深度图像编码的复杂度,本论文对其计算最为集中的模式决策部分进行研究,包括编码单元(CU)划分、帧内预测模式决策以及深度预测模式(DMM)决策过程。主要完成的工作和成果如下:(1)针对CU划分过程,提出了一种基于纹理特征分析的深度图像CU划分快速算法。首先利用深度图像纹理变化特征与CU划分特征之间的对应关系进行初级纹理特征分析;然后根据CU内部像素分布统计特性进行精细纹理特征分析;接着利用上述特征对CTU进行划分深度预测,并适当终止部分CU的划分。此外,本论文根据测试序列纹理特征和量化参数(QP)调整该快速算法中的灰度分级数和CU纹理复杂度阈值,使算法具有更好的序列适应性。(2)针对帧内预测模式决策过程,提出了一种基于机器学习分类的帧内预测模式决策快速算法。首先通过对37种帧内预测模式设置类别标签,提取相关特征进行离线训练得到随机森林预测模型;然后用模型预测当前预测单元(PU)最佳类别标签,建立与类别标签对应的候选预测模式列表,以减少模式决策过程中进行哈达码优化的预测模式个数;最后利用候选模式列表内预测模式之间哈达玛代价的幅值关系来减少进行率失真代价计算的候选预测模式个数。(3)针对深度图像深度预测模式引入的计算复杂度,提出了一种基于像素特征分析的DMM预测模式决策算法,首先分析当前PU内部像素的分布特征以及当前PU尺寸与DMM模式选择的相关性;然后通过计算当前PU上下左右四个边界DMM特征标识来判断当前PU是否采用DMM预测模式,以减少部分PU的DMM模式计算,进一步优化PU的模式判决。"
560,相干声波扰动对流层散射通信的探究,"对流层散射通信主要利用对流层的湍流对于电波的散射特性实现电磁波的远距离传输,在野战条件下是除了卫星通信和微波通信外的另一种重要的高可靠性通信手段。本文从声波扰动对流层的基本机理出发,利用相干声波激励对流层产生的相对介电常数起伏“人工不均匀体”实现电磁波的有效传输,使得散射超视距传输模式的“凭借”机制可以人为控制,散射超视距传输模式的性能和参数不再完全依赖自然湍流,从而有效提升散射通信传输信道的可靠性,提升散射通信的稳定性。它是机器学习理论、计算几何学、晴空大气人工变态以及电大尺寸问题的计算电磁学几个研究方向高度交叉融合的创新体。本文从理论建模和散射实验两方面对其进行探究,主要进行了以下工作:首先,进行相干声波扰动下对流层模型建立及其散射计算。根据对流层散射链路几何关系、声波干涉理论和平面声源阵列原理建立相干声波扰动条件下相对介电常数起伏“人工不均匀体”的理论模型,完成了“人工不均匀体”形状、尺寸和分布的可视化描述;采用机器学习的聚类算法按照一定的介电常数的差异对建立的“人工不均匀体”模型进行三维空间区域分解;采用计算机图形学的相关算法计算得到每个子区域的三角面元剖分的外包络面;对雷达收发波进行射线离散,并使用加速算法实现射线与“人工不均匀体”内部每个子区域外包络面相交的判别,进一步使用射线追踪法来计算“人工不均匀体”的散射特性(雷达的接收特性);分析声源系统核心因素对散射结果的影响,结果表明增大声源功率和减小声源阵元的间距,场强模值会随之增加,在一定范围增加声源频率和声源阵的子源个数,场强模值会增加,超出范围时场强模值反而会降低。其次,进行相干声波扰动局部大气的散射实验设计与探究。在微波暗室内进行散射实验进行设计、完成与分析,首先对声源系统的结构进行设计,并讨论声源系统核心参数对“人工不均匀体”归一化介电常数起伏的影响。在此基础上,对实验方案进行完善,开展相关散射实验,将实验数据与理论计算结果进行了比对,得到了较为满意的结果,同时本文还对误差进行了分析。"
561,基于机器学习的RSSI室内环境感知与定位技术研究,"近年来,人工智能和物联网技术发展迅猛,一些新型移动设备的出现,刺激了基于位置感知服务的激增,室内无线定位技术逐渐成为人们关注的重点。因此,如何在动态的室内定位环境中实现具有自适应性、普适性、高精度性的室内定位技术是当前研究的主要内容。现有的基于接收信号指示强度(Received Signal Strength Indicator,RSSI)的室内定位技术具有设备简单,数据采集方便的优点,同时机器学习具有学习能力,可以通过采集样本数据训练网络,为网络加入预测功能,并且通过采集不同环境下的训练数据集,使网络能够适应不同的环境。综合以上思路,研究这两种技术相结合的室内定位技术,使其具备学习和适应不同定位环境的能力,以达到高精度的定位效果,有着重要的现实意义。首先,本文介绍了现阶段室内定位技术和机器学习的相关基础知识以及室内定位技术在各领域的应用潜能,分析了现阶段室内定位技术面临的难点问题,主要针对室内定位环境的自适应和测距定位算法两项关键技术展开研究。其次,分析了现有的基于RSSI测距和基于机器学习的室内定位技术的优缺点,提出本文的研究目标。现有的基于RSSI测距的室内定位技术通常采用对数路径损耗模型,该模型涉及两个环境参数,利用锚节点之间的相互通信,能够实现静态室内定位环境中环境参数的实时修正,并且利用提前部署的锚节点,可以快速生成电子地图。但是在由人员状态改变引起室内定位环境动态变化的场景中,该方法很难做到实时更新。针对该问题本文提出了一种基于聚类的室内人员活动感知与检测算法,该算法利用聚类技术,将环境中采集的不同人员状态下的RSSI值和相应的方差值进行聚类,得到每一种人员状态下RSSI值和方差值的阈值,在实际定位中应用阈值进行分类,实现了动态室内定位环境中人员状态的检测,减小了人员因素的影响,并且为后续依据人员状态选择测距定位模型提供了基础。最后,针对室内测距定位算法,指出了现有技术存在精度不高,不能随着人员状态调整自身模型的问题,提出了联合自适应增强策略的室内测距定位算法。该算法首先采集人员静止和移动两种状态下的数据对网络进行训练,经过多次迭代得到不同人员状态下的测距定位模型,并结合基于聚类的人员活动感知与检测算法检测人员状态,提升了距离的转换精度,实现了根据人员状态选择测距定位模型的策略。与现有的算法相比,所提算法能够适应不同的定位环境,并且精度更高,实现了定位系统的自适应性、普适性、高精度性。"
562,基于贝叶斯神经网络的优化移动数据业务吞吐率方法的应用研究,"《2018年上半年中国移动互联网行业发展分析报告》指出,我国2018年上半年手机终端业务日活跃用户数超过7000万,月活跃用户数超过2亿。使用移动数据业务上网的用户占比从2017年7月份的23.7%上升到2018年6月份的28.2%,半年增长近6%,而且这一数字还在持续扩大。随着用户数量的增长,在运营商投资通信网络建设成本一定的情况下,充分利用现有通信网络的资源提升用户移动数据业务吞吐率,对满足用户上网体验至关重要。参数优化是网络侧优化吞吐率的主要方法。受现网配置参数的限制,网络中很难有高质量的差异化数据去喂“机器学习”算法;同时,吞吐率还受话务模型,网络质量等因素的影响,所以在网络侧通过建模优化吞吐率比较困难,网络侧只能针对某些异常小区进行定位,达不到全网调优的目的。本文采用了贝叶斯神经网络算法,对影响移动数据业务吞吐率的因子进行学习,识别出关键因子并建立了一个优化模型,该优化模型通过调整手机终端上报的RANK等级达到提升吞吐率的目的。该优化模型具有充分利用网络资源,实现原理简单,适用范围广泛的优点。本文完成的主要工作有以下三个方面:1.通过构建测试环境,编写测试用例模拟现网情况,采集大量数据样本。2.建立基于贝叶斯神经网络算法的优化模型。3.验证模型的正确性,同时将模型应用于手机终端系统中。实验结果表明,在部分试验场景下,某款终端芯片RANK2上报比例提升10%,移动数据业务平均吞吐率提升2.8%。该实验结果证明了通过机器学习的方法可以有效提升移动数据业务吞吐率,进而可以推广到全网调优数据业务吞吐率。"
563,用于无线光网络拓扑控制的机器学习算法研究,"自由空间光通信(Free Space Optical Communications,FSO)是一种经过调制将可见光、激光或者红外光通过大气进行信息传输的光通信技术。该技术具有带宽大、速率高、安全性高、组网灵活和成本低等优点,近些年来已经成为通信行业的热点之一。然而,由于FSO波束窄、终端集成困难以及节点度受限等自身问题,作为通信的第一步,FSO组网存在一些亟待解决问题。目前,针对FSO组网技术的研究已日臻成熟,国内外公开的期刊论文较多。由于FSO传输可视距,要求收发端具有较高的对准性。同时,不同于传统无线网络,FSO链路功率受限且受到大气信道的影响,在接收端信号功率会降低,所以通信的范围有一定的影响,进而影响网络规模和网络的扩展性。因此,FSO的组网技术不能沿用传统的无线自组网中的组网技术。而需要设计合理有效的网络拓扑控制和路由策略以便最大限度的弥补FSO链路特性带来的不足,对整个网络的生存也有重大影响。本文首先阐述了自由空间光通信的研究背景意义及关键技术,然后针对FSO组网设计了FSO网络的节点模型、能量模型及网络模型,并对本文用到的Voronoi图、机器学习进行了介绍。在此基础上,本文提出了基于分层分布式网络模型,结合局部Delaunay三角剖分(LDT)算法和机器学习,考虑到簇头和下层节点的移动,提出了一种用于无线光网络拓扑控制的机器学习算法(Topology Control Based Machine Learning Algorithm,TCBMLA),简称TC-ML算法。该拓扑控制算法不仅可以创建具有高连通性和强鲁棒性的拓扑结构,而且可以实现拓扑结构的重构。该拓扑控制算法主要包括两种算法。第一种称为拓扑形成算法,包括上层拓扑形成算法和下层拓扑形成算法,上层拓扑形成算法主要构造了基于Voronoi图的主干网络,下层拓扑形成算法主要以机器学习预测出的节点平均度为参考形成下层拓扑结构。第二种称为动态管理算法,通过利用Voronoi图的局部动态性重新配置上层拓扑,通过利用机器学习的预测算法重新分配下层拓扑结构。在此基础上,研究了节点的连接准则,包括节点的最大接入度,给出了推导公式,避免了节点过载和能量消耗过大的问题。本文也对TC-ML算法进行了仿真和分析,结果表明,TC-ML算法可以形成一个高连通性、全覆盖和可自动重构拓扑的FSO网络。"
564,基于协作干扰的无线网络物理层安全技术和加密数据流分类方法,"嵌入式系统、移动网络和无线网络无处不在,并在许多场景中得到应用。由于无线网络的开放特性,无线设备之间通信变得方便,更多的安全隐患也随之出现,因此,安全性是无线系统中的一个重要问题。随着计算机处理能力逐渐提高,传统的密码学安全方法的缺陷也随之显现。大量IoT设备的出现,也给传统的密钥管理方法带来了巨大冲击。为了确保无线网络的通信安全,必须在安全属性、功能和加密原语之间做出谨慎的权衡。例如,资源受限的节点应接收较少的计算密集型任务,而缺乏抗篡改能力意味着长期的秘密不应该驻留在节点中。为保证网络通信的安全性,除了可以使用传统的安全方法,还可以利用无线信道的随机性,在物理层上保证无线网络安全通信。对此,本文首先研究了无线网络中协作干扰的安全问题。本文提出的方法对窃听者的位置和窃听者的数目不进行任何限制,即存在数目不限的窃听者,且窃听者可能位于距离发送方或接收方附近的位置。该策略的核心思想是采用分治策略对窃听者进行干扰,利用发送方和接收方主动产生的干扰信号来解决邻近收发端的窃听者所引发的安全问题。协作干扰方法中,需要对部分网络节点设置参数,包括:作为干扰器的合法节点数目,收发双方的阈值等。实践中,我们可以使用次优化方法确定需要作为干扰器的合法节点数量,其基本思想是,把可闻区域(由于有窃听者存在,通信不安全的区域)内的其它合法节点视为窃听者,如果在当前干扰器的数量下,可闻区域内的所有合法节点都被阻塞,则认为当前的通信是安全的,此时干扰器的数量即为所需数量。此外,在不同的网络场景中,难以获得合适的参数,也难以实现最大的保密容量。文中提出了一种可行的方法,即利用简化的机器学习算法得出次优值。为了减少节点的资源损耗,文章选择了收敛速度快、计算复杂度低的K-最近邻算法。然而,K-最近邻算法容易陷入局部最优解而非全局最优解,为了在保证低计算复杂度的前提下解决这一问题,文中采用了简化的遗传算法来获取全局最优解,并由此得到协作干扰中的全局次优参数值。为进一步确保网络通信的安全,文章提出了一种对应用层的安全方法DD加密流量分类,即从加密的混杂网络流量中对特定应用的流量进行分类。对加密网络流量进行分类可以帮助网络管理者分类不同的网络应用和协议,以实现多种安全目的,如网络设计,QoS服务中的应用优化和协议调度等。流量分类方法不但提供了更好的QoS服务,也保证了网络通信的安全性。本文使用机器学习来实现流量分类方法:将采集到的流量分为训练集和测试集,训练过程中,构建C4.5决策树分类器和马尔可夫链分类器;在测试集中,使用C4.5分类器对马尔可夫链分类器进行辅助,并逐渐完善马尔可夫链方法所用的流量指纹。评估和仿真结果表明,协作干扰具有提高网络安全性能的能力,可用于无线网络的初始连接。且在协作干扰的基础上,对加密流量的分类可以进一步提升无线网络的安全性。"
565,基于机器学习的定制化网络切片技术研究,"下一代移动互联网需要满足各种不同应用场景需求与关键性能指标,难以用同一张网络支持所有需求。因此,需在通用的开放式网络架构下,利用软件定义网络(Software Defined Network,SDN)、网络功能虚拟化(Network Function Virtualization,NFV)、网络切片(Network Slicing,NS)等技术,构建定制化的专属虚拟子网,满足特定网络业务的需求。在网络切片技术实例化的过程中,网络业务的识别问题是实现面向业务类型建立切片的基础,需首先解决。由于网络规模的扩大,传统的数学工具在解决这一问题中遇到了前所未有的障碍。而随着机器学习的发展,可利用其算法较为准确的实现业务的识别,因此基于机器学习的网络切片技术值得研究。同时,网络资源分配也是保证用户体验的决定性因素之一,在进行资源分配时如何保证质量体验(Quality of Experience,QoE)的同时提高谱效有待研究。针对上述的两个问题,本文进行了如下研究:(1)本文研究了一种基于神经网络的网络业务识别方法,并给出了基于机器学习的网络切片设计方案。针对网络业务识别问题,设计了基于神经网络的网络业务识别方案,给出神经网络参数确定原则与方法。然后,针对SDN网络环境,设计一种滑动时间窗的方法进行网络信息采集,并且结合业务服务器的日志文件完成样本标注。最后,采用软硬件结合的方式搭建了基于SDN/NFV的网络切片原型平台,在SDN实验网上基于滑动时间窗构建了数据集。分别基于实验网的数据集以及公开的Moore数据集验证了所设计的基于神经网络的业务识别方案的可行性,同时也证明了基于SDN实验网采集的数据集训练的神经网络模型在应用时的泛化能力更强。随后,基于实验网的业务类型识别结果,进行了定制化网络切片的实验。(2)为了进一步保证切片服务的性能,本文研究了一种基于强化学习的网络资源分配算法。该算法将业务类型以及每种业务的下行数据量作为Q学习的状态集,资源分配方案作为Q学习的动作,综合考虑谱效和QoE定义了Q学习的价值函数,利用贝尔曼方程递推回报求解。Q学习考虑了未来的网络状态对现在决策的影响,因此随着学习次数的增加,算法效率得到有效提升。最后针对三种业务进行网络带宽资源分配的仿真实验,结果表明,本文所研究的基于强化学习的资源分配算法可以在满足多业务QoE需求的基础上,提高网络谱效。"
566,多模态连续维度情感识别研究,"人工智能的出现让生活变得高效且便捷,人们也因此开始意识到人机交互的重要性。情感是人类生活中必不可少的元素,但由于机器无法像人类一样感知情感,在很多情况下机器无法真正的融入人类生活,并且对人类造成了负担与伤害。因此,计算机情感计算尤为重要。在情感计算中,人们将其分为离散情感计算和连续维度情感计算。离散情感仅仅包含了几类情感,而连续维度情感则是通过多维度的方式表现全部情感状态。本文通过利用多模态信号预测连续维度情感,针对于不同模态间的相互关系与单一模态的特性,提出了组合型回归网络(W-SVR-GBRT),提高预测的准确性。本文也关注到模态间存在的负面影响,提出了一种新型模态间融合策略,即模糊加权在线支持向量回归模型(FWOSVR),从而解决了模态内异常情感帧的问题。本文主要研究内容有以下几点。1.本文首先从人类情感的复杂性与模糊性角度分析连续维度情感空间与离散情感的差异性。通过对听觉模态与视觉模态的分析,明确了哪些特征能够充分地表达连续维度情感,分别提取相关情感特征,使用主成分分析融合了浅层特征和深层特征并达到降维效果,从而提高对情感的表达效果,并分析维度对全局特征的影响,选取最优维度。2.本文通过分析不同模态对不同维度情感空间作用效果的差异性,发现单模态无法准确表现情感,识别效果不理想。从而使用音/视频双模态识别连续维度情感,提出建立加权的组合回归网络模型(W-SVR-GBRT),并对多模态情感进行多级融合与回归。梯度增强回归模型(The Gradient Boosting Regression Tree,GBRT)首次被应用在维度情感识别领域,并针对情感模态的差异性补充了支持向量回归模型(Support Vector Machine for Regression,SVR),将集成学习的思想与高维空间中寻优的思想相结合,并通过改进线性回归模型进行决策级融合,提高情感识别的预测精度。3.本文关注到了偏离实际情感值较大的部分,对出现异常值的多种情况进行分析,提出模糊加权在线支持向量回归(Fuzzy Weighted Online Support Vector Regression,FWOSVR)的融合策略,通过在线的方式对模型进行校正,建立非线性连续时变系统模型,保证了在决策级融合过程中异常值对整体结果的影响最小,从而解决了异常值干扰的问题,使得在arousal情感空间中精确度提升18.21%,valence情感空间中精确度提升7.88%。"
567,线性调频连续波雷达人体运动状态分类算法,"线性调频连续波(LFMCW)雷达系统结构简单且近距离检测性能好。基于LFMCW雷达的人体探测与其它传感器相比有着全天候、抗干扰能力强等优势。用LFMCW雷达实现高精度的人体运动状态分类可以对公共场所有异常行为的人员进行检测,保障公民安全,还可以应用于车载产品,使车辆和行人保持安全距离。基于LFMCW雷达的人体运动状态分类在反恐、交通安全和人体运动学研究等方面有着很广泛的应用前景。本文利用Infineon(英飞凌)24GHz连续波雷达对不同身高不同性别的人进行多组走和跑的实际测量,采集了大量的数据。对雷达回波数据预处理后采用时频分析的方法得到人体走和跑的时频图。并用机器学习和深度学习的方法对人体走和跑时频图的进行分类,逐步提高模型的分类性能。首先用机器学习的方法对人体走和跑的时频图进行分类,提取了时频图的HOG特征、LBP特征、HAAR特征,选择SVM分类器并用单一特征分别训练SVM得到三个SVM模型,对比分析不同特征训练的SVM模型的性能差异。为了更加全面的利用时频图的信息,通过不同的特征组合方式训练模型,提高模型性能。再选择XGBOOST分类器,调整树深度,通过对比实验得到性能最优的XGBOOST模型。最后提出基于stacking的方法对SVM模型和XGBOOST模型进行融合,通过对比实验确定了最佳融合方式,并通过实测数据对模型进行性能测试,和单一特征训练的模型及组合特征训练的模型相比,提高了模型性能。用机器学习的方法对人体走和跑的时频图进行分类时,因为特征提取的多样性和分类器选择的多样性,过程较为复杂且最终得到的模型性能不是最优。所以提出用深度学习的方法对时频图进行分类,根据时频图结构简单的特点,如果用复杂的网络对其进行分类可能会导致过拟合。因此首先设计浅层的卷积神经网络并从数据和模型两个方面对网络进行优化,提升模型性能。再改变网络的结构和层数,通过对比实验确定性能最优的网络结构和层数。本文采用不同的方法对人体走和跑的时频图进行分类,通过设计、优化和改进逐步提高模型的性能,最终得到的模型在测试集的分类正确率可达97.17%。"
568,散射通信链路自适应传输技术研究,"对流层散射信道因具有强抗毁灭性、可有效抵抗强干扰、越障能力强,被广泛地运用在超短波超视距无线通信中。但散射信道传输路径损耗大、可能工作在低信噪比、存在时间和频率双重选择性衰落性,导致利用散射信道开展超远距离通信极具挑战性。针对上述散射信道特征,本文开展了散射通信链路自适应传输技术研究,主要包括信道质量测量、多种速率MCS传输和切换控制方案等方面的内容。从大尺度衰落、小尺度衰落和信道时频幅度三维图的角度分析了对流层散射信道特性,并结合经典的散射信道确立了仿真信道模型。本文选择具有时频二维联合框架的单载波交织频分复用系统SC-IFDM作为通信体制,有效克服了散射信道的时频双选衰落等复杂的信道特性。在信道质量测量方面,主要研究了散射信道低SNR估计和信道质量指标(LQM)映射算法。首先,利用SC-IFDM独特的帧结构,提出了一种SNR盲估计方法。与原有的算法相比,本文所提的算法明显改善了低SNR的估计范围和准确性,将SNR的估计范围提升到-18dB,其NMSE在10~(-1)以下,使用盲估计方法,可以有效节约系统的导频符号开销。低SNR的准确估计,为后续研究LQM映射算法和参数切换控制奠定基础。接着,研究了两种常见的LQM映射算法,一种是直接映射函数算法,EESM和LESM映射算法;另一种是互信息有效映射(MIESM)算法,介绍了平均每比特互信息(MMIB)算法,经映射算法得到一维的有效SINR,用于传统的查表法切换控制方案中。最后,为提高反馈效率,研究了信道质量反馈策略。在链路自适应传输方面,主要研究了多种速率MCS传输和切换控制方案。为确保散射通信系统的稳健传输,分别优化了信道编码和速率匹配、调制解调及提取软信息、频率分集合并等传输方案;通过组合编码码率、调制方式和分集阶数等,设计了11种不同信息速率的MCS传输方案,满足不同速率的业务需求,实现单用户的可调传输速率范围为100kbps~1.25Mbps。针对基于一维LQM反馈链路不准确的问题,将机器学习应用到链路自适应切换控制中,通过训练样本数据适应信道环境的变化,动态地调整MCS切换控制方案。本文主要研究了基于分类思想的SVM和基于最大回报函数的Q学习两种机器学习方法,优化MCS切换控制策略,提升了链路通信系统的吞吐量性能。采用机器学习的方法,保留高维度的信道质量信息,使MCS的切换控制更加准确,有效提高了对流层散射通信链路系统的吞吐量。"
569,基于机器学习的信号与辐射源关联识别研究,"在日益复杂的电磁环境中,信号与辐射源的关联识别引起了国内外学者的广泛关注。信号与辐射源关联识别是指在信号与辐射源之间建立一一对应的关联关系,通过识别辐射源信号进而实现对关联辐射源的有效识别。首先,本文将信号与辐射源关联识别问题分为两部分:信号与辐射源型号关联识别和信号与辐射源个体关联识别。前者是通过识别不同型号的辐射源信号,根据信号与辐射源的一一对应关系实现对辐射源型号的识别。后者是在完成辐射源型号识别后,对该型号不同辐射源个体进行识别,即识别相同型号、相同工作方式的不同辐射源个体信号,进而根据信号与辐射源的一一对应关系实现对辐射源个体的识别。其次,针对信号与辐射源型号关联识别问题,本文以辐射源型号已知的信号样本为研究基础,将电磁信号与不同型号的通信、雷达等辐射源进行一一关联,通过建立信号的分类器进而实现对辐射源型号的识别。实际应用时根据未知信号在分类器中的输出类别从而实现对辐射源型号的识别。由于不同类型的辐射源信号在制式上的不一致性,使得传统的辐射源识别方法对于不同类型的辐射源无法进行统一的特征提取。本文引入深度学习思想,利用卷积神经网络对信号特征进行智能化提取,将不同类型辐射源信号的识别问题进行了统一,避免了人为选取特征造成的特征表征不明显和特征数量不足的缺陷。再次,针对信号与辐射源个体关联识别问题,是在对辐射源型号进行了有效识别后,对该型号的不同辐射源个体进行分类识别。以辐射源个体信息已知的信号样本为研究基础,将信号与相同型号、相同工作方式的不同辐射源个体进行一一关联,通过建立信号的分类器进而实现对辐射源个体的识别。实际应用时根据未知信号在分类器中的输出类别从而实现对辐射源个体的识别。本文中首先使用了基于双谱与机器学习算法的分类识别方法,通过计算辐射源信号积分双谱并求取峰值作为信号特征,利用支持向量机来对信号特征进行分类识别。仿真分析表明该方法对于四部相同型号的对讲机具有良好的分类性能,而在待识别对讲机数量较多时该方法存在一定的局限性。最后,本文针对双谱与支持向量机方法的不足,将深度学习卷积神经网络引入到信号与辐射源个体关联识别中。利用卷积网络直接对信号特征进行提取,通过反向传播修正网络参数,实现对信号特征的智能化提取。本文使用了十部相同型号的对讲机对算法性能进行了测试,仿真结果表明该算法具有良好的识别准确率和实用性。"
570,面向CUDA程序的线程放置优化策略研究,"GPU具备强大的数据并行处理与浮点计算能力,因而被越来越广泛地应用于数值模拟和科学计算等领域。但面对GPU的复杂硬件结构和完全不同于CPU的多线程编程模型,提高GPU上程序开发效率以及程序的性能就显得尤为重要,线程放置策略是其中重要的一环。线程放置策略比较复杂,传统的线程放置策略包括参考指导建议、穷举参数等。本文在程序静态信息和运行时信息基础上,使用机器学习算法建立了CUDA程序线程放置优化模型。本文首先对具有较强代表性的程序核心信息做了总结,并设计了基于nvprof工具采集对应的运行时信息的方法。但采集运行时信息存在耗时过长的弊端,采集过程需要反复运行程序导致时耗成倍增长。为此,本文进而提出了采集静态程序信息替代部分运行时信息的思路。本文通过使用LLVM框架将CUDA程序转化为中间表示形式,编写分析pass统计源程序的循环信息、指令信息、存储信息等,综合实现了CUDA程序静态信息的采集,大大减少了程序信息采集的耗时。本文还提出了全面反映程序性能变化的设置标签算法。经过筛选,本文确定了多个机器学习算法参与训练,并使用网格搜索方法、交叉验证方式完成参数调优的工作。在实验分析中,本文在三个公开程序集上选取程序建立训练集,共设计完成了三组实验。通过静态信息替代效果分析实验,验证了静态信息对运行时信息有较好拟合效果,可以在保证模型训练精度前提下,使信息采集时耗减少23.2%。通过机器学习算法对比实验,发现了支持向量机算法对本模型具有更好的训练效果。通过与已有模型在同等条件下展开测试,证明本文提出的模型相比已有模型提高精度3.7%、降低时耗51.8%,拥有更好的训练效果与时间优势。"
571,基于机器学习的闪存错误率预测方法研究,"目前,2D MLC(Multi-level Cell)NAND Flash广泛应用于从移动设备到大型基站的各种系统中。然而,随着用户对存储容量需求的日益提升,容量扩张到达瓶颈的2D NAND Flash已经逐渐无法满足用户需求。3D NAND flash的超高容量则使其逐渐占领存储的舞台。然而2D MLC和3D TLC(Triple-level Cell)NAND Flash所面临的重要问题就是耐受力低,数据易出错。为提高其可靠性,降低错误率并降低运行成本,使用动态ECC(Error Correcting Code)纠错。如果够提前预知相对精确的芯片错误率,就能够为动态ECC的复杂度选择提供指导。因此本文利用机器学习算法构建预测模型预测闪存芯片错误率对芯片可靠性的提升有重大意义。目前大多数对NAND Flash的研究都是基于仿真实验进行的,这样得到的结果显然不够准确。本文基于自研的硬件平台分别设计了2D MLC和3D TLC NAND Flash的数据获取方案,并对芯片进行实际的磨损试验与驻留试验获取实验数据,然后根据实验数据对2D与3D芯片特性进行研究与对比分析。此外,本文基于2D MLC闪存芯片的实验数据,分别应用Elastic Net算法、BP神经网络算法及随机森林算法对2D MLC NAND Flash芯片进行错误率建模,并进行模型训练及模型结果的对比分析;为保证模型精度,分别基于3D TLC NAND Flash的短期驻留数据和长期驻留数据对3D芯片进行建模。分别对三种算法模型进行训练及参数确定,并对模型结果进行分析。最后对整体算法模型进行了性能的对比及评估。算法模型测试结果表明,本文建立的算法模型能够以较高的准确度预测NAND Flash芯片的错误位数;且本文模型训练所用数据为真实的实验数据,模型结果更具可靠性。"
572,机器学习在隐写术与隐写分析中的应用,"“机器学习”是实现人工智能的一种途径,它的目的是让计算机自动地从数据中学习规律,甚至是利用学习到的规律对未知数据进行预测。将机器学习应用于隐写术和隐写分析,能够促进隐写术和隐写分析的发展。例如:将机器学习中的“降维与稀疏学习”应用于隐写术中,可以利用压缩感知技术保护隐秘信息;另一方面,也可以利用压缩感知来提取特征信息,用于隐写分析。又如在监督学习中,我们利用生成的载体数据和含密数据来训练隐写分析的分类器,包括支持向量机、神经网络和集成分类器等。在非监督学习中,也能够根据提取的特征来自动地聚类载体图像和含密图像,实现自动分类的效果。目前对隐写术的研究主要在于两点:一是如何提高嵌入的信息容量而不影响原始载体的视听觉效果;二是如何提高隐写术自身的安全性,以保证隐秘信号不被发现。与之对应的,隐写分析的主要研究在于:如何能够在未知隐写算法的情况下,通过空域或频域特征来判断未知载体为含密载体或正常载体。本文主要从以上两个方向进行研究,论文的主要工作及创新内容如下:1.针对一般空域隐写术中,只对载体图像进行处理,而不对隐秘信息进行处理,且嵌入容量不高问题;本文提出了一种基于压缩感知和随机嵌入的空域隐写算法。算法使用压缩感知技术对原始隐秘图像进行降维加密,以这种方式提高原始图像的嵌入率;同时在k个LSB的位平面中,随机选择嵌入的位置,进行隐秘信息的嵌入;本文算法不会破坏载体的视觉效果,在与其他算法对比时,同一嵌入量能够带来较高的PSNR值;在与8DPVD算法对比时,本文算法具有更好的抗隐写分析性能。2.针对以往空域隐写分析需要提取比较多的特征进行训练分类器的问题,本文提出了一种基于分块压缩感知的隐写信号检测与恢复方法。使用压缩感知在隐写分析的作用主要有:提升分类时的正确率以及减少特征提取的数目。首先,用方向提升小波对图像做稀疏表示;然后使用归一化的高斯分布模型生成块压缩感知测量矩阵,这个测量矩阵可以用来感知方向提升小波系数。接着,我们用感知到的特征残差来重建原始秘密信号。算法与其他几种传统的空域分析方法比较,证明了本方法不仅具备分析空域隐写术的能力,而且能够在含密图像中恢复出原始信号。"
573,基于机器学习的URL安全检测技术的研究,"随着互联网科技的不断前进,越来越多的网络应用实例发生在我们身边,互联网科技在辅助人们生活变的更好的同时,也为人们带来了新的危险。恶意URL带给人们的损害致使人们开始逐渐意识到,采取行动来对抗恶意URL攻击,降低恶意URL攻击给人们带来危害的可能性是极其重要的。黑名单过滤检测技术也就应运而生,但随着科技的逐渐发展,数据集逐渐变得庞大,简单的黑名单检测技术远远不能满足当前对恶意URL检测技术的需求。机器学习算法逐步的应用于恶意URL的检测技术研究中,但是各个研究者所构建的模型准确率均有差异,且研究者们一般选择使用单一的机器学习算法来构建检测模型,这必然会导致检测模型在某些条件下表现出较为不好的性能。本文主要对基于机器学习的恶意URL检测技术进行了研究,构建了一个多分类器共同作用的检测模型,最后使用构建的多分类器模型设计并实现了一个对实时数据流进行处理的恶意URL检测系统。本文中主要完成的工作内容包括:分多种渠道对所需的正负数据集进行收集,并对收集到的数据进行了数据均衡、疑似恶意单词替换数据清洗等预处理操作。结合恶意URL检测特征提取的现有研究成果,加入自定义的新特征项,构建了一种新的综合特征提取方案,并对TF-IDF特征提取方案与基于word2vec词向量特征提取方案进行了实现。构建多分类器检测模型,检测模型中的三个分类器分别是,基于综合特征提取的逻辑回归模型、基于TF-IDF特征提取的SVM模型、基于word2vec词向量特征提取的CNN网络模型。通过给三种模型分配不同的权重,实验并调整恶意URL判定的阈值,来提高多分类器共同作用检测模型的综合性能。使用所提出的多分类器检测模型构建了一个恶意URL检测系统。设计并实现了一个对实时数据流进行恶意URL检测的系统,并对其进行了测试与结果分析。测试结果中发现,利用所提出的多分类器检测模型方案构建的恶意URL检测系统,在测试集上表现出了较好的分类性能,在正确率、召回率、精确率、F1值、检测耗时上表现出了较好的综合性能。"
574,基于机器学习方法的软件缺陷预测模型研究与优化,"随着软件的规模及复杂性的日益增加,软件测试成本开销日益增大。因此对软件缺陷进行有效预测,使可能包含缺陷的软件模块得到优先测试,从而降低测试成本开销,具有重大的现实意义。在此背景下,论文根据软件缺陷预测的两大目标,即软件模块是否有缺陷的概率,以及可能包含缺陷软件模块的排序,展开了对软件模块缺陷分类预测和软件模块缺陷排序预测的研究工作。具体工作如下:软件缺陷数据集中的大部分软件模块是无缺陷的软件模块,因此缺陷数据集是分类不平衡数据集。论文针对分类不平衡问题,研究了已有的不平衡处理方法,深入分析了SMOTE方法、ADASYN方法、EasyEnsemble方法和BalanceCascade等方法的核心过程。最后,论文在多种不同的数据集上进行了充分的实验,发现EasyEnsemble采样方法效果最佳。软件缺陷分类预测分为两类,即预测有缺陷和预测无缺陷。论文在进行缺陷预测分类工作时,论文首先研究了当前流行的集成学习方法,包括Bagging和Boosting方法;然后研究了多种基于Bagging的集成学习方法和多种基于Boosting的集成学习方法;随后,论文利用Stacking策略将多种集成学习方法融合在一块,构建了一个新的模型;最后,论文针对多种不同数据集设计了充分的实验。实验结果表明,基于Stacking的集成学习模型能够有效提高模型分类预测能力。论文通过模型预测软件模块的缺陷数目,然后依据数目对其进行排序。论文在预测缺陷数目时,首先,将递归特征消除算法作为特征选择方法;然后,利用Lasso回归和岭回归对递归特征选择算法进行改进;最后,利用回归模型进行缺陷预测排序。实验结果表明,改进的递归特征消除算法能够提高缺陷预测排序能力。"
575,融合用户评论的新闻内容质量检测算法研究,"网络自媒体平台上新闻数量庞大,文章质量良莠不齐,人工审核的成本太高、效率太低,平台亟需一个自动低质新闻检测系统。目前已有的新闻内容低质检测工作存在以下几个问题:1)只针对单个质量类型建模进行研究,比如虚假探测,缺乏对整个新闻多角度多类型的检测;2)平台针对新闻内容的曝光前的先验检测模型比较“宽容”;3)基于新闻内容的模型有着无法检测的低质类型的局限性,比如抄袭;4)对于自媒体编辑者有意规避平台规则创造的新低质新闻无法检测,另外,低质新闻类型繁多、难于定义全面,很多低质类型没有被定义。5)已有的新闻低质类别存在交叉重叠问题。针对以上问题,本文提出了融合用户评论的新闻内容低质检测算法的开放性版本。本文研究工作对平台设计规则去阻断低质新闻的传播、提升推荐效果、检测低水平作者等都有重大作用。本课题的主要研究内容如下:(1)本文第二章针对问题1将新闻内容质量检测作为一个多分类问题,提出了基于新闻文本内容的先验低质检测QAM-C模型,结合循环神经网络和卷积神经网络捕捉句子中的局部语义信息和长距离语义信息,并使用层次化的网络结构对长文档建模捕获句子间的依赖关系。将提出的模型和流行的机器学习、深度学习模型的效果进行了对比,实验结果表明我们的模型效果胜过了所有的基线模型,同时也发现,文本内容特征不足以满足部分类别的检测。(2)本文第三章针对问题2和3,提出了融合用户评论的后验低质检测QAM-CR模型,增加了一个子模块来对用户评论进行建模。该模块使用LDA主题模型捕获多条评论中的集中话题,利用记忆网络结合注意力机制选择重要的评论特征以过滤噪声干扰。将QAM-CR模型与第二章模型效果进行实验对比,实验结果表明,我们提出的模型胜过了基线方法的同时,也超过了我们的先验模型,进一步证明了评论特征的有效性。(3)本文第四章针对问题4和5,将新闻内容质量检测转化为一个开放性的多标签分类问题。采用了迁移学习的方法训练模型,引入了reject机制,基于统计方法动态选择阈值。我们在上文的实验结果基础上,对比了QAM-CR模型的开放性版本的效果,证明了模型的有效性。"
576,基于运行时特征和机器学习的并行程序性能预测,"随着高性能计算系统计算能力不断提升,其体系结构和软件系统的复杂性和规模也不断增加,这对各种大规模并行应用的设计和优化带来极大的挑战,因此面向高性能系统的大规模并行应用性能建模的研究越来越重要。准确地预测大规模并行程序的性能,不仅能够为用户分析程序性能,使其能在高性能计算系统上高效地执行应用程序,还能帮助用户管理和调度作业,合理地分配调度策略,减少作业等待时间,并且能够进行资源评估,指导用户申请资源。本文提出一个并行程序性能预测框架,由特征获取、性能建模和性能预测三部分组成。该框架使用基本块频率作为程序特征,然后利用机器学习算法构建多输入参数的性能预测模型。在获取特征的过程中,首先通过插桩技术获取小规模并行程序运行时特征,然后使用预处理技术选择有用的特征。在性能建模部分,以基本块频率和进程为输入,程序运行时间为输出,进行性能建模。在性能预测部分,为了降低获取大规模并行程序特征的开销,提出了混合插桩算法和程序删减算法。在本文的最后,通过在天河二号平台上执行六种常用的并行测试程序,对提出的性能预测框架进行验证。实验结果表明,当该性能预测框架采用支持向量机回归建模时预测效果最好,平均预测误差低于10%,误差的标准差低于7%。本文还与两个典型的以输入参数为特征的建模方法进行对比,实验证明,本文提出的方法优于其他两种方法。此外,预测开销低于整个程序开销的0.13%。综上所述,本文提出的并行程序预测框架生成的预测模型具有强泛化能力,并且预测的开销小。"
577,基于机器学习的网购平台产品评论情感分析,"随着互联网的发展,电子商务迅速兴起,很多消费者选择线上购物并且针对所购买的产品质量及购物体验发表自己想法和建议。这些网购平台的产品评论中往往蕴含着大量有用的信息。对于消费者而言,可以为购物者提供参考意见,间接影响着消费者的购买决策;对于商家来说,这些产品评论有助于对产品质量,客服服务等等进一步完善;同时网购平台也可以根据这些信息对商家进一步的管理。因此,对网购平台的产品评论进行情感分析具有一定的现实意义。近年来,文本情感分析受到了越来越多人的关注和研究,现有的研究中均取得了一定的研究成果。本文在前人研究的基础上,提出了一些新的研究思路,具体研究工作如下:第一,在中文分词问题上,本文基于隐马尔科夫模型进行中文分词,然后利用Word2ve方法来提取文本特征生成词向量,最后结合文本分类中常用的机器学习算法即支持向量机(SVM),K近邻分类(KNN),朴素贝叶斯(NB)和深度学习中的长短期记忆网络(LSTM)进行分类,通过准确率,F1,ROC曲线和AUC对模型性能进行评价。根据Python实验结果得出结论:LSTM模型的分类性能明显优于其他三种机器学习的分类算法,但所需训练时间也最多;SVM和KNN的分类效果次之,NB的分类效果相较之下最差。总体来讲,四种分类算法的分类效果按照从优到劣可表示为:LSTM>SVM>KNN>NB.第二,在上文基础上,引进集成学习的方法。本文介绍了三种常用的集成学习方法包括Boosting,Bagging和Stacking,并提出一种新的模型集成思路:首先将SVM,KNN,NB作为集成方法Stacking的第一层的基础学习器,然后将其预测值作为第二层的输入特征,第二层选用Boosting,Bagging,LSTM作为元分类器,在第三层中将第二层的预测结果进行投票作为总模型的最终输出。实验结果显示,这种模型集成的思路可以有效提升分类器的精度和F1,验证了这种方法的有效性。"
578,用于割草机平台的行人检测技术研究,"近年来随着计算机处理器计算能力的提升,计算机视觉技术得以长足快速的发展。行人检测是机器视觉领域的研究热点,在智能监控,无人驾驶等系统中有着广泛的应用。草地上行人的精确识别是割草机器人最为关键的技术之一。草地环境具有复杂的自然环境、障碍物形状的不规则性、光照多变等特殊条件,使行人检测的过程处理更具有挑战性。本设计为割草机的行人检测模块,主要工作为识别草地上的行人并加以标记,机器人根据识别信息进行相应的回应动作。以计算机视觉为基础,改进传统行人检测算法。主要工作如下:设计了一种机器学习行人检测特征提取方法,使用混合特征提取的方式使提取的特征具有多样性,提升召回率。使用多例学习支持向量机进行分类,引入“袋”模型的概念,提升分类的准确率。针对传统算法在特征提取中消耗大量时间的问题,引入了Cascade级联分类器,使用层数较低的Cascade分类器提取出大量的行人框,保证了行人在行人框中,且行人框的数量远小于历遍过程取得的框数量,提升了检测速度。设计了一种改进单步多框检测器模型,利用深度学习神经网络模型高准确率检测的优势,引入轻量化网络代替SSD网络中的基础网络,用低参数量的深度可分离卷积代替原模型中高参数量的普通卷积,减少大量网络参数,前项传导公式使用BP算法减少计算量和初始参数设置难度,最终达到加速行人检测的效果。搭建了割草机视觉系统,机器学习部分采用混合特征增强鲁棒性,针对草地环境特殊性,使用多例学习支持向量机分类,深度学习部分采用改进单步多框检测器。利用双目相机模型,通过视差计算获取行人同割草机的距离。在实际工作场地进行实时测试,通过实验测试,改进的机器学习行人检测算法较传统的hog+svm算法速度提升近20%左右,深度学习算法速度压缩到每秒10.6帧左右,达到实时性要求。"
579,基于微博用户的消费意图识别技术研究,"近几年的高速增长点则集中在社会媒体上,微博微信等网络社交媒体的雨后春笋般兴起,让人们可以随时随地分享自己的生活、对热点的关注以及对时事的观点,人们的生活随着社会媒体的普及变得更加互联互通、共话共享。本文以微博为例,用户在微博上通过140字以内的短文本表达自己的想法,通过深度挖掘、条分缕析用户的微博文本来识别用户的消费意图。本文中定义消费意图为用户对于商品或者服务,表现出来的购买意向。通过发掘识别用户消费意图,可以将分析预测结果多角度多维度应用于商业推广和业绩预测等领域。例如在推荐系统中,如果发现用户具有消费意图,就可以精准的定向推荐给用户对应的内容,创造商业价值;在电影上映或商品发布的时候,相关文本中具有消费意图的比重可以反映用户对于它们的需求,为下一步的判断提供依据;在分析预测用户的消费行为时,首先需要确定用户是否具有消费意图,在判断清楚消费意图的基础上进一步的研究才具有价值。传统的消费意图识别方式是根据用户可能具有的不同的消费意图,构建特定的模版进行匹配。本文收集微博用户在电影领域领域的微博文本,将消费意图问题看作一个文本分类问题,首先采用支持向量机的方式对消费意图进行识别,解决了构建模版导致的实现复杂、可扩展性不强的问题,并且使用LDA主题模型扩展文本的特征。随后采用深度学习的方式通过构建卷积神经网络和长短期记忆网络结合的模型进行消费意图识别。在消费意图识别过程中,卷积神经网络对于用户的微博文本进行特征的抽取,结果作为长短期记忆网络的输入,长短期记忆网络处理文本中的特征的时序关系,输出消费意图文本的分类结果。实验结果中支持向量机分类方法最优F值为70%,神经网络模型F值为84%,能够有效的识别用户的消费意图。随后介绍了事理图谱技术,通过对事件的分析预测,构建实例图谱揭示事物演化规律,进行更好的消费意图挖掘和精准化推送产品或者服务。"
580,基于机器学习的试题多知识点和认知动词自动标注研究,"在互联网教育时代,教育信息化为教育领域带来了重大变革,很多教学资源都以数据的形式存储。其中尤为重要的是试题数据资源。而现在普遍存在的情况是,这些试题数据在设计时仅仅包含试题的内容和答案,并没有直接给出试题所考察的目标,即缺少认知动词和知识点的标注。因此,如何能自动地为试题标注所考察的知识点和要求的认知动词层级,更好地发挥试题数据资源的作用是一项十分有意义的研究内容。基于此,针对数学试题数据本文的研究任务主要分为两部分,分别是基于机器学习的知识点标注和认知动词标注。(1)提出了一种基于集成学习的多知识点标注方法。在试题知识点标注方面,首先对试题知识点标注问题进行了形式化的定义,将试题多知识点标注问题转化为多标签分类问题;借助教材目录和领域知识构建知识点的知识图谱,并以此作为试题的知识点标签体系,并用知识图谱对原始的试题知识点数据进行了替换;构建了以支持向量机为基分类器的集成学习多知识点标注方法,通过设置子集准确率阈值来筛选出优基分类器进行集成,以期达到更好的标注效果。(2)提出了一种基于数据增强的数学试题认知动词标注方法。首先,使用不同认知动词下的试题文本数据分别构建深度文本生成模型,用于生成不同类别下的大量数据,以便弥补原始数据中存在的不平衡问题。其次,在设定文本长度阈值对生成的数据进行初步筛选的基础上,借鉴主动学习的样本查询策略,使用不确定性抽样方法对生成数据进一步筛选。最后,使用筛选得到的生成数据和试题数据结合用于训练TextCNN模型。本文对数学试题知识点标注和认知动词标注进行了研究,提出了两种不同的标注方法,在一定程度上都优于传统的机器学习标注方法。"
581,大空间视频烟雾检测算法研究,"随着科技的日益发展,监控视频已广泛部署于各种大空间场景中,其除了用于视频图像实时观看、录入、回放、调出及储存外,目前国内外研究者们更进一步探索它的新兴应用,例如利用监控视频实现火灾检测、行人检测等。传统的接触式火灾检测方法主要使用感温,感烟,感光等传感器来获取环境中温度、空气成分、光强等信息变化实现火灾检测,这些方法由于精度低、不稳定、技术限制等原因已无法满足大空间场景中的火灾检测。视频火灾检测(VFD,Video Fire Detection)技术相比传统接触式火灾检测技术具有更好的稳定性,能适用于仓库、车站、广场等大空间场景中,因此,受到了广泛关注。论文主要研究大空间场景中VFD的一些关键技术,在已有VFD技术基础上,将均匀局部二进制模式(ULBP,Uniform Local Binary Pattern)、离散小波变换(DWT,Discrete Wavelet Transform)、机器学习分类器及卷积神经网络(CNN,Convolutional Neural Network)理论引入VFD中并进行了深入的研究。以下为研究主要完成的工作:1.研究了常用的运动物体检测方法,提出了一种结合YUV颜色空间烟雾滤色规则和高斯混合模型(GMM,Gauss Mixture Model)运动检测的烟雾运动区域检测算法。现有的运动物体检测方法在复杂环境中不仅不能有效提取完整的烟雾运动区域,而且提取的区域包含大量的非烟雾像素物体。运动物体区域检测不能有效提取烟雾区域,轻则导致图像分类算法计算量增大,影响实时性,更严重则将导致图像分类不准确。论文提出的方法可以有效的获取运动区域,且能滤除该区域非烟雾像素。2.研究了常用的特征提取方法及机器学习特征分类器,提出了一种基于多特征融合和Real adaboost的烟雾图像识别方法。仅使用单一特征提取方法获取的特征极不稳定,极易受环境干扰,而且仅使用一种方法不能充分提取烟雾图像中的烟雾信息。此外,已有的烟雾识别方法大多都仅考虑常用的机器学习分类器进行特征分类,这些方法的分类器算法存在与输入特征不匹配导致最终烟雾图像识别算法精度不是很高。论文提出的方法融合多种特征,并选用匹配度较高的分类器算法,有效的提高了烟雾图像的识别准确率。3.研究了经典卷积神经网络模型,提出了一种基于卷积神经网络的烟雾图像识别网络模型。现有的VFD技术的图像识别方法大多采用浅层机器学习结构实现烟雾图像识别,即首先使用特征提取方法获取烟雾图像中的烟雾信息形成特征向量,然后利用机器学习分类器进行分类,达到烟雾图像识别目的。浅层机器学习的结构为人工提取图像中的特征,特征存在不充分或冗余。论文提出的网络模型,网络结构简单,能实现自动化的图像特征提取和图像分类。"
582,嵌入式环境下人脸识别技术研究,"人脸识别是计算机视觉领域的重要分支和研究方向,在智能家居、身份认证等领域有着非常广泛的应用,基于机器学习的人脸识别算法也越来越受到学术界的重视。本文的主要工作是人脸识别技术的研究,重点是子模式GLHist-LP人脸识别算法的研究,以及该算法在以ARM为核心的嵌入式平台上的实现、测试与分析。在研究分析了现有人脸识别相关技术基础上,提出了子模式GLHist-LP人脸识别算法网络结构,与现有识别算法相比,该结构降低了人脸特征的维数,可以加快人脸识别算法的执行速度,提高人脸识别准确率与效率;主特征提取的主要工作是通过面部局部区域划分形成子模式,对得到的四种子模式图像利用改进的Gabor滤波器进行卷积处理,进而得到Gabor特征图,并对特征图集合进行二值模式直方图降维,提取到256维的LGBP直方图信息,将其结果应用于子模式GLHist-LP人脸识别算法中,降低了识别算法的运算量;辅特征提取的主要工作是利用LBP特征对全局图像的纹理敏感性和旋转不变性实现特征提取,对得到的特征向量再通过2D-PCA线性映射算法完成降维操作,得到维数为82的辅特征,针对主特征缺乏面部整体结构信息的问题实现了完善和强化,提高了识别算法的精度;对主特征和辅特征进行数据归一化融合,融合后的特征总维数为338,从而得到人脸识别的关键特征信息;通过迭代的方式将不同的Adaboost弱分类器训练成高精度和高泛化性的识别模型;在嵌入式平台上进行算法实现,完成了主特征提取、辅特征提取、特征融合和分类器训练等工作,实现了人脸识别功能。该子模式GLHist-LP人脸识别算法基于嵌入式平台的实现程序测试结果表明,程序运行流畅,模型工作正常,人脸识别正确率为94.46%,人脸识别时间在1s以内,达到了预想目标,具有实际应用价值。"
583,基于内存转储分析的代码注入攻击检测方法,"代码注入攻击是计算机系统安全领域面临的重要问题之一。基于主机的代码注入攻击(HBCIA,Host-Based Code Injection Attacks)相比于早期的代码注入攻击,因其攻击方式的隐蔽性和复杂性,给用户计算机系统带来了巨大的威胁。在基于主机的代码注入攻击中,注入者实体和受害者实体同为驻留在同一操作系统上的进程,注入者实体通常利用操作系统提供的系统调用接口来对受害者实体进行代码注入。为了对引入基于主机的代码注入攻击技术的恶意软件进行有效检测,当前业界公开了多种基于主机的代码注入攻击检测方法,从动态监测和静态检测两个侧面,在不同的主体和内存区域粒度上对基于主机的代码注入攻击恶意行为实施检测。其中,基于主机的代码注入攻击内存取证方法基于对内存转储文件的分析来检测基于主机的代码注入攻击,被认为是最为实际有效的检测手段之一。本文对当前在内存转储文件中检测基于主机的代码注入攻击的主流系统Quincy进行了深入研究分析,发现Quincy系统采用的基于机器学习的基于主机的代码注入攻击内存特征方案存在以下问题:首先,Quincy系统采用的基于主机的代码注入攻击内存特征方案仅考虑与进程内存结构分布和代码语言属性相关的局部特征,而未考虑与进程、线程相关的全局特征;其次,Quincy系统采用的基于主机的代码注入攻击内存特征方案中存在局部类中特征缺失或特征描述粒度较粗的问题。以上问题导致在Windows 10系统下对恶意软件家族检测的查准率较低。针对以上问题,本文提出一个新的基于主机的代码注入攻击内存特征方案。该方案具有如下特点:(1)向Quincy系统的基于主机的代码注入攻击七大特征类内存特征方案中增设一个global特征类,加强了对目标恶意代码所在进程和线程的信息相关基于主机的代码注入攻击特征的考量。(2)向Quincy系统的基于主机的代码注入攻击七大特征类中增添了与对抗取证相关的内存特征、与恶意木马隐蔽通信机制相关的内存特征、以及与木马恶意操作行为相关的内存特征。上述新增特征和特征类全面升级了当前Quincy系统的内存特征方案。在新内存特征方案基础上,本文为Quincy系统设计并实现了一个性能扩展组件Eugen,用于提取新基于主机的代码注入攻击内存特征并对基于主机的代码注入攻击进行高精确性检测。对Eugen组件加强的Quincy系统进行的性能测试结果表明,基于新的基于主机的代码注入攻击内存特征方案的系统比基于原七大特征类的Quincy系统在Windows 10上表现出了更强的家族探测能力和查准率,相对于Quincy系统家族探测度提升了1.6个家族,家族完整度提升了1.6个家族,查准率提升了7.2%。"
584,分布式消息系统性能优化技术的研究与实现,"近年来,随着金融应用、传感器网络等领域的迅速发展,新的数据每分每秒都在产生。为了从海量的新数据中持续实时地获取分析结果,许多大型互联网公司采用流计算来处理数据。作为流计算的底层通信主干,分布式消息系统被广泛采用。随着数据量不断增大,分布式消息系统的性能问题逐渐暴露出来。为了更好地支持不同的应用场景,分布式消息系统提供了大量可供配置的参数。但是,对于大多数用户来说,如何配置这些参数来提高分布式消息系统的性能是十分困难的。虽然目前存在一些能够提升分布式消息系统数据处理能力的性能优化方法,但是在样本数量较小、时间有限的场景下,其性能优化效果并不理想。如何在有限的优化时间内,对分布式消息系统进行有效的性能优化成为了工业界和学术界亟待解决的问题。针对上述提出的性能优化问题,本文通过对分布式消息系统进行分析和建模,提出了一种自动化的性能优化方法。该方法在实验样本的基础上,构建了一个基于随机森林的性能比较模型,并借助模型在配置集合上的排序能力,设计了一种最优配置搜索算法。该算法能够在有限的时间约束内,搜索出使得系统性能较优的配置。本文的研究内容分为以下几个方面:(1)定义分布式消息系统性能优化问题。对分布式消息系统进行性能建模,使用数学公式对应用场景、运行环境、系统配置等性能影响因素进行定义。分析了分布式消息系统的性能优化问题以及现有解决方法的不足,最后对性能优化问题进行数学建模,给出了性能优化问题的明确定义。(2)构建基于随机森林的性能比较模型。对分布式消息系统的配置参数进行预处理和抽样,并结合实际集群进行吞吐量实验,初始化训练样本。选择随机森林模型对训练样本进行学习,构建出能够对吞吐量大小关系进行比较的性能模型。最后使用排序准确度公式,对性能比较模型的准确度进行验证。(3)设计与实现基于搜索的性能优化方法。在性能比较模型的基础上,结合加权的拉丁超立方抽样方法,实现了一种基于搜索的性能优化方法。该方法能够在有限的优化时间内,结合全局搜索算法与局部探索算法,选择出性能最优的配置参数组合,并将候选的配置集合输入实际集群中进行吞吐量测试,然后把测试所得到的吞吐量输入优化方法中进行再次迭代,在优化时间结束后,输出当前的最优配置参数。在实验部分,本文使用相同的训练集对传统的性能预测模型和基于随机森林的性能比较模型进行训练,比较两种模型在测试集上的排序准确度。在8种不同的应用场景下,使用包括Random、BestConfig、RFHOC、Hyperopt和SMAC在内的5种对比算法对本文提出的性能优化方法进行验证和分析。实验结果表明本文的性能优化方法得到的吞吐量相比对比算法平均有21%的提升。"
585,基于机器学习的第三方追踪和反广告拦截检测系统,"随着现代化的不断发展,为了丰富网页内容和吸引更多用户,很多网站会在网页中嵌入第三方应用程序~([1])。第三方应用程序可以美化网页,提升用户与网页的交互好感。然而也存在一部分第三方应用程序在服务网页的同时会侵犯用户的隐私信息。它们通过收集用户的浏览历史以及用户在网页中的一系列交互行为来分析用户的喜好,从而制定适合特定用户的广告。还有一些第三方应用程序试图了解用户更加私密的信息,包括怀孕生育、修复不良信贷等。为了保护用户隐私信息,研究人员和政府机构已经提出了一系列的保护措施。其中最有效的方式之一便是使用黑名单来拦截具有追踪行为的第三方应用程序。具有追踪行为的第三方应用程序通常以四种方式存在于网页中,包括web bugs、iframe、JavaScript文件和Flash文件~([2,3])。Flash文件在第三方追踪中起着非常重要的作用。本篇论文开发了一个系统DFTrackerDetector,其主要对网页中的第三方Flash文件进行检测,查看其是否具有追踪行为。根据不同的行为方式和不同的目的,Flash文件会调用不同的ActionScript API。因此DFTrackerDetector以ActionScript API为特征,利用静态分析的方法对特征进行提取,最终利用机器学习算法构建分类器并自动化生成追踪者名单列表。DFTrackerDetector在测试集中具有94.73%的准确率。广告在互联网的发展过程中起着举足轻重的作用。网站会在网页中留出一定的位置展示广告并赚取一定的费用,因此用户可以在终端获得免费服务。但是由于利益的驱使,造成了一些网站对广告的滥用。一些广告会被放到非常明显的位置以至于影响用户的正常阅读,还有一些广告会追踪用户信息,造成用户隐私信息的泄露。随着用户对保护个人隐私意识的不断提高,为了获取一个干净安全的浏览环境,越来越多的广告拦截插件被安装到浏览器中。用户的这一行为严重影响了在线广告行业的商业模式,使得广告商不得不对此行为实施一系列的反击措施。一些网站参加了所谓的“可接受的广告计划”,从而该网站的广告不被广告拦截器屏蔽,可以完整的被展现在网页中。还有一些网站会在网页中部署JavaScript文件来检测用户的浏览器中是否安装了广告拦截器。检测到广告拦截器后,JavaScript文件会做出一系列的响应,一些JavaScript文件要求用户完全禁用广告拦截器或者将该网站列入白名单,还有一些JavaScript文件要求用户进行捐赠以正常浏览网页。为了应对广告商的反击,广告拦截器也正在检测和过滤反广告拦截器。为了快速生成反广告拦截器的名单列表,本文提出了一个基于机器学习的反广告拦截检测系统ABDetector。具有反广告拦截行为的JavaScript文件和没有反广告拦截行为的JavaScript文件会调用不同的JavaScript API。因此ABDetector将JavaScript API作为特征来建立分类器,不同于其它特征提取的方法,本文使用动态分析的方法来提取JavaScript文件中的特征。在测试集上ABDetector的准确率为81.46%。"
586,基于机器学习的二进制漏洞挖掘技术研究,"传统的软件漏洞挖掘技术是包括模糊测试、符号执行、模型检测和污点分析等在内的技术。近年来,大数据和机器学习的兴起又引导了新一轮的软件漏洞挖掘技术研究。目前,使用机器学习或数据挖掘进行软件漏洞挖掘的研究主要分为三大类:基于软件度量的漏洞预测技术、基于异常检测的漏洞预测技术及基于漏洞代码模式识别的漏洞预测技术等。但是,先前的大多数研究都是针对源代码的,只有很少一部分是针对二进制软件的。并且,大多数的研究都是基于粗粒度的,以软件组件为粒度的漏洞挖掘不利于精确定位到漏洞的具体位置,以函数为粒度的漏洞挖掘将漏洞模式局限在函数内部。本文主要研究了以下内容:(1)分析当前主流的软件漏洞的产生原因,总结缓冲区溢出、整数溢出、释放后重用漏洞在汇编层面上的特点,了解程序运行时可能接收到的信号以及部分软件保护机制,通过静态分析和动态分析的常用手段实现对程序进行跟踪和自动化分析。(2)在样本收集方面,本文认为函数调用序列不足以刻画漏洞,因而提出一种基于代码块粒度的样本收集方法,创新性地以汇编代码块为粒度,对于漏洞程序,提取从数据引入到程序崩溃之间的代码片段;对于正常程序,提取从数据引入点到程序退出之间的代码片段。在提取的过程中,解决由程序开启所有安全保护而导致无法提取PLT表的问题,并提出基于代码块分簇的降循环算法来降低相同代码片段的循环次数。针对样本收集不平衡的问题,本文提出了一种针对汇编代码块的过采样技术。(3)针对汇编代码块序列,本文设计了基于Block2Vec的机器学习模型。先前的工作是以每条汇编指令为单位作为Doc2Vec模型的输入,而本文以基本块为单位作为Doc2Vec模型的输入,因此称为Block2Vec。在Doc2Vec模型的训练上,本文将收集到的所有程序的所有汇编代码块的去重集合作为训练数据。训练完成之后对样本中的每个代码块进行向量表示,相同模式的代码块在经过Doc2Vec模型表示之后的结果是相近的,最后通过级联和统一维度处理得到该样本的向量表示。为了测试汇编代码块序列样本的效果,本文构建了LSTM网络和Text-CNN网络,将汇编代码块序列样本和函数调用序列样本经过上述相同的处理,分别训练LSTM分类模型和TextCNN分类模型,结果表明使用汇编代码块序列作为样本的Text-CNN模型效果较好,准确率达到96.3%。"
587,调用路径驱动的Android应用程序恶意行为检测方法研究,"Android是目前使用人数最多,应用最为广泛的移动操作系统。由于Android开源、开放的生态,开发者可以自由地开发第三方应用软件,以运行在搭载Android平台的智能终端上。海量的应用软件为数以亿计的用户提供各种各样的服务,但其中隐藏着大量的恶意软件,不断窃取和操纵用户敏感的隐私数据,导致信息泄露、电信诈骗等违法活动层出不穷。现有Android恶意软件检测方案通常将敏感API的使用集合作为恶意软件特征,存在粗粒度和精确性较低的局限性。而API的调用顺序和执行路径是所有应用的基本逻辑,提取敏感API的调用顺序和执行路径作为特征,是对API使用集合特征的深化扩展,可称为“特征的特征”。因此,为了提升Android恶意软件检测的精确性,本文重点关注应用软件的敏感调用路径。在分析Android应用的运行机制、监听和回调机制的基础上,本文通过对应用软件执行静态分析得到敏感的调用路径,同时引入了多种机器学习算法训练Android恶意软件检测分类器。因此,本文提出了基于敏感调用路径的Android恶意软件检测方法,有效地实现了对未知安全性的Android应用软件的准确检测。本文的主要贡献如下:(1)量化Android系统的敏感API,建立了包含647个API的敏感目标API列表。引入了自然语言处理中的关键词抽取技术,提取Android恶意行为知识库中的敏感行为关键词,通过在Android官方开发文档中搜索和匹配关键词,生成了该列表。(2)针对Android恶意软件检测,提出了一种细粒度的恶意软件检测方案。该方案根据一系列敏感的目标API,在静态分析生成程序调用图的基础上,深入理解函数的执行逻辑,生成能够执行到这些目标API的敏感调用路径的集合。在对大量应用软件样本分析后,建立了一个包含73848条不重复调用路径的Android敏感调用路径特征库。(3)引入有监督的机器学习算法,训练Android恶意软件检测分类器。将样本软件生成的敏感调用路径集合和特征库进行匹配,采用one-hot的编码方式处理成相应的特征向量,采用k-近邻、朴素贝叶斯、支持向量机、随机森林四种经典的分类算法,训练恶意软件检测分类模型,通过模型评价指标对其进行调参和分析,最终使用随机森林算法训练的Android恶意软件检测分类器性能最好,准确率达到98.9%,相比于DroidAPIMiner提升了3.97%。"
588,基于静态行为特征的恶意软件检测方法与实现,"人们在受益于移动手机带来的便携服务的同时,所面临的Android软件安全问题也愈发严峻。目前学术界针对Android恶意软件检测的研究,主要采用动、静态分析两种方法。动态分析方法能够捕获应用程序运行时状态,但其相对耗时且检测成本高;静态分析方法拥有无需实际运行应用程序、代码覆盖率高等优点,但仍存在若干不足,例如需要手动维护庞大的病毒特征库、无法对新型恶意软件做出有效识别。针对静态分析方法存在的问题,本文设计了一种面向静态行为特征建模的Android恶意软件检测方法,并实现了一套基于该方法的完整的检测系统。本系统在提取出函数调用关系图的基础上,抽象出具有更高语义且能有效区分Android恶意软件的概率特征向量,从而提高了检测恶意Android程序的准确度。具体的检测方法与实现内容有:1)本文设计的检测方法主要包括预处理、API调用序列获取、行为特征建模以及行为检测模型构建四个阶段。预处理阶段基于Soot开源框架,利用反编译技术并结合Soot的相关指令,自动、批量化地获取到Android应用程序的函数调用关系图;针对调用图存在的包含较多冗余API调用链等缺点,API调用序列获取阶段可从调用图中提取到包含时序信息、且特征数目明显减少的初级API调用序列;由于初级API调用序列的语义抽象程度不高,不利于多版本的Android应用程序检测,因此,行为特征建模阶段依据Android官方公布的包索引名,从初级API调用序列中抽象出对应的高阶序列,并借助于马尔可夫链模型中的状态转移思想,对高阶序列进行行为建模,以构建出概率特征向量,从而可有效表示API调用之间的高级语义;行为检测模型构建阶段基于AdaBoost提升方法,并结合CART生成和剪枝策略,可从概率特征向量中学习到检测恶意应用程序的分类器。2)基于上述Android恶意程序检测方法,本文实现了一套检测恶意Android应用程序的系统,该系统由预处理模块、API调用序列获取模块、行为特征建模模块与行为检测算法模块组成。为验证检测系统的有效性,本文首先就各模块的有效性分别做了实验测试,结果表明,新方法能有效获取到APK对应的函数调用关系图,提取出易于理解的初级API调用序列,抽象出具有高级语义的概率特征向量;然后,使用比例分割法和十次十折交叉验证法对海量数据集进行测试,取得了较低的误检率与较高的检测率,佐证了本文提出的检测系统能有效地识别Android恶意软件,并实时适应Android版本的变化,以及对新型Android恶意程序作出正确判断。"
589,基于在线机器学习的工业控制系统入侵检测算法研究,"工业控制系统是实现智能电网、智能制造等的核心与关键。开放性、智能化、网络化、实时性等导致工业控制系统面临严峻的信息安全挑战。工业控制系统的入侵具有时间跨度大、先验知识少等特点,导致基于规则和基于批量学习的入侵检测算法在实时性和效率方面无法满足工业控制系统的需求。工业控制系统的入侵检测算法核心在于数据分布不平衡情况下的跨时空传感器与控制器信息快速、实时、准确分类。本文针对工业控制入侵检测系统的实时性要求,采用在线机器学习(online learning)模式,研究工业控制系统的入侵检测算法,实现入侵行为的快速、准确识别。针对工业控制系统实时生成大量数据导致的数据标记工作代价过大问题,和异常行为数据占比相对较少的数据类别分布不平衡问题,采用主动学习(active learning)思想,对代价敏感的在线梯度下降算法CSOGD做出改进,提出一种基于在线学习的代价敏感主动机器学习算法。该算法通过在二元分类中提升少数类的错误分类代价,使分类模型以更高的置信度给出分类预测结果,提升少数类的识别率;并通过选择信息量最大的数据样本给出标记,仅利用标记样本更新分类模型,在提升入侵检测模型分类准确率的同时降低数据标注工作量。结果显示,在美国密西西比州立大学提供的工业控制系统数据集上,本文所提基于在线学习的代价敏感主动学习算法对异常行为的识别准确率相比于CSOGD算法提高11.08%。针对工业控制系统中异常实时检测和异常行为种类识别的需求,提出一种基于在线学习的代价敏感多元分类算法。算法实时接收系统产生的数据,利用代价敏感的思想,根据数据样本集中各类别样本数量设计代价矩阵(cost matrix);基于代价矩阵设计错误分类损失函数,计算不同错误分类导致的模型损失并更新模型,以高置信度给出实时数据的预测结果,提高多元分类模型对不同类别异常行为的识别能力。结果显示,在美国密西西比州立大学提供的工业控制系统数据集上,对数据集中含量最少的那一类异常行为的检测准确率最高达到89.40%,相比于同类最优算法ROMMA提高55%。本文提出的算法实现了在线环境下的工业控制系统入侵行为及时检测、异常行为分类和检测模型实时更新,适用于工业控制系统中数据类别不平衡的入侵检测分类任务。"
590,基于机器学习的SQL攻击检测技术的研究,"SQL注入是网络上使用非常广泛的攻击手段,也是防御难度极大的网络攻击方式。在信息安全领域中,SQL注入因其适用范围广,操作门槛低,可造成的损失大而被视为对网络安全威胁极大的一类攻击方式。针对SQL注入攻击的防御方法有很多,但随着SQL注入攻击的发展和网络规模的逐渐壮大,现有的SQL注入检测技术已经无法满足防御要求。随着机器学习相关算法的逐渐成熟,机器学习方法被应用到很多领域,也有人将机器学习方法应用到SQL注入检测中,但还没有成为主流的检测方法。目前商用SQL注入攻击检测方法大多还是基于规则防火墙技术来对SQL注入进行检测。本文提出了一个基于机器学习方法的SQL注入攻击检测,目的是能够更精准及广泛地检测出SQL注入攻击。在样本数据准备阶段,采用了三种方法进行收集样本数据集,首先,利用SQLMAP接口,编制扫描模块,对特定网站进行扫描,并捕获数据,获取大约7000条样本;其次,通过研究分析SQL注入的攻击特点与分类依据,建立了SQL注入攻击模型,以此为基础形式化描述SQL注入攻击,再实例化生成SQL攻击语句,通过合法扫描目标特定网站,利用软件捕获SQL注入攻击数据,收集了大约8000条样本数据;最后,人工在网上收集了现有的SQL注入攻击样本数据集。另外准备了5000条非SQL注入样本,加入样本集。数据准备完成后,我们选择了四种不同的机器学习模型建立分类器,分别是支持向量机、长短时记忆网络、卷积神经网络和K近邻算法。通过训练四种机器学习算法分类器,我们对四个SQL注入攻击检测分类器进行了测试。通过测试,我们发现无论是在训练效率,还是在分类准确率上,卷积神经网络算法都有着极大的优势,是最适合对SQL注入攻击进行检测分类的算法。而在所有种类的SQL注入攻击中,基于时间的注入攻击检测准确率是最高的,显错类的SQL攻击检测准确率是最低的。这说明,基于时间盲注的攻击是最容易分辨的,而显错类注入是最难分辨出的一类SQL注入攻击。"
591,面向AI应用的网络加速架构设计,"近年来人工智能技术取得了前所未有的高速发展,在很多领域内(比如互联网,自动驾驶等)扮演着不可或缺的角色。随着人工智能时代的到来,为了解决海量训练数据和场景复杂度高等诸多难题,更大规模的机器学习模型应运而生。大规模的机器学习模型往往具有更高准确性,同时也具备更强的表达能力,可以帮助人们解决难度较高的问题。然而,大规模的机器学习模型无可避免的将会使训练节点面临计算能力和存储的双重压力。模型计算复杂度高,会导致单机训练可能消耗无法接受的时长,机器学习模型的规模大,会导致单机的存储可能无法满足训练需求。因而使用分布式机器学习集群来完成训练任务变得至关重要。不同的并行化技术、集群架构和通信机制等都会对分布式机器学习集群的性能造成很大影响,如何更好地在分布式机器学习集群上面进行数据及模型的划分、存储和训练等是分布式机器学习面临的主要问题。不同模型在分布式集群上进行模型训练时可以使用不同的并行化技术,对于单机无法存储的大规模模型,只能使用模型并行方式进行训练,而目前分布式机器学习模型训练速度慢,模型参数规模大等依然是该领域面临的主要问题。针对这两个问题,本文首先从模型并行角度出发,详细分析了模型并行下机器学习模型的按层划分和跨层划分这两种分割方式及其对应的流量特性,并据此提出了模型并行下机器学习模型的分割优化策略MPOS。MPOS从模型不同层的通信特点、模型层构成关系两个方面出发,对模型分割后的子模型之间的计算能力和通信能力方面进行优化,旨在加快机器学习模型在分布式集群平台上的训练速度,降低模型训练时间。在实际平台部署后,根据测试结果,使用MPOS策略进行模型分割在训练时所用时间比一般的模型分割方法降低15%左右。为了更好地加快机器学习模型在分布式集群平台上的训练速度,本文又详细分析了机器学习模型训练在不同并行化技术下的流量特点,并基于此设计了适用于AI应用的分布式集群网络架构ECube。ECube架构很好地结合了AI应用的流量特性和在机器学习模型训练时不同工作节点之间的通信特性,相比常见的Fat-Tree架构和BCube架构,在数据并行和模型并行方式下,其性能均有很好的提升。根据仿真对比分析,在这两种并行技术下,在ECube架构上进行机器学习模型训练所用的时间普遍比在Fat-Tree架构上降低了40%左右,实现了模型训练的加速,降低了分布式集群进行机器学习所用的训练时间。"
592,基于CNN的恶意请求检测,"近20年以来,互联网在中国快速普及,各式各样的Web应用如雨后春笋般出现在互联网之上,为广大的网民用户提供各方面的网络服务。而由于Web用户的数量越来越庞大,Web服务在生活中的地位越来越重要,Web应用的安全问题也越来越受重视。特别是Web服务端的安全问题,服务提供商的Web应用在保证为用户提供优质服务的同时,还需提防来自各方面的恶意攻击。而对于Web应用而言,很多恶意的攻击都隐藏在海量的用户请求之中,Web应用要想为用户提供优质服务的同时抵御这些恶意攻击,就需通过恶意检测系统将正常用户请求与恶意用户请求区分开,以阻止Web应用对恶意请求的处理。目前大部分Web应用实际使用的恶意Web请求的检测方法主要还是基于保留字符串的检测方法。通过对各类恶意请求的原理和外部特征的分析,总结出一些恶意请求特有的字符串作为系统保留的字符串,恶意请求检测过程即是对这些保留字符串的检测,含有保留字符串的Web请求就会被归为恶意请求。这种检测方法虽然查准率较高,但需人工总结和维护保留字符串,而且当恶意请求改变攻击方式或者隐藏关键字后,便可绕过此类检测方法的检测。本文设计并实现了一个基于CNN模型的恶意Web请求检测系统。通过借鉴CNN模型识别图像时的特征提取原理,本文针对Web请求的URL结构,设计了一个基于CNN的恶意Web请求检测模型,通过CNN的卷积核自动提取各类恶意请求的显著特征,进而从海量的用户请求中检测出待检测的各类恶意请求。通过在最终的测试过程中与其他同类模型相比,本文的模型在查全率与查准率的指标上占优的同时,还大幅降低模型的假阳率。针对复杂的Web应用环境,为了提高整个检测系统的应对攻击方式变化的能力,本文还设计并实现了模型调度系统,帮助检测模型实时采集线上数据,监测线上数据的变化,并筛选典型恶意样本再训练并更新监测模型,使整个系统能自动适应攻击方式的改变,以保证检测系统的长期稳定,高效的运行。而从最终的测试结果来看,当恶意Web请求的攻击方式发生改变时,在调度系统完成对新攻击样本的采集之后,再使用更新的训练集训练现有模型,进而更新检测系统的检测模型,使整个检测系统适应攻击方式的改变,从而使检测系统可持续帮助Web应用有效抵御各类恶意Web请求。"
593,面向特定应用的拥塞控制策略研究,"强大的计算能力和海量的训练数据推动了基于机器学习的图像分类、语音识别、无人驾驶等高新技术的迅猛发展。随着机器学习模型的不断增大,日益复杂的计算任务对存储和计算能力的需求需要通过分布式机器学习系统来解决。大规模分布式机器学习普遍采用的数据并行的分布式策略会产生典型的多对一流量模式,快速增长的参数同步数据量规模和频率对网络提出了更高的带宽需求。网络通信成为了分布式系统机器学习应用完成速度的重要瓶颈。传统的拥塞控制策略没有考虑分布式机器学习应用的通信模式和流量分布特征,粗粒度的控制机制使网络不能灵活响应网络波动,导致网络出现拥塞,影响分布式机器学习的训练速度。本文根据当前拥塞控制策略的研究思路,从单路径传输和多路径传输两个方面详细分析了相关策略,并从这两种思路出发,针对基于单路径传输的流完成时间优化问题和基于多路径传输的Transmission Control Protocol(TCP)incast问题分别提出了相应的解决方案。为了解决当前方案控制粒度粗、对后续流量预测性差以及收敛速度慢的问题,论文设计了基于单路径传输的时延量化拥塞控制策略。通过量化数据包排队时延并添加流量变化趋势,该方案能够获取细粒度的链路状态信息。状态信息采用快速反馈机制生成自定义数据包发送回源端,减少了滞留时间。发送端根据反馈信息采用发送速率调整算法准确控制发送窗口。仿真结果表明,该方案在一定条件下可以有效提高20%的网络吞吐,降低50%的平均流完成时间,改善小流完成时间长尾问题。为了在保留多路径传输网络利用率优势的同时,解决多路径传输本身机制对TCP incast问题的影响,本文设计了基于多路径传输的子流自适应拥塞控制策略。通过细粒度的拥塞信息感知以及根据拥塞信息的子流数目自适应机制,该方案能够动态调整可用子流数目并根据子流路径拥塞程度选择轻拥塞路径进行传输。在不降低网络利用率的同时,该方案能够增强网络对TCP incast问题的容忍度。仿真结果表明,该方案可以有效解决多路径传输下的TCP incast问题,性能表现与基于单路径传输的拥塞控制策略相当。在一定条件下,该方案具有更高的网络利用率以及更低的队尾时延。"
594,基于指纹与统计特征的HTTPS隧道流量检测技术研究,"随着信息化进程不断深入,大量设备、数据接入了互联网,给社会生活带来巨大便利的同时也引发了严峻的安全挑战。一方面,各类网络攻击层出不穷,大量数据泄露事件频现报端;另一方面,流量混淆工具的广泛使用使得一些网络流量审查机制疲于应对。网络攻击工具与流量混淆工具的使用目的虽然不同,二者在规避流量检测方面采用的技术却相似。随着加密技术的广泛应用,传统的基于深度包检测的方法逐渐失效。目前,网络安全防御者和流量审查者面临的共同挑战是:如何在不影响正常业务的同时从规模日益增长的网络流量中准确识别出攻击或混淆流量。目前规避流量检测的主要方法是混淆,即伪装成正常业务流量,具体分为随机化、拟态和隧道三种技术。如果一种混淆流量与正常业务流量足够相似,检测系统的误报率就会急剧升高,为了不影响正常业务,检测系统将不得不放弃对此类混淆流量的封锁。为增强隐蔽性,一些混淆工具选择目前使用广泛的HTTPS网络协议进行伪装。例如,Meterpreter是Metasploit渗透测试框架中一款高级动态攻击工具。为规避流量检测,该工具衍生出包括基于HTTPS协议的隧道在内的数个变种,但目前业界公开的对其流量进行识别的研究较少。又如,Shadowsocks是目前使用广泛的抗网络流量审查工具之一,为增强隐蔽性,社区开发了simple-obfs HTTPS流量混淆插件,但业界对该插件的效果一直存疑。针对这两种HTTPS隧道工具,本文从混淆流量识别的角度进行研究。(1)在详细分析混淆流量识别及相关领域主要的两种基于深度包检测和基于机器学习的方法优缺点后,提出一种将HTTPS流量的指纹特征和统计特征结合的机器学习检测方案。一方面,将HTTPS握手包中的明文指纹信息,如客户端支持的加密套件、扩展等,转化为数值特征;另一方面,基于HTTPS应用包中的统计特征构造二级特征。最后,将指纹特征、统计特征和二级特征输入机器学习分类算法训练检测模型;(2)在评估业界多个公开样本集及分析Meterpreter HTTPS和Shadowsocks Obfs两种隧道工作原理和流量特点后,设计并构建了两种HTTPS隧道流量及正常HTTPS流量的采集系统,共采集24,571条正常HTTPS流量样本,17,812条Meterpreter HTTPS隧道流量样本和7,692条Shadowsocks Obfs隧道流量样本,作为检测系统的样本集合;(3)设计并实现了基于指纹与统计特征的HTTPS隧道流量检测系统,自动完成流量样本解析、两类特征提取、分类模型训练和样本类型判别等工作。基于该系统和样本集合测试了覆盖多种类别的8个分类算法的表现。在对比分析各个算法的精确率、召回率和F1分数三个指标后,得出随机森林算法在此样本环境下整体表现最优的结论(精确率和召回率均高于99%)。对比分析了本系统使用随机森林算法检测两种隧道流量时得到的特征重要性排名,发现指纹特征和统计特征对两种隧道流量检测结果的影响大致相同,且对二者检测结果影响较大的特征也基本一致,表明本方案应该有较强的扩展性。"
595,Web页面浏览行为安全分析技术研究,"随着“互联网+”概念的发展和“大数据”时代的到来,Web服务越发广泛且规模越来越大,同时也出现了多种新的攻击手段。传统基于规则和特征的Web安全技术是永远在追着敌人跑,无法检测未知威胁,因此亟需更为高级的检测手段。行为安全分析作为一种以机器学习为核心的高级威胁发现技术,显示出了比传统安全手段更好的检测性能,正得到越来越高的关注。本文对Web页面浏览行为进行安全分析研究,提出一种混合行为分析技术,实现异常检测、遏制入侵和主动防御,并通过行为关联分析为安全事件调查提供情报上下文。本文主要工作和创新点如下:1.针对浏览行为数据维度不足的问题,在服务端日志数据的基础上引入了前端埋点数据和TLS指纹数据,更全面的描述用户的浏览行为。分析了现有TLS指纹数据的应用,针对其宽容度低的问题,提出了基于2-gram和局部敏感哈希的指纹增强方法。2.针对行为模式异常检测误报率高的问题,提出一种混合页面浏览行为安全分析方法。将行为分析技术分为行为模式分析和行为内容分析,首先使用隐马尔科夫模型学习正常用户的行为模式得到正常行为基线,判断行为模式与正常行为的偏离程度进行异常检测;接着结合深度卷积神经网络实现对行为内容的威胁检测模型;最后利用增强的TLS指纹将这两种模型融合,通过关联T分钟内的历史决策数据共同决策识别威胁。3.提出使用增强的TLS指纹关联分析发现使用分布式代理的黑客行为,对黑客进行追踪溯源,在安全事件调查时提供可视化关联分析结果,提高人工分析的效率。通过模拟实验以及对真实环境部署中得到的数据集进行测试,证实可以真实有效的发现黑客变换IP的多阶段攻击行为。4.使用OpenResty、TensorFlow、Flask、数据库和HTML等一系列技术完成了混合行为分析系统原型的设计和实现。通过对比实验,验证了混合行为分析方法相对于单独使用类HMM模型的行为分析异常检测方法有更高的查准率和查全率以及更低的误报率。对比实验结果也表明卷积神经网络对比LSTM网络更适合于浏览行为内容威胁检测。"
596,机器学习类WAF的安全性评估技术研究,"当前Web应用与服务呈爆发式增长,其对应的攻击也日益猖獗,Web安全威胁成为个人和企业无法忽视的安全痛点。WAF作为Web应用的第一道安全防线成为最常用的防护方案。随着机器学习技术的发展和应用落地,基于机器学习的WAF解决了传统基于规则WAF的检测效率低,维护复杂并难以检测新型Web攻击的问题,成为WAF发展的新方向。但是基于机器学习的WAF大多没有进行安全性测评,这无疑是一个重大的安全漏洞。针对此问题本文提出一种通过攻击方式对机器学习类WAF进行安全性评估的方法。本文的主要工作和创新点如下:1.首先总结和介绍了WAF中常用算法所面临的安全威胁及对应的攻击手段,并重点分析了其中的对抗攻击,信息泄露相关攻击和投毒攻击。2.提出一个可扩展的量化评估模型SQSE-Model,该模型首先从保密性,完整性和可用性三个方面对机器学习类WAF常用算法所面临的攻击进行分类,每种攻击作为评估模型中的一个模块,各个模块之间通过数据流相互联系;然后将数据流参数化,给出其计算方式,并提出评估模型中每个攻击模块的量化评估方法;最后得到一组从保密性,完整性和可用性三个方面对目标WAF进行评估的数字化结果。3.提出一种基于注意力机制的URL对抗样本生成算法,解决了文本对抗攻击领域中的对抗样本生成方法不适用于URL这种特殊文本格式的问题,并在SQSE-Model中基于该算法完成WAF完整性评估中对抗攻击的实施。该URL对抗样本生成算法首先通过模型提取攻击得到一个影子模型,根据影子模型中的注意力值推断出模型中对决策贡献度较高的词,然后通过URL中特殊字符的属性将决策高贡献词进行分类,最后按照所设计的策略对样本URL中的每一个键值对的值进行迭代的字符级扰动,直到达到扰动结束条件。4.选取了三个具有代表性的评估对象URLNet,HMM WAF和SVM WAF进行实验。根据每个评估对象的自身特点和环境设置,得到针对该评估对象的攻击路线。由于条件限制,实验实施了针对保密性和完整性的攻击,最后给出量化的计算结果。实验结果表明,所提出的URL对抗样本生成算法是可行并有效的,所提出的评估模型具有良好的适应性,可以给基于机器学习类WAF的安全性测评工作提供一种新的思路。"
597,归属演算下归纳学习初探,"人工智能研究的是智能行为的机制,它通过构造和评估具有智能行为的人工制品来研究智能。机器学习系统根据环境数据,通过一定的学习方法,获得处理某问题的方法。在机器学习领域中,归纳学习是指给定一个描述语言,智能体根据给定的语言所描述的符号数据,通过一定的搜索方法,获得一个一般概念、规则或理论的过程。归属演算就是可以表示归纳学习过程的一种描述语言,它由计算机科学家米哈尔斯基所介绍,以“属性和属性值的关系”为基础进行形式化,并给出了多于二值逻辑的多种解释模式。算法要做的就是问题求解,所以算法就是求解问题的过程描述。归纳学习过程聚焦到某类归纳学习问题时,就可以通过归纳学习算法来描述。归纳学习算法在重言蕴涵的基础上定义了泛化和特化两种相反操作符,从而定义了泛化规则。本文就是在结合归属演算和泛化规则的基础上,尝试将归属演算运用于简单的候选消除算法,从而在解决人工神经网络难解释性的指导下,探索归纳学习和人工神经网络结合的可能性。归属演算表示归纳学习的反思表明,对于泛化符等符号来说,它有归纳、属性关系、操作符和函数的解释。对一种符号具有多种解释方式,既是基于计算机实践需要的逻辑语言有表示力强的优点,也是具有模糊性的缺点。这尤其在对归属演算表示归纳学习的评价中可以看出。在归属演算对其他形式的转化中,属性论将个体的集合和属性相互转化的表示,使得以“属性和属性值的关系”为基础的归属演算语句转化为属性论形式成为可能,从而归属演算也可以转化为集合论形式。一阶谓词演算与归纳学习形式有直接的联系,归属演算语句可以转化为范式的形式,通过增加正反例谓词,问题则表示得更加简化。那么,如何在可解释人工智能的指导下重塑归纳学习是一个问题。在对归纳学习与机器学习其他研究方向的比较中,人工神经网络模型处理学习数据在数值域中,这和归属演算处理在符号域上形成对比,它们各有优缺点。归属演算表示的缺点主要在于离散结构以及计算空间复杂,它与人工神经网络相互借鉴已是未来趋势。一个方向就是建立基于综合逻辑方法和人工神经网络学习的人类智能模型假设。另一个方向基于归纳逻辑程序设计。归纳逻辑程序设计以一阶谓词逻辑为基础,其问题表示和归纳方法与归属演算表示异曲同工。归纳逻辑程序设计的高阶、概率和可微扩展与归属演算的其他解释模式形成对照。"
598,KPI数据实时异常检测算法研究与实现,"KPI数据(Key Performance Indicator)是有实际应用意义的、通过定时采样获取的时间序列数据,KPI数据异常检测对于企业应用有着十分重要的意义:通过实时的监控KPI数据,发现KPI数据存在的异常,及时进行相应处理,从而保证应用的正常运行。在企业中,通过对KPI数据设置阈值来进行实时异常检测的方法十分普遍,然而阈值的设置依赖用户经验,同时,随着KPI数据逐渐增多,为每一条KPI数据配置若干阈值的方法就会耗费巨大的人力。针对KPI数据异常检测问题,为了实现免阈值设置、高度自动化的目标,本课题开展了相关工作,提出了三种算法,这三种算法高度自动化,使得用户无需为每一条KPI单独设置阈值,具有很高的使用价值和实用意义。本文的主要工作包括:首先,提出了基于异常阈值可分性的KPI异常检测算法。本文给出了“异常阈值可分性”的概念用于评价特征是否有助于发现异常,利用异常阈值可分性,本文提出了基于监督学习的异常检测框架,通过算法自动提取每个KPI数据的特征,框架能够针对每个KPI的特点进行相应的学习,从而为每个KPI实现异常检测。经过与成熟算法和系统的实验对比,本文的方法能够将F1 score提升13个百分点以上。其次,提出了基于极端值理论的KPI异常检测算法。本文应用极端值理论,无需对原始KPI数据的分布做出任何假设就能实现动态阈值设置。本文的创新有三大方面,包括引入矩估计加速计算效率、引入预测算法改善异常检测效果,引入定量更新以应对概念漂移问题。最后,提出了基于动态投票的无监督KPI异常检测算法。结合KPI数据的特点,本文给出面向KPI数据的“局部区域”的概念,使得适用于特定数据类型的基本检测器在投票时有更高的权重。在此基础上,分别提出了动态硬投票算法和动态软投票算法,打破了传统无监督KPI异常检测算法只能通过硬投票方式进行异常检测的局限性。实验结果表明本文能将原有无监督异常检测系统的F1 score提升4个百分点以上。"
599,基于MEMS传感器的运动识别算法研究,"动作捕捉是指利用相应的传感器对目标物体的运动数据进行采样,记录其运动过程,然后通过计算机处理数据,最终实现对物体运动情况的分类识别或分析研究等功能的技术,其中基于MEMS惯性测量单元的运动捕捉系统能够真正实现不受场景约束的动作数据采集,在商用发展方面最具前途。当前对动作识别模型的研究主要停留在对传统机器学习算法的简单应用层面,识别算法往往只适用于特定的动作数据集,模型的迁移能力较差,为了弥补研究现状的不足,本文提出了包含“传感器信号接收-数据预处理-特征工程-识别模型”的一般化动作识别链流程,主要研究内容如下:实现了标准化的惯性动作数据预处理流程,包括简易的误差校准方案和适用的数据清洗方法,避免了MEMS器件的测量误差积累和采集过程中产生的脏数据对数据质量造成的影响。在数据预处理环节的基础上,针对离线识别和在线识别两种研究模式的需求,分别介绍了事件窗和动作窗两种分割逻辑下的动作截取算法实现。为了准确检测运动的起点和终点,利用Teager算子和高斯平滑滤波作为动作幅度指标,推导了动作阈值的参数建模方法,提出了以能量峰值为调节依据的自适应阈值确定方案,能够较为准确地截取各类有效动作信号段。为了尽可能覆盖主要的惯性运动特性,本文给出了能够表达多类动作特点的特征计算方法,具体包括统计学特征、信号时频特征和系统建模特征下共计19类特征。为了避免特征之间的实际区分效用重叠,本文基于信息增益原理提出了一套实用的特征贡献度评价指标,可以结合数据集实现对特征组合方案进行筛选调整。识别模型部分,本文讨论了传统机器学习算法作为动作识别模型的不足,基于集成学习原理,以分类回归树为基础分类模型,以boosting策略进行组合,在动作数据集上实现了极端梯度提升树的学习算法,结合特征提取策略,能够在羽毛球基础动作数据集对22类动作实现97.99%的准确率。在线动作识别方案下由于滑动窗无法精准地定位动作数据的位置,对识别算法的数据位移不变性提出了一定的要求。在此前提下提出了替代特征工程方案的深度学习方案,使用一维卷积神经网络搭建动作识别模型,在滑动窗采集方案下的平移扩展数据集上能够达到96.83%的准确率,表现出相对数据位移的鲁棒性。"
600,基于学习行为分析的学习能力评估与学习意图预测方法研究,"教育信息化进入了新的发展阶段,正在从数字教育转为以大数据分析、人工智能等现代信息技术为支撑的智慧教育。由于具有个性服务、智能分析、自然交互、泛在接入等特征,智慧教育成为我国教育信息化发展的趋势,也是落实党的十九大报告中“加快教育现代化”的重要举措。目前,智慧教育在导学、推荐、答疑、评价等环节仍存在一些技术难题,智慧教育在推荐环节,由于教育资源和学习者之间存在语义鸿沟,用户难以在众多的教育资源中找到符合自己需要的学习资源。如何填补教育资源和学习者之间的语义鸿沟,实现二者在语义层面的匹配,是应对这一挑战的关键。本文就如何填补教育资源和学习者之间的语义鸿沟的课题中的两个问题展开研究,即评估学习者学习能力问题和预测学习者学习兴趣与意图问题。评估学习者学习能力问题主要需要解决的问题是准确的评估、预测学习者的学习能力,以及准确的评估教育资源的难易度,通过将学习者学习能力与教育资源难易度的匹配,为学习者推荐合适学习资源;预测学习者学习兴趣与意图问题主要解决的问题是准确把握学习者在某些领域表现出的长期兴趣以及在某些专业甚至课程上表现出的短期的学习意图,使得在线教育平台能够为学习者推荐其真正感兴趣的教育资源。对于学习者于学习能力评估问题,本文提出了基于项目反应理论的学习能力评估模型,利用模型得出已有学习者的学习能力值以及题目参数,然后利用课程中各题目参数计算出了课程的多级难度,然后利用这些参数对新的学习者进行能力评估,针对学习行为数据不足的学习者,本文提出了机器学习与项目反应理论相结合的混合模型解决这类学习者能力评估的冷启动问题;针对学习行为数据较多的学习者,本文根据其在具体所学课程的学习情况提出了同课程学习能力评估和跨课程学习能力评估两种评估方法。综合以上三种评估方法,可以比较准确的评估学习者学习能力。对于学习者学习兴趣与意图预测问题,本文提出了基于文本分析的学习兴趣与意图预测模型,将学习者在学习平台的一些行为数据整理为文本数据,利用改进的TF-IDF算法和word2vec提取文本特征,将提取出的相应向量通过利用时间窗口以及引入衰减因子分别预测学习者长期的学习兴趣与短期的学习兴趣。针对无法进行在线验证的问题,提出了另一种验证方法验证了模型提取出的文本特征是有效的,进而说明本文预测出的学习兴趣与意图是合理的。"
601,基于智能计算的机器学习模型自动搜索,"自动机器学习是指在完全没有人工干预的条件通过算法自动的完成机器学习的完整设计流程,其核心是要实现包括模型选择、特征选择、参数调优等环节在内的自动化设计。自动化机器学习能够给研究者在已有问题上带来新的研究思路,并降低人工智能技术在各工业领域的应用门槛,已成为当前人工智能最前沿的研究方向之一。本文主要针对自动机器学习中的架构搜索方向下的两个子领域展开研究,分别是机器学习模型结构搜索和神经网络架构搜索。机器学习模型结构搜索研究如何自动设计机器学习模型集成的方式,通过自动尝试集成不同模型的优点得到优于单模型的集成模型。神经网络架构搜索研究如何自动设计神经网络架构,通过自动生成新的神经网络架构进行训练找到适合任务问题的网络架构。在机器学习模型结构搜索研究中,我们定义了一种基于图的模型集成表达形式,提出了将图拆分成层单元的组合方案;然后将图结构结合遗传编程算法,定义了新的随机算子、交叉算子和变异算子。我们将机器学习模型作为图结构中的节点,数据在图结构中各个节点之间传输,用遗传编程算法对图结构展开搜索,以此来找到机器学习模型的集成结构。我们将算法在PMLB十五个分类任务上展开模型搜索,并同时比较多个其他方法。实验结果表明,本文提出的方法在测试数据集上的分类效果优于传统机器学习方法和其他自动化机器学习方法。同时展示了搜索过程中最优模型准确率提升时模型结构所经历的变化,发现回归模型在集成的结构中有提升准确率的作用。在神经网络架构搜索中,我们基于贝叶斯优化神经网络架构搜索方法展开研究,对于优化采集函数的算法提出了改进。本文采用了蒙特卡洛树搜索作为优化采集函数的搜索策略,搜索时控制树的宽度与深度两个搜索方向,平衡探索与利用的关系优化搜索结果,同时基于算法原理优化搜索的时间。我们在两个分类图像数据集上展开神经网络架构搜索的实验并与基于模拟退火的方法(Auto-Keras)进行比较,最终实验结果表明,我们所提出的搜索策略效率更高且搜索得到的准确率更高。同时展示了我们与对比算法搜索到的神经网络架构,发现我们的模型复杂度更小,更不容易过拟合。"
602,在线问卷用户专注度衡量方法的研究与实现,"近年来随着网络的普及,网络问卷的使用愈加频繁和广泛,控制问卷的数据质量一直是调查者研究的一个重要课题。在线问卷为网络用户提供了一个交互模式,随着心理科学的发展,通过收集用户的鼠标轨迹等行为信息分析在线问卷中的数据质量、识别用户的困惑情绪、帮助调查者改进问卷设计等研究课题逐渐流行起来。本文在现有研究在线问卷与鼠标轨迹相关问题的基础上,结合机器学习方法,提出并实现关于在线问卷用户专注度衡量问题的分析方法。对用户在网络问卷中的专注度进行建模和分析,使用机器学习的特征工程和分类方法,衡量用户在回答问卷时的专注度(即认真/不认真)。本文的主要工作包含以下两个方面:(1)首先对在线问卷中网络用户的行为进行建模,详细描述用户在填写网络问卷可能发生的行为(即打开问卷、填写问卷、提交问卷等),定义可收集的行为数据和在线问卷用户专注度衡量问题,公式化地描述问题的输入、处理和输出。输入为用户的行为信息数据,包含鼠标轨迹相关的速度、加速度、距离、角度变化,鼠标的点击、滚动及答题时间间隔等。处理过程为机器学习的二分类模型,根据用户行为信息识别和衡量其在回答问卷时的专注度,进而将用户的专注度分为两类(即认真/不认真),作为问题的输出。(2)在用户行为建模和问题定义的基础上,提出本文针对在线问卷用户专注度衡量问题的模型和方法,通过设计和实现在线问卷网站和鼠标轨迹收集模块,设计并实施在线问卷调查实验采集用户数据,使用机器学习方法对定义的问题进行求解、评估和验证。首先对数据进行预处理,再对处理后的数据进行降维和分类,然后使用查准率、查全率、F1度量等性能指标评估对比不同降维方法和分类方法的效果,选择其中效果较好的方法作为求解问题模型的方法。通过设计和实现在线问卷网站和用户行为收集模块,共采集到578份有效用户数据,对数据做预处理、降维、分类和评估后,得到的实验结果表明,卡方检验法和梯度提升决策树的效果相对较好,查准率、查全率和F1度量分别为78.1%、84.25%和81.06%。同时还与其他分析用户行为数据的方法进行对比,结果表明本文方法在各项性能指标上均优于对比方法,平均性能指标提升了16.11%。本文从网络用户与在线问卷交互行为这一角度,在现有文献研究的基础上,思考和分析用户在回答在线问卷时的态度,通过对用户鼠标轨迹等行为信息使用机器学习的方法,帮助调查者改进问卷设计和控制数据质量,具有一定的现实意义和实用价值。"
603,基于微博评论的情感分析研究,"在我们的日常生活中,互联网是越来越普遍,人们使用互联网的频率也在快速上升的,比如大家可以通过网页或者微博来上网,观看其他人发表的言论,自己也可以在上面发表相应的评论。每天都有大量的有意义的评论产生的,我们可以从这些评论中来感知发表人的信息,同时也可以知道发表人的观点想法等等。的在中国,有很多关于情感分析方面的研究,于是也就有人开始对微博中的评论展开研究了。我们在搜集了大量的微博研究的相关文献之后,发现目前使用最多的研究方法有情感词典的方法,也就是通过构建相应的微博情感词典,进而来分析微博评论的极性;还有一种方法是采用机器学习的方法,也就是通过一些构建模型,通过模型来判断文字的正负的。我们都知道的,中华文化源远流长,是非常丰富的,语言含义非常丰富,比英文单词的复杂性要高很多,很多单字与组成的词意思相差很多,对于有很多个有关系的单词组成的词语的含义,有时使用一些模型算法的效果并不是很好。另一方面,在情感极性的分类过程中,基于情感词典的分类方法几乎没有在乎到微博话题领域的词汇,从而影响了情感分类结果的正确性。目前,在国内,鲜有文献对微博的情感分析有很深入的研究,比如通常会忽视发表言论的人的情感强度,另外一些算法也稍有欠缺,同时对于特征项也很难准确提取。在搜集了其他研究者对于微博评论研究的文献并仔细查阅之后,发现采用情感词典的方法对于情感分析研究是一个不错的选择,另外由于微博有它自己的特殊性,与其他评论研究会有一点不同,所以我们建立了专属于微博的情感词典,选择相关的微博评论,提高情感分类的准确率。我们在获得相关的评论文本之后,首先要对它进行预处理,使其方便后续的研究,然后,使用我们专属于微博的情感词典,对其进行特征提取等操作,和相应的处理消极词汇、程度副词、微博表情符号、情感词和评价对象的微博评论。最后,将采用一些算法公式,对前面已经处理好的数据进行正负分类,达到一个准确的分类效果。我们将会在微博上挑选一些热点话题,实验数据包含生活、交通事故、微博话题领域的科学和技术三个领域,最后的结果通过实验验证是比较合理的。"
604,基于高频数据的中国股市日内回转交易研究,"由于我国A股市场实行“T+1”交易制度,在实际投资中,中长线交易更受投资者们的喜爱,对于超短线日内回转交易的认识程度不高,更缺乏对此的研究。然而随着我国各种金融衍生工具的出现,我国股票市场走上了高速发展的道路,更是因此形成了多种多样的交易策略。本文研究了通过沪深300成分股建立现货组合进行对冲并在股票现货市场上进行日内回转交易的策略,以期在股票市场上取得低风险的稳定收益。本文分为构建现货组合和日内回转交易两部分进行研究。第一部分通过跟踪沪深300指数构建股票现货组合。首先根据不同的现货构建方法进行研究,并从中选取了部分优化复制的方法来构建现货组合。利用主成分分析和K-Means算法对沪深300成分股进行聚类分析得到10类、20类、30类、40类、50类股票,并从每一类股票中选取平均振幅最大的成分股利用遗传算法计算其跟踪沪深300指数的最优权重。然后比较分析了“聚类+优化权重”、“聚类+等权重”、“市值排列+优化权重”、“市值排列+等权重”的跟踪误差,确定了“聚类+优化权重”的跟踪效果最好。最后利用沪深300股指期货进行对冲以帮助后续的日内回转交易规避系统性风险。第二部分研究通过预配置相应股票建立底仓实现日内回转交易的方法。日内回转交易依据A股市场上的高频数据进行低买高卖,主要利用股票5分钟数据构成的技术面指标,如:MACD、KDJ、BOLL、RSI等,并首次使用较为新颖的XGBoost提升算法对离散化后的技术指标进行分析。之后根据XGBoost模型的预测结果建立日内回转交易系统进行回测,得到了稳定且低风险的年化收益率结果,并对回测结果进行分析,得出日内回转交易在股票市场处于震荡期间收益率更好的结论。综上,在我国股市现行的“T+1”交易制度下,可以通过预配置股票底仓的方式进行日内回转交易,在股市震荡的情况下依然保持资产稳步提升,获取低风险收益。"
605,基于机器学习的二手房估价模型,"伴随着房地产行业的迅速发展,近几年来购房热度逐渐飙升。住房关系人民的生活之本,而房价更关乎整个国民经济和人民生活的幸福感,因此住房价格逐渐成为社会关注的焦点问题。在现有的文献中,研究房价问题一般会采用传统的多元线性回归方法,该方法存在一个弊端是假设不同小区之间、小区与周围环境之间是互不影响的,其房屋估价的准确性很难得到保证。因此,本文在传统特征价格模型基础上加入空间效应,使用机器学习方法,建立一种更加科学准确的二手房估价模型。这种改良的空间特征价格模型能够帮助开发商更好地做出投资决策,为消费者购房时提供更准确的参考依据。本论文的主要内容包括:1、应用爬虫方法搜集了昆明市盘龙区132个小区的1060条数据,针对其中的缺失数据和脏数据进行预处理,将空间分异概念引入传统估价模型中,提出改进的空间特征价格模型。2、运用多种方法对收集的房价数据进行预测。首先介绍了所用方法的相关理论知识,用引入空间变量的最传统的方法―多元线性回归对数据进行分析,发现拟合度不高,F值很小。然后用XGboost和随机森林方法找到对小区单价影响较大的几个特征变量,10折交叉验证后,选出最优的参数。最后分别取70%为训练集,30%为测试集后,用支持向量回归、随机森林回归以及XGboost回归进行建模,得到单价的预测值。3、对比测试集房价预测值的误差和模型拟合优度,分析影响估价模型的主要因素并提出相关建议。结果表明,小区的位置、小区周围的交通条件(如距最近地铁站、公交车站的远近)、小区周围的教育环境(距最近学校的远近)以及房屋建造时间等对房价产生很大的影响。通过提取重要性较高的变量建模后,发现随机森林回归方法相对误差最低,XGboost回归模型拟合优度最高,即引入空间效应的随机森林回归模型和XGboost回归模型更适用于昆明市盘龙区二手房数据的研究。"
606,基于二维小波的花朵图像识别,"小波变换的基石是傅里叶变换,而傅立叶变换主要受到不确定性原理的影响,或者说傅立叶变换在频域和时域之间是缺乏分辨率的。将信号分解成小波比分解成频率,能够得到域中更好的分辨率。然而当使用小波变换时,信号是被转换成小波域的,通过这种转换方式,小波变换可以运用到机器学习和图像识别中。机器学习、图像识别等技术广泛运用于各领域,国内外研究中,有将小波应用于图象识别,人脸识别,自然语言识别等识别领域的,一般有如下几种方法:使用小波对图像进行分层或切割再对部分图像进行指标分析;使用几种尺度函数在不同方向上提取一维小波系数进行研究;将图片降到超小维度,再使用二维小波进行识别。在将二维小波应用于图像识别领域的研究中,大多数方案使用的是图片库,但是一旦出现非图库中的图片,识别率就非常低,针对图像识别面临的这个难题,研究出一套适用更多图片的算法就显得具有广阔前景和应用价值。本文在小波分析过程中不使用图片库,选取单个花朵图片,利用提取二维小波分层尺度系数,结合主成分分析降维,选取可以识别出花朵种类的特征值,最后使用决策树进行花朵种类识别和模型评估。本文的主要研究工作如下:基于图像的基本处理,提取图像的灰度矩阵,提取图像的分层近似小波系数。基于主成分分析,对提出的小波系数进行降维。基于决策树,对系数进行训练和预测,将决策树迭代10000次,得到该模型的花朵图像识别正确率。"
607,基于机器学习的滚动轴承智能故障诊断方法研究,"滚动轴承因其摩擦阻力小、互换性好、灵活度高而被广泛应用于机械设备中,其良好运转与否对机械设备运行安全具有十分重要的意义。为了尽可能地避免或减少滚动轴承对机械设备运行故障的影响,针对传统故障诊断方法的不足,本文应用机器学习相关理论对滚动轴承的智能故障诊断方法做了深入研究。具体内容如下:(1)介绍了滚动轴承的典型结构和常见失效形式,研究了滚动轴承的振动机理,从运动学角度推导了滚动轴承的特征频率,并从信号处理角度分析了滚动轴承振动信号常用的时域和频域特征。(2)针对滚动轴承智能故障诊断中传统神经网络容易造成过拟合、局部最优等问题,提出了一种思维进化算法优化BP神经网络的方法。以常用振动信号的时域、频域特征参数作为思维进化算法优化BP神经网络模型的输入,对轴承故障类型及故障程度进行智能故障诊断,对比分析了算法优化前后的结果。(3)针对滚动轴承智能故障诊断中处理故障样本时因样本数据量过大及算法结构单一问题而导致故障多分类精度较低的问题,提出了一种特征降维与随机森林相结合的方法。以常用振动信号的时域、频域特征参数作为特征将维随机森林方法的输入,对轴承故障类型及故障程度进行智能故障诊断,并与SVM、PCA-SVM等方法从准确率和时效性方面进行了对比研究。(4)针对滚动轴承智能故障诊断中传统特征提取和特征选择方法所带来的不确定性和复杂性,提出了一种卷积神经网络方法。利用原始振动数据设计并训练卷积神经网络智能故障诊断模型,对轴承故障类型及故障程度进行智能故障诊断,研究了学习率、迭代次数、训练样本比例、Batchsize等对模型诊断性能的影响,并选取最优参数进行滚动轴承的智能故障诊断。为了验证以上所提出方法的有效性,基于LabVIEW设计了滚动轴承智能故障诊断振动信号采集系统,在滚动轴承故障诊断实验台上模拟了不同故障类型及故障程度的滚动轴承在多种工况下的运行状态。在实验中,从时效性、准确性方面对比分析了本文所提出几种不同方法,验证了所提出方法的有效性,可为工程中滚动轴承智能故障诊断提供一定的参考思路。"
608,基于大数据的盾构机掘进参数研究,"为了缓解城市化进程带来的交通压力,地铁建设已经称为盾构机最重要的应用场景之一。在实际的盾构掘进项目中,盾构机掘进参数的控制在很大程度上依赖于操作者的经验。如何使用之前多年积累的盾构掘进历史数据,确认各个参数间的关系,量化盾构机掘进参数的控制,成为一个亟待解决的问题。本文以南京长江隧道为工程实例,结合大数据分析流程,通过预处理、趋势统计、离散统计、回归分析和机器学习建模等对盾构机掘进参数进行研究,以确定各个参数之间的关系和各个地层的最优预测模型。本文的研究过程和结论如下:(1)本文设计的盾构机掘进参数辅助分析系统能帮助数据分析人员更加快捷地完成盾构机掘进参数的分析任务。(2)由平均值、标准差、变异系数和箱形图的统计分析可知,刀盘转速、贯入度和掘进速度三者在盾构机掘进时的变化趋势基本一致,并且这三个参数对含有砾砂和圆砾的地层十分敏感。总推力和泥水压力二者的变化趋势在各个地层基本一致。在项目的起始段和到达段,各个参数的离散程度明显偏大。(3)由盾构机掘进参数的一元回归分析和多元线性回归分析可知,一元回归公式在拟合优度较好的情况向下,预测能力很差,这种现象主要是由过拟合造成的。多元回归公式在拟合优度较好的情况下,预测能力较好,本文认为多元回归分析在盾构机掘进参数分析中应用效果更好。由盾构机掘进参数的多元线性回归分析的结果可知,掘进速度主要受刀盘转速和贯入度二者的影响,泥水压力、刀盘扭矩和总推力对掘进速度的影响较小。(4)本文使用机器学习算法中的K近邻算法、CART回归树、随机森林和BP神经网络分别对盾构机掘进参数进行建模分析,结合多元线性回归模型为各个地层选择最优模型。"
609,基于数据融合的出行特征识别,"出行者的出行目的信息是城市交通规划或优化的关键依据之一,现有的公交出行目的信息采集主要依赖人工获取的方式,该方式需要耗费大量的人力物力,且在采用人工调查方式时往往进行小样本抽样调查,因此所获得的结果取决于取样是否合理。而出租车作为城市公共交通与私人交通的中间者,其出行目的分布可以有效评估城市公共交通与私人交通的衔接程度。随着信息技术的发展,越来越多的交通工具的运营数据可以自动获取,因此,如何结合所获取的信息数据,通过一定的技术手段解析乘客的出行信息已经成为了近年来研究的热点,并逐渐在实践应用中取得了良好的效果。首先,本文构建了出租车乘客的出行特征提取模型。结合出租车的运营数据,通过乘客运营数据中记录上下车字段值的变化,实现了出租车乘客出行距离、出行时间等特征获取。其次,提出了基于集合运算的出租车运营数据和在线POI数据融合的出租车乘客出行目的识别算法和模型。总结现有的研究方法指出仅采用出行特征会导致识别精度不高,特别是具有类似特征的不同出行目的极易混淆的问题,通过融合出租车运营数据以及在线地图POI数据,实现了出租车乘客出行目的获取,该方法通过结合机器学习以及下车点附近的POI类别,可以有效避免类似特征的不同出行目的无法精准识别的问题,与仅用出行特征相比,所提出的方法可以有效提高识别精度。最后,以成都实际调查数据对模型识别的精准性进行了验证,并对成都出租车实际运营数据实现了出行目的识别。验证结果表明,融合POI数据之后的模型识别精度提高了12%,所提出的方法能够应用于实际大规模出租车运营数据的出行目的识别。本文所构建的出行者出行信息获取模型能有效解析出行者出行目的信息,为城市交通规划及优化提供辅助决策信息。"
610,基于计算机技术的数字工具在修复工程中的应用研究,"修复是建筑遗产保护的核心问题之一,也是当前社会研究的热点问题。近年来随着国家对近代历史建筑重视程度的提高,其修复问题也成为了当前的研究重点,然而城市快速发展,部分建筑缺少应有的监督保护体系,其现状不容乐观,但是在现有的修复方法中缺少针对性的数字化工具,修复工程中历史建筑调研工作的效率还不是很高。随着大数据时代的来临,人工智能快速发展,信息技术的进步使得许多重复性劳动可以被自动化处理,已经在提升多个行业的工作效率,对于建筑遗产领域亦是如此。本文就基于此进行了相关尝试――开发智能化的数字工具实现对历史建筑图像等信息的批量分析处理,将繁琐的人工操作自动化。首先,总结了历史建筑修复工程的相关理论和方法,梳理出数字化工具的需求框架;其次,调研了辽宁近代历史建筑,统计整理出可组成其数据库的内容,分析了当前辽宁近代历史建筑中存在保存状态差、修复效率低、缺少针对性数据库管理等问题,完成工具的功能性设计部分;基于上述需求框架和功能设计结果,结合计算机的数据库、机器学习、图像分析等技术,在Qt框架下开发出具有交互界面的数字化工具;最后,应用工具对部分辽宁近代历史建筑进行实例研究,总结该工具在历史建筑构成与分布分析、图像数据自动整理、建筑细部相似度、风格判别、主色调提取、表皮残损识别及数字化修复参考等方面的作用,同时也指出其在计算准确性和研究方法上的不足。本研究可在一定程度上提高修复工程的效率,为修复工程提供相关的分析及参考依据。该方法具有一定的科学性和客观性,能在一定程度上减少因主观理解的差异性而导致修复工作出现偏差;还可以进一步推广至历史建筑其他研究领域,将数字技术深入建筑遗产工作中,全面提高工作效率,辅助完成历史建筑的调查、研究、保护、修复、监测等工作。"
611,基于神经网络和机器学习的土壤湿度反演研究,"土壤湿度,也称为土壤含水量,是影响大气和地球表面水分交换的关键指标,直接控制着地球生态环境气候变化和水循环。根据土壤湿度这一参量,可以高效的监测气候和环境的变化,对监测农作物旱涝灾害、区域气候变化、地表植物蒸散等应用具有重要意义,为了满足上述这些实际应用的需求,土壤湿度的数据应具有以下特点:(1)高时间、空间分辨率(2)可覆盖大面积区域。但是目前传统观测手段不能满足大范围检测的需求、遥感探测技术又不能获得高空间分辨率的土壤湿度数据。针对这个现状,采用目前最新的被动微波遥感土壤湿度数据和对地观测数据,对土壤湿度进行反演和降尺度研究,提高土壤湿度的空间分辨率是当下需要研究突破的难点。本研究选取目前比较先进的天宫二号宽波段成像仪可见光近红外谱段影像,以及SMAP(Soil Moisture Active and Passive)土壤湿度数据作为降尺度反演数据源。分别通过GA(Genetic Algorithm)遗传算法改进的贝叶斯神经网络算法和GA遗传算法改进的随机森林算法建立光谱信息和土壤湿度之间的关系,对SMAP土壤湿度数据进行降尺度反演,将空间分辨率由3km提高至100m。然后将不同隐含层节点个数下的贝叶斯神经网络改进模型与不同决策树个数下的随机森林改进模型进行对比分析,对模型精度和拟合效果进行深入研究,分析了算法的复杂度,探讨神经网络和机器学习算法在遥感数据反演层面的适用性。最后,研究了各个通道的光谱反射率与土壤湿度之间的相关性,本文的主要研究内容及结论如下:(1)数据获取及预处理。对遥感影像进行大气校正,然后采用基于光谱指数的云和阴影检测算法对天宫二号影像中的厚云进行掩膜处理,识别影像中的厚云将其提取出来并剔除掉,使其不参与样本训练的计算。从SMAP/Sentinel-1 L2土壤湿度数据中提取经度、纬度、土壤湿度三个参数并与所选天宫二号影像进行经纬度匹配。(2)使用GA遗传算法对贝叶斯神经网络和随机森林两种算法进行改进,并使用改进后的算法对土壤湿度进行降尺度反演。基于MATLAB 2018A神经网络工具箱和GUI页面,以天宫二号宽波段成像仪采集的14个通道的光谱反射率数据为输入值,SMAP/Sentinel-1 L2土壤湿度数据作为输出值进行学习和训练。(3)结果表明:SMAP土壤湿度数据在神经网络和机器学习改进算法的反演下由3km空间分辨率提高到100m空间分辨率。其中采用GA改进的贝叶斯神经网络反演时,当隐含层节点个数为24时训练效果最好,R2(Coefficient of determination)为0.755,均方根误差RMSE(Root mean square error)为0.161;采用GA改进的随机森林机器学习算法反演时,当决策树个数为60时效果最好,R2为0.809,均方根误差RMSE为0.120。在处理大数据样本时,GA改进的随机森林算法时间复杂度低于GA改进的贝叶斯神经网络算法。本研究发现天宫二号宽波段成像仪可见光近红外的8、9、10通道下的光谱反射率与土壤湿度之间有更强的相关性。对SMAP土壤湿度数据进行降尺度反演时,随机森林改进模型比贝叶斯神经网络改进模型的精度更高,拟合效果更好,可以实现较为准确的大范围土壤湿度降尺度反演。"
612,基于机器视觉和高光谱的水稻氮素营养诊断方法研究,"水稻是我国单产量最高的粮食作物。在水稻种植管理过程中,精准施氮可提高其成穗率,降低病害发生率,从而有效提升终产量。为实现水稻氮素营养状况的准确识别,开展了基于机器视觉技术和高光谱技术的水稻氮素营养诊断方法研究。为实现基于机器视觉的水稻氮素营养状况分类诊断,以两优培九超级杂交稻品种为试验对象,设置4种不同施氮水平的水稻栽培试验。应用扫描仪获取水稻幼穗分化期及齐穗期的顶1叶、顶2叶、顶3叶的叶片及叶鞘图像。通过图像处理获取19项水稻特征指标,分别应用机器学习算法中的BP神经网络(BPNN)和概率神经网络(PNN)建立水稻氮素营养诊断模型。研究发现,幼穗分化期水稻顶3叶叶片特征最具区分度,可作为氮素营养诊断的有效时期和部位;识别效果以BP神经网络好于概率神经网络方法,其整体识别准确率达90%;叶片的6项RGB、HSI颜色空间分量组合最能体现其氮素营养状况。为实现基于高光谱的水稻氮素营养状况分类诊断,以中嘉早17水稻品种为试验对象,设置4种不同施氮水平的水稻栽培试验。应用地物光谱仪获取水稻分蘖期顶3叶光谱数据,通过MSC、SNV、SG三种方法进行光谱预处理,分别应用主成分分析(PCA)和连续投影算法(SPA)对预处理后的光谱进行特征降维和特征选择,应用机器学习算法中的支持向量机(SVM)建立水稻氮素营养诊断模型。研究发现,采用MSC-PCA-SVM模型对分蘖期水稻顶3叶进行水稻氮素营养诊断的准确率最佳,达97.5%。以上研究结果表明,机器视觉技术和高光谱技术分别结合机器学习算法可应用于水稻氮素营养诊断,为研究水稻氮素营养状况的精准、快速诊断识别提供了一种新途径。"
613,基于单像素特征的膀胱肿瘤分割和浸润深度的计算评价,"膀胱癌是全球普遍恶性肿瘤之一。癌症统计《Cancer statistics,2019》显示美国新增癌症病例中,男性膀胱肿瘤患者发病率和死亡率分别位居第五位和第七位。我国男性膀胱肿瘤发病率位居恶性肿瘤第七位,并且呈逐年上升趋势。最新《NCCN肿瘤学临床实践指南》指出,膀胱肿瘤浸润深度是指导医生为患者制定合理手术方案和后续监护管理的重要指标,因此如何准确获取肿瘤的浸润深度具有重要的研究意义。临床上,光学膀胱镜(Optical Cystoscopy,OCY)联合经尿道穿刺活检(Transurethral Biopsy,TUB)技术是获取肿瘤浸润深度的金标准,但是不同位置肿瘤的浸润深度不同,此外TUB技术有创、检查过程痛苦、易引起患者极度不适且可能造成损伤。因此,临床上迫切需要一种无创、全面评价肿瘤浸润深度的有效方法。随着医学影像技术的创新与改进,医学影像分辨率得到极大提升,研究表明,医学影像信息在浸润深度的研究上展现出极大前景。课题组前期基于患者T2加权MRI腹部成像已采用耦合定向水平集(Coupled Directional Level-set,CDLS)结合形态学特征检测获取疑似肿瘤区域,本文主要工作是完成疑似肿瘤区域中肿瘤组织的准确提取,并计算肿瘤浸润深度。本文主要工作包括以下两部分:(1)基于机器学习的膀胱肿瘤分割:该方法首先基于膀胱T2加权序列核磁共振影像(Magnetic Resonance Imaging,MRI)使用预处理方法获得黏连有肿瘤组织的膀胱壁区域,通过对预处理获取的图像进行小波变换(Wavelet Transform,WT),分别提取小波分量以及原图的纹理、灰度、位置特征,并结合支持向量机(Support Vector Machine,SVM)和直推式支持向量机(Transductive Support Vector Machine,TSVM)实现对疑似肿瘤区域中肿瘤组织的有监督和半监督分类,其中训练集、测试集各包含10例患者,分割结果与放射医师手动分割的膀胱肿瘤区域对比,SVM和TSVM方法分割结果的平均戴斯相似系数(Dice Similarity Coefficient,DSC)分别为0.8277、0.8841,其中基于TSVM的方法性能更优,不仅表明本文提出算法在区分肿瘤以及壁组织上的有效性,亦表明半监督分类方法在解决小样本分类及膀胱肿瘤分割中的作用与优势。(2)膀胱肿瘤浸润深度的计算评价:由于上一部分结果表明TSVM的分类性能优于SVM,因此本部分基于TSVM的分割结果计算肿瘤浸润深度。将分割获取的肿瘤区域从预处理获得的黏连有肿瘤组织的膀胱壁区域中剔除,基于拉普拉斯偏微分方程,计算该区域的膀胱壁三维厚度,再利用去除疑似肿瘤区域后剩余膀胱壁的平均厚度减去疑似肿瘤区域中膀胱壁的最小厚度获得最终的浸润深度,其结果与基于金标准(放射医师手动画取的肿瘤区域)计算的浸润深度作比较,10例患者MRI数据计算结果表明,基于TSVM的浸润深度与基于金标准的浸润深度的平均误差为0.2525mm,表明本文提出的肿瘤浸润深度的计算方法能有效评价肿瘤的浸润程度,从而为医生制定治疗方案提供定量信息。"
614,基于机器学习的某P2P平台违约风险预测研究,"目前,互联网金融行业呈现欣欣向荣的局面,借贷业务作为金融行业中的基础业务,其理念和方式也在不断地推陈出新,随着小额信贷市场中“普惠金融”理念的提出,P2P网络信贷平台应运而生,平台提供极简的借贷审核流程以及借款项目跟踪记录,为投资人和借款人提供便利的借贷通道,缩短了传统借贷业务的办理时间。但是,随着P2P行业由成长扩张阶段转为爆发增长阶段,行业竞争日益激烈,不规范的行业运营导致问题平台不断暴露,借款人违约率也持续升高,平台经营者遭受了巨大的损失。为了防止互联网金融行业发展的进一步恶化,除了相应监管政策需要完善落实,更应该提高平台的抗风险能力,一项基础而又重要的工作是建立并运行一套低成本高效率的违约风险预测模型。本文首先介绍P2P行业发展背景及研究现状,接着对机器学习分类模型的相关理论知识做了阐释。然后本文运用八爪鱼爬虫软件采集了“人人贷”平台开源借贷数据,经过数据预处理后,先对代表性变量与客户违约率之间做统计分析,然后基于数据集构建决策树、随机森林、XGBoost三种机器学习模型,评估各模型违约风险预测能力,基于调参后XGBoost模型所得到的具有高精确度、高召回率的预测结果,结合Stacking集成模型聚合性强的特点,建立了基于优化后的XGBoost组合型违约风险预测模型。实证分析的结果表明,该模型能够为P2P运营后台中放贷审核模块提供理论和技术支持,有助于促进P2P网络信贷健康有序发展。"
615,基于机器学习方法的美国房屋价格影响因素分析,"近年来,随着中国经济的快速发展,赴美留学和移民的人数日益增多,海外房产投资需求也越来越大。为此,本文从微观角度来研究影响美国房屋价格的主要因素,旨在通过对房屋的实用性和舒适性等多维度分析,实现对房价的精准预测,为赴美留学者和移民等人进行海外房产投资提供一定的指导作用。本文以美国房屋价格为研究对象,结合国内外学者的研究来初步确定合适的房屋价格预测模型。首先对数据集进行预处理并对变量做描述性统计分析来建立特征工程;其次选用多元线性回归、岭回归、随机森林和XGBoost对数据集进行预测,分析对房价有显著影响的特征变量;最后通过交叉验证计算不同方法在预测数据集上的均方根误差,选出最优模型为XGBoost,最终我们用XGBoost分析得出影响美国房屋价格的主要因素。研究结果表明,影响美国房价有三个主要方面:1、房屋相关面积。其中可以首先考虑地面面积和地下室面积这两大因素,因为这些因素往往与价格成正比,直接决定了房屋的价格;2、房屋装修情况。房屋的整体材料、房屋材料的质量、原施工日期、改造日期都是影响美国房价的重要因素,尤其是房屋的整体材料对房价的影响最大;3、房屋配套设施。高档全浴室数、地下室全浴室数、总房间数和花园墙透光性也可作为主要的考虑因素。"
616,基于机器学习的未知辐射源信号分选与识别算法研究,"在日益复杂的战场电磁环境背景下,实验室的仿真电磁环境平台已无法满足现有信号处理算法对于信号高密度特性、高逼真度的需求。而对于未知雷达信号的分选,传统的经典算法依赖于前端的信号预处理分选方法,而目前的预处理算法过于单一,导致密集信号处理效率低、对复杂信号分选准确率低。为了建立逼真的电磁环境平台及研究快速准确的雷达信号处理算法,本文主要进行以下3个方面的研究:1.针对当前电磁环境平台不能为电子侦察提供真实信号源的问题,通过分析现代战争面临的复杂的电磁环境,采用图形交互界面设计了能够为认知侦察提供近似实战的电磁环境平台。该平台通过对信号进行特征建模、采用多线程并行产生数据,能够得到近似于真实战场的电磁环境数据,并通过图表直观的将数据显示出来,使仿真平台能更有效地应用于现代雷达侦察信号处理的过程之中。通过仿真实验表明,该平台模拟产生的数据与真实战场数据相比具有较好的相似度,能够为现阶段信号处理提供有效的数据源。2.针对当前复杂电磁环境下,未知辐射源信号分选面临的准确性不高的难题,提出了基于多域联合的未知辐射源信号分选方法,该方法通过分析雷达不同的工作模式,对于不同工作模式下呈现出的不同特征,对到来的辐射源全脉冲信号按照其交叠程度进行截取,并对每一段脉冲提取专家规则,以专家规则为输入,采用机器学习方法设计分类器,为全脉冲数据的分选选择最优去交错参数,使其最大程度避免采用严重交叠参数进行分选,实现在混叠严重情况下对雷达辐射源信号的分选。仿真结果表明,在含有噪声及混叠严重的情况下,该方法能够对未知辐射源做出明确判断,并通过不断的测试使用,模型分选能力越来越强,能够实现不同情况下的去交错分选。3.针对当前复杂电磁环境下,雷达辐射源信号的重频调制样式越来越复杂、多变,对雷达辐射源重频调制方式的自动识别变得越来越困难这一难题,分析了现代战争面临的复杂的电磁环境以及雷达辐射源信号的潜在规律,提出一种融合无监督及有监督两种方式混合的深度信念网络。通过仿真实验表明,该识别方法在时间允许范围内准确性得到了很大的提升,并具备很好的抗缺失能力和抗虚假能力,能够在复杂环境下有效识别出辐射源信号的重频调制类型。"
617,基于WIFI的位置指纹室内定位算法研究,"随着无线通信技术快速发展和移动智能终端广泛普及,人们对基于室内环境的位置服务需求日益增长,无论是在医疗、商业还是在紧急救援等公共安全领域都迫切需要室内定位技术来提供优质的位置信息服务。在多种多样的室内定位技术中,基于WiFi的位置指纹定位法具有定位精度高、易实现、扩展性强、覆盖范围广和价格低廉等优势,逐渐成为人们研究的热点。因此,本文主要研究基于WiFi的位置指纹定位法,主要内容如下:首先,对基于WiFi的位置指纹定位法与传统的室内定位算法的原理进行介绍,并且分别对不同的定位方法分析对比,证明了基于WiFi的位置指纹定位方法的优势所在,为本文定位方法的选择提供理论支持。其次,在指纹数据库建立阶段,介绍了影响无线信号传播的多种因素,提出了改进的综合滤波算法,应用该算法对采集的数据进行滤波处理,搭建仿真实验平台,并与最大值滤波算法、高斯滤波算法和均值滤波算法进行数据处理结果对比,结果表明所提算法处理后的RSSI值波动范围和方差均有所减小,提高了指纹库的质量。然后基于AP选择,提出了KPCA算法对位置指纹库进行特征提取,并通过仿真实验与LE、ICA、LDA、PCA算法对比验证,实验结果表明KPCA算法具有非线性特征提取的独特优势,进一步提高了指纹库的质量。最后,对于定位模型的选择,本文介绍了传统的定位算法NN、KNN、WKNN、概率型算法和基于机器学习的定位训练模型SVM,提出了LSSVM室内定位模型,并提出了改进的参数寻优算法KV-PSO对定位模型中参数C和σ进行寻优,通过实验对本文提出的定位算法(KV-PSO-LSSVM)与传统的定位算法进行定位测试,结果证明了本文所提算法降低了定位误差,表现出了理想的定位性能。"
618,基于数据重表达与样本熵的雷达辐射源信号识别方法研究,"随着现代雷达科技的不断发展,各种调制模式的雷达辐射源不断更新迭代,同时当今战场电磁环境更加复杂多变,以至于雷达辐射源信号多种多样,各种参数不断变化,利用常规的雷达辐射源信号识别方法已经不能满足现代瞬息万变的电子对抗战场情况,致使目标侦察识别日渐困难。针对现有方法识别准确率低以及对噪声敏感的问题,构建基于机器学习的信号分类识别框架,提出一种新的雷达信号识别的方法,实现了低信噪比下雷达辐射源信号的高正确率识别。本文的具体研究工作如下:1、研究了数据处理重表达方法对雷达信号识别效果的贡献,由于雷达脉冲信号在采样频率一定时,脉宽参数的不同导致各脉冲的采样点数不一致,需要对脉冲数据进行降维。利用改进的重表达算法对时间序列信号降维,因此需要对符号化聚合近似SAX方法进行理论研究分析;针对该方法自身的信息损失问题,对改进的SAX符号化BOP(Bag-of-Patterns)相结合的方法进行理论研究分析,并通过设计时间序列数据重表达前后对比实验,来验证对雷达信号分类准确性的影响。2、本文主要研究的是复杂电磁环境下截获的复杂雷达辐射源信号数据处理方法,即重表达;为了能够有效地对数据处理后的雷达信号进行特征选择与特征提取进而实现准确信号的分类,针对本文提出的重表达方法对分类结果的影响做了交叉验证实验,并对重表达对原始数据信息损失与降维去噪情况进行表述。同时本文通过提取样本熵(SampEn)、近似熵(ApEn)两种特征进行对比实验,进而根据仿真实验结果选用样本熵作为雷达信号分类特征。为了能够有效地对数据处理后的雷达信号进行特征选择与特征提取进而实现准确信号的分类,针对本文提出的重表达方法对分类结果的影响做了交叉验证实验,并对重表达对原始数据信息损失与降维去噪情况进行表述。3、仿真实验对接收到的雷达辐射源信号进行Fourier变换和归一化处理,然后对预处理后的信号进行数据重表达,提取信号的样本熵和近似熵特征并针对同类时序信号进行实验对比。最后运用SVM实现6类雷达辐射源信号的识别。由仿真实验结果可知,当信噪比在0dB以下时,6类雷达辐射源信号的平均正确识别率最低为92.03%;当信噪比为10dB时,6类信号可以达到完全分离,验证了所提方法的有效性和可行性。"
619,The Key Technology on Chinese Word Segmentation Based on Bi-LSTM-CRF Model,"自然语言处理是人工智能领域的核心技术之一,而自然语言处理中的汉语分词是自然语言处理的基础。目前主流的分词方法是基于传统的机器学习模型。近年来,随着人工智能浪潮的再次兴起,无论是短期记忆还是长期记忆的LSTM神经网络模型都对传统的循环神经网络模型进行了改进,该模型能长期依赖于信息的不足,并广泛应用于自然语言处理各种任务,取得了良好的效果。作为自然语言处理模块的重要组成部分,中文分词的好坏会影响到基于自然语言处理的相关研究,中文分词盼段将会影响相关的精度,因此中文分词阶段的精度将会其他例如语义和语法层次以及应用层次,分词的精度是衡量这一阶段的重要指标。在中文分词的精度提升上,必须解决如下几个关键问题:1.在中文分词中3如何拥有更高的识别精度是该自然语言处理子方向的首要解决的问题。不仅仅通过该词在句子中的位置来预y分词结果往往是不够的,而对上下文进行依赖,通过句子位置和上下文之间的关系进行分词更加的具有研究价值和重要意义。2.传统的神经模型LSTM模型已经证明在处理信息学习有着相当大的优势,但是LSTM神经网络的前向传导的特点,在训练过程中会导致部分后文的关系并没有被考虑学习,解决全文的上下文关系的学习,防止文本依赖不足所导致的问题也是需要研究的方向。3.对于根据上下文之间的潜在关系进行研究所得出来的结果是基于非规则的研究,但这些上下文关系有的时候并不以一定具有普遍的确定性,这样会导致尽管上下文有联系但是会出现一些前词和后词逻辑性并没有关联的结果,如何增加中文分词的逻辑性对提升中文分词精度有相当的理论研究价值。4.对每一个通过神经网络进行模型都有者自己最佳的参数学习方式,以此来达到局部最优解,对模型相关的参数需要通过不断调整来达到较优以接近最优值。通过上述对问题的阐述,本文在解决上述问题的主要贡献是(1)首先对经典的单向LSTM模型进行了改进,通过增加正向LSTM层并设针双向LSTM模型。这样通过对文本进行前向和后向的传导,以此来改善单向LSTM对以下文本的依赖不足。(2)在神经网络通过添加CRF层,增加了单词间的约束。通过使用CRF所具有的转移矩阵特性来学习单词之间的逻辑,提高因逻辑错误所导致的分词结果精度降低。(3)通过验证词向量嵌入的必要性和设置最佳Dropout防止过拟合,以及动态调整学习率等参数设置来达到模型最佳的精度。在整体的设计上,首先在传统神经网络的基础上,对增加的字向量进行改进,利用字嵌入预处理,然后扩展到LSTM层的双向LSTM,并通过整个连接增加了CRF层的密集度。本文利用Bakeoff提供的SIGAN2006会议进行了主要对比实验。通过实验,基于本文的BI-LSTM-CRF模型取得了较好的效果。通过北京大学的数据集PKU和微软的数据集MSA，准确率和查全率都达到了很好的效果。在机器学习方面,条件随机场可以达到很好的分词效果,在深度学习方面,分词效果得到了更明显的提高。本文主要通过结合双向记忆相关神经网络模型的优化,原LSTM单元结构的神经网络每时每刻、每一步都在执行一种记忆机制,但每一个计算量随着句子长度的增加而激增,导致分词阶段的任务效果较差,逻辑问题较多。本文的改进是词向量用于维度预处理,然后双向段记忆神经深度学习神经网络模型是用来进行隐藏的多个循环传输层,从而达到最好的中文分词的效果。该方法较好地解决了单隐层、防止过拟合以及卷积神经网络不能处理长依赖序列信息的缺点。同时,双向短记忆和长记忆依赖神经网络解决了简单循环神经网络长期依赖和单向LSTM无法利用方向序列信息的问题。经过softmax和dense层处理后,输出将是每个单词所携带的标签的概率。为了解决一些单词没有逻辑的问题,将输出放入CRF层进行传输矩阵处理。最后,合并后的BI-LSTM-CRF模型可以更好地从语义角度进行分词。在最终的实验中,在预实验中人民日报1998语料库的数据集P值为95.3359%,R值为95.1864%,F1值为95.3359%。人民日报2014语料库的数据集P值为96.7524%,R值为94.7981%,F1值为95.7653%。国家数据集P值为93.1640%,R值为93.2534%,F1值为93.2087%。在最终对比实验数据中,在微软的MSRA数据集,通过F1值的比较,通过F1值的比较,可以看出bi-lstm-crf模型的F1值约为2.9%高于CRF++模型,和高于LSTM模型0.9%,bilstm模型高出0.8%,高于Istm-crf模型0.8%。从p值和r值可以看出,基于MSRA数据集的bi-lstm-crf模型比其他模型工作得更好。在PKU数据集中,在P值比较中,bi-lstm-CRF模型比LSTM-CRF模型低0.2%,但比CRF++模型高0.7%左右,比LSTM模型高0.4%左右,比bilstm模型高0.4%左右。在P值和R值方面,MSRA数据集和PKU数据集都有了显著的改进。最后,尽管其结果在查全率和查准率方面均低于LSTM-CRF模型,但F1值与CRF++相比提高了约1.5%,与LSTM相比提高了约0.4%,与bilstm相比提高了约0.6%。本文的主要工作如下:(1)提出了一种双向LSTM-CRF模型,该模型采用双向LSTM神经网络进行数据输入和输出,通过CRF建立约束条件,增加单词之间的相关性。同时,在整个训练过程中,通过Ngram2Vec实现单词方向量化,引入Dropout和学习率等参数对模型进行优化。最后,将自定义字向量标签层和分数函数通过黄金对比度文件得到的相关值进行比较,得到模型的相关精度。(2)系统的将本文提出的模型与其他著名模型在NLP柄注数据集上的性能进行了比较。(比较模型例如LSTM、BILSTM、LSTM-CRF、CRF++模型等)⑶将BI-LSTM-CRF模型应用于NLP标准序列标签数据集,由于存在双向LSTM组件,模型可以同时使用过去和未来的输入特性。此外,由于CRF层的存在,模型可以使用文本级的标记信息。与以往的观y结果相比,该模型具有较强的鲁棒性,对嵌入字的依赖性较小。它可以在不依赖文本嵌入的情况下生成准确的标签性能。本文的模型还存在一些值得研究和改进的地方有(1)本文实验设定精度粗略,未对最优参数设定进行优化。(2)将传统的LSTM替换为LSTM的其他变体单元,进一步简化了模型,但在某些情r下并没有提高模型的效率。以下研究方向值得改进:(1)从实验中可以看出,本文模型提高了召回值,但与其他模型相比,召回率并没有显著提高。因此,在进一步完善模型的过程中,应该更加重视召回率的提高。(2)将传统的LSTM替换为GRU等不同的LSTM单元,使模型更加简化,提高了效率。(3)引入注意机制,改进模型,进一步提高精度。(4)本文使用的分词模型进一步应用于与序列标注相关的其他问题。"
620,基于高斯过程回归的高铁制动过程速度预测,"高速铁路是我国重要的基础设施之一,在国民经济中占有重要地位,而列车运行控制系统是保证列车安全、快速运行的关键,列控系统中用于保障安全的核心是列车自动防护系统(Automatic Train Protection,ATP),ATP通过超速防护实现列车的间隔控制和速度控制,从而保证列车的运行安全。在列车制动过程中,现有的ATP超速防护算法是基于列车自身参数建立模型,但是在实际制动中,由于线路状况不同、天气情况复杂以及自身参数变化等客观情况的影响,基于参数模型的制动控制往往和实际情况存在差异,影响行车安全。因此,运用非参数模型实现更精确地列车制动速度计算,对于列车超速防护算法的研究具有一定的参考意义。本文采用数据驱动方法,将高斯过程回归应用到列车ATP超速防护算法领域,对速度监控曲线中列车制动过程速度的计算与预测进行研究。本文主要工作包括:(1)研究了列车运行控制过程和列车超速防护曲线,分析列车的力学模型,运用两种参数模型方法,主要针对列车进站制动过程进行了仿真研究。(2)从权值空间与函数空间两个角度推导高斯过程回归理论,分析了不同单一核函数的结构与适用的数据类型,研究了不同单一核函数、组合核函数对预测模型的影响,总结了面对不同类型的数据时选择核函数的规律。用基于不同核函数的高斯过程回归模型拟合列车进站速度,通过舒适度对比,将拟合表现最好的组合核函数模型得到的结果视为列车优化制动曲线。比较由高斯过程回归模型得到的优化制动曲线和传统参数模型得到的制动曲线,说明了优化制动曲线更符合列车制动的实际过程,列车优化制动曲线可以像传统ATP防护曲线一样为列车控制提供参考,实现列车制动过程中的速度优化。(3)针对列车当前制动时速度-距离数据不断产生,而标准高斯过程回归方法无法及时将新样本纳入模型的问题,采用迭代高斯过程回归方法进行列车进站制动速度的预测,相较于标准高斯过程回归方法,提高了算法的精度与实时性,能够及时将新样本加入训练模型,提高了模型的可靠度。说明了列车速度预测曲线可以和优化制动曲线相互配合,实现列车速度控制优化。"
621,论张朝钢琴作品《皮黄》的演奏,"《皮黄》是当代作曲家张朝的代表作之一,它在中国钢琴音乐作品当中占据重要的地位。钢琴演奏是理论与实践相结合的艺术表现形式,本文通过分析这首作品的戏曲音乐元素、民族调式与创新、音色、踏板、节奏的处理以及分析不同演奏版本的比较等等,并结合自己的实际演奏经验进行阐述。作品中具有哪些戏曲音乐元素,运用民族调式的同时在哪些方面进行创新。在以上分析的基础上,通过音色的模仿、踏板的处理、节奏的把握等演奏分析,并加入不同演奏版本的比较研究,在实际演奏过程中可以更好的把握作品,将作品以更加恰当地演奏方式诠释出来。希望通过对这首中国现代钢琴作品的研究,可以为钢琴学习者们提供一些有价值的参考。"
622,基于学习分析的在线学习成绩预测建模研究,"随着在线学习者规模的增加,学习者的在线学习学业预测成为教学难题。所以本文立足于学习分析技术,利用从在线学习平台获得的数据,尝试建立能预测学业成绩的模型,从而为学业预警和优化教学策略提供科学依据。(1)首先分析了学习分析与教育数据挖掘的区别及学习分析的内涵,并提出了学习分析流程与要素模式,阐述了学习分析在教学过程中的环节及其组成要素。接着提出“学习”要素框架,从多个方面对“学习”进行了描述。基于“学习”要素框架分析了学习行为投入对学业成绩的影响,提出了学习行为投入测评框架,从多个维度对学习行为投入程度进行衡量。(2)以决策树和随机森林算法作为学习成绩预测模型的实现方法。首先对算法原理进行了分析。然后采用信息熵的算法思想对数据集中的连续型变量进行了离散化,实验证明该方法能有效提高算法的拟合程度。接着利用算法对数据集进行拟合建模,通过调参和剪枝等处理方式得到了效果较好(准确率达80%)的预测模型。最后利用混淆矩阵对模型进行评估,模型对样本预测分类的准确率分别为H(84%)、M(69%)和L(89%),表明模型对学业预警是有效的。(3)预测结果表明“学生缺席次数”和描述学习行为的四个特征(“查看资源次数”、“举手次数”、“查看公告次数”和“讨论次数”)对学习成绩影响最大。通过对学习行为四个特征的相关性分析,“讨论次数”与其他三个相关性都较低,而其余特征两两之间相关性都较强,该结果有助于学习行为投入测评框架的维度划分。"
623,面向5G的IoT覆盖增强和资源管理的研究,"物联网(Internet of Things,IoT)技术彻底改变了无线传感网络,在当今时代真正实现了万物互联的普及通信。但遗憾的是,随着IoT设备数量的与日俱增,现有的物联网技术受到了频谱规模的限制,大规模的用户无法重复使用授权频段,而在资源充沛的非授权频段却没有一个覆盖能力完全达到大规模物联网可以使用的技术,所以探究基于非授权频段且具有良好覆盖性能的物联网系统是解决大规模物联网用户接入的重要途径。随着IoT用户数量的增加以及应用场景的复杂化,物联网用户的资源分配问题也成为了解决大规模IoT设备接入的另一个难题。第五代移动通信系统(The 5th Generation mobile communication system,5G)提出要在提高系统容量的同时以用户为中心。而传统的资源分配算法是从提高业务准确性和质量的角度提高用户的体验质量(Quality of Experience,QoE),运营商的优化往往是以网络为中心,这样的解决方法并不能充分保证用户QoE,并且随着用户接入场景的更加多样,优化服务质量的传统资源分配算法并不能灵活的应对更加复杂的场景。因此,基于用户体验的无线资源分配研究具有重要意义。本文针对大规模IoT设备接入进行了两个方面的研究,第一:设计了一种基于非授权频段的窄带物联网通信系统(Unlicensed Narrowband Internet of Things,U-NB-IoT),从物理层的角度达到增强覆盖范围和降低能耗。第二:针对大规模物联网场景,提出了一种基于深度强化学习的集中式资源分配算法,该算法在满足链路干扰约束的同时最大化用户体验。本文主要内容以及创新点如下:第一,与传统的窄带物联网(Narrowband Internet of Things,NB-IoT)不同,本文设计了一种基于非授权频段的FDMA的时分双工(Time Division Duplex,TDD)系统,并且给出了系统的下行设计细节,包括信道设计,帧结构和基带处理等。第二,本文更加具体的提出了下行数据信道和同步信道的发送以及接收的若干方案,并且通过方案对比验证了同步和数据链路的性能,进一步改善了覆盖性能。第三,针对大规模物联网场景,本文提出了一种基于深度强化学习的集中式资源分配算法,满足链路干扰约束。第四,不同于以优化服务质量(Quality of Service,QoS)为目标的传统的资源分配算法,本文研究最大化用户体验,通过基于效用的平均意见得分(Mean Opinion Score,MOS)对QoE进行测量。相比于传统的强化学习算法,本文利用了一种演员评论家(Actor-Critic,AC)的强化学习框架克服了传统强化学习算法无法实现的连续功率分配问题。仿真结果表明,本文提出的算法在不同条件下具有稳定的收敛性以及良好的QoE水平。"
624,面向弹幕文本的情感分析研究,"二十一世纪被称作高速发展的信息时代,互联网用户从以前的被动接受信息逐渐转变为主动分享经验和发表评论。用户在进行决策之前,慢慢开始习惯于在相关评论或心得中获取参考意见。如何在海量的互联网信息中快速提取出对自身有价值的信息,已成为信息时代每个人都需要掌握的技能。传统文本情感分析研究对用户的决策起到了很好的辅助作用,国内外研究人员对传统文本的情感分析的各方面改进工作取得了较大的进步。而随着弹幕视频和直播行业的兴起,弹幕成为人们实时交流和讨论的重要工具,如何对这种带有时间序列特征的文本进行情感分析,仍存在较多研究空间。针对目前情感词典适用性差和语义表达不足的问题,本文通过分布式词向量技术改进了情感词典的构建方法。首先,在已有的中文情感词典的基础上,使用Word2vec训练出词语的词向量并计算词间相似度值,将TF-IDF值和词间相似度值加以权重计算作为种子词集的筛选标准和分类依据。然后,用种子词集判断候选情感词集中词汇的类别,形成情感词典。最后,通过对比实验并进行结果分析,对比于传统的情感词典构建方法,本文改进的基于词向量的情感词典构建方法可以获得更高的适用性及精确度。针对弹幕文本在时间序列上前后影响关系及多数研究不能直观展示情感分析结果的问题,本文利用情绪衰减模型改进了弹幕文本的情感计算方法,并用可视化方法对计算结果进行直观分析。首先,将分词过后的弹幕文本数据按词性分类,筛选出对情感计算有影响的类别并整理。收集其中出现的特殊数字和字母组合等,汇集成词表并标注相应情感倾向类别。然后,引入情绪衰减模型,将情绪衰减计算方法融合到情感计算中,体现弹幕文本的情感持续特性。最后,根据情感计算结果生成趋势曲线图,并结合弹幕数量时间变化图和情感词标签云,对弹幕文本的情感从多个角度进行可视化分析。"
625,基于深度学习的用户评论情感分析,"互联网的飞速发展使得越来越多的网络用户习惯在网络上发表自己对某一事物的看法与评论,由于对这些评论所包含的情感进行分析可以创造巨大的商业与社会价值,用户评论情感分析长期以来都是信息科学与技术领域研究的热点。用户评论情感分析的主要任务是预测用户评论的情感倾向,也被称为情感分类。现有基于深度神经网络的情感分析模型,虽然克服了传统机器学习方法需要人工设计特征的不足,但这些模型无法感知到评论中的每个词对情感倾向的贡献程度,限制了情感分类任务的性能。此外,词向量技术将单词映射到低维向量空间中,是深度学习文本特征表达的基础,但现有的通用词向量生成模型仅依赖于单词的上下文结构来学习词向量,而无法获取单词的情感信息和领域相关性,故不适合直接应用于情感分类任务。针对上述问题,本文进行了如下研究:1.针对现有神经网络模型无法感知评论中每个单词重要性的问题,提出了一个结合注意力机制的卷积神经网络(Convolutional Neural Network,CNN)情感分类模型。该模型首先使用卷积神经网络提取评论的局部特征,并使用长短时记忆网络提取整条评论的序列特征。通过比较两个网络提取特征的相似度来计算注意力权重,并将局部特征的注意力加权和作为评论最终的特征表达。经过大量数据训练后,注意力机制可以判断评论中不同词语的重要程度,使得模型可以“注意到”评论中对情感影响最大的特征,提高评论特征表达的质量。实验结果表明,提出的模型和现有基于深度神经网络模型相比可以提升情感分类任务的准确率。2.针对现有词向量模型不能同时获取单词的领域信息和情感信息,构建了一种面向情感分析的跨领域情感词向量生成模型。该模型能够通过监督学习的方式获取到单词所包含的情感信息。此外,模型通过计算领域相关性来为一些单词生成跨领域词向量,以获取单词在领域转换时所发生的语义变化。通过实验验证,提出的模型可以生成适用于情感分类任务的词向量,与主流通用词向量模型相比,在情感分类任务上的性能有所提升。"
626,基于深度学习的网络新闻文本分类研究,"网络新闻作为大数据时代人们获取社会有效信息的重要手段,受到了人们的广泛关注。实现对海量网络新闻智能高效的分类,对个性化新闻推荐、话题识别与跟踪、新闻网站分类导航等都具有重要意义。随着计算机技术的发展以及互联网的普及,网络新闻信息资源呈现爆炸式增长。面对海量且混乱无序的网络新闻信息,用户所面临的难题不再是如何获取新闻信息,而是如何在大规模新闻资源中高效准确的找到能够满足自身需求的信息。随着信息化时代的发展,用户对获取信息的内容和质量的要求也在不断提升,新闻信息作为网络新闻用户获取社会信息资源的重要渠道,随着文本分类技术的发展和成熟,为文本分类在网络新闻领域的应用和实践奠定了基础,网络新闻文本分类的发展迎来了新的契机。为了能够提升网络新闻领域的信息服务质量,满足用户在大数据时代的多样化和个性化信息需求,本文在深入研究网络新闻文本分类的背景、研究现状、相关理论和发展等内容的基础上,采用文献计量法对文本分类领域近十年发表的相关文献进行统计分析,从年度发文趋势、学科分布、期刊分布、机构分布、作者分布、高被引文献分析以及研究热点与前沿等方面理清文本分类领域的发展脉络和研究现状,为促进文本分类领域的进一步发展提供理论参考依据。与此同时,为网络新闻领域构建了一个高效的网络新闻文本分类模型框架。该模型主要由四个部分组成,分别是新闻文本预处理、基于词向量的新闻文本表示、新闻文本特征提取与分类以及文本分类结果评价。在实验过程中首先通过学习得到新闻文本的稠密的Word2Vec词向量表示,从而解决传统文本表示的高纬度、数据稀疏及缺乏语义等问题,然后以新闻文本词向量为输入,通过卷积神经网络对新闻文本特征进行自动学习和提取,从而避免传统新闻文本分类方法人工参与特征提取的费时费力及误差累积的缺点,实验结果显示该方法可以有效的提高网络新闻文本分类的效率,促进新闻领域实现更加有效的信息组织和管理。本文提出的基于深度学习的网络新闻文本分类模型具有可行性,能够给用户提供更优质的新闻信息服务,对网络新闻文本分类技术的发展提供了一定的参考价值。"
627,生产数据驱动的动态作业车间调度规则决策研究,"如今,在智能制造趋势下数据驱动的生产管理方法研究已成为重要的研究点。在企业一般作业车间生产过程中常存在着生产异常扰动,使得做好的排产调度方案需要及时动态地进行调整,这便是动态作业车间调度问题。解决动态作业车间调度问题,启发式优先调度规则方法相比搜索优化算法、整数规划等有着排程迅速和灵活易实施的优势,因此在实际企业中调度规则的排程调度方法在需要快速响应的动态作业车间场景下得到了广泛应用。然而由于调度规则类型不一,适用的车间工况不同,关于如何选用调度规则就涉及到调度规则的决策问题。目前在实际动态作业车间调度中,调度规则选用上的决策过程还主要依赖于人工经验,这使调度规则决策结果存在着偏差,难以实时地决策出最符合当前工况的调度规则。因此,本文结合数据驱动的决策思想,对生产数据驱动的动态作业车间调度规则决策方法进行了研究。首先,在分析生产数据驱动的动态作业车间一般调度优化机制的基础上,确定了将生产系统属性数据作为驱动调度规则决策模型的输入数据,对应决策出的调度规则便是模型的输出目标,输入数据和输出目标构成了调度样本。调度规则决策模型的构建采用了机器学习的方式,为了获取构建决策模型所需的优化调度样本数据,研究了基于Multi-pass仿真机制的优化调度样本生成方法,并搭建了用于调度问题实例仿真优化的生产调度仿真平台。然后,针对调度样本的生产系统属性中所含的冗余或噪音属性会影响决策模型的精度,提出一种基于改进离散萤火虫算法EDSBFA的调度特征选择方法,并在UCI数据集和调度样本数据集上测试了其优化特征选择的性能。接着,提出基于EDSBFA调度特征选择和基于极限学习机(Extreme Learning Machine,ELM)调度样本学习的封装式调度规则决策模型构建方法。基于EDSBFA-ELM的调度规则决策方法在实验测试中综合性能要优于文献中已提数据驱动的调度规则决策方法。另外,针对调度规则决策模型在动态作业车间动态调度中的使用方式,提出了两种人机协同的动态调度机制。最后,通过某企业自制件作业车间调度问题实例以联合仿真的方式验证了所提调度规则决策方法和动态调度机制的可行性和有效性,并给出了应用系统的设计思路。"
628,基于机器学习的心电信号处理方法研究,"心电信号是一种重要的生物电信号,能够反映出众多的生理信息,是医生诊断患者心肌类疾病的重要依据来源。为了提高医生通过心电信号诊断患者心脏健康状况的工作效率,在心电信号处理方面研究主要集中在:(1)如何获得更干净且失真度越小的心电信号;(2)如何更准确有效的识别出各种心电特征波形;(3)如何通过心电信号自动判断患者的健康状况。为获得更加干净的心电信号,文中采用自适应滤波器对原始心电信号进行处理,滤除其中所掺杂的工频和肌电噪声信号。为避免自适应滤波器需从外部引入参考信号的不足之处,本文采用无需外部参考的自适应滤波器模型。将单导联心电信号作为参考信号并通过移位运算获得期望信号或将原始心电作为期望信号并通过均值运算获得参考信号,实验结果显示三种无外部参考信号的自适应噪声抑制器均能获得良好的抑制工频干扰和肌电干扰的效果,其中模型二最终的滤波效果最优。基线漂移容易造成心电信号不定期且不定幅值地上下波动,使得信号发生形变,影响医生对心电信号的分析诊断。本文采用中值滤波器对心电基漂信号进行拟合,再将拟合所得的基漂信号从原始信号中减掉,到达抑制基漂信号的效果。以心电的时域特征为支持向量机的特征信号,将R波波峰从众多心电采样点中提取出来,并以R波波峰为参照点对其他波形进行定位。本文选用MIT提供的公开心电数据库中的心律不齐信号为例子验证算法在识别R波峰值的准确性,从实验结果中看出在原始心电信号存在较为严重的噪声干扰的情况下,本文算法也能够很好地识别R波的波峰位置,AUC值达到0.9992,并在此基础上定位其他特征波形。心肌疾病的自动诊断是目前心电信号研究的重点之一,本文首次使用心电的混沌特征结合时域和频域特征信号作为随机森林的特征集,对常见的4种心率不齐信号以及正常心电进行诊断,实验结果显示,本文算法对存在心律不齐的心搏信号的分类准确度达到90%以上,诊断结果具有一定的参考价值。"
629,人工智能生成技术方案对专利制度的挑战与应对,"人工智能发展日新月异,技术进步必然带来专利法变革。技术发展与专利法律基本是动态平衡的。人工智能在众多领域的应用对我国现有专利制度带来诸多挑战,在专利法层面对其作出合理回应刻不容缓。人工智能的发展源于1956年,2017年可谓是人工智能第三次浪潮的起始年。人工智能的核心在于机器学习技术,其通过训练数据、提取特征及抽象结合等方法,归纳数据和吸取经验来实现自我算法改进。如:亚马逊的Amazon Go就是人工智能的核心技术机器学习在新零售的典型应用。人工智能生成的技术方案对专利制度的挑战具体表现在专利授权的三性标准、专利审查实践的困境、人工智能法律主体地位的认定以及专利权利归属等四方面。人工智能生成的技术方案在专利授权的新颖性判断中遇到了瓶颈,如:现有技术领域如何准确判断,创造性判断标准中的主体“本领域的普通技术人员”如何定义以及现有专利法律制度中对实用性的要求在人工智能时代如何体现;专利审查实践中,人工智能生成的案件冗杂亦会增加审查员负担;是否赋予人工智能一定法律主体地位;人工智能生成的部分技术方案在达到专利授权标准的情况下,专利权利归属需要明确。对新颖性的困境来说,由发明人提前检索确定技术领域并运用人工智能筛查冗杂的专利申请文件不失为一个选择;对创造性的瓶颈而言,引入“普通人工智能概念”作为参考;实用性的出路则需要技术与法律的共同应用。是否可以考虑赋予人工智能一定的法律主体地位,即在人工智能为主导人类为辅助的情况下的发明创造过程中,类比适用职务发明保护模式将人工智能“看成”雇员,而为其提供物质技术条件的人“看成”雇主;另外,就人工智能生成的技术方案获得专利权的归属问题,类比适用专利法第6条即采用约定优先模式,在人工智能数据提供者、算法编写者以及测试调试人员之间先行约定确定权属;而在人工智能工作者无约定的情形下,则将专利权归属于为人工智能生成技术方案提供物质技术条件的人。"
630,机器学习在大学生培养质量评价中的应用研究,"从上世纪末以来,受我国高等教育扩招政策的影响,我国高等教育的发展进入了快车道,人才培养质量问题也日趋明显。同时社会各界对大学生的质量要求逐年提高,对高校而言怎样保障为社会输出人才的质量。那么就需要有一个适应当下社会需求的大学生培养质量评价方法。大学生培养质量评价没有统一的标准,通过对已有的评价方法和评价指标研究发现,现有的评价指标不全面,指标赋权方法主观性强,评价方法效率低评价过程繁琐。本文研究工作如下:第一,针对指标构建不合理的情况,根据社会各界对人才的需求和大学生自身的发展要求构建大学生培养质量评价指标体系。指标体系包含知识,能力,和素质3个一级指标;专业知识,创新能力,思想素质等14个二级指标和40个观测点。第二,对思想素质的评价,大多采用教师评价的方式,不能全面对学生的思想素质进行评价。本文研究数据采集方法和量化方法,从教务系统,图书管理系统、教学评审材料、问卷调查获取观测点数据,并对二级指标进行量化。对思想素质等指标量化采用教师评价和学生互评的方式,使指标量化角度更全面。第三,分析常用赋权方法的优缺点,针对主观赋权法主观性强和客观赋权法解释性差的问题,提出主观赋权法和客观赋权法相结合的组合赋权法。使用层次分析法根据高校教师,企业人员,政府工作人员等进行问卷得到主观权重,使用熵权法结合采集的数据计算出客观权重。使用距离函数计算主观权重系数为0.56,客观权重系数为0.44。组合权重不仅解释性好,又对权重的主观性进行了修正。第四,传统评价方法效率低,过程繁琐。通过对大学生培养质量评价研究,提出使用机器学习进行大学生培养质量评价能够有效提高评价效率简化评价过程。使用样本对机器学习算法进行训练,得到机器学习评价模型。训练完成后模型可以方便的应用于评价,能够提高效率,简化评价过程。评价方法采用AdaBoost对SVM的集成模型,SVM核函数选择高斯核函数,并引入多样性测度函数对AdaBoostSVM进行改进。用Iris数据集对算法测试,结果表明改进的AdaBoost-SVM模型的准确率在小数据集上达到92%.在少量数据集下准确率高于SVM和BP神经网络。使用学生样本数据对AdaBoost-SVM行训练和测试,模型迭代7次准确率达到91%,评价方法简洁有效。"
631,基于集成学习的σ~(54)启动子及RNA修饰位点的预测,"机器学习在生物信息学中的应用越来越广泛,它对我们探索生命起源、生物进化以及细胞病变起到了巨大的推进作用。相比较传统的生物化学实验方法,机器学习的方法成本低,耗时短,在启动子的预测以及RNA修饰位点的预测等方面都取得了重大突破。近年来,集成学习受到越来越多的人的关注,它是通过一定的规则将多个学习器组合起来获得更好的学习效果的一种机器学习方法。本文针对集成学习在生物信息学中的应用进行了深入的研究,主要研究内容如下:(1)在原核生物的转录中,σ~(54)启动子发挥着重要的作用。为了快速、准确地预测出原核生物中的σ~(54)启动子,本文以集成学习思想为核心,采用支持向量机(support vector machine,SVM)作为基学习器,自主设计了SVM-AdaBoost算法,并在此方法的基础上构建了SVM-AdaBoost预测模型:http://112.74.38.96:8080/SVM_Adaboost,在严格交叉验证下其准确率达到了96.06%,明显比现有的预测模型iPro54-PseKNC的准确率要高。(2)RNA修饰在生命体中普遍存在并且发挥着重要的作用,准确识别并预测出这些RNA修饰的发生位点对于人类探究其生物学功能和机制有着极其重要的意义。为了应对能够实现用一种方法更准确地识别几种不同类型的RNA修饰位点这一挑战,本文提出了一种融合位置特异性单核苷酸及双核苷酸偏好特征的k-元组核苷酸组成(pseudo k-tuple nucleotide composition,PseKNC)编码方式,构建了一个基于XGBoost(eXtreme gradient boosting,XGBoost)集成算法的RNA修饰位点的预测模型。我们采用了交叉验证的方法对最终的预测模型进行了测试,测试结果表明其预测准确率比现有的预测模型要高。这些研究成果对于探索人类基因奥秘、疾病的发生和治疗具有重要的意义。"
632,基于集成学习的酒样光谱识别的研究,"白酒历经传承已有上千年的韵味,是中华儿女引以为傲的经典。但是现阶段的市场中充斥着大量的贴牌酒,和以次充好的酒,危害着人民群众。但是传统的白酒检测手段因为条件的限制,需要大量的实验和分析过程,耗时较长。因此,市场上急需一种检测快速的检测手段。对此,本文提出相应的基于集成学习酒样荧光光谱鉴别的模型。利用激光诱导荧光技术相应快速的特点,结合集成学习算法来进行白酒酒样的鉴别。本文分析了市场的贴牌酒的形式,分别选取红星二锅头56度、散酒56度、小青花42度、红星二锅头42度作为实验样本。使用这四种酒样,分别验证模型对相同品牌的不同度数、不同品牌的相同度数、不同品牌的不同度数酒样光谱数据识别的有效性。首先,实验对每种酒样采集100个荧光光谱,共400个酒样光谱。然后采用预处理算法对采集到的光谱进行预处理,修正采集过程可能有的噪声和偏差,再对预处理后的酒样光谱加上原始光谱共五种光谱数据分别进行AdaBoost算法建模来选取最优的光谱预处理方法及学习率。为了提升酒样光谱模型,引入LightGBM算法,使用同样的超参数对基于LightGBM算法的酒样光谱识别模型进行训练,得到一个更加强壮的模型。通过对五种光谱数据的建模可以发现,通过SNV预处理方法处理后的光谱在进行AdaBoost方法建模时可以得到更为理想的效果,同时在学习率选择为0.1时,在迭代300次后可以取得最优的结果。对同样的SNV预处理后的光谱进行建模后,模型的5折交叉验证为1,同时,训练时间选少于基于AdaBoost进行建模的模型。因此,本文最终提出结合SNV预处理方法与LightGBM的酒样光谱识别模型,该模型对测试集的准确率为100%。同时具有更好的泛化性能。本文首次将LightGBM引入白酒酒样的识别,同时加入激光诱导荧光技术。仿真结果表明基于LightGBM结合SNV预处理方法在酒样模型的建模是值得被深入研究的。本文构建了一个快速、准确的酒样识别模型实现了对白酒的快速检测。也为之后建立基于更加完善的酒样激光诱导荧光光谱数据库的模型提供了一定的借鉴。图[32]表[4]参[72]"
633,基于DBN-RVM的短期电力负荷预测,"电力负荷预测对电网的安全、可靠和经济运行具有重要意义。影响电力负荷变化的因素众多,大致可以分为自然因素和社会因素两大类。由于各种因素相互耦合并且多变,对负荷的影响机理复杂,因此电力负荷变化呈现出一定的随机性。任何一个电力负荷预测模型都会有一定的误差,如何提高预测精度、减小预测误差一直是科研工作者的研究热点。针对以往预测方法建立的模型存在预测精度低、鲁棒性差、受噪声影响大、易陷入局部最优、泛化能力不足和无法考虑诸多负荷影响因素等问题,结合电力负荷的变化特点,本文将深度学习和相关向量机应用到短期电力负荷预测中,在对预测模型进行深入研究的基础上改进了单一预测模型,使电力负荷预测的精度进一步提高,取得了较为满意的电力负荷预测结果。本文分析了影响电力负荷变化的主要因素,研究了日平均负荷的周期性变化特点。首先通过时间序列法,利用BP神经网络对未来一段时间日平均气温进行粗略预测。然后以电力负荷的主要影响因素作为预测模型输入量,日平均负荷作为模型的输出量,建立了基于DBN的短期电力负荷预测模型和基于RVM的短期电力负荷预测模型,分别在计及气温、不计及气温的条件下通过上述两种模型进行短期电力负荷预测。针对以往短期电力负荷预测模型的各种不足以及单一算法模型负荷预测精度受气温预测精度影响大等弊端,提出了一种新的基于DBN-RVM融合算法的短期电力负荷预测模型。首先该融合算法模型利用相关向量机的方法建立电力负荷周期变化的通用模型。然后利用深度置信网络建立通用模型的预测误差补偿模型,通过预测误差补偿模型补偿通用模型的预测误差从而实现电力负荷的高精度预测。将单一算法模型和融合算法模型的预测结果进行对比,在计及气温和不计及气温条件下,基于DBN模型的预测结果平均相对误差分别为4.22%和5.23%,基于RVM模型的预测结果平均相对误差分别为3.43%和1.76%。基于DBN-RVM融合算法模型的预测结果平均相对误差分别为1.63%和1.55%。结果表明,基于DBN-RVM的融合算法模型大大提高了短期负荷预测精度,在计及气温和不计及气温的条件下均能实现对短期电力负荷的高精度预测,该融合算法模型减小了对气温预测精度的依赖,削弱了负荷影响因素中一些随机噪声对电力负荷预测的影响,提高了模型的鲁棒性、适用性和可靠性,是进行短期电力负荷预测的一种新型、实用的方法。图[31]表[15]参[49]"
634,基于多特征融合的糖尿病视网膜病情评估,"糖尿病性视网膜病变是一种具有特异性改变的眼底病变,它主要是由糖尿病引起视网膜血管壁受损而导致视网膜出现微动脉瘤、出血点等病灶,是由糖尿病引起的严重并发症之一。糖尿病性视网膜病变是糖尿病患者视力丧失的主要原因。当前,随着生活方式的改变,糖尿病患者快速增多,随之造成糖尿病性视网膜病变患者也越来越多,导致大量工作人群致盲。糖尿病性视网膜病变一般分为两个主要时期:非增生性视网膜病变时期与增生性视网膜病变时期。如果患者能在非增生性病变时期得到及时的诊断和治疗,就能大大降低致盲的概率。目前,眼科医生主要利用彩色眼底相机来采集眼底图像,并通过观察眼底图像中出现的异常病灶进行诊断。然而,由于眼底上可能出现病变的种类多样、形态不一,对医生的专业水平要求较高,从而导致专业眼科医生的数量远远不能满足患者的就诊需求。因此,利用技术手段提高糖网病变的诊断效率至关重要。本文拟基于机器学习和图像分析理论与技术,研究糖尿病性视网膜病变自动化诊断技术,主要研究成果如下:(1)筛选并改进了现有基础深度神经网络架构,使之适应糖网病变筛查。另外,针对糖网病变标注图像较少这一问题,本文基于迁移学习原理,结合其它领域图像数据集和眼底图像数据集,训练得到基础分类模型。(2)提出了一种基于多特征融合的眼底图像病情评估学习方法。根据眼底图像的特点以及数据集的分布特性,从同一位患者的左右眼图像中来提取特征并进行融合,从而提高诊断正确率。另外,为了提高模型的泛化能力、提高单张图像的分类准确性,本文进一步为单张图像做不同的变换,从而生成多种不同的特征并进行融合。实验结果显示,本文的方法显著提升了眼底图像病情诊断的正确率。(3)提出了一种基于注意力机制的眼底图像病情评估学习算法。在现有的分类网络中引入了注意力机制,通过对不同区域增加不同权值,使得在网络中使得有助于分类的特征被强化,而对分类无帮助的特征被弱化,从而实现对网络分类性能的提升,并且可以对图像中的较为明显病变区域进行可视化。实验结果显示,在基础分类网络中加入注意力机制有助于提高分类精度,而且通过注意力机制的可视化图像可辅助确定病变位置。"
635,安卓混淆恶意应用程序检测方法研究,"近年来,安卓系统因其开放性始终占据移动市场的主导地位。然而,安卓恶意应用的日益增长严重威胁着用户的财产和信息安全。安卓应用的安全性逐渐引起人们的重视,针对安卓恶意应用的研究和检测方法应运而生,其中静态分析技术备受研究者的青睐成为主要的检测方法。然而近年来,混淆技术被广泛地应用于安卓应用,良性应用的开发者通过混淆技术来保证自己的知识产权不受到侵害,而恶意应用的开发者通常利用该技术增加应用被逆向分析的难度或者使用反射技术隐藏恶意代码,从而躲避静态分析。因此安卓混淆技术是一把双刃剑,在安卓混淆应用中良性应用和恶意应用并存。5G时代的到来使得移动设备的安全问题更加突出,如何有效地检测市场中的安卓混淆恶意应用是一个意义重大且亟待解决的问题。当前,混淆恶意应用的检测与分析方法存在数据集不明确且静态分析技术效率低下的问题。针对这些问题,本文构建了一个动态检测安卓混淆恶意应用的方法,该方法分为混淆应用检测和恶意应用检测两个模块。使用混淆应用检测方法构建了用于混淆恶意应用检测的数据集,分别包括778和712个混淆的正常和恶意应用。恶意应用检测模块在误报率为1.55%的情况下达到了 93.49%的准确率。本文的研究工作包括如下三个部分:(1)全面总结安卓混淆技术:安卓应用的混淆技术复杂多样,且使用不同混淆技术的应用具有不同的特征。通过判断应用所用的混淆技术则可以提取针对具体混淆技术的相关特征,从而提高安卓恶意应用的检测效率。因此本文全面地总结了当前常用的安卓混淆技术,分别是标识符重命名、字符串加密、控制流混淆、Java反射和打包技术。为了评估混淆技术检测的效果,本文从开源市场下载安卓应用的源码文件,并使用3种不同的混淆技术对它们进行混淆操作,得到了3个纯粹的混淆应用数据集,包括375个被标识符重命名的混淆应用、342个字符串加密的应用和338个控制流混淆的应用。(2)混淆应用检测:对混淆恶意应用的有效检测建立在纯粹的混淆数据集上,而当前市场中没有现成的混淆数据集,因此本文提出了一个用于检测混淆应用的方法。首先在混淆应用检测的内部构建了 3个用于识别不同混淆技术的检测器,依次是标识符重命名检测器、字符串加密检测器和控制流混淆检测器,然后分别使用支持向量机算法对应用程序进行分类。使用上文构建的3个混淆数据集,3个内部检测器的准确率分别达到了 90.91%、88.47%和78.96%。对于未知的安卓应用,若应用使用了其中任意一种混淆技术,则将其归类为混淆应用。最后,该方法从1315个正常应用和1288个恶意应用中分别筛选出了 778和712个混淆应用,以此作为检测混淆恶意应用的数据集。(3)混淆恶意应用检测:针对混淆应用躲避静态分析的问题,本文构建了一个动态检测混淆恶意的方法。通过在模拟器中安装并运行安卓应用,分析其行为特征,本文选取了 12类常用的动态特征,并基于混淆应用的特点新增了两个特征。该方法使用支持向量机、决策树和随机森林对实验进行评估,分别得到了 93.49%、91.89%、93.03%的准确率,验证了检测混淆恶意应用的有效性。"
636,基于字符串和函数调用图特征的安卓恶意应用检测方法,"随着移动互联网的不断发展,智能手机已经成为了人们日常生活中不可或缺的一部分,给人们的生活带来了极大的便利。用户在享受智能终端应用带来便捷的同时,也面临着日益严重的网络安全问题(个人隐私信息和财产安全的问题)。安卓系统作为当前主流的移动操作系统,毫无疑问成为了恶意应用开发者主要的攻击目标。研究如何有效地检测安卓恶意应用,具有十分重要的现实意义。刻画安卓应用的行为是进行安卓恶意应用检测至关重要的部分。很多现有的静态分析工作主要从安卓应用中提取字符串特征对应用的行为进行刻画,如权限,系统API的调用等特征;也有一部分工作使用安卓应用的结构性特征进行安卓恶意应用检测,如应用的控制流图,数据流图等特征。但是由于安卓恶意应用的行为变得越来越复杂,仅使用一类特征对应用进行检测,可能会造成较多的应用被错分。因此,本文针对字符串和函数调用图两类特征如何进行有效地协作,能达到比单类特征检测效果更好的问题进行研究。主要研究工作如下:(1)本文提取了 6类字符串特征和2类函数调用图特征来共同刻画安卓应用的静态行为。字符串特征包括应用申请的权限、硬件特征、Intent过滤器、受保护的API调用、代码相关特征及应用使用的权限;函数调用图特征包括基于敏感API和基于Dalvik指令编码的函数调用图特征。(2)本文提出将两类异构特征融合后进行安卓恶意应用检测。提出将基于敏感API的函数调用图特征得到的频率关系矩阵转化成向量,与字符串特征放于同一矩阵进行特征融合。提出将字符串与基于Dalvik指令编码的函数调用图特征的预测结果进行融合。两种方法充分地利用两类特征的分类优势,以提高安卓恶意应用检测的准确率。(3)本文使用支持向量机、k近邻、逻辑回归和随机森林4种机器学习算法对本文提取的特征进行分类性能的评估。实验结果显示,基于字符串特征的最优准确率达97.02%,基于函数调用图的最优准确率达91.93%。基于两类特征融合的最优检测率达97.79%,比仅使用字符串特征的检测率高出2.16%。基于两类特征预测结果融合的最优准确率达98.63%,假阳性率达0.72%,与仅使用字符串特征检测相比,假阳性率减少了 0.96%。实验结果证明,基于字符串和函数调用图特征协作的安卓恶意应用检测效果优于仅使用字符串或函数调用图特征进行检测的效果。"
637,基于多类型惯性传感器协同机器学习的工人工效监控系统,"基于惯性传感器的肢体活动识别技术是人机交互和普适计算领域一个新兴的研究方向,并在智能人机交互、医疗保健、教育和运动分析等领域进行了广泛地研究。然而基于惯性传感器的肢体活动识别技术应用在建筑领域还处在一个缓慢发展以及探索可行性的过程,早期研究未能考虑到惯性传感器位置对施工活动识别的影响,且由于施工活动的复杂性使得基于惯性传感器的施工活动识别还有待研究。因此本文重点研究了基于多类型惯性传感器协同下施工活动及工人工效的识别,主要工作如下:基于多类型惯性传感器协同的施工活动识别。文献研究确定了装卸材料施工任务分解的四种活动作为施工活动识别对象,且通过活动与身体部位相关性分析选择了身体四个部位放置设备单元。进行实验一和二收集受测者的装卸施工活动数据,原始数据使用低通滤波器去噪、信号分割及特征提取形成特征向量。为确定窗口尺寸,使用神经网络分类方法分别生成五种窗口尺寸下的不同位置及类别数据模型,综合分析确定了单一位置及类别惯性传感器模型性能最佳及均衡的信号分割窗口尺寸为3s。随后实验数据对比分析了单一位置、两个位置组合、三个位置组合和四个位置的惯性传感器类别配置模型性能结果,最终得出最优惯性传感器类别及位置组合为脚踝+上臂+手腕的加速度(A)。验证了基于多类型惯性传感器协同下工人工效识别的有效性。在研究出的最优惯性传感器类别及位置组合基础上,使用实验二的受测者实际施工活动数据,分析验证了脚踝-A+上臂-A+手腕-A模型性能最优,且在该模型基础上识别实际施工活动并预测计算出各项施工活动时间占比,通过与实际结果对比得出高性能的惯性传感器类别及位置组合模型识别的施工活动时间占比无太大差异,这令人信服的数据结果验证了基于多类型惯性传感器协同下工人工效识别的有效性。最后综合开发了一套基于机器学习的多惯性传感器协同工作下建筑工人身体姿态动态识别与工效监控系统并使用实际施工活动数据验证了该系统的可靠性。"
638,基于栈式自编码神经网络的股指预测研究,"金融市场是一个典型的复杂系统,它既包含很多子市场,又同时与很多市场相关联。在上世纪初,人们乃至许多学者都认为这个复杂系统难以衡量和研究,于是早期的经济学、金融学理论大都建立在简化的系统之上,如资本资产定价模型(CAPM)建立在市场中存在大量同质的理性投资者等严格的假设上,随着学者们的不断研究,经济学金融学理论逐渐发展完善。直到今天,CAPM模型仍然活跃在很多课堂乃至于工作中,告知了我们金融市场这一复杂系统值得研究。随着时代的发展,金融市场同样在发展,各种新兴创新的金融产品及市场机制都被提出并应用。传统的市场理论如市场有效假说EMH等都存在各种问题并难以解释,而利用金融市场时序数据预测模型能够帮助揭示金融市场的内在运行规律,凸显特殊新兴的要素来认识市场,并利用其监管市场,具有十分重大的理论价值;而利用预测模型预测趋势结果能够帮助投资者们选择投资时机,预期投资风险和结果,更好地实现投资效率,具备一定的现实意义。面对如今日益复杂演化的金融市场,传统预测模型虽然理论上仍然有不错的效果,但在实际应用与判别市场未来趋势上,却难以做到切实有效。而机器学习和数据挖掘领域中愈发火热,颇具代表性的深度学习模型,逐渐站上了舞台。几年前AlphaGo战胜世界围棋冠军的壮举就展示了深度学习的卓越能力,如今深度学习模型已经深入到我们身边的衣食住行,方方面面。然而金融市场作为一种非平稳、无穷方相互博弈的复杂性体现,不是一种模型可以一蹴而就的。学者们尝试各种方式各种模型不断的研究着金融市场。本文选择利用深度学习模型来探究金融时间序列预测的可行性和效能水平。考虑了目前金融市场预测模型的发展脉络和发展方向,采用了在图像识别等领域颇有优势的栈式自编码神经网络SAEs(Stacked AutoEncoders),来对金融时间序列数据进行预测分析。理论上比较而言,SAEs模型是可控数量的多个自编码器的有效堆叠,实现对输入数据的高维抽象信息提取,并通过逐层贪婪学习算法,避免深层模型容易出现的梯度爆炸等问题,能成功拟合和得到预测结果。本文选用了沪深300指数日数据作为中国股票市场情况的代表来进行实证,分别建立SAEs模型与BP神经网络和长短期记忆递归神经网络LSTMRNN两种模型,对日收盘价及日收盘价的趋势变动进行实证预测并比较分析。实证结果表明标准参数下SAEs模型相比BP神经网络模型和LSTM-RNN模型取得了更好的预测效果和预测精准度。同时通过静态预测的方式,得到不错的股票指数的短期趋势命中率。最后考虑了栈式自编码神经网络SAEs模型自身的复杂性和逐层算法的复杂性,进一步从不同的维度来优化SAEs模型在短期趋势命中率上的预测结果。实证结果表明输入数据为日收益率时能得到明显优于日收盘价的趋势命中率,同时输入数据信息量更大时能得到更好的趋势命中率,而SAEs的模型架构及自编码器隐含层层数与输入数据互相干扰,影响着预测精准度。另外增加了美股市场代表的标普500指数日数据比较分析中美两国股票市场的差异性,验证了市场的可预测性及栈式自编码神经网络的泛用性。"
639,光纤制备大数据辅助决策系统,"随着我国通信基础的大规模建设,光纤光缆制造业获得了迅猛发展。与此同时,智能制造正引领工业3.0革命的浪潮,我国传统制造业逐渐开始升级,朝着智能制造业进行转型。我国光纤制备企业基本已经实现信息化和智能化管理,但是,在光纤制备工艺方面还存在着一些问题:如何准确发现光纤制备工艺参数的影响因素及内在关联关系;如何固化专家制备经验;如何准确预测工艺参数的变化对未来产品质量的影响等。本文阐述了传统光纤制备工艺的现状和不足,探究利用机器学习的方法对光纤制备进行辅助决策,并形成可视化的系统。分析预制棒数据和光纤数据,建立回归决策树模型,根据模型形成光纤制备规则,分析预制棒参数和光纤参数的内在关联,并对结果进行可视化,形成完整的系统。本文主要研究内容如下:1.对预制棒数据和光纤数据进行深入理解,对数据进行噪声去除、归一化和数据链接的一系列操作,为机器学习的特征构建和建模进行预处理工作;基于对数据和业务的了解,通过信息增益法对预制棒数据进行特征选择;用预制棒数据作为特征,光纤的某个参数作为目标,构建回归决策树模型,此模型即为光纤制备辅助决策算法的基模型。通过实验分析,验证了回归决策树模型的有效性。2.根据回归决策树模型的分裂路径,获取到多个光纤制备规则;根据信息增益法获取重要性较高的预制棒特征作为光纤的影响因子,通过分析历史数据,获取光纤目标和影响因子之间的关系。3.搭建大数据平台和web服务器,将光纤制备规则和影响因子进行可视化,并形成完整的光纤制备大数据辅助决策系统。针对设计的光纤大数据辅助决策系统,总结其优势:通过回归模型的分裂路径,获取多条光纤制备规则,固化制备经验;通过对光纤参数的影响因子分析,有效地发现预制棒参数的变化对光纤的影响以及它们的内在联系;搭建大数据平台,存储和分析海量的数据,提高系统的时效性;完整的可视化平台,能直观的展示算法的结果,为制备专家提供方便的辅助决策帮助。"
640,基于机器学习的车门协同设计冲突消解,"现如今,工业产品的复杂性和现代社会生产规模正在逐步增加,一个产品的设计通常需要许多人或不同团队之间进行协作,汽车产业也是如此。汽车产业协同设计环境的结构,信息传递的方法和协同设计中冲突解决的方法将极大程度上影响汽车产业的自主研发能力。冲突的消解一直是协同设计领域的焦点问题,近些年来,不同学者提出了许多冲突消解的算法,大多以冲突的检测或者避免错误的发生(加锁)为主,都有其不足之处,这些方法极大程度上影响了协同设计的效率。随着信息技术、计算机技术的进步,人工智能技术已经无处不在,机器学习的研究也越来越成熟,不同相关算法的学习以及构建自定义框架的成本都在降低,汽车行业对人工智能的需求越来越迫切。在车门的传统设计的过程中,在车门铰链、车门主断面的布置和设计方面需要大量的手工操作,进行反复校核,对设计者的设计经验要求非常高,这将对研发效率造成很大的影响。因此,有必要提出一种新的设计方法进行改进。针对上述所有问题,本文建立了一种基于机器学习的车门协同设计冲突消解的方法,主要工作如下:1.基于自主研发的COMX平台实现参数化协同设计的框架,结合NX Open二次开发和NX/Spreadsheet实现协同设计中基础架构搭建和API封装。2.通过探讨车门设计流程,针对车门设计过程中的关键步骤,提出了一种参数化驱动的车门铰链和车门主断面的设计方法来提高车门设计的效率。当参数化设计过程中产生冲突时,以车门设计规范为原则,建立相关算法修改参数,设计相应的参数数据库用于后续的机器学习的训练。3.在MATLAB中建立BP神经网络,将车门设计过程中的产生冲突的参数建立数据库进行训练,在已有数据的驱动下,每当发生冲突时,能快速预测出一套新的参数方案,从而减少车门设计过程中的重复性和试探性,有助于设计者获得最佳的车门布局方案,大大提高了车门设计的质量和效率。"
641,基于创伤大数据的创伤失血性休克伤情预测预警模型建立研究,"目的本研究通过数据检索技术从海量创伤数据中抽取创伤失血性休克伤员数据,通过智能筛选方法提取创伤失血性休克关键指标,进而应用机器学习、深度学习算法对时序数据进行分析及模型验证,能对创伤失血性休克进行预测预警,对模型性能进行客观评价,提高医护人员对该并发症的提前感知能力,实现早干预、早治疗,改善伤员预后,并为其他应用大数据技术开展类似临床决策支持研究提供一定参考。方法:(1)应用数据检索技术从MIMIC III数据库中提取创伤失血性休克伤员数据,使用粗糙集算法对包含伤员生命体征、血常规、血气分析、凝血功能、血生化、尿常规的庞大指标数据集进行解析;进而使用元胞遗传算法进行独立重复实验,根据指标在筛选中被保留次数判定其识别能力,进而形成新的关键指标集。(2)根据被筛选出关键指标对伤情识别能力不同,即被筛选保留次数不同,对关键指标进行重组及分组,以时间序列性关键指标为分析对象,去除补缺后不能满足研究需求的指标。分别应用机器学习中的逻辑回归、支持向量机、朴素贝叶斯和AdaBoost对创伤失血性休克结局变量进行预测,对分类器模型性能进行评价,分别获得不同分组指标集下各种算法所计算出的准确率、召回率、精确率、F值,并对结果进行比较。(3)分别使用MLP和GRU两种神经网络模型,使用创伤失血性休克伤员阶梯式关键指标,即分为仅生命体征、生命体征+血气分析和生命体征+血气分析+血常规共三种不同指标组合,设置时间跨度为1小时,调整时间步长,使模型表现最优,对模型性能进行评价,获得不同分组指标集下各种算法所计算出的准确率、召回率、精确率、F值,并对结果进行比较。(4)以解放军总医院急救数据库中满足研究条件的创伤伤员数据对已建立模型性能进行客观验证,获得外部验证结果,并与内部验证结果进行实际比较,探讨模型在其他数据集中的泛化性能。结果:(1)应用元胞遗传算法进行10次独立重复属性约简试验,约简保留10次的关键指标为呼吸频率和白细胞;约简保留9次的关键指标为天冬氨酸・氨基转移酶;约简保留8次的关键指标为PC02、PH、体温、尿比重;约简保留7次的关键指标为血浆纤维蛋白原测定、收缩压、舒张压;约简保留6次的关键指标为国际标准化比值、乳酸、氯化物、葡萄糖、心率。共发掘出10组最优的关键指标组合规则。(2)将待分析时间序列指标分成包含全部指标、13个关键指标、8个关键指标、6个关键指标的共4组数据集,分别应用4种机器学习算法进行预测分析。当应用全指标数据集时,AdaBoost方法,在准确率、召回率、精确率三方面均超过90%,表现优于其他三种方法;在应用不同数量关键指标数据集时,AdaBoost在应用于包含13个关键指标的数据集时,F1.5值达到90.1%;应用于全数据集时,F1.5值达到91.8%,在4种算法中表现最优。(3)使用GRU和MLP两种神经网络模型分别在三组不同的预测预警指标数据集上进行预测,当时间跨度为1h且时间步长为5时模型表现性能最优。其中,应用GRU进行创伤失血性休克预测时,单独使用生命体征预测的F1 5值最高可达85.1%,当保证F1.5值不低于80%时,可提前2小时预测创伤失血性休克发生;使用生命体征和血气分析指标进行预测时,F1.5值最高可达86.3%,当保证F1.5值不低于80%时,可提前3小时预测创伤失血性休克发生;使用生命体征、血气分析和血常规指标进行预测时,Fi 5值最高可达90.1%,当保证F1.5值不低于80%时,可提前4小时预测创伤失血性休克发生。在使用相同指标、提前相同时间时,GRU的F1.5值均高于MLP,表面前者性能优于后者。(4)通过外部验证,AdaBoost模型在内部验证和外部验证中均取得了较好的表现性能,具有较好的鲁棒性,其F1.5值最高达0.892,与外部验证结果最为接近;深度学习算法泛化性能欠佳,仅在准确率方面与内部验证结果接近。结论:(1)关键指标筛选是开展创伤失血性休克预测预警,提高模型预测效能的重要基础,也是尽可能减少需求指标数量,优化模型的重要措施和手段。(2)使用机器学习方法能够较好地对创伤失血性休克是否会发生进行预测。当应用关键指标集预测时可能存在最适指标组合,需综合考虑指标采集的经济效益和时间效益。(3)使用深度学习对创伤失血性休克进行预测预警,引入预测时间窗,提出预测指标阶梯化概念,当仅使用可实时监测的指标且应用算法能获得较好的预测效能时,在理论上就能对创伤失血性休克实施实时动态预测预警。(4)通过外部数据集验证是检测模型综合性能和泛化性的有效方法,使用筛选获得核心关键指标时模型的泛化性能较好,说明应用元胞遗传粗糙算法筛选关键指标对于提高模型性能方面的具有重要的应用价值。总之,通过系列研究,获得了多种能够为临床创伤伤员进行失血性休克预测预警的模型算法。下一步的研究重点是进行严密的临床验证,对实际预测效果进行严格测试,不断对模型进行优化改进。"
642,基于机器学习的锻造过程数据分析方法的研究,"锻造行业一直是我国制造业中的基础行业之一,近年来,我国各种锻造企业的年产量逐步上升,取得了阶跃性的进展。然而除了对产量的要求之外,客户往往对了解锻造产品质量以及生产过程等因素的需求日益增强,在智能制造背景下,各锻造生产厂商已经逐步完成对锻造生产过程的信息化采集,在采集到大量锻造生产过程大数据的同时,如何利用好这些锻造生产过程大数据,寻找出数据之间的内部联系,挖掘出数据的价值是企业向智能化发展的必经之路。本文针对锻造生产过程大数据进行了研究,首先对智能制造背景下,锻造行业在生产过程中所面临的瓶颈进行了概括,并对机器学习进入了深入研究,得出了机器学习算法就是解决锻造过程中大数据的分析问题。利用对Profinet网络协议的深入研究,实现了对锻造加工区域网络架构的搭建,在此基础上,运用智能传感器与锻造加工区域中的自动化集成系统建立起锻造生产过程中的数据采集系统,并将物料经过每一道工序中的质量数据进行单件绑定。在获得了物料单件质量信息的基础上,利用聚类算法来对锻造生产过程中的模型进行了搭建与验证,分析出了锻造生产过程中的不同工况与生产过程中数据之间的关系,进而分析出锻造生产线的稳定性。另外,利用回归算法搭建锻造加工区域模型,实现了对锻造生产过程中数据的预测,且效果较好。锻造加工区域的数据是反映当前生产状态的重要因素,实现了锻造生产过程数据的预测实现了对生产过程稳定性的预测。最后本文研究了基于Hadoop的大数据平台,实现了对生产过程大数据平台架构的总体设计。"
643,基于物联网的电力变压器振动监测与诊断算法及其系统软件的研究与开发,"我国经济的持续快速发展带动了电力工业的迅速发展,变压器是电网中最重要的设备之一,在整个电力系统中占有着十分重要的地位。确保变压器正常运行是电网安全的首要前提,大型电力变压器在运行时一旦发生突发事故,可能引起大面积的停电,造成重大的社会效应和经济损失。而且电力变压器的维修成本高、维修周期长,产生的各种经济损失也是十分巨大的。本文采用振动分析法开展电力变压器带电检测与故障诊断方法的研究与实现。在课题组提出的振动特征及提取算法的基础上,研究提出了一种有效的机器学习模型,并用于实际变压器的故障诊断。应用日益成熟的物联网技术与架构,开发、实现了基于Android平台的变压器振动监测与诊断软件系统。该系统通过云平台可以实现全天候、远程地对电力变压器进行带电、实时监测和故障诊断。本课题研究内容如下:(1)阐述电力变压器振动机理和基于振动的特征值及其提取算法。(2)基于振动特征值,分别对朴素贝叶斯分类模型和支持向量机模型进行了研究,通过对实验和现场变压器实测数据结果的对比与分析,提出并实现了一种针对电力变压器带电监测和故障诊断更为有效的机器学习模型及其诊断算法。(3)在上述研究结果的基础上,应用物联网技术及架构,设计、开发和实现了变压器带电振动监测与故障诊断软件系统。实际使用效果表明,所设计的系统能够有效地对电力变压器的健康运行状态进行远程和实时监测,提高了变压器运行的安全性、稳定性和可靠性。"
644,基于深度学习的宏基因组序列分类方法研究,"基因测序技术的高速发展使得测序的成本指数下降,下一代测序技术被广泛应用。同一时间能对复杂环境中不同微生物的基因组进行测序,从而获得大量的微生物基因数据。宏基因组学通过16S rRNA扩增技术直接获得微生物的全部DNA序列,通过这些序列信息分析出整个微生物群落物种的丰度,再根据丰度信息得到群落的特征和功能。16S rRNA测序产生的片段同时具有同源性和特异性,同源性可以用来追踪物种的起源,特异性可以鉴别出不同的物种。已有研究表明人体肠道菌群与疾病和代谢息息相关,宏基因组分析已成为研究微生物群落的重要的一种辅助方法。宏基因组研究的重要一步是鉴定物种的类别,已有许多的方法被提出用来解决此问题,但是这些方法的分类正确率仍有很大的改进空间。针对宏基因组分类问题,本文提出了混合深度卷积神经网络和全连接神经网络的分类模型。该模型在卷积神经网络阶段实现数据特征降维,在后一个全连接阶段学习各种特征之间的非线性关系。用RDP和Greengenes数据库中的三组数据集分别训练和测试模型,数据集中包含细菌和古菌的16S序列以及真菌ITS序列。训练好的模型能够根据给定的基因序列预测已存在数据库的分类标签,在无参考数据库的情况下使用GPU实现多条查询序列并行分配。本文对以下几方面内容展开了研究:(1)宏基因组数据分类特征提取。使用两种不同的特征提取方式,一种是基于k-mer,以k个碱基划分整条序列,组成特征空间。另一种是基于对齐的,这种方式先把不等长的序列通过全局比对的方式处理成长度一样的序列。基因序列是字符串信息,在训练之前进行编码,编码过程中考虑了序列实际的生物学意义。(2)针对宏基因组序列分类预测问题,设计了基于深度学习的混合深度神经网络模型。深度神经网络模型逐层学习基因数据中的非线性特征,进而利用这些层次化的特征数据来对宏基因组序列进行分类预测。并对训练好的模型进行了保存和可视化。(3)把两个数据库中的三个数据集处理成一致的表达格式。在每个数据集用了三种不同的方法进行训练测试,其中RDP分类器分类使用的是默认参数。对于本文设计的模型,通过多组实验,确定模型的参数。用精确率、召回率、F1-score等分类评估指标评估了三种不同方法的分类性能。"
645,基于机器学习的混凝土徐变模型研究,"混凝土是土木工程中应用最为广泛的一种材料。在实际工程中,混凝土徐变对于各类结构的耐久性能有着至关重要的影响。从混凝土徐变开始受到关注至今,已经有大量的试验研究被全世界各地的学者完成并将试验数据收集成库。然而目前采用的混凝土徐变模型对于大量的试验数据而言,预测结果并不理想,基于传统的拟合回归徐变模型在大数据集情况下预测效果有待改善。本文采用机器学习的方法对数据库中大量的混凝土徐变数据进行分析,主要内容有以下几个方面:(1)使用混凝土徐变数据库中大量的试验数据,对现行混凝土徐变预测模型(包括MC2010,ACI-209,GL2000,B3,B4)的预测效果进行了包括预测值域分布范围、预测精度和误差分布的对比分析。在此基础上,采用网格搜索法对上述混凝土徐变预测模型进行了参数修正,各模型修正后的拟合效果均有不同幅度的提高,修正后最高拟合决定系数为0.688。(2)将徐变数据库中的试验数据进行整理,整理后的数据集按3:1的比例分为训练集和测试集,基于训练集建立了全连接神经网络混凝土徐变预测模型和支持向量回归混凝土徐变预测模型,并在测试集上对两种机器学习的混凝土徐变预测模型进行了验证。基于机器学习的混凝土徐变预测模型的拟合决定系数能够达到0.8以上。(3)采用最大信息相关分析方法,对混凝土徐变影响参数与混凝土徐变之间的相关性进行了计算,得出基于互信息的混凝土徐变影响参数与徐变的相关性排序。然后结合以上提出的混凝土机器学习徐变模型,采用全局敏感性分析方法对混凝土徐变影响参数的敏感性进行了分析。并将混凝土徐变敏感度分为独立敏感度和相关敏感度,结合相关性分析,选出了混凝土徐变重要参数。(4)使用混凝土徐变数据库中的数据,以混凝土徐变重要参数作为输入参数,结合分数阶粘弹性流变模型,采用进化算法对混凝土徐变训练集数据进行符号回归,建立了基于大数据集的混凝土徐变模型。采用测试集数据对模型进行验证,其拟合确定系数能够达到0.75以上。区别于全连接神经网络模型和支持向量回归模型,基于进化算法的符号回归模型有明确的表达公式。为了区分,本文将全连接神经网络模型和支持向量回归模型等统称为隐式模型,将有明确公式表达的模型称为显式模型。最后,考虑输入参数之间的相关性,采用拉丁超立方抽样方法,对混凝土徐变显式模型在不同服役条件下的预测效果进行了不确定性分析,为实际情况使用给出了推荐。"
646,融合多传感器的故障诊断方法研究,"滚动轴承是支撑机械旋转的一个关键零部件,一旦发生故障,将会直接影响到整个系统的平稳运转,甚至可能造成巨大的经济损失和安全事故。传统机械故障的检修方法是定期计划检修,其特点是耗时费力、成本高昂。当前,基于零部件状态来决定是否对机械设备进行维修的状态修是各国进行大型设备检修的主流方法。随着我国重载货车地对车安全监控预警系统(4T)的建立,以及近几年大数据和深度学习技术的不断发展,基于数据驱动的故障诊断技术能够在重载货车状态修上发挥重要的作用。4T系统由货车滚动轴承振动诊断系统(TADS)、货车红外线轴温检测系统(THDS)、货车运行状态地面监控系统(TPDS)、货车运行故障图像检测系统(TFDS)四个子系统组成,本文充分利用从4T上挖掘的重载货车关键零部件运行状态数据,建立融合多传感器特征的故障诊断模型,经过实验分析,该方法能够实现对滚动轴承的精确故障诊断。本文具体的工作内容如下:(1)挖掘THDS、TPDS、TADS的温度、压强、偏移量、时域信号等特征作为模型输入,同时使用缺失值填充、特征去冗、离群值修正等特征预处理技术处理特征中存在的缺失数据和噪声数据。本文使用GBDT对特征进行重要性排序,并与XGBoost模型进行结合,提出GD-XGBoost分类模型对滚动轴承进行故障诊断。(2)挖掘TADS的振动信号,由于滚动轴承的振动信号具有非平稳、非线性特点,先使用Hilbert-Huang变换提取信号的Hilbert边际谱特征,作为模型的输入。本文对DenseNet网络结构进行改进,改变卷积、池化层的参数使其能处理一维序列;引入Inception模块来拓展网络宽度,使用不同大小的卷积核来提取信号不同尺度的特征,提出1D-DenseNet神经网络结构对滚动轴承振动信号进行故障诊断。(3)针对使用单源模型对滚动轴承进行故障诊断可能存在的不确定性问题,本文使用D-S证据理论对以上两个单源故障诊断模型进行决策层结果融合,进一步提升了滚动轴承故障诊断模型的诊断精度和抗干扰性。最后将本研究进行系统实现,作为铁路货车状态修诊断决策系统的一部分。"
647,Classification of Benign and Malignant Thyroid Nodules in Ultrasound Images,"随着计算机视觉技术的进步,医学图像处理已被广泛用于医疗诊断。近年来,为了提高癌症早期检测准确率并改善治疗的效果,特别是在脑癌、肺癌、乳腺癌等肿瘤结节的诊断。超声图像的分辨率较低,并且图像中显示肿瘤的区域通常是模糊的,如边缘模糊,形状不规则。甲状腺结节是人体内分泌系统常最见的疾病,自动实现结节的良恶性分类可以辅助医生进行相关疾病的诊断。本质上,大多数甲状腺结节是良性的,只有不到5%是恶性的。大多数现有技术都有一些局限性,因为这些技术是在有限的数据集下进行检查和评估并且没有实现自动分类。因此,为了更加准确的实现甲状腺结节良恶性自动分类,我们将卷积神经网络应用于甲状腺结节超声图像的分类。为了提高检测的准确性,我们使用了深度卷积神经网络VGG-16提取结节区域的特征用于分类。在本研究中,VGG-16被用于甲状腺结节的分类。我们在公共数据集和本地数据集上训练和测试了模型。该模型可以较为快速、可靠地对甲状腺癌结节的良恶性进行分类,在医学领域具有一定的应用价值。"
648,基于深度神经网络的中文评论情感分析研究,"近年来,互联网的发展给了众多用户在网络上发表自己言论的机会,而为个人碎片化倾诉与沟通提供新空间的微博(Weibo.com)在社会各类人群中有着极大的影响力。本文以微博的公开数据为实验依据,针对微博评论文本情感倾向复杂的特点,本文提出了基于深度学习模型的情感分析研究。这一研究课题对于挖掘情感具有重要作用。从文本中挖掘出来的情感信息可以反映发布者当时的情感状态,在个性化推荐、舆情控制、基于社会调查的政策制定等方面蕴含着极大的应用价值。首先,本文选择以微博评论数据进行研究,利用Python语言进行了网络爬取数据,针对微博数据集的不足和可用数据的标注混乱现象,搜集、整理了网络公开可使用的微博评论数据集。同时,针对微博评论的语义表达隐秘的特点,设计了基于隐马尔科夫模型及维特比算法的分词技术。利用综合状态之间的转移概率和前一个状态的概率情况,计算出概率最大的状态转移路径,回溯并记录概率最大路径,找到最可能正确的分词方案。其次,针对传统的词向量化独热编码的的方法存在的数据稀疏性问题,本文提出使用一种词向量文本特征提取工具的改进方法,利用了FastText中Sub-word子词嵌入技术获得更具有语义和语法关系的词向量,以及其表征类别的树形结构,在其输出端使用H-softmax多层分类器方法,同时与传统Word2Vec的跳字模型进行文本特征的提取方法对比,证明了方法的有效性,提升了模型的计算效率和训练速度。最后,本文设计了在模型中引入注意力机制,通过对编码器所有时间步的隐藏状态做加权求和来得到背景变量。能够直观的解释各个句子和词语对分类类别的贡献程度和重要性。将注意力机制连接在LSTM模型和输出层中间,表现了输出目标句子的某个词和输入句子中的每个词的对应关系,使加入注意力机制后模型在微博评论情感分类上的效果得到了提升。"
649,基于卷积神经网络的人脸个体与性别识别的研究,"人类识别世间万物的基础是把各物种先进行归类,然后将各类别事物命名予以区分。其中,区分的难点是相似类别间的事物,它们之间的区分和识别主要依据的是脸部、体型和个体的行为表现等。从生物学原理上解释,人类在分类的过程是通过眼睛传递到大脑,然后大脑根据眼睛看到的图像做出反馈,最后再对所看到的事物进行归类和命名。这种通过眼睛到大脑来分类识别的传递方式是通过无数个神经元组成的人体神经网络系统来实现。依据这种生物学原理,在人类进入信息化时代,造物技术的发展,人们开始研究机器学习代替人做一些简单的分类问题,人脸识别就是具有代表性的分类应用。随后,机器学习技术的发展推动了深度学习方法的出现,特别是深度学习领域出现了模仿人类神经系统的原理方法,具有代表性的就是卷积神经网络(CNN,Convolutional Neural Networks)。介于CNN的框架方法和分类技术的成熟,表现出出色的分类识别效果。因而CNN方法在近年受到国内外学者的追捧,在人脸识别领域也受到众多学者热爱和应用。本文在调查和研究有关CNN的人脸识别基础上,聚焦的重点是构建CNN的模型结构和分类方法来提高识别的准确率和效率,主要的工作安排如下:(1)针对本文使用的人脸数据集尺寸太大且存在无用特征信息的问题,利用积分图像和级联的算法对数据集中图片提取研究所需的人脸部分,实验将本文研究的CASIA-WebFace、LFW和Adience三种数据集提取所需尺寸的人脸,重新命名数据集。(2)针对众多的人脸识别技术在CNN上的应用只是单方面提高人脸的识别率,但是忽视了网络模型输入参数,导致模型输入参数多、训练时间长和无法在内存小的硬件上运行等问题,提出一种基于改进的SqueezeNet的人脸识别模型。改进的SqueezeNet模型采用首尾采样层分别融合后续的卷积层,提取细微的人脸纹理特征来稳定模型收敛性。针对分类函数Softmax的改进,采用L2范数约束的方法,将最后一层的特征约束在一个球面内,减少相同特征间距,提高网络收敛能力。并且在实验中验证了该方法有效性。(3)为了进一步提高CNN在人脸性别识别的准确率,在传统的采样层融合模型基础上,提出一种新型全局融合采样层的CNN模型(NFDCNN,New Fusion Deep Convolutional Neural Network)。在NFDCNN框架结构上,每两采样层之间的卷积层在卷积特征提取之前融合前一级的子采样特征,这种方法可以保留原始的特征信息,同时与深层纹理融合,具有较高的特征信息还原度,缩小网络误差。NFDCNN模型分类函数在常规的Softmax上做了改进,引入了区域边缘分类函数AM-Softmax,该分类函数在归类上是以一块区域为界来划分,函数分布规律图上表面具有扩大不同类别间距离,缩小类内距离,并且在实验中验证。"
650,基于域对抗网络的跨领域文本情感分析,"随着web2.0的发展,互联网深入人们生活的方方面面,同时为人们提供了更加方便和宽广的信息交流平台。越来越多的用户在社交平台上表达自己的想法,在购物平台上阐述自己对产品的使用看法,在新闻平台上发表个人观点,由此产生了大量包含用户观点信息的文本数据,因此分析这些文本数据的情感极性也就有了很重要的价值。情感分析又称意见挖掘,是对网上各种新闻资源、社会媒体评论和其他用户生成内容的进行分析、处理、归纳和推理的过程。文本情感分析是情感分析算法的一个分支,典型的监督分类算法都适用于文本的情感极性分析。然而,当训练数据与测试数据不属于同一个领域的时候,传统的分类方法的预测效果就变得很差。通常是因为源领域有强烈情感性的特征在目标领域可能不再具有这些特征或是呈现其他情感极性,为了将源领域的特征泛化到目标领域特征中,并对目标领域进行情感分析,跨领域情感分析成为了解决方案之一。跨领域情感分析方法当前主要关注用特征提取器提取多个领域之间的共享情感特征。其中利用深度学习中特征提取网络优秀的特征提取能力提取不同领域之间的共享情感特征,再利用共享情感特征进行情感分析是当前跨领域文本情感分析的主要研究方向。目前深度学习方案中主要利用自编码器和域对抗实现共享情感特征的提取,因此本文主要优化改进域对抗能力以及利用深度学习中的各种不同的网络结构提取句子中的语义信息,最后将提取出来的不同领域文本中的共享情感特征用于文本情感分析。本文的主要研究内容,及创新点如下:(1)由于不同领域之间的特征不同,使用以往的域对抗方式容易出现梯度消失和梯度爆炸,并且提取的特征泛化能力差的问题。本文通过提出基于Wasserstein距离的域对抗方式,然后结合正交约束来更好地提取领域深层共享特征,同时在整体网络结构上使用降噪自编码器,使得特征提取器能够提取出鲁棒性更强的领域共享情感特征。(2)针对以往特征提取方式提取的共享情感特征中缺少句子语义信息等问题,本文使用BERT模型获取句子中的语义信息,再借助卷积神经网络对提取的特征进一步的特征选择以及特征降维。然后借助域对抗机制混淆源领域和目标领域的特征,同时利用源领域含标签的数据训练情感分类器。最后在亚马逊公开数据集上的对目标领域情感极性进行预测,并且取得了较好的预测结果。"
651,基于神经网络的命名实体识别研究,"命名实体识别的主要任务是从文本中识别人名、地名以及机构名等有意义的实体,是自然语言处理基础任务之一。命名实体识别在知识图谱构建、信息检索等众多领域扮演着重要角色。然而传统命名实体识别方法依赖于人工构建的特征模板,需要耗费大量的人力物力,且在处理大规模文本数据时存在局限和不足。利用深度学习进行命名实体识别可以减少特征提取的工作量,同时解决数据稀疏性问题。为构建东盟十国多语言知识图谱,首要任务是对多语言语料进行命名实体识别。因此,本文提出了基于神经网络的命名实体识别方法,具体研究内容如下:(1)提出一种基于BiGRU-CRF的中文命名实体识别模型。该模型首先使用word2vec将中文字符转化为低维稠密向量,其次利用BiGRU网络提取向量的语义特征,最后通过CRF层预测并输出最优标签序列。为了进一步提高识别效果,在BiGRU和CRF层之间添加两层隐藏层。在数据预处理方面,提出一种数据集划分算法,并对文本进行更加科学合理的划分。在东盟十国数据集上将该模型与几种混合模型进行对比,实验结果显示该模型在命名实体识别任务中拥有更好的识别性能。(2)在处理跨语言命名实体识别任务时经常会出现语序混乱问题,BiGRU-CRF模型已无法满足实际需求,因此将Self-Attention机制和CNN与BiGRU-CRF模型相结合,构建一种基于Self-Attention-BiGRU-CNN-CRF的跨语言命名实体识别模型。首先利用GAN训练跨语言词向量,其次通过CNN和BiGRU获取向量的语义特征,最后通过CRF层预测并输出最优标签序列。在BiGRU中添加Self-Attention机制可以减轻不同语言转换时出现的语序混乱问题,突出关键词对实体标注的影响,从而提高了模型的命名实体识别性能。在ConLL2002和2003通用数据集上将该模型与其他模型进行对比,实验结果表明,该模型在西班牙语、荷兰语、德语的跨语言命名实体识别任务中任务中F1值在各模型中表现最优,分别为72.73%,71.56%,58.03%。"
652,基于多特征融合的微博情感分析研究,"随着网络时代的到来和科技的进步,以微博为代表的社交网络平台逐渐成为人们分享和获取信息的主要途径。用户发布在社交网络平台的这些信息大多带有明显的情感色彩。通过对这些带有主观性情感色彩的信息进行情感分析,有助于推动舆情分析、个性化推荐和突发事件预防等领域的研究,因此微博情感分析具有重要的应用价值。本文重点围绕微博中的图文进行情感分析研究,主要研究内容有:(1)现有的微博情感分析方法较少注意到用户情感表达的差异和微博内容中除文字之外的特征,导致微博的情感分析效果难尽人意,为此,提出了融合内容特征与用户特征的文本情感分析方法。构建文本情感分类模型TSCCUF,将对情感具有很好指示作用的内容特征、用户特征与微博句子进行融合。实验结果表明,内容特征与用户特征的融合,增强了模型捕捉情感语义的能力,相较于未进行特征融合的BLSTM、MCNN等模型,TSCCUF模型各项性能都有较大的提高。(2)针对使用CNN构建的图片情感分类模型容易出现过拟合或收敛速度慢的问题,提出了基于参数迁移与微调的图片情感分类模型TFCNN;针对单模态文本或图片的情感分析方法准确率不高的问题,设计了图文融合的微博情感分析方法。在文本情感分类模型TSCCUF和图片情感分类模型TFCNN的基础上,分别设计了特征层融合和决策层融合方法进行图文融合的情感分类。实验结果表明,图文融合的情感分析方法比单独基于文本或图片的情感分析方法拥有更高的情感分类准确率,并且在决策层融合可获得更好的分类效果。(3)针对现有的大多数微博情感分析方法未考虑到微博之间情感的依赖问题,提出了融合交互特征与转发特征的微博情感分析方法。构建微博情感分类模型TSCCFF,将交互特征、转发特征与微博句子进行融合,弥补了以单独微博句子作为输入的数据稀疏性,并且充分捕获了微博句子与交互特征、转发特征的情感依赖关系。实验结果表明:与代表性算法CNN、LSTM以及基于注意力机制的双向LSTM相比较,TSCCFF模型能够对用户真实情感进行更加有效的分析。"
653,基于机器学习的固态缓存优化研究,"近年来,SSD凭借其较高的读写性能及性价比,在缓存系统中发挥越来越重要的作用。通常缓存空间远小于后端存储空间,容量差距大约在一个数量级甚至更多,因此SSD缓存的写入密度(单位时间和空间的写入量)远远高于HDD后端存储的写入密度,这给保障SSD的寿命带来了巨大挑战。同时,在社交网络的工作负载下,对SSD缓存的大量写入是不必要的。例如,在某知名公司的社交图片系统中,大约61%的图片只会被访问一次,但它们仍然被写入了缓存。由于这些图片只访问一次,进入缓存后不会被再次访问,对缓存而言写入这样的图片就是无用的。因此,如果能够主动地预测这类图片并阻止它们进入缓存,将消除对SSD缓存的不必要写入,提高缓存空间利用率,并延长SSD缓存的使用寿命。为了实现这一目标,提出了一个适用于不同缓存空间大小的一次访问判定标准,进一步提出了一次访问过滤策略。在此基础上,设计了一个用于预测的分类器来实现这一策略。与目前为止最先进的基于历史信息的预测方案不同,预测需要在文件第一次访问时就做出判定,也就无法借助文件的历史访问信息来完成,这对于实现良好的预测准确性带来了极大挑战。为了解决这个问题,将决策树集成到分类系统中,提取用户的社交信息作为分类特征,并综合使用代价敏感学习、历史表、训练模型定时更新等方法来提高分类精度。基于该技术方案,预测准确度达到了80%以上,大幅度地降低了SSD写入次数,提高了缓存命中率。实验结果表明:一次访问过滤策略使缓存多个方面的性能得到了提升,以LRU为例,使用一次访问过滤策略后缓存命中率提高了4.4%,对SSD的写入率降低了56.8%,平均访问延迟降低了减少5.5%。"
654,基于并行计算的地质雷达正演模拟及典型岩溶洼地地质特征智能识别,"我国西南地区高速公路建设面临着大量的岩溶洼地的岩溶地质问题,其土洞、溶洞的潜在塌陷给高速公路的建设和运营带来了极大的危害。探明岩溶洼地中土洞、溶洞等地质异常体所处的位置、类型、充填情况并进行针对性处理,对于高速公路的安全建设和运营具有较为重要的意义。地质雷达作为一种快速、无损、高效的检测方法,已成为典型岩溶洼地地质异常体勘查的主要手段。随着地质雷达检测数据量的迅速增加,人工对地质雷达图像进行判别已经无法满足工程检测对于地质雷达图像快速、准确判别的需求。本文以宜毕高速公路岩溶洼地区路基勘查为背景,以实现典型岩溶洼地地质雷达图像的快速、智能识别为目的,通过实地调查、理论分析等手段划分岩溶洼地的主要地质模式;开发基于并行计算的快速地质雷达正演模拟软件;基于岩溶洼地地质模式,模拟不同地质异常体,不同相对介电常数模式下的地质雷达扫描图像;使用岩溶洼地地质雷达正演模拟图像数据集训练深度学习目标检测算法;主要成果如下:(1)根据岩溶洼地地质成因、排水方式等因素对岩溶洼地的地质模式进行了详细的划分;建立了在复杂地质条件下粘土层相对介电常数与深度的关系。(2)为提高地质雷达正演模拟准确度,本文推导了二维时域有限差分的高阶辛差分形式;推导了卷积完美匹配层吸收边界高阶辛差分形式;推导了地质雷达正演模拟中数值稳定性和色散条件;推导了雷克子波发射源的函数形式。(3)使用GPU并行编程对时域有限差分算法进行了加速,开发了基于二维高阶辛差分的地质雷达正演模拟软件(FastGPRv1.0);开发了地质雷达正演模拟画图软件;在同等计算精度条件下,将正演模拟计算速度提高了近50倍。(4)使用FasGPRv1.0对不同覆盖层相对介电常数模式、不同空洞跨高比、不同充填情况等多种地质情况进行了充分的模拟,共生成地质雷达正演模拟图像1680张。分析在不同地质条件、不同频率下的地质雷达图像典型响应特征,并将正演模拟生成的地质雷达图像制作成地质雷达正演模拟图像数据集。(5)使用多种图像数据增强手段,对岩溶洼地典型地质灾害雷达正演模拟图像数据集进行图像数据增强工作;基于Tensorflow深度卷积神经网络框架实现了SSD目标检测算法;在地质雷达正演模拟图像数据集上进行了训练,算法在测试集上达到76%的平均准确率;在现场采集的地质雷达图像上做了相关验证工作,验证了通过正演模拟数据集训练深度学习算法的可靠性。"
655,基于深度学习的脑血管病电子病历辅助诊疗研究,"脑血管病是危害中老年健康的常见疾病,因其治疗和护理周期长、复发率高等特点,成为各地医疗中心的主要负担。同时,各级医院医疗信息化过程中积累的脑血管病电子病历和患者档案等数据,结合深度学习等人工智能技术,成为了解决脑血管病辅助诊疗问题的新思路。基于上述背景,本文从分析脑血管病电子病历辅助诊疗研究现状入手,通过引入深度学习算法模型,找到了弥补电子病历数据不完整、医疗中心数据模版不统一、大规模医疗语料库缺失等局限性的突破口,即通过命名实体识别技术和图嵌入技术的融合,在海量电子病历数据中提取关键信息,构建相似病历检索模型,并可基于此模型结果实现脑血管病电子病历辅助诊疗应用场景的扩展。本文的研究内容主要有以下几点:(1)引入注意力机制的命名实体识别研究:针对中文电子病历医疗模版不统一和缺少大规模语料库的问题,将引入注意力机制的Bi-LSTM-ATT-CRF命名实体识别模型引入相似病历检索研究中,通过计算注意力权重提取电子病历关键信息,突破电子病历模版限制;通过半监督学习方式,解决语料库缺失问题;(2)基于脑血管病命名实体网络和图嵌入node2Vec的相似病历检索模型研究:针对中文电子病历数据记录不完整的问题,通过图嵌入技术node2Vec将云平台脑血管电子病历数据网络化表示学习,通过随机游走技术挖掘网络中的隐藏关系,获取电子病历的篇章向量表示,通过余弦相似度计算电子病历相似度;(3)相似病历检索模型的应用:结合天坛医院脑血管病协同防治云平台信息共享的现状,实现云平台下基于相似病历检索模型的脑血管病辅助诊疗应用。通过对脑血管病电子病历辅助诊疗的研究,得出了以下结论:(1)通过与条件随机场、Bi-LSTM以及Bi-LSTM-CRF的对比实验,证明了引入注意力机制的Bi-LSTM-ATT-CRF模型在医疗命名实体识别领域的适用性;(2)通过与空间向量模型和LDA主题模型的对比实验,证明了通过融合命名实体识别技术和图嵌入技术可以有效提升医疗相似文本检测的效果;(3)通过实际应用,证明了本文提出的模型结果可以扩展电子病历辅助诊疗的应用场景,实现从相似病历检索、病症分布分析和诊疗手段效果分析三方面帮助医生快速匹配脑血管病症状相近的病历表现,找到关联案例,实现脑血管辅助诊疗,提高医生的工作效率。"
656,基于Resnet&FM模型的电影个性化推荐研究,"推荐系统是解决信息过载问题的有效手段之一,它能提高用户获取有效信息的效率、消除信息壁垒、增加信息价值。近年来,随着网络中抽象的非结构化数据以几何速度增长,传统电影推荐系统在新的数据环境中已经不能针对特定用户进行精准的推荐,而深度学习模型是逐层加工的、非线性的网络结构,对抽象的非结构化数据有着很强的学习能力。因此,将深度学习引入传统电影推荐系统中有着重要的研究意义。通过梳理现有的研究成果发现,基于内容的推荐以及基于矩阵分解的推荐都有着对抽象的电影项目特征提取困难的缺陷,而基于协同过滤的推荐虽然在用户与项目评分矩阵稀疏时推荐困难,但能通过引入深度学习模型来有效解决这一问题。经综合分析,本文根据基于模型的协同过滤推荐策略开展了以下几个方面的研究工作:(1)针对电影个性化推荐场景中数据的特点,对电影推荐数据的特征工程开展研究,通过引入词嵌入以及Word2vec解决了One-Hot编码带来的维度爆炸以及文本特征提取困难的问题。(2)全面分析了单一浅层学习模型与深度学习模型的数学原理及其优缺点,并从特征融合和模型训练两个角度出发,改进了Wide&Deep模型。在Wide侧引入因子分解机,自动学习全部的二阶显式关联特征,弥补了原来线性模型依赖人工构建关联特征的不足;在Deep侧引入残差结构,缓解了深层次神经网络梯度消散的现象,构建了适用于电影个性化推荐场景的Resnet&FM融合模型,并与Wide&Deep模型开展对比实验,RMSE提升了1.6%、MAE提升了0.7%。(3)开展Resnet&FM模型激活函数与权重初始化策略选择的研究。深度学习模型对高维抽象特征的学习能力主要由非线性的神经元个数以及整个网络的参数所决定,通过对神经元以及参数初始化策略的数学原理进行分析,并通过实验对比,证明了基于Kaiming初始化以及Relu函数的Resnet&FM模型效果最佳。与标准初始化配合Sigmoid函数相比,RMSE提高了3.3%、MAE提高了3.6%、与Xavier初始化配合Tanh激活函数相比,RMSE提高了4.3%、MAE提高了4.4%。(4)Resnet&FM模型的优化算法决定了是否能够找到最佳的参数拟合电影个性化推荐场景中的用户数据以及电影项目数据的一般规律。因此,本文通过对不同种类的梯度下降算法原理进行比较分析,并结合Renset&FM模型开展对比实验,确定了Adam算法为该推荐模型的最佳优化算法。"
657,电磁层析成像深度学习图像重建算法研究,"电磁层析成像(Electromagnetic tomography,简称EMT)技术依靠其非接触、用途广泛、高可靠性等优势,在采矿冶金、无损探伤、医学成像等领域均有应用。其广泛的工业需求对其成像质量有了更高的要求。在EMT逆问题的研究中,由于其先验信息有限,且具有病态性与不适定性等问题。进一步提高图像重建精度和速度为该领域的热点研究问题。近年来,人工智能类算法在语音、图像、翻译等多领域的成功应用引导我们探索利用其解决传统EMT问题的可行性,试图用其强大的学习能力和有代表性的样本,自主学习成像特征,达到提高成像质量与速度的目的。本文主要工作内容如下:(1)受机器学习数据预处理中数据降维思想的启发,设计了降维SVD算法。文中通过仿真与实验两种方式,结合三种传统算法的成像对比实验,分析了降维SVD算法的优势和劣势。(2)基于深度学习理论,设计了两种EMT深度学习图像重建算法:SSAE+RBF和Optimized FC。并对网络细节做了详细描述,从理论上阐述了两种网络算法用于解决成像问题的合理性。(3)设计并仿真了两种类型30000个样本,用于网络训练过程中成像特征的学习和网络参数学习;设计了一种损失函数,作为网络训练优化目标,并通过理论推导证明了该损失函数的合理性。(4)本文设计的两种深度学习图像重建算法,通过在2000个测试样本上与传统算法的批量成像对比实验,展示了本文网络算法的成像优势;通过在测试样本集上混入不同噪声等级噪声的成像对比实验,展示了本文网络算法的抗干扰能力;通过与传统算法的成像时间对比实验,验证本文网络图像重建算法的速度优势。文中设计的两种深度学习图像重建算法,在与训练集特征近似的、未学过的样本测试集上取得了大幅度优于传统算法的成像效果。本文初步证实了深度学习理论应用于传统EMT领域,以提高成像精度和成像速度的可行性。在网络成像算法设计、样本设计和损失函数设计等方面,对EMT深度学习成像算法的进一步研究有一定借鉴意义。"
658,提格里尼亚语新闻分类研究,"近年来,随着网络技术的进步,互联网的发展以及网络用户数量的增加,网络数据量呈现指数级增长。虽然大量的数据是有价值的,并且其中大部分数据是文本文档,但是,除非以适当的方式组织这些文本信息,否则用户根据其需要选择有意义的文本信息将成为一个新的问题。处理该问题的一个方式是设计处理自动化的文本分类系统,这个过程被称为文本分类(TC)。文本分类通常需要在线组织和管理大量可用的文本文档。文本分类的目标是首先从已标记的文本文档中学习类别的特征,然后应用学到的类别特征将文本文档自动化地归类为它所对应的类别。在已有的文本分类文献中,大多数文本分类研究的文本主要是由英语、汉语、日语、多数欧洲语言等少数通用语言编写的,然而,由一些小众语言编写的文本进行文本分类需求却在不断增长,例如,属于闪米特语系的提格里尼亚语。但是,针对提格里尼亚语的文本分类所开展的研究却很少。与其他语言一样,由提格里尼亚语编写的数字化文本文档的数量也呈现指数级增长,因此,非常迫切地需要对它们进行组织和管理以便简化提格里尼亚语的存储、搜索、浏览,并且满足用户需求。对由提格里尼亚语编写的文本文档进行文本分类是一项具有挑战性的任务,因为提格里尼亚语的语法和形态是复杂的,同时由提格里尼亚语编写的文档语料资源是非常匮乏的。在本文的研究中,我们提出了针对由提格里尼亚语编写的新闻文章的自动化文本分类模型,该模型分两个阶段进行:数据准备(包括数据清理、文本规范化、分词、去停用词、词干提取以及特征工程等步骤)和利用有监督的机器学习技术去学习分类器。本文的主要目的是利用有监督的机器学习技术为由提格里尼亚语编写的新闻文档最终找到一个非常有效的文本分类模型(也被称为分类器)。由于提格里尼亚语的文本语料非常稀少,因此,构建新的提格里尼亚语的语料库对于提格里尼亚语的文本分类研究是至关重要的。在本文的研究中,我们构建了自己的语料库,并且对提格里尼亚语的新闻文章进行标签标注。构建语料库所使用的原始文本文档来源于名为“哈达斯厄立特里亚”的日报,该日报通常是由厄立特里亚新闻部进行刊登。所构建语料库被随机分层抽样分成两个集合:其中一个集合用于训练,被称为训练数据集,另一个集合被用于测试,被称为测试数据集。其中,训练数据集的文本数量约占总数据集文本数量的80%,测试数据集的文本数量约占总数据集文本数量的20%。除此之外,每一篇新闻文章被人工标注在10个类别标签上,这10个类别分别为运动、科学与技术、政治、关系、法律、历史、健康、教育、经济、文化与社会。由于没有用于提格里尼亚语的自然语言处理工具和资源,我们开始设计新的算法来预处理提格里尼亚语的文本文档。在数据预处理阶段,语言依赖文本规范化、停用词提取器以及提格里尼亚语的词干提取是通过探索和分析提格里尼亚语的语法结构来获得的。文本规范化程序有两个阶段:文本清理和文本规范化。首先从语料库中删除了不必要的标点符号、数字和非提格里尼亚语的单词。为了使语料库中的文本规范化,将从语料库中识别出提格里尼亚语的“cliticized”、“hyphenated”以及“short”这三种形式的单词转换为标准化的正确形式。预处理文本文档的另一种常见做法是识别文档中所含语义非常少的单词,但这些单词出现的频率很高。这些词被称为停用词。已有的研究已经构建了针对不同语言的停用词列表,例如英语,中文,阿拉伯语等,但没有标准方法来识别提格里尼亚语的停用词。因此,我们专门设计了针对提格里尼亚语的停用词提取程序去自动化识别停用词。格里尼亚语的停用词通过标准的逆文档频率方法获得。词干提取是减少单词变体的重要步骤,并且能够加快文本预处理速度并提高文本分类的性能。像阿拉伯语和阿姆哈拉语等其他闪米特语一样,提格里尼亚语的语法形态非常丰富并且复杂。语法形态的主要特征在于屈折和派生,因此可以从单个的提格里尼亚语单词创建大量的单词变体。这些形态可以通过词缀来创建。例如,将前缀、后缀、中缀,或者它们的组合添加到一个提格里尼亚语单词的词根或词干中则可以获得新的单词变体。因此,在文本分类中,提格里尼亚语单词的词干提取对于从这些混合变体中提取它们的共同词根或词干是必不可少的。然而,由于缺乏用于研究格里尼亚语的可利用的并且现成的词干分析器,我们开发了一个使用规则方法去除词缀的程序。在本文的研究中,应用了三种不同的文档向量表示策略来抓取文档特征,并将文档转换为由数字表示的特征向量,处理好的文档特征向量将被用于下一个处理阶段。第一个向量表示策略是使用由词频-逆文档频率表示,也可被简记为“TF-IDF”。TF-IDF是强有力的文档向量表示方法。它能够帮助可视化每篇新闻文章中单词的相对重要性。然而,TF-IDF不考虑特征之间的语义关系。为了将文章中的单词、短语、段落转换为向量表示,word2vec和doc2vec作为新的向量表示策略被应用在不同的自然语言处理应用中(包括文本分类)。Word2vec和doc2vec考虑了特征之间的语义信息,基于这种额外语义信息的假设,我们为基于提格里尼亚语的文本分类构建了有效的词向量嵌入表示和段落向量嵌入表示。为了展示在基于提格里尼亚语的文本分类中如何应用词向量嵌入,我们在整个数据集上训练word2vec来构建提格里尼亚语中词向量的模型。然后,这个词向量嵌入模型的结果将被用于将每篇新闻文章转化为一个向量,该文章向量的表示是通过加权平均所有由TF-IDF表示的词向量。相似地,通过训练两个层次的doc2vec模型构建两个段落向量嵌入,这两个模型分别被称为由词袋表示的段落向量分布(PV-DBOW)和段落向量分布存储器(PV_DM)。然后,我们通过连接两个段落向量表示模型PV-DBOW+PV-DM来构建文档向量嵌入模型,该模型是第三种文档向量表示方法。在将新闻文章文本转换为由数字形式表征的特征向量之后的后续处理阶段是学习分类器。在本文的研究中,分类任务是利用有监督分类器来训练的,其中,训练数据的向量表示有三种形式,分别为 TF-IDF、TFIDF weighted averaged word2vec、PV-DBOW+PVDM。分类器包括K最近邻(KNN)、支持向量机(SVM)、多层感知器(MLP)、随机森林(RF)。在训练期间,我们对训练数据集应用了 10折交叉验证,并调整了每个分类器的超参数,以提高其整体准确性。然后,在测试数据集上测试分类器并评估它们的性能。实验表明,由TF-IDF表示的词向量在SVM中获得了所有有监督分类器中最高的得分,总体准确率为93.65%,紧随其后的是由TF-IDF表示的词向量在MLP中的模型,总体准确率为93.45%。实验结果还表明,非线性的SVMs和MLP在段落向量表示(PV-DBOW+PV-DM)中也获得了比较好的性能表现,总体准确率分别为92.16%和91.07%,紧随其后的是由word2vec表示的词向量的SVMs模型和MLP模型,总体准确率分别为91.96%和91.87%。其中,word2vec表示的词向量是通过加权平均由TF-IDF表示的词向量得到的。实验结果表明,在所有采用的特征提取技术中,非线性高斯SVM和MLP适用于区分提格里尼亚语的文本分类任务。另一方面,由TF-IDF表示的词向量通过随机森林RF模型获得了最低准确度得分,准确度为77.98%。然而,由TF-IDF加权平均得到的word2vec词向量表示却大大提高了随机森林RF模型的性能,平均准确度为91.87%,提高了大约13.89%。这也表明模型需要有一种不仅处理单词重要性而且处理文档中单词之间语义含义的方法。因此,词向量嵌入能够可靠地用于提格里尼亚语的文本分类问题。最后,通过对提格里尼亚语文档中不同向量表示进行比较,可以得出结论:词向量嵌入和段落向量嵌入可以有效地扩展单词和文档的语义特征,使我们能够更加准确地对基于提格里尼亚语的新闻文本进行分类。"
659,基于深度学习的文本处理系统设计与实现,"随着人工智能技术的发展,法律、医疗和安全等行业都受到深远的影响。在这些行业中,大部分的数据都能够以文本形式存在,文本处理的目的是更好地管理这些文本并且从文本中获取用户需要的信息,具体是对目标文本进行分类、信息抽取等处理。深度学习已经在语音识别、计算机视觉和机器翻译等领域取得良好的应用效果,同样深度学习也能应用在文本分类等文本处理任务中。文本分类是文本处理中的核心部分,主要任务是学习给定文本的内容和标签,将这种映射关系生成分类器,利用分类器对未知类别的文本进行分类。本文主要研究工作如下:1、利用神经网络模型学习文本中的特征映射,实现文本特征的自动提取。分模块介绍了基于深度学习的文本分类算法原理,深度学习模型主要采用的是卷积神经网络和分层注意力网络。2、在两种深度学习模型的研究前提下,融合多个深度学习模型以提升文本分类的准确率,并且利用公开的中文文本分类数据集进行对比实验。根据实验结论进行分析,卷积神经网络模型分类准确率最低,采用分层注意力网络能在此基础上提升3%,而融合两个模型之后,分类准确率比卷积神经网络提升6%。3、针对法律行业的文本处理研究,设计并且实现了一个基于深度学习的法律文本处理系统。该系统的实现主要是基于深度学习框架TensorFlow,数据集来源于网络上采集的合同模板,采用卷积神经网络和分层注意力网络的融合模型构建分类器,在处理合同文件的同时也能对用户输入需求进行信息抽取,并且匹配到用户需要的合同模板。本文在深度学习和自然语言处理技术的研究基础上,主要进行法律行业的文本处理研究。法律行业的文书,比如裁决文书、合同文本、法律法规等,一般数量庞大、内容复杂,人工处理的方法效率低下,本文基于深度学习算法对法律合同文书进行文本分类、用户需求匹配等文本处理工作,能够提高办公效率和用户体验。"
660,基于机器学习的HDR图像取证技术研究,"随着科技发展带来便利性的同时,人们的安全性也受到威胁。如今数字图像已经是人们唾手可得的一种信息传递媒介,但却很少考虑这种媒介的真实性和原始性。图像取证就是一门利用图像的统计特征来验证数字图像真实性、原始性和完整性的学科。高动态范围(High Dynamic Range,HDR)图像以其丰富的亮度范围和优秀的视觉效果正在一步步走出实验室,走近人们的生活中,目前市面上已经有很多款可以直接观看HDR视频的数字电视。然而遗憾的是,目前很少有学者关注到HDR图像的安全性方面。图像取证主要分为主动取证和被动取证两大类,其中被动取证又包括图像来源取证,图像篡改取证和图像的隐写分析三类。现有的大部分图像取证算法仅仅关注低动态范围(Low Dynamic Range,LDR)图像,很多LDR图像取证方法直接应用在HDR图像上时效果不好甚至完全行不通。本文的研究内容主要集中在HDR图像的来源取证和HDR图像的篡改取证两方面。关于图像来源取证,本文首先使用图像联合直方图分析不同方法生成的HDR图像在统计特征上的区别,然后提出了合成模式噪声的新概念用于表征不同方法生成的HDR图像在生成过程中引入的固有噪声。接着我们针对HDR图像高空间分辨率、高灰度分辨率和独特压缩方法的几大特点,提出了一种用于HDR图像来源取证的神经网络,并在图像亮度域上取得了不错的效果。最后通过残差结构的替换进一步提升了该神经网络对HDR图像来源取证问题的准确率。另一方面,对于图像的篡改取证,本文通过对数亮度直方图分析了不同模糊润饰操作对HDR图像引入的像素值变化,并对直方图加以量化作为不同模糊润饰操作下的图像统计特征。除此之外,本文还提出了一种针对HDR图像模糊润饰操作的新的神经网络,并通过多段短路连接的初始结构提高网络的初始特征提取能力和网络拟合能力,解决神经网络在使用HDR图像像素值时效果不佳的问题。本文的实验部分在神经网络的不同结构的运用方面做了一定的对比,同时分别将传统图像取证特征与深度学习模型的结果进行比较。实验证明,本文针对HDR图像来源取证和HDR图像篡改取证分别提出的神经网络结构均能达到较高的准确率并且具有一定的鲁棒性。"
661,基于人脸识别的宿舍门禁系统的研究,"身份验证技术是门禁系统的核心,由于生物科技、计算机技术和信息技术的飞速发展,身份验证技术发生了革命性的变化。传统的身份验证多为磁卡、数字密码等方式,存在诸多的弊端。如今先进的身份验证方式多采用生物识别技术,其中,人脸识别因其具备用户友好、设备要求低等特点而引起广大学者和科研机构的关注。最近几年,深度神经网络技术的发展为人脸识别领域注入了新的血液。本文基于卷积神经网络理论设计实现了一种宿舍人脸识别门禁系统,具备一定的安全性,并取得了良好的效果,且具备较高的实用价值。本研究主要内容如下:1.分析人脸检测技术的发展,采用了一种多级联卷积神经网络结构进行人脸检测,根据网络的学习任务设置三个不同的损失函数,得到的模型最终在主流人脸图像集上能够达到较高的检测率。针对本研究的使用环境,采用了直方图均衡化的方式优化夜间成像,能够有效改善光线不足带来的影响,采用了中值滤波的方式控制图像噪声,能在一定程度上提升检测和识别准确率。2.使用了改进的特征提取网络对人脸进行特征提取,改进的网络在具备轻量级的参数量的同时加深了网络深度,能够提升运行速度和分类性能,在主流人脸图像集上获到了良好的效果。3.提出了一种基于眼部特征点的眨眼检测方法,与传统眨眼检测方法相比,本研究提出的方法运行速度快、计算简单且具备较高的准确率。4.实现了基于WEB端的宿舍人脸识别门禁系统,包含人员注册与认证通行等功能,该系统对设备要求低,实用性强。系统采用本研究训练所得的模型,它的参数较少,精度较高,其性质适用于门禁系统的使用,能提升门禁系统的使用效率。"
662,基于机器学习算法的重复购买行为预测研究,"重复购买行为是营销学领域的研究热点。随着电子商务的快速发展,参与网购的用户越来越多,如何基于大数据预测用户的重复购买行为成为电商平台非常关心并想解决的问题。重复购买行为预测技术可应用于电商平台推荐系统中,帮助商家识别具有重复购买意向的用户,从而实现营销信息的精准投放。准确预测重复购买行为的关键在于通过模型算法挖掘出数据中所隐含的用户行为规律。然而,由于网购用户群体规模巨大且不同用户群体的购买行为规律具有很大的差异性,这使得数据挖掘工作变得异常困难。传统的机器学习算法在预测时忽略了用户购买行为规律的差异性,难以取得好的预测效果。因此,本文着重研究如何提高机器学习模型在重复购行为预测问题中的泛化性能,使其克服用户行为规律的差异性对预测性能造成的影响。本文在对现有机器学习算法进行研究的基础上,提出了细分化集成学习方法。该方法可以从数据集中学习到多种用户购买行为规律,提高了模型的预测性能。论文的主要研究工作如下。(1)重复购买行为影响因素研究。通过对电商平台用户购买行为数据的分析,从用户、商家以及商家和用户的关系三个方面挖掘影响重复购买行为的重要因素,并构建了52种与重复购买行为相关的特征。(2)现有机器学习模型的对比研究。论文对常用的机器学习方法进行了研究。实验结果表明,现有的机器学习模型预测精度普遍不高。Logistic回归、神经网络、决策树等单一模型在解决样本类别不均衡问题时存在局限性。集成学习方法虽然可以通过欠采样的方式解决类别不均衡问题,但无法有效的学习到具有差异性的用户购买行为规律,预测效果同样不理想。(3)细分化集成学习策略研究。考虑到目前的机器学习方法在预测重复购买行为时存在的局限性,论文对Bagging集成学习方法进行改进,提出了细分化集成学习。细分化集成学习通过在Bagging中设置强规则结合策略,使其能逐层过滤样本数据,从而实现对用户购买行为数据的细分。这种新的集成学习方法可根据细分后的数据集学到多种购买行为规律。实验结果表明,与现有的机器学习方法相比,细分化集成学习具有更好的预测效果。(4)预测模型的泛化性能研究。从泛化误差的角度对细分化集成学习模型的泛化性能进行了研究。通过对模型的泛化误差进行分解发现,细分化集成学习的样本过滤机制可以降低方差,因此具有更好的预测性能。"
663,基于集成机器学习的老年多器官功能不全早期死亡风险因素分析及预测模型构建,"研究背景:老年多器官功能不全综合征(Multiple organ dysfunction syndrome in the elderly,MODSE)是指老年人在器官存在老化和罹患各种慢性疾病的基础上,器官机能减退处于功能不全的临界状态,由某种可能并不严重的诱因激发,在短时间内出现2个或2个以上器官序贯或同时发生功能不全或衰竭的临床综合征。其病死率极高,是导致老年重症患者死亡的主要原因之一。故早期诊断和预测转归并及时进行相关集束化综合治疗是降低其死亡率的重要途径。临床上,常用的器官功能不全的评分,如Marshall评分、序贯器官衰竭评分(Sequential Organ Failure Assessment,SOFA)、急性生理学与慢性健康状况评分系统Ⅱ(Acute Physiology and Chronic Health Evaluation,APACHE Ⅱ)评分,但这些评分主要适用于普通成年人,MODSE具有其不同于普通成年人发生的多器官功能不全综合征(Multiple Organ Dysfunction Syndrome,MODS)的特点,常用的器官功能不全的评分对病情严重程度的评价和转归的预测存在局限性。鉴于老年重症患者和ICU处置环境的复杂性以及各种变量的易变性,收录监测全方位、多维度的指标,电子病历(Electronic Health Records,EMR)的创建和发展为这方面研究创造了可能性。目的:1)针对MODSE人群,运用机器学习算法分析MODSE早期死亡相关风险因素;2)利用集成机器学习模型XGBoost等构建评估MODSE早期死亡风险的预测模型,更好地辅助临床决策和治疗。方法:1)利用公开的基于电子病历的大型数据库重症医学信息数据库MIMIC-Ⅲ(Medical Information Mart for Intensive Care),根据纳入排除标准纳入 MODSE患者16014人,其中院内死亡2360人(14.73%),根据预后将患者分为死亡组(2360人)和存活组(13654人),采集人口统计学信息、入ICU第一天的生命体征、临床干预措施、全身炎症反应综合征评分(SIRS)等122个特征,比较两组患者各指标差异,采用XGBoost模型算法进行死亡相关特征重要性排名;2)根据MODSE纳入标准,在MIMIC-Ⅲ数据库、eICU协作研究数据库和解放军总医院重症数据库中生成三个MODSE患者数据集。随机抽取80%作为训练集,剩余20%为测试集,将122个特征作为模型参数,采用集成机器学习模型:SVM(支持向量机模型),KNN(K近邻模型),RF(random forest随机森林模型),XGboost模型于训练集中建立预测模型,在测试集中用受试者工作特征曲线(ROC)评估模型对MODSE患者死亡风险的预测价值,并与临床现有模型如SOFA、APACHE-Ⅲ、MODS、SAPS等评分的性能进行对比;最后将性能最好的模型于三个数据库中进行交叉验证。结果:1)与存活组比较,死亡组患者GCS均值、年龄均值、心率最大值等升高,BMI、收缩压最小值等下降,差异均存在统计学意义(P<0.01)。XGBoost算法特征排名前10的指标为:呼吸频率、APTT、年龄、体温、BMI、收缩压、血小板、血糖、休克指数、白细胞计数;2)XGboost模型预测MODSE患者死亡的性能最好,AUC为0.853,敏感性为0.826,特异性为0.729,准确率为0.874,较其他机器学习模型及传统临床评分优异。交叉验证对比中,MIMIC-Ⅲ数据库构建的模型在解放军总医院重症数据库中验证效果最好,AUC为0.882。结论:与传统的评分相比,集成机器学习模型的预测性能更加优越,具有更强的普适性。"
664,网页篡改检测系统设计与实现,"在互联网时代,信息高速流通。网站成为获取资源的重要平台,同时网站上的信息搜索更成为人们主要的信息获取方式之一。随着我国逐步深化“互联网+政务服务”,政务网站已成为政府与民众交互、提供服务、宣传国家方针政策、展现国家民主政治的重要窗口。然而,大多数政务网站,尤其是县市级及以下行政单位的门户网站,都缺乏本地网页防篡改系统的支撑,随时面临着被恶意攻击和篡改的风险。网站上的网页被篡改,不但会影响到网站的正常运营,造成一定的经济损失,其中含有政治攻击和宗教色彩的篡改,还会对政府形象造成严重损害,降低政府公信力。市面上成熟且功能强大的防篡改产品一般都是针对于企业等大型用户,用于政务网站成本太高。因此,设计和实现一个经济适用性和实用性兼备的专门为政务网站设计的篡改检测系统是有必要的。本文以研究政府网站的网页篡改检测为目标,首先对基于网站本地服务器端和远程客户端的网页篡改检测技术的实现方法以及优劣进行了深入研究和分析,其次结合政府网站的安全现状,重点研究了对于网页结构的异常篡改检测、政府网站公告栏的篡改检测、新增页面的篡改检测和基于机器学习的暗链攻击检测方法,设计和实现了一种基于反向代理的网页篡改检测系统,提高了政府网站网页篡改检测的准确性以及效率,在一定程度上降低了政府网站安全防护的成本。研究工作主要包括以下几个方面:1、通过分析政府网站网页的布局特征和页面变化特征,通过CSS选择器对网页动态更新区域进行定位。并将网页的篡改检测分为结构变化检测、静态区域检测和基于公告列表的内容篡改检测。2、首先实现了网页的整体结构篡改检测,其次针对动态更新的网页公告发布区域,提出了一种准确度较高的篡改检测算法,同时对于公告列表中的新增页面,提出了一种基于Myers’diff算法的层级节点加权算法。3、对于政府网站可能遇到的暗链攻击问题,采用了一种优于传统暗链检测技术的基于机器学习的暗链检测方法,该方法利用国家互联网应急中心的恶意网页分析数据集,通过对暗链相关结构特征、锚文本特征、域名特征和特征扩展来进行特征提取,引入随机森林和XGBoost算法进行分类模型的训练,实现了对被植入暗链的网页进行自动识别和较准确的检测。"
665,基于脑机接口脑电图的人脑想象数字识别,"脑电图,简称EEG,是通过电子仪器,从头皮上将脑部的自发性生物电位加以放大记录而获得的图形,是通过电极记录下来的脑细胞群的自发性、节律性电活动。将电极附着到头皮上,电极从人脑获取数据,可记录大脑皮层的电活动。目前常用的电极定位系统始于1929年,称为“10-20电极定位系统”包括19个记录电极和2个参考电极但在目前一些研究中,使用的电极超过20个。在标准的EEG实验室中,有256个电极连接到人的头部进行记录。为了佩戴EEG,除了基于10-20电极定位系统设置电极外,还应给每个电极提供电解质以降低阻抗水平。阻抗水平的降低对于降低脑电信号的噪声水平是必要的。尽管已经发明干电极不需要任何电解质凝胶,干电极类型的阻抗水平仍然很高。因此,在实际使用中,使用电解质凝胶的湿电极是优选。在本论文中,使用的是Emotiv EPOC+品牌EEG,具有14个电极。每个右半球和左半球的耳后有两个参考点。Emotiv EPOC+系统中的14个电极遵循10-20电极定位系统。基于10-20电极定位系统每个电极位置都被命名的规则,Emotiv EPOC+电极名称分别是 AF3,F7,F3,FC5,T7,P7,01,02,P8,T8,FC6,F4,F8,AF4。以上14个电极分布在整个小脑皮质上。为了佩戴这种EEG,在开始时需每个电极提供电解液。之后,EEG头盔佩戴在实验主体头上,两个参考点连接在主体耳后部。此外,靠近眼睛的两个电极,AF3和AF4应距离受试者的眉毛3指。然后,可以使用TestbenchTM软件进行校准过程。Emotiv EPOC+EEG是一种便携式脑电图品牌,已被用于许多脑计算机界面研究,因此该品牌在我们的研究中被选用。近年来,由于人工智能技术的兴起,,脑机接口相关研究也得到了蓬勃的发展。并且在未来将越来越受到研究者和产业界的重视。因此,选择脑机接口研究领域来推动科学前沿的极限以获得更好的未来是有趣的。但在其传统定义中,脑机接口的主要目标是使残疾人能够像其他正常人一样正常工作。人机交互的这个目标,脑机接口的别名,已被科学家考虑作为推动科学实践的主要动机。早期脑机接口技术已被用于开发基于BCI的轮椅。例如P300系统,其是脑机接口中将大脑信号转换为控制信号的典型示例之一。P300的工作方式是从A到Z的字母以及0到9的数字中挑选出一些在屏幕上不断变换显示,实验对象被要求通过EEG系统将视觉响应在毫秒级内实时转换为控制信号。要求受试者将他/她的注意力集中在某个字母或数字上。然后,系统可以识别受试者关注的字母或数字。系统的分析在几毫秒内完成。在300毫秒内,与其他毫秒级的时域相比,该系统的电势是最高的。研究发现它是由于来自某个字母或数字的屏幕闪烁的刺激响应而发生的。外,运动假象系统运动假象系统也是BCI技术应用的一个典型范例。与P300系统不同,其专注于帮助失去肢体的残疾人。对于运动假想系统,实际上电极不仅附着在头皮上,而且还附着在身体的其他部位上;特别是在失去的四肢附近。从两个著名的脑机接口系统的实际使用效果来看,其具有很大的改进提升空间。众所周知,计算机系统中使用的是二进制,通过0和1,可以对所有的文字、声音、图像等。因此,我们着重研究基于脑电信号的人脑想象数字分类识别问题。虽然类似的问题在过去得到了一些研究,但是准确率不足是其最大的问题。本文中,尝试基于机器学习和深度学习的新方法来突破脑机接口研究的局限性。旨在提高数字想象分类的百分比准确度,使得其在未来实际可用于控制信号和许多其他应用。本文着重于创建一个基于二进制数字想象分类的脑机接口系统。首先在纸上打印出标准的0和1的形状,让实验对象记忆,然后要求实验对象对以标准形式给出的数字在大脑中进行想象,通过计算机对电脑信号进行识别。论文实验分为两部分进行比较,采用传统的机器学习分类算法和深度学习算法进行比较。在传统的机器学习算法中,使用来自单个实验对象的数据,每个数字需要记录一百次。每次记录一个数字的时间为30秒,然后休息20秒再继续进行下一个数字的记录,依此类推。对数字0重复记录一百次;然后对数字1在记录一百次。最后对记录的信号进行处理及分类。一开始,每个数字的一百次试验被连接起来。然后,从每次试验的30秒记录时间中的10秒中间跨度中及时取出所挑选的数据。选定的中间跨度从起点10秒开始,直到20秒时结束。从理论上讲,基于小脑皮质记录的脑电波可分为几种波形:δ,θ,α,β和γ波形。基于所记录的受试者的刺激或活动,每种波形均具有某种特别的含义。已知具有最低频率范围(约04Hz)的δ波在受试者处于深度和无梦睡眠的情况下具有高振幅。当受试者处于深度放松和困倦的状态时,θ波,范围从4到8Hz,具有高振幅。对于某些情况,自主活动还可以触发该波型的高振幅。当受试者处于清醒状态且使用较少的注意力时,最佳已知具有8至12Hz的α波具有高振幅。当受试者处于放松状态时,α波也与病症相关。β波,范围从12到30Hz,在人类活动中起主要作用。每当受试者在进行需要高认知水平的特定任务时,该波型具有高振幅。例如当实验对象求解数字问题时,β波具有明显的波动。最后,对于γ波,其频率范围从30到70Hz,其特性仍不明确。目前的结论是当受试者处于完全清醒意识并进入冥想状态时,Y波可能具有高波动。在我们的研究中,主要使用α波与β波进行二元数字想象分类。主要的工作包括:1.对于传统的机器学习分类方法,选择合适频率范围内的脑电信号对于提高分类准确性至关重要。在之前文献的研究中,一般所选择的频率范围在8到30Hz之间。该频率范围包括α波和β波。因此,在传统机器学习分类的开始,频率应该在α和β频带内进行带通滤波。然后通过对带信号的分析,进一步将频率范围将缩小到能更好满足二进制数字想象分类实验的一定带宽内。带通滤波器后,我们使用了不同的特征提取方法提取信号特征。从而实现更高的分类结果。其中,电极的电极的选择也十分重要(即选择哪个电极的信号来进行分类),不同的电极信号的功率或点位不同,分类准确率不同。此外,选择正确的频率范围也可能影响分类准确性。本中文,对于传统机器学习分类方法,提取的第一种特征是通过事件相关电位分析(ERP)分析选择电极位置。对于二进制数字想象分类,按照上述的电极信号记录方式,对每个电极记录下来的信号中的10秒信号值进行平均。然后,将ERP数据绘制出来从而确定哪个电极位置ERP值的贡献更大。基于传统机器学习电脑信号分类的另一种特征提取方法是功率谱密度(PSD)分析。PSD分析可以对频率进行选择,从而得到更高的分类结果准确率。PSD分析也同时可以用于上述ERP方法对电极选择的正确性检验。频率范围可基于功率谱图进行选择。在该方法中,我们选择最高功率谱对应的频率范围。从而提高分类结果准确率。在PSD分析之后,使用公共空间模式算法(CSP)进行分析。众所周知,在BCI中,CSP可使用两类信号方差值差异最大化。通常被用于数据被分类之前。一般而言,对于每一类信号,CSP构造一个协方差矩阵,然后对协方差矩阵进行特征值分解。从而得到EEG源信号分布向量/空间模式。这些向量即可用于信号的二分类。基于传统的机器学方法,我们使用了不同的习分类器进行分类,包括:线性判别分析(LDA),支持向量机(SVM),Logistic回归和人工神经网络-多层感知器(ANN-MLP)。在没有适合ERP和PSD分析的情况下,最高分类准确率为60%。然而,结合CSP并对算法流程进行改进,我们实验结果的分类准确率提高66.88%。2.上述基于传统机器学习算法的结果并不令人满意,本文进一步引入深度学习架构。首先使用带通滤波器对α(8-13Hz)和β(13-30Hz)波频率范围内的数据进行预处理。根据滤波后的信号绘制ERP topo图并输入到卷积神经网络(CNN)进行特征提取和分类。CNN网络结构包括10层卷积和Maxpoo1ing两个完全连接层,一个drop out层,和一个回归层。我们使用些网络对来自15个不同实验对象的脑电数据进行训练和分类。最高分类结果达到99.65%,该结果表明该方法极大的优于传统方法的分类结果。"
666,基于机器学习的政协提案和相关舆情的分析,"全国政协提案是我国政治制度非常重要的机制之一,每年全国各级政协委员都要提出提案,仅北京市2018年公开的提案就有798件,全国各级政协委员提出的提案总数更多。采用技术手段对政协委员形成的提案进行热点主题发现,并根据这些热点主题进行舆情统计分析,可以挖掘相应的社情民意,为政协委员提供技术信息的参考。目前,关于提案的热点主题发现和采用技术手段对热点主题进行舆情统计的相关研究尚未见到。本文设计了一套政协提案及其相关舆情分析系统,为政协委员提供信息技术支持。本文主要工作包括以下几个方面:(1)对政协提案划分主题并提取关键词。编写网络爬虫程序,从政协提案网站采集了提案数据;根据政协提案的结构特点对提案进行向量化表示,使用K-means聚类算法对提案进行聚类,每一类表示一个主题;设计了两种关键词提取算法从每个主题中分别提取出三个关键词,分别简称“长词”和“短词”,并设计对比实验分析了两组关键词的有效性,结果表明“长词”比“短词”更能反映主题内容。(2)设计、训练情感分类模型并预测所有未标注数据的标签。开发爬虫程序,采集了每个“长词”的微博舆情数据并保存为结构化文本格式;设计了基于双向LSTM的情感分类模型,训练模型,在测试集上达到了 90.45%的准确率,远远高于基于传统机器学习算法的情感分类模型在该数据集上的测试准确率。(3)对政协提案的相关舆情进行统计并可视化。在上述工作的基础上,对获取的微博舆情数据进行了统计:从关注度演进趋势和关注度大小、情感演进趋势和情感倾向等角度对每个主题的相关舆情进行了统计分析。"
667,基于人脸检测和识别的学生考勤系统研究,"随着信息时代的发展,机器学习得到了广泛研究,其中以深度学习算法和卷积神经网络(简称CNN)为基础的人脸检测和识别技术得到了快速发展。传统的人脸检测和识别算法在提取人脸特征向量时,易受到外界环境和其它变化因素的影响,以致不能更好地获取人脸信息,完成人脸的匹配和识别。现有的人脸检测和识别算法中,针对于人脸检测中光照强度、姿态旋转及部分遮挡等变化因素的研究相对较少,以至于在上述变化因素出现时,实时人脸检测和识别的准确性会被降低。因此,在考虑变化因素的前提下,如何有效地提升人脸检测能力和提高人脸识别的准确性,是一项重大的研究课题。本文在卷积神经网络模型的基础上,首先,针对于人脸姿态旋转、光照强度及部分遮挡等变化因素的影响,提出了多级联CNN模型用于人脸检测,设计了改进的CNN模型并进行了训练,与Facenet模型的训练结果进行了比较,进而选择效果较优的网络模型用于设计人脸识别模块;最后,在所设计的算法基础上,完成了学生考勤系统的设计和测试。本文的主要具体工作如下:1.根据检测过程中存在的变化因素,提出了一种多级联CNN模型。该模型针对于实时画面中的人脸进行检测,通过多组卷积神经网络逐层对图像进行人脸预测。此方法一方面可以减小光照强度、人脸姿态旋转等变化因素对人脸检测准确性的影响,另一方面,通过计算多组卷积神经网络对人脸图像预测结果的平均值作为最终人脸检测结果,能够在很大程度上提升人脸区域检测的正确性;通过与基于Haar特征的AdaBoost方法实际检测效果相比较,结果表明:多级联CNN模型具有更优的实际检测效果。2.在Facenet深度CNN的基础上,本文采用Inception-resnet-V1网络结构,选择Triplet loss三元目标损失函数,使用CASIA-FaceV5人脸图像数据集,进行了Facenet深度CNN模型训练实验。实验发现:Facenet深度CNN模型面对小样本人脸数据库的训练效果不错,能够全部有效地识别出人脸信息。3.基于CNN结构,本文设计了一种改进的CNN模型,通过进一步增加网络层数,调整、优化网络结构,更好地获取人脸信息,提高人脸识别的准确性。为了验证该方法的有效性,本文选择CASIAFaceV5图像数据集,对改进的CNN模型进行训练,实验结果表明:该模型在人脸识别准确率上相比于已有算法有了一定的提升,在面对样本规模不大的人脸数据库时,具有较好的应用效果。4.在以上所设计的算法基础上,结合摄像头和MySQL数据库,完成了学生考勤系统的设计和测试。采用MySQL数据库保存图片信息,包含学号、姓名、性别、专业和人脸特征等。实验结果表明:基于人脸检测和识别的学生考勤系统具有较好的实时性和可行性。"
668,基于移动感知网络和ANN识别施工人员跌落险兆事故的研究,"跌落事故(绊倒、滑倒和高空坠落)是造成建筑业伤亡事故的首要原因,与身体失去平衡和姿态的不稳定有密切关系,被认定为失稳导致的安全事故。为降低施工现场跌落事故发生的可能性,本文拟通过技术迭代支撑和管理手段升级,提升建筑施工现场的安全管理水平。在技术迭代支撑层面,以智能手机作为数据采集工具和群智感知基本单元,结合人工神经网络算法(ANN),验证其在涉及施工安全管理中需要主观判断、识别和人为处理问题上的替代表现;在管理手段升级层面,由于跌落事故可视为跌落险兆事故的进一步演化,对各种环境条件下发生的跌落险兆事故进行探究,将为深入认知和主动预防跌落事故提供崭新视角。在训练实验环节,由平衡板人为地创建和设立失稳环境,模拟跌落险兆事故的发生,为ANN的训练提供了数量充足、质量可信的样本。由于平衡板所模拟的跌落险兆事故是静态的,为提升与真实场景下发生的动态跌落险兆事故间的契合度,构建静、动态跌落险兆转换模型。数据分析表明,补偿后的静、动态跌落险兆间数据流特征值的平均差值控制在13%以内,拟合的效果较好;在检验实验环节,构建基于TP、FP与FN的评价体系,从准确率和错报率两个方面对ANN的识别效果进行评价。实验结果表明,ANN识别跌落险兆事故的平均精确率达90.02%、平均召回率达90.93%;平均错报率为16.26%,验证了ANN识别跌落险兆事故的应用潜力;在测试实验环节,绘制跌落险兆事故次数―时间散点图,获取阈值_(20%)和_(10%),以1分钟为时间窗口对上述阈值进行放大,得到_(20%)′为4.62、_(10%)′为3.64。以定量的方式描述跌落险兆事故与跌落事故间的相关性,并从概率角度解释其应用意义;进一步地,构建基于智能手机的移动群智感知网络,完成单一施工人员拓展至5人施工班组小群体的初步探索,探究建筑工人作为感知数据“生产者”、施工管理人员作为感知数据“消费者”的群智施工安全管理模式,利于识别和及时消除施工现场导致跌落事故的潜在危险因素,为及时、高效地掌控施工现场安全态势提供新的解决思路。"
669,随机森林算法在城市空气质量评价中的应用研究,"随着社会经济的快速发展,工业化程度越来越高,城市人口数量迅速增加,空气污染日益严重。如何加强空气污染防治,及时有效的防止严重污染事件发生,是我们越来越关心的问题。为防止城市空气污染事件的发生,保证城市空气质量,我们必须对空气质量进行准确合理的评估。并对于突发事件及时提出有效的防治措施,尽可能的给居民保障一个健康的生活环境。科学有效的空气质量评价方法在确保城市空气质量方面发挥着非常重要的作用。然而,我国的空气质量评价方法目前使用较多的还是传统的空气质量评价方法,而传统的空气质量评价方法一般是从单个污染因子进行考虑,运用固定的公式计算得到的,并且掺和了很多主观因素。而随着大数据和人工智能方法的进步,面对海量的数据,传统方法已经很难满足数据处理效率的。机器学习是一种实现人工智能的方法,如何更好的利用大数据和人工智能来进行空气质量评价,已经成为目前学者专家们的研究热点。随机森林算法是目前一种较好的机器学习评价算法,具有预测准确率高、处理效率快,泛化能力强,不容易过拟合等优点使其在被很多学者专家们运用在很多领域,包括图像分类、故障诊断、交通流预测等领域。本文建立以城市空气质量为背景的空气质量评价模型,先是对评价因子进行选择,对评价标准和现有的空气质量评价方法进行大量的研究。其次,从随机森林算法的的原理和理论知识入手,介绍了算法构建过程并对其优化方法进行了研究,为之后的空气质量评价模型的建立做好铺垫。接下来,选取2014-2016年中我国113个重点环保城市的空气质量数据作为原始数据,通过数据的预处理与数据集划分后,建立基于随机森林的空气质量评价模型,同时通过对模型建立过程中的不平衡数据处理和参数调整两个方面进一步优化模型,并使用准确率和AUC值来评估模型的模型效果;最后,将随机森林算法与人工神经网络和支持向量机进行比较,分别计算它们的准确率和AUC值。实验结果表明随机森林算法的评价效果最好,可以准确有效的对城市的空气质量进行评价,同时通过袋外数据对空气质量评价因子的重要性进行排序,为今后的大气污染防治提供建议。"
670,基于机器学习的抗癌药物反应预测研究,"肿瘤已经成为威胁人类生命健康和生活质量的重要疾病,如何为肿瘤患者选择最佳治疗药物是医疗卫生和生物信息学研究领域的前沿课题之一。目前,确定患者是否会对抗肿瘤药物产生反应通常需要花费数月的时间,中间要经历反复的试验,还伴随着随时出现误用的可能性。研发有效的抗癌药物反应预测方法已经成为肿瘤学研究的重要课题。药物敏感性建模的准确性高度依赖于数据类型、特征选择、模型选择和模型验证等相关因素。本文从这些角度出发,提出了一种基于机器学习的抗癌药物反应预测方法,它集成了机器学习和统计学习几种常用的计算工具,使用基于细胞系数据的模型预测肿瘤药物反应情况。本文的数据来源于英国惠康桑格研究院发布的癌症体细胞突变目录数据库和肿瘤药物敏感性基因组学数据库,共包含上千株细胞系在药物干预前的基因突变、拷贝数畸变、基因表达三大组学特征以及这些细胞系对196种抗肿瘤药物的响应数据。模型主要由特征提取模块和分类预测模块两部分构成。特征提取模块的作用是将输入的高维基因组特征降维,首先应用关联规则挖掘算法为每一种抗肿瘤药物的敏感状态和耐药状态挑选出相关性强的基因状态数据,保留细胞系中这些基因的状态构成初始特征向量,并对初始特征向量进行累积池化处理,在进一步降低特征维度的同时增加模型的鲁棒性。分类预测模块的结构为三层前向型神经网络,因为每种药物-状态对的特征向量长度不同,所以为每种药物和每种状态构建一个分类器,共计构建了392个预测分类器。考虑到临床实践的时间效率问题,本文还提出了另外一种分类预测模块设计方案,它将K-means聚类算法和径向基函数应用在极速学习机网络中,预测细胞系样本对药物的敏感性和耐药性。本文使用R语言实现了关联规则挖掘算法,使用Python语言以及Keras框架实现了整个预测模型。实验结果表明,在196种抗肿瘤药物中,模型在测试集中的平均AUC值为0.810,平均预测准确率为0.776,高于使用相似方法和数据集的其他论文以及目前资深医生的诊断水平。基于改进的极速学习机网络的药物反应预测性能优于几种常见的机器学习算法,训练和验证速度快。本文还设计和开发了抗癌药物反应预测系统。上述结果表明本文提出的模型可以有效捕捉患者的基因组特征,同时生成准确的药物反应预测结果,有望在个体化医疗中发挥作用。"
671,基于机器学习的高速光信号调制格式识别与OSNR监测,"下一代智能光网络能够根据动态信道状况、系统资源和用户业务需求自适应地调整信号速率、调制格式、波长等参数以实现系统资源的最大化利用。因此,系统参数的监控与识别是未来智能光网络的核心技术之一。其中,光信噪比监控技术可以实时地获取传输信号的质量并为信号检测提供依据。调制格式识别技术可以自动识别接收信号的调制格式,为相干接收机中调制格式相关数字信号处理算法(Digital Signal Processing,DSP)提供信息以自动配置接收机中的DSP算法,从而获得最佳接收性能。论文研究了两种调制格式识别的方案和一种OSNR监测的方案。主要工作如下:1、研究了一种基于信号幅度方差和4次方功率谱密度的调制格式识别方案。首先,根据信号幅度方差实现偏振复用(Polarization Division Multiplexing,PDM)相移键控(Phase-shift Keying Modulation,PSK)和正交振幅调制(Quadrature Amplitude Modulation,QAM)信号大类的区分。然后,分别把PDM-mPSK信号和PDM-mQAM信号4次方功率谱密度的均值和峰值投影到2维平面,并利用逻辑回归算法实现PDM-mQAM或PDM-mPSK子类的识别。搭建了仿真和实验系统,实现了PDM-QPSK/-8PSK/-16QAM/-32QAM四种常用调制格式的识别。结果表明,该方法可以在信号OSNR值远低于其7%FEC阈值的情况下实现调制格式的100%识别,且该方法对激光器线宽和光纤非线性的影响具有一定的容忍度。2、研究了一种基于4次方和8次方功率谱密度的调制格式识别方案。首先,把信号4次方和8次方功率谱密度峰值投影到2维平面,用支持向量机(Support Vector Machine,SVM)实现调制格式识别。对于无法区分的PDM-16QAM和PDM-64QAM,可根据幅度区分之后的4次方功率谱密度均值进一步区分。搭建了仿真和实验系统,实现了PDM-QPSK/-8PSK/-16PSK/-8QAM/-16QAM/-32QAM/-64QAM的识别。结果表明,该方法可以在信号OSNR值低于其7%FEC阈值情况下实现100%的识别率。3、研究了一种基于信号功率非线性变换结合深度神经网络(Deep Neural Networks,DNN)实现OSNR监测的方法。通过对信号幅度,信号2次方、4次方和8次方功率谱密度获取信号与OSNR相关特征量,并利用DNN提取相关特征量以实现OSNR监测。仿真结果表明,针对28Gbaud PDM-QPSK/-8PSK/-8QAM/-16QAM信号相干光通信系统对应的背靠背OSNR监测平均标准差分别为0.1dB、0.09dB、0.26dB和0.46dB。这四种调制格式在入纤功率分别为4dBm、4dBm、3dBm和3dBm,传输距离分别为2000km、1040km、1040km和800km的单模光纤时获得的OSNR监测平均标准差分别为0.43dB、0.34dB、0.66dB和0.79dB。"
672,基于LSTM网络的政策挖掘研究与应用,"随着大数据、云计算、人工智能等新一代信息技术的快速发展和政府信息化水平的提升,政府的治理范畴、内容和手段也受到了不可忽视的影响,近年来政府大数据也逐渐成为政务管理者和研究者关注的焦点。通过对海量政策文本的挖掘,在定性研究的基础上,借助信息技术等计量化手段对政策文本进行科学化的分析,找出政策文本的个性与共性规律,辅助政策研究者更好地进行量化研究,并为政策挖掘研究提供理论与技术支撑。同时,政策文本大数据挖掘会对政府治理产生深刻变革和影响,利用政务大数据提升政府决策水平和治理能力,对政府管理创新乃至智慧决策来说是一场新的机遇和挑战。本文首先对政策挖掘的现状和相关文献进行分析,结合实践及相关理论与技术提出采用深度学习中LSTM网络模型对政策文本进行挖掘研究,并对LSTM算法模型进行改进,提出了 SimHash-LSTM算法,提高了政策挖掘中文本分类的精度。本研究借助网络爬虫技术从互联网上获取中央及各个地方的百万份政策文本,并对文本进行清洗处理,构建了一个相对全面的政策文本数据库,进而基于改进的LSTM神经网络模型,实现对政策文本的分类、政策扩散等深入挖掘,并提供了智慧城市领域的政策文本分类以及政策扩散算例分析,验证了模型的有效性。在本文的最后通过面向对象编程的思维构建了基于深度学习的政策挖掘平台,提供从数据获取、数据清洗、文本分词、文本表示到文本摘要、文本分类、相似度计算、主题模型等整个挖掘过程的可视化展示。通过Django、Bootstrap框架,结合NGINX代理、MySQL数据库等实现了页面的展示与交互,使得政策挖掘平台可以得到更进一步的推广应用。"
673,基于深度学习的评论文本情感分析,"当前文本表示模型较难捕获评论文本中结构词或短语的意义。同时深度情感分析模型忽略评论文本的层次结构,而直接将整个评论视为一个超长句子处理,且无法以可视化的方式评估其对情感词或句子的辨别能力。在许多现实场景中经常因数据集规模较小而不能满足深度神经网络模型训练的要求。同时现有深度情感分析模型一般都是单任务模型,未能有效利用不同任务间可共享的特征信息。为解决上述问题,首先设计一种能将评论文本结构信息引入深度情感分析模型的标志识别策略(Mark Recognition Strategy,MRS),并基于MRS提出一种分层标志模型(Hierarchical Mark Neural Model,HMN),该模型采用“词-句子-评论”的层次结构,使其不仅能够区分词的情感程度,还能辨别句子对整个评论情感的贡献程度。再通过引入词与句子级别的标志信息帮助模型处理带有复杂结构的评论文本,并能用可视化的方式评估模型HMN对情感词与句子的辨识能力。接着又提出一种基于模型HMN的迁移学习方法HMN-TF,该方法适用于模型HMN在小评论数据集上进行情感分析的场景,并针对模型的层次结构提出4种迁移参数微调(Fine-tuning)的策略。考虑到评论情感分析包括情感分类和观点摘要抽取等任务,为此提出一种基于HMN的多任务模型HMN-MT,该模型以训练并完成情感分类与观点摘要抽取任务的方式来提升表现。为评估MRS、HMN、HMN-TF和HMN-MT的有效性,在Amazon in Singapore、Test Freaks和Amazon Fine Food评论数据集上开展实验,并与评论文本情感分析的前沿模型在Accuracy与F1Score等指标上进行比较,其中模型HMN与最佳对比模型相比提升约1.6%,MRS最高可将深度神经网络模型的表现提升6.7%,HMN-TF在小评论数据集上Test Freaks的效果提升1.7%,模型HMN-MT的表现与前沿模型相比也有略微提升。"
674,基于机器学习的机械臂运动规划研究,"基于机器学习的机械臂运动规划研究是基于智能抹灰机器人项目开展的,其研究目的是为了构建智能抹灰机器人在阳角、门、窗等工况环境下的机械臂作业系统。本文采用双目视觉与机器学习等技术设计了一种作业系统,并分别对双目视觉、机器学习和多自由度机械臂等学科的相关算法进行了研究和改进,完成了作业系统的开发。本文的主要研究内容如下:1、本文对双目视觉三维重建中的关键技术进行了研究,设计了一种分层匹配的双目视觉系统。本文经过对多种特征点检测算法的对比测试,选定了SURF算法进行图像特征点的提取与描述,并根据双目视觉的匹配环境特点,采用分治策略对快速近似最邻近匹配算法FLANN进行改进,提高了匹配效率,最后,使用三角剖分和纹理贴图的方式进行立体显示。2、本文对神经网络的相关理论进行了研究,并结合双目视觉设计了一种用于机械臂姿态估计的网络模型。本文根据相机的图像采集姿态与三维重建后的点云坐标之间存在的某种对应关系,规划了神经网络训练样本的采集与处理方式,并使用标定后的样本数据训练了一个用于估计相机姿态的网络模型。3、本文对多自由度机械臂的运动学控制技术进行了研究,设计了一种六自由度机械臂运动学控制模型。本文以丹麦的六自由度机械臂UR10为仿真目标,构建了它的D-H参数表,并采用解析法推导出了机械臂模型的正逆运动学控制方程,完成了模型的底层控制。在关节空间和笛卡尔空间中本文采用五次多项式插值算法推导出了轨迹规划控制方程,并对机械臂模型进行了轨迹规划仿真实验。4、为了验证前文的研究成果,本文将其集成在智能抹灰机器人平台上,对机器人软硬件构成和设计进行了规划,完善了相关作业流程和软件开发,并在实际工况环境下进行了测试,证明了前文研究的意义和价值。"
675,基于机器学习的P2P网贷平台违约风险预测实证研究,"P2P网络借贷作为一种新型的金融服务业模式,在解决小微企业融资及个人贷款等方面比传统银行更加高效与便捷。它省去了线下私人贷款和银行贷款的一系列繁琐程序,直接提供线上交易,使用户极大地享受了虚拟世界带来的便利。这种新型的网络借贷模式受到了广泛欢迎。但是,近年来,网贷的风险已经不断积累,一系列风险事件纷纷爆发,导致大量的平台破产倒闭。这不仅严重损害了投资者的合法权益,同时也极大地危害了金融行业的安全和社会的稳定。对此,网贷平台部门也出台了相应的政策来引导行业的合规发展。而对于平台自身而言,也应该做好风险管理及预警工作。由于我国P2P网贷平台蕴藏着许多借贷违约风险,准确预测违约风险并采取相应的处理措施是当前P2P网贷平台当务之急。本文主要使用多个机器学习方法构建模型对P2P网贷用户违约率进行研究,通过对比选择出其中最适合做该行业的用户借贷违约率的风险识别模型,帮助平台提前辨别出风险隐患大的借贷者,保障平台自身及用户的利益。本文是在以往研究的基础上选取lending club网贷平台公开提供的2016年至2017年第一季度用户借贷交易原始数据,在对数据进行分析处理的基础上,分别使用Logistic回归模型、蝙蝠优化算法的前馈神经网络(BABP神经网络)以及最小二乘支持向量机(LSSVM)三种机器学习的方法对P2P网贷平台借贷用户违约风险经行了实证研究。本文的重点就是对三种模型的构建,然后分别基于这三种方法将它们应用于违约风险预测的实验中,最后通过比较三种模型计算出来的结果,评估三种方法在预测P2P网贷平台违约风险的适用性。各个模型得出的实验结果显示,最小二乘支持向量机的预测效果更加优越,更适合作为网贷平台的用户借贷违约风险识别模式。其中Logistic回归模型通过SPSS统计软件中二元Logistic回归分析完成,BP网络和LSSVM通过MATLAB编写相应的模型代码实现。"
676,基于语言处理模型的蛋白结构分类的实验分析,"通过计算机手段对蛋白质进行空间结构的研究,可以作为实验手段的有效补充,应用于蛋白质空间结构的预测、设计和比对当中。该领域的研究已经成为蛋白质工程的一项重要内容。蛋白质的空间结构是以不同种类氨基酸的排列顺序为基础的,不同氨基酸在肽键、氢键、范德华力以及静电作用等因素的影响下形成复杂的空间结构,但存在一定规律。因此,研究氨基酸序列与蛋白质空间结构的对应关系称为结构生物学中至关重要的内容。本文将语言处理的思想用于研究蛋白结构分类的研究中,将蛋白质结构中的不同氨基酸序列视为一种自然语言。在以前的研究中主要使用生成式模型进行从氨基酸序列到蛋白空间结构的预测,本文选用判别式模型展开研究,这在以前是没有被提出过的。本文选择了UniProt蛋白质库作为蛋白质分子序列的实验数据集,根据PDB数据集中的蛋白质的结构信息进行数据集标注,最终数据集包含2985181个蛋白质分子序列,每个分子序列包含50个氨基酸。本文在单词向量化方法上选取skip-gram和FastText中文本分类两种方法,分词量分别选取了6和9,单词向量维数分别选取了5和50,通过非线性的LSTM和线性的FastText两种模型进行分类,使用了测试集和拓展测试集进行测试,在以上5组变量基础上进行了10组对比实验,获得了20个实验结果。最终得到使用FastText中的文本分类按照分词量为6、维数为5对训练集进行单词向量化,再使用LSTM模型进行分类的合适方法。该方法在两种不同的测试集进行测试最高预测准确率分别可以达到68.61%和80.89%"
677,一种适合建筑景观格局生成的网络,"在对建筑景观格局的特征研究中,传统的研究方法主要集中在对建筑物的外形轮廓等信息进行获取,缺乏对隐含特征的提取和创造出拥有获取特征的建筑景观格局,其本质上是有监督的分类,只能利用提取出的特征对建筑的种类进行判定而不能利用这些特征进行整合并重绘。即使特征提取算法中的建筑重构相关研究仍需要人为提供建筑参数,面对大量不同的建筑物时便无法适应。由于缺乏对建筑群共同特征的提取与重构的方法,传统的建筑特征提取在一些关注景观空间分布形态如建筑格局对热环境影响的研究中,只能局限于有限的明显特征指标。对需要挖掘建筑隐含特征的研究诸如建筑景观构型与热岛效应的关联等尚无定论,更缺乏如何优化以达到最科学合理的建筑景观格局等研究结论。作为无监督学习的生成对抗网络有望利用AI手段提取出建筑景观格局中大量的隐含特征,实现传统方法无法实现的建筑景观格局生成。本文在生成对抗网络基础上,针对建筑景观格局的特点提出了一种新的生成对抗网络模型来更好实现建筑景观格局的生成。研究工作如下:1.分析生成对抗网络在建筑景观格局生成过程中存在的问题和原因,创新提出了一种新的网络模型来改善问题并验证了新型模型的优越性。2.针对建筑特征提取中存在的不足,在新型模型的基础上进一步创新提出了建筑格局特征分区、分割训练的改良方法,使得模型训练更加迅速且生成了更富有创造性的建筑景观格局。3.进行了新型模型在多种数据集上的实验来评估此模型的通用性。通过对机器学习领域经典数据集进行训练,依然得出了优秀的生成结果,验证了本文模型具有良好的通用性。4.进行实际应用,通过进一步对更复杂的建筑景观格局特征提取和重构,获得了目前尚未得到分类的优秀建筑景观格局。进一步证实了该模型对建筑特征提取重构的优越性,使优化建筑景观格局对环境等方面影响的研究成为了可能,值得继续研究。"
678,网络群体性事件的认知及治理,"近年来,随着我国进入社会转型期,以往片面追求速度的粗放型发展所积累的生态、经济、社会、文化矛盾开始喷涌,而当前的制度框架却无法对之进行有效的回应及处置。与之相对的是,正是由于缺乏完善的制度供给,人民群众日益增长的需求无法得到充分的表达及实现,使得制度外方案成为重要选项,甚至呈现出高频化趋势。信息时代,移动互联网及社交媒体平台日渐发展壮大,为公民的诉求表达及动员提供了廉价且高效的制度外实现路径。在某些特定利益及诉求的驱使下,网民制造观点,传播舆论,推动网络舆情在某些中心议题上集聚形成网络群体性事件,利用互联网兼具的放大镜及聚焦镜功能,引爆外部环境压力场,推动自身利益诉求的实现。一个无法回避的现实是,当前并未形成成熟有效的网络群体性事件干预策略。一方面,社会化治理局面尚未形成,网络群体性事件治理的主要职责与任务仍落在政府一边,社会层面的治理动力并为得到充分认可及调动。另一方面,政府应对仍以“维稳”、“管控”为主,疏导成效堪忧,且时常引发行为合法性争议,往往加深网络群体性事件消极化程度。本文认为,可以聚焦网络群体性事件舆情的两大维度:传播性、内容性,从中窥探参与群体的利益及诉求,并在此基础上构建制度化框架以及相应的治理策略。因此,研究通过案例深挖,采用基于计算机自然语言处理的内容分析法,以新浪微博作为数据源,深入挖掘“寿光洪水”网络群体性事件的微博舆情意涵,把握事件舆情的传播结构及规律,梳理网络议题、网民情感的分布及变迁,在探析网民言论所反映的期望、诉求基础上,构建了网络群体性事件善治的可能性策略。本文发现,网络群体性事件往往呈现出不同人群的利益诉求汇集,主要包括:当事人寻求制度外渠道的关注、援助;围观者认知、评议公共事件;意见领袖趁势营造网络影响力;普通网民蹭热点实现社交价值等。应当构建与之匹配的治理机制及策略,如:完善利益表达机制;传播过程中权威声音归位;提高舆情过程化监控能力;建立意见领袖等社会治理力量动员机制;依靠正能量话题引领,构建匹配受众需求的议题方向等。"
679,基于深度学习的文本情绪分析研究,"本文从自然语言处理的宏观角度介绍文本分析的相关技术步骤与理论基础的全面解析中探讨寻找出一种基于自注意力机制的双向双层长短期记忆算法,理论上可以有效学习文本情绪分析对于样本数据集和标签集向前、向后的时序处理依赖和对于样本数据集内部的远程依赖。并使用Tensorflow的GPU版本对此算法在IMDB情绪分析数据集上的表现进行实验分析。本文先介绍了从非结构化文本到结构化文本的词向量化原理和流程,分析词嵌入的相关理论基础、技术基础,并介绍浅层分析算法的主要分类和原理。阐述了分类算法、回归算法和聚类算法的典型算法思想,基于浅层学习中的经典线性模式和线性回归模式原理及思想,阐述了多层神经网络的一般结构和处理层次以及误差逆向传播算法的详细过程。再基于此提出了自注意力机制的双向长短期记忆算法框架,然后从双向长短期记忆算法的演变和迭代步骤方面剖析长短期记忆算法对于文本情绪分析任务学习序列问题的有效性,从误差逆传播算法了解到双向长短期记忆算法在反向传播过程中存在的远程依赖问题,并提出自注意力模型可以帮助解决此问题从而回答了为何要针对文本分析任务提出此算法框架的原因。最后,本文基于此种算法框架使用Keras深度学习开源库和Tensorflow开源库进行实验平台的搭建,在给定其他因子不变的条件下,电影评论数据集IMDB上取得了比单纯的自注意力机制模型、单向长短期记忆、双向长短期记忆模型更为良好的效果。并延展了其他因子对此算法的性能影响。"
680,基于机器学习和机器视觉的点胶机自动定位系统,"随着电子产品的发展,各厂家把产品设计得更薄更轻,使得封装工艺要求变得更高。传统的点胶机存在精度差、效率低等一系列的问题,故本文在传统点胶机的基础上加入了机器视觉技术和机器学习的方法,使得点胶机具有更高的精度和效率,从而满足现代制造业的需求。本文主要介绍了机器视觉点胶机系统的组成。机器视觉点胶机系统分为硬件部分和软件部分。硬件部分包括光源、相机、镜头以及运动控制器,本文分析了它们在机器视觉系统中的作用,性能参数和如何选型。软件部分包括图像预处理、相机标定以及目标检测。图像预处理首先将三通道彩色图像进行灰度化转化成单通道灰度图像以减少数据量提高计算效率,然后进行图像滤波抑制噪声。本文通过典型的针孔摄像机模型分析了4大坐标系的转换关系,在实际成像过程中还考虑了镜头畸变的影响,使用OpenCV视觉图像处理库中的函数进行图像校正,并根据机器视觉点胶机的实际情况选取了合适的标定方法。之后,根据机器视觉点胶机的实际情况,本文采用了两种目标定位方法:(1)在MB-LBP级联分类器的基础上额外再串联两个分类器,基于SIFT特征和SURF特征的分类器,构成一个新的级联分类器以满足机器视觉点胶机的目标检测和定位的要求。(2)使用HOG和SVM进行目标检测定位,由于HOG特征维数较大,先使用PCA对HOG特征进行降维,然后使用SVM对降维之后的特征进行分类和定位。两种方法得到了类似的查准率并成功运用在视觉点胶机中。"
681,基于梯度提升算法的直线振动筛分机理与参数优化的研究,"振动筛作为散体物料分选设备被广泛应用在工业生产的各个场景当中。提高筛分效率与处理量一直是振动筛领域研究人员的奋斗方向。但在不增大筛机整体尺寸和结构强度的前提下,筛分效率与处理量往往是相悖的两个性能指标,即单方面提高筛分效率往往会使筛分过程变得缓慢,从而导致处理量下降。为此国内外学者对振动筛的筛分机理进行详细的研究,试图探索出新的筛分性能优化方式。本文中定义了6个描述筛分中间状态筛面上颗粒分布的特征量(分层指数均值、小颗粒触筛均值、小颗粒触筛方差、小颗粒透筛均值、大颗粒透筛均值、筛分时长),较为完整地分析筛分中间状态对筛分结果的影响规律,利用数值模拟技术对直线振动筛的筛分过程进行仿真,利用梯度提升决策树算法对所得仿真数据进行建模分析。主要研究内容有:(1)在较大范围内进行筛机参数选取,并以此进行仿真实验。为后续的筛分中间状态特征量以及单位时间筛分效率的计算奠定数据基础;(2)观察筛分过程,定义筛分中间状态特征量,分析各个特征量对单位时间筛分效率的影响规律;(3)使用梯度提升决策树算法对筛分中间状态特征量与单位时间筛分效率建模,分析各个特征量的影响权重排序,以及联合影响规律;(4)使用梯度提升决策树算法对筛机参数与各个筛分中间状态特征量建模,分析筛机参数对各个筛分中间状态特征量的影响规律;(5)使用粒子群算法对所得的筛机综合数据模型进行筛机参数寻优,对所得的筛机参数组合分别进行仿真实验与实物实验,验证模型的准确性、稳定性以及有效性。最后分析验证实验组的数据,筛机数据模型预测筛分性能较优的筛机参数在较大范围内变动,而各组的筛分中间状态特征量仅在小范围内变动,且最终的单位时间筛分效率值相近,说明最优筛机参数组合并不唯一,并且多种筛机参数组合可得到相似的筛分中间状态与相近的筛分结果。"
682,基于网络流水印的Tor匿名通讯追踪研究,"如今互联网己经成为人们日常生活中不可分割的一部分,但个人信息泄露等安全问题日益严重,个人的隐私被越发关注,不断有用户尝试以匿名的身份访问互联网。Tor作为隐藏流量源的匿名通讯机制,通过重路由技术能够有效地隐藏用户的身份,目前它的用户数目己经超过了 450万人。但是Tor不仅能为普通用户提供着服务,由于其双向匿名机制,同时也为非法交易及其他犯罪行为的平台――暗网,提供了良好的生存环境。由于暗网的负面影响,以及Tor入口流量特征明显易被识别的缺陷,它的使用受到很大限制。Tor网桥为解决此问题应运而生,它可搭载多种混淆协议将Tor的流量伪装得不引人注目。obfs4作为目前使用人数最多的混淆协议,能够干扰针对其原生流量的特殊对待,由此带来的新挑战尚未攻克。本文研究的主要内容是针对搭载obfs4协议网桥的Tor流量进行追踪,围绕这一课题,做了如下几个方面的工作:首先,本文介绍了 Tor的机制,包括其组成、连接过程和网桥等,并详细阐述了 obfs4的工作原理,对Tor的现状进行了分析。此外,对常见的流量分析方法加以总结,包括对流量识别及追踪技术的分类综述。其次,提出了基于样本维度权重的SVM算法,以识别obfs4的Tor流量。针对obfs4现有的16种特征值,进行多种方式的权重组合,以较优的比重,使用改进后的高斯核函数SVM算法进行实验。结果表明,本方法较己有方法在性能上有显著提高,能够较为准确的识别出obfs4的流量。再次,提出一种IPD质心方法,利用K均值聚类算法的聚类特性将已有方法进行改进,使得加入的水印在obfs4网桥三种模式上均能被高效地检测出。实验结果表明,改进后的算法有着更高的检测率和识别率,且应对不同的网络环境有着较强的适应能力。最后,提出了三种使用场景,针对使用Tor双向匿名机制的暗网环境进行流水印方案的合理运用。场景包括用于确认用户与特定服务通讯关系、用于发现特定服务的访问用户以及用于追踪暗网服务的真实身份。并对三种使用场景的优势劣势以及实施难度进行了评估。"
683,基于机器学习的Android恶意软件检测技术研究,"近年来,随着移动互联网的不断发展,移动设备逐渐成为人们生活中的一部分,给人们的生活和工作带来极大的便利。Android操作系统由于其开源性和免费性,吸引了大多数的用户以及第三方开发者,占据了大部分的操作系统市场,但是许多恶意软件也随之而来。多种多样的恶意软件行为带来了很多的安全问题,如窃取用户的隐私以及给用户带来经济上的损失等等,对Android恶意软件的检测研究变得尤为重要。机器学习技术不断成熟,成为了Android恶意软件检测的热门技术,但目前仍存在检测准确率低和误报率高等难题,研究基于机器学习的Android恶意软件检测技术具有重要的理论意义和应用价值。本文的主要研究工作包括:(1)介绍了Android恶意软件检测的研究背景及意义,分析了目前国内外移动设备及手机操作系统的应用情况和Android恶意软件的发展情况,综述了Android恶意软件检测技术的国内外研究现状,归纳总结了Android系统相关的理论和检测恶意软件常用的机器学习算法。(2)针对Xgboost算法中参数以及参数组合的选取不当容易导致检测方法的分类效率下降的问题,研究基于ACO-Xgboost的Android恶意软件检测方法,将蚁群算法(Ant Colony Optimization,ACO)引入到Xgboost参数优化中,利用ACO的适应性以及全局寻优能力,对Xgboost设定的相关参数进行优化,得到最优参数组合,用于Android恶意软件的检测。通过提取Permission、Intent和API三种特征,优化获得最优特征集,设计了与粒子群算法(Particle Swarm Optimization,PSO)和遗传算法(Genetic Algorithm,GA)优化的Xgboost进行对比的实验,并进行了检测准确率和误报率的实验数据分析。(3)针对Android恶意软件检测过程中不相关特征掩盖异常存在的问题,研究基于DBN和Xgboost的Android恶意软件检测方法,引入深度置信网络(Deep Belief Network,DBN)进行特征学习,利用DBN构建恶意软件检测模型的特征学习模块,通过无监督学习进行特征降维,用Xgboost对Android恶意软件进行检测和分类。设计了相关实验,并进行了检测分类的实验数据分析。本文的创新之处包括:(1)提出了一种基于ACO-Xgboost的Android恶意软件检测方法。该方法使用ACO算法优化Xgboost参数,使得Xgboost获得最优参数组合。实验结果表明,该方法的检测准确率比GA-Xgboost和PSO-Xgboost分类方法,分别提高了3%和0.88%,检测误报率也低于其他两种方法。(2)提出了一种基于DBN和Xgboost的Android恶意软件检测方法。该方法利用DBN对Android恶意软件进行特征学习,获得具有良好特征表达的特征集,用于对Android恶意软件的检测和分类。实验结果表明,该方法在分类准确率方面比单独使用Xgboost高0.91%、比DBN高1.66%,也高于SVM和GDBT分类算法,在误报率方面也有良好的检测效果。"
684,基于机器学习的网络入侵检测技术研究与实现,"随着网络应用的普及,网络安全问题也随之而来,网络攻击也朝着多样化,复杂化和分布式的方向发展。入侵检测系统是发现攻击的第二道防线,其可以对网络中事件进行实时监控,是一种主动的防御技术,弥补防火墙的不足。近年来,随着机器学习的发展,使现有入侵检测与处理有了更为有效的机制,面对大规模的网络数据,由于机器学习算法本身的缺陷和不稳定性,目前仍存在检测准确率低和误报率高,并且检测效率低等难题,研究基于机器学习的网络入侵检测技术具有重要的理论意义和应用价值。本文的主要研究工作包括:(1)介绍了网络入侵检测技术的研究背景和研究意义,综述了国内外研究现状,概括了入侵检测和机器学习相关的理论知识,总结了常见的入侵检测技术,分析了入侵检测常用的机器学习算法。(2)针对网络数据存在大量冗余特征导致检测算法效率和准确率降低的问题,研究基于改进的随机森林(Improved Random Forest)特征选择算法和支持向量机(SVM)的入侵检测方法,通过权重投票融合基于OOB数据分类正确性和曲线下面积置换两种特征重要性度量方法,采用序列向后搜索策略,搜索获得了最优特征子集,解决了实验中数据存在冗余问题。设计了在KDD CUP99数据集上的仿真实验,进行了检测效率和检测准确率的实验结果比较和分析。(3)针对现有的入侵检测算法适应性不强以及检测准确率低的问题,研究基于深度学习多分类器集成方法。采用stacking技术对SVM、NB、KNN、DT等四个分类器的集成,解决了权重投票的集成学习技术只能学习分类器之间线性关系的问题,克服了单个分类算法的缺陷。设计了五层神经网络的仿真实验,并进行了实验结果进行了比较和分析。本文的创新之处包括:(1)提出了一种改进的基于IRF-SVM入侵检测方法,通过改进随机森林特征选择算法,使用权重投票技术融合基于OOB数据分类正确性和曲线下面积置换两种特征重要性度量方法,解决网络数据中存在冗余特征的问题。在KDD CUP99数据集上的实验结果表明,该方法对Normal、DOS、Probe、R2L、U2R的检测准确率分别为98.35%、98.72%、97.63%、93.64%、96.85%,比经典的SVM模型的检测准确率有较好的提高。(2)提出了一种基于深度学习多分类器集成的入侵检测方法,该方法通过深度学习算法集成了SVM、NB、KNN、DT四个分类器,增强了检测算法的稳定性。实验结果表明,该方法对Normal、DOS、Probe、R2L、U2R检测准确率分别为99.76%、99.88%、99.42%、98,63%、98.52%,明显高于基于权重投票算法的分类准确率。"
685,自闭症个训课堂的辅助教学工具设计与实现,"联合国组织为了提高民众对自闭症的认识、呼吁更多的专家学者进行自闭症方面的研究,将每年的4月2日定为“世界自闭症关注日”,自闭症患者群体也因此得到了更多的关注。更多的专家学者希望通过信息技术来改善自闭症的诊断和干预。本文通过对自闭症教育康复机构的实地调研,发现自闭症个训课堂仍存在数据结构不统一、未信息化、评价不及时等不足之处。根据上述问题,本文设计与实现了针对于自闭症个训课堂的辅助教学工具。本文工具利用信息化手段为自闭症个训课堂的助教以及家长提供更规范的课堂记录方案,使课堂信息以更结构化的方式留存,便于课后家长和教师回顾整个课堂,并且可以为基于机器学习的自闭症教学评价及内容推荐提供前期的数据收集。本文介绍了基于自闭症背景下的移动应用开发,以及目前常见的教育信息化工具,并且根据项目需求选择了合适的技术路线。技术路线主要是以微信公众平台作为入口,前端采用React框架,React框架具有跨平台、效率高、热更新、成熟度高、扩展性好的特点;后端采用Spring Boot框架,这是当前中小企业最常用的后台技术解决方案,集成综合能力强、成熟度高、搭建便捷;数据库部分使用了MySQL,是应用较多的成熟数据库。接着对于传统的自闭症个训课堂进行描述,根据自闭症教师、助教、家长三种身份进行需求分析。在此基础上,本文对系统进行整体设计,从系统框架到主要的功能模块,并且以流程图的形式对每一个功能模块部分进行详细的设计说明。数据库的设计部分则以E-R图和具体数据表的形式呈现给读者。在完成系统设计之后,根据所选的技术路线完成系统前后端的实现,以UML类图的形式让读者对底层功能模块有更直观的了解,以功能模块的实际页面展现系统开发的主要成果。完成系统实现之后,本文介绍了系统的测试部分,对课堂活动模块、课堂记录模块等重点模块进行功能测试,对高并发量下的用户访问进行性能测试,用户响应时间在2s以内,完成了系统开发的预期目标。最后本文对整个系统的可扩展部分进行说明,展望未来需要完成的工作。"
686,基于概率图模型的储层预测方法研究,"油气储层预测技术是综合应用地震、地质、钻井、测井等各项资料对地下油气储层的分布、厚度、岩性和物理性质进行预测的一项技术。储层预测的主要工作内容大体分为储层岩性预测、储层形态预测,储层物性预测和储层含油气性综合分析,孔隙度作为反映储层油气储量的重要指标,是储层物性预测的一项重要研究内容。目前孔隙度体预测采用地震反演得到的阻抗、密度等信息和测井得到的孔隙度信息进行回归,然后将该关系应用于整个体数据。但是目前该方法在实际应用过程中存在诸多问题,主要体现在:(1)不同储层岩相孔隙度与弹性参数的关系不一样,如果将所有岩性的弹性参数与孔隙度整体建立关联关系可能导致结果存在较大误差;(2)测井数据较少可能导致回归关系泛化能力偏弱,使得结果不理想;(3)从地震数据中获得的弹性参数可能存在误差,导致预测结果误差。为解决以上问题,本论文基于概率图模型中的条件随机场理论,构建了岩相和孔隙度同步预测网络,并在此基础上开展了以下研究工作:(1)通过阻抗与孔隙度的标签对,建立条件随机场和梯度提升树融合的孔隙度-岩相同步预测网络。通过条件随机场实现了孔隙度和阻抗共同控制下的岩相迭代更新,在岩相控制下采用梯度生成树解决了井数据样本标签较少情况下的回归问题,该融合网络实现了在相对少样本条件下的岩相和孔隙度的同步预测问题。(2)构建了直接通过波形数据进行孔隙度和岩相同步预测的网络。考虑到阻抗数据可能存在误差,本文将阻抗替换为地震波形导入前述条件随机场梯度生成树融合网络模型进行孔隙度和岩相预测。由于地震波形数据的多维度特征,本文提取地震波形纹理特征并利用梯度生成树进行特征重构,构建了新的特征分类方法,将分类结果作为初始模型输入,有效改善了孔隙度岩相同步预测网络的精度。(3)提出了基于地震波形特征的条件随机场孔隙度岩相同步预测方法,将地震波形特征进行降维,并将降维后特征与孔隙度建立标签,将该标签引入梯度生成树条件随机场网络,实现地震相和孔隙度的同步预测。实验分析结果表明,采用地震波形进行孔隙度和岩相预测可以有效避免阻抗数据计算所引入的误差,改善预测效果。通过本论文的研究,拟探索出一套可行的通过人工智能方法进行储层岩相和储层物性参数预测的技术方案,为推动人工智能技术与储层预测结合提供借鉴。"
687,基于人工智能的剩余停车位数量预测方法研究,"在目前,许多停车辅助工具,例如智能手机中的APP能够实时的显示停车场内的停车空位,然而随着停车场内车辆的进入和离开,停车场内的剩余停车空位数也会随之改变,所以实时获取的停车信息就会失效,所以人们更愿意了解在未来某个时间点的停车场内的剩余停车空位信息,而不是实时的信息。精确的预测停车空位可用性有助于规划人们的行程,有助于提升停车设施的利用率。在本文中,基于果蝇优化的支持向量回归提出了一种预测停车场的停车空位数的新模型。在提出的模型中,支持向量回归(Support Vector Regression,SVR)的参数被初始化为果蝇群体,并且果蝇优化算法(Fruit fly Optimisation Algorithm,FOA)被用于搜寻SVR的最优参数,我们针对不同的场景下进行有效的实验,指预测不同容量的停车场在不同时间段后的剩余停车空位可用信息,为了验证提出的果蝇优化的支持向量机(Support Vector Regression with Fruit fly Optimisation Algorithm,FOA-SVR)模型的有效性,三种常用的预测模型,指反向传播神经网络模型(Backpropagation Neural Network,BPNN)、极限学习机模型(Extreme Learning Machine,ELM)和小波神经网络模型(Wavelet Neural Network,WNN)被用作对比模型。实验结果表明,提出的FOA-SVR在所有的预测场景下有着较高的预测精度和稳定性。此外,本文还提出一种迭代多步预测的长短期记忆神经网络(Long ShortTerm Memory Recurrent Neural Network,LSTM-NN)被用于预测剩余停车泊位,模型中的参数通过网格搜索方法来优化。此外,还采用了另外常用的回归算法模型作为LSTM-NN模型的对比模型,分别是门循环单元神经网络(Gated Recurrent Units Neural Network,GRU-NN),栈式自编码器(Stacked Autoencoder,SAE),SVR,BPNN和K近邻(K-Nearest Neighbor,KNN)。这些对比模型的关键参数同样的也是被网格搜索优化。我们通过在二个不同类型的停车场数据集上进行有效的实验来验证模型在短期预测和长期预测上的表现,实验结果表明,我们所提出的多步迭代预测的LSTM-NN表现更优于其他预测模型,特别是在车流量较大的商业类型停车场数据上表现更为突出。"
688,基于云计算平台的旱区典型农作物遥感信息提取研究,"中国是农业大国,粮食的产量是影响农业发展的一个关键因素,而作物识别是保障全球粮食安全初始阶段。随着全球气候的干暖化,作物生长周期发生改变,且造成了很多作物灾害,对作物进行大面积识别可以及时调整作物的生长结构和作物种植制度。因此,无论是粮食安全还是气候变化,对作物进行高效、及时的大面积识别显得尤为重要。本文应用Sentinel-2B、Landsat-8和样本数据,以内蒙古自治区土默特右旗县为研究区,以玉米、小麦、葵花三种主要作物为提取目标,提取典型农作物物候特征和纹理特征,开展了基于Google Earth Engine云平台的典型农作物多特征遥感信息提取研究。首先,使用Sentinel-2B遥感影像、Landsat-8遥感影像和实地采集的样本点为主要原始数据,结合往年当地的作物物候和温度变化,分析2018年三种作物的物候特征。根据Landsat-8遥感影像生成三种作物的NDVI曲线,对典型作物物候特征进行分析。其次,将三条曲线间变化较为明显的时间点和作物的种植、收获时间点作为多期影像数据源,对数据源进行分析,最终选择了5个时相。使用Sentinel-2B分别分析这5个时相的遥感影像的8种纹理特征,共生成40个纹理特征,并对典型作物纹理特征进行分析。最后,用主成分分析法将45个特征进行分析,分别用最小分类法、最大似然分类法、分类决策树分类法和随机森林分类法对主成分分析后的前15个不同的特征组合进行分类。实验结果表明:(i)基于单特征的分类精度(50.21%~91.26%)低于多特征的分类精度(55.26%~93.34%);全部特征的分类精度(55.26%~93.34%)低于特征选择后的分类精度(62.44%~97.37%)。(ii)不同的分类方法要结合不同的特征组合才能使分类效果最佳。(iii)研究区玉米主要分布在三间房乡、海子乡,提取面积为912.4km2;小麦主要分布在明沙淖乡、美岱召镇和G6京藏高速路北部,提取面积为110.46km2;葵花主要分布在毛岱乡和尧将军镇,提取面积为228.86km2。"
689,网络小说误导性评论过滤技术研究,"截至2018年,我国网络文学读者已突破4亿人,读者每天发布海量小说评论,大量低质量评论充斥着评论区。而误导性评论作为低质量评论中的一类,影响读者的阅读体验,需要对它们进行有效的过滤。相较于传统文本分类问题,误导性评论过滤是典型的网络短文本分类问题,高效地对其进行过滤有三个难点:文本长度短,上下文信息量不足;口语化表达带来的文本不规范问题;评论情感倾向不平衡性导致的样本分布不平衡。近些年来,深度学习技术凭借其抽取数据特征的优势和强大的问题拟合能力,在文本分类、机器翻译等诸多自然语言处理领域获得了巨大成功,同时也为短文本分类问题提供了全新视角。本文目标在于设计一个高效的误导性评论过滤系统,该系统针对误导性评论的特点,与传统文本分类系统相比有如下三点改进。(1)提出了基于多种上下文的中文词向量表示方法。由于网络小说评论文本的不规范性,通用词向量覆盖率低,只能使用评论语料在相同分词条件下训练词向量。但是,由于短文本上下文信息不够充足,使用短文本训练的嵌入式词向量表征能力不足,鉴于此提出了基于多种上下文的词向量训练方法,引入了N-gram特征、汉字特征和评分特征,通过多种上下文信息提高词向量的表征能力。(2)提出了NB-LR(Naive Bayesian-Logistic Regression)语料库扩充算法。由于误导性评论样本存在样本分布不平衡的问题,利用传统模型对数据量依赖小,部署速度快的特点,提出采用NB-LR语料库扩充模型,用以减少筛选正样本的时间。(3)引入评分向量的融合网络文本过滤算法。其中包括一种评分向量表示方法和一个融合了卷积神经网络和注意力模型的融合网络模型。由于误导性评论与评分的高度相关,将评分信息融入到输入中,将会提高文本特征表达能力,因此提出score2vec评论向量表示方法将评分表示为词向量一样的稠密向量;另一方面,融合了卷积神经网络和注意力模型,利用卷积神经网络在局部特征捕捉上有卓越的能力,同时使用注意力模型捕获长距离的依赖关系,优化全局词向量和评分向量的权重分配。从而提升了误导性评论的过滤效果。基于以上三点改进策略,本文设计并实现了一个以天为单位的离线批处理误导性评论过滤系统。在训练流程中实现了词向量训练,语料扩充和深度模型训练三个部分。在预测流程实现了对新增评论的预测和过滤,并对预测结果进行监控。"
690,基于深度特征融合的人脸-语音多模态身份识别研究,"多模态的生物特征识别是指利用两种及以上生物特征,通过综合不同模态特征的信息来进行身份识别,得到比只利用单一生物特征更加准确和稳定的识别结果。而人脸和语音的多模态识别因为其数据的易采集性,识别率高,活体检测功能等优点一直是多模态生物特征识别技术中的研究热点。深度学习的特征提取能力以及端到端的学习模式对于多模态特征融合有很大帮助,因此本文主要研究如何利用深度学习方法对人脸和语音特征进行特征层级的融合识别,主要研究内容概括如下:(1)提出结合多模态卷积和循环神经网络的人脸和语音融合识别模型。首先对如何利用卷积网络对人脸和语音特征进行融合识别进行研究,设计出了4种不同的多模态卷积网络结构,并通过实验对比来确定最佳的网络结构。多模态卷积网络的特征提取能力强,并且在训练过程中特征提取和融合部分能通过学习互相适应,所以能够提取出判别性强的融合特征。接着提出了将多模态卷积网络与循环神经网络结合,将一段时间的视频分帧并利用多模态卷积网络提取出一段时间序列的融合特征并将融合特征放入循环神经网络利用时间序列信息得到更准确的识别结果的方法。并且提出了3种不同的循环神经网络对序列特征进行分类的方法并进行了实验对比。(2)提出基于注意力机制的人脸和语音特征融合识别模型。首先在特征提取阶段利用改进的卷积神经网络残差网络来提取人脸特征,用长短时记忆网络提取语音特征来减少网络参数。在特征融合方面,利用注意力机制来综合处理一个序列中的人脸特征和语音特征,然后利用序列中融合特征的注意力权重来赋予序列中判别性强的特征更高的权重同时减少被噪声污染的特征的权重,使得噪声信息带来的影响进一步降低,提高了模型的判别能力。此外还通过实验来探究不同特征融合方法和网络结构对识别结果的影响,并研究如何将模型应用到实时的以及序列的人脸和语音多模态融合识别中,经过实验验证模型能够适用于实时的以及时间序列的人脸语音多模态身份识别。"
691,突发事件网络信息抽取和可视化技术研究,"每当有突发事件发生,其信息几乎占据了互联网的热搜榜首。及时从大量网络信息中获取突发事件关键信息,成为网络舆情监测预警中亟待解决的问题,也催生了信息抽取的应用前景。突发事件网络信息抽取主要存在如下几个方面问题:(1)新增未登录词影响了命名实体识别的性能;(2)描述事件的属性信息特征较难获取;(3)事件信息展示方式较为单一,综合程度不高。深度学习和语义依存分析有望提升信息抽取的性能;GIS可视化可将不同数据综合展示。本文研究了突发事件网络信息抽取和可视化技术,主要研究成果如下:(1)研究了命名实体识别。突发事件网络信息中包括很多新增未登录词,对命名实体识别的性能产生较大影响。本文利用FastText词向量的N-gram特性,提出了基于BiLSTM和CRF的中文命名实体识别方法。首先,将数据以字符为单位进行分词,利用FastText工具生成词向量;然后,将词向量输入BiLSTM神经网络,提取全局特征;最后,根据输出的特征序列,采用CRF选取出概率最大的标注序列,实现命名实体识别。实验结果表明,该方法可以提升未登录词的识别效果,提升命名实体识别的性能。(2)研究了突发事件属性信息抽取。目前属性信息抽取的研究主要集中在标注语料库,开放域语料库的抽取性能较差。本文提出了基于语义依存分析和规则模板的属性信息抽取方法。首先,从各个文档中抽取属性信息表达式,构成属性信息集合;其次,生成属性信息表达方式对应的规则模板;再次,利用语义依存分析补充规则模板,实现属性信息抽取;最后,将抽取的属性信息与正确的属性信息进行比较,调整规则模板,完善事件属性信息抽取。实验结果表明,该方法有效提高了突发事件属性信息抽取的性能。(3)研究了突发事件GIS可视化。图表可视化无法详尽表达突发事件信息,从而影响了对整个突发事件的掌控。本文设计了基于GIS的突发事件可视化方法。首先,调用Google Map API将地理位置映射为地理坐标;然后,将属性信息在地图上分层展示;最后,整合所有分层数据,实现GIS可视化。实验结果表明,该方法能够生成比较清晰的可视化展示,有效地呈现了突发事件关键信息。"
692,基于机器学习的变压器顶层油温异常预警研究,"油浸式变压器是最为广泛使用的变压器,其顶层油温状态研究具有重要的生产和研究价值。当前的顶层油温异常相关技术,具有设备成本高昂,技术操作复杂且难以推广的特点。本文根据国网变压器油温异常标注不足的数据现状,提出了一种新型的两阶段油温异常预警策略。其中:第一阶段为基于半监督学习的顶层油温异常标注,第二阶段为基于LSTM循环神经网络的油温异常预警算法。相关研究归纳如下。第一阶段:首先采用k-means算法寻找油温无标签训练集的不同工况聚类;然后根据油温异常标注阈值对油温无标签训练集各个聚类类簇下的各个油温区间的数据进行油温异常标注;其次基于规则抽取与实际应用需要,将进行异常标注后的油温训练集中引入随机森林模型,训练后可获得油温异常判定决策规则及油温异常分类器;最后将模型在人工标注测试集中进行测试,如果达到指定准确率加召回率的要求则达到了目标,否则通过阈值优化算法优化阈值并重新进行标注和测试。第二阶段:首先将第一阶段标注了异常标签的油温训练集经过数据集转换算法获得训练数据集,并导入到LSTM循环神经网络模型;依靠隐藏层的特征提取和LSTM循环神经网络具有学习长短期依赖知识的能力,进而完成模型的训练;最后利用训练完成的模型便可以进行油温异常预测。由于LSTM循环神经网络具有学习长短期依赖知识的能力,在油温异常预测场景中使用LSTM循环神经网络的预测效果相比传统的数据挖掘方法更好。本文通过多角度对比实验对提出的相关算法进行了验证,证明了其有效性和可行性。同时本文方案在S市的油浸式变压器中投入生产实测,进一步证明了上述方案的可行性和有效性。本文基于半监督学习,同时使用了有标签和无标签的样本,降低了样本标注的代价且取得了不错的效果。同时不需要额外的检测设备,可适用于不同类型的变压器,具有良好的可推广性。"
693,《机器学习前沿：2017雷蒙德和贝弗利・萨克勒英美科学论坛》翻译实践报告,"本文为《机器学习前沿:2017雷蒙德和贝弗利・萨克勒英美科学论坛》(The Frontiers of Machine Learning:2017 Raymond and Beverly Sackler U.S.-U.K.Scientific Forum)的翻译实践报告。该论坛主要介绍当前人工智能的发展方向、机器学习的应用领域及对未来社会的预测。原文为一篇科技论坛报告,具有科技文的典型语言特征:该文本专业术语和新兴词汇多、专业性概念涉及范围广。此外,原文语言客观、信息性强、结构清晰。因此翻译难点主要集中在专业词汇和长句的翻译以及语篇的衔接性和连贯性方面。以纽马克的交际翻译理论为依据,运用了交际翻译、语义翻译两种不同策略并分析其在本翻译实践中的使用情况,总结出适用于应用类科技文的翻译技巧,即零翻译、增译、减译、分译以及调整语序,结合翻译例句分析,证明以上翻译技巧在科技类文本翻译中具有可行性。"
694,基于随机森林算法的关键蛋白识别方法研究,"识别出生物体内有用的蛋白质对生物体进化以及医学领域都要极其重要的作用。当前辨别蛋白质重要性的方式有两种。一是基于生物化学方法,但利用生物实验的方法来识别具有一定的缺陷,具体表现为:时间较长、费用较高、以及不能处理数据量较大的问题等等。二是利用计算机为工具对生物进行分析并以生物学的相关知识进行解释的一种方式。利用计算机识别蛋白重要性的方法大多是利用蛋白质交互网络(Protein Interaction Network)提取拓扑中心性度量特征来识别。可是由于一些相关生物实验数据的残缺和蛋白质网络自身的复杂性,一直没有发现可以准确区别关键蛋白质和非关键蛋白质的单一中心性度量特征,并且从目前的相关研究来看,关键蛋白质和非关键蛋白质间的区别不能由单一特征决定,应该是由多种因素共同决定的。单一中心性度量往往不能有效识别关键蛋白质,需要融合多个拓扑中心性度量方法,突破传统的利用排序进行精细选择的方式,建立机器学习模型进行蛋白的分类和识别。随机森林算法属于集成类型的算法,可以集成多个单分类器即集成多棵决策树的分类效果从而组成一个整体意义上的分类器。鉴于之前研究均是利用单一特征进行分类识别,且由于随机森林具有集合多分类器的优点,分类效果具有明显的优势,因此本文选择随机森林机器学习方法来识别蛋白质的重要性。本文将从分析蛋白质网络结构出发,融合多个拓扑中心性度量方法,利用随机森林算法构建模型,对关键蛋白质的识别进行研究与分析。本文选用芽殖酵母蛋白质作为研究对象,具体的研究内容包括将收集到的数据进行清洗,构造蛋白质网络(PPI),选用六种中心性度量方法进行特征的提取,构建识别关键蛋白质的模型,选择随机森林算法,以及将实验结果用统计学指标进行评估分析。结果表明该算法可以准确快速的识别出关键蛋白质,排除假阳性、冗余性等干扰因素,相比较其他算法具有更高的识别能力。综上所述本文提出的融合多个中心性度量方法,利用随机森林算法建立蛋白重要度预测模型能够更有效的识别关键蛋白。"
695,基于机器学习的自闭症儿童情绪识别方法研究,"自闭症是一种表现为社会交流障碍以及感官运动重复的疾病。当前自闭症发病率在全球范围内持续上升,自闭症儿童的数量也在不断增加,有资料表明,其确诊的时间越早,干预治疗的效果就越好。如今,在自闭症儿童的诊断与治疗上不断有专家提出新的思路和见解,以机器学习为代表的信息技术也在不断地融入其中。国内自闭症儿童的治疗以干预为主,但存在缺乏足够的有经验的自闭症指导教师的现状。是故本文以机器学习为主要技术背景,基于实际应用场景构建了一个衡量自闭症学生课堂中情绪表现的系统,希望通过分析自闭症儿童的课堂学习视频,对学生的情绪作出有效评判,借以辅助教师对其课堂表现进行评价和追踪,减轻教师负担。该系统以自闭症教学场景中的个训课堂为主,针对实际教学环节进行建模,并基于其构建了自闭症儿童课堂学习过程中的情感评价指标。自闭症儿童在课堂上给予的反馈主要在于动作和表情,这也是本次研究的重点。所设计的指标包括以动作为主要表现形式的参与度评分和以表情为主要表现形式的表情强度及愉悦度评分,前者以动作响应时间为衡量标准,后者依托于面部表情模型。系统的输入数据为个训课堂学习视频,在进行评分之前首先需要对自闭症儿童的动作和表情进行识别,故项目的核心可分为两部分,第一部分为动作识别和表情识别,第二部分为基于其结果的评价方式。考虑到系统搭建过程中数据的传输和存储问题,同时基于姿态估计的特征点提取框架已经相对成熟,设计了将原始数据转换为特征点的方案。对于存在空间联系的非结构欧式数据,近几年图卷积神经网络的表现较为出色,故选用图卷积神经网络作为后续识别的主要方案。在实验过程当中,以帧序列和关键点坐标构成的矩阵作为输入,确定了时空图卷积网络作为动作识别的主要模型,精确度达到了90%,并在分析了欧氏距离及余弦特征之后设计了动作起始帧的计算方式,通过计算动作响应时间即可获得参与度得分;在表情识别的实验过程当中,发现了随机森林对以图片为单位的特征点序列的分类精确度可达到99%,故确定了随机森林作为表情识别的主要分类器,并在分析了表情强度和愉悦度同表情类别的关系之后设计了其评分方式。"
696,基于数据挖掘技术的高校学生用户画像系统设计与实现,"随着教育信息化的发展,高校的教学管理、学生的校园活动产生了大量的数据。这些数据不断产生与积累,形成了庞大的、分散的、复杂的数据集。此外,大学生人数不断增多,给学校的教育管理带来前所未有的挑战。对这个不断壮大的大学生群体缺乏科学的数据分析,容易忽视、遗漏一些潜在的问题,如心理健康、消费借贷、沉迷游戏等,进而可能引发重大的问题。从海量数据中挖掘出有价值的信息是大数据应用的共识。用户画像通常被认为是对用户属性、行为、特征的标签化。用户画像是高校应用大数据的核心基础,是高校精细化管理的前置条件,是智慧校园建设的重要内容。相比以往基于较小样本的数据分析,数据时代能够获取更多维度的大学生数据,较大程度地接近全样本,可以更精准地勾勒学生的数据面貌。本文通过收集高校学生的基本属性、学业属性、消费习惯、图书借阅、上网行为等维度的数据,对其进行数据清洗、数据集成、数据变换、数据规约等预处理,筛选出用于构建学生用户画像的属性特征,通过数据挖掘技术挖掘数据中隐含的知识,从而描绘出客观、丰富、细致的学生用户画像。建立高校学生用户画像系统不仅有利于全面展示大学生群体数字面貌,还可以辅助学校科学管理与决策,动态监测学生异常并及时预警,为学生提供个性化的定制服务。"
697,基于人工智能的图像质量积极评价,"图像作为一种二维信号,能够直观地将信息传递到人脑中。但图像从形成到存储的过程中存在着许多干扰因素,容易导致图像信息损失,造成视觉质量下降,因此有必要建立相应的评价机制对其质量进行评价。而智能时代的到来,使得以机器代替人脑进行图像质量评价逐渐成为现实。本文主要从以下两个方面对图像质量的评价方法进行了研究。针对目前无参考图像质量评估算法对图像质量预测准确性不足的问题,提出了一种基于空间编码的无参考图像质量评价方法。该方法首先在不同的位平面上提取了图像的空间结构特征,该特征能够量化像素之间的结构信息,可以更准确地反映图像的失真程度。然后使用神经网络建立图像质量评价模型,在LIVE、CSIQ、TID2013数据库中的实验结果表明,所提出的图像质量评价算法比现有的主流算法更为准确,并且与人眼的主观感知一致性高。最后,设计了基于质量评价的自动对焦方法,将该算法应用于相机的自动对焦,验证了算法的有效性和实用性。针对目前难以准确有效地提取混合失真图像质量特征的问题,提出了一种基于空间分布分析的图像质量评价方法。该方法首先将图像进行亮度系数归一化处理,然后将图像进行分块。之后使用卷积神经网络进行端对端的深度学习,利用多层次卷积核堆叠的方法获取图像的质量感知特征,并通过全连接层将特征映射到图像块的质量分数。再将块质量分数汇总获取质量池,通过对质量池中局部质量的空间分布情况进行分析,提取能够表征其空间分布情况的特征,然后再次使用神经网络建立局部质量到整体质量的映射模型,将图像的局部质量进行汇总。最后通过MLIVE、MDID2013、MDID2016混合失真图像库中的性能测试,验证了算法的有效性。"
698,基于网站链接特征的钓鱼网站检测技术研究,"钓鱼网站主要是指一些黑客通过仿造真实网站的页面内容以此来迷惑用户进而达到获取互联网用户的一些隐私信息,如一些金融网站的账号和密码等等。根据APWG(Anti-Phishing Working Group)发布的相关报告,近年来网络钓鱼攻击不断呈上升趋势。针对钓鱼网站检测这一问题,本文提出了两种解决方案。第一种方案是在分析了传统的一些用于钓鱼检测的技术存在的一些问题,如:需要分析大量的网页内容,这就导致时间开销过大无法满足实时检测的要求,还有的检测技术需要使用到第三方服务,这就可能会因为这些服务的异常而导致检测结果失效。因此,本文的第一种解决方案只分析网站的URL特征以及第一层页面内部链接的一些特征,然后利用机器学习的方法作为检测手段,另外还结合了搜索引擎元词搜索的特点用来寻找钓鱼网站攻击的目标对象网站,该方案在能较快识别钓鱼网站的同时还能较准确的找到钓鱼网站攻击的目标对象网站。第二种解决方案的提出基于以下两方面的因素,一是考虑到一些假冒网站可能会做反爬虫机制,因而使得一些检测技术无法获得网页内容。二是通过大量分析,钓鱼网站的URL使用的一般是方便制作并且造价便宜的域名,而合法网站的域名是有一定代表意义的,使用的基本是顶级域名。因此,第二种方案只在URL的层面进行分析,该方案借用Word2vec工具使用深度学习的方法自动学习URL的特征向量表示而不需要手工设计特征然后使用机器学习分类算法达到检测的目的,该方法在1百万的数据集上实验并做相关的评测,准确率可以达到99%以上,而且检测速度在毫秒级,相比传统的一些方法无论是准确率上还是速度上都有很大的提升。"
699,基于脑白质纤维跟踪算法的疾病特征标记方法及应用研究,"目前,基于扩散加权磁共振成像(Diffusion Weighted Magnetic Resonance Imaging,DW-MRI)的脑白质神经纤维跟踪算法是目前利用脑白质中的水分子扩散揭示活体大脑神经纤维信息的唯一方法。随着成像技术的发展,利用脑白质纤维跟踪技术探究脑区与各神经类疾病的关系成为临床应用领域的一大热点。但现有的疾病特征标记方法存在以下两个问题:第一,疾病区分特征单一;第二,方法的精准性、可靠性等并不高,无法满足临床需求。针对以上问题,本文在脑白质神经纤维跟踪算法的基础上,引入机器学习,深入研究神经类疾病特征分类并提出相应解决方法。本文的主要工作和成果如下:(1)针对疾病区分特征单一问题,提出基于脑白质纤维跟踪算法的解剖特征提取方法。该方法分为数据预处理、纤维重构、确定纤维跟踪以及大脑解剖特征提取四大步。同时介绍了基于体素的全脑纤维特征指标,包括以纤维体素为单位计算各体素的所有纤维长度的总和λ_v以及其长度逆λ_(inv),以及基于脑连接度的纤维特征――区域间连接度的纤维偏向指数LI。(2)针对缺乏可靠科学的神经类疾病特征标记方法问题,在脑白质纤维跟踪算法的基础上,引入机器学习,提出一种特征分类算法。该方法利用ReliefF算法对纤维量化指标进行特征选择,之后通过支持向量机(Support Vector Machine,SVM)对疾病分类,结合连通性,研究疾病间的潜在差异。该方法是全自动化流程,无需医生手动划区等额外操作,整个过程高效简洁。(3)针对帕金森病(Parkinson’s Disease,PD)和影像扫描无多巴胺缺陷患者(Scans Without Evidence Of Dopaminergic Deficit,SWEDD)难以区分的问题,本文通过基于脑白质纤维跟踪算法的解剖特征提取方法提取28例PD患者和22例SWEDD患者的解剖特征,利用提出的ReliefF-SVM特征分类算法区分两类疾病。实验结果表明,基于SD_STREAM的疾病特征标记方法更能成功区分PD和SWEDD,分类准确率高达81.25%。根据分类结果,左脑的苍白球、伏隔核,右脑的腹侧尾状体、伏隔核和后顶叶丘脑这五个区域可以标记PD和SWEDD。在连通性的实验结果中可以看出,PD和SWEDD在扣带回与壳核、丘脑之间的连接上存在差异。帕金森病和SWEDD两类疾病的成功区分验证了本文提出的基于脑白质纤维跟踪算法的特征提取方法以及ReliefF-SVM特征分类算法的有效性,可为疾病分析提供新的策略。"
700,手机壳高精加工的刀具磨损状态识别与剩余寿命预测,"高精加工过程中,由于刀具的磨损,使得加工工件出现各种质量问题。以手机壳倒角高光加工为例,会出现拉丝、崩膜以及发雾等现象。有效的刀具磨损状态监测模型可以降低废品率,提高生产效率,对实现自动化生产有重要贡献。针对高精加工过程中,刀具磨损量小,传感器信号中刀具磨损敏感特征不易提取等难题,本文提出了基于卷积神经网络(CNN)的多传感器信号特征提取技术并结合极端梯度下降算法(XGBoost),多层长短时记忆网络-粒子滤波(Stacked-LSTM-PF)进行刀具的磨损状态监测。根据实际的精加工刀具磨损特点以及常见的工件异常质量形式设计模拟实验,确定利用主轴振动、工件振动以及切削力信号的多传感器融合技术进行状态监测的实验方案。利用短时能量方法对加工信号进行截取与小波降噪处理。提出了对信号进行时频域特征提取,利用CNN进行特征二次提取的特征提取方法,利用基于距离评价技术和基于信息增益的方法进行特征选择,获取刀具磨损的敏感特征。建立SVM、决策树以及XGBoost的刀具磨损状态识别模型,分别对比时频域特征、原始信号直接用CNN提取的特征和CNN二次提取特征的分类结果。证明了本文提出的特征提取方法有效性以及XGBoost算法的优越性,准确率达到97.52%。提出了基于Stacked-LSTM-PF的刀具剩余寿命预测模型,利用Stacked-LSTM进行刀具磨损值的定量预测以及粒子滤波(PF)的刀具磨损物理模型的参数辨识。对比不同LSTM网络参数对刀具磨损值预测误差的影响,确立了隐含层为36个节点,LSTM堆叠层数为3层的网络结构的剩余寿命预测模型,磨损值预测平均平方损失误差(MSE)仅为3.8968(10~(-3)),剩余寿命预测相差在5件以内。通过在某企业实际生产现场应用,证明了本文提出的特征提取方法、基于XGBoost磨损状态识别模型(准确率达95%)和基于Stacked-LSTM-PF剩余寿命预测模型(剩余寿命相差1件)的有效性。"
701,基于深度卷积神经网络的移动端花卉识别系统,"随着高性能计算芯片的发展,在移动设备上部署深度学习模型成为了当今的热门。卷积神经网络(简称CNN)作为深度学习技术的一种,由于其能够自适应地学习并组合出有效的特征,非常适用于花卉识别这种较难的细粒度图像分类范畴。CNN通常有上百万个计算节点与参数,这意味着硬件设施要有较强的算力与较大的存储资源。然而在边缘计算中(比如移动端和嵌入式平台),设备的计算能力较低,内存也较小,因此部署起来有较大难度。论文围绕移动端CNN的部署和优化展开研究,探索了一系列技术来使花卉识别模型尺寸更小、预测时间更短、识别精度更高。论文的主要工作包括:(1)模型选择方面,详细分析了CNN的演变和网络结构,以及各种经典的CNN架构。接着从CNN的时间复杂度和空间复杂度入手,选择了尺度、速度和精度都取得了较好权衡的轻量级CNN MobileNet-V2。(2)模型训练和优化方面,通过对CNN的训练流程和常用优化算法进行分析,提出了一种结合Momentum的RMSProp优化算法,和其它优化算法相比,该算法在相同的迭代轮数内,损失函数下降得更快,正确率上升得更高,更快寻找到最优解。另外本文采用同步模式的双GPU并行训练来缩短训练时间,并采用迁移学习、L2正则化、数据增强等一系列训练策略来提升模型精度。(3)模型压缩方面,采用了一种高效8-bit整数运算神经网络量化方案,该方案能将CNN的32-bit浮点运算转化为高效8-bit整数运算,减小模型体积的同时缩短模型预测时间,而精度下降却非常低。以MobileNet-V2作为基准进行测试,转化后的uint8模型相比原先的float32模型,体积缩小52%,预测时间缩短48%,而精度下降1%。(4)基于TensorFlow Lite开源框架,在安卓移动终端上实现了模型移植。该花卉识别系统的APK大小为7.17MB,小米6手机上单帧预测时间为57ms,在Oxford-102 Flower公共数据集上的Top-1正确率为95.9%,此外与其它花卉识别模型的对比也表明了该系统在尺度、速度和精度等方面都具有较好的性能。"
702,基于改进BLSTM神经网络的短文本情感分析研究,"随着计算机和互联网技术的更新和发展,越来越多社交、商业平台陆续出现,面对社会舆论热点、在线购物体验等事物伴随而来的是大量含有情感色彩的评论、微博等短文本。无论是从消费者还是商家制定消费、销售策略的角度,还是从政府部门监控舆情的角度,或是从新闻等媒体更有效传播信息角度上看,快速得知这些语料情感倾向的方法和模型的研究不仅具有应用价值也具有理论意义。于是应运而出了情感分析这一全新的研究领域,情感分析的方法按照其原理和思想可以分为三类――规则词典、机器学习和神经网络,结合这一背景为了使研究更具代表性,本文主要采用经过改进的情感得分(修正情感得分),支持向量机,双向BLSTM神经网络及其改进模型对6万余条商品短文本评论进行情感分析研究。通过相关学术文献研读发现目前该领域存在以下几个问题:(1)传统情感得分的符号可以判别情感极性,但数值随文本长度随机变化,基本的统计学习无法发掘情感得分数值部分的意义;(2)词向量作为多数机器学习和神经网络模型的输入,多数研究采用相关平台上基于一定语料训练而成的词向量库来作输入,但用于具体研究时这一做法的泛化能力有待考究;(3)另一部分研究自行训练的词向量多数采用平权的方式计算每条短文本的向量表达,忽略了词频和逆文本频率指数对每条词向量权重的影响,实验输入不够完善。针对情感分析领域存在的上述问题,本文进行了如下工作:(1)对相关文献进行研读和梳理,整理存在的弊端提出改进的思路,并将本文用到的模型理论进行阐述;(2)考虑传统规则词典情感得分忽略了文本情感极性值与文本长度之间的关系以及商品评论的文本数据其长短与感情强度之间的关系,本文对其进行两步改进,定义平均长度引入修正情感得分来替代传统的情感得分;(3)将切词包的标准词库中加入正负两个情感词典的路径对获取的6万余条语料进行切词、去除停用词等预处理,对于支持向量机以及BLSTM神经网络模型的输入,本文词向量的构建基于在Python语言下利用gensim包里的Word2Vec函数进行的平权词向量和基于TF-IDF加权的词向量,两者作为两次输入在BLSTM神经网络模型中进行对比;(4)介绍本文实证部分的评价体系,并介绍各个模型编程中的关键函数,共进行修正情感得分、支持向量机、双向长短期记忆神经网络及其改进模型四个方法的实证训练,四种模型的F1值分别为0.80、0.85、0.87、0.89,从实验结果上可以看出经过改进的双向长短期记忆神经网络模型在情感分析的功能上具有一定的优越性。最后,对本文的研究结果进行总结,并针对研究过程中存在的问题和未完善点进行展望。"
703,基于多规则的数据修复方法,"随着计算机技术的不断发展和大数据时代的到来,数据质量的提升也逐渐受到重视,数据质量由数据一致性和准确性等决定,数据质量直接决定了数据处理和数据分析等基于数据的操作和以此为依据所得到的研究结论,比如针对工业数据中的用户分析,数据本身的准确性以及用户与数据的对应关系的准确性是数据分析的基础,如果不能保证数据的准确,数据分析并不能得到相应的可信结论。在商业社会中,数据质量也直接或间接的影响着工业化的效益,定期维护数据库中的数据,有利于保持较高的数据质量。本文是在SSG公司的数据集上进行的研究,考虑数据集特定列reference结构的复杂性和数据的特征,推而广之,对于关系型数据库中此类型数据的数据修复进行讨论。基于传统的基于规则的数据修复方法的思路下,将函数依赖关系中对数据库的结构设计的应用拓展到条件函数依赖关系对数据元组的规则约束,两者结合构建规则集合,提升数据修复效果的前提下,也大大提升了修复的速率,是基于实际应用的修复策略的方案。同时基于机器学习对空值的修复,对于上述修复规则中对数据修复过程无法修复修复空值的问题,结合依赖关系给出了完整的修复方案。本文主要工作如下:1)针对数据修复问题,提出了基于多规则的数据修复优化算法。为降低仅利用正则表达式作为修复规则的查找过程的繁复性,首先利用正则语言的特性构造正则表达式,然后优化TANE算法生成条件函数依赖关系,将两者结合构造基于元组的规则集。在此规则集基础上,借鉴RSR算法的利用有穷自动机和操作符选择的思想,构建优化模型对数据进行检测并修复。通过SSG公司数据对优化后的方法进行实验验证,得到了不同频度依赖关系的修复效果以及确定频度下数据修复的效果,实验结果证明了该方法可以有效修复数据,并能有效提升数据修复速率。2)针对数据修复过程中的空值问题,提出了基于神经网络ANN模型的空值填充方法。本文基于数据依赖关系,考虑待修复元组与相关元组集合的关联性,提出了基于神经网络ANN模型下的空值填充优化方法即FD_ANNRST模型,通过对比实验证明,此方法较其他模型能够更有效的解决空值的修复问题。"
704,改进群智能优化算法研究及应用,"群智能优化算法由于其实现简单,灵活性强,鲁棒性高等优点,得到了很多研究者的关注,并被广泛的应用于各种领域的优化问题。近年来,有很多新颖的群智能算法被提出,其中包括灰狼优化算法(GWO)、鲸鱼优化算法(WOA)和蚱蜢优化算法(GOA)。这些算法都是通过模拟动物的捕食和迁移行为实现的。虽然这些群智能算法与经典的群智能算法(如遗传算法,粒子群算法等)相比具有明显的优势,但是在优化实际问题时依然有着收敛速度慢,容易陷入局部最优的问题。本文针对这三种群智能优化算法各自存在的问题分别提出了改进方法,并将这些改进算法成功应用到现实优化问题。本文的主要研究内容如下:(1)在GOA的基础上,通过引入反向学习机制、Levy飞行机制和高斯变异机制提高算法的全局和局部搜索能力,提出了一种改进蚱蜢优化算法(IGOA)。在IGOA算法中,高斯变异机制首先被用来增加种群多样性,提高局部搜索能力。其次,利用Levy飞行提高GOA的随机性和跳出局部最优的能力。最后,反向学习机制被用来加快算法的收敛速度。基准函数优化实验的结果表明,IGOA与其他群智能算法相比,具有更强的全局优化能力。基于IGOA优化的混合模型IGOA-KELM在预测公司财务压力的实验中也取得了理想的结果。(2)针对WOA存在的问题,本文提出了一种基于混沌初始化策略,高斯变异和混沌局部搜索策略的改进鲸鱼优化算法(CCMWOA)。在CCMWOA算法中,混沌初始化策略首先被用来生成高质量的初始种群,这有利于提高算法的收敛速度。其次,高斯变异机制被用来保证算法在迭代过程中的种群多样性。最后,具有收缩性质的混沌局部搜索被用来提高WOA的局部探索能力。在基准函数优化实验中,与WOA相比,CCMWOA的全局优化性能得到了显著的提升。在CCMWOA优化三个具有约束条件的工程设计问题实验中,CCMWOA获得的设计方案明显优于其他算法。(3)为了更好的平衡GWO的全局搜索能力和局部搜索能力,本文提出了基于新层级结构的改进灰狼优化算法(IGWO)。在新层级结构中,Beta狼会围绕当前最优解(Alpha狼)进行局部搜索,提高算法的局部搜索能力。Omega对整个解空间进行随机全局搜索,避免了整个种群陷入局部最优的风险。在基准函数上的实验表明,IGWO的整体优化性能明显优于GWO以及其他常用的群智能算法。此外,基于IGWO构建了一种混合机器学习模型IGWO-KELM,并将该模型应用于诊断甲状腺癌。实验结果表明该模型可以达到86.11%的诊断精度,78.43%的敏感度和92.43%的特异度。"
705,融合时间因素的智能家居用户操控习惯挖掘研究,"随着大数据时代的到来,智能家居行业得到了极大的发展。然而,由此产生的大量用户历史操控数据却未得到很好地利用,限制了行业竞争力的提升。因此研究如何利用海量的智能家居用户历史操控数据,挖掘出用户的操控习惯,实现家居设备的智能化决策,成为智能家居行业走向智能化过程中的关键问题之一。本文依据行业内的标准,将智能家居用户操控习惯分为两大类来研究:第一类是面向单一智能家居设备的用户单控操控习惯;第二类是面向多个智能家居设备的用户关联操控习惯。针对目前主流的智能家居用户操控习惯挖掘算法,未能很好地利用用户历史操控数据的时间特性的问题展开研究,提出了相应的用户单控操控习惯挖掘算法和用户关联操控习惯挖掘算法,并进行了验证实验。本文主要研究工作如下:(1)介绍了智能家居和用户操控习惯的概念,重点研究了目前被用于智能家居用户操控习惯挖掘的聚类分析以及关联分析技术。(2)对常被用于用户单控操控习惯挖掘的聚类分析算法进行了总结与分析,提出一种具有自组织聚类和遗忘学习能力的用户单控操控习惯挖掘算法。首先,针对目前的聚类分析算法缺乏自组织选择类别簇数量以及自组织聚类过程收敛过慢的问题,该算法提出一种融合自编码技术和竞争学习机制的人工神经网络来初始化算法,使得算法可自组织产生更合理的类别簇数量和对应的质心。其次,针对目前的聚类分析算法无法融合时间因素来判别用户历史操控数据的重要性,缺乏遗忘学习能力的问题,该算法基于艾宾浩斯遗忘规律引入了一种遗忘因子,改进了传统聚类分析算法的质心更新机制,使得算法可以进行类脑遗忘学习,从而让算法挖掘到更贴近用户近期真实习惯的用户单控操控习惯。(3)对常被用于用户关联操控习惯挖掘的关联分析算法进行了总结与分析,提出了一种融合时间因素的用户关联操控习惯挖掘算法。目前的关联分析算法仅使用支持度和置信度作为用户关联操控习惯挖掘过程中的筛选条件,未能充分利用户历史操控数据的时间特征,导致所挖掘到的用户关联操控习惯中包含的各子操作行为之间缺乏时间维度上的顺序性和关联性。有鉴于此,该算法首先通过改进的FP-growth算法得到用户历史操控数据的时序频繁项集,然后引入一种时间约束因子,对从时序频繁项集生成用户关联操控习惯的过程进行时间约束,使得算法所挖掘到的用户关联操控习惯中包含的各子操作行为之间存在时间维度上的顺序性和关联性。(4)介绍了如何将所提出的智能家居用户操控习惯挖掘算法应用于智能家居系统中。在云端智能家居系统的基础上,开发了一个智能家居控制软件以及用户操控习惯挖掘软件。首先,通过控制软件实现了智能家居设备的远程监控和用户历史操控数据的收集。然后,通过用户操控习惯挖掘软件对所收集到的用户历史操控数据进行操控习惯的挖掘和推荐。仿真实验表明,本文所提出的用户操控习惯挖掘算法具有可行性和工程应用价值。"
706,基于MAX 10 FPGA的紫外预警智能纽扣,"紫外线是生活中常见的一种不可见光,适宜的紫外线对人体有一定的保健作用,但过强的紫外线长时间照射人体皮肤,轻者引起皮肤暗沉和松弛老化,重者更会导致皮肤癌的出现。为避免伤害的发生,紫外线指数成为一个重要的天气指标参数,但天气预报中公告的数值往往与实际中在时效性和准确性都有所出入,使得长期户外运动的人员很难及时准确的做出相应防护措施。因此,一种具有实时性的局域紫外线预警系统被提出来克服目前紫外线指数被动获取的弊端。本论文提出的一种可穿戴式的智能紫外预警智能纽扣,其主要包含:数据采集系统、数据处理系统、以及数据显示系统。控制器选用的是Intel/Altera公司的MAX 10 FPGA。数据采集系统分别采用紫外线传感器和温湿度传感器去采集局域环境中紫外线和气温和湿度的信息,并采用LED灯作为数据显示系统来显示观测到的数据等级。数据处理系统包括数据训练模块和数据融合、优化模块。数据训练模块主要在计算机上实现,其训练数据集来自于网站Weather Underground,输入属性有三种,分别为为紫外线、温度和湿度,输出的标记是危险或者安全。数据训练部分采用机器学习算法来训练数据,并比较支持向量机、K近邻和决策树三种算法的预测准确率,选用合适的算法在硬件实现。在数据融合、优化模块中,本文使用紫外线和温湿度数据来进行数据融合,并提出危险和安全的两种提示信号,通过LED灯显示预测结果。在硬件中使用推断、直接查表和K近邻查表三种方案处理数据。通过比较三种方案的数据融合结果的准确率以及考虑控制器运行速度的问题,得出K近邻查表预测的方案较为优越的结论。本论文针对皮肤防护理念设计出一块可穿戴的智能紫外预警纽扣,能实时的检测环境数据,并通过多个数据融合算法处理数据,一旦环境处于危险状态,立即发出告警信号。"
707,机器学习与自由电子激光的应用研究,"先进的光学装置的诞生,意味着科学家们可以使用全新的研究方法来探索未知的世界,例如,可以以纳米尺度创建微观物质的三维结构图像。伴随着设备的不断改进,许多实验设备采集的数据量将急剧增加,但只有一小部分数据可用于后续分析。实验所得到的许多数据,有可能是没有意义的无效数据,我们需要将它筛选去除掉,也有些数据可能是含有意义,但比较难以利用。本论文的目的是将机器学习与光学实验结合起来,讨论如何能够智能化、高效地处理光学实验中所产生的数据。纳米晶体学研究了蛋白质等大分子物体的结构,用X射线照射结晶样品产生衍射图像,通过获得来自许多不同方向的衍射图像,就有可能重建样品的空间结构。X射线源以固定的速率产生闪光,由于技术限制,样品的通过位置无法和X射线闪光同步,或者图像内的信号量太小,这导致产生许多无用的、不包含任何信息的图像。X射线自由电子激光器对科学研究产生广泛影响并且拥有着巨大潜力,是解开物质结构动力学的关键因素。为了充分利用这一潜力,我们必须准确地了解X射线特性。但由于自由电子激光器的不稳定性,需要对每个脉冲的特性进行全面诊断。然而,直接进行诊断会影响实验,而且无法在高频率下实现。我们采用机器学习的策略来解决以上面临的问题。由于以上情况涉及到大量的数据处理,机器学习可以成为一个有力的工具,有效地处理以上所出现的问题。本文采用多种数据处理方法、机器学习策略,来解决光学实验当中因为大量数据而产生的限制问题。"
708,基于深度学习的滚动轴承故障诊断方法,"滚动轴承是旋转设备的重要部件,一旦出现故障,会降低产品质量甚至造成生产事故,因此对滚动轴承进行及时诊断具有重要意义。在当今大数据时代,由于反应轴承运行工况的海量数据的积累,传统基于“人工特征提取+人工特征选择+浅层分类器识别”的轴承故障诊断方法对专业知识和领域专家经验依赖性较强,逐渐难以满足现代自动化诊断的要求。深度学习作为现代人工智能领域崛起的新生力量,克服了传统轴承故障诊断方法的缺陷,能自动地从数据中学习具有代表性的特征,在很大程度上摆脱了对诊断专家的依赖,并逐渐应用于轴承故障诊断。因此,本文针对传统轴承故障诊断方法的局限,在机器学习技术和深度学习技术的基础上,着重研究了基于深度学习的轴承故障诊断。本文的研究工作基于深度学习滚动轴承故障诊断的半监督和有监督问题,主要内容如下:(1)分析了滚动轴承的故障机理,论述了基于信号处理和机器学习的滚动轴承故障诊断方法的研究现状,对现有的基于深层神经网络的轴承故障诊断方法进行了分析,并在此基础上给出了论文的结构安排和创新之处。(2)针对带标记数据样本少而未标记数据样本多的情况,提出一种基于压缩感知和改进深层小波神经网络的半监督学习滚动轴承故障诊断方法。将压缩感知方法的压缩采样能力和降噪能力与改进深层小波神经网络结合,有效提高了轴承故障识别效率。实验验证了提出方法的有效性。(3)针对带标记数据样本多的情况,提出一种基于同步挤压S变换和深层曲线波卷积神经网络的滚动轴承有监督学习故障诊断方法。为有效提高轴承振动信号的时频分辨率,引入同步挤压S变换;为有效训练深层卷积神经网络,使用curvelet变换代替传统的卷积运算,并将二者结合用于滚动轴承故障诊断,实验验证了提出方法的有效性。(4)针对诊断目标数据样本少的问题,提出一种基于EDWNN和迁移学习的轴承诊断方法。为扩展诊断目标数据量,引入迁移学习方法;为克服单一深度模型稳定性差的问题,引入集成学习策略;为使分类器能够刻画数据细节,提高数据拟合率,引入深层小波支持向量机。实验表明提出方法在目标样本不足的情况下,也能提高轴承的诊断精度和稳定性。"
709,中低压燃气调压器故障自诊断技术优化与测试,"在节能减排的号召下,天然气能源发展有着巨大潜力,近年来的能源革命中扮演了重要角色。燃气调压器作为燃气运行管网的关键设施,在燃气输配系统中有着重要作用。针对目前中低压燃气调压器出现故障需依靠人工判别的问题,实现其智能化的故障自诊断,对燃气输配管网的快速发展和安全运营具有重要的社会经济意义。本文首先介绍了中低压燃气调压器故障诊断技术的研究现状,对调压器的分类和不同运行状态的特征做了简要分析;其次建立了基于EMD分解法和SVM算法的中低压燃气调压器故障自诊断系统;最终经过实际案例验证,该方法取得了良好的机器学习性能与准确度,为中低压燃气调压器故障自诊断的智能化提供了一种可行的途径。具体的研究方法为:采集其出口压力数据进行EMD分解得到能量矩值,计算得到每个样本的动态波动幅度指标(DB)作为补充判据。绘制出口压力雷达图,对调压器的输出状态进行了深度细化,共分为了7种不同输出状态。运用优序图法合理判定专家技师的人工诊断结果。在机器学习过程中通过网格搜索的方法分别优化了惩罚参数C和核函数参数g,用交叉验证的方法解决了样本数量较少的问题。在此基础上建立最优支持向量机的模型,形成了一套有效的中低压燃气调压器故障自诊断系统。对经过优化后的中低压燃气调压器故障自诊断技术进行测试,运行结果表明:在实际工程中,该优化后的SVM模型能够对中低压燃气调压器故障状态进行正确分类,准确率提升至了91.40%。该技术的上线应用优化了中低压燃气调压器的运营管理方式,对保证燃气管网安全高效运行具有重要意义。"
710,基于深度学习的小分子虚拟筛选和反应产率预测,"药物研发是一项复杂的工程,为了得到疗效可靠且性质合理的药物,需要进行大量的实验,浪费大量的人力物力财力。与此相同,在有机合成中,为了得到目标化合物或者找到高产率的反应条件,也需要进行不断地尝试。从经济环保高效的角度出发,构建各种可靠的计算模型,实现数据驱动的药物设计和有机合成是至关重要的。深度学习作为一种机器学习表征算法,使用包含多层非线性处理单元的神经网络来学习数据表征,通过反向传播算法来指示机器应如何更改其内部参数发现数据集中的复杂结构。深度学习有多种框架,被广泛用于语音识别、视觉识别和自然语言处理等领域,并取得了极佳的效果。由于各种组学和生物学数据的积累,深度学习模型已经在药物设计的各个领域崭露头角,并且在某些领域的表现要优于简单的机器学习模型。除了药物设计外,深度学习模型凭借其强大的学习表征和数据处理能力,在逆合成路线和反应产物预测等有机合成相关问题上也有出色的表现。本论文的第一章介绍了机器学习的发展历史及常用算法,深度学习模型的常见框架及训练过程,并重点介绍了深度学习方法在药物设计和有机合成某些领域的具体应用实例。第二章首先介绍了靶点ZAK(sterile alpha motif and leucine zipper containing kinase)相关的生物学背景,指出其是治疗心血管疾病及某些癌症的重要靶标,但目前没有专门针对ZAK的小分子抑制剂类药物上市。然后介绍了ZAK的晶体结构,分析复合物中配体和ZAK的结合模式,收集其他激酶选择性差的ZAK交叉活性小分子与其晶体结构对接,指出使用传统的基于结构的药物设计方法进行ZAK小分子的虚拟筛选存在高假阳性的风险。为了提高虚拟筛选的富集率,我们发展了基于深度学习的预测模型,将深度学习分类模型与分子对接相结合用于ZAK小分子抑制剂的虚拟筛选中。而且为了得到对ZAK有选择性的小分子,我们在挑选过程中还引入激酶谱预测模型,联合使用上述方法,我们成功找到了骨架结构新颖并具有选择性的ZAK小分子抑制剂。在第三章,我们论述了深度学习在有机化学反应产率预测中的应用。我们在文献中收集高质量的Suzuki-Miyaura反应数据,并应用量化软件计算了反应物和催化剂的性质。用反应物和催化剂的量化性质和反应时间、反应温度、催化剂用量三个反应条件作为模型的输入,构建了深度神经网络回归模型来预测Suzuki-Miyaura的反应产率,经过超参优化,确定最优模型。最优模型不仅在模建反应数据上有良好的表现,还可以为未见过的新反应预测产率。除了预测反应产率外,我们的模型还可以根据预测的产率为反应确定高产率的反应条件,所有结果都得到了实验证实。综上所述,本文以深度学习为基本手段,并将其成功应用到的两个具体且有意义的课题中。我们发展的基于深度学习的方法不仅可以使我们的课题取得良好的结果,同样适用于其他相似的体系,充分肯定了深度学习是推动药物设计和有机合成实现数据驱动发展的重要力量。"
711,基于LDA的多标记源文本分类研究,"互联网技术的发展加快了大数据时代的到来,快速获取和分析大数据是当代互联网应用不可缺少的能力。而文本是数据信息的主要载体。传统监督机器学习算法需要大量专家标记数据才能训练高性能模型,而获得专家标记往往费时费力。众包系统利用群众智慧对数据进行标记,能以较低的成本对任务快速响应,因此得到了广泛的使用。但由于群众知识背景和工作能力各不相同,导致收集到的多标记存在噪声,不能直接代表正确标记。多标记源分类器是一种整合多标记的方法。文章将以提升多标记源分类器准确度和节约标记成本为目的,对多标记源分类器进行研究。将进行的主要工作有三个方面:(1)提出了朴素贝叶斯深度加权算法用于数据分类。朴素贝叶斯(Naive Bayes)因其强独立性和特征同重要性假设,在对非均衡类样本分类时,容易将属于少数类的样本分到多数类。考虑到各个样本在分类中的不同重要程度,利用感受性曲线面积值对特征加权,实现提升算法的目的。实验结果表明,朴素贝叶斯加权算法有利于提高分类器在偏态样本中的分类准确率。(2)利用LDA((Latent Dirichlet Allocation))特征融合方法用于文本建模。多标记源在标记过程中往往受到文本主题的影响,通过融合主题模型特征和word2vec词向量特征构建文本特征,再代入高斯过程多标记源分类器进行训练,得到性能更高的模型,最终根据新文本特征推理出更准确的标记估计值。实验表明,特征融合方法能够进一步提升高斯过程多标记源分类器性能;(3)利用主动学习与多标记源分类器结合算法实现众包标记文本分类。主动学习同众包系统都具有减少成本的功能。主动学习首先利用少量标记样本初始化模型参数,然后利用适当规则挑选更有价值的样本交给人工标记,并不断迭代,直到满足终止条件。众包系统则可以为挑选样本提供人工标记渠道。同时根据主动学习思想制定合适规则,挑选出最适合标记该样本的标记源,达到成本最小化。实验证明,主动学习选取样本进行标记后训练模型,较随机抽取样本标记后训练模型,能实现更高准确度。三种算法存在如下关系:第一个算法将作为对照组加入到后续算法的对比实验中,第三个算法是在第二个算法上的提升,期望在保证分类器精度的条件下进一步降低文本标注的成本。"
712,基于机器学习的恶意网址识别方法的研究与发现,"随着互联网的快速发展以及网民数量的不断攀升,信息在高速与频繁的交换过程中木马注入、网络钓鱼、分布式攻击等网络攻击不断涌现,严重威胁个人用户的隐私、网络环境的生态及国家信息财产安全。许多网络攻击借助传播恶意URLs来实现。本文针对恶意URLs的检测问题进行了相关研究。针对基于黑名单机制只能检测识别已发现的恶意URLs,无法预测新近出现及未标记的恶意网址的问题,本文对大量URLs进行统计分析,设计并提出具有高检出率的恶意URLs检测特征空间,包含基于时间、元辅音比等34维特征。为验证比较特征有效性,结合机器学习及深度学习算法进行检测实验,证明对恶意URLs检测识别具有良好的区分能力,检测准确率高达99.5%。通过对特征集的对比分析发现:时间、子路径最大长度、URLs中元组在负向数据集概率和、URLs中元组在正向数据集概率和、域名最长字串占域名比例、域名中不同种类的字符占域名比例等15维特征在先前研究中未被使用或较少被使用,但在本特征集中起关键性区分作用。针对人工设计特征规则过程中会引入不相关、冗余、噪声特征等问题,本文提出一种发现综合特征空间的方法,主要采用随机森林、J48、贝叶斯等机器学习算法对基于信息增益、信息增益率、基于相关性等多种特征选择算法选定一组准确率高的广谱特征空间。实验证明,采用此方法提取的特征空间对恶意URLs的检测具有良好的贡献能力,检测准确率高达99.4%,多分类器平均准确率达98.6%,高于全特征集0.4%,特征空间维度下降55.9%。针对URLs检测识别中主流的特征提取算法面临的人工设计规则困难、规则更新时效性差的问题,本文设计了一种URLs编码器并结合3种结构的卷积神经网络来实现URLs特征自提取的方法。该方法采用统计n-gram(n=1)字符数量的方式构建URLs编码器并将URLs映射编码成矩阵结构,然后通过预训练完成卷积神经网络初始化,进而实现URLs特征的自提取。再结合多方面因素对本文的特征提取模型进行验证分析。实验表明,本文提出的将URLs编码与卷积神经网络结合的特征提取方法可以有效地完成对良性和恶意URLs的特征自提取,且提取的URLs特征具备良好的区分差异性,多分类器的分类准确率也均超过97%,最高可达99.2%。"
713,基于线性SVM的钓鱼网站检测系统的设计与实现,"伴随着信息时代的快速发展,网络安全也越来越被重视。现如今的电子商务相关产品的层出不穷使得个人信息安全问题变得严峻。因此我们必须对此做出相应的对策。在这个信息时代,用更智能的方法将钓鱼网站检测变得更加方便简单。钓鱼网站一直是网络安全中需要解决的难题之一,它的隐蔽性很高,但造成的损失往往很大。针对钓鱼网站的研究,有很多学者通过机器学习算法对钓鱼网站和正常网站进行分类。本文主要根据在钓鱼网站检测中常用的分类算法为基础,通过对网站的URL特征和页面内容特征进行实验比较研究,同时设计并实现了一个高性能的钓鱼网站检测系统。主要工作内容如下:1)首先本文分析了一次完整的钓鱼网站攻击案例,之后结合现今的钓鱼网站检测技术,其中包括黑白名单库检测机制、启发式钓鱼网站检测机制和基于视觉相似性的检测机制。并针对上述检测机制进行了优劣比较和总结。2)然后通过调研及钓鱼网站的发展趋势,设计并实现了钓鱼网站检测引擎,其中包括黑白名单检测机制,分析了几种查询算法的原理,并优化选择最佳的算法,黑名单检测机制主要工作是直接过滤大量已经鉴别过的网站,降低系统性能开销;引擎的第二部分是URL检测机制,通过收集现今钓鱼网站的URL,并分析这些URL的特征得到了11个钓鱼网站的URL特征,通过逻辑回归算法对其进行训练并分类;最后一部分是页面内容特征检测,结合钓鱼网站实际情况,通过每篇前K个特征选取方法,结合线性SVM算法得到高性能模型,并且通过实验对比得到最佳的页面内容特征数。3)最后介绍了钓鱼网站检测系统的整体架构设计和系统部署方式以及系统的运行性能,在架构设计中考虑了系统最为服务系统的性能问题,并设计实现了高性能的服务系统架构;在系统部署中提出了Nginx反向代理服务器作为,并分析其原理,为整个系统做负载均衡;系统性能测试先对各个检测进行训练,对比常见分类算法对于页面检测系统中的性能,然后对系统进行整体测试得到最后的检测结果。"
714,基于多核学习的支持向量机方法研究,"20世纪60年代Vapnik等人提出了统计学习理论。基于该理论,于90年代给出了一种新的学习方法――支持向量机。该方法显著优点为根据结构风险最小化归纳准则,有效地避免了过学习、维数灾难和局部极小等传统机器学习中存在的弊端,且在小样本情况下仍然具有良好的泛化能力,从而该算法受到了广泛的关注。但是,随着支持向量机的不断发展和应用,其也逐渐显现出一些局限。其一,支持向量机对孤立点和噪音数据是非常敏感的。为了解决此问题,Lin等人提出了模糊支持向量机的概念,即将样例的模糊隶属度引入到支持向量机中。模糊支持向量机在一定程度上降低了噪声点和孤立点对最终决策函数的影响,提高了支持向量机的抗噪音能力。其二,核函数与核参数的选择,对学习性能有至关重要的影响,然而目前还没有关于核函数以及核参数选取的有效手段。近年来多核学习已成为机器学习领域广大学者的研究热点。即用多个核相结合来代替单个核函数。多个核函数往往可以更加充分地刻画数据间的相似性,尤其是复杂数据间的相似性。从而多核相结合可以较准确的表达数据的相似性。作为核方法的重要成果,多核学习能够克服核函数核参数选择这一难题。本文为了同时解决核函数选择难题和对噪音数据敏感问题,将多核学习方法引入到支持向量机中,提出了多核模糊支持向量机与多核支持向量回归机。基于多核学习的模糊支持向量机方法在保持模糊支持向量机抗噪音能力的前提下,显著提高了算法效率,具有重要理论与实际意义。多核学习方法目前在支持向量回归机中应用较少,本文为了解决支持向量回归机中的核函数核参数选择难题,将基于核对齐的多核学习方法引入到支持向量回归机中。本文主要工作及取得的成果如下:1.将多个核函数直接相加的多核方法与模糊支持向量机模型相结合,提出了基于粗糙集隶属度的模糊多核支持向量机。在UCI数据上实验对比表明,本文提出的方法比经典支持向量机、模糊支持向量机和多核支持向量机在预测精度方面表现优异。2.将基于核对齐的多核学习方法引入到模糊支持向量机中,提出了基于核对齐的模糊多核支持向量机。根据最大化组合核与理想核之间的相似性,计算核权重,得到的组合核更精确地刻画数据间的相似性。在UCI数据上实验结果验证了本文所提方法有效性。3.将基于核对齐的多核学习方法引入到支持向量回归机中,提出了基于核对齐的多核支持向量回归机。实验结果表明,多核支持向量回归机在预测精度上能与最优的支持向量回归机方法保持一致甚至更好,在计算开销上,多核支持向量回归机方法要远优于支持向量回归机。"
715,基于局部差异的最小生成树功能脑网络分类研究,"复杂脑网络的分析与研究是近几年来神经精神疾病领域的研究热点。作为复杂网络理论在神经认知科学的具体应用,复杂脑网络在了解有关神经精神疾病的发病机理方面起到了很重要的作用。将图论应用于复杂网络中,会为复杂网络的研究提供更多的方向和思路。最小生成树是应用最为广泛的图论算法之一,作为新兴的有效研究手段,活跃于神经精神疾病的相关研究中。该方法能够确保脑网络的连通性,按一定规则对边进行删减,最终获得总权重最小的生成树。在进行相关指标的计算时,其结果也不会受到网络大小以及密度等因素的干扰,同时,该网络在神经学上也具有良好的可解释性。尽管这一领域已经取得许多令人惊喜的成果,但仍然存在一些亟待解决的问题。先前的研究发现,传统最小生成树的特征提取方法使用局部可量化指标来分类脑疾病,忽略了低权重的连接和集群在大脑网络中信息处理的重要作用,造成网络中一些有用信息丢失,较其他网络特征而言,其分类正确性明显偏低,特征有效性和分类准确率都将会因此下降。在此基础上,本文希望找到一种综合方法既可以最大程度实现组间差异的表征,又能提供更多更有效的分类特征,以服务分类研究。为解决这些问题,本文提出了一种在局部差异网络的基础上构建最小生成树功能网络进行特征提取的新方法。具体的创新工作如下:首先,基于网络的统计被用于识别抑郁组与对照组间功能连接强度有明显区别的连接及连接所涉及的大脑区域,作为构建局部差异网络的第一步。该方法是对大型网络进行统计分析的一种处理图上多重比较问题的非参数统计的有效方法。许多研究已经使用这种方法来识别与实验效果或组间差异相关的连接以及包含人类连接体的网络。其次,对每个局部差异子网进行最小生成树脑网络的构建。所构建的网络在确保连通性的同时,尽可能保持较高的连接强度。本文分别构建以每个脑区及其差异连接所涉及的脑区为节点的局部差异网络,在此基础上,对每个子网进行最小生成树功能连接网络的构建,进行下一步的分析研究。最后,本文对局部差异最小生成树脑网络进行分类研究。大脑作为一种复杂网络,需要对其从多方面进行量化。在每一个局部差异最小生成树脑网络上进行全局和局部指标的计算,可以获得更多可用于分类的有效特征,能在一定程度上提升分类准确率。结果表明,与传统在全脑使用最小生成树构建脑网络的分类方法相比,本文的方法能够提供更多的有效特征,这将使分类准确率有明显的提升。本文为今后在脑网络拓扑属性分析及机器学习应用方面,对网络构建以及特征提取提供重要的可参考依据,也为医学辅助诊断和脑科学特别是脑疾病的研究提供一定的帮助。本文是国家自然科学基金项目《静息态功能脑网络高阶复杂时空效应分析及建模研究》(61876124)的主要组成部分。研究工作还得到了山西省科技厅应用基础研究项目(201801D121135),山西省教育厅高等学校科技创新研究项目(2016139),山西省科技厅重点研发计划项目(201803D31043),教育部赛尔网络下一代互联网技术创新项目(NGII20170712)的支持。本文的关键是在局部差异最小生成树脑网络上进行相关的研究,以及发掘脑疾病患者在其脑网络上发生的改变,希望能获得可以为脑疾病早期诊断起到一定帮助的标志物。这一课题在国际和国内都非常热门且重要。"
716,多节点规模下的功能网络拓扑属性分析及分类研究,"利用脑网络模板对脑网络进行构建是当前脑网络疾病领域的一个研究重点,该方法为脑神经疾病的诊断提供了一种更有效的技术。研究发现,不同模板定义下的网络节点规模的差异对网络的结构及其拓扑属性会产生极大影响。然而,传统单一模板构建的网络忽略了节点的规模,也缺乏不同节点规模对拓扑属性可信度影响的探究。同时,对于机器学习方法中网络节点规模的差异是如何影响网络结构、分类准确率的仍在研究中。为解决这些问题,本文在前人的基础上,针对节点规模对网络拓扑属性、分类特征表现、选择策略及分类准确率的影响进行深入研究。以下为本文的主要工作:第一,定义多节点模板并构建网络。本文使用纽约大学公开的正常被试的数据集和山西医科大学抑郁症的数据集分别进行脑区划分,得到五个不同节点数量的脑网络。第二,探究不同节点数量对拓扑属性的影响。对纽约大学公开的正常被试的数据集构建的不同节点规模的脑网络的局部属性进行提取,然后对比拓扑属性的差异,最后对脑网络的功能连接和网络拓扑属性的可靠性进行分析。第三,探究节点规模对分类特征的选择及性能的影响。首先提取抑郁症数据集构建的不同节点规模的脑网络的局部属性,然后通过K-S检验法在局部属性之间进行统计分析,经过判断,选取判别性特征(显著性差异的属性)作为分类特征,采用SVM对抑郁症与正常人进行分类。第四,使用最大相关最小冗余法对特征间的冗余性进行分析,并判断不同节点规模的脑区间的距离对冗余度的影响与传统的统计显著性的特征选择方法在不同节点规模的可行性,最后检验实验中高维特征是否存在过拟合问题。综合考量发现,随着空间节点数量的增加,网络结构的可靠性在逐渐提高,分类效果也在不断改善。结果表明,不同节点规模得到的特征有效性相当,即节点数量多的模板虽然不能提供更有效的特征,但是,却可以提供更多的有效特征,这将导致分类准确率的提升。同时,节点数量多的模板由于脑区间距离更接近,特征间的冗余程度也在增强。文中还发现传统的统计显著性的特征选择方法在不同节点规模下均可行,但分析结果表明,传统的0.05的阈值设置过于严格。本研究得到国家自然科学基金(61672374,61741212,61876124,61873178),山西省自然科学基金(201601D021073,201801D121135),山西省高校科技创新项目(2016139)的研究资助。山西省重点研发(R&D)项目(201803D31043)。本文的研究重点在于多节点模板定义及网络构建,在此基础上进一步探讨了网络节点规模对网络拓扑属性以及分类特征的选择及性能的影响。本文为今后将脑网络拓扑属性应用到机器学习方法时,为构建网络选择合适的模板提供了一定的参考价值。"
717,基于BP和LSTM神经网络的基因表达预测研究,"随着生命科学和计算机科学的迅猛发展,生物数据呈指数级增长,在质量和数量上都极大地丰富了生物信息学的数据资源,为解开生命奥秘提供了数据基础。基因芯片技术作为分子生物学在实验领域的一项重大突破,被应用于测量基因的表达水平,为探索生命的本质提供了极大的便利,成为探究生命奥妙的重要工具之一。基因表达谱是在基因芯片的基础上,通过杂交测序方法,利用探针标记所得互补序列而来。根据基因在不同条件下表达的差异,利用基因表达谱可以进行环境检测和防治、药物筛选、基因功能发现、复杂疾病诊断、个性化治疗、农作物优育优选及司法鉴定等。因此研究基因表达谱具有重要的理论价值和应用意义。尽管获取全基因组表达谱的成本在逐步下降,然而基于基因芯片技术产生数千甚至上万条基因表达谱数据,不仅生物过程繁杂,而且一般的实验室无法承担这一高额的费用。NIH LINCS研究人员分析了约1000个精心挑选的landmark基因,并依托线性回归的方法推测剩余target基因的表达。但是线性回归预测基因表达的方法往往忽略了基因表达谱数据的非线性特征,无法精确的预测基因表达。BP神经网络可以提取输入和输出数据之间较为复杂的非线性映射,LSTM神经网络可以捕获输入数据之间的相互作用,将二者结合起来可以方便的从原始数据中抽取高级特征表示。通常,大多数基因表达谱数据通常具有样本少且维数高的特点,因此使用深度学习算法拟合基因表达谱数据非常容易出现过拟合现象。本文针对以上问题,利用BP和LSTM神经网络提取基因表达谱数据的非线性特征的同时,引入迁移学习策略和正则化技术,有效解决了深度学习算法在小数据集上容易过拟合的问题。鉴于此,本文开展了基于DCIOBP和LSTM的基因表达预测研究。研究内容如下:(1)针对原始基因表达谱数据维度高,且存在冗余基因和无关基因的特点,本文利用无监督聚类算法K-means对原始基因表达谱数据进行去重处理。为了消除实验技术所引起的表达量的变化,并使每个样本的数据和平行实验处于同一水平,本文将去重后的数据进行标准化和归一化处理,为回归预测模型的构建做好数据准备。(2)针对传统的线性回归方法预测基因表达,忽略了输入和输出数据之间的非线性特征的问题,本文采用BP神经网络自动提取landmark基因和target基因之间的非线性特征,再结合输入到输出的直接连接方法,将输入数据和输出数据之间的线性特征添加到预测模型中,综合考虑landmark基因与target基因之间的线性和非线性特征,提升模型的预测能力。(3)为了提升基因表达回归预测精度,本文利用LSTM神经网络自身的门控单元,捕获输入数据landmark基因的长期依赖信息,结合第三章所提出的基因表达回归预测模型,预测target基因的表达;通过引入迁移学习策略和正则化技术,解决了深度学习模型拟合小数据集时容易过拟合的问题,并且提升了回归预测模型的跨平台预测能力。"
718,基于深度学习的太阳射电分类问题的研究与实现,"太阳射电爆发通常发生在强烈的太阳活动期间,它们携带着有关爆发区域的物理环境和辐射条件的重要信息。因此,研究太阳射电爆发可以了解爆发区域的磁场结构和粒子运动特征,具有很高的实用意义。一般来说,太阳射电需要具有专业知识的天文学家进行手工分类,这种方法费时费力。近些年来,研究人员尝试使用传统的机器学习方法来实现太阳射电的自动分类。使用机器学习的方法通常需要手动设计特征用于描述图片,而太阳射电图片中携带的信息很复杂,因此设计的特征通常很复杂,并且很难准确描述图片深层次信息,这对分类的准确率会造成很大的影响。随着深度学习技术的飞速发展,它在图像分类领域也取得了很大的突破,本文提出了基于深度学习的太阳射电分类方法。首先,我们借助主成分分析法对射电频谱图进行降维,然后根据该频谱图的特点,提出了一种矩形的卷积核进行图片特征的提取;另外,针对太阳射电数据集中各类别样本数量分布不均衡的问题,我们提出了一种两阶段的策略来解决。第一阶段,我们使用生成新样本和重采样原始样本的方法来补充样本数量较少的类别;第二阶段,我们提出一个代价敏感的多分类损失函数,用于在训练的过程中让网络更加关注样本数量较少的类别。总体来说,我们先借助样本增强策略对样本量进行补充用于之后的训练,然后利用所提出的损失函数,最终可以训练得到太阳射电分类器。我们在太阳射电频谱数据库上进行了实验,并与其它方法进行了比较,实验结果表明我们的方法能取得良好的分类效果。"
719,集成机器学习与面向对象影像分类的大区域林地信息提取及其泛化能力研究,"森林在陆地生态系统中起着调节气候、涵养水源等方面的作用,是国家可持续发展战略的重要物质基础。准确获取林地空间分布有助于林地变化监测且通过对其变化的分析,制定相应保护管理政策。遥感技术的发展可以为生态监测和大面积森林资源清查提供经济有效的手段。利用遥感技术获取林地信息时,传统的目视解译属于劳动密集型信息提取工作,资源耗费巨大。与计算机相结合的遥感技术大大提高信息提取的自动化,其中,借助机器学习法是其中一个重要的研究方向。当前机器学习法在应用到特定的遥感影像分类中,普遍属于逐景训练、逐景分类的模式,存在训练样本重复选取以及分类过程中模型参数消耗等问题。对于跨越几十甚至上百景遥感影像广泛的研究区域,如何通过在小面积典型区域内建立的机器学习模型实现大范围研究区内高精度的林地信息提取,有待探索。机器学习方法中分类器正确分类训练集以外数据的能力称之为泛化能力,也称为预测能力。泛化能力是评价分类器所生成的算法好坏的重要指标。泛化能力越强,预测精度越高。选择泛化能力高的分类器从而使之有效用于训练集之外其它数据集,对于实现机器学习模型的可移植性至关重要。为了能够从多景多时相批量遥感影像中高质量地提取出跨越大地理区域的遥感影像林地信息,有必要探索一种具有更高泛化能力的机器学习算法。研究立足于两点来探究机器学习对于大区域林地信息提取的泛化能力。首先是好的机器学习分类器的使用,本文从众多机器学习法的研究中选取当前主流的三种机器学习算法,包括支持向量机、随机森林、深度神经网络。集成面向对象的影像分析法,进行机器学习分类器最优模型的构建。其次是针对当前遥感影像逐景训练、逐景分类的模式,考虑从研究区中选取小面积典型区域内的训练样本,对所选取的机器学习分类器分别进行训练,利用训练的最优分类器实现整个研究区林地信息的提取。通过对整个研究区林地提取精度及接边一致性等方面综合评价所选机器学习分类器的泛化能力。(1)针对大部分遥感影像采用逐景训练、逐景分类的信息提取模式,文中通过实验论证了在小面积区域的代表性数据上建立的最优机器学习分类器,可以应用到整个研究区域数据上,甚至可应用到相近时间、类似的数据上。证明文中所提出的遥感信息提取框架的合理性。同时该信息提取框架减少了分类器建立过程中的参数消耗和样本的重复性选取工作。通过小样本选取即可实现批量遥感影像得高精度信息提取,大大降低样本依赖性,提高了遥感信息提取效率。(2)采用集成面向对象与机器学习的方法,基于祁连山针叶林典型样区构建了支持向量机、随机森林、深度神经网络的最优模型。利用文中提出的信息提取框架对比三种机器学习分类器的在时间和空间上的泛化能力。整体来看,深度神经网络无论在空间还是时间上均表现出最高的泛化能力,其次是随机森林和支持向量机。当前多数分类回归等学习法为浅层结构算法,相对于浅层学习如支持向量机和集成学习随机森林,深度神经网络利用“层次化”的信息拟合复杂的非线性函数。文中构建深度神经网络时集成面向对象的影像分析法,对于所提取的反映针叶林信息的多个特征,采用Relief F-Cfs-Pso组合过滤式特征优选方式实现降维。减少输入变量的数量,利用每层更少的神经元拟合更加复杂的函数。通过消除多隐层间的冗余信息,最终确定4隐层的网络可实现较高的泛化能力。(3)对三种分类器在时空泛化能力的差异性进行分析表明三种分类器的在空间上的泛化能力均高于时间上的泛化能力。原因在于最优模型是在探讨空间泛化能力时所构建,并将该模型直接用于时间段相差较大的另一期影像的信息提取中,导致了精度的下降。因此,对于最优的深度神经网络的优化问题,通过改变样本即增加另一期影像的典型样区样本,直接用深度神经网络进行整个研究区的信息提取,提取结果在分类精度以及多景影像的接边一致性等方面精度均有所提高。证明可通过新增加典型样区,达到提高神经网络信息提取精度的目的。(4)基于最优模型就提取的两期精度最高的祁连山针叶林信息,分析近20年针叶林面积的时空变化以及景格局指标发现相比于2000年,针叶林在2017年整体增加423.88km~2,增加了11.14%。从景观格局角度来看,整体破碎度增大,景观形状边界变得复杂。受人为干扰整体减小。针叶林分布情况整体呈现出较好的局势。但局部地区林地发展不均衡。具体来看,祁连山东、中、西以及县级行政区划的面积、景观指标变化情况表明地方之间林地长势参差不齐。保护区内居民毁林草开荒种地现象一直存在,林木矛盾等使得祁连山西段中的肃南裕固族自治县林地近20年减少212.15km2。祁连山东段林地面积虽然整体呈现增加趋势,但位于东段的天祝地区林地退化严重,景观格局破碎,受人为活动的干扰致使景观形态简单。位于青海省的门源回族自治县和湟中县因退耕还林(草)的政策林地的面积得到大幅增长,景观的斑块更加紧凑,整体形态更加简单。因此针叶林虽然在整体上得到很大的改善,但局部地区林地情况不均衡,仍然存在恶化现象。需因地制宜地加强相关保护管理政策的有力实施,并加强后期的监测与评估。"
720,基于流动重力与统计学方法的地震危险区划分研究,"地震作为一种危害性极大的自然灾害,严重的威胁了人民的生命财产安全和社会经济的发展,因此提前划分地震危险区对于防震减灾具有重要意义。然而,人们对于地震的准确预测尚为世界性难题,地震的孕育、发展和发生的过程极为复杂,且影响地震产生的因素众多,这些因素与地震的发生呈现了高度的非线性关系~([1])。流动重力数据一直以来被科研人员作为有效的地震前兆信息,应用于地震危险区的划分和判断研究中。其中,震前重力的异常变化与孕震过程联系紧密,这一现象在一些典型地震的解剖中得到有效验证,如汶川Ms8.0、于田Ms7.3、芦山Ms7.0、姚安Ms6.0等。这些地震出现了显著的地震前兆标志,即重力正负变化低值带或高低变化的四象限分布特征。本文就是在前人研究的基础上,利用流动重力数据资料、地震目录数据和全国断层分布数据建立了一套新的地震危险区划分方法。首先本文基于地震目录数据,根据地震发生的时空位置,利用点密度分析中的核密度算法,计算并绘制出了区域长期的发震背景信息,为地震趋势判断提供参考。围绕地震的发生与断层空间分布密切相关,以及地震发生成条带状这一特点,应用了断裂缓冲区这一概念。基于断裂缓冲区,本文统计得到主要活动断裂的活动性指标,提出了统计活动性和相对活动性断裂的概念,划分出有发震能力的断裂带及其影响的区域范围。最后将断裂缓冲区应用到b值的计算中,利用了计算断裂的b值的方法,并且评估了该方法应用于地震危险区评估的可能性。为了解决震前重力异常模式主要依据研究人员经验判读,无法自动识别和划分重力危险区域这一局限。本文还利用机器学习算法,依据重力场时空变化图像,进行地震前兆特征的机器自动识别。首先基于历年的发震实例建立数据样本库,并利用线下增强学习的算法扩充了数据样本库。之后利用机器学习算法,训练样本库数据,建立神经网络模型。最后通过""人脸定位""方法对流动重力监测所获得的重力变化图像中的重力异常部位进行定位识别,从而自动完成重力学地震前兆的图像判读。结合发震断裂空间范围、b值计算结果以及机器学习算法所识别的重力异常区,综合给出地震危险区,可对未来地震进行预测评估。"
721,基于大数据处理技术的提升机制动系统故障诊断,"能源开采作为我国的重要经济产业,其能否安全生产倍受关注。矿井提升机是煤矿开采中重要的机械设备之一,承担着煤矿矸石与生产工作人员的提升与下放任务,提升设备的安全运行对煤矿安全生产,尤其是工作人员的生命安全影响重大。可靠的制动系统是提升设备安全正常运转的必要保障,随着监测技术的不断完善,基于运行工况的提升设备监测数据出现了数据量大、属性冗杂等大数据特点,这些数据的处理和合理应用是开展制动系统故障诊断研究的关键。本文以矿井提升机为研究对象,提出了基于大数据处理技术的提升机制动系统故障诊断方法,在对提升机制动系统的故障机理及数据特点分析的基础上,研究了数据获取及数据处理等方法,并利用机器学习算法生成的故障诊断规则对提升机制动系统进行故障诊断与预测。主要研究内容如下:第一,建立了基于大数据技术的制动系统故障诊断体系结构。分析了矿井提升机制动系统的结构及工作原理,研究了制动系统的常见故障机理,并分析了制动系统故障数据特点;建立了基于大数据技术的制动系统故障诊断体系结构。第二,基于SPSS的数据分析方法对监测数据进行了分析与处理。深入分析了适合本文分析的故障类型,选取了提升机在线监测系统的相关监测参数,并对故障数据进行筛选和离散化处理,基于SPSS软件对监测数据进行分析,得到了表征提升机的状态信息的相关属性及属性间的相关关系。第三,提出了改进的C4.5故障诊断分类算法,并获得了良好的分类效果。详细分析了决策树的常用算法,对其构建步骤进行了比较,然后引入肯德尔和谐系数对C4.5算法进行了改进,并基于Python语言实现了该算法。经实例验证该算法具有良好的故障分类效果。第四,基于以上理论和方法,以实验室2JTP-1.2型提升机作为试验设备,对算法生成的诊断模型进行了试验验证。通过模拟试验故障采集故障数据,利用诊断规则进行故障诊断和预测,对不同算法生成的诊断规则进行对比验证。本文提出的基于大数据处理技术的提升机制动系统故障诊断方法,经试验验证,能够解决提升机制动系统故障诊断中的数据量大难以处理、特征属性之间的相关性考虑不足、数据利用率低等问题,同时该方法生成的诊断规则准确率较高,可以应用于实际生产,从而有效地保障煤矿安全。"
722,重介分选智能控制系统设计及过程数据分析研究与应用,"重介分选过程是选煤厂生产过程中的一个重要环节,同时悬浮液密度的精确度直接关系到精煤产率,其中通过控制分流和补水是目前主要调整悬浮液密度的操作方法,在此基础上不断地出现了各种自动分选控制系统,系统的控制效率以及算法的精确度也成为了保证生产的重要指标,同时在互联网技术鼎盛发展的时代下,智能化技术的提出使得工业现场全方面都有了革新性技术提升,实现以智能化技术为基础的智能化选煤厂也成为了当今选煤行业主要的发展目标。本文结合物联网、大数据、云计算等技术,对选煤厂重介分选过程设计了一套智能化控制系统,同时通过数据分析和机器学习实现对分流过程的优化控制,开发了远程移动端信息平台,并结合云计算资源完成整个选煤厂生产管理全过程的管控,最终实现重介分选工艺过程的智能化控制和数据治理。传统的重介分选控制系统主要是依靠本地网络连接,PLC做逻辑控制,工控机做人机组态界面,对于智能远程控制、过程数据存储、数据处理分析和平台资源管控方面并没有过多的关注,只实现了基本的动作控制,实际应用过程中还存在很多问题,需要人员实时参与。本文结合工业物联网框架,设计了一套基于Spring Boot MVC架构的Web远程控制系统,通过Modbus/TCP技术完成数据通讯交互,并且使用Mybatis整合Mysql设计了一套重介分选系统数据库,实现了重介分选智能化控制,并在现场进行了实际测试,测测结果能够满足正常生产要求。重介分选过程分流控制是一个非线性、大滞后的过程,通过对重介分选过程数据的分析,建立了分流阀开度预测模型,利用Python语言进行机器学习训练,使用支持向量机算法进行了分类,选取了200组数据进行仿真,结合阀门流量特性曲线以及稀介桶液位得到对应的分流阀预测分类,当补水和分流取较小值使得系统更加稳定,最终得到分流阀开度的优化设计。重介分选智能化控制是智能化选煤厂建设的一个环节,对于智能化选煤厂建设来说,提出了基于混合云平台的远程运维解决方案,通过云平台管理选煤厂的生产信息、调度信息、设备信息等,实现了重介分选控制系统与选煤厂管理系统的接入,同时对数据进行云存储管理,对数据进行备份分析等操作;从安全上来说,结合云安全各项技术无缝保护混合云系统的数据和运维安全;设计基于APICloud的移动端远程控制平台,使得整个选煤厂能够便捷、实时的得到整个选煤厂乃至集团的各种信息。系统已经在该厂重介车间进行试运行,整个系统运行状态良好,对分流阀的分类预测也能够保持在准确率95%左右,同时有效的收集了多种工艺和设备数据,为进一步进行数据分析提供了有效资源,同时对于集团公司领导和调度人员来说,远程的Web系统使得他们足不出户就可以了解到现场实际情况,大大减轻了工作量,而智能化系统的应用也为整个选煤行业进行数字化、自动化、信息化建设开辟了新的道路。"
723,采煤机与刮板输送机协同位姿监测理论与方法研究,"随着我国科技的快速发展与能源生产、消费理念的转型升级,煤炭开采方式不断向绿色智能方向发展,采煤机与刮板输送机都是综采工作面的重要设备,且两者具有紧密的协同运动关系,实现采煤机与刮板输送机位姿的实时准确监测是保证采煤机与刮板输送机能安全高效生产的重要条件。当前采煤机与刮板输送机的监测主要针对单机的姿态与位置研究,将采煤机和刮板输送机进行有效的协同监测的研究很少,且已有研究主要还是集中在理想的水平工作面条件下,没有考虑复杂工况下底板不平整的井下实际情况,对刮板输送机形态的研究忽略了地形条件的情况。本文分析了采煤机与刮板输送机的协同运动关系,建立采煤机与刮板输送机协同监测方法,利用捷联惯导系统建立采煤机与刮板输送机协同监测的物理传感体系,对采煤机在刮板输送机上运动时的形态耦合关系进行分析,建立了基于采煤机运行路径中姿态与位置信息的刮板输送机三维空间形态计算方法,并搭建了采煤机与刮板输送机协同试验平台进行试验验证,利用滚动预测方法与两种机器学习算法结合对刮板输送机的工作形态进行预测。主要研究内容和成果如下:(1)对采煤机与刮板输送机协同运动时的原理、接触关系进行了研究,利用采煤机上搭载的捷联惯导系统解算得到了采煤机在刮板输送机上运动时的俯仰角、航向角与采煤机在刮板输送机上的位置。(2)分析采煤机与刮板输送机中部槽的实时形状耦合关系,建立了基于采煤机运行轨迹的刮板输送机竖直面形态计算模型,通过检测刮板输送机部分中部槽的俯仰角作为先验信息,滚动计算出采煤机运行过程中所经过各节中部槽的俯仰角,得到刮板输送机在竖直工作面的形态。可实时准确地掌握刮板输送机竖直面的工作形态,通过调节滚筒高度控制刮板输送机形态,使其保持正常工作状态,使采煤机可以在刮板输送机上正常行走。(3)构建了刮板输送机水平面形态计算方法,可计算出刮板输送机各中部槽的航向角,得到水平面刮板输送机的工作形态,与竖直面刮板输送机形态计算法结合,可得到三维空间刮板输送机形态。实时得到刮板输送机水平面形态,可为液压支架的推移机构的推移距离提供依据,保证综采工作面的直线度。(4)通过使用基于滚动预测方法的支持向量机与极限学习机模型进行刮板输送机形态的预测,并对两者的预测结果进行比较。刮板输送机的竖直面形态由采煤机下滚筒截割形成的底板决定,预测出刮板输送机形态可为采煤机下滚筒截割路径的规划提供位置依据,保证刮板输送机在竖直面有适宜的工作形态。"
724,基于机器学习的液压泵装配质量检测技术研究,"随着人力劳动成本的攀升,在装配生产线上自动化和智能化的需求越来越高。尤其是在一些微小精密零件的生产装配线上,高强度高精度的要求往往是人力检测达不到。本文针对液压泵零件装配质量提出了高效智能的检测方法,它应用机器学习的手段检测液压泵的叶片零件在装配过程中出现的问题。在硬件系统章节,参考传统机器视觉系统的架构,并根据液压泵零件图像的特点设计一套合适的硬件系统,包括相机、光源、镜头和主机的信息,并给出检测系统中每个硬件的关键参数以及选择每个硬件的标准。综合成本、性能等因素提出了一套合理的机器视觉方案。在图像分割章节,主要研究液压泵图像中的叶片提取算法。先是介绍阈值分割法和边缘分割法等常用图像分割方法,然后分析液压泵装配图像的特点,发现液压泵零件图像本身有丰富的几何特征,例如由许多环形和矩形组成。利用底座图像是个圆环的特点,提出通过霍夫圆检测手段检测出底座和叶片的图像,然后通过坐标变换将其转换到极坐标系中,最后对极坐标系中的底座和叶片图像进行像素投影从而得到叶片图像。在图像特征章节,首先简单介绍了图像特征中的角点特征和局部二值模式(LBP)特征。研究了叶片图像在不同安装状态下的特点和各种特征的应用范围,然后提出一种新特征Gabor灰度共生矩阵混合特征去识别叶片的装配质量并且相比于其它特征有10%的效果提高。在分类器章节中,对比经典的模式识别中的分类器逻辑回归分类器和支持向量机(SVM)分类器。根据液压泵零件装配图样本短缺的情况和图像特征的特点提出使用支持向量机分类器对叶片装配质量进行检测,使得液压泵装配质量检测系统检测准确率达到了0.916。最后借鉴在目标跟踪领域中算法的在线学习系统和分类器的更新策略,设计了支持向量机在线学习方案,使液压泵装配质量检测系统更加智能,更好适应外界环境的变化,同时降低设备维护成本。"
725,齿轮箱故障诊断测点敏感性的研究,"齿轮失效是诱发机器产生故障的重要原因。因此对齿轮进行故障诊断对于降低设备维修费用、防止突发性事故具有重要意义。基于振动信号的齿轮故障预测和故障诊断,是最广泛采用的方法。振动加速度传感器在齿轮箱的安装位置,将直接影响振动信号对齿轮故障的敏感程度。本文研究了振动传感器安装位置对故障诊断的影响,主要内容如下:(1)根据齿轮箱故障诊断中对原始振动信息的获取,提出了使用加速度传感器在齿轮箱上获取的振动信号时应该将其布置在对振动信号最优的测点位置。实验通过三维布置法(即法向、轴向和轴承位置)使的加速度传感器能够采集到X,Y,Z三个方向的振动数据,并对三个不同位置的传感器采集的数据进行分析对比,从而得出对故障信息最敏感的位置。(2)运用了时域同步平均去噪方法对三个测点位置所采集的振动信号进行预处理,接着通过选取合适的故障特征参数指标对去完噪后的振动信息进行全生命周期上的对比和分析,通过比较不同时期不同测点对故障发生时的及时性和准确性,从而得出加速度传感器的最佳测点位置。对比分析后发现齿轮箱上对振动信号最敏感的位置应为轴承测点位置。(3)针对所得出的敏感测点位置,运用全连接多层感知器对其再辅以验证。选取在轴承位置采集故障振动信号和正常轴承信号,并在不对信号做任何预处理的情况下直接输入到网络模型中,通过观察多层感知器输出的故障分类正确率从而验证了轴承位置所采集的振动数据的确有着较为优质的信号特性。"
726,旋风分离器的性能建模及多目标粒子群优化,"旋风分离器是气固分离器中应用最广泛的设备,它是一种依靠离心力将固体颗粒从气流中分离出来的分离器。由于结构简单维修方便等原因,它被广泛的应用在了化工、能源和环保等领域。效率和压降是旋风分离器的两个相互矛盾的性能参数,追求高效低阻的旋风分离器设计是一个复杂的多目标优化问题。在旋风分离器的多目标优化问题中目标函数一般有理论与半经验模型、计算流体动力学模型和元模型三种形式。其中,不同的理论与半经验模型的计算结果由于采用了不同的假设和简化条件会有很大的偏差,而计算流体动力学模型又是一个耗时耗费的工作且不适于应用在迭代优化任务中,因此构建一个由实验数据或模拟计算数据通过复杂过程建模得到的简单有效的元模型是非常有意义的。为了清晰地描述效率、压降与旋风分离器的结构参数和操作条件之间的复杂非线性关系,采用基于主元分析法(Principal Component Analysis,PCA)和粒子群优化(Particle Swarm Optimization,PSO)技术的支持向量回归算法(Support Vector Regression,SVR)对旋风分离器的粒级效率和压降进行建模。利用主元分析法、随机抽样技术和归一化方法对文献中提供的实验数据进行预处理,然后通过粒子群优化算法确定支持向量回归模型中的惩罚系数C、核函数的参数g和不敏感损失ε,最后用80%的预处理数据对已获得优化参数的SVR模型进行训练,用剩余的20%数据测试模型的泛化能力。将PCA、PSO和SVR三种算法耦合在一起的PCA-PSO-SVR模型对粒级效率和压降的测试集进行预测的均方误差分别为6.948e-4和8.982e-4,相关系数分别为0.982和0.990,通过比较说明该模型比现有旋风分离器效率和压降的理论与半经验模型、元模型具有更高的准确性、泛化能力和鲁棒性。将这两个元模型作为目标函数应用到多级串联旋风分离器的多目标优化设计会得到更好的结果。旋风分离器是气固分离的重要设备,然而在大多数工业中,单级的旋风分离器并不能满足生产的需要,需要用到三个甚至更多旋风分离器串联起来协同工作。但目前有关多级串联旋风分离器的研究较少,而且大多数的旋风分离器的结构优化研究只针对提高效率和降低压降两个目标并没有考虑如何降低成本。本文利用多目标粒子群优化算法(Multi-objective Particle Swarm Optimization,MOPSO)以建立的两个PCA-PSO-SVR模型和成本为目标函数对三级串联PV型旋风分离器的入口截面比K_a、排气管下口直径比(?)和筒体直径D在固定入口流量的情况下进行多目标优化。这种多目标优化方法为多级串联旋风分离器的设计提供了一种新的方法,它的结果是得到了一组权衡压降、效率和成本关系的Pareto最优解。"
727,基于机器学习的卫星参数关联挖掘,"空间科学先导专项地面支撑系统是支撑硬X射线调制望远镜卫星(HXMT卫星)等空间科学任务卫星在轨运行的重要服务平台。对卫星在轨运行期间产生的大量参数数据进行事后分析,掌握星上设备的在轨状态和性能变化趋势,是地面支撑系统的主要任务之一。挖掘卫星参数之间的关联关系,提取参数之间蕴含的客观联系与规律,是进行事后分析的重要方法和基础,具有很高的实际应用价值。本文分析调研了现有的相关性分析算法,并基于现有算法,结合卫星参数数据的特点,设计出多种基于LightGBM机器学习模型的卫星参数关联挖掘算法,通过HXMT卫星在轨真实数据的实验验证,表明所设计的卫星参数关联挖掘算法能够将高度关联的参数组从海量参数中筛选出来。根据卫星参数数量众多、取值情况复杂的特点,本文首先将HXMT卫星参数根据参数取值的种类数量,分成二分类参数、多分类参数和回归参数;并将卫星关联挖掘算法根据参与分析的参数数量,分成卫星单参数关联挖掘算法和卫星多参数关联挖掘算法。本文设计的基于LightGBM机器学习算法模型的卫星单参数关联挖掘算法,该算法利用LightGBM算法能够量化建模所用特征的重要性的特点,可以快速评估海量参数之间的相关性程度,适用于卫星参数中的二分类参数。本文使用HXMT在轨真实参数数据进行试验验证,结果表明,当目标参数和单一参数高度相关时,能够顺利找出此参数组合,但也发现更多的参数是和多个参数之间有较强的相关性。本文设计的初步筛选和进阶筛选两种卫星多参数关联挖掘算法,适用于全部种类的卫星参数。其中,初步筛选算法根据参与分析的卫星参数总量,动态调整算法每轮迭代增加的参数数量区间的长度,算法灵活且复杂度低,思路简洁朴素,目的是为了快速缩小高相关参数的搜索范围;进阶筛选算法为求识别精准,每轮迭代只将当前参数集合中相关程度最高的参数选出,经过多轮迭代后最终获得全部的高相关参数,算法复杂度较高。本文使用HXMT在轨真实参数数据进行试验验证,结果表明,对于参数只有两种取值的二分类参数,可以准确挖掘出所有和目标参数高度相关的参数集合;对于参数取值种类数多于两种的,取值情况更复杂多变的多分类参数和回归参数,算法能够将关联性较高的参数集合初步筛选出来。本文结合卫星参数特点,设计了参数关联挖掘算法,通过实验验证,能够从海量参数中挖掘出所关注的目标参数的高度关联的参数集合,本论文的研究成果可用于空间科学任务在轨状态实时监视系统。这表明本文提出的基于机器学习模型的关联挖掘算法有较高的实际应用价值,为空间科学卫星在轨参数数据进行事后分析提供了重要的参考意见。"
728,基于机器学习的卫星在轨运行状态判别方法研究,"随着我国航天事业的不断发展,卫星的发射数量越来越多。为了保障卫星正常运行,获取卫星在轨运行状态,需要对卫星进行实时监视。当前,地面监视人员主要通过监视由专家总结出的重要遥测参数的阈值,来判断卫星在轨运行状态,这种方法存在较多缺点,比如系统需要预先设置大量阈值、阈值的设定依赖于专家经验、系统可扩展性较差,当需要监视的卫星由于性能变化使参数阈值发生变化时,需要重新设定。针对这些问题,论文以量子科学实验卫星为例,开展基于机器学习的卫星在轨运行状态判别方法研究,使得能够自动判别卫星的在轨运行状态,本文的研究内容具有重要的研究意义和实用价值。本文的主要工作内容及创新点如下:1、以量子科学实验卫星为例,分析卫星遥测数据的组成与特性论文调研了卫星遥测参数分析的研究现状,分析了量子科学实验卫星遥测参数的组成与统计特性,并对量子科学实验卫星的单维遥测参数间存在的相关关系进行分析与挖掘。2、量子科学实验卫星在轨运行状态判别问题的分析与建模量子科学实验卫星在轨运行期间会产生大量遥测数据,这些遥测数据能够反映量子科学实验卫星的在轨运行状态,包括卫星完成的光学实验类型、光学实验是否成功完成以及有效载荷的工作模式等。首先,论文根据量子科学实验卫星遥测数据与星上光学实验类型的对应关系,以量子科学实验卫星遥测数据为原象,以星上光学实验类型为象建立了表示这种对应关系的数学模型,使得模型能根据卫星遥测数据判断卫星完成的光学实验类型。其次,针对量子科学实验卫星在星地量子纠缠分发实验过程中有星地单向纠缠分发和星地双向纠缠分发两种工作模式,论文建立了以遥测数据为原象,以有效载荷的两种工作模式为象的数学模型。结合机器学习理论,量子科学实验卫星光学实验类型的判别模型可以抽象为多元分类问题,载荷工作模式的判别模型可以抽象为二分类问题。论文选择不同的机器学习算法对上述模型进行训练。3、实验数据集的集成与预处理,以及基于不同机器学习算法对卫星在轨运行状态判别模型进行训练与验证针对量子科学实验卫星遥测数据的特性,设计了遥测数据预处理方法。为了获取量子科学实验卫星在轨运行期间完成的光学实验类型以及有效载荷工作模式,论文对量子科学实验卫星的短期科学实验计划文件进行解析并提取相关内容。将卫星的遥测数据与光学实验类型、有效载荷工作模式数据,根据时间对应关系进行数据集成,得到用于模型训练的数据集。论文对现有的机器学习算法进行调研,选取适合论文所建数学模型的机器学习算法,在量子科学实验卫星的历史遥测数据集上对所建模型进行训练与验证,并对实验结果进行分析。实验结果表明,论文提出的方法在没有专家先验知识的前提下,判别准确率达到99%以上,实验结果具有较强的可信度。此外,将机器学习技术应用于卫星的地面监视工作,可以提高地面监视人员的工作效率。本文的提出的方法具有较强的可扩展性,可以方便的用于其他卫星的监视工作中。"
729,改进DCNN算法及其在无人机目标识别中应用,"深度学习在无人机感知与规避中的研究是近些年来的热门方向。利用深度学习的方法对无人机视觉范围内捕捉到的画面进行分析,能够更好的感知周围的环境,有效地规避障碍物以及规划更优的航迹路线。本文研究分析了深度学习在图像分类、目标检测、人脸识别、人脸关键点检测的发展过程及其应用。对现有深度学习算法进行了改进,并应用于无人机目标识别,取得了较好的成果。本文主要研究内容为以下几个方面:(1)在深度卷积神经网络(DCNN)的基础上,对经典的深度残差网络进行改进,提出了一种多捷联式残差网络模型。将两层残差学习模块与三层残差学习模块结合使用,设计出一种占用内存更小、时间复杂度更低的多捷联式残差网络模型(Mu-ResNet)。通过搭建多种不同深度的多捷联式残差网络进行实验研究,在cifar10数据集上进行分类训练,最终测试结果显示Mu-ResNet的整体性能较ResNet有所提升,且加深网络也未出现退化现象。(2)对经典的区域建议网络(RPN)进行改进,提出一种级联区域建议网络(CRPN)的搜索模式。将设计出的级联区域建议网络(CRPN)与多捷联式残差网络(Mu-ResNet)结合。由于级联区域建议网络对不同大小尺寸的特征图进行区域搜索,大大减小了计算量,并且对图像中小目标检测的效果更好。采用MuResNet与CRPN结合的网络模型在无人机目标数据集以及PASCAL VOC数据集上进行多目标识别测试,较使用ResNet与RPN结合的网络模型,识别准确率得到了较大的提升。(3)对人脸识别和人脸关键点检测的特性,在多捷联式残差网络和级联区域建议网络的基础上,设计出了一种基于特征点修正的人脸识别算法,对目标分类识别中检测到的行人进行细分类(人脸识别)。该算法将人脸识别与人脸关键点检测用同一个卷积神经网络完成,且通过检测出的关键点位置修正人脸识别框,实验表明我们的算法在FDDB数据集上能得到更好的识别准确率,召回率和关键点的平均误差。在无人机目标数据集中对行人的人脸识别也取得了较好的效果。本文所提出的各种算法均采用Matlab、python以及C/C++语言在内存为8g的GPU的计算机下开发和调试。无人机目标检测数据集为大量无人机航拍图像,算法除了在自己的采集的数据集上完成仿真实验,也在公开数据集(cifar10、PASCAL VOC、FDDB等)上进行了验证。算法在数据集上具有较高的准确性以及实时性是本文所关注的两个重要衡量指标,在每一章的实验部分都测试了算法的实时性与准确性,最终在大量数据集上的测试都达到了预期的实验效果。"
730,基于路侧传感器的多车辆检测跟踪技术研究,"近年来,自动驾驶成为了一大热门研究领域。基于路侧传感器对车辆进行检测跟踪,提取车辆的位置、轨迹等信息,并将这些信息广播至无人车,可以辅助无人车自动行驶。在实际的道路场景中,车辆的检测与跟踪存在着各种各样的挑战。一方面天气变化、光照强度等不可控因素时刻影响着道路环境,另一方面车辆在视频画面中有着大小不一的尺寸,车辆间的相互遮挡也为检测跟踪带来了困难。另外,对于自动驾驶场景中实际可用的系统而言,同时保证系统的准确性与时效性也是较大的挑战。本文提出了一种基于深度学习的轻量化的车辆检测模型以及一种基于空间关系与颜色特征的多目标跟踪方法,最终设计并实现了基于路侧视觉传感器的多车辆检测跟踪原型系统。在车辆检测模型方面,为了同时满足准确性与时效性的要求,我们将轻量网络MoblieNet迁移至Faster R-CNN目标检测框架,结合具体场景优化RPN结构,大大减少了模型参数量与计算量,从而提高了模型的检测速度。在目标跟踪方面,我们基于检测结果,通过前后帧间目标的空间关系与颜色特征计算目标匹配概率,完成目标关联匹配。对于遮挡等引起的目标漏检,使用KCF跟踪器进行位置预测,最终实现了对多目标有效的跟踪。最后,我们在实际场景下对本文方法进行了测试实验,实验结果表明我们的方法具有较高的多车辆跟踪正确率及较快的运行速度,符合研究预期。"
731,基于深度学习的用户窃电行为检测,"在过去的几十年中,用户窃电行为引起了很多关注,电力盗窃在国内乃至全世界都造成了巨大的损失。因此,及时识别电力系统中的电力盗窃对于系统的安全和可用性至关重要。虽然很多研究者已经做出了各种研究工作,但是随着数据的增加,窃电检测任务依然具有挑战性,并且准确率和效率较低。最近,在很多领域,与使用手工特征和浅层结构分类器的方法相比,深度学习方法已经实现了更好的性能。本文提出了三种基于卷积神经网络和循环神经网络的窃电用户检测方法,分别是1D-DenseNet网络、Multi-scale DenseNet网络和BPIE-BiSRNN网络,以捕获顺序特征的长期和短期周期特征。将我们提出的方法与经典算法进行了比较,实验表明,本文提出的几种方法均可以显著提高窃电行为检测的准确性,可以大大降低人工检测窃电的成本。相比于传统机器学习方法,本文提出的深度学习方法,将logloss值从0.343降低至0.253,而AUC值从0.756提升至0.871。"
732,基于机器学习的短期电力负荷预测方法研究,"准确的短期电力负荷预测有助于提高电力系统的运行效率,降低运营成本。传统的基于统计学习的方法预测精度较高且容易实现,但在负荷波动剧烈时表现较差。机器学习方法具有较强的拟合能力,能够充分反映负荷的非线性特性,在短期电力负荷预测领域取得了不错的效果。本文基于机器学习中多种方法,结合实际数据对短期电力负荷预测方法进行了研究。论文主要工作如下:首先,研究了短期电力负荷特征集合的构造。该部分首先对数据进行预处理,为保证后续模型预测的准确度,对数据集中的缺失值进行补全,并剔除异常值;其次要确定影响负荷变化的属性,确定模型的输入,对于数量较多的滞后历史负荷特征,采用梯度提升树递归特征消除法从中筛选出重要度较高的特征,提升模型预测精度以及降低模型的计算复杂度;最后,为进一步挖掘历史负荷序列中的信息,采用深度自编码器对历史负荷序列进行特征提取,构造新的特征,完成特征集合的构建,为后续预测模型奠定基础。然后,研究了基于小波神经网络短期电力负荷预测模型的构建。该模型首先通过引入线性递减规则将差分进化算法的两种更新策略引入到和声搜索算法的更新过程,并利用锦标赛选择策略选择出变异算子中的和声,实现对和声搜索算法的改进;其次利用改进后的和声搜索算法选出小波神经网络的最优初始权重值,对固定初始权重的小波神经网络进行训练学习,完成负荷预测模型的构建;最后基于实际负荷数据,验证了上述模型的有效性。其次,研究了基于加权EMD的小波神经网络短期电力负荷预测模型的构建。该模型通过EMD分解将电力负荷序列分解成多个子序列;根据子序列的均值和方差进行聚类,将均值大方差小的序列作为标准序列,计算类别中其他序列与标准序列的欧氏距离的倒数作为权重;最后采用改进后的小波神经网络对子序列分别进行预测,最终预测结果为各个子序列的加权求和,并基于实例完成了模型的验证。最后,研究了基于blending模型融合短期电力负荷预测模型的构建。针对单一模型预测结果不稳定的缺点,通过组合模型集成不同方法的优势来提高预测性能。采用blending融合框架,将XGBoost、随机森林、极限学习机以及小波神经网络进行融合,并基于实际负荷数据,验证了该模型的有效性。"
733,基于机器学习的智能电网调度控制系统在线健康度评价研究,"智能电网调度控制系统(简称D5000系统)监控电力系统发、输、变、配和用电的全过程,并实现“调控一体化”,是电网安全稳定运行的关键。在D5000系统运维管理过程中,虽然调度人员可以获取该系统的运行健康状态,但针对其在线健康状态评估方法的客观性还有待提升。因此,本文结合D5000系统的实际需求,开展基于机器学习算法的在线健康度评价研究工作,针对其业务繁多、评价体系复杂、评价指标众多、指标间关系模糊、评价计算量大、时效性需求高等特点,研究了基于机器学习的D5000系统在线健康度评价方法。研究成果对提高D5000系统的健康度评价可靠性,保障智能电网安全稳定运行具有重要意义。本论文的研究内容来源于国家电网公司总部科技项目“调度自动化设备健康度评价”(项目编号:A2017069),本论文的研究对象为智能电网调度控制系统,针对该系统的评价指标体系,展开基于机器学习的健康度评价研究,本论文主要工作如下:(1)研究了基于半监督聚类的D5000系统健康度评价方法。在考虑提升评价客观性以及难以大量获取系统健康状态样本标签的基础上,提出一种基于决策图和成对约束的半监督聚类算法进行健康度评价。首先,分析了 D5000系统评价指标体系的特点;其次,分析D5000系统原始监测数据的特点,并针对数据特点对样本数据进行预处理;然后,确定了基于决策图和成对约束的半监督聚类D5000系统健康度评价方法;最后,利用UCI数据集选取的三组数据进行聚类实验,结果表明所提算法可以有效提升聚类性能,并且用国家电网公司实测的D5000系统监测数据进行实验,通过与传统典型方法的比较,验证了本文所提健康度评价方法的有效性,为智能电网调度控制系统健康度评价提供了新思路。(2)研究了基于极端随机森林的D5000系统健康度评价模型。在健康度评价方法的基础上,结合对历史数据分析,确定基于极端随机森林的D5000系统健康度评价模型。首先,针对结果数据特点分析了D5000系统评价模型的需求;其次,提出一种基于随机森林与熵权法结合的指标权重确定方法;然后,依据评价方法结果数据以及权重确定了基于极端随机森林的D5000系统评价模型,并进行实例分析;最后,通过D5000系统模拟系统的故障模拟数据提出了系统评价可靠性验证方法,完成健康度评价模型可靠性验证。(3)构建了基于Hadoop的D5000系统健康度在线评价体系。针对D5000系统评价体系复杂、评价计算量大、评价时限要求高的特点,提出了一种基于MapReduce的健康度并行评价方法。首先,分析了 Hadoop平台以及MapReduce模型的优势;其次,通过组合式MapReduce框架计算系统的健康度分数,在上级MapReduce中,Map读入数据拆分评分任务,Reduce按照层级结构归约计算进程以及硬件健康度级别,在下级MapReduce中汇总平台与应用健康度级别得到D5000系统的状态,同时采用了任务调度自适应算法保证系统的负载均衡;最后,搭建了D5000系统健康度评价实验平台,并通过实验验证了所设计的体系提高了D5000系统健康度评价的效率。"
734,小麦赤霉病高光谱信息多循环提取及组合式识别研究,"小麦是世界上最重要的粮食作物之一,在我国有着广泛的种植面积。赤霉病是小麦的一种主要病害,它具有较强的传染性,不仅会导致小麦减产甚至绝收,严重影响小麦种子质量,还会大量分泌多种毒素严重危害人畜健康。因此,小麦赤霉病籽粒的识别研究具有至关重要的意义。本文以小麦赤霉病籽粒高光谱信息提取技术及识别模型的研究为切入点,以图像处理技术、特征提取技术以及分类算法为手段,确证了利用高光谱成像技术实现小麦赤霉病快速识别的可行性;同时,针对特征信息提取方法及识别模型的优化进行了相关研究,建立了多循环信息提取方法及组合式识别模型,提高了特征信息提取精度及识别精度,降低了误判率及漏检率,构建对赤霉病小麦籽粒的高效、准确、可视化的识别模型。本文的主要研究内容与研究成果如下:(1)小麦赤霉病籽粒高光谱图像预处理技术研究利用高光谱成像系统采集中科院第二粮仓计划示范农场提供的健康小麦和赤霉病小麦样本在可见光到近红外(470~1100nm)波段的高光谱图像。在空间图像方面,先利用灰度方差法作为清晰度评价指标选择进行图像处理的最优波段,利用最大类间方差法结合灰度线性拉伸和开操作完成麦粒掩膜提取,并利用主成分分析增强掩膜提取精度。在光谱预处理方面,利用Savitzky-Golay(SG)卷积平滑算法、多元散射校正和变量标准化对小麦光谱数据进行处理,最终采用SG卷积平滑算法进行光谱预处理。在高光谱特征提取方面,利用主成分分析(principal components analysis,PCA)和连续投影法(successive projections algorithm,SPA)进行高光谱数据降维,PCA变换后6个主成分包含原有99%以上的信息,SPA算法提取出8个特征波长,分别为:479.9、498.2、543.8、630.5、726.2、828.9、904.1、920.1nm。通过有效的数据预处理和特征提取为建立高效快速的小麦赤霉病识别模型提供了保障。(2)小麦赤霉病特征信息提取技术及优化在提取小麦样本光谱的过程中提出了一种基于k均值聚类法(k-means)结合kappa系数进行多次循环的方法来提取最优训练样本。最终以每类500条样本光谱作为训练集,每类10000条样本光谱作为测试集,并结合总分类精度和kappa系数对模型进行评价。在PCA和SPA两个特征空间内结合光谱角匹配、k均值聚类法、最近邻域法、线性判别分析和支持向量机(Support Vector Machine,SVM)五种分类算法构建多种小麦赤霉病识别模型。结果表明SVM算法在SPA特征空间中构建的分类模型的分类性能最优,训练集分类精度为91.1%,测试集分类精度达到88.84%,kappa系数为0.7767。(3)小麦赤霉病高光谱特征组合式识别模型建立及验证在SVM模型对小麦赤霉病识别研究的基础上,提出了两种进一步提高赤霉病小麦识别精度的方法分别为:基于多元散射校正的二次SVM识别方法和综合PCA和SPA两种特征空间的组合式SVM识别方法。前一种方法利用SVM模型和SVM散射校正模型二次分类的方法将测试集在SPA特征空间中的分类精度提升至88.98%。后一种方法综合样本在PCA和SPA特征空间中的信息,在不同的反射率区间内选择更合适的特征信息构建的分类模型,将测试集的分类精度提高至90.18%。采集以50%赤霉病染病率混合的小麦籽粒高光谱图像,作为未来标签未知的测试样本,并结合已知小麦高光谱图像利用SG-SVM(PCA+SPA)模型进行小麦赤霉病原位可视化识别研究。上述研究成果表明利用高光谱成像技术结合数据处理算法可以实现小麦赤霉病籽粒的原位快速可视化识别,有助于提高小麦赤霉病的检测效率、检测数量,降低漏检率,为小麦仓储运输加工提供保障,切实可行的确保小麦安全。进而,实现小麦赤霉病的快速无损检测,为我国粮食安全的检测技术手段提供了有力的技术支持。"
735,结合心电信号与临床因素的心衰预警技术研究,"心力衰竭是目前全球范围内最常见的致死因素之一,它给患者、患者家庭以及全社会都带来巨大的精神与经济负担。建立可靠的心衰自动预警模型对心衰疾病的管理有着至关重要的意义,也成为近年来医生和决策者日益关注的问题。本文以多参数智能监测数据库中的心电信号、临床检查变量及人口统计学资料为研究对象,将信号处理与机器学习技术引入该领域初步建立了心衰自动预警评估模型。研究内容主要包括:(1)根据心电信号为典型时序序列的特点,建立基于长短时记忆网络的心衰疾病自动诊断模型。在本模型中,首先将心电信号经过去噪、心拍分段、Z-Score标准化等预处理操作,然后利用同步压缩小波变换提取心电信号固有模态及模态能量熵与排列组合熵特征,最后将提取的特征输入搭建的长短时记忆网络,实现是否为心衰病人的分类;(2)结合心电信号特征、临床检查变量与人口统计学资料,在得到有无心衰诊断结果的基础上,建立基于粒子群优化的随机森林预警模型,进一步对心衰患者5年内是否死亡作出预警。首先,分别提取5年内生存和死亡心衰患者的心电信号熵特征,将之与临床检查变量及人口统计学资料融合之后,输入粒子群算法优化的随机森林分类器中,对心衰病人5年内是否死亡作出预警并对其死亡风险因素进行排名分析。实验结果证明,本文提出的心力衰竭自动诊断模型可以达到97.50%的分类准确率,并且在后续的心衰疾病预后评估过程中,ROC曲线下面积也达到0.80以上。由此,本文提出的模型在一定程度上可以为医生的临床治疗、随访管理以及患者的自我管理提供有效指导。"
736,基于心电信号的心衰自动诊断技术研究,"心力衰竭是各种心脏疾病发展的终末阶段,具有患病率高、死亡率高、花费高、预后差等特点,已成为世界范围内的重大公共卫生问题。心电图是临床上最常见无创性的能够准确直观反映人体心脏电位活动的工具,为医生诊断提供了重要信息。本文利用PhysioBank生理信号公共数据库数据,结合信号处理与机器学习技术,旨在研究高效快捷的心力衰竭自动诊断方法,为实现心力衰竭的客观诊断评价具有重大意义。主要工作如下:(1)提出了基于灵活解析小波变换的心衰诊断模型。将预处理后的心电信号进行灵活解析小波五层分解,计算分解后子带信号的模糊熵,并对熵特征进行了特征打分排名,去除冗余特征,建立最优特征集。最后,采用多种传统机器学习方法进行心衰诊断,利用十倍交叉验证方法和混淆矩阵对不同分类器效果性能进行评估。结果显示,支持向量机和最小二乘支持向量机在心衰的自动诊断中具有很大的应用潜力,最高准确率为94.63%;(2)提出了基于一维深度神经网络的心衰诊断模型。主要从心电信号的一维特性角度出发,建立了适合于处理一维时间序列的深度卷积神经网络模型,输入经过R点检测的心拍分段和非R点检测的直接分段两组数据,进行了实验对比,结果显示该模型对输入心拍是否进行R点检测并不敏感,最高准确率达到96.71%;(3)提出了基于信号特征与深度学习的心衰诊断模型。主要从深度卷积神经网络对处理图片数据的高效性角度出发,利用更能表征心电信号非线性特征的高阶累积量方法,提取了心电信号的三阶累积量谱图,分别输入AlexNet,ResNet和DenseNet模型。结果表明,结合提取信号特征的深度学习方法能够更好地对心衰进行辅助诊断,最高准确率达到97.86%。"
737,混合特征选择模型在妊娠期糖尿病诊断中的应用研究,"妊娠期糖尿病是一种发生于妊娠期的糖代谢异常情况,其常会引母婴围产期疾病和Ⅱ型糖尿病。而尽早地诊断并控制病情,可以有效地降低疾病所带来的风险,随着生物医学和计算机科学的发展与融合,越来越多的机器学习算法与技术应用于辅助医疗诊断。目前有机器学习算法在糖尿病诊断的应用研究也比较多,而随着数据维度的提升,特征选择模型也越来越广泛的应用于辅助医疗诊断过程中。本文提出一种具有泛化意义的层次特征选择模型,并给出形式化描述,可以用于表示单一特征选择模型和多混合特征选择方法融合。借鉴计算机科学广泛应用的分层结构,通过分层结构对特征选择模型进行管理,以实现在特征选择阶段的模型融合。提出的层次特征选择模型具有泛函性好,鲁棒性强等优点,适用于发现特征物理解释不明确,与类标签之间模式不可知的情况。其次,本文改进了一种基于关联规则的特征选择算法,根据规则的置信度和特征在规则中出现的频率,计算特征对应的加权频率分数,用以表征特征重要性,实现特征选择功能。本文使用的是天池糖尿病数据集,包含55维SNP特征和29维体征特征,根据数据集的特点,提出混合特征选择模型,分别使用层次特征选择模型和基于关联规则的特征选择算法对组合后的SNP特征和离散化后的体征特征进行特征选择,对选择后的特征进行拼接,最终实现特征选择功能。并通过实验验证,在天池糖尿病数据集下,本文提出的混合特征选择模型特征选择效果优于其他对照特征选择模型。"
738,级联GA-CatBoost在妊娠期糖尿病预测诊断中的研究,"随着信息智能化进程不断发展,互联网与传统医疗不断融合,数据挖掘和机器学习技术已经越来越频繁地被用于预测疾病发生的可能性。在医疗诊断领域,越来越多的生理指标、疾病类型和生物工程技术,加大了医生诊断疾病的难度,针对该问题,机器学习和数据挖掘技术能够从医学数据中提取隐藏的、具有潜在价值的和新颖的信息,以提高诊断准确性,减少时间和成本。一方面可以对医生的诊断结果提供进一步的验证,另一方面还能给医生提供一个复杂疾病的分析工具。CatBoost(Category Boosting)是一种基于梯度提升树并且支持类别特征及字符串类型特征的机器学习框架。梯度提升是一种强大的机器学习技术,是解决具有异构特征、噪声数据和复杂依赖关系的问题的主要方法。本文以妊娠期糖尿病为研究对象,采用迭代自组织数据分析法(Iterative Selforganizing Data Analysis Techniques Algorithm,ISODATA)和拉伊达准则检测并且剔除离群值,将CatBoost作为预测模型,使用遗传算法(Genetic Algorithm,GA)优化对CatBoost模型的参数进行联合优化,选择最优训练参数,最后将CatBoost与XGBoost(eXtreme Gradient Boosting)、LightGBM级联,即级联GA-CatBoost。主要研究和工作内容如下:(1)研究课题分析了国内外相关研究概述,介绍了糖尿病尤其是妊娠期糖尿病(Gestational Diabetes Mellitus,GDM)的发病原理、医学诊断指标特点,并详细说明了目前预测诊断糖尿病的常用方法及其优缺点。(2)针对离群值对预测结果的影响,采用迭代自组织数据分析算法和拉伊达准则检测并消除离群值,因为离群值对妊娠期糖尿病预测分类的影响较明显,在进行预测诊断过程中需要边学习类别的特征、边防止离群值的干扰。该算法允许每个实例只属于一个集合,目标是在集合内达到高度相似性,而集合之间的相似性很低。使用ISODATA检测离群值可以减少离群点的干扰并提高预测的准确度。(3)构建多种分类器,对比分析各种分类器的性能。由于妊娠期糖尿病数据集包括连续属性和缺失值,根据数据类型填充缺失值并进行one-hot处理;在使用IV值进行特征分析的同时构建组合特征。最后结果表明CatBoost分类器具有最佳分类效果。(4)本文使用遗传算法多点搜索点空间,最终得到全局最优解。由于CatBoost的参数较多,预测准确率严重依赖于参数的设定,每个参数都具有不同的作用,依靠主观判断和试探法,工作量巨大并且精确度较低,本文通过遗传算法(GA)和网格搜索(GS)分别对CatBoost模型参数进行调优,通过AUC(Area Under roc Curve)值对比,得到GA得到的参数效果更好。最后,将GA-CatBoost、XGBoost、LightGBM级联,即级联GACatBoost,能够提高模型泛化能力。"
739,基于机器学习的缺血性中风病恢复期临床辅助诊断系统建模与应用研究,"当前,对于缺血性中风病的临床辅助诊断算法模型的研究大都是以现代医学理论为基础构建的,主要通过综合各项医学辅助检查指标结果实现疾病的辅助诊断。虽然存在着部分从中医病因病机、体质辨识等方面的研究,但目前中医临床上仍缺少以缺血性中风病为主的临床辅助诊断工具。因此,这需要通过运用机器学习和数据挖掘等相关理论,充分发挥中医临床康复医疗技术的优势,挖掘中医康复专家临床经验和病案的利用价值,系统化、实例化的设计并实现缺血性中风病临床辅助诊断系统。本研究基于机器学习方法,从数学建模、数据挖掘和系统设计实现三个方面,构建缺血性中风病恢复期临床辅助诊断系统。目的:通过创新“现代科学技术+中医药理论”思路,以缺血性中风病恢复期为主体,借鉴国内外关于心脑血管疾病临床辅助诊断模型的研究技术,探索构建具有中医药特色的缺血性中风病恢复期临床辅助诊断模型,挖掘缺血性中风病恢复期中医临床用药配伍规律,设计与实现缺血性中风病恢复期临床辅助诊断系统,降低了中医临床医生对缺血性中风病恢复期患者进行疾病诊断时出现的误诊风险,同时也为中医药临床发展缺血性中风疾病防治研究工作提供新思路和新方法。方法:1.运用数据预处理技术,对来自福建中医药大学附属康复医院脑病科采集的1915例缺血性中风病恢复期中医临床医疗数据进行前期处理,提高研究数据的质量,并建立缺血性中风病恢复期中医临床病例资料数据集。2.应用Logistic回归分析方法和支持向量机方法,探索建立了缺血性中风病恢复期气虚血瘀证、痰瘀阻络证和阴虚风动证的临床辅助诊断模型。3.应用Apriori关联规则算法,整理和挖掘缺血性中风病恢复期气虚血瘀证、痰瘀阻络证和阴虚风动证的中医临床用药信息,总结缺血性中风病恢复期三种中医证型的中医临床用药配伍规律。4.应用计算机软件系统开发技术,设计开发缺血性中风病恢复期临床辅助诊断系统,并将其嵌入医院信息管理系统和脑梗死恢复期中医临床路径系统中,实现缺血性中风病恢复期三种中医证型的临床辅助诊断模型和临床推荐用药规则的临床实际测试与运用。结果:1.确定了缺血性中风病恢复期风险临床表征变量65项,其中气虚血瘀证17项,痰瘀阻络证28项,阴虚风动证10项。2.缺血性中风病恢复期三种中医证型的临床辅助诊断模型,经过ROC曲线分析和临床诊断对比验证,临床辅助诊断的准确率分别达到81.67%、89.17%和96.67%。3.确定了缺血性中风病恢复期三种中医证型的临床推荐用药规则共37条,其中气虚血瘀证15条,痰瘀阻络证10条,阴虚风动证12条。针对气虚血瘀证,推荐使用以赤芍、黄芪、当归、川芎和地龙为基础的中药方剂;针对痰瘀阻络证,推荐使用的中药是:胆南星、石菖蒲、陈皮、半夏和丹参;针对阴虚风动证,推荐使用山茱萸、山药、熟地黄、丹皮和麦冬相互配伍。4.设计并开发了缺血性中风病恢复期中医临床辅助诊断系统软件,并通过了福建省产品质量检验研究院检测报告(CMA认证)。结论:1.基于Logistic回归分析方法和支持向量机方法构建的缺血性中风病恢复期三种中医证型的临床辅助诊断模型,经过理论验证与实践验证,获得了较高的辅助诊断准确性,意味着这三种辅助诊断模型可以进入医院信息系统和脑梗死恢复期中医临床路径系统进行使用,体现了其应用价值。2.基于Apriori关联规则算法挖掘的缺血性中风病恢复期三种中医证型的临床推荐用药规则,经过中国中医药方剂数据库的识别比对,验证了气虚血瘀证、痰瘀阻络证、阴虚风动证的临床推荐用药规则符合中医经典治疗缺血性中风病相关证型的方剂组成,可认为临床推荐用药规则是合理有效的。3.缺血性中风病恢复期中医临床辅助诊断系统在临床实际应用过程中,能够辅助中医临床医生进行缺血性中风病恢复期病人的诊断与治疗。"
740,基于模糊熵的精神分裂症感觉门控复杂度的研究,"精神分裂症严重影响人类的生活质量甚至生命安全,而对其准确诊断是控制、治疗该疾病的首要任务。由于脑电信号(Electroencephalogram,EEG)的突出优势,其在疾病诊断中应用广泛。但传统诊断方法主要从EEG信号的时域、频域角度去检测疾病,这些方法不仅耗时耗力,而且主观性强,无法有效挖掘其中更有价值的隐含信息,并且对精神分裂症的诊断始终缺乏统一的标准。因此,开展关于精神分裂症准确诊断的研究变得尤为重要。随着非线性动力学的发展,以及EEG信号的非线性特征,利用非线性指标分析大脑疾病复杂度的变化在临床上成为一个热门的话题。之前的研究证明精神分裂症患者存在显著的复杂度异常。而熵作为一种非线性指标,具有抗噪能力强、数据长度依赖度小等特点,广泛应于EEG信号检测。而精神分裂症患者存在显著的感觉门控(Sensory Gating,SG)缺陷,SG-P50已被证明是精神分裂症重要的内表型,许多研究人员借助P50诱发电位研究SG机制。但是在SG的认知过程中,精神分裂症患者的复杂度调节仍然是未知。因此,本研究将熵引入到SG复杂度的研究中,期望能寻找到患者SG异常的动力学证据,并为精神分裂症的临床诊断提供一种可靠、准确的评价指标。本文使用听觉配对刺激范式对来自合作单位北京回龙观医院的55名正常被试和61名精神分裂症患者,记录其SG下的EEG数据。经过预处理后,分别使用近似熵、样本熵和模糊熵探讨基线(BaseLine,BL)状态和成对刺激下(S1和S2)大脑活动的复杂度变化情况。并从归一化和抑制比角度验证精神分裂症患者的SG异常。最后结合EEG信号的多种特性构建“EEG图像”,使用深度学习的方法进行分类研究,验证熵的检测能力。研究结果提供了对患者感觉信息处理和SG缺陷的更深入的理解,为精神分裂症的临床诊断提供了科学有效的检测标准。本研究主要完成的内容有以下几点:(1)近似熵、样本熵和模糊熵检测能力对比研究分别使用近似熵、样本熵和模糊熵结合听觉配对刺激范式研究正常对照组和精神分裂症患者组在静息态和任务态的复杂度变化情况,将三种熵的检测能力进行比较,并将存在显著差异的电极构成感兴趣区。(2)基于模糊熵的SG异常机制研究探索研究精神分裂症患者SG的复杂度变化模式。通过归一化处理,分析两组被试在配对刺激下的差异。并利用复杂度抑制比检测两组被试SG的区别,提取有差异的电极,进行感兴趣区分析,之后将感兴趣区的熵值与患者的量表信息做相关。(3)基于深度学习的精神分裂症患者分类研究利用熵值作为分类器的输入特征,进一步证实模糊熵的检测能力。首先对比了不同熵在传统机器学习分类方法中的检测性能,验证模糊熵的检测性能最好。为了进一步提升对精神分裂症患者的分类性能,研究中提出一种结合时、空、频域的深度学习算法,使用模糊熵值构建“EEG图像”,训练卷积神经网络,提升分类精度。以上研究结果一致表明,模糊熵是研究SG复杂度的一种有效方法,为寻找患者的SG缺陷提供动力学证据,并可作为精神分裂症临床诊断的一种非线性标准。"
741,人工智能在司法审判运用研究,"当前大数据和人工智能以势不可挡的冲击力影响着社会生活,司法领域并没有选择回避,而是以主动姿态接受人工智能的影响和介入,其目的就是通过人工智能与法官审判工作的深度融合以促进司法改革整体效能的提高。司法实践证明,人工智能应用司法审判在一定程度上能够提高司法效率,防止冤假错案、保证司法公正。但需清醒地看到人工智能是一把双刃剑,当前,人工智能在我国司法实践中还属于一种辅助性、参考性工具,只是为法官等司法人员提供行动参考,仍属于一种统计型、材料准备型、文字模板型的人工智能。人工智能运用司法审判的基础是深度学习技术的发展以及海量的司法大数据。尽管它的智能性给司法领域带来诸多创新,但由于审判工作有其司法亲历性、责任性的规律所在,人工智能尚无法模拟法官自由心证,以及法官审判经验的专属性、法官的自由裁量权、以及个案的公平正义等也均决定了人工智能在这些领域难以也不应发挥效用。因此,在人工智能运用司法审判过程中,要防止技术崇拜以及技术恐惧的两个极端,人工智能只是司法审判辅助工具,人工智能无法取代法官,法官才是司法审判的主体。本文在绪论中介绍了论文的选题背景和意义,以及国内外的研究现状,此外还介绍了本文的创新点及研究方法。本文在第二章论述了人工智能的基本内涵以及在司法审判运用中的发展历程、原理与特点进行研究。本文在第三章主要对美国、英国等国家人工智能在司法审判的运用的具体实践和国内北京、上海等法院的具体应用。本文在第四章论述了人工智能应用司法审判具有提高司法效率、防范冤假错案以及预防司法腐败保证司法公正等方面的作用,但同时也带来了一些负面影响,人工智能无法模拟法官自由心证、不利于法官的自由裁量以及个案的公平正义等。本文在第五章主要是提出人工智能在应用司法审判的过程中要明确其与法官审判的边界以及与法官的关系和各自定位。同时提出,面对人工智能对司法审判的影响,要有正确的态度,要防止技术崇拜,明确法官在司法审判过程中的主导地位。"
742,基于机器学习树模型的GNSS-R海面风场反演研究,"海洋表面风场是海洋重要的动力学参数,几乎与所有的海洋活动密切相关。全球卫星导航定位系统(Global Navigation Satellite System,GNSS)不仅可以用于传统的导航和定位,还可以利用其前向散射信号进行遥感应用研究,该技术称为GNSS反射信号遥感技术(GNSS-Reflectometry,GNSS-R)。GNSS-R技术凭借其低成本、全天候、高时空分辨率、覆盖范围广等优点得到了广泛的关注,经过几十年的发展,在海洋高度、海面风场、海面溢油、土壤湿度等方面都有所应用。本文以GNSS-R技术结合机器学习树模型算法反演海面风场为研究方向展开了相关工作。本文利用TDS-1(TechDemoSat-1)卫星与欧洲中期天气预报中心(European Centre for Medium-Range Weather Foresting,ECMWF)分析场数据进行时空匹配得到原始样本集。对原始样本集进行预处理后得到适合机器学习树模型学习的训练集和验证集。训练集用于树模型的训练,验证集主要用于检验学习器的反演精度。用五种常用的树型模型决策树、随机森林、GBDT、LightGBM以及XGBoost基于滑动窗口的方法对海面风场进行反演。对于风速的反演,集成树模型的反演误差小于2m/s达到了反演的要求,由于可能未提取风向敏感的物理参量,风向的反演误差较大,约为50°。在此基础上,选择风速反演效果较佳的模型随机森林和LightGBM进行了模型融合,采用Averaging、CV-Averaging、Stacking三种模型融合方法,进一步提升了模型的风速反演精度。之后基于随机森林和LightGBM又进行了更深层次的研究和分析,对于提高海面风场反演精度具有重要的指导意义。主要包括以下三个方面:(1)以赤道为中心,随着两侧纬度变化树模型反演精度的变化;(2)对于不同月份风场的反演,南北半球在反演精度上的差异性;(3)对于昼夜不同时间段,风场反演结果对比与分析。本文基于机器学习树模型算法实现海面风场反演,在提取到风场敏感物理参量的前提下,可以取得良好的效果。"
743,基于视频监控的室内人员计数方法研究,"利用建筑物内已有监控摄像头进行人员分区计数具有无需额外布设传感器网络、数据丰富、估计精度高等优点,该方法已成为计算机视觉研究的一个重要领域,而获取建筑物内人员分布对建筑智能控制又有着重要意义,面向建筑节能的室内人员计数研究已成为学术界和工业界的一大研究热点。因此,本文针对不同的应用场景,对建筑物内区域人员数量估计开展了一些研究,设计了两种基于视频监控的室内人员计数方法以及一种基于二项分布的人员计数修正算法。本文研究的内容及成果主要有以下三个方面:首先,针对室内有效区域图像可被获取的场景,基于建筑物室内环境特点,使用了一种基于图像分析的人员计数方法,并针对单帧图像往往无法准确检测图像的人头区域,可能存在被遮挡、误检、漏检等情况,使用了一种基于聚类分析的人数修正方法。该方法首先评估室内环境特点,对ROI(region of interest)区域进行了提取,然后使用级联的Adaboost(adaptive boosting)分类器和卷积神经网络与SVM(support vector machine)分类器对区域内的人头目标进行检测以实现人员计数。针对单帧图像检测中可能存在的漏检、误检问题,提出了一种基于DBSCAN(density-based spatial clustering of applications with noise)算法的人数修正方法。实验结果表明该方法在室内人员计数中具有很好的鲁棒性、准确性与实时性。其次,考虑到基于有限张图像分析的人员计数方法存在的被遮挡、覆盖不全面和某些室内人员所在区域图像缺失等问题,设计并实现了一种基于区域边界人员进出统计的室内人数计数方法。该方法通过在区域边界设置有效的检测区域,采用基于高斯混合模型与背景差分法融合的前景提取算法,使用卡尔曼滤波算法对人员进行跟踪,通过人的重心变化判断人员进出方向,最终实现人数统计。本文在实际监控场景中对该算法进行了验证,准确率能达到90%以上。最后,考虑到基于边界进出的人员计数方法随着时间推移存在的累计误差问题,设计了一种基于误差模型的人员计数修正方法。本文详尽分析了基于边界人员进出统计中累计误差产生的原因与影响,对边界区域中人员移动的特点进行了分析,建立了一种基于二项分布的累计误差模型,通过该误差模型判断传感器统计的人数何时应该进行人数的修正。最后基于该累计误差模型,设计了一种基于误差模型的人数修正方法,结合误差模型判断修正的时间,对统计人数的累计误差进行修正。实验结果表明,相较于简单的通过统计人员进出进行人数计算的方法,使用了本文的计数修正方法后,人员计数的性能有了很大的提升,累计误差修正效果明显。"
744,基于堆栈自编码器的WSNs链路质量评估方法,"无线传感器网络是一种由大量部署在监控区域的节点以自组织方式形成的网络,链路是实现节点互连和通信的基础,感知节点资源的有限性、监测环境的复杂性、以及噪声的多样性导致节点间链路质量呈现出方向性、非对称性、波动性以及通信“灰区”等时空特性,使得节点间通信具有不稳定性,影响数据的传输。有效的链路质量评估是拓扑控制以及路由控制的基础,可以保障数据的传输,有助于提高整个网络的吞吐率,进而延长整网的寿命。本文从链路的非对称性出发,借助堆栈自编码器的特征提取能力,构建链路质量评估模型(Link Quality Estimation Based on Stacked Autoencoder,LQE-SAE)。通过对接收信号强度指示、信噪比和链路质量指示进行非对称分析,选取其上、下行参数;采用零值填充的方式对每个探测周期内因丢包而导致的缺失的链路质量信息进行处理;采用堆栈自编码器分别提取接收信号强度指示上、下行参数之间的非对称特征,信噪比上、下行参数之间的非对称特征以及链路质量指示上、下行参数之间的非对称特征;采用堆栈自编码器对提取的三个非对称性特征进行融合,将得到的结果作为支持向量分类机的输入,以包接收率为依据划分的链路质量等级作为标签进行训练,得到链路质量等级;采用准确率评价评估模型的有效性,采用查全率评价评估模型在五种不同链路质量等级上的性能,采用稳定性等级评价评估模型的稳定性。本文在室内走廊、小树林、停车场以及马路四种不同场景下,通过自主开发的链路质量测试平台收集链路质量信息,用于模型训练和分析。实验结果表明,在四种场景下,与基于支持向量分类机、超限学习机和小波神经网络的链路质量评估模型对比,LQE-SAE具有更高的准确率。稳定性实验在过道场景下,通过调整干扰大小进行实验,结果表明LQE-SAE具有良好的稳定性。"
745,基于梯度提升决策树的链路质量评估方法,"在无线传感器网络应用中,链路质量评估是保障数据可靠传输和上层网络协议性能的基础性问题。有效的链路质量评估方法不但能够客观的评价链路质量、链路的稳定性和敏捷性,还可以为数据传输提供保障。本课题来源于国家自然科学基金,旨在研究无线传感器网络中的链路质量评估方法。梯度提升决策树(Gradient Boosting Decision Tree,GBDT)作为一种机器学习方法,具有鲁棒性强、精度高等优势。本文将链路质量评估转化为一个多分类问题,利用最大信息系数方法分析物理层参数与包接收率之间的非线性相关性,综合选取接收信号强度指示、链路质量指示以及信噪比作为链路质量评估模型输入参数;考虑到离群点和参数不同量纲之间会带来一些影响,使用盒图方法筛选出离群点,并进行平滑和归一化处理,以减少模型的复杂度;根据包接收率划分链路质量等级,作为链路质量的评价指标;选取最小化负对数损失函数,构建一种基于GBDT的链路质量评估模型;针对参数的设置对评估结果影响较大问题,采用带变异算子和惯性权重的改进粒子群优化算法对GBDT模型的参数进行优化。本文选择在室内、室外(室内走廊、校园树林和校园马路)环境下部署无线传感器网络,使用本实验室自主研发的一款链路质量测试平台软件来获取实验数据,采用准确率、精确率、召回率和F1指标来评价GBDT模型与其它模型的性能。实验结果表明,经过本文优化后的GBDT模型性能最优;与传统的GBDT模型、支持向量机模型相比,本文模型具有较高的精度和稳定性。"
746,基于轻量级梯度提升机的机会网络链路预测方法研究,"机会网络是一种节点对不断连接又经常断开的间歇式连通网络,通过节点频繁移动带来的连接机会实现通信的分布式系统,具有网络拓扑非连通、规模大、动态性高,节点移动具有一定的社会性、非周期性,机会通信存在间歇性、时序性等特点,近年来学术界对其十分关注。链路预测是通过研究节点属性和节点之间网络拓扑结构动态变化,估计节点间未来存在链接的可能性,是机会网络研究的热点和难点之一。论文分析了机会网络拓扑结构随时间不断发生改变的特点,介绍了国内外现有的链路预测方法以及轻量级梯度提升机在解决时间序列问题中的广泛应用。针对机会网络中节点不断移动的特点,引入历史信息分别改进基于邻居的资源分配指标和基于距离的局部路径指标,并将两者融合得到机会网络相似性指标O_LS;对时间序列进行分析,划分时间片后构造滑动时间窗口,计算相应的机会网络相似性指标O_LS,得到预测模型的输入;选择决策树作为基学习器,投票法作为集成策略,以网格搜索和交叉验证的方法优化训练模型确定模型的迭代次数和树叶子节点的数目,得到轻量级梯度提升机模型,预测机会网络的链路。本文使用ITC和INFOCOM两个真实世界数据集,基于Sklearn机器学习库进行实验,采用精确度和AUC作为评价指标,验证相似性指标O_LS的有效性和稳定性,评价机会网络预测模型的性能。两个数据集上的实验结果表明,相比于CN、PA、RA相似性指标预测方法,本文构造的相似性指标O_LS具有更好的精确度和稳定性,以及构建的轻量级梯度提升机预测模型表现出良好的预测性能。"
747,基于统计特征与桥梁方法的小目标检测算法研究,"目标检测是自动识别、预警、智能交通等计算机视觉领域的关键技术。目前检测算法主要分为三类:传统方法、传统机器学习方法、深度学习方法。由于三种方法各有优缺点,具体目标的检测方法需要根据其特征的明显程度和场景复杂度等因素来决定的。为了能够更加有效地检测目标,本文进行了以下工作。1、由于不同类别目标之间(比如军用舰船和民用船只中的大型捕捞船)各项特征非常相似,所以基于传统方法或者传统机器学习方法的检测算法正确率一般。为了能够更加有效地检测出不同目标,本文提出了基于改进的深度学习yolo模型的检测算法。它主要通过图像网格预测和后高斯处理来检测船只目标的。模型主要框架如下:对图像进行网格划分,然后分别计算类别概率,这个时候输出矩阵的局部分布呈类均匀分布。然后对数据进行高斯处理,使得矩阵局部呈类高斯分布。最后通过检测高斯分布或者高斯最高点的方法来实现目标识别与图像定位。实验结果显示,本文深度学习网络模型相对于YOLO v2网络和SSD300网络,平均正确率分别提高了1.4%,2%左右,比YOLO v2网络实时性提高了1.5%以上。2、弱小目标具有像素数量少、纹理特征不明显、形状信息较少、局部对比特征较强等特性。为了能够更加有效地检测出弱小目标,本文提出了基于改进的统计模型与桥梁模型的检测算法。它主要通过图像中弱小目标与其邻域背景的特征差异性来检测小目标。传统模型主要步骤如下:首先在滑动窗口范围内提取像素值的均值、方差等特征;其次根据这些统计特征和桥梁方法判断该窗口范围内有无小目标。如果存在小目标,记录下其位置;最后对小目标区域进行二次筛选,二次筛选的方式是从基于统计特征、基于局部极值、基于连通域形状的筛选方式中选择一个。实验结果显示,此算法相对于较经典算法,虚警率降低了百分之五十八以上。3、目前小目标的检测使用传统算法效果最好,正常大小的目标使用深度学习检测效果较好,本文通过目标大小作为两种模型的切换条件来对目标进行检测。当目标大小小于临界值时,使用小目标检测算法。当目标大小大于临界值时,使用深度学习检测算法。"
748,基于日志分析的大数据威胁感知系统的研究,"随着互联网技术的快速发展,网络安全问题日益严峻。面对日益复杂的网络结构,网络威胁变得更加多元性和破坏性。传统的安全工具如Snort和防火墙,通过规则对单条日志进行匹配分析,不能捕捉完整的攻击行为,往往会出现误报和漏报的问题,而且规则编写依赖经验丰富的安全技术人员的专家知识,系统的泛化能力弱,实现成本高。本文提出一种基于日志分析的大数据威胁感知系统,利用机器学习模型搭建系统两道防线,实现既快速又精确地感知网络威胁,并对系统模型进行可解释性研究,且对预测结果和可解释性研究结果进行展示。在威胁感知系统中,训练样本是整个系统的基础,特征的完备性、有效性和标注的准确性关系着整个系统的性能。本文研究和设计了构建行为特征和状态特征的方法,并对特征设计降维和降参方法。针对标注不准确和标注样本少的问题,设计了基于自适应损失的半监督学习模型,对样本进行重新标注(净化)和标注(扩充)。整篇论文的具体工作内容如下:1.查阅文献总结威胁感知系统的研究背景和意义以及相应技术的研究现状,从中分析出本文系统的设计目标和思路。2.对实现系统的关键技术的实现原理进行研究并总结其特点和使用技巧。关键技术包括大数据平台技术、传统日志分析技术、机器学习模型、可解释性模型和展现层技术。3.分析传统构建特征方法的缺点,提出构建行为特征和状态特征的方法,并提出了降低稀疏行为特征维度和网络参数个数的办法。分析数据采集过程中出现的两大问题,提出了基于自适应损失函数的半监督学习模型解决思路,并评估了半监督学习模型的性能。4.设计威胁感知系统的架构和训练、预测流程。对系统中日志采集模块、日志匹配模块、日志检测模块、日志分析模块和结果展现模块进行详细地设计实现。5.通过实验训练和评估系统,保证了系统的可靠性和稳定性。介绍了系统训练的流程、调参思路和部分实验结果,并评估系统,最后分析模型可解释性的研究结果。最后,本文实现了基于日志分析的大数据威胁感知系统。通过实验表明,本系统能够精确高效地定位威胁,同时具有低误报率和漏报率的特点。模型可解释性的研究结果,一方面验证了系统可靠性,另一方面揭示了系统脆弱点和攻击者的攻击手段,帮助安全人员管理运维服务器。"
749,基于图像语义理解的恶意网页识别方法研究,"信息安全与用户财产以及个人利益息息相关,为防止用户误入恶意网页蒙受财产的损失,如何高速有效的鉴别网页的实际内容,成为时下研究的热点。然而随着当今信息产业的高速发展,信息传输速率得到了极大的提升,恶意网页从过去以文字作为主要的信息载体,逐渐过渡到图像与文字相结合的模式。特别在赌博、色情、诈骗等网页中,充斥着大量有害的图片信息。假使可以有效地提取这些图像特征,将有助于提高恶意网页的识别率。因此,本文通过提取网页图像的特征语义,结合网页文本特征以改善恶意网页的识别效果。论文开展的主要工作如下:(1)为有效的提取恶意网页中的图像信息,本文采用深度学习方法对图像进行识别,旨在提取图像信息辅助恶意网页检测。通过总结常用深度学习算法的优缺点设计对比实验,结合恶意网页的实际检测环境进行算法选型。同时针对MASK R-CNN中存在计算冗余现象,改善MASK R-CNN的网络结构,提升检测效率。(2)由于静态图像中可以表达的信息量较少,特别是姿态信息因表达不详尽易产生歧义性,因此本文采用语义分割和Kinect模板匹配法相结合的方法对目标姿态的语义进行预测,通过识别人体的基本姿态,再结合图像中的物体上下文信息,利用BP神经网络进行语义组合,推导出图像的最终语义辅助检测。(3)研究恶意网页的攻击原理以及检测方法,针对现有恶意网页检测技术中对图像信息利用不充分的现状,改良传统恶意网页检测算法,引入图像语义提取模块辅助网页识别,再与恶意网页的其余特征相融合,最终送入分类器进行识别。本文通过分模块的设计来实现恶意网页检测系统,同时采用不同类型的网页数据集对系统进行测试,以验证本文改进算法的正确性。测试结果表明,与其他恶意网页检测方法和相比,引入图像语义特征有效地提高检测精度。"
750,基于自步学习和鲁棒估计的属性选择算法研究,"信息化时代的高维大数据通常呈现高维,多样性的特点。由于这些数据在积累的过程没有经过选择,使得高维大数据存在大量的不相关,冗余的属性,而能有效表达数据功能的属性被隐藏其中。这不但会增加存储数据所需的空间,还会消耗大量的计算资源,特别是随着数据维度的增加达到某一个值时,反而会导致数据挖掘算法性能的下降。因此对高维数据进行维数约简对于解决目前高维数据面临的诸多问题具有重要意义。属性选择作为维数约简的一种有效方法,在可靠性和对结果的解释性上都好于子空间学习方法,但子空间学习可用于探索数据的内部结构。所以本文结合这两种方法,从自步学习和鲁棒估计的角度,针对目前的属性选择算法未能充分考虑噪声和异常值影响以及忽略实现世界中的数据大多存在的流行结构从而导致的数据挖掘算法性能不佳等问题,提出了两种属性选择算法。具体如下:(1)针对现有属性选择模型没有充分考虑离群训练样本的影响而导致模型泛化能力差问题,提出一种结合自步学习和稀疏学习的有监督属性选择算法。具体地,首先通过自步学习理论优先选择高置信度的样本来训练初始属性选择模型,然后依次加入次高置信度的训练样本增加初始选择模型的泛化能力,直至增加的训练样本使得模型的泛化能力减弱或者所有训练样本被用完。最后用选择的属性进行多元回归分析检验提出的SPM_RS算法的性能。六个公开的数据集上实验结果显示,该算法在回归分析中得到的结果均优于对比算法。(2)传统的属性选择模型易受异常值的影响,同时未能考虑到数据中的局部流行结构,所以在本文中,我提出通过学习一个变换矩阵来进行鲁棒图降维,在不受异常值影响的情况下将原始高维数据映射到其低维属性空间。为了做到这一点,1)我提出的方法同时自适应学习三个矩阵。即,原始数据的反向图嵌入矩阵,变换矩阵,以及在其低维属性空间中保持原始数据局部相似性的图矩阵;2)使用鲁棒估计器,避免这三个矩阵优化过程中的异常值的影响。因此,原始数据通过两种策略进行清理,即,基于三个结果变量和鲁棒估计器对原始数据的预测。利用反向图嵌入和图矩阵的方法,从精确估计的属性空间中学习变换矩阵。此外,对所得的目标函数提出了一种新的优化算法,并从理论上证明了算法的收敛性。实验结果表明,该方法在不同的分类任务上优于所有的比较方法。综上所述,本文创新的将自步学习和鲁棒估计嵌入属性选择模型,自步学习作为一种鲁棒学习方法倾向于平稳的探索数据,鲁棒估计通过给异常值赋予较低的权值来最小化异常值的影响,并结合流行学习探索数据的内部结构。为了测试提出方法的性能,所有的实验均在公开数据集上进行,并与最近几年优秀的降维算法做对比,使用分类和回归作为评价方法。实验结果显示,我设计的方法性能优于对比算法,证明了我提出方法的有效性。"
751,基于卷积神经网络的特征选择和特征表示文本分类研究,"移动通信经历了从1G到4G发展过程,目前5G正在蓬勃发展,互联网每时每刻都会产生包含文本、图片和影音等信息的海量数据,存储在云服务器、个人计算机或移动通信设备上。如何高效、快捷地获得有价值的信息是互联网用户最关心的问题,因此,对海量信息能进行智能自动分类处理、排除无价值或不健康信息的网络技术成为研究的热门领域。文本分类作为自然语言处理领域的研究热点之一,对优化网络环境、处理海量文本信息有重要意义。本文以提高文本分类准确率和缩短文本分类模型的训练时间为目标,主要研究内容如下:(1)本文首先对目前比较主流的分词工具进行性能测试,以分词结果的准确率和分词时间为判断依据,选用Jieba分词工具对文本进行分词。针对文档中的停用词种类繁多,且开源的停用词表各有千秋,本文重新整理了一套停用词表。为文本预处理奠定了良好的工作基础。(2)本文通过研究四种传统特征选择算法:词频(Document Frequency,DF)、卡方(?~2)检验(Chi-Square Test,CHI)、互信息(Mutual Information,MI)、信息增益(Information Grain,IG)。针对CHI特征选择算法的“低频词缺陷”,从词频和类离散度两个角度出发提出了改进方法,并在朴素贝叶斯分类器上进行实验。改进后的CHI-M特征提取算法分类平均准确率为87.49%,召回率为86.73%,较改进之前的平均分类准确率和召回率分别提升了4.88%和4.94%,验证了本文改进算法的有效性。(3)文本特征表示是文本分类任务中的重要环节。本文首先重点研究了基于概率模型的LDA主题向量模型和基于神经网络的word2vec词向量模型,并且对两个模型的重要参数进行训练,然后从语义表达和词义联合两个方面考虑,结合以上两种文本特征表示方法,设计了一种新的文本特征表示模型LDA-word。(4)为验证LDA-word文本特征表示模型的有效性,突破传统机器学习分类准确率提高的极限,本文通过深度学习中的卷积神经网络(Convolutional Neural Networks,CNN)实现文本分类。同时为加快模型收敛速度,在卷积层使用了ReLU激活函数。其次,采用Dropout策略减弱卷积神经网络模型的过拟合现象。最后在输出层引入Sigmoid函数,来提高模型输出的稳定性。(5)本文通过深度学习框架TensorFlow中的tensorboard可视化工具来监督三种文本特征表示模型的训练过程,并分别使用LDA主题向量模型、word2vec词向量模型和LDA-word模型进行文本特征表示,然后输入CNN实现文本分类。实验结果表明,本文提出的LDA-word模型的分类结果在准确率、召回率上均有明显提升,并且通过该模型将训练语料库输入CNN之后的训练时间相较于LDA主题向量模型和word2vec词向量模型分别提高了0.71倍和1.56倍。"
752,基于机器学习的天文图像复原研究,"天文图像在成像过程中受大气湍流、CCD电噪声等因素影响,最终观测图像发生退化,造成观测信息的丢失,影响观测效果。通过数字图像处理的方法对退化图像进行复原,可以提高图像的像质。目前,大部分研究都采用反卷积的方法对图像进行复原,在复原过程中认为图像视场内的PSF是不变的。实际上,在大视场短曝光成像系统中,图像PSF随时间变化,且同一图像中各个视场位置的PSF都不一致,因此使用一致PSF的反卷积复原方法都不能达到较好的复原效果。基于上述原因,本文提出了一种基于图像PSF特点的大视场分区反卷积算法和基于深度学习的图像复原神经网络。在分区反卷积算法中,首先估计图像的天光背景,提取出星点在图像中的坐标位置,再提取出星点的PSF,进一步对PSF数据进行降维,去除噪声提取特征。然后对降维后的数据进行聚类分析,根据指定的评价指标选取出具有PSF分布特征的聚类结果。将聚类结果结合星点坐标对图像进行分割,使分割结果包含PSF在视场中的分布特征。最后,利用对应类别的PSF与分区后的子图进行反卷积复原,再将复原结果进行拼接,得到分区反卷积复原图像。与传统的分区复原方法相比较,本文的复原结果在信噪比提升方面更为稳定,验证了本文算法对大视场天文图像复原的有效性。将本文的复原算法应用到多通道望远镜的图像叠加工作中,使像质得到提高。在基于深度学习的图像复原网络中,首先根据维纳滤波的数学模型讨论了图像复原过程,再结合PSF的可分解性解释了卷积神经网络的图像复原原理。然后,搭建网络框架,利用模拟的数据对模型进行训练,最后根据峰值信噪比(Peak Signal-to-Noise ratio,PSNR)与结构相似度(Structural Similarity,SSIM)对复原效果进行评价,证实了本文的深度反卷积神经网络的可行性。"
753,基于深度学习的实体关系抽取研究,"关系抽取旨在识别命名实体之间的语义关系。作为自然语言处理中信息抽取的重要子任务,是构建知识图谱、实现语义搜索、建立智能问答系统等应用领域必不可少的关键技术,具有极其重要的研究价值。关系抽取研究的热点经历了知识工程、传统机器学习、深度学习三个不同阶段。本文采用深度学习方法分别对存在单实体对和多实体的句子进行关系抽取研究。单实体对关系抽取时采用了SemEval-2010 Task 8数据集,分别使用Word2vec和GloVe对句子中实体之间的最短依存路径进行词向量表示,作为卷积神经网络和双向长短期记忆网络的输入,然后由网络自动学习特征,通过拼接的方式将两种特征融合,最后用softmax分类器得出所属关系的类型。实验表明,在使用Word2vec单通道输入的情况下,F1值与CNN、DepLCNN、MV-RNN、SDP-LSTM、LSTM-CNN相比,分别提升了14.1%、2.5%、4.7%、1.4%、1.1%。在使用双通道输入时,F1值比单独采用Word2vec和GloVe分别提升了1.0%和4.5%。说明使用多种词向量表示最短依存路径和通过拼接的方式融合卷积神经网络与长短期记忆网络的特征能显著提高关系抽取的效果。句子中包含单一实体对过于理想化,现实中往往包含多个实体,因此本文在ACE 2005英文数据集上进行了多实体关系抽取研究,为了考虑不同实体之间的相互关联,将整个文档表示为一个有向图,图中的节点为句子中的实体,边通过实体及实体对的上下文来表示。然后将实体对间不同长度的路径通过注意力机制聚合成单一向量表示,作为softmax分类器的输入。实验结果表明使用基于注意力机制的路径聚合方案能显著提高多实体关系抽取的F1值。"
754,基于蜜罐技术的Mirai僵尸网络检测技术研究,"随着智能设备和终端的不断发展,物联网技术日趋成熟。由于物联网设备多架设在公网,缺乏有效的保护措施,并且难以升级,其天然的安全隐患造成了物联网僵尸网络的横行。同时,由于僵尸网络的隐蔽性,给安全研究人员的检测和评估带来了较大的困难。本文从Mirai僵尸网络的检测和风险评估等多方面进行了研究。(1)基于蜜罐技术的Mirai僵尸网络节点识别基于流量的僵尸网络识别方法存在数据处理量大、节点通信流量获取困难等问题,难以在未知网络中进行识别。针对这一问题,论文分析Mirai代码,研究Mirai病毒工作机制和原理,设计了Mirai病毒识别特征,结合蜜罐和漏扫技术,提出了Mirai僵尸网络节点识别方法。在此基础上,论文设计并实现了Mirai僵尸网络节点的可视化检测系统。论文在公共网络中对系统进行了验证,共捕获272204次扫描行为,175923次感染行为。(2)基于函数调用图的Mirai病毒文件识别为了提高僵尸网络节点识别的可信度,减少漏检、错检,本文进一步研究Mirai及其变种僵尸网络病毒文件识别方法。无源码条件下的病毒文件识别通常采用特征码/关键字匹配技术,然而由于受混淆和压缩等技术影响,这一方法难以有效识别Mirai及变种病毒。针对这一问题,论文提出了基于函数调用图的相似性的识别方法。首先,论文选取函数调用图作为特征来反映同源程序相似性,利用其对程序语义特性的表现能力来抵抗混淆等语义维持攻击技术的干扰。然后,论文通过邻接矩阵的特征值组合成为图的特征向量来比较其相似性,从而回避了直接比较图相似性的复杂计算开销。最后论文使用有监督机器学习算法学习样本生成分类模型,实现了对Mirai及其变种病毒的识别。仿真分析显示,就受试者工作特征曲线、精确率和召回率等多项指标而言,论文所提算法最终达到0.8239精确率,0.8310准确率,0.8446召回率,且优于基于谱图特征的病毒识别算法。(3)基于节点重要性的Mirai僵尸网络安全风险评估Mirai及其变种是物联网内传播最广泛的僵尸病毒,评估Mirai僵尸网络安全风险对制定网络安全策略具有重要意义。基于隐马尔科夫模型的技术是应用得最广的风险评估方法,但存在不能直接应用于Mirai僵尸网络的问题。此外,该技术也缺乏对节点和网络安全风险关系及影响的评估,尽管在Mirai僵尸网络环境下,该影响难以忽略。针对上述问题,本文提出新的网络风险值计算方法,改进了基本隐马尔科夫模型评估方法。引入了节点重要性的概念,通过节点关联性计算网络中各个节点的节点重要性,通过节点重要性和节点风险值加权的方式计算整个网络的风险,改变了原有风险计算中对所有节点均同等看待的方式。本文使用公开的数据验证了模型,结果显示,论文所提方法对于网络风险变化的敏感度提升,有利于改进物联网环境下的安全事件的应对能力。"
755,基于XGBoost的SSH流量识别研究,"随着人们在网络通信中对隐私的重视,网络流量加密正在成为一种保护隐私和通信安全的常用手段。但是,网络流量加密也给网络流量识别和异常流量检测带来很大的难题。SSH(Secure Shell)协议是目前使用比较广泛的应用层安全协议,拥有比较完善的交互认证机制和非对称的加密机制。这种加密机制在给用户提供安全通信服务的同时,也使一部分用户能够通过SSH隧道隐蔽自己的非法行为,特别是利用SSH协议的端口转发功能来访问国外非法网站。因此,对SSH流量的识别进行研究具有重要的意义。首先,本文对SSH协议交互的过程进行了深入实验和分析,解决了SSH隧道下不同应用的特征向量提取问题,进而提取了SSH隧道下不同应用握手阶段的包长特征、基于网络流的特征和比例类型的特征。此外,在特征提取过程中会出现网络波动等异常情况,造成数据传输过程中的丢包和重传,使得采集到的网络流量中存在噪音样本,进而导致训练样本中出现类别概念模糊的问题。本文针对此问题提出了基于孤立森林的SSH特征向量去噪方法,有效提升了识别方法的准确率。其次,本文针对SSH加密流量特征是连续的、非线性的特点,将XGBoost集成学习方法应用到SSH加密网络流量分类研究中。该方法可以很好地处理加密流量中连续的、非线性的统计特征,例如包长,时间间隔等,也增加了很多防止过拟合的方法,例如正则项,决策树的深度,叶子结点的权重,特征采样等。本文还对XGBoost集成学习方法的迭代次数和基分类器的参数进行了优化,以便更好地识别SSH隧道下的应用。优化后的方法相比传统机器学习模型对SSH加密流量识别准确率和召回率有很大的提升。针对SSH隧道下HTTP、FTP、SMTP、SCP、Login等五种常见应用进行实验,识别准确率和召回率都在90%以上,其中对于HTTP协议的召回率达到了95.81%。"
756,基于SDA的中文垃圾邮件过滤研究,"随着互联网技术的高速发展,电子邮件以其成本低廉、传输便利的优势在互联网上被广泛使用,逐步成为人们重要的一种交流通信工具。但是在商业利益的驱动下,企业和个人经常通过群发邮件进行营销,使得用户收到的垃圾邮件数量远远超于正常邮件数量。据统计,在2018年全球虚假电子邮件的日发送量估计已高达64亿,过去几年中,企业电子邮件诈骗(BEC诈骗)损失成本已达到120亿美元。由此可见,对反垃圾邮件技术的研究不可或缺。传统垃圾邮件过滤方法在中文垃圾邮件过滤中存在准确率不高、数据特征难以提取的问题,而浅层神经网络模型在垃圾邮件过滤中不能表示复杂的目标函数,训练时容易陷入局部最优。本文提出了基于SDA的中文垃圾邮件过滤方法,首先对深度网络进行无监督逐层预训练,初始化网络参数;然后通过有监督学习对网络参数进行反向微调,获取最优的模型参数;该深度网络模型可以很好的对短文本中文垃圾邮件进行过滤,并针对深度网络在训练时速度慢、模型鲁棒性差、容易受噪音影响以及容易出现过拟合等特点,对模型进行了优化和改进。本文主要的工作如下:(1)本文采用TREC06C数据集,提取其中的11360条短文本中文垃圾邮件数据正文作为样本数据,然后通过训练Word2vec中CBOW模型来获取深度网络分类所需要的词向量,并将自然语言处理中的深度学习模型堆叠式降噪自编码器应用于中文垃圾邮件中;(2)由于深度网络在训练时极容易发生过拟合现象,本文在深度网络中加入Dropout技术来防止网络过拟合,实验表明:网络中添加了Dropout后,结果更加平稳,网络的泛化效果更好;(3)本文采用的W2C_SDA深度网络中文垃圾邮件过滤模型是一个混合的深度网络,它由堆叠式降噪自编码器和Softamx分类器组合而成;为了提高网络的收敛速度和缓解过拟合现象,在Softmax分类器中加入了L2正则化,实验表明:添加了L2正则化后,网络收敛速度加快,准确率提高了0.2%;(4)通过实验获得W2C_SDA模型最优参数,并且在一个数据集上与伯努利贝叶斯过滤模型和KNN过滤模型的分类效果进行对比,实验表明:与贝叶斯过滤模型和KNN过滤模型相比较,该方法在中文垃圾邮件过滤效果更好。"
757,基于深度卷积网络的跨站脚本检测方法研究,"随着XSS攻击方式的转变与多样化,使得检测的难度日益提高,并且带来的危害也与日俱增。由于恶意攻击代码的数量逐渐增加且不易识别,传统的XSS攻击检测模型已经难以检测形式越来越复杂的攻击。因此,本研究将深度学习的方法应用到XSS攻击检测中,其不仅能够学习更复杂的目标函数,而且可以获取更优异的特征,在处理样本量巨大且高维的XSS数据时具有更大的优势。针对传统方法对XSS攻击检测存在攻击脚本针对性不强、数据检测不准确、容易造成漏洞检测覆盖率低等问题,而浅层机器学习方法训练速度慢、难以对高维度的特征进行描述,提出了AMCNN-Highway深度网络的XSS检测方法,该方法可以从海量XSS数据中很好的区分出攻击与正常脚本。本文主要贡献如下:(1)首先收集20万条用于训练的XSS数据,为了增强数据的可辨识度,对获取的XSS数据以Word2vec的方法进行处理;并且深入研究了卷积神经网络(CNN)对自然语言处理的原理及实现过程,对自然语言处理中应用最为广泛的TextCNN深度学习模型进行分析;(2)为了使深度网络在训练的过程中关注更多有代表性的恶意代码特征,在TextCNN结构的基础上增加了恶意代码注意力机制;经过恶意代码倾向注意力算法对XSS语料词向量进行运算获取输入矩阵,构建了基于恶意代码注意力的XSS检测模型(ACNN);实验表明,该方法比TextCNN有更高的检测准确率;(3)对ACNN的检测模型进一步深层优化为AMCNN-Highway深度网络;通过加深神经网络的层数,对AMCNN中最后三层网络的XSS特征图采用多尺度池化操作获得多层特征,将获得的各层特征向量进行融合,融合后的特征向量作为Highway网络层的输入;经过Highway网络局部调整优化的输出被当做Softmax分类器的输入以完成最后的XSS检测任务。通过实验得出AMCNN-Highway深度网络的最优参数,并且与其它的XSS检测方法对比,本文模型获得的准确率相比其它检测方法有较好的提升。AMCN N-Highway深度网络的XSS检测方法主要体现四个层次方面的优点:有利于对高维特征数据分析;使得网络的训练速度更快;提升神经网络的泛化能力;提升网络对XSS检测的准确率,有效的避免漏报与误报。"
758,基于仿生算法的网络入侵检测系统研究,"随着互联网的不断扩展和高速发展,网络环境变得越来越复杂,存在的风险也越来越大。因此,网络安全已经成为一个非常重要的问题。网络的缺陷可能会导致网络攻击,并影响用户的隐私。为了保障网络信息安全,网络入侵检测技术得到了广泛重视。网络入侵检测技术是利用入侵者留下的痕迹信息,如试图登录的失败记录等,有效地从外部或内部发现非法入侵。由于网络环境日渐复杂,传统的入侵检测方法运行速度较慢并且对未知网络攻击的识别能力较差,其无法有效解决现有的网络入侵问题。机器学习作为新一代的人工智能技术,能够针对大量的数据进行自主学习和训练,有望弥补传统方法的不足,为入侵检测带来新的发展和突破。另外,仿生算法作为一种模拟生物免疫系统防御行为的新兴技术,在计算机科学领域也受到了越来越多的关注。生物免疫是一种复杂的分布式信息处理学习系统,有较强的自适应性、多样性、学习、识别和记忆等特点。基于人工免疫系统的一些模型和仿生算法在实际应用中显示了优良的信息处理能力。人工免疫系统在入侵检测方面取得了一些成功,但人工免疫理论研究还不够成熟,部分提出的检测模型并没有使用实际的数据进行验证。在研究网络入侵检测技术的过程中存在数据量大、检测率低、误报率高等主要问题。因此,本文基于现有的研究成果,针对入侵检测系统的不足,进行相关的改进和提高,并研究新型的网络入侵检测系统。主要工作体现在以下四个方面:1.首先介绍了课题的研究背景,主要包括课题的由来以及主要研究内容,然后给出本文工作的创新点。接着介绍了网络入侵检测系统的发展,并简单介绍了基于机器学习的网络入侵检测研究。然后介绍了人工免疫系统理论以及常见的人工免疫算法。最后对入侵检测领域存在的不足做了分析,并给出了相应的解决思路。2.针对支持向量机算法分类中存在的不足,提出了基于粒子群算法优化支持向量机参数的网络入侵检测模型。在数据预处理部分利用one-hot编码对数据集中的离散数据进行转化,用主成分分析算法对特征进行降维,减少了支持向量机运算的复杂度并节省了时间。利用NSL_KDD数据集进行二分类和多分类实验,从总体分类准确率、检测率与误报率三个方面与其他机器学习方法进行比较。3.针对传统否定选择算法检测器集合存在冗余的问题,提出了一种改进的V-detector算法。首先设置半径可变的检测器生成算法,在检测器生成过程添加一个距离最近的自体为特征变量,提高检测器生成效率,降低检测器集合的冗余。然后在检测器终止条件时选用假设检验方法,保证检测器对非自体空间覆盖率一致的情况下,减少了训练过程的时间。最后利用改进的单个V-detector分类器构造多级分类模型以解决网络入侵检测中的多种攻击类型分类问题。4.利用改进的V-detector算法和新型人工免疫算法树突状细胞算法组成新的入侵检测模型。V-detector算法来源于否定选择算法,树突状细胞算法来源于危险理论,两种方法的结合属于不同类型的分类器异构集成。两种单分类器的集成结合了两种的优点,采用加权多数投票原则综合分类结果。该模型应用于网络入侵检测方向,提高了对未知类别的识别能力,降低了误报率。"
759,改进k-means和Adaboost实现标签分布学习,"目前在机器学习领域,有监督学习依然占据着重要的作用。有监督学习的主要学习方式有单标签学习和多标签学习。但是,由于单标签和多标签学习只能表示标签和实例的“是”或“否”的对应关系,而不能很好地应用在需要相关标签来表示对于实例的重要程度的应用场景中。因此,标签分布学习作为一个新型的机器学习范式被提了出来。在标签分布学习范式下,实例对应的标签能表示对于实例的描述程度。目前的标签分布学习算法的实现主要有三个策略:(1)问题转换,(2)算法适应,(3)专门化算法。本文就依据第二个策略提出并实现了以下两种基于算法适应的标签分布算法:(1)针对标签分布数据中样本实例的特征空间和标签分布空间可能存在的关系,提出了应用k-means算法实现标签分布学习(KM-LDL)。该算法考虑到在特征空间中邻近的样本,那么其对应的标签分布在空间中也应接近。那么利用k均值算法(k-means),对训练集的样本进行聚类,然后找的每个特征簇所对应的标签分布集合。最后利用测试集特征向量和训练集的各个簇均值向量间的距离作为权重,来预测测试集的标签分布。该算法和现有的3种标签分布算法在6个公开的数据集上实验,实验结果表明该算法在5种评价指标上都取得了更优的效果。(2)通过观察可以发现传统的多标签学习的BP神经网络在输出结果之前,使用softmax函数输出一个概率分布的结果,而标签分布的形式与概率分布相似。由此,我们利用传统的神经网络得到的概率分布形式的结果就可以作为所要预测的标签分布,在此基础上,进一步结合AdaBoost的BP神经网络算法来提高预测性能,提出基于BP-Adaboost的标签分布学习(LDL-BPAB)。更进一步地,引入自适应阈值来改进LDL-BPAB,提出基于自适应阈值改进的BP-Adaboost算法的标签分布学习(LDL-IBPAB)。在8个公开的数据集上实验表明,LDL-BPAB算法取得了令人满意的结果,同时LDL-IBPAB取得了更优秀的实验结果。"
760,基于机器学习的房产智能自动评估模型的研究与系统实现,"自动评估模型作为房产估价的核心,应具备以下特点:1)数据质量高:数据决定了模型的上限,而且房产评估的可比案例要求可信;2)特征的选取和量化方法合理:影响房地产价值的特征因素的选取和量化需要符合中国房地产市场数据的特点;3)模型精度高:房产价格受多种因素的影响,但需要对其价格进行准确的评估。但是在现有研究中,还存在缺乏房产数据质量提升的研究、影响房产价格的特征因素体系不够完善、模型研究局限在验证单模型有效性的问题。针对以上问题,本文具体研究内容如下:1)基于多相似度估算器的房源重复记录识别模型:解决从不同房源抽取出的房产记录信息存在严重的重复房源问题;2)基于房价特征因素体系的特征提取及量化方法:解决国内房价特征因素体系不够完善,因估价人员的主观因素影响估价精度的问题;3)基于多层级模型融合的自动评估模型:解决由于房产价格受多种因素的影响,而且房产分区难以合理划分,导致模型建模复杂、精度不高的问题。基于上述研究内容,本文在已有爬虫和地址治理能力的基础上,实现了较高精度、可落地的房产批量评估系统,估价精度指标MAPE达到9.3 8%,具体包括以下模块:1)房源重复识别模块:实现了基于多相似度估算器的房源重复记录识别模型的封装和接口调用;2)特征工程模块:实现了基于房价特征因素体系的特征提取及量化,并可根据配置对特征进行预处理;3)自动评估模块:实现了基于多层级模型融合的自动评估模型的封装和接口调用。4)模型迭代模块:实现模型定期迭代更新机制,解决房价受时间因素影响的问题。"
761,双曲空间中的神经网络图表示学习,"机器学习试图使用图结构化数据作为特征信息进行预测或发现新的模式,其研究重点主要集中在嵌入图中的离散节点进入具有某些所需几何特性的连续空间。尽管图表示学习潜力巨大,但将图嵌入到低维空间并不是一项简单的任务。本文的工作重点是赋予神经网络表示适当的几何结构,以捕获图数据的基本属性,特别是层次结构和聚集行为。而复杂网络中的异质和高聚集拓扑特性却令人惊讶的反映在双曲负曲率空间的基本属性中。因此,本文的目的是通过使用神经网络对相互作用或关系进行建模,并利用数据所存在的双曲流形度量结构来学习得到节点的低维紧凑特征向量表示。而后,探索双曲空间是否有助于学习图数据的嵌入。本文通过将图中丰富的层次结构与现代机器学习所支持的连续表示相融合,分别提出了基于Poincaré模型的生成对抗图表示学习和基于双曲面模型的神经排序图表示学习来捕获图数据的潜在特征表示,特别是其都利用了神经网络的无监督端到端方法以及双曲几何的分层自组织能力来自动抽取节点的相似性和层次结构信息。(1)基于Poincaré模型的生成对抗图表示学习,通过将距离度量设置为Poincaré双曲几何模型中的距离函数,以此来明确的在嵌入空间中抓取数据的层次结构特征。同时,该方法结合先进的随机游走策略探索图的远程拓扑结构信息来构造训练所需的数据集,利用神经网络的对抗学习原理来自动获取更高层次的节点特征表示。所设计的神经网络通过生成模型和对抗模型之间的相互竞争来交替提升彼此的性能,采用强大的学习优化策略来提升模型效率,从而使得该方法能够产生更高质量的节点特征表示。而后,将学习得到的节点特征向量表示分别应用于节点分类、链接预测和可视化并分析了模型的维度敏感性,其实验结果表明该方法在多个任务中具有良好的表现力和有效性。(2)受到一些最近提出的利用双曲空间来提供强有力蕴涵关系表示的启发,基于双曲面模型的神经排序图表示学习没有使用过度复杂的节点交互机制,而是设计了一种嵌入双曲几何的更小更快的神经排序模型来捕获图数据的拓扑结构信息。该方法通过贝叶斯个性化排序目标来最大化正确链接和错误链接之间的差距,以自动学习节点之间的相似性信息。为了捕获数据的层次结构特征信息,特别的在神经网络模型的双曲层通过双曲面模型中的距离函数计算节点之间的层次距离得分。最终,该模型利用基于黎曼梯度下降的方法来学习低维紧凑的节点特征向量表示。在得到节点的潜在特征向量表示后,本文在节点推荐和节点分类任务上对比不同空间中的图表示学习方法,以及分析所提出的方法对维度的敏感性和模型的收敛性。实验结果表明所提出的方法在节点特征学习上不仅高效而且能获得更加紧凑和更具表达力的特征向量表示。综上,本文通过在神经网络模型中引入双曲几何度量来学习图中节点的拓扑结构特征表示,并展示了它们如何高效地学习节点的相似性和层次结构,以提供超越欧几里德嵌入的优势。诸多实验结果表明所提出的方法在节点特征学习上不仅高效而且能获得更加紧凑和更具表达力的特征向量表示。同时也表明,学习有意义的图表示可以使许多重要的图分析任务受益,而嵌入双曲空间中的层次结构能很好地对应于数据的基础语义。"
762,属性选择鲁棒性研究,"随着数据信息化的日益发展,人工地从数据中筛选出需求的信息已经变得十分困难,为此研究者以统计学思想为基础提出了机器学习方法,而其中分类、聚类和回归分析等知识发现方法更是获得了较为广泛的应用。但原始数据中可能存在的冗余及偏差信息会导致知识发现算法难以获得预期的结果,因此预先对数据进行必要的处理在机器学习领域的研究中同样十分重要。以属性选择算法为代表的数据预处理技术被提出用来从从原始数据中提取出更加重要及“纯净”的信息。基于训练方式的不同,传统的属性选择方法可以被分为三类,即过滤式、包裹式及嵌入式。由于嵌入式方法将属性选择过程与训练过程融为一体,因而可以在优化过程中实现自动选择属性的效果,已经被研究证明优于过滤式方法和包裹式方法。然而,传统的属性选择方法虽然能够在一定程度上降低原始数据的维度并提升后续知识发现模型的学习效率,但仍然难以满足现阶段数据尺寸高速膨胀的状况。这是由于处理高维数据的困难不仅仅只源于数据中样本的数量及维度的增长,而是应对伴随着增长而带来的大量冗余、噪音以及离群点等难题。因此,本文以传统嵌入式属性选择模型为基础结合自步学习、低秩学习及谱图学习理论提出三种更加鲁棒的属性选择算法来应对高维数据存在的不同问题。论文的主体内容分为如下部分:(1)基于自步学习的无监督属性选择算法(UFS_SPL算法)。UFS_SPL算法将结合自步学习、稀疏学习和属性自表达技术,提出了一种无监督属性约简模型。此算法利用属性自表达实现无监督学习并使用自步学习解决传统属性选择算法忽略样本之间的差异性从而导致模型易受离群点干扰的问题。具体地,UFS_SPL首先自动选取一个重要的样本子集训练得到属性选择的鲁棒初始模型,然后逐步自动引入次要样本提升模型的泛化能力,最终获得一个同时具有鲁棒性和泛化性的属性选择模型。通过聚类实验评测,UFS_SPL算法在真实数据集上相较其他属性选择算法具有更好的效果。(2)属性自表达的低秩无监督属性选择算法(LFSR算法)。LFSR算法将结合低秩学习、谱图学习、属性自表达及稀疏学习技术,提出一种鲁棒的低秩谱属性选择模型。此算法结合低秩学习与谱图学习技术处理传统无监督属性约简方法难以深入探索数据内在结构(即全局结构和局部结构)从而导致属性选择效果有限的问题。具体来说,LFSR算法首先用一个属性自表达损失函数加上一个稀疏正则化(?_(2,1)-范数)实现无监督学习与属性选择,然后使用低秩学习和谱图学习同时考虑数据的全局结构和局部结构来降低冗余与噪音的影响。经聚类实验验证,该算法较对比算法能取得更好的效果。(3)基于动态谱图学习的谱属性选择算法(DG_SFS算法)。DG_SFS算法将动态谱图学习、稀疏学习融入到回归模型中,提出一种鲁棒的动态谱属性选择模型。此算法针对传统谱属性选择方法中从原始数据构造的谱图矩阵容易受到原始特征空间的冗余及噪音影响的问题。具体地,DG_SFS算法首先利用有监督回归模型与组稀疏?_(2,1)范数实现属性选择基本功能框架,并在已建立的框架中添加谱图学习理论动态地从原始数据的低维子空间中挖掘数据内在局部结构并实现一步属性选择策略。经过分类实验验证,该算法获得了更好的属性选择效果。本论文针对传统属性选择模型存在的不足对属性选择进行鲁棒性改进研究,并通过分类或聚类算法作为实验的评测途径使用不同评价指标对结果进行分析。同时,为验证提出算法的正确性,论文中所有算法均严格按照统一实验环境进行验证和分析。实验结果显示本文论文提出的新算法在各项指标均优于选取的对比算法。在未来的工作中,本人将考虑把这些技术直接应用到聚类、分类或回归算法中。"
763,多样本多维数据的智能分类预测模型及其应用,"多样本多维数据是指由大量的具有多维属性的样本组成的数据集。此类数据普遍存在于材料、医疗、航空航天、电力电子等领域,通过挖掘和分析这些数据,构建预测模型,可推演出上述领域中某个指定目标变量的可能性结果。然而,尽管近年来大数据分析与预测理论获得了较大发展,但因上述多样本多维数据具有模糊性、不确定性、耦合性和多维属性特性,直接采用现有的机器学习算法和统计分析方法,较难获得高预测精度。本课题的研究目的是提出多样本多维数据分析与智能预测理论与方法,并应用它解决牙周炎疗效的分类预测问题,也为其他领域的多样本多维数据挖掘与预测提供可借鉴的方法。本文的主要创新性工作包括:(1)在分析一维云的基础上,为了适应数据多维度的特性,分别提出了二维云模型和多维云模型构建方法,给出了二维和多维前件云产生云滴的算法过程和二维与多维单规则发生器的算法步骤,解决了多样本多维数据的模糊性和不确定性引发的预测精度低的问题。(2)在详细分析Xgboost、PCA和BP神经网络的优缺点的基础上,提出了Xgboost-PCA-BPNN组合预测算法,降低了多样本多维数据的耦合性和多维性对预测性能的影响,提升了预测准确度。(3)在分析北京某口腔医院牙周炎治疗过程4.5万例位点数据的基础上,分别将所提出的多维云模型和Xgboost-PCA-BPNN组合预测算法应用于牙周炎治疗效果预测,获得了较好的预测效果。测试结果表明,Xgboost-PCA-BPNN组合预测算法精度达82%,优于多维云模型和其他机器学习方法,如逻辑回归、Xgboost和Xgboost-逻辑回归组合算法。"
764,金融科技对证券投资咨询行业的影响研究,"近几年,金融科技逐渐受到关注,各大行业开始纷纷布局金融科技,证券投资咨询行业也不例外。当前,许多证券投资咨询行业中的机构想通过金融科技节约成本、提高效率,从而提高机构竞争力,这种现象也促进了证券投资咨询行业的发展。本文运用金融学、法学和计算机等相关知识和理论,以金融科技、证券投资咨询行业为两条主线,对恒生电子智能投顾产品进行剖析,探讨其对证券投资咨询行业影响的正效应及风险,在此基础上阐述了该案例对行业发展的借鉴意义及启示。文章首先概述了金融科技和证券投资咨询行业,分别对金融科技发展历程、特征、国内外证券投资咨询行业发展现状、行业SWOT进行分析,并运用PEST模型探讨了两者结合的环境,为恒生电子智能投顾案例应用做铺垫。其次探讨了恒生电子智能投顾案例,通过对智能投顾的四款产品逐个分析来梳理恒生电子金融科技在证券投资咨询行业中的运用,同时提出运行过程中可能存在的问题。最后从智能投顾对证券投资咨询行业影响的正效应和风险两个方面进一步剖析,充分挖掘恒生电子智能投顾案例对证券投资咨询行业的促进作用以及针对存在的风险提出适当的解决方案。他山之石,可以攻玉,文章的最后,根据恒生电子智能投顾案例,结合当前证券投资咨询行业的现状,对金融科技在证券投资咨询行业的运用作出进一步思考。"
765,时间序列聚类分析中几种算法的研究及应用,"聚类是无监督机器学习方法之一,聚类数据可以帮助识别相似数据,为决策行为提供最佳方案。例如,预订出租车应用程序可以把客户数据进行聚类分析以匹配供求关系、检测电子商务交易的恶意订单类型或在约会应用程序中将客户分类等。为了得到聚类的最佳决策结果在各种的聚类分析都有自己的基本条件请求,当用错误的数据分析条件请求时会导致低质量的结果。因此,我们希望深入研究和比较这类数据。应用时间序列分析基于先前观测值的预测,将聚类分析和时间序列数据混合起来,以便更好地理解聚类分析,以达到服务广大公众的初心,同时还希望更多的专家学者在这一领域持续探索,以期未来在更广泛的领域应用。目前常用于描述金融市场中的数据,如数字货币、人民币兑美元汇率、上海证券交易所50指数(上证50)和泰国证券交易所50指数(泰证50)。本文主要研究金融时间序列数据的时间序列聚类算法比较,通过时间序列聚类分析研究金融市场的数据,得出不同数据集的最有效聚类算法,并验证了其合理性及有效性。本文主要内容如下:1、论文依次介绍了数据挖掘、机器学习、时间序列聚类的重要性以及相关的一些检验方法的基本原理,为文章开展正式研究奠定理论基础。2、论文综述了生物信息学、机器人学、医学、化学、手势识别、语音识别、跟踪、金融、生物特征学、天文学、制造学等领域的相关数据挖掘、机器学习和时间序列聚类研究。3、论文通过分析时间序列聚类的结构,包括距离测量、时间序列原型、聚类算法和聚类评价标准等几个部分。本文针对每个数据集分别设置了3种模式的聚类算法,如层次聚类、k-中心点划分聚类、K-形划分聚类和Tadpole划分聚类。我们使用轮廓索引(Silhouette index)、COP索引(COP index)、DB索引(DB index)、CH索引(CH index)和DB*索引(DB*index)等聚类评价方法来比较这些聚类算法是否有效性。4、论文在实证分析中,构建了关于数字货币、人民币兑美元汇率、上证50指数(上证50)和泰国证券交易所50指数(泰证50)的时间序列聚类分析。对每个时间序列数据集使用3种聚类算法模式比较,并用5个指标对聚类算法进行评价,以确定每个聚类算法的有效性。研究结果表明,层次算法是对于非等长度数据数字货币和上证50指数最有效的算法。另外,对于等长度数据所有货币兑美元汇率和泰国证券交易所50指数(泰证50),划分算法是最有效的。"
766,基于加权支持向量机的概率估计在个人信用评估中的研究,"近年来,随着中国经济的快速发展,个人小额信贷业务持续增长,像住房按揭、信用卡、汽车贷款等个人消费贷款需求逐步扩大。在信用贷款中,申请人(客户)通常关心能否及时发放贷款;而金融机构则担心申请人(客户)能否在预定的时间内偿还贷款,以降低信用违约所带来的经济损失。目前,我国的个人信用评估体系尚不完善,贷款违约时有发生。为了减少损失、节约成本并科学发放贷款,需要一个准确且合理的个人信用评估体系作为支撑。个人信用评估体系的核心是根据以往信贷申请人的个人信息建立信用评估模型,并依据个人信用评估模型预测新的信贷申请人能否按时还款,从而决定是否为其发放贷款。良好的信用评估模型不仅可以帮助金融机构准确预测申请人的个人信用,从而准确且高效地处理贷款审批,有效地规避信用风险、降低经济损失,也有利于信用好的申请人更快地申请到的贷款,提高经济运行效率。本文通过回顾以往个人信用评估模型,发现当前个人信用评估模型存在如下问题:第一,现今社会已处于大数据时代,个人信用评估数据不仅数据量大,而且数据维数较高,传统的基于统计学习方法的个人信用评估模型计算成本大;第二,传统的基于机器学习的个人信用评估模型尽管计算速度快,但大多只能进行分类不能进行概率估计,个人信用评估模型如果可以进行概率估计,能极大提高模型的适用范围。针对以上不足,本文对传统的支持向量机(Support Vector Machine,SVM)模型进行改进,建立了加权支持向量机(Weighted-Support Vector Machine,w-SVM)的概率估计模型,将w-SVM的概率估计模型用在个人信用评估中。首先,w-SVM的概率估计模型将两类样本,即“违约”客户和“不违约”客户的损失函数加权处理;其次,在信贷审批中,不同额度的借贷对用户信誉的要求不同,w-SVM的概率估计模型可以对两类样本进行概率估计,从而根据实际情况设定阈值,最终将客户分类为“违约”客户和“不违约”客户,从而提高模型的适用性;最后,本文将w-SVM的概率估计模型与逻辑斯蒂回归(Logistic Regresion,LR)模型、随机森林(Random Forest,RF)模型、传统的SVM模型进行对比,综合考虑模型预测的准确率、召回率、精确度、_2F、AUC(Area Under Curve)各项指标,证实了w-SVM的概率估计模型在个人信用评估中具有显著优势。"
767,抗氧化剂分子数据库建立及其QSAR分析,"自由基攻击几乎所有类型的生物化学物质,如脂质,蛋白质,DNA等,这些都是自由基链式反应。过量的人体内自由基导致氧化应激,会导致各种类型的全身性疾病的发展。传统抗氧化剂的筛选方法需要耗费较大的人力物力。因此亟需建立具有统计学意义和预测能力的QSAR模型,进而快速、准确地预测筛选化合物的抗氧化剂活性。本研究的目的是建立一个高质量的体外抗氧化剂数据库,并且据此综合运用化学信息学原理建立稳定可靠的QSAR模型,建立化合物清除DPPH自由基的能力与相应的结构特征间的定量构效关系模型来预测化合物的抗氧化活性。用于筛选新的潜在抗氧化剂。从PubChem数据库和文献中收集了具有抗氧化活性的化合物,并且通过去除重复值、无机物和离散值,保留799种化合物的完整antioxidantsDB数据库,该数据库中抗氧化剂分子的pIC50活性值从3.2到5.5,logP(o/w)辛醇/水分配系数范围-4.5~20.3,抗氧化剂的分子的量范围110~2809.9 g/mol。数据库中天然来源的抗氧化剂化合物占37.3%。分子量在200到600 g/mol之间,logP(o/w)在0到5之间包含的抗氧化剂分子最多。合成的抗氧化剂大多都是亲脂性的。天然的抗氧化剂分子量较大。antioxidantsDB中主要的化合物类别为苯并咪唑衍生物、香豆素衍生物、吡唑衍生物、吡啶衍生物、噻唑衍生物等。数据库中包含的物理化学、生物活性信息,如官能团、抗氧化活性区间、分子量、氢键供体、氢键受体和分子类型,有助于全面深入了解抗氧化剂分子。通过该数据库,可以进行化合物的相似性搜索,结构搜索等基于特征的查询,同时使用数据库方便研究者快速了解抗氧化剂目前研究现状,以便进一步进行数据分析与预测。在QSAR的开发过程中,分子描述符作为活性和小分子结构的桥梁,是QSAR分析的基础。使用MOE软件生成2D和3D分子描述符一共有322个。其中不相关的冗余描述符会影响预测精度。通过PCA和共线性分析去除和抗氧化活性不相关的描述符有300个,保留了重要的22个描述符为PEOE_VSA-3、vsurf_CW8、E_sol、a_don、vsurf_HB8、SlogP_VSA0、h_pKa等。基于22个分子描述符,采用PLS、SWR-MLR、SVR、RF、kNN算法建立了五种QSAR模型。通过训练集内部10折交叉验证,Q~2均大于0.64、RMSE_(cv)均小于0.23,对于测试集模型的表现R~2均大于0.67,RMSE均小于0.22。模型具有良好的拟合性和预测性。RF模型的内部10折交叉验证有最好的效果Q~2等于0.70,RMSEcv为0.20。对于测试集kNN模型的预测能力最好R~2等于0.74,RMSE等于0.19。开发的模型具备预测能力,可以用于预测一组化合物的抗氧化活性,模型的预测结果和实验值相关系数均大于0.5。其中PLS模型对这组包含实验值的外部验证集预测效果最好R等于0.63。通过本项目的研究,建立了数据库,提供了采用化学信息学原理进行抗氧化物研究的基础,通过化学信息学原理和方法进一步促进抗氧化物的研究和筛选。尽管我们尽了最大的努力,antioxidantsDB并不是所有抗氧化剂分子的详尽存储库。在未来,我们打算增加抗氧化剂分子的覆盖面,并寻找它们对人类健康的潜在影响。我们将继续增加抗氧化剂分子数据库的覆盖面,增加模型预测能力,并进行抗氧化剂人类健康的潜在影响的研究。为了获得更多关于抗氧化能力的物理化学决定因素的信息,扩展我们已知的抗氧化剂分子的化学空间是值得的。"
768,迁移学习在湿式球磨机负荷参数软测量中的研究与应用,"球磨机是在选矿、电力和化工等流程工业领域的一种基础磨矿设备。该工业设备的效率与其内部负荷具有密切联系,及时调整磨机的装球量及给料量,使磨机稳定运行在最佳负荷点,对提高磨矿产品质量和磨矿系统的安全稳定运行意义重大。因此,能够表征球磨机内部工作状态的关键负荷参数(料球比、浓度、充填率)的准确检测对于球磨机的优化运行控制具有决定作用。受限于球磨机的机理模型复杂,具有大时滞、随机干扰大等特点,常规的仪表检测方法无法实施,因此通过建立辅助变量和主导变量之间的函数映射关系而实现预测未知主导变量的软测量建模方法已成为该研究领域的关键技术之一。然而,在实际生产过程中,存在着钢球磨损,突然添加钢球等操作,造成工况的改变,以至于造成数据分布的改变,从而导致模型不能准确测量负荷参数。针对上述湿式球磨机运行过程中工况发生迁移的问题,本文将迁移学习引入软测量算法中,重点研究多工况情况下,湿式球磨机负荷参数软测量方法。主要的研究内容可归纳为以下几点:1、针对球磨机工况改变后,实时工况和历史工况数据分布失配导致的模型失准问题以及实时工况样本少的问题,提出一种基于迁移变分自编码器-标签映射的软测量模型。首先迁移目标领域数据编码得到的隐变量分布参数,对源领域数据对应隐变量进行拟合,再解码得到迁移数据;然后采用相似性度量选取相似样本构建标签映射模型,并得到映射标签;最后使用迁移数据和映射标签构建出最终的软测量模型。2、针对球磨机工况改变后,实时工况和历史工况数据分布失配导致的模型失准问题以及实时工况样本少的问题,引入域适应思想,提出一种基于域适应支持向量回归的软测量模型。迁移目标领域中少量带标签样本数据所蕴含的特征信息,矫正源领域模型,提升源领域数据构建模型对目标领域数据的适应程度。3、针对域适应支持向量回归方法缺少对高维数据空间分布结构的约束,提出一种基于域适应流形正则支持向量回归的软测量模型。以适用于非线性数据的SVR为基础,通过少量目标领域的带标签样本构建DASVR模型,把流形正则项引入到DASVR中,约束数据的空间结构。"
769,基于鱼群跟踪轨迹的生物水质预警方法研究,"水污染问题一直是影响人类生命健康及财产安全的重要因素,而水质监测是实现水污染治理的前提。因此,如何实现水质变化的监测及预警是当下迫切需要解决的问题。目前常用的水质监测方法是理化监测法与生物监测法,其中生物监测法可弥补理化监测法的不足,实现污染物间混合效应的监测,能够更加实时、准确、高效的反映水质变化状况。本文基于计算机视觉原理,以红鲫鱼鱼群为水质指示生物,通过调节水体pH值获取不同环境下鱼群游动视频,采用多目标检测与跟踪技术、智能信息处理及机器学习技术,研究了基于鱼群跟踪轨迹的生物水质预警方法。主要的研究内容包括:1、设计了能够监测鱼群运动行为变化的生物水质预警系统平台及鱼类毒性实验的实验方案。该平台硬件部分主要包括:视频采集设备、鱼群实验水箱及上位机监控设备等3部分;软件系统主要包括系统简介、视频采集、检测跟踪、记录查询、水质预警等5个功能模块。通过在该系统平台上进行的多次鱼类毒性试验表明,平台可实现对鱼群运动行为变化的连续监测及水质预警。2、研究了基于Kalman滤波算法的鱼群多目标检测与跟踪方法。针对鱼群个体目标间相互遮挡造成的检测与跟踪难的问题,提出了结合鱼体运动方向的鱼群多目标检测与跟踪算法。基于背景差分法实现鱼群目标的检测;利用Kalman滤波算法进行鱼体运动状态的估计,建立鱼体质心、面积及运动方向相结合的代价方程,通过帧间关系矩阵实现相邻帧鱼体目标的匹配关联,完成鱼群多目标跟踪。实验结果表明,相比于只基于质心信息的鱼群多目标跟踪算法,本文提出的跟踪算法性能有着显著提升,可有效应对多目标检测与跟踪难的问题。3、研究了鱼群运动行为特征参数的量化方法。基于鱼群运动轨迹,对鱼群个体及群体特征参数进行量化,个体特征参数包括:运动速度、运动加速度,群体特征参数包括:鱼群平均游动速度、平均游动距离及鱼群离散度。并对比了正常水质(pH=7)与异常水质(pH=6,8)环境下5个参数的变化情况,实验结果表明不同水质环境下上述鱼群运动行为特征参数具有显著差异,可为生物水质预警研究提供数据支撑。4、研究了基于机器学习的生物水质预警方法。为解决现有阈值加权求和法进行生物水质预警过程中阈值参数多、参数确定过程复杂及预警精度低的问题,提出了基于GA-SVM的生物水质预警算法。将正常水质与异常水质下的鱼群运动行为特征参数作为不同类的样本集,利用SVM模型对样本集进行分类,通过遗传算法对模型参数进行优化,实现生物水质预警的分类;并对比了固定参数、K-交叉验证优化参数及GA算法优化参数的SVM模型分类准确率。实现结果表明,采用GA算法优化参数的模型分类准确率最高,验证了基于GA-SVM生物水质预警方法的有效性。"
770,基于深度学习的遥感影像分类应用研究,"遥感影像记录了丰富的地面物体光谱信息、空间结构信息,是地面物体整体面貌最直观的表现。利用影像记录的信息对遥感影像中的目标进行识别和分类是获取目标信息的主要途径,这些地物目标的分类结果对农业生产、环境保护、军事侦察、地理测绘制图等具有重要意义。但是由于遥感影像地物目标种类复杂,高分辨率遥感影像欠缺光谱信息等原因,增加了遥感影像的分类难度。常被应用于遥感影像分类工作中的传统机器学习方法,在分类时不仅要克服遥感影像数据量给分类工作带来的困难,还要人工对数据进行繁重的特征分析和特征提取工作。同时,对遥感影像进行特征分析和提取也需要更为专业的专家知识,分类结果的精度也取决于先验专家知识。因此,传统的机器学习方法在遥感影像分类上有明显的局限性。近些年出现的深度学习技术,可以自动学习大量图像数据的深层次特征,它依据提取的特征对图像中目标进行准确的识别和分类决策,在一定程度上提高了图像的分类精度。鉴于遥感影像分类和图像分类技术之间的密切联系,把深度学习技术应用到遥感影像分类上极具可行性,同时该技术也能克服传统方法在遥感影像分类上的局限性,具有很高的研究价值。目前,应用于遥感影像分类领域的深度学习技术虽然取得了一定的成果,但它还存在分类精度不高、对大场景下的高分辨率遥感影像分类没有给出有效的解决方案等问题。针对上述问题,本文将基于深度学习技术的全卷积神经网络模型应用在遥感影像分类中。主要研究内容如下:(1)针对大场景下高分辨率遥感影像中目标大小差距较大,目标无法有效识别问题,本文在全卷积神经网络(FCN)模型基础上,根据剪裁策略提出一种改进的全卷积遥感影像分类模型(FCN-16s)。然后在FCN-16s模型基础上,结合改进的Skip结构得到新的FCN-16s+Skip模型。实验结果表明,相比传统FCN模型,两个改进的模型能够有效提取目标,在大场景高分辨率遥感影像分类上有着更高的精确度。(2)为了进一步提高大场景下高分辨率遥感影像的分类精度,本文提出集成的遥感影像分类方法,即将FCN-16s和FCN-16s+Skip两个模型的预测分类结果进行集成融合,使得集成后的分类结果能够具有两个模型的优点,进一步提高影像分类精度。实验结果表明,对比单一模型,集成的遥感影像分类方法具有更高的分类精确度。(3)鉴于U-Net模型的良好扩展性,为了进一步提高遥感影像分类效率和精确度,本文在U-Net模型基础上,加入融合残差结构和循环结构的循环残差卷积融合结构,形成一种基于循环残差卷积结构的遥感影像分类模型。实验结果表明,该模型能更好地自动提取和利用遥感影像的特征,从而获得高精度的遥感影像分类结果。"
771,基于深度收缩自编码网络的机械设备故障诊断研究,"随着计算机、传感器和通信技术的发展,现代工业系统变得越来越复杂。如何保证机械设备的可靠运行,在设备发生故障时精准的定位故障并且快速修复故障变得十分重要。故障诊断就是一种在设备发生故障时,确定故障发生原因的技术,在实际生产过程中能够帮助工厂进行快速的故障排查和故障修复。故障诊断的方法有很多种,目前基于传统机器学习的故障诊断方法应用广泛,这种方法能够不依赖系统的先验知识,直接从采集到的工业设备运行数据中挖掘出设备的故障特征。但是传统的机器学习算法存在维度灾难、过拟合等问题,而且对于不同的设备往往需要人工的构造特征,泛化性能不好。本文针对这些问题,将深度学习的方法引入到机械设备的故障诊断之中。本文的主要工作有:1、提出了一种基于深度自编码网络的机械设备故障诊断方法,利用收缩自编码构建深层网络,实现设备故障特征的自动挖掘,移除对人工构造特征的依赖,提高方法的泛化性和通用性。2、提出了一种一元分类的融合算法,通过分辨设备的已有故障类型和未知故障类型,提高模型的准确率。3、通过实验数据验证本文方法的有效性并与当前普遍使用的基于机器学习的故障诊断方法进行比较,详细分析影响模型准确率的因素。"
772,基于迁移学习的车牌识别系统的设计与实现,"车牌识别系统是智能交通系统的重要组成部分。在智能交通系统中,车牌识别是利用车牌的唯一性来识别和确认车辆,以保证系统的可执行性及便捷性。目前车牌识别系统大多使用在特定角度的拍摄场景中,例如小区门禁、交通固定卡口、安防、高速公路收费站等。然而在自然场景中,由于角度扭曲、不同光照条件、遮挡、不同像素比例、车牌变形和复杂背景等因素的影响,车牌识别系统无法对完整牌照信息进行准确定位及识别。针对这一现状,本研究重点关注自然场景下的车牌识别问题,论文的主要贡献及研究内容如下:提出了一种基于深度学习的车牌识别系统实现方案。鉴于自然场景中出现的多干扰因素,传统的车牌识别算法不再适用。基于深度学习的车牌识别系统通过对各类复杂场景中的车辆牌照进行特征提取及学习,从而提高系统在自然场景下的鲁棒性。本研究由车牌定位、分割及识别三个模块组成。相比于传统的车牌识别系统,提出的方案无需对图片预处理及车牌字符分割,不但在实时性上有所提升,还避免了字符分割造成的准确率丢失。提出了一种基于迁移学习的车牌定位及识别算法。车牌定位及识别模块分别采用SSD目标检测及Xception图像分类算法实现。考虑到训练样本的有限性及大量的标注成本,引入迁移学习机制对模块优化改进。对比了基于不同规模训练数据集的算法的表现性能,实验结果表明提出的算法有效解决了冷启动问题,在提高系统泛化能力方面取得了很好的效果。在此基础上,采用字符识别模型作为牌照底色识别算法的特征提取器,实现对牌照字符及颜色的双重识别。最后,将车牌定位、切割和识别步骤进行整合,搭建车牌识别系统,并在5000张测试集上对系统总体性能进行测试。测试结果显示系统准确率为98.34%,平均每张图片识别时间为88毫秒,较好地满足实际场景中车牌识别系统的需求。"
773,复杂环境下的交通标志识别方法研究,"交通标志识别系统作为高级辅助驾驶系统的重要组成部分,不仅保障了车辆行驶的安全性,而且提升了车辆行驶的效率。传统的交通标志识别系统主要针对的是在环境状况良好条件下,采集得到的交通标志图像;然而车辆行驶的环境较为复杂,由于车载摄像装置的抖动、周围非目标物体的遮挡以及传输介质的干扰,造成了采集图像的运动模糊、残缺和噪声等问题,从而导致交通标志识别精度的大幅度降低。针对此问题,本课题研究了复杂环境下的交通标志识别算法,主要研究内容为:(1)提出并实现了平稳迭代在线支持向量机(SIOSVM)算法模型。结合已有的支持向量机模型和在线学习理论,针对在线支持向量机模型初期不稳定、学习效率随时间推移而降低、分类时间随时间推移而增加的缺点,提出了SIOSVM的在线识别模型,对特征提取后的交通标志特征向量进行分类识别。(2)提出并实现了一种新的改进卷积神经网络(改进CNN)模型。改进CNN模型由CNN特征提取模型和SIOSVM分类识别模型组成:首先通过实验分析搭建了CNN特征提取模型;然后将提取得到的特征作为样本,输入SIOSVM分类识别模型,通过模型训练,最终得到改进CNN模型。(3)验证改进CNN模型的性能。将改进CNN、OCNN、CNN、LeNet-5、AlexNet和HOG+SVM六种模型进行对比实验,以复杂环境下的交通标志图像作为测试样本,验证改进CNN模型的性能。实验结果表明:本课题所设计的基于改进CNN模型的交通标志识别系统具有较强的在线自适应能力;在保证响应速度的前提下,该模型相对其他几种经典模型具有较好的泛化能力,对于复杂环境下的交通标志图像有较高的识别准确率。"
774,国际EPC工程项目物资采购风险评价研究,"在“走出去”战略和“一带一路”倡议的推动下,中国对外承包工程业务已取得长足的进步。随着国际工程业务的不断发展,设计―采购―施工(Engineering Procurement Construction,EPC)总承包模式凭借其高效整合与配置资源的优势在国际工程业务中越来越得到业主和承包商的青睐。在EPC模式下,物资采购作为工程项目实施的关键环节,是实现工程设计意图、保障工程施工顺利开展的基础。然而,在国际EPC工程项目合同签订时,项目工作开展较少,物资采购仍然存在许多变数,使承包商在采购实施过程中面临复杂多样的风险。国内诸多学者虽然对国际工程与EPC项目物资采购管理展开了卓有成效的研究,但对EPC项目物资采购风险管理的关注度不足,研究成果具有一定的局限性。因此,如何对国际EPC工程项目物资采购风险进行系统分析与评估以实现项目全过程物资采购的优化管理,成为一个亟待研究的课题。基于现实问题的需求和理论研究的不足,本文从中国承包商的视角着手,综合采用文献研究法、问卷调查法、基于贝叶斯网络的数学建模法等方法展开研究。构建了国际EPC工程项目物资采购风险评价指标体系、风险状态评价标准和风险评价模型,提出了国际EPC工程项目物资采购风险评价准则与控制策略。具体研究如下:(1)基于现有的物资采购风险研究成果和案例,将物资采购风险逐级分解,识别出24个主要风险因素;根据专家经验知识筛选风险因素,最终建立了包含2个一级指标、11个二级指标、23个三级指标的物资采购风险评价指标体系。(2)通过分析相关文献资料,对物资采购风险的发生概率等级与风险损失等级进行划分;综合考虑风险发生概率等级和风险损失等级两方面因素,构建了物资采购风险状态评价矩阵,将风险状态分为H、M、L三种状态。(3)通过问卷调查获取建模所需的样本数据,借助GeNIe 2.0软件,构建了基于数学模型――贝叶斯网络的物资采购风险评价模型;利用风险评价模型进行逆向推理和敏感性分析,识别出物资采购的12个关键风险因素。(4)基于构建的风险评价模型,提出了物资采购风险评价准则;依据识别的12个关键风险因素,提出了相关控制策略。"
775,基于机器学习的电力用户用电异常检测技术研究,"准确的电力用户用电异常检测,有助于锁定疑似窃电的用户,为供电公司的窃电稽查工作提供参考,提高现场检查的命中率,降低运营成本,同时可以节省大量的人力物力,具有重大的经济效益。但目前的异常检测工作中,仍然存在训练数据标签难以获取与正异常样本数量不均衡等问题。为了解决这些问题,本文结合电力负荷数据集的特点,开展异常检测研究工作,所做研究主要包括:首先,针对电力用户用电负荷数据集研究了数据预处理方法。根据电力负荷数据集的特点,进行了缺失值补全与异常值检查等预处理,提取负荷序列的统计性指标、趋势指标与频域指标等特征,并使用孤立森林算法对电力负荷数据集进行异常度排序,以筛选可信度高的正常样本。其次,研究了欠采样技术与半监督学习方法。为解决样本的类间不平衡问题,提出了基于聚类的分层最近邻欠采样算法,该算法根据样本在特征空间中的分布情况,采用分层抽样的思想,提取最具代表性的样本,从而平衡训练样本的类间比例;针对电力负荷数据集包含少量有标签数据与大量无标签数据的特点,建立基于半监督学习的协同森林异常检测模型。使用电力负荷数据集与公共数据集完成实例分析工作,实验结果表明,所提欠采样方法可有效解决样本数据类间不平衡问题。最后,研究了改进的协同森林异常检测模型。在建立模型前考虑使用聚类的方法将单类异常转化为多类异常,以此提高所建立异常检测模型的准确率;为了解决半监督学习不安全的问题,提出了基于样本检测的协同森林异常检测算法,在模型的每次迭代过程中,通过计算异常隶属度对被打上标签的样本进行检测,完成样本标签的纠正,以此提高半监督异常检测模型的安全性;最后,建立基于样本检测的协同森林异常检测模型。使用电力负荷数据集与公共数据集完成实例分析工作,实验结果表明,基于样本检测的协同森林异常检测模型在检测准确率与模型安全性上均有所提高。"
776,基于机器视觉的西瓜花体识别研究,"机器视觉技术在农业工程领域已得到大量应用,主要集中在对农作物形态、颜色,尺寸形状等特性进行提取识别,以检测作物生长状况、病害虫情况等,从而对作物质量进行控制。目前温棚作物授粉存在着劳动力需求大、环境恶劣以及人工授粉造成产量或品质下降等严重问题,若能够通过机器视觉进行目标作物的识别,进而对其智能化授粉设备提供技术支持,使其具有广阔的应用前景。本文以西瓜花体作为研究对象,针对西瓜花体的性状、姿态和授粉状态进行机器视觉识别研究。首先对采集的自然环境状态的西瓜花体图像归类分析,建立了西瓜花体的姿态和开放周期的图像库,其次提出了一种基于Lab颜色空间的西瓜花体分割方法,对西瓜花体图像预处理(图像滤波、边缘检测、直方图均衡化)操作,并转换到Lab颜色空间分析三通道分量图,运用OTSU算法在b通道完成图像的分割;然后研究了机器学习方法,运用基于图像特征的识别方法,对西瓜花体样本图像进行特征提取,并通过SVM进行分类识别,并与基于Faster-RCNN神经网络自动特征提取分类识别进行对比试验。研究表明:基于图像特征对于单个状态识别较好,尤其是正向花体授粉状态和花体的性状识别率达到70%;基于Faster-RCNN神经网络多状态融合的识别率能够达到80%左右;最后设计了嵌入式西瓜花体识别处理系统。该系统依托树莓派3b+和角蜂鸟为硬件架构,兼容Faster-RCNN神经网络算法,搭载神经网络加速芯片提高了整体识别速度。本文利用机器视觉技术识别西瓜花体状态,设计的嵌入式识别系统准确性高,适用性广,对智能化授粉装置提供了技术支持和研究基础。"
777,基于Android设备的牛只检测与识别研究,"目标检测是自动驾驶、人脸检测、视频监控等不同应用领域的一项重要任务。虽然最新研发的一些图像和视频实时定位和识别技术可以保证较高的识别精度和检测速度,但目前大多数深度学习应用程序只能在服务器或台式电脑上运行。Android平台不仅可以通过摄像头捕捉图像、视频,还可以检测动物的面部。考虑到目前有很多移动计算设备,本文实现了基于Android设备的目标检测算法的牛脸检测和识别应用。由于现阶段的移动设备基本都可以达到深度研究的计算需求,这使得在Android设备上运行目标检测成为可能。本文中提到的应用程序能够实时识别和检测多头牛的面部。为这个项目中选择的模型的速度进行了优化,因为代码的实时性对工作速度的影响不容小觑。我使用TensorFlow训练了SSD-MobileNet-V1模型。TensorFlow提供了一个预先训练的模型为检测到的图像绘制边框,并使用跟踪代码进行目标跟踪。SSD-MobileNet模型可以大大减少参数的数量,达到更高的精度。SSD网络是一种回归模型,它利用不同卷积层的特征进行分类回归和边框回归。开发MobileNet网络是为了在有限的硬件条件下提高深度学习的实时性。MobileNet和SSD的结合使得牛的检测和识别变得非常准确快速。该模型包含四个部分:用于导入目标图像的输入层、用于提取图像特征的MobileNet基网络、用于分类回归和边框回归的SSD以及用于导出检测结果的输出层。对于数据集,使用7444张图像数据集训练了一个效果好,精度高的模型。在这收集的数据集中,包含256头牛的面部图像,每头牛大约40-50张图像。数据集包含训练数据集和测试数据集两部分。训练过程中,利用Nvidia GTX 1060进行了243000次迭代,大约用了4天的时间。经过训练,模型损失下降到0.410,精度上升到0.95。所有牛类别的平均精度均值(total mAP)为96-100%。检测与识别过程采用两种方法实现,分别用Android camera(Galaxy S9)和PC上的TensorFlow目标检测从精度和检测速度两个方面对检测与识别性能进行评估。实验结果表明,该方法大大提高牛脸检测精度和识别效率。作为参考,该模型在训练过程中使用了Intel i5-4590 CPU@3.30GHZ x4所有核心的80-100%。"
778,基于有监督学习的“三高”检测的研究与实现,"随着人们生活水平的不断提升,各种现代社会派生的“富贵病”正悄无声息地侵入到我们的生活中,这导致人们对自身健康状况的需求愈发高涨。但由于医疗资源的紧缺和不平衡分布、生活节奏加快、体检价格不菲等原因,现有的医疗卫生体系主要针对重大疾病的检测、预防和治疗,难以完全满足人们对于慢性病的检测和预防的需求。“三高”是慢性病代表之一,我国“三高”患病率呈逐年上升趋势。解决三高问题的关键是早发现、早预防和早治疗,而早发现是解决“三高”问题的有效前提。由于“三高”的病理形成机制较为复杂,临床检测存在早期检测准确率低、费用昂贵等问题,因此本文通过数据驱动的方法来自动学习健康数据指标与“三高”之间的内在联系,希望能够在保持较高准确率的情况下,减少人工成本,从而低成本的解决“三高”检测的问题。本文的研究内容主要包括预处理方法、模型设计、超参数优化以及性能评估等方面。首先,在预处理阶段,对健康数据进行筛选,并使用奇异值阈值(Singular Value Thresholding,SVT)的方法对缺失数据进行填充。然后,利用八种经典的机器学习模型对“三高”检测问题进行了初步尝试,并以此作为“三高”检测模型的基准。再者,基于集成学习的思想和Stacking策略,利用神经网络将K近邻、朴素贝叶斯和决策树这三个基础机器学习模型进行“融合”,这显著提升了模型的准确性、特异性和灵敏度。在此基础上,本文从模型性能和模型多样性两方面进行改进,使用更为复杂的逻辑回归、随机森林和XGBoost模型作为初级学习器,并利用支持向量机代替神经网络作为次级学习器,构建了一个“双重集成”的“三高”检测模型,从而进一步提升模型的准确性、特异性和灵敏度。此外,本论文还使用贝叶斯优化的方法对模型进行超参数调优,保证模型达到最佳性能。最后,实验证明了本文所提出的两个“三高”检测模型方案的可行性以及性能的先进性,与各经典机器学习模型及目前处于领先地位的“三高”检测模型相比,本论文提出的模型在各项指标上都有所提升。综上所述,本课题的研究对“三高”自动检测问题提供了一个具有指导意义的解决思路。"
779,基于机器学习的胶质母细胞瘤多模态磁共振图像分割方法研究,"目的胶质母细胞瘤(glioblastoma multiforme,GBM)是由星形胶质细胞分化形成的颅内原发恶性肿瘤,具有生存率低、致残率高、病死率高等特点,对患者伤害巨大,无论是疾病的诊断、治疗方案的提出还是预后观察,均需对GMB进行定位和诊断。多模态MR图像含有丰富的组织结构信息,被广泛地应用于GBM的诊疗。目前临床上主要依赖放射科医生利用MR图像手动分割GBM,但其组织在MR图像中存在灰度差异不明显、周围常有水肿、边界不清等问题,且专家手动分割复杂繁琐、可重复性差。因此,精确手动分割GBM存在极大挑战。自动方法可以避免因人为因素造成的误分割,结果相对客观,能极大程度地减轻医生工作强度。因此,自动分割GBM多模态MR图像具有极其重要的临床意义。方法针对现有大多数GBM多模态MR图像分割算法未实现细分割肿瘤区域的问题,本文提出了一种基于随机森林的GBM多模态MR图像分割方法。首先,配准GBM 3个模态MR图像后使用N4ITK方法进行偏置场校正;其次,提取MR图像的位置特征、强度特征、纹理特征、上下文特征和对称特征后,应用随机森林分类器获得初步分割结果;最后,移除小于200像素的区域后使用5×5的中值滤波平滑各区域边界得到基于随机森林的GBM分割结果。在此基础上,本文为进一步提高GBM自动分割的准确性,提出了基于三维区域生长的GBM多模态MR图像分割方法。首先,计算得分图与肿瘤区域掩模,利用肿瘤区域掩模获取肿瘤区域信息,进而分析肿瘤区域置信度与精度;其次,选择种子点进行三维区域生长,将高分区域替换随机森林模型初步分割的相应区域,生成新的训练数据;再次,利用新的训练数据训练随机森林模型,将训练后的随机森林模型依据初始提取的219种底层特征对各像素进行分类;最后,移除小于200像素的区域后使用5×5的中值滤波平滑各区域边界得到基于三维区域生长的GBM分割结果。结果本文利用两种分割方法将MR图像分割为正常脑组织区域、肿瘤坏死区域、活跃肿瘤区域、除去肿瘤坏死区域和活跃肿瘤区域的T1异常区域和不包含T1异常区域的FLAIR异常区5大区域,采用Dice相似性系数、敏感度、特异度三个指标分别对整个肿瘤区域和以上4个肿瘤子区域分割性能进行评估。实验结果显示,基于随机森林的GBM多模态MR图像分割方法,其Dice相似性系数分别为0.869、0.748、0.857、0.768、0.681,敏感度分别为0.851、0.739、0.872、0.745、0.667,特异度分别为0.9942、0.9949、0.9958、0.9937、0.9933;基于三维区域生长的GBM多模态MR图像分割方法,其Dice相似性系数分别为0.877、0.763、0.865、0.771、0.702,敏感度分别为0.853、0.742、0.874、0.748、0.673,特异度分别为0.9946、0.9965、0.9963、0.9941、0.9937。结论从实验结果可看出,本文提出的两种GBM多模态MR图像自动分割方法均能得到较好的分割结果。通过比较分析可知,基于三维区域生长的GBM多模态MR图像分割方法在不同肿瘤子区域分割相似性、敏感度和特异度上显示出了较为优异的性能。本文为自动分割GBM多模态MR图像提供了一种思路,在GBM的早期诊断、手术定位等应用方面具有一定的临床参考价值。"
780,基于机器学习的心肌梗死检测算法的研究,"心电图是临床上检测心脏疾病方便快捷的手段。传统心电图诊断基本都是基于信号处理,首先将ECG信号经过相关变换后从中提取特征,然后根据该特征检测疾病。传统方法存在一些弊端,如对原始ECG质量要求高、信号处理难度大、特征提取困难等,尤其是对于心肌梗死这类特征较多并且一些特征模糊的疾病,更是难以处理。机器学习的一些方法在很大程度上可以有效解决这些问题。深度卷积神经网络可以从多维度对特征模糊的非典型心肌梗死做特征提取,而对于特征明确的典型心肌梗死,可以利用决策树快速做出诊断。因此,本文提出基于机器学习的心肌梗死检测算法,利用多种机器学习方法相结合,不仅可以有效解决心肌梗死疾病检测问题,也为其他疾病检测提供了一种新的思路,具有一定研究价值。本论文首先介绍了课题的背景及意义,并剖析了传统心电图诊断存在的问题以及心肌梗死的研究现状,提出基于机器学习的心肌梗死检测的算法。通过对课题相关技术的深入研究,建立从ECG前期处理、波形检测到特征提取和模型构建与评估的整个流程。其中,ECG前期处理主要包括ECG精度转换、重采样、滤波、平滑、去基线等相关算法的实现,在该部分重点实现改进的自适应滤波算法,并与其他滤波算法对比。波形检测部分主要实现ECG各个波的检测和起始点定位,其中重点实现了QRS波群起始点的定位。之后结合医学相关知识对ECG进行特征提取,然后根据典型心肌梗死和非典型心肌梗死的不同特征构建特定的模型并对模型进行训练,最后对模型评估并对实验结果进行分析。本文根据心肌梗死疾病特点,提出决策树和卷积神经网络相结合的算法,不仅很大程度增加了心肌梗死检测的准确率,而且也降低了算法整体的时间复杂度。算法利用12导联数据进行分析,可以对心肌梗死产生部位做初步定位。本文最后分别测试PTB数据库和医大一数据库,并与其他算法对比,实验结果表明在心肌梗死的检测上,本文算法准确率有所提高,并且整体性能优于其他算法。"
781,基于深度学习的心律失常诊断算法的设计与实现,"心律失常是一种常见的心血管综合征。心律失常的正确识别对心血管疾病的预防具有重要意义。心电图是一种反映心脏活动的医学监护技术,目前广泛应用于心律失常的检测。通过心电图观测心电信号是否异常,是否出现异常心搏,进而做到对心血管疾病提前预防或诊断的效果。在临床检查中,由于受到工频、肌电等干扰信号的影响,心电信号中通常会包含各种噪声,对心电图的识读带来一定的困难。同时,由于心电图数量的提升,医护人员的主观性以及心律失常的复杂形态等原因,传统的人工识图方式,效率低下,并存在着误诊漏诊的可能性。因此,为了节约病人的时间、减少专家的压力以及提高心电图识读的效率,设计出一种对心律失常自动诊断的分类算法就显得尤为重要。本文结合深度学习模型的特点,针对心律失常自动诊断算法的设计,做了深入研究,主要内容包括:1、利用小波变换算法对心电信号滤波处理。心电信号中通常夹杂着各种干扰信号和基线漂移。通过小波分解进行阈值处理,能够将高频噪声进行抑制。同时,还能改善信号中的基线漂移现象。2、提取关键特征,设计了一种波形编码规则。波形的形态变化是诊断心律失常的重要依据,其形态判定需要提取波形的形态特征。同时,根据心脏电信号的传递顺序,提出了一种基于时序排列的波形编码方法,使其更加准确的描述心律失常所引起的波形变化。3、构建基于深度学习的心律失常诊断模型。结合时序数据的特点,以长短时记忆神经网络为基本单元,构建了DBiLSTM学习模型。算法模型以时序心电编码为输入,以诊断编码为输出,实现了六类心拍的有效诊断。4、通过与支持向量机、反向传播神经网络和卷积神经网络模型进行实验对比,结果看出,本文所建模型收敛速度快,取得了较好的分类效果。"
782,社区居民糖尿病风险预测系统的设计与实现,"近些年来,我国的经济发展迅速,国民生活方式相对于之前也有很大的改变,全球得糖尿病的人数增加特别快,并且有很多人患病后并不知道,对患病人的健康危害特别大,同时高昂的治疗费用拖垮了很多家庭,严重降低了家庭的幸福指数。目前大部分医疗机构对糖尿病的诊断还是依靠医生的个人经验和体检数据为准,这样进行疾病诊断是有一定的弊端的,需要医生具有高超的医术和充沛的经历,否则很可能会误诊、漏诊,如果不能在最好的时机进行医治,很可能会加重病情的恶化,这种现象是我们都不愿意看到的。目前智慧医疗成为了时代的趋势,如果将糖尿病和机器学习结合,采用机器学习算法来辅助医生诊断,将会很大程度上提高诊断的科学性,有效的克服医生凭经验诊断的主观性的问题。针对以上所述,本文依托于实验室项目,构建了糖尿病风险预测模型并设计实现了糖尿病风险预测系统。具体内容包括(1)算法选择:本文通过查阅文献,对糖尿病的特点进行研究,研究了很多现存的疾病风险预测模型,然后结合原始数据样本特点,选择了随机森林、XGBoost和CatBoost三种算法进行建模。(2)数据预处理:针对原始数据中出现的各种各样的不利于模型预测的问题,为了保证在建模中能够发挥最佳的效果,本文去除各种存在的问题,调整数据的格式,把数据处理成适合于进行建模的数据形式。(3)特征选择:预处理后的数据维度仍然很大,这么多的字段不利于建模,并且存在很多字段对建模没有太大作用,所以本文进行特征选择,使用IV值分析进行特征选取,最终选出11个特征作为最后的模型输入变量。(4)建模并实验分析:使用(3)中所述方法选择的特征,使用(1)中所述三种算法分别进行建模,并对最后的模型进行调优,每个模型都得出其最优的预测结果,使用精确率、召回率、F1值和运行时间四个指标对模型进行评价比较,并选出CatBoost算法模型嵌入到糖尿病风险预测系统中。(5)系统设计与实现:对糖尿病风险预测系统进行充分的需求分析,完成系统设计与实现,并对系统进行功能测试。"
783,应用机器学习预测2型糖尿病不同发病阶段的研究,"目的使用2型糖尿病(Type 2 diabetes mellitus,T2DM)患者的临床资料和生化检查建立基于机器学习理论的2型糖尿病并发症的预测模型,其次以二元Logistic回归作为补充,初步筛查2型糖尿病患者并发症的关联因素及影响顺位,用建立好的模型预测不同发病阶段的2型糖尿病患者是否患有并发症,初步分析关联因素与2型糖尿病及并发症之间的联系。方法调取2017年7月-2018年7月西北地区某省人民医院共420名2型糖尿病住院患者的电子病历信息,收集糖尿病诊断数据及生化检查资料,进行数据预处理之后筛选得到了其中可能对2型糖尿病及并发症具有研究意义的77个变量,将所有数据进行归一化处理后建立数据库,使用MATLAB软件,采用机器学习中的人工神经网络(Artificial neural networks,ANN)算法,用误差反向传播(Back propagation,BP)神经网络作为拟合模型,将样本分为训练组和验证组,其中训练组包含样本358例(占样本总量的85%),建立BP神经网络模型,结构为77-50-1、学习率为0.1、训练误差为0.2、最大训练步数设为1000步(epoeh)、传递函数为对数Sigmiod函数、采用Levenberg-Marquardt优化方法对网络进行训练。验证组样本有62例(占样本总量的15%),验证BP神经网络模型的预测性能并预测其是否患有并发症。其次,应用基于流行病学研究设计的二元logistic回归,分别用卡方检验和t检验筛选有统计学意义的变量,再将筛选出的变量纳入行二元logistic回归分析,应用SPSS18.0软件对所有的数据进行处理,筛选2型糖尿病并发症的关联因素。结合BP神经网络模型和二元logistic回归得出的影响因素,从实际临床学习和文献中分析关联因素,初步探讨其与2型糖尿病及并发症的关系。结果BP神经网络模型用验证组进行预测的正确率约为93.55%,灵敏度和特异度分别为95.6%、88.2%,在77个变量影响值排序中,嗜碱性粒细胞比率、平均红细胞体积、红细胞、红细胞体积分布宽度、腰围、舒张压、收缩压、总胆汁酸、年龄、糖尿病家族史等因子顺位排序靠前;二元logistic回归中年龄和平均红细胞体积是2型糖尿病发展至并发症的两个关联因素。结论应用BP神经网络模型进行预测的正确率约为93.55%,灵敏度和特异度分别为95.6%、88.2%,可见BP神经网络模型具有较高的预测性能,其中嗜碱性粒细胞比率、平均红细胞体积、红细胞、红细胞体积分布宽度、腰围、舒张压、收缩压、总胆汁酸、年龄、糖尿病家族史等因子顺位排序靠前;二元logistic回归中年龄和平均红细胞体积是2型糖尿病发展至并发症的两个关联因素,BP神经网络预测结果中得到的变量也包含了logistic回归中得到的变量。本次研究初步尝试应用BP人工神经网络算法建立2型糖尿病并发症的预测模型,用于预测2型糖尿病不同发病阶段的患者是否处于并发症这一阶段,期望筛选更复杂更多样的指标并且获得影响度排序,为2型糖尿病发展至并发症阶段的早期诊断提供一定的科学依据。"
784,基于特征选择和支持向量机的乳腺癌诊断研究,"肿瘤是世界上严重的致死因素之一,危及人类生命健康。而在女性死亡因素之中,乳腺癌位居前列。治愈乳腺癌的关键点在于疾病的早期诊断和治疗,尽早对肿瘤进行诊断对于临床治疗有着重要意义,因此,找到能够准确识别肿瘤类型的算法,提早进行治疗尤为关键。由于科学技术的发展及对于健康的追求,人们对于疾病相关数据的收集也与日俱增,与此同时,高维数据特征信息的增多,也意味着对于数据分析处理的计算量加大,所需特征空间也呈指数上升,即造成所谓的“维数灾难”。分析数据的首要任务即为对特征数据进行降维处理,剔除冗余特征,减轻计算压力,也能使结果更加准确。本文针对乳腺癌从三个方面来进行分析研究,包括:(1)针对乳腺癌的临床数据,提出基于层次聚类和支持向量机的改进算法(H-SVM),首先对乳腺癌数据进行降维处理,使用层次聚类算法为特征选择方法,提取出数据新的模式,然后根据聚类结果对原始数据进行转换,组成新的数据集,并对新数据集应用支持向量机分类器算法进行分类诊断,得到相对较好的结果。(2)提出基于K-medoids聚类和支持向量机的改进算法(KD-SVM),使用K-medoids聚类算法作为特征选择方法对乳腺癌数据进行降维处理并提取新的模式,然后根据聚类结果对原始数据进行转换组成新的数据集,并在新数据集上应用支持向量机分类器算法进行分类诊断,其分类精确率优于H-SVM算法。(3)针对乳腺癌的高维基因表达数据,提出基于正则化和支持向量机结合的基因分类算法,分别使用Lasso和Elastic net两种正则化惩罚方法,对于基因特征进行有关基因筛选,并对筛选所得特征应用支持向量机进行分类,得到较高的分类精确率。"
785,基于傅里叶变换红外光谱与机器学习方法对中暑死诊断和死亡时间推断的研究,"目的:探究傅里叶变换红外(Fourier transform infrared,FTIR)光谱技术结合机器学习方法在法医病理学中关于中暑死诊断和死亡时间推断的应用。方法:(一)中暑死鉴别诊断:雄性新西兰白兔42只,体质量2.2~2.5 kg,随机分为中暑死组(21只)和对照组(21只,溺死、机械性窒息死和失血性休克死各7只)。采集玻璃体液FTIR光谱数据并进行预处理,利用预处理后光谱数据建立中暑死鉴别模型。(二)死亡时间推断:健康雄性SD大鼠30只,体质量240~260 g,大鼠颈椎脱臼处死后置于4℃、20℃和30℃环境中(每组10只)。于不同时间点取大鼠肝组织,采集肝脏样本的FTIR光谱数据,对光谱数据进行预处理并建立死亡时间推断模型。结果:(一)中暑死鉴别诊断:(1)、不同死因白兔玻璃体液平均光谱差异较显著,综合t-检验和PCA结果,中暑死和对照组光谱的显著差异主要和玻璃体液内蛋白质、氨基酸以及碳水化合物结构或组分差异相关;(2)、利用多种算法建立中暑死鉴别模型,其中利用遗传算法(genetic algorithm)结合偏最小二乘判别分析(partial least squares discriminant analysis,PLS-DA)建立的判别模型较简单(57个变量),模型敏感性、特异性和准确度都达到了100%,受试者工作特征曲线(receiver operating characteristic curve,ROC)下面积(areas under the ROC curves,AUCs)为1。(二)死亡时间推断:(1)、各温度组不同死亡时间点大鼠肝组织平均光谱吸收峰差异较明显;(2)、主成分分析(principle component analysis,PCA)显示20℃和30℃环境中,不同死亡时间点光谱呈现较明显的聚类趋势,且这些光谱聚类趋势主要与组织中某些蛋白质、核酸以及碳水化合物等物质组分或结构差异相关,而4℃组样本分布较散乱,没有发现较明显的分布规律;(3)、分别利用4℃、20℃和30℃组光谱数据建立死亡时间推断偏最小二乘(partial least squares,PLS)回归模型,三个温度组外部验证结果决定系数(R~2)分别为0.55、0.82和0.96,预测均方根误差(root mean square error of prediction,RMSEP)分别为38.5 h、16.4 h和4.6 h;(4)、将4℃和20℃组大鼠肝组织FTIR光谱数据分划为0~24 h,48~96 h和120~168 h三个时间段,建立偏最小二乘判别分析(partial least squares discriminant analysis,PLS-DA)模型对死亡时间范围进行判别,4℃和20℃组PLS-DA模型外部验证准确度分别为69%和86%。结论:(1)、FTIR光谱技术能反映被检测生物样本几乎全部的分子组分信息,在法医学领域有广阔的应用前景;(2)、可利用FTIR光谱技术结合机器学习理论算法建立高温死鉴别诊断模型,为复杂死因的法医学鉴定创造了新的研究思路和方法;(3)、FTIR光谱技术结合机器学习理论算法能有效地定性、定量分析大鼠死后肝组织,有望成为一种简捷、快速的死亡时间推断技术。"
786,基于深度学习算法的小分子毒性预测研究,"在药物研发领域,虽然许多有前景的化合物已经在动物模型中进行了广泛的临床前研究,但依旧有超过30%的化合物由于其毒性作用太大而在临床试验中失败。可见,药物的安全性评价,尤其是早期的毒性检测,在新药研发中起着非常重要的作用。根据文献报道,毒性信号通路中有两种主要的信号通路:应激反应(Stress Response,SR)通路和核受体(Nuclear Receptor,NR)信号通路。对于这两类信号传导通路,本研究分别选择了抗氧化反应元件(Antioxidant Responsive Element,ARE)响应和雄激素受体(Androgen Receptor,AR)响应作为研究对象,采用深度学习算法和传统机器学习算法建立了化合物的两种响应的预测模型,并且得到了令人满意的结果。本论文主要包括以下几个方面的内容:(1)阐述了化合物毒性预测的研究进展,并详细介绍了传统机器学习算法以及深度学习算法的基本原理。(2)为建立准确的化合物ARE响应的预测模型,我们基于Tox21数据中的ARE响应数据,首先计算两种类型的分子结构特征(包括传统的分子结构描述符和分子指纹特征),然后结合多种深度学习算法以及传统的机器学习算法分别构建用于预测化合物的ARE响应的分类模型。在基于传统的分子描述符的模型建模过程中,通过基尼指数来筛选与ARE响应密切相关的结构描述符,以防止传统的机器学习方法出现过拟合问题。但是在基于深度学习算法的模型建模过程中,鉴于深度学习算法的独特优势,我们不需要进行特征筛选,相应地引入一些较为有效的模型优化策略来构建化合物的分子描述符与ARE响应之间的分类模型,并分析了相应的分子描述符与ARE响应之间的相关性。在构建基于分子指纹特征的ARE响应的预测模型时,所有的分子指纹特征均用于模型的构建。建立的模型通过混淆矩阵以及受试者工作特征曲线(Receiver Operating Characteristic,ROC)来评估模型的可靠性。结果表明,基于指纹特征的深度神经网络(Deep Neural Network,DNN)模型具有良好的预测能力和泛化能力。对于训练集、测试集和外部验证集预测的准确率(ACC)分别为0.992,0.914和0.929。本研究可以为化合物的ARE响应预测提供准确可靠的模型。(3)本论文第二个研究工作应用多种深度学习算法及其他机器学习算法基于Tox21中的AR响应数据建立了用于预测化合物AR响应的分类模型。结果表明,基于分子指纹特征的循环神经网络(Recurrent Neural Network,RNN)模型具有最好的预测能力。该模型对训练集、测试集和外部验证集预测的ACC分别为0.997,0.980和0.976,预测结果是非常可靠的。此外,我们将我们的模型与2014年Tox21数据建模挑战中最佳模型DeepTox pipline的预测结果进行比较,结果表明我们的模型优于这一最佳模型。本论文研究得到的结果可以为化合物的两种毒性响应的预测提供可靠的具有良好的泛化能力的模型,同时也表明深度学习在小分子毒性预测方面是一种非常有前景的建模方法。"
787,中文分词中词典分词和模型分词融合的实证研究,"将一连串的字段根据一定的规律分成一个个独立的、可识别的字段就是中文分词过程。因为中文是由一个个汉字组成,没有便于切分汉字之间的分隔符,所以中文分词是自然语言处理的第一步,是不可避免的基本步骤,分词处理结果是否理想直接决定了最后的结果是否理想化。在知识更新迭代变化快的今天,对分词处理方法的灵活性和科学性有了更多、更高的要求。互联网的普及让大量的新词汇不断涌现,这些新词汇的产生不仅是互联网进步的一个反应,同时也对词典分词发起了新的挑战,如何高效迅速的处理这些包含新词汇的文本是文本词典的重点研究对象。目前的分词系统中主要使用词典分词或者机器学习分词完成分词任务。而词典分词虽然可控性好、分词速度快,但是其对未登录词无法正确切分。虽然机器学习模型CRF能够很好解决未登录词问题,但训练CRF需要人工设计很多特征,且需要花费很多时间来验证特征的有效性。基于深度学习的自然语言处理算法逐渐兴起之后,在序列标注任务上使得模型能够自动的抽取特征成为可能,大大减少了人工设计特征的工作量。虽然基于模型的分词能够很好的解决未登录词问题,但是其可控性没有词典分词好,对于一个未解决的新词模型,词典分词可以快速的人工添加新词到词典解决问题。而对于模型而言可能就需要添加很多相关的训练语料,这些训练语料往往是比较难获取或者获取成本很大的。本文为了提高中文自动分词效果,使用MMseg算法实现词典分词模块以及BI-LSTM+CRF作为模型分词模块,最终将两者进行融合进而达到既能够有词典分词的可控性,又能够通过模型分词解决词典分词的未登录词问题。本文的方法在SIGHAN的汉语处理评测的Bakeoff语料中进行测试。首先实现MMseg的词典分词模块,然后针对模型分词的算法先进行各种参数调优,最后融合两者的结果。实验表明在模型融合之后的结果中,准去率、召回率、F1(F1-Measure)值都有所提升,而且模型融合后能够很好解决模型的可控性和未登录词问题。"
788,青少年吸烟者大脑功能连接度及其模式分类研究,"吸烟成瘾严重危害人类健康,先前研究发现了吸烟与大脑结构和功能异常有关。然而,对于吸烟成瘾脑神经机制,目前仍没有统一定论。研究表明,戒断能诱发渴求,目前对于青少年吸烟者渴求的大脑功能变化模式并不清楚,因此本文针对青少年吸烟者戒断状态下的功能连接度进行研究。此外,为了能清楚地探究吸烟者脑影像的差异是否能推广到新的样本,本文使用了模式分类方法,对吸烟个体进行分类。前者研究为后者提供了先验指导,后者研究为前者作了进一步推广,两项研究紧密相关。本文的核心内容和创新点如下:(1)采用功能连接度方法探究青少年吸烟者戒断诱发渴求的大脑功能变化模式。功能连接度方法对体素的时间序列间进行皮尔逊相关分析,本文采用高斯核函数改进传统线性时间序列,提出基于高斯核的时间序列模型。相比传统模型,改进后的模型拥有更好拟合效果。结合改进后的模型和功能连接度分析方法,提取两种状态的青少年吸烟者的功能连接度,并进行配对T检验,得到戒断诱发渴求大脑功能连接度差异,运用多元回归分析方法,探究青少年吸烟者渴求与功能连接度的关系。本研究促进了对吸烟者短期戒断下全脑功能变化模式的理解,并为吸烟者戒断诱发渴求的神经机制提供了一定的影像学依据。(2)采用模式分类方法识别青少年吸烟者。本文提出基于多模态影像数据的特征融合和多元属性选择的模式分类方法,并将该方法应用于青少年吸烟者的研究。该工作使用青少年吸烟者的多模态磁共振成像数据,提取各类影像指标,进行特征融合;然后,采用低秩自表达属性选择算法进行特征选择;最后,利用线性支持向量机进行分类,同时,用逻辑回归验证线性支持向量机的鲁棒性,比较两种分类器的有贡献脑区/有贡献特征是否相同,有贡献特征的权重是否相关。结果表明融合特征的效果优于单变量分析方法的效果。对分类贡献最大的脑区涉及纹状体-额叶回路的脑区,该脑区在工作一中也有发现,验证了工作一的结果。综上所述,本文使用功能连接度方法揭示了戒断诱发吸烟者渴求强度与认知控制损伤的脑神经机制有关。此外,使用基于多元属性选择的模式分类方法对吸烟个体进行分类。两项研究都发现,纹状体-额叶回路的脑区在吸烟成瘾中具有重要作用,这将为吸烟成瘾的治疗提供指导和借鉴。"
789,基于机器学习的毕业生就业预测模型研究与应用,"近几年来,全国大多数高校的招生人数逐年增加,毕业生的数量也随之增多。在这样的大环境的基础下,毕业生面临的就业形势也愈加严峻。为了提高毕业生就业率,大部分高校都很看重就业指导工作,但是大部分就业辅导工作都普遍存在着缺乏针对性和流于形式等问题,并不能让真正需要帮助的学生受益。高校一般都有多个管理系统,比如学籍信息、课程信息、毕业登记等,这些系统全方位地记录了学生的各种信息,但这些系统目前还只是用于存档查询,如果可以充分利用这些系统包含的信息,找到影响就业的主要因素,就可以对于毕业生就业进行预测,给高校的负责毕业生就业工作的管理者以及老师提供有效的建议,对于毕业生在就业方面遇到的难题给出一个可参考性的解决方案。本文先对特征选择算法和预测算法的相关理论进行阐述。针对本文的应用场景,即就业预测,结合了国内外学者在毕业生就业相关方面的研究成果,本文对于影响毕业生就业的因素做了深入的分析,总结了学生数据的特点:信息量大而复杂,特征维度较高,各属性之间趋向离散,既有离散型特征也有连续型特征,且冗余特征较多。根据以上特点,本文提出了一种基于互信息及权重的混合型特征选择算法(Hybrid feature selection based on Mutual Information and Gain Weight,以下简称HMIGW)。通过进一步分析,将HMIGW特征选择算法和XGBoost特征选择算法结合起来,为毕业生就业预测问题提供了解决的途径。通过比较本文算法与其他用于预测的常用相关算法,客观的对本算法进行评价。最后,根据相关部门的运营反馈,提出了算法的优化和改进方向,并根据算法效果针对不同群体提出促进毕业生就业的决策与建议。"
790,基于深度学习的音乐自动标注方法研究,"伴随着当代信息科学技术的快速发展,多媒体资源飞速增长。音乐作为多媒体资源的重要形式之一,有着广泛的受众和高需求量的市场。为了使音乐检索和音乐推荐的服务质量与日益增长的用户需求相匹配,对音乐内容的深度挖掘与精准定位便显得尤为重要。音乐标签,作为音乐片段所具备属性的抽象化总结,对其实现自动标注不仅可以节约大量的人力与时间,还有助于音乐标签的标准化和统一化,因此在音乐检索和音乐推荐中具有重要的地位。本文旨在研究基于深度学习的音乐自动标注方法,开展的主要工作如下:首先,对音乐自动标注任务进行分析,对常见的音乐自动标注方法进行研究。深入研究MagnaTagATune数据集,对音乐标签进行多维度的分析,根据音乐自动标注任务的需求和数据本身的特性,进行标签分类和标签融合,从原始音频中提取出梅尔频谱图作为音乐自动标注方法的输入信号。然后,提出一种新型的用于音乐自动标注的卷积循环神经网络,将卷积神经网络和循环神经网络以并行的方式结合起来,利用卷积神经网络对梅尔频谱图进行深层特征的抽取,利用循环神经网络对梅尔频谱序列进行时域总结,再将两种神经网络输出的结果进行整合,得到每种音乐标签的预测概率。最后,在卷积循环神经网络的训练阶段,采取动态设置学习速率的措施,针对不平衡的数据集采用加入惩罚因子的损失函数,提高模型训练的效果。实验选用受试者工作特征曲线和曲线下面积作为主要的评估指标,对本音乐自动标注模型和其他音乐自动标注模型进行t检验以验证本方法的独特性。实验表明,所提出的卷积循环神经网络标注准确率为95.4%,受试者工作特征曲线下面积为0.903,取得了目前最优的标注效果。"
791,LoRa物联网无线通信技术性能预测研究,"随着物联网的蓬勃发展,传统的近距离通信技术在发展过程中有很多制约因素。为解决当前物联网发展所面临的问题,低功耗广域网(Low Power Wide Area Network,LPWAN)应运而生。Lo Ra(Long Range)作为LPWAN的代表性技术,是一种传输距离远,功耗低的无线通信技术,可以根据用户需求进行自主设计,应用在许多领域中。根据Lo Ra的特性,其传输数据的性能和硬件配置密切相关。在实际部署过程中,为合理配置Lo Ra物理层参数提升Lo Ra性能并提高数据传输质量,建立硬件配置参数与评价Lo Ra性能参数间的关系至关重要。本文充分研究了物联网和Lo Ra性能分析发展现状,在当前已有的性能分析基础上,结合Lo Ra硬件可配置参数特性和探索性数据分析方法,对Lo Ra性能进行研究分析。本文的Lo Ra性能研究主要针对接收到数据的信噪比(Signal to Noise Ratio,SNR)和接受信号强度(Received Signal Strength Indication,RSSI)展开。首先,根据性能分析目标要求,提出一种Lo Ra性能测试方案,对Lo Ra测试硬件和软件进行总体设计,并选择两种无遮挡测试环境实现Lo Ra测试。其次,针对两种测试环境的数据,运用探索性数据分析(Exploratory Data Analysis,EDA)进行数据预处理,再分别运用决策树和支持向量机这两种机器学习算法进行建模预测,提出了两种优化配置参数选择的预测模型,分别建立了配置参数与SNR和RSSI之间的关系。最后,针对这两个模型进行预测评估,模型预测准确率高,并且都可以在相应的测试环境中通过设定相关硬件配置参数达到提升Lo Ra性能的目的。通过两种数据预测模型的建立,在未来相应环境的部署中可以按照参数配置模型对硬件进行设置,从而提升Lo Ra性能让硬件设备得到广泛应用。"
792,基于机器学习的互联网大数据分析平台的管理系统研究,"随着互联网的飞速发展,各种网络业务呈现出爆发式的增长,产生的互联网流量数据也爆发式增长,互联网大数据分析平台的的运维环境变得复杂多变,产生的数据量大,并且千变万化,平台需要监控的指标越来越多,这对于传统的平台运维模式和技术方案带来了很大的挑战。目前,大数据分析平台的运维人员通过简单的检测器或者设置固定的阈值来对平台的各项指标进行监控,并且对于不同的业务场景,阈值的设定也不尽相同,这需要平台的运维人员丰富的经验。随着平台业务的增多,监控指标也在增加,需要设定的阈值也在增多。并且人工设定阈值带来大量的错报以及漏报问题,平台运维人员需要花费更多的时间去监控、排查以及修复问题,平台的运维变得很被动,运维成本也在不断的增加。基于规则和简单设置阈值的运维方式,只能够应对简单的场景,难以扩展。相反,统计方法和机器学习提供了更加灵活的表达方式,强大健壮,能够应对不断变化的需求。本文介绍了机器学习在大数据分析平台运维管理中的两方面应用,第一是聚类方法在平台原始数据分布规律的发现和以及采集服务器负载均衡中的应用;第二是回归算法在平台监控指标的智能化预测以及异常检测中的应用。不同于传统的图像或者文本数据,本文实验数据为时间序列,因此特征提取与传统的机器学习流程上有一定的差别。本文通过数据的汇聚处理将平台原始数据转为算法可用的时间序列数据,然后使用不同的距离计算方法和聚类方法对其聚类和分析。对于平台的监控数据,本文充分挖掘时间序列的特征信息,将单一时间序列特征扩充为表现力丰富的多维特征,之后分别采用LSTMs(Long Short Term Memory networks)以及机器学习回归模型对时间序列进行预测,同时与传统的时间序列分析方法ARIMA(Autoregressive Integrated Moving Average Model)进行了对比。有了准确的预测能力之后,本文自主设计一种异常检测算法,并通过验证得到了满意的结果,实现了对平台监控数据的异常检测。"
793,基于半监督学习的情感分类方法研究,"随着互联网技术的迅速发展,越来越多的用户热衷于在网络上对产品、服务、时事等发表评论。如果能自动挖掘出这些主观性文本中蕴含的情感倾向,对个人、企业、政府等有着巨大的应用价值和经济价值。文本情感分类技术正是解决这一问题最有效的工具。半监督学习作为一种普适性的机器学习技术,能够充分利用未标注样本提升分类性能。针对文本情感分类很多场景面临标注语料不足、而标注样本费时费力的情况,本文主要围绕半监督学习情感分类展开研究。本文主要创新点如下:一、本文提出了基于分层抽样随机子空间的协同训练情感分类算法。该算法采用分层抽样的方法构建子空间,改进了将随机特征子空间半监督学习算法直接应用于文本情感分类中可能会存在部分子空间不包含强相关属性的缺点,算法在确保子空间多样性的前提下,有效提升了每个子空间的充分性。实验表明,本文算法的分类效果要优于基于随机特征子空间的半监督学习算法以及其他部分常用的半监督学习算法。二、本文提出了基于多样性与高置信度估计的半监督情感分类算法。该算法结合样本的后验概率和先验分布信息,改善了增量式自训练算法在迭代训练的过程中易引入误标记样本的问题。其次,为了避免引入的样本分布集中会造成数据空间与真实分布不一致的情况,算法通过多样性度量来保证彼此差异性。实验表明,与部分常用的增量式半监督学习算法相比,本文提出的算法有更好的分类性能。"
794,基于深度学习的跨模态人脸识别,"跨模态人脸识别是人脸识别领域的一个研究热点,而素描人脸跨模态识别对现实世界的安防和娱乐应用有着重要意义。素描跨模态人脸识别问题在早期就有着广泛的研究。通常,素描跨模态人脸识别任务的核心主要是两大部分:合成/映射/提取特征和人脸识别。近几年,深度学习在人脸识别任务上已经有非常优异的表现,且使用深度学习解决图像合成问题的研究日益增多。但是,目前少有研究工作关注深度学习方法在素描跨模态人脸识别中的表现。此外,现有的素描人脸数据集数量较小,使用小数据训练深度模型的方案并不是最优的。为了将深度学习更好的应用于素描跨模态人脸识别任务上,本文探究了现有图像合成和人脸识别深度模型在此任务上的效果,通过组合现有的深度图像合成网络以及人脸识别深度学习方法构成本文的基础解决方案。其次,本文提出在图像合成网络中嵌入人脸识别预训练模型,在合成任务里利用大数据人脸识别经验,来引导合成更具有判别性的图像。此外,为了针对素描人脸图像提取到更优的深度特征用于提升识别率,且考虑到素描数据集数量小的问题,本文提出引入外部大数据集利用已有素描合成模型进行数据增强,学习得到素描人脸识别深度模型,并且使用三元组的度量学习损失用于适应训练数据集的数据分布。最终,本文所提出的方案在CUHK和CUFSF数据集上分别达到了 100%和98%的识别率。"
795,基于深度学习的图像分类方法研究,"随着互联网技术的飞速发展,人们已经进入了大数据信息时代,图像变成了人们生活当中十分重要的信息载体形式。随着图像数据库越来越庞大,如何通过对图像数据分类来快速提取视觉信息,已逐渐成为了图像处理和计算机视觉领域的一个重要研究方向。图像分类在图像检索、图像识别、智能安防、医疗诊断等领域有着重要的理论意义和实际应用价值。传统的图像分类方法需要人工设计来提取图像特征,计算量大,分类准确率低,已经无法满足时代变革的需求。深度学习近几年广泛活跃在图像分类的舞台之上,具有较强的特征表征能力和泛化能力,能够对图像数据进行自主学习,自动提取特征。因此,本文提出了一种基于深度学习的图像分类方法,进一步研究深度学习模型中的卷积神经网络在图像分类中的应用。本文以提高深度学习模型的分类准确率、减小网络规模大小和防止模型过拟合等问题为出发点,共提出了两种设计方案。首先是一种基于改进卷积神经网络的图像分类算法,主要设计了一个7层的卷积神经网络,通过从网络架构和内部结构两方面对经典的卷积神经网络AlexNet算法改进和优化,调整激活函数和池化方式,研究极限学习机作为卷积神经网络分类器的可行性。使用CIFAR-10和CIFAR-100两个复杂图像数据集对改进卷积神经网络进行训练,测试和优化网络参数,实验表明改进后的模型准确率分别提高了12.87%和6.85%。其次研究了深层卷积神经网络并提出一种基于Mobilenet V2网络的自然场景图像分类方法。通过大规模自然数据集ImageNet对ResNet50和Mobilenet V2网络进行预训练,将训练好的模型通过迁移学习到新的网络中,再利用新网络重新训练一个自主构建的含9类自然场景数据集并进行微调。实验表明Mobilenet V2网络模型大小比ResNet50网络减少了11倍,速度提升了3倍,分类准确率能达到90.01%,验证了该网络在图像分类上模型大小和速度的有效性。最后对数据集外的图像进行测试表明该网络能有效的避免过拟合和较强的泛化能力。"
796,深度学习中的卷积神经网络硬件加速系统设计研究,"近几年来伴随着深度学习所带来的新的机器学习热潮,深度神经网络已经广泛的应用于图像识别、图像分类、目标检测和自然语言处理等不同的大规模机器学习问题当中,并且已经取得了一系列突破性的实验结果与实际应用,如今深度学习其强大的特征学习能力与识别分类能力被广泛的研究与关注。但由于深度学习中的卷积神经网络模型通常具有深度高、层次复杂、数量级大、并行度高、计算和存储密集的特征,从而使得大量的卷积计算操作和池化计算操作在具体应用中成为巨大的瓶颈,并且大量层间计算结果的存储对于计算机的存储结构也提出了较高的要求,使其在实时的应用场景下面临着巨大的挑战。现场可编程阵列FPGA(Field-Programmable Gate Array),是一种电路密集度大的运算加速器件,它集成了丰富的内部存储硬件资源、灵活的可编程逻辑资源以及高性能的计算资源,能够充分发挥卷积神经网络结构并行特性,并且能够在尺寸要求小、功耗限制低情况下实现卷积神经网络的高速运算,是实现卷积神经网络运算的理想平台。本论文主要针对深度学习中的图像识别任务进行了硬件加速系统设计研究。文章主要根据卷积神经网络的结构特点,在基于ZYNQ系列芯片的FPGA上将卷积神经网络进行了硬化实现,利用FPGA的并行计算特性与流水线技术减少了卷积神经网络的计算时间,从而实现了卷积神经网络的硬件加速;同时为了满足实时场景下对图像识别的应用需求,本文设计出了一种实时识别硬件系统框架,采用软硬件协同的方式,使用ZYNQ系列芯片的ARM完成对输入图像数据的实时采集、存储和显示,将采集存储的数据通过AXI4总线传输至FPGA中硬化后的卷积神经网络来完成对图像的实时识别,并且该系统框架还可以替换不同的硬化卷积神经网络模型,满足多场景下的实时识别任务需求。实验结果表明,本文设计的硬化卷积神经网络模型能够在单个时钟周期内完成528次卷积运算,相较于通用CPU的计算效率得到了显著提升;在对权值参数进行11位定点量化后网络的识别率为97.8%,具有较高的准确率;并且本文设计出的实时识别硬件系统框架能够实现对摄像头采集图像的实时识别,同时结合ZYNQ器件中高度模块化设计使得整个系统框架具有移植性高的特性,且系统整体运行时所需的功耗低。"
797,图像前背景分离的机器学习算法及应用,"图像是承载信息的主要载体之一。随着计算机技术的发展,利用计算机对图像所包含的信息进行采集、处理与识别成为了一个热点研究领域。其中图像前背景分离是目标检测、跟踪、识别的一个十分重要的部分。顾名思义,图像前背景分离就是把一幅图像中感兴趣的部分分离出来。在不同应用场景下对前景分离结果的要求是不同,例如利用天天P图、MIX等图像编辑工具制作表情包时就要求对图像进行细分割。而在无人驾驶、图像检索中仅需对图像进行粗分割。因此图像前背景分离算法种类繁多,处理结果也是不尽相同。自上个世纪以来,学者们相继提出了Knock、Bayesian、Grabcut等算法应用在图像前背景分离等领域。其中Grabcut是应用最广泛的,也是最经典的算法之一。但该算法需要人机交互才能处理图像,因此算法的效率和自动化程度较低。针对此问题,本文改进了传统Grabcut算法。实现了Grabcut自动化。本文主要研究工作如下:首先,在介绍常用机器学习算法原理并对其优缺点进行分析的基础上,介绍了Grabcut算法原理并进行实验,针对该实验结果进行分析与总结。其次,探讨了一种基于Lab颜色空间纹理特征的自动图像前背景分离算法。先对图像进行分块,并将图像从RGB转换到Lab颜色空间,接着提取子块颜色、纹理特征。选择种子进行区域生长,为了改善区域生长带来的过分割,使用区域合并算法。较传统方法,本文算法不需要人工交互,也不需要样本训练,实验结果表明本文方法对背景复杂、目标与背景颜色相近的图像处理结果不理想。但对背景单一且目标和背景相差比较大的图像能够快速、准确的实现分离,且分离的前景符合人眼的主观感知。最后,针对上文提到的方法对复杂图像处理效果较差以及Grabcut算法需要人机交互等问题,提出了一种基于区域生长与合并的自动Grabcut算法,对上文方法的分离结果进行二值化并进行一定的形态学处理形成掩模Mask,设置面积阈值去除部分“噪声”区域生成最终的Mask。最后将其用来初始化Grabcut,即结合混合高斯模型和图割理论算法。实验结果表明改进算法能快速、准确的自动分离出前景。"
798,基于深度学习的中文信息抽取研究,"信息抽取技术随着计算机科学的进步不断突破,命名实体识别和实体关系抽取作为信息抽取技术的主要任务,命名实体识别可以从非结构文本中抽取出诸如人名、地名、机构名等重要实体载体,实体关系抽取可以从已获得实体的文本中抽取实体间语义关系。两者作为重要的基础任务,是很多高级任务如机器翻译、机器问答等的组成部分之一,因此具有深远的意义和影响。论文主要研究成果如下:(1)针对传统机器学习方法需要大量的特征来保证准确率,特征模板特别依赖于人工和专家知识,以及传统机器学习存在难以获取长距离依赖信息等缺点。构建一种基于BERT-BiLSTM-CRF深度学习网络架构,通过BERT模型来对语料进行文本特征提取,作为BiLSTM网络的输入。BiLSTM克服了传统机器学习的长距离依赖难以获取的缺点,从而对标签序列做出有效的预测。CRF可以通过训练学习得到标签转移概率和约束条件,在最终预测时防止非法标签的出现。实验结果表明,BERT-BiLSTM-CRF模型拥有良好的识别效果。相较于传统模型在准确率、召回率和F值上均有较大程度提升。(2)提出了一种注意力机制融合句法分析的BiGRU神经网络模型,利用依存句法分析获取中文的结构特征,充分挖掘中文句子中的潜在信息,输入到双向GRU模型中,有效克服长期遗忘的问题,GRU模型结构比长短时记忆网络模型更加简单,参数较少,减少了过拟合的概率。利用注意力机制能够对句子中不同特征分配权重,选择性关注句子中能够改善识别效率的特征信息,减少数据中噪声带来的不良影响。实验结果表明注意力机制融合句法分析的模型性能具有良好表现。(3)提出了基于BiLSTM的实体与实体关系联合抽取方法。将实体识别和关系抽取同时进行,克服了传统实体关系抽取任务中先识别句子中的实体,然后再进行实体关系判断这两次任务中的错误累加的问题。将中文的词性标注特征加入到中文的词向量中,名词、助词等能明确指示句子各组块之间的语法和语义结构关系,借鉴串联抽取模型处理的优势,提出基于联合抽取的关系抽取处理方式,采用端到端的BiLSTM框架将中文实体关系抽取任务转变为中文序列标注的问题,实验结果表明,该方法较传统的基于中文处理方式,准确率明显提高。"
799,基于深度学习的文本情感分析算法研究,"在大数据时代,人们在电商平台、电影社区平台、讨论平台等区域留下了大量的带有的信息,文本作为这些数据最常见的载体,如果能利用自然语言处理技术挖掘出文本潜在的情感态度,将会推动网络舆情监督、商品售后、自动抉择的发展,具有非常重要的实际应用价值。传统的文本情感分析方法主要是基于情感词典和基于机器学习。基于情感词典的方法中,不论是人工构建还是自动构建的情感词典都存在覆盖度不足和应用领域单一的问题。基于机器学习的方法中,常见的有朴素贝叶斯、最大熵和支持向量机,在这类方法中样本不足和人工特征提取困难都将严重影响最后的文本情感分析效果。深度学习自提出以来获得了学术界的广泛关注,本文借鉴深度学习在自然语言处理领域取得的优秀成果,提出了基于深度学习的文本情感算法研究。本文主要内容分为以下四个部分。首先,利用结巴分词算法对中文文本进行切句、分词、去停用词(标点符号、英文字符),并对词进行统计建立词典;接着,针对传统的词向量表示的维度灾难和数据稀疏问题,本文用embedding layer、word2vec和glove等深度学习技术获取低维度、稠密的词向量。本文的主要贡献在于提出两种算法模型,一种是针对长短期记忆神经网络仅学习文本的历史信息,而忽略了文本的未来信息,本文用双向长短期记忆神经网络代替长短期记忆神经网络,并结合卷积神经网络获取文本特征,提出基于卷积神经网络和双向长短期记忆神经网络的文本情感分析模型;另一种是考虑到文本中不同的词对最后文本分类有不同的作用,本文引入了多头注意力机制,提出基于双向长短期基于神经网络和多头注意力机制的文本情感分析算法模型;最后,文本针对所提出模型均做了多组对比实验,其中前一种模型采用了谭松波中文酒店评论数据集和IMDB英文电影评论数据集,后一种模型使用了电商平台上的商品评论数据集,以精确率(p),召回率(r)、F1值(f1)和准确率(acc)作为模型好坏的评价标准。实验结果表明,本文所提出的两种深度学习模型均进一步提升了文本情感分析的性能。"
800,基于深度学习的视频多目标检测研究,"随着城市摄像头的安装日益普及,以及视频监控领域的发展,视频多目标检测方向成为计算机的热门研究领域。随着深度学习的发展和计算机硬件设备的完善,在人脸识别无人驾驶和目标检测等领域已经取得了巨大的成就,并实现了广泛的运用。本文主要针对计算机视频领域,采用深度学习算法对视频中的物体进行实时性的目标检测,并将算法移植到嵌入式运算平台上,完成在移动端的视频多目标检测系统设计。考虑到现有的基于深度学习的目标检测算法的参数量过大,嵌入式平台的运算能力有限,我们根据SSD目标检测算法这种端到端的预测方式,对算法进行剪枝,提出轻量化模型的目标检测算法MobilenetV2-SSD,并综合对比SSD、MobilenetV1-SSD、MobilenetV2-SSD算法的优劣性。在Caffe深度学习框架上实现MobilenetV2-SSD算法,并将训练后的模型移植到NVIDIA Jetson TX2嵌入式平台上,实现在移动端的视频多目标检测系统的设计。1.基于region proposal策略的目标检测算法存在对视频多目标检测速度过慢的情况,本文采用SSD目标检测算法中anchor的方式对边框进行回归,采用卷积核实现在卷积神经网络中同时进行边框预测和目标回归策略。2.考虑SSD目标检测算法的参数量过大,本文基于MobilenentV1的深度可分离卷积和MobilenetV2的Inverted Residual Block卷积神经网络结构,提出了MobilenetV2-SSD算法,实现对模型的剪枝,轻量化算法模型,实验证明在不明显降低模型准确率的情况下可以压缩到原有模型的1/5。3.为了实现在嵌入式端的视频多目标检测,我们在嵌入式端采用的是带有GPU芯片的NIVIDIA Jetson TX2嵌入式平台,经过实验测试,基于MobilenetV2-SSD算法在服务器上训练移植到JetsonTX2上,能够在移动端完成对视频多目标的实时性检测的效果,实现我们在移动端的视频多目标检测的目的。"
801,基于深度学习的JavaScript恶意代码检测技术的研究与应用,"JavaScript脚本语言被广泛用作传播恶意代码的载体,而传统恶意代码检测方法难以识别混淆变形后的恶意代码,需要采取复杂的特征工程提取恶意代码关键特征,并且分类器检测的好坏直接依赖于特征的选取,故提出较好的特征提取方法至关重要。深度学习方法具有从海量数据中学习数据规律的能力,适用于处理当今高维复杂和大样本的恶意代码数据,基于此,本文提出了基于卷积神经网络(Convolutional Neural Network,CNN)的JavaScript恶意代码检测方法和基于堆栈式稀疏降噪自编码网络(Stacked Sparse Denoising Auto-Encoder Network,sSDAN)的恶意代码检测方法。利用CNN在图像识别领域取得的优异成果,本文提出了一种基于CNN的JavaScript恶意代码检测方法。首先将代码样本数据转换为相对应的灰阶图像数据,得到图像数据集,然后利用卷积层和池化层构成的特征抽取器有效提取图像特征,最后使用softmax分类器进行分类和预测,通过与传统的机器学习分类算法对比,CNN检测模型具有更高的准确率和较低的误报率。利用自编码网络在处理维度过大、特征信息冗余数据方面的优异效果,本文提出一种基于sSDAN的JavaScript恶意代码检测方法。首先将代码样本转为矢量型数据作为sSDAN模型的输入,然后加入稀疏限制和高斯噪声进行逐层训练,可以获得恶意代码有效去噪后不同层次特征的表达,最后,通过设计多组实验验证模型的检测效果,实验结果表明sSDAN适用于当前高维、复杂多变的恶意代码,可以为当前的恶意代码检测研究提供一种新的思路。基于上述的CNN检测模型设计并实现一个Chrome扩展检测工具,用来检测网页中是否存在恶意的JavaScript代码。"
802,基于视觉感知的图像质量评价算法研究,"在现今生活中,数字图像作为信息表达与交流的工具获得了广泛应用。然而,在图像采集、分析、传输、处理和重建过程中,很容易因为各种各样的原因导致图像发生失真现象,影响图像本身的视觉效果,如何保持图像质量与人类视觉效果相一致是图像质量评价研究的核心内容。基于此,本文将在前人研究图像质量评价模型的基础上,探究更加符合人眼视觉系统的感知特性,以及自然场景统计特性,以便提取出能够反映图像某种特性的特征,从而实现客观评价与主观评价之间更高的一致性。(1)针对全参考模型,提出了一种基于HSV色彩空间和边缘特征的图像质量评价方法。首先将图像转换到符合人眼视觉特性的HSV色彩空间,得到亮度分量以及颜色特征。接着根据人眼视觉掩蔽特性,提取亮度分量以及灰度图像的边缘分别作为缓慢变化和强烈变化的局部特征。然后利用视觉显著性模型,获得强烈变化区域、缓慢变化区域以及颜色特征作为补充的边缘扩展区域视觉质量。最后将视觉显著性模型作为加权函数对局部区域视觉质量进行融合,以此确定最终的图像质量分数。在四大常用公开数据库(LIVE、CSIQ、TID2008、TID2013)上的实验结果表明,本文所提算法的评价指标总体上取得了较为理想的结果,其中在TID2013数据库的不同失真类型上SROCC指标明显高于其它算法。(2)针对无参考模型,提出了一种结合结构和自然场景统计的图像质量评价方法。首先根据人眼视觉系统的特性,提取图像的边缘和纹理作为图像的感知特征。接着将图像转换到更适合处理自然图像的lαβ色彩空间,提取图像的亮度分量以及作为颜色特征的红绿和蓝绿分量作为自然场景统计特征。然后运用非对称广义高斯模型获得亮度统计参数和颜色空间统计参数。最后将所提取的特征作为支持向量回归模型输入,对图像质量进行预测。在常用数据库(LIVE、CSIQ、TID2008、TID2013)上的实验结果表明,本文提出的算法能获取与主观评价更为一致的结果。"
803,基于机器学习的可感知序列型工控入侵检测技术研究,"随着信息化与工业化深度融合进程的推进,越来越多的信息领域技术手段被应用到工业领域当中。两化融合给工业生产力带来了极大的提升。但与此同时,工业控制系统也因信息化技术的介入而面临更多的安全挑战。原本相对封闭的工业控制系统存在着设备老旧、补丁安装不及时、安全机制缺乏等固有问题。当这些存在巨大安全隐患的设备暴露在更严峻的网络环境中时,恶意攻击者可以利用多种攻击手段对工业控制系统的安全性进行破坏。以序列攻击为代表的语义攻击,就是一种兼具隐蔽性和高度危害性的针对工控系统的网络攻击方式。本文设计并开发了一种可以有效检测序列攻击的入侵检测系统。该系统由捕获层、提取层、建模层、检测层、响应层等五个层次组成。本文以工业生产环境内广泛使用的S7协议为研究对象,对该协议进行深度解析,为后续的研究奠定了坚实的基础。为了能够准确反应网络流量时序特征的变化及其产生的安全影响,以离散时间马尔科夫链为基础建立工业网络流量模型。检测层对学习阶段构建的模型与检测阶段构建的模型进行比较分析,发现异常情况并进行上报。本文创新地提出了根据事件重要性和事件语义进行权重配置的检测优化手段。通过检测优化,可以显著降低入侵检测系统的误报率。最后,本文以工业控制系统安全实验室内的工业仿真环境来检验入侵检测系统的检测效果。在没有攻击行为的安全环境中,入侵检测系统分别进行了学习阶段和检测阶段的工作,发现了少量误报并分析了误报产生的原因。为了检验该系统对序列攻击的检测效果,构造了针对轨道交通控制系统内屏蔽门的序列攻击流量。回放攻击流量,入侵检测系统准确地发现了序列攻击造成的异常。结果表明:本文设计并开发的入侵检测系统可以有效地检测针对工业控制系统的序列攻击。"
804,基于主机和网络特征关联的木马检测方法研究,"近年来高级可持续威胁(Advanced Persistent Threat,APT)攻击事件频频发生,木马程序作为一种高潜伏性、高威胁性、高隐蔽性的恶意软件在APT攻击中扮演着重要的角色。木马程序对个人、企业、社会组织以及国家的网络空间安全造成严重的威胁。对木马程序的检测一直是网络安全领域的研究热点,国内外的研究者已经提出了许多的木马检测方法,但是目前的检测方法大多是单独分析主机或网络的特征表现,其检测的漏报率和误报率仍有待降低,并且检测结果的可靠性也有待提高。本文首先深入分析了木马程序的运行原理及其通信过程中的不同阶段的不同表现。针对目前基于网络的木马检测方法需要一段时间来统计流量特征而导致的检测延迟问题,提出了一种基于网络流量分析的快速木马检测方法,实现了在木马通信早期对木马通信会话进行快速检测。其次,为了进一步降低木马检测的误报率和漏报率,增强木马检测抵抗混淆技术的能力,提出了一种基于主机和网络特征关联的分段木马检测方法,该方法将主机特征和网络特征进行关联,并为木马通信的两不同阶段使用机器学习分类算法训练了不同的检测器。最后,搭建了真实的实验环境进行了实验。实验结果表明基于网络流量分析的快速木马检测方法可以在木马通信早期快速检测木马通信,基于主机和网络特征关联的方法在增加抗混淆技术的基础上进一步降低了检测的漏报率和误报率,验证了方法的有效性。"
805,网络安全知识图谱构建关键技术研究,"随着大数据技术的发展和网络环境的日趋复杂,网络空间中包含了大量有价值的网络威胁情报数据。如何从碎片化、海量化的威胁情报数据中挖掘出关联关系、攻击模式等是威胁情报分析研究的焦点,因此,基于网络安全知识图谱的威胁情报分析成为了研究热点。网络安全知识图谱可将海量的碎片化的多源异构威胁情报数据进行细粒度的深度关联分析和挖掘。网络安全知识图谱构建的基础就是信息抽取,本文重点研究海量网络安全文本数据中的网络安全实体识别和实体之间的关系抽取。首先,传统的命名实体识别方法难以识别网络安全领域中新的或中英文混合的安全实体,且提取的特征不充分,因此难以准确的识别网络安全实体。针对此问题,本文在神经网络模型CNN-BiLSTM-CRF的基础上,提出一种结合特征模板的网络安全实体识别方法,其利用人工特征模板提取局部上下文特征,进一步利用神经网络模型自动提取字符特征和文本全局特征。实验结果表明,在大规模网络安全数据集上,本文提出的网络安全实体识别方法与其它方法相比,相关评价指标优于其它方法,F值达到86%。其次,针对远程监督方法在构建语料过程中引入的噪声数据问题,本文在远程监督模型PCNN-ATT的基础之上,提出了一种ResPCNN-ATT的远程监督关系抽取方法,其利用PCNN提取语义特征,引入深度残差学习解决由于噪声数据引起的梯度消失问题,进一步利用多实例注意力机制计算实例与对应关系的相关性,以降低噪声数据的影响。实验结果表明,在NYT数据集和NSER数据集上,本文提出的方法与其它方法相比,关系抽取准确率优于其它方法。"
806,面向零售业时间序列预测与分析的算法研究,"随着体验式购物的不断兴起,零售业正在以各种形式迎来它的新生。零售业具体表现出的商业模式有很多种,本文选取它最经典的一种表现形式――购物中心――进行研究。本文以某购物中心的销售时间序列数据作为研究对象,分析各种可能影响零售业销售行为的影响因素,构建合适的特征工程,构建合适的时间序列分析与预测的模型。针对购物中心最关心的两个时间序列预测问题:销售额与销售频次,作出科学的分析与预测。主要针对时间序列预测算法及特征选择进行研究。首先,在特征选择方面,采用面向零售业时间序列的基于相关-互补-冗余特征选择模型。引入特征间的互补性,可以增强了特征子集的整体表现力。通过实验表明,该模型选取的特征在不同预测算法中,均比基线特征提取模型有较好的预测精度,相关指标优化3%以上其次,在零售业时间序列预测方面,采用面向零售业时间序列的基于EMD与深度学习预测模型。该模型采用EMD分解算法将零售业时间序列分解成含有不同信息分量的子序列,挖掘子序列的局部特性,从而针对性地进行建模预测。采用GRU以及MLP模型构建子预测模型,将子预测结果进行组合得到最终的预测结果。该预测模型的RMSE指标优化5%以上,MAE指标优化1.5%以上。此外,对模型进行了效率优化,通过对分解的子序列进行重组,简化为两组子序列,趋势序列与短时波动序列。实验表明,通过对这两组序列进行建模研究可以在损失不足1%精度的代价下,明显提升计算效率。"
807,基于Spark的工业控制网络安全预警平台的设计与实现,"随着互联网+以及信息化与工业化的不断发展,工业控制网络在国家基础设施上得到了广泛的应用,然而在这大环境背景下,由于没有专门的物理隔离,工业控制系统大多采用以太网,网络环境的开放,工业控制网络不断受到安全攻击,因此工业控制网络面临着巨大的挑战。工业控制系统智能化的发展,随之工控网络中的数据呈现出海量化、高维化、复杂化等特点,目前大多数的工业控制网络所建立的安全预警系统都是以Hadoop为载体进行相关离线分析,通过相关机器学习算法建模来识别,然而没有考虑到安全预警的实时性、效率以及扩展性等问题。本文对采用Spark计算框架为载体建立一种快速高效、精确性高和扩展性强的安全预警平台,在面对大规模复杂数据时能够得到实时计算分析。本文根据工业控制网络的特点,结合工业控制网络完全预警的要求,具体研究了目前主流的大数据计算系统,分布式发布订阅消息系统以及深度学习训练框架等关键技术。然后依据该平台的设计需求分析,构建出一个以Spark计算引擎为核心的工业控制网络安全预警平台。开始设计出该平台的整体架构原理图,组成数据采集与网络流量深度包检测协议解析模块、实时计算数据分析模块、安全预警预测模块和数据存储模块4个功能模块。其中首先对数据源利用网络流量传感器进行数据自动化采集,使用深度包检测技术进行应用层内容解析总结特征,接着通过分布式发布订阅消息系统为桥梁,建立与Spark实时分析计算的通道,对特征进行预处理,实现了对工业控制网络中复杂海量数据的实时分析与统计,然后通过DeepLearning 4J建立Spark分布式卷积神经网络流量异常检测模型,最后是对采集的数据进行持久化存储,利用Redis对实时数据的分布式存储以及呈现,并对预测结果数据进行存储,方便模型的增量更新,利用模型对实时数据的预测并对实时结果呈现来达到安全预警的目的,有利于工作员的作出应对。通过对平台的搭建部署以及实现,针对电力控制网络这一案例来具体分析数据并测试的平台的适用性,吞吐量的性能,模型训练与识别的计算性能开销,最后与其它算法进行对比分析,验证平台的识别率与精确性。由此证明了该平台具有可行性强、吞吐量高、实时效率高、识别精确率高以及可扩展性强等优势,能够对工业控制网络的复杂高维数据进行实时分析,并达到安全预警的目的,为工作人员提供了便捷,节约了成本,提高了效率。"
808,基于关键超参数选择的监督式AutoML性能优化,"近年来,关于机器学习的研究与应用在各个领域都取得了丰硕的成果,这些成果主要依赖于机器学习专家对机器学习各环节的大量人工干预,尤其是在算法选择和超参数调优阶段。自动机器学习(AutoML)的出现减轻了专家的负担,使其将工作重心从繁琐、重复的选型和调参任务转移到数据分析上来。众所周知,人们通常通过调整超参数的设置来提升模型的性能,这个过程称为超参数调优,它是AutoML中最耗时的阶段,在此过程中因为不同超参数对模型性能的影响差异较大,所以选择关键超参数对提高AutoML性能具有十分重要的应用价值和研究意义。本文面向传统监督式机器学习中的算法选择和超参数优化的组合优化问题(简称CASH问题),重点分析超参数与模型性能之间的内在关系,并对AutoML配置器在运行过程中的搜索策略进行了深入研究。针对其性能瓶颈,设计并实现了基于关键超参数选择技术的性能优化组件。主要研究内容包括:(1)分析监督式AutoML配置器SMAC的性能瓶颈,发现在配置生成阶段,配置器中的采集函数因低性能配置具有高不确定性而产生额外不必要的评估开销;(2)分析超参数与模型性能之间的内在关系,利用平均不纯度下降法(MDI)量化超参数对模型性能的贡献量,提出了一种基于关键超参数选择的剪枝策略,并构建剪枝组件;(3)在SMAC配置器的基础之上,设计并实现了新配置器Pruning-SMAC,该配置器具有可动态调整的搜索空间,并通过利用本文提出的剪枝组件在迭代运行过程中收集历史性能数据来修剪超参数取值范围,从而逐步得到核心搜索空间,避免在已知性能较差的区间内选择配置,减少不必要的开销,以此提升AutoML的性能。"
809,基于迁移学习的粒子群优化算法研究及应用,"粒子群优化是一类模拟大自然演化行为的进化优化技术,其产生来源于鸟类的群体觅食行为。随着进化优化技术的快速发展,在科学研究和工程实践中粒子群优化扮演着越来越重要的角色。然而,在解决实际优化问题时,如何加快种群的收敛速度,提高算法的搜索效率,仍是一个开放性难题。分析发现,现有的粒子群优化算法大都从问题的零初始信息开始搜索最优解,这在一定程度上浪费了种群计算资源。迁移学习是一种运用已有历史知识对相关领域问题进行求解的机器学习方法。将迁移学习扩展到进化优化领域,不仅可以减少算法的计算代价,而且可以显著改善种群的搜索能力,具有非常重要的研究价值。鉴于此,本论文研究基于迁移学习的粒子群优化算法及应用,主要包括以下两部分内容:(1)给出基于相似历史信息迁移学习的进化优化框架,提出一种基于相似历史信息迁移学习的粒子群优化算法。从已解决问题的历史模型库中找到与新问题匹配的历史问题,将历史问题对应的知识迁移到新问题的求解过程中,以提高种群的搜索效率。首先,定义一种基于多分布估计的最大均值差异指标,用来评价新问题与历史模型之间的匹配程度;给出基于模型匹配相似性的种群初始化策略,以加快种群的搜索效率;设计基于快速聚类的代表个体保留策略,用于模型库的更新;然后,将自适应骨干粒子群优化算法嵌入到所提框架,给出一种基于相似历史信息迁移学习的骨干粒子群优化算法。最后,应用于多个标准测试函数,实验结果验证所提算法的有效性。(2)将迁移学习思想应用于旅行商问题(TSP)的进化求解中,提出一种迁移学习引导下大规模TSP问题的快速粒子群优化算法。首先,利用K-mediods技术对相邻城市进行聚类,定义一种基于几何角度相似性的城市拓扑匹配策略,用来寻找与待优化城市子集合分布相似的历史城市子集合;接着,给出一种融合类内城市顺序迁移学习和类间顺序贪心学习的可行路径生成策略,用来初始化粒子群;然后,设计一种基于自适应交叉和变异的整数型粒子更新策略,以适应TSP问题自身特点。最后,应用于16个典型TSP测试问题。实验结果验证所提算法的有效性。"
810,基于惩罚似然的含潜变量贝叶斯网的结构学习,"图模型能清楚地表示变量间的结构关系,被广泛的应用于机器学习、因果推断、生物信息学等各个领域。图模型中的贝叶斯网是一个有向无环的模型,能够更直观的描述变量间的依赖关系,特别是在其中引入潜变量后,不仅可表示因果推断中不可观测的混杂,而且可简化模型降低模型的复杂度,还可以提高计算的效率。然而,如何确定潜变量的个数、潜变量取值空间以及变量之间结构依赖关系,获得与数据拟合最好的模型,是一个非常具有挑战性的问题。这一问题在机器学习领域称为结构学习,本质上是统计学中的模型选择问题。本文针对含潜变量的贝叶斯网的结构学习问题,给出了基于惩罚似然的方法。这里的惩罚包括两项。一是对于可观测变量间的系数进行_1l范数惩罚,以获得稀疏的模型;二是采用核范数(本文中为矩阵的迹)惩罚,以控制潜变量的个数。我们采用交替凸搜索方法,结合ADMM算法和坐标轴下降法,最小化惩罚似然,从而获得观测变量间的结构关系和潜变量个数的估计。我们给出了详细推导过程,编写了R程序,与当前主流的PC算法、RFCI算法、Adaptive Lasso惩罚似然方法、低秩稀疏(lrps)方法、低秩稀疏+贪婪搜索(lrps+ges)方法进行了比较。通过大量的模拟,我们发现当样本量大于200时,我们的方法有较好的表现。"
811,基于在线评论的京东平台大米消费者满意度研究,"网络技术的突飞猛进与消费环境的升级转变,决定了企业经营模式与互联网融合的必然趋势。在这种背景下,越来越多的农业企业不断地渗入到电子商务领域,积极地拓展线上销售业务,就此各类型农业电商平台蜂拥而起。而消费者满意度是决定农业类企业或平台能否持久运营发展的关键因素,所以对于农业企业如何提升消费者对其产品或服务的满意程度仍是新时代亟需解决的重要问题。与此同时,尽管有少数研究已经采用在线评论解决了农业领域的部分问题,但在这些文章中尚未有引入机器学习与情感分析技术来进行消费者满意度的研究。因此,本文以京东大米的在线评论为研究对象,挖掘京东平台上大米消费者满意度的主要影响因素,探究各因素与消费者满意度间的直观联系,以更好地帮助京东平台上大米企业找到提升消费者满意度的策略方法,从而促进大米产品销量,提升大米企业的综合竞争能力。本研究利用机器学习和自然语言处理方法,首先对消费者的情感进行分析,然后对评价文本中的高频词进行聚类分析以探寻出影响消费者满意的主要因素,在此基础上结合灰色关联度分析法,构建了大数据环境下京东平台大米消费者满意度影响因素的研究框架。以京东大米在线评论为样本数据进行了实证研究,采用有监督的朴素贝叶斯算法对消费者的情感进行分类,分为满意、不满意和中性三类,验证准确率为86.14%;通过K-means算法对高频名词进行分类,识别影响京东大米消费者满意度的7个主要因素分别为服务态度、物流、包装、生产日期、价格、品牌以及口感;最后利用灰色关联分析对影响消费者满意度的因素进行了排序,从强到弱为:口感>物流>包装>品牌>生产日期>价格>服务态度。其中口感对京东大米消费者满意度的影响最为显著,服务态度对京东大米消费者满意度的影响最小。基于上述研究结果分析,以提升京东大米消费者满意度策略及促进线上大米农业企业发展建议为切入点,提出了严格把控产品质量、提升产品配套服务、重视品牌效应、合理控制价格区间与产品活动以及加强平台大数据分析应用的五点管理启示。"
812,基于机器学习的无线通信解调研究,"随着智能移动设备的普及和无线服务需求的增加,如何在低时延、大连接的5G场景下实现高频谱利用率、低误码率的信号传输已成为研究热点。无线信号在传输时会受到多普勒频移、多径效应以及强干扰的影响形成非高斯信道,而传统的最佳解调器是针对加性高斯白噪声信道设计的,在非高斯信道场景下无法满足低误码率需求。机器学习通过训练提取数据的特征可在复杂环境下充分逼近任意非线性系统,且具有较好的鲁棒性和容错能力。因此,本文利用机器学习处理复杂非线性问题的优势,针对室内复杂场景设计基于机器学习的解调器降低解调误码率。本文的主要工作和贡献可归纳为:(1)针对复杂的无线通信环境,本文首先建立一个灵活、基于机器学习解调器的端到端无线通信系统,系统由矢量信号发生器、发送天线、接收天线、矢量信号分析仪和基于机器学习的解调器组成。然后,基于所构建的系统模型,在室内场景中测量并建立了包含单载波调制中二进制相移键控和正交振幅调制以及多载波调制中正交频分复用的数据库。最后,为加快解调器的收敛速率,对收集的数据进行归一化预处理,并将单载波数据库上传到百度云和谷歌云,在线公开建立访问。(2)针对单载波调制方式,本文设计了两种基于机器学习的解调器:基于深度置信网络(Deep Belief Networks,DBN)与支撑向量机(Support Vector Machines,SVM)级联的解调器以及基于k近邻(kk-Nearest Neighbor,kkNN)的自适应增强(Adaptive Boosting,AdaBoost)解调器。在基于DBN-SVM的解调器中,本文首先提出了DBN解调器和一对一SVM解调器,并利用其各自的优点进一步设计了基于DBN-SVM的解调器,即:利用受限玻尔兹曼机和误差反向传播算法组成的DBN有监督的训练网络参数,进行特征提取,然后利用一对一SVM进行多类特征分类。在基于κNN的AdaBoost解调器中,通过多个kkNN弱分类器级联形成强分类器,并且在每次迭代时通过增加错误解调信号的权重,同时减少正确解调信号的权重来降低误码率。测试结果表明本文所提出的基于机器学习的解调器相比于最大似然估计解调器误码率明显降低。(3)针对多载波调制方式,本文改进了上述所设计的两种基于机器学习的解调器。在改进的基于DBN-SVM的解调器中,用测试复杂度比一对一SVM多分类器更低的有向无环图SVM多分类器来对DBN输出的特征进行分类。此外,对DBN网络的结构参数如训练批次长度、神经元个数等也做出改进。在基于kkNN的AdaBoost解调器中,针对原解调器计算冗余的情况,本文加入正则化项,同时通过设置迭代误差阈值以防止过拟合。测试结果表明本文所设计的两种改进解调器的误码率低于相干解调。"
813,利用机器学习方法研究助熔剂法生长单晶,"高质量单晶的生长对凝聚态物理的研究具有重要意义。单晶是广泛的科学研究领域的重要先决条件,如凝聚态物理,表面科学,激光和非线性光学。量子霍尔效应/分数量子霍尔效应,Wyle semi-metal等基础研究都依赖于高品质单晶。对单晶的合适生长条件的探索是昂贵且耗时的,特别是对于三元化合物,因为缺乏三元相图。助熔剂生长晶体的方法是晶体生长的一种非常重要的生长方法,对晶体性质的研究有着重要的意义。理论上只要能找到某种适合的的助熔剂或助熔剂组合,就能够用助熔剂法把这种单晶生长出来,而且成功的生长条件有可重复性。利用助熔剂法生长单晶,助熔剂的选择还有生长条件的确定非常重要。本文使用实验室助熔剂生长单晶的实验数据,利用机器学习的方法寻找晶体生长的条件。具体研究如下我们从两个不同的实验室采集了助熔剂法生长单晶的历史数据,分别标记为Group I,Group II。Group I的数据比较充足,生长的样品基本涉及了元素周期表示的所有元素,我们的研究主要针对于Group I,Group II作为讨论机器学习在这个问题研究上的一致性。根据助熔剂法生长单晶的的经验,挑选了对晶体生长可能有影响的生长条件,助熔剂和溶质的物理化学性质。生长条件包括最高温,离心温度,温度差,降温速率,高温停留时间,助熔剂种类,原料单质种类,原料含量。助熔剂和溶质的物理化学性质包括熔点,蒸汽压,原子序数,相对原子质量,电负性,密度,相图。将这些属性作为机器学习训练的特征,将生长结果作为标签,利用决策树,随机森林,支持向量机(SVM),梯度提升决策树(GDBT)四种机器学习算法,寻找最优模型。SVM的效果最好其在测试集的准确81%,f1分数为81%,成功样品的查准率为67%,对比实验数据的准确率30%,通过机器学习训练的模型选择成功生长的条件较人为选择成功生长的条件成功率提高了一倍。模型的阈值可以改变其成功样品的查准率,我们可以根据实际应用的不同需求,调整模型参数,使其符合我们我们的应用需求,模型的性能随着训练数据量增大而增强。助熔剂法生长单晶的机器学习模型可以应用到实验室,帮助实验室更好地生长单晶,本文介绍了将这个模型运用到实验室的方法。方法一是模型独立生长,遍历生长某个晶体的所有可能的特征组合,然后利用训练出来的模型去对这些组合进行拟合,拟合可以得到这些条件生长成功的概率,可以选定一个阈值,把概率在阈值以上的条件按照概率高低优先生长。方法二是模型协助人为经验生长,实验者按照自己的经验挑选条件,模型再判断条件的可生长性。决策树模型具有很好的解析性。通过决策树模型我们发现助熔剂的电负性是描述其作用的一个很重要的物理属性,对生长晶体的其他条件的选择有关键意义。我们从决策树中总结出了一些规则,它们分为两种类型。其中一些人已经很清楚理解了一个明确的理论,但由于有很多因素需要结合,很容易被忽略但是被机器学习(ML)重新发现。而另一个没有明确的理论。前者包括:(a)当冷却速度较低时,需要考虑的因素较少。否则,还有更多因素需要考虑。更好的单晶生长与(a)较低的冷却速率和(b)较低的熔点B较低的熔点更有可能成功相关。ML还发现了一些没有明确解释理论的规则:(a)单晶Ax By Cz的生长,x/z和y/z值都比较大的单晶体生长比较困难。(b)当助熔剂和单晶组分之间的平均液相密度差异很大时,很容易失败。(c)建议选择与单晶组分的平均电负性差别不大的助熔剂。此外,建议选择与A,B和C绝对电负性差最大值较小的助熔剂。"
814,基于Wi-Fi信号的室内动作识别研究,"人体动作识别具有广泛的应用前景,如医疗保健,智能家居等。近来,由于不同的人体动作会对Wi-Fi信号产生不同的影响,而信道状态信息(Channel State Information,CSI)可以较准确地记录这一变化,所以可以使用CSI进行人体动作识别。基于WiFi非接触式方法的人体行为识别具有不泄露用户隐私,不受光线强弱影响等特点,因此其将作为基于视频的人体行为识别技术的一种重要补充,拥有广阔的应用前景。为此,本文设计和实现了基于Wi-Fi信号的室内动作识别系统,主要工作如下:(1)本文设计并实现了一个基于Wi-Fi信号的室内动作识别系统。这一系统包括数据采集、数据预处理、动作区间截取和数据压缩以及动作识别四个模块,并成功实施了我们的人体识别系统,同时对系统进行了数据采集和性能测试。(2)提出基于双阈值的动作区间截取算法。原始采集的数据中包含非动作部分,为了更准确地截取动作区间,本文提出基于平均绝对偏差(MAD)的双阈值动作区间截取算法,这一算法首先通过阈值比较不同窗口的MAD值,判断是否为有意义波形,然后进一步利用小窗口再次进行阈值比较,更准确地提取出包含人体动作的数据段。(3)设计两种不同的动作识别方法进行最后的动作识别,分别是基于动态时间规整与K近邻相结合的模板匹配方法和基于卷积神经网络的方法。实验结果显示,使用模板匹配识别实现了平均88%的预测准确率,使用卷积神经网络达到了平均95%的识别率,实验结果表明两种方法是有效的,而且说明利用Wi-Fi信号进行人体识别的可行性。"
815,基于Android的地铁综合服务系统的设计与实现,"科技的发展改变着人们的出行方式,越来越多的乘客选择地铁出行。但目前相关的地铁软件大多仅为用户提供路线规划服务,越来越不能够满足用户对于地铁出行的多方位需求。同时随着人们的出行计划越来越缜密,地铁路线推荐方案的精准度变得越发重要,特别是对于一些有精细化乘车需求的用户,例如赶末班车的用户,赶时间上班的用户等。然而,目前市场上的地铁路线推荐软件大都理想化地估计乘车时间,不能满足用户对于预估精准度日益增长的需求。基于以上原因,本文致力于构建一个提供地铁全方位服务的系统,不仅为用户提供智能路径规划功能,还为用户提供了更多与乘坐地铁相关的精细化服务。对于系统中的智能路线规划功能,主要是通过处理分析各地铁站数据,并结合机器学习中梯度提升树模型,K-Means聚类,线性回归模型在客流预测领域的运用,基于迪杰斯特拉算法的思想为用户提供了精准的地铁路径推荐方案。包括最短用时方案、最晚出行推荐方案,最少换乘方案以及地铁不可达情况下的距离目的地最近的乘车方案。此外,为满足用户乘坐地铁出行的其他需求,系统还为用户提供了文章阅读,文章推荐,失物招领,周边设施信息展示,VR站内向导,延误、限流推送等功能。以上功能都极大的提高了系统中用户的留存以及用户活跃度。其中,文章推荐模块采用了基于大数据的Lambda架构,分为离线批处理层,实时推荐层以及服务层。根据用户的历史行为数据,为目标用户进行基于物品的协同过滤推荐,丰富了用户的乘车体验。其他模块的Android开发均秉承MVC的设计理念,使用Spring Boot作为服务器端框架,以及使用MySQL数据库,HDFS文件存储提供数据的持久化存储,Redis作为缓存。目前该系统已经上线。其中乘车路线推荐模块的平均查询耗时为39.3ms,模型准确率(乘车误差时长小于三分钟的路径为准确路径)达到92.8%,模型准确率相对较高,满足系统要求。"
816,基于机器学习的立体停车库智能监控系统设计,"立体停车库能极大程度利用空间,缓解了停车库供不应求的现状。目前立体停车库技术已经发展得比较成熟。但是维保问题日益显著,主要表现为电机的异常工作模式和结构的不可靠性。由于电机和结构的异常往往会微小体现在表面上,立体停车库维保人员很难发现,这成为立体停车库维保的一大难题。另外,由于立体停车库每天进出量都很大,对于相关数据的记录也是一大难题。机器学习作为驱动人工智能一大动力,近年来得到了全面的发展。机器学习的本质是通过对海量数据的训练,使机器得到划分新数据的能力,是模拟人脑的一种学习方式。机器学习分为有监督学习和无监督学习,常见的监督学习方法有分类和回归,常见的无监督学习的方法有聚类和降维。选取合适的机器学习算法能极大提高分类的正确性。为了解决立体停车库维保存在的种种问题,本论文设计了一种基于机器学习的立体停车库智能监控系统,使用振动变送器、电流变送器、网络摄像头、网络采集卡等设备搭建立体停车库的采集前端。利用Python作为编程语言实现对数据的机器学习,通过支持向量机(SVM)、K近邻等机器学习算法实现对立体停车库安全状态的评估和信息识别,并使用数据库对关键数据进行储存。通过开展系统性的实验,分析和验证了本设计的可行性、可靠性、实用性。本论文的主要研究内容和工作主要包括以下几个部分:1)对立体停车库维保所存在的问题进行了系统的分析。设计了立体停车库智能监控系统的系统架构,以可行性、可靠性、实用性、稳定性为基本诉求制定了系统的实现方案。通过调查和研究优选了能实现对数据进行机器学习的最佳编程语言。2)设计了立体停车库智能监控系统的采集前端。以振动变送器、电流变送器、网络摄像头为主要传感器,实现系统对原始数据的捕获。以Ethernet为总线,实现了传感器的有效控制和稳定传输,POE的供电方式优化了系统的架构。稳定可靠的采集系统为实现数据的机器学习奠定了基础。3)研究学习了机器学习算法的概念和分类,通过分析最终选择支持向量机、K近邻机器学习算法为系统的核心算法,深入研究了梯度下降,贝叶斯理论,逻辑回归等机器学习算法的基础。推导了机器学习算法中的数学原理,并通过程序语言来实现算法。4)以Python为编程语言设计了立体停车库智能监控系统的软件,实现了对关键数据的显示,完成了对数据的机器学习,能将关键数据存入数据库。完善了用户界面,使之实现简洁性、实用性的要求。同时,以实验室为实验场景完成了对系统可靠性、稳定性的验证。"
817,基于融合模型的工程项目螺纹钢采购单价预测研究,"目前,我国工程项目建设处于蓬勃发展的阶段,工程项目建设中物资采购是必不可少的环节。而如何有效的控制物资采购成本是项目管理中重点关注的内容。在此背景下,本文对如何精准预测工程项目中使用量最大的螺纹钢的采购单价展开了相关研究。基于预测的结果,以期为采购人员和项目经理实施更优的采购策略提供决策支持,进而降低工程项目的采购成本,优化项目的运营质量。在现有的相关研究中,多数学者关注的是螺纹钢市场价格的预测或是电力、农产品等相关市场价格的预测。然而,组织内部采购螺纹钢的场景和上述问题存在较大差异,例如对市场螺纹钢价格的预测无需考虑供应商供货周期的影响。基于上述分析,为了能够更好的解决组织内部视角的工程项目螺纹钢采购单价预测的问题,本文首先针对研究问题进行了实地调研和相关文献的查阅,分析了相关问题的解决方案(单一模型预测)的优势与不足,引入了集成学习的概念,利用集成学习的思想,通过多个模型的融合提高了螺纹钢采购单价预测的精度。论文的主要研究工作有:(1)构建工程项目螺纹钢采购单价预测指标体系。通过实地调研等相关方法,分析了工程项目物资采购的特点、模式,以及采购过程中存在的问题;引出工程项目螺纹钢采购单价预测的必要性,结合指标体系设计原则,构建了工程项目螺纹钢采购单价预测指标体系,并通过相关特性分析验证了指标体系的合理性。(2)基于机器学习的工程项目螺纹钢采购单价预测模型仿真。基于网格搜索和五折交叉验证完成了随机森林和XGBoost模型的调参工作,并设计了 BP神经网络的结构;实验证明,模型的预测性能均达到了相对比较优的结果。(3)多模型融合的工程项目螺纹钢采购单价预测模型仿真。随机森林、XGBoost和BP神经网络作为融合模型的初级学习器,基于Stacking方法完成三个模型的融合。实验证明,BP神经网络作为融合模型的次级学习器,模型预测的精度提升幅度最大。图25幅,表7个,参考文献64篇。"
818,基于深度学习的一阶目标检测算法应用研究,"目标检测作为机器视觉领域的一个热门的研究方向,在图像内容理解和场景分析任务中发挥着重要作用,是大量高级视觉任务的必要前提。目标检测技术广泛应用于交通道路标识识别、智能安防系统、军事目标侦察监控、医疗手术器械导航等多种数字图像处理领域,为计算机理解当前场景信息制定下一步工作计划提供了可靠的辅助决策。针对不同的目标检测应用场景,所使用的目标检测算法也各不相同,但核心思想都是对目标进行定位和分类,而目标的定位和分类都是通过提取目标特征实现的。目标特征的完备性与有效性很大程度上决定了目标检测的效果好坏,目前利用基于深度学习的目标检测算法可以有效解决目标特征完备性的问题,但目标特征有效性很大程度上受到应用场景的制约,导致现实场景中的目标检测任务往往达不到预期效果。因此,针对解决实际应用问题的目标检测算法研究具有十分重要的理论意义与实践价值。随着观测技术的不断进步,现如今交通、军事、医疗等各领域的图像数据已经出现了数量大、质量高、信息丰富的趋势,依靠人工判读或传统目标检测技术获得的数据处理结果缺乏准确性与时效性,复杂背景下目标检测仍然存在精度低速度慢的问题。为此本文利用基于深度学习的一阶目标检测算法YOLO(You Only Look Once),针对算法在真实场景下的舰船检测与高分辨率遥感图像目标检测产生的问题,提出了一系列提升检测速度精度,降低误检虚警优化方法,有效提高了目标检测模型的准确性与实用性。本文主要研究内容如下:(1)基于深度学习的一阶目标检测算法YOLO及其改进方法研究。本文对YOLO算法及其改进方法进行了比较全面的归纳总结,作为以检测速度著称的算法,YOLO取得了目前最佳的目标检测效果。本文从核心思想、改进方法、模型网络结构及损失函数等角度对算法进行了全方位的介绍与分析,总结了提升目标检测速度与精度的各种优化方法。通过对该目标检测算法的细致研究,不仅为模型改进方式提供了有力的理论支撑,还可以针对实际问题提出合理的解决方案。(2)为了解决目标检测任务中精度低、虚警率高及小目标检测效果差等问题,本文面向航拍数据中的舰船目标检测场景提出了一种基于YOLOv2的舰船目标二级分类算法,并利用自制舰船数据集建立舰船目标检测系统。所提算法针对舰船检测问题提出了一种改进模型,通过引入残差结构加深网络深度提升模型对小目标的检测能力。在该模型基础上利用目标二级分类、模型预训练、候选框维度聚类等多种优化方法提升模型的性能,在降低虚警率、提升目标检测准确度的同时实现了舰船目标实时检测。实验结果表明,在保证检测速度的基础上,所提算法相较于原YOLOv2算法及SSD(Single Shot Multi Box Detector)算法具备更高的检测精度。(3)针对高分辨率遥感图像目标检测速度慢效率低的问题,提出一种基于目标显著性与改进YOLOv3的高分辨率遥感图像目标检测算法。算法首先利用目标显著性模型自适应切割样本数据,滤除了宽视角大尺寸高分辨率遥感图像中无用的背景信息,通过对目标潜在子区域的粗提取,避免了尺度归一化带来的目标分辨率损失。显著性处理过后,算法提出一种基于多尺度预测的目标检测模型针对性的预测图像中的大中小目标,采用不同于原算法的预训练方法增强模型对各分辨率下目标的检测能力。在已有模型的基础上,还使用候选框维度聚类及优化网络训练方式的方法对模型进行了改进,通过候选框维度聚类及多尺度预测等方式能够加快模型收敛速度,有效提升目标的定位精度。所提算法旨在保障检测精度的同时通过减少计算量加快目标检测速度,通过所提算法与其他算法的实验验证对比,结果表明本算法能够在满足较高目标检测精度的条件下快速进行目标检测,具备较好的目标检测能力。"
819,赌博网站的采集与识别系统的设计与实现,"随着互联网的蓬勃发展和网民数量的与日俱增,恶意网站对人们带来的安全威胁也是数不胜数。例如赌博、反动组织、假冒、钓鱼、诈骗等一系列非法网站。为了应对这种恶意行为,传统的方法是通过黑名单的方式来阻止。然而,随着一些新的网络技术的应用,恶意网站的层出不穷使得传统方式难以应对。在恶意网站为其恶意行为引入灵活性的同时,不可避免的引入了一些不同于正常网站的特征。恶意网站识别技术作为网络安全中的核心抵御技术,能有效识别并预防一系列的安全威胁,保护网络使用的安全性、健康性。本文通过对比分析国内外关于恶意网站的研究成果及现状,针对赌博网站领域,选出了本系统适用的赌博网站识别技术。系统的主要功能包括:数据采集模块、数据预处理模块、数据存储模块、数据识别模块。该系统是一个研究性项目,基于公司的数据分析系统,着重研究赌博网站,对主要功能模块做出详细分析,给出用例说明。在监控网站的实时监控前提下,本文将针对各大模块,设计赌博网站数据从采集之后到使用的整体流转过程,最后使得识别数据能够被实时的产出。同时,为了便于维护与二次开发,遵循团队主流技术路线,赌博网站识别系统的实现将基于Linux操作系统,使用Python语言、Scrapy框架进行开发,根据选取的各个机器学习算法中准确率的高低采取适用的机器学习算法进行识别,以完成网页数据的采集、预处理、存储与识别等功能,最终达到可以通过对互联网新涌现出来的网站数据进行统计和分析,可以以一定的准确度对其进行识别,将识别数据持久化,存储于ElasticSearch等存储系统中,为下游所有服务提供优质而全面的数据来源。用于恶意网站分析与一系列安全设备中。赌博网站识别系统目前已经完成并作为一个核心组件实际运行在公司的数据分析系统中,并针对识别准确度在不断完善中,为安全防护提供服务。"
820,基于机器学习的高潜力用户挖掘算法的设计与系统构建,"随着信息时代的潮流席卷而来,硬件设备和软件技术也飞速发展,从前在线下交易的大量数据如今已经能够存储在线上服务器中高效的进行存取处理和查询。通过及时和精确地分析大量用户基础数据和行为数据,挖掘用户行为模式得到的有用信息和知识,支撑着商业化服务的推进和完善。其中用户画像作为描绘目标用户,关联用户诉求与产品设计的重要工具,已经在各个行业和领域得到了广泛的应用,本文以网约车行业为背景,为了解决跨业务线的高潜力用户挖掘问题,针对不同业务线的用户进行画像,根据用户历史行为模式,判断未来的发展趋势。利用用户的基本信息和行为信息,抽象成特征,探索了普通的机器学习算法、深度学习与迁移学习三种模型在本问题上的表现及性能,并且结合人群画像分析系统的设计与实现,令模型产出的用户标签可以系统的、可视化的展示给公司内部成员。实验证明这几种方法可以准确的判断出高潜力用户群体,使得企业可以有针对性的做营销活动,有效地降低了推广宣传的成本,提升了投资回收率。本文主要工作内容和创新点如下:1)在XGBoost模型中,本文提出了一种利用woe值来编码非数值特征并且划分等级的特征处理方法,将稀疏且不定长的非数值特征对应到固定个数个等级中,生成新的map类型的特征,实验结果表明这种非数值特征处理方法对模型的效果有明显促进作用,且模型已上线,成为筛选高质量人群的有力工具。2)在神经网络实验中,本文利用深层神经网络(DeepNeuron Network,DNN)以及深度交叉网络(Deep&CrossNetwork,DCN)进行实验对比,不断调整网络结构以及所选取特征直至最优。3)本文采取基于特征的迁移学习方法与基于参数的迁移方法,提出迁移深度交叉网络(Transfer-Deep&CrossNetwork,TDCN),预训练几个稀疏的类别型的特征,将嵌入矩阵参数更新至最优,将权重矩阵及嵌入矩阵迁移到深度交叉网络中,分别尝试了 frozen和fine-tuning权重矩阵参数的方式进行训练,实验表明采用预训练过的特征继续微调比普通的神经网络的ROC曲线下面积(Area Under roc Curve,AUC)提高了百分之三。4)参与人群画像分析系统的设计与实现,助力精准营销与数据分析,且该系统已在公司内部成功上线。"
821,分布式光纤振动传感系统模式识别方法研究,"相位敏感光时域反射计(Phase-Sensitive Optical Time Domain Reflectometer,(37)OTDR-)是分布式光纤振动传感系统的一种典型结构,以光纤作为传感传输媒介,具有结构简单、使用方便、测量范围广泛以及抗干扰等优势,在现代人工智能测量领域扮演越来越重要的角色。随着现代人工智能领域不断发展,仅仅对振动信号进行测量和定位已经无法满足实际需求,在确定振动事件发生的同时,还需要确定振动信号类型以及判断振动起因。因此,需要开展对相位敏感振动信号进行模式识别方法研究。本学位论文针对(37)OTDR-分布式光纤传感系统模式识别方法进行研究,主要包括振动信号的特征获取和振动信号分类,对不同的算法进行对比、研究及改进,达到提高准确率、降低误报率的目的。本学位论文主要完成的研究工作如下:1.本文系统地介绍了分布式光纤振动传感系统,包括研究现状及现有的系统结构,OTDR理论模型的构建及仿真。主要介绍目前模式识别达到的研究水平及主要的研究方法,阐述目前方法存在的问题。2.本文详细地阐述了振动信号处理流程,包括解调、定位、特征提取及特征工程。其中针对振动信号的特点,提出一种希尔伯特变换(Hilbert)结合改进的经验模态分解(Modified Ensemble Empirical Mode Decomposition,MEEMD)的特征提取方法,并分别仿真、模拟实验对比了经验模态分解(Empirical Mode Decomposition,EMD)和互补经验模态分解(Complementary Ensemble Empirical Mode Decomposition,CEEMD)方法。通过对比,可以得出MEEMD分解方式在信号特征提取方面耗时短,相对于CEEMD,节省3.1363s,准确率高,重构误差最小。3.本文以MEEMD方法为主,结合时域、能量域等方法,对无振动信号、人走路、振动隔离网、重物坠落以及小车通过等事件进行实验分析。在已知振动信号的类型的情况下重复实验,获得3000组振动信号的特征向量组,包含振动事件的振动信息,作为事件类型的特征输入。4.本文针对分布式光纤传感系统的灵敏度高、误报率高的特点,采用一种二级分类器设计。通过支持向量机(Support Vector Machine,SVM)分类方法进行一级分类,区分环境干扰及人为干扰;根据人工智能中的机器学习算法,采用集成学习算法作为第二级分类器,进行随机森林和梯度增强决策树(Gradient Boosting Decision Tree,GBDT)两种分类器设计,通过调节分类器参数,确定分类器模型,并对比不同模式识别模型准确率,在工程应用中,针对不同的应用场景需求,灵活选取。5.本文搭建实验环境,采集环境、振动信号作为实验数据,经过特征提取方法获得3000组振动特征向量,将其中的80%数据作为训练样本数据,20%作为测试样本数据,通过交叉验证的方式,对分类器参数进行调优,获得分类器模型。对未知振动信号进行模型检测,两种分类器的准确率在相同样本数据的情况下,均达到97%以上。"
822,基于采样理论的机器学习方法研究,"采样理论是多个学科的基础理论。通过采样方法,不仅可以获得精确推断不可行条件下的近似解,还可以基于采样方法,加速计算。大数据场景下,采样方法得到更加广泛的应用。数据不平衡问题是机器学习领域的经典问题,基于数据层面的解决思路包括数据过采样和欠采样方法。数据驱动的模型在面临真实场景下的问题时,会遇到更多的数据不平衡问题。本文的主要研究工作如下:研究数据不平衡问题对机器学习中分类模型评估指标的影响,借助可视化手段,通过实验证明分析数据不平衡问题会对模型学习带来负面作用。针对从数据层面解决数据不平衡学习问题的两种思路,过采样方法和欠采样方法,分别从理论分析和对比实验角度证明采样方法的有效性,为后续研究工作打下理论和实验基础。已经有相关研究将演化思想引入采样算法中,并结合Lévy分布提出了自适应的采样算法,本文改进了基于Lévy分布的演化采样算法,通过增加该分布α值的选择,使得候选样本的选取不会局限于极端情况,从而实现更加高效地选择。理论分析和实验表明,改进算法在收敛速率和精度上优于基于高斯分布,柯西分布,对称指数分布的演化采样算法和其他自适应的演化采样算法。针对不平衡数据集上的采样问题,在深入分析基于Lévy分布的过采样方法的基础上,认为样本比例生成函数的选择并不一定必须是Lévy分布,因此提出基于高斯分布和分段分布的数据过采样方法。其核心思想是通过构造类Lévy分布的样本比例生成函数,使得从边界样本合成的新样本密度最大,靠近多数类的样本合成的新样本密度次之,靠近少数类的样本合成的新样本密度最小。因此,该算法可以达到增强分类边界的同时减小噪声生成的目的。通过在多个数据集上的实验,表明所提算法的有效性。"
823,基于双因素模型的投资组合研究,"决策树算法、随机森林和支持向量机模型是机器学习的细化分支领域,多年来深受各个学者、券商专业团队的喜爱,将其应用在量化投资领域。在此背景下,因子的构建和对于股票走势的判断,是这一领域专家学者不断追寻的话题。本文则希望通过研究和借鉴各个已有的文章的指标体系,结合相关机器学习算法,在此基础上进行创新和突破。本文把选股过程根据基本面指标和技术面指标的不同性质,将选股过程划分为两个阶段,以基本面指标判断上市公司长期状态和技术面指标判断买卖时机选择的理念进行本文投资组合的研究工作。首先,本文在第一章节阐述选题的背景与意义、相关文献综述、研究对象与研究工具;第二章节基于双因素模型的投资组合构造,围绕文中双因素模型投资组合策略构建思路进行展开,对本文提出的双因素模型进行具体介绍;第三章节内容围绕本文提出的双因素模型策略的第一个因素(阶段)即基本面因素进行实证研究;第四章节是对上节内容的优化和提升,在上节选出目标上市公司的基础上加入技术面因素(阶段),利用机器学习方法提升选股策略的效果;第五章节,对本文的研究内容结合具体实证情况进行总结。其次,本文将因子分析方法和决策树、随机森林、支持向量机方法分别应用在基本面选股和技术面选股(择时)两个阶段。结果显示:根据动态支持向量机模型实施后的交易策略能够获得较中证800指数3.29倍的期间累积收益和较全指消费指数3倍的期间累积收益,对应的期间累积收益率为106%。较之前仅由基本面选股,半年期间买入持有的等份额投资组合23.5%的累积收益率有大幅度的提升,前者的收益率相当于后者的4.51倍。除此之外,经过技术指标建模构造的投资组合在资金风险方面也较未经优化的模型有更好的表现。最后,本文基于2018年上半年度股票行情数据,从基本面角度在主要消费行业进行股票标的筛选,运用技术面指标对经由筛选后得出的股票标的涨跌情况进行逐日预测并根据预测结果进行相应的买卖操作,从而构建在期间的投资组合。对于完善选股投资策略的多样性有重要指导意义。"
824,基于移动处理器的性能数据挖掘与算法优化关键技术研究,"越来越多的大数据任务与算法运行在计算资源有限的移动平台。然而,如何刻画这些任务在移动处理器上运行时的处理器性能特征以及利用处理器性能特征优化大数据算法面临着诸多挑战。ARM移动处理器的性能监控单元提供了若干硬件计数器,用于计数时钟周期级别的发生在处理器或内存系统操作的指定微体系结构事件。随着程序的执行,这些硬件计数器会产生大量监控数据,称为性能大数据。性能大数据的用途非常广泛:刻画任务负载、分析程序性能瓶颈、以及微体系结构优化等等。但是,从性能大数据出发刻画在移动处理器上运行大数据任务时的处理器性能特征并利用性能特征优化大数据算法存在诸多挑战,主要可归纳为:1)数据维数高。性能大数据的维数往往高达几十上百甚至上千,在分析性能大数据的过程中,通常是凭借经验观察其中某些维度的数据,或利用这些维度的数据建立统计学习模型。这些方法无法全面地刻画任务特征。2)数据信息大。大数据任务产生的性能特征各不相同,硬件计数器得到的事件信息量大,难以理解。因此,本文提出了一种基于移动处理器性能数据挖掘框架MobilePerfMiner。使用硬件计数器,通过迭代使用XGBoost算法构建性能模型,为大数据任务的微体系结构事件进行重要性排序,降低性能大数据维度。从而根据刻画的性能特征优化大数据算法。本文的贡献有以下几点:1、性能大数据预处理。整合分散的数据,读性能大数据进行拼接,归一化,结构化等操作。2、性能大数据降维。使用XGBoost算法迭代约简性能大数据的维度,得到微体系结构事件的特征重要性排序。3、刻画处理器性能特征。根据硬件事件的排序,得到重要的微体系结构事件,由此刻画运行大数据任务的处理器性能特征。本文使用硬件计数器监控处理器支持的62个微体系结构事件。对18个Spark大数据基准测试程序作测试。分析了在移动处理器上运行Spark基准测试程序的性能特征。再利用这些性能特征,优化了的程序的性能。实验结果表明:1)降维后的性能大数据更能够准确地刻画性能特征,大数据任务的性能特征有共性与个性表现。2)基于重要性排序的微体系结构事件的Spark参数调优方面,对于针对指令特征调优Spark程序节约了36%的程序执行时间;对于内存系统特征平均节约了37%的运行时间;另外还对数据序列化配置参数进行调优,平均节约了21%的程序执行时间。"
825,面向缺陷挖掘的代码表示学习,"软件缺陷挖掘是利用机器学习和数据挖掘技术来挖掘现有软件系统代码中存在的缺陷,代码表示学习是其中的一个关键问题。目前在该领域已存在很多关于代码表示学习的研究。但是这些方法都依赖大量的缺陷数据来学习代码表示,忽略了实际中缺陷数据通常严重不足的现状;并且它们旨在研究如何对静态代码进行建模,尚未有合理的模型可以刻画动态代码的特征,所以难以识别因代码改动而引入的缺陷。针对以上现状,本文从面向静态代码和动态代码的缺陷挖掘两个方面,分别对代码的表示学习进行研究,主要创新如下:1.在面向静态代码的缺陷挖掘中,本文提出一种基于代码功能表示学习的模型重用框架,有效缓解了特定任务中训练数据不足的困难。我们首先从开源的软件仓库中收集大量的免费代码和文本注释资源训练一个通用的代码功能表示模型,接着通过模型迁移的方法将此模型适用到不同的软件缺陷挖掘任务中。我们从直接回归学习和对抗学习两个角度分别构建了具有文本语义增强的代码表示模型RUM和RAM。在不同缺陷挖掘任务中的实验结果显示,相比于从头开始训练模型,重用RUM和RAM到当前的模型所获得的性能具有显著的提升,尤其是当训练数据不足时。2.与静态代码不同,动态代码中不仅包含有代码部分,还包括了一些动态修改过程的标志符。在面向动态代码的缺陷挖掘过程中,基于改动前后差异的特征成为判断是否引入缺陷的重要因素。针对动态代码的特性,本文提出一种基于多示例学习的模型结构来捕捉动态差异特征,并成功构建了一个用于自动判断代码改动是否在集成前被接受的代码评审模型DeepReview。在真实数据集上的实验结果显示,DeepReview在自动代码评审任务中相比于传统特征方法和最先进的方法都取得更好的效果。"
826,基于成长规律的杰出学者预测研究,"杰出学者是科研人员中的佼佼者,是社会进步和国家发展的推动者。目前,随着科学技术逐渐受到世界各国的重视,学者的数量也与日俱增,然而,重要的科学成果往往是由少数学者发现并创作,因此如何在海量的学者中发现杰出学者成为人们关注的焦点。研究学者的成长过程并从中发现规律是尽早发现杰出学者的重要途径。学者在成长为杰出学者的过程中,以自身的先天素质为基础与外界的环境、物质相互作用,形成自身的能力,并通过科学创造活动得到社会的认可。这一过程存在大量共同特性可以为预测杰出学者提供研究基础。因此,本文以中国科学院院士作为我国杰出学者的代表,从个人属性和学术属性特征两个方面研究杰出学者成长过程中的规律,然后提取相应的指标构建杰出学者预测模型,为学者评价、人才培养以及科研管理决策工作提供参考。本文的研究内容主要分为两个方面:杰出学者成长规律研究和杰出学者预测模型构建。首先,对杰出学者成长规律进行研究,主要从两个方面入手:一方面,学者的个人属性:年龄、性别、籍贯、教育经历、工作经历、担任行政职务情况以及获奖情况;另一方面,学者的学术属性:科研合作情况、论文影响力情况、个人影响力情况。经过统计分析总结出以院士为代表的杰出学者成长规律:(1)成长周期较长,是典型的“大器晚成”式人才;(2)人才自身的努力可以弥补本科阶段缺少重点高校优质教育的不足,但在研究生阶段,重点高校、优秀科研院所以及出国进修是其成才过程中不可缺少的平台;(3)工作环境较稳定,同时,工作流动频次与院士成长周期呈负相关;(4)成长过程中存在马太效应,65.3%的学者是在当选院士前后5年的时间内获得了国家级科学技术奖;(5)院士评选对SCI论文相关的产量质量指标越来越重视,且论文的产量与其能否成为院士的相关性不大,影响力以及质和量相结合的指标是判断其能否成为院士的重要指标;(6)科研合作是其学术成长过程中的普遍现象,合著人数在6-8人时,SCI论文的产量和影响力是最高,此时团队中每位科研人员的能力都得到了最大程度的发挥。其次,构建杰出学者预测模型。通过对以院士为代表的杰出学者的成长规律研究,初步构建预测模型的指标体系;然后经过特征筛选发现,性别、合作度、籍贯、最高院校性质以及分类别的行政职务特征与目标变量的相关性较低,因此进行剔除和合并处理,得到作为模型输入的13个指标;其次,利用三种机器学习算法构建预测模型,通过对测试集的预测,发现基于SVM算法建立的杰出学者预测模型较其他两种模型而言效果更优;最后,为验证杰出学者预测模型在现实场景中的应用效果,使用构建的模型预测院士候选人,发现三种预测模型的最高准确率均达到了 60%以上,与现有相似研究对比得出本文构建的预测模型的准确率在可接受的范围内。"
827,基于用户选路行为偏好学习系统的研究与实现,"在日常交通环境中,用户的出行、选路等行为偏好将直接影响交通环境的状态变化,进而影响智能交通系统的管控决策;同时,交通环境的变化也会对用户选路决策产生影响。因此,对用户选路行为偏好的学习,对提高交通调度和出行规划的准确度和有效性具有重要作用。目前,交通数据中包含大量的出行轨迹信息,通过对这些数据进行挖掘分析,可以挖掘用户出行的偏好,为车联网服务、智慧交通管控等提供依据。针对车辆轨迹数据存在的时空分布不均导致的目标用户行为模式识别困难问题,论文提出了一种基于生成对抗网络的选路偏好对抗生成方法,基于交通态势数据和用户历史行为数据,通过深度学习网络提取特征图,以挖掘目标用户的行为特征,并将宏观态势特征和微观用户行为特征融合,结合基于最大信息熵的生成对抗学习算法提升模型的鲁棒性。最终通过基于选路聚合的态势预测方法,将用户选路偏好的因素融入交通态势的预测中,提升态势预测的性能。在论文提出的基于生成对抗的用户选路行为偏好学习方法基础上,结合选路偏好学习系统的功能需求,论文进行了详尽的需求分析,然后依据需求分析对系统的总体框架进行了构建,对各个模块的静态功能和动态交互进行了详细设计,并给出了关键实现流程说明。最后,对系统的功能实现进行了测试,验证了系统的有效性。"
828,基于多任务学习的交通结构挖掘模型研究与实现,"城市交通结构组成作为城市交通调度和个体出行重要的参考依据,是当下以及未来更好地实现智能交通系统的重要前提。本课题在已有的交通结构挖掘相关模型和理论的研究基础上,围绕着其存在的不足:(1)以城市整体为研究对象,强调城市交通宏观政策的影响;(2)基于传统机器学习,依赖于大量的轨迹数量,不能充分利用数据信息,产生信息的浪费或者无关信息的冗余;(3)针对某一特定空间的交通结构的挖掘,往往因为空间范围小,轨迹数量少而被忽视等,基于多任务学习思想,提出适用于不同场景,具有不同结构的挖掘模型。主要研究内容如下。一、综述了与交通结构组成分析相关的基础理论和关键技术,对现有的研究模型进行了说明和总结,分析了其中存在的不足,提出了本课题基于介观层面的交通结构挖掘的研究思路和具体框架。二、考虑对城市空间划分颗粒度粗,研究空间范围大,人群出行数据轨迹量相对充足的现实场景,或是不指定某一特定区域,旨在揭示基于用户的相关特征属性对交通结构分布的影响时,本课题将传统的机器学习与多任务学习思想相结合,利用特征之间存在的图结构的相关关系,构造基于特征相关性的模型,提出了城市粗粒度划分空间下的交通结构挖掘模型,实现充分利用数据,避免了不必要的信息浪费和冗余信息的干扰,并与经典的多元逻辑回归模型进行对比分析。三、为应用于空间范围小,数据轨迹量小,区域划分颗粒度细下的交通结构组成挖掘与分析,实现对特定区域更精确和个性化地分析,以迁移学习和多任务学习为指导思想,利用多个特定区域之间的地理位置相邻性,以及几种交通出行方式之间的相关性等特点,分别针对现实应用场景中简单空间环境和复杂空间环境下的特定区域,提出二维层面上的基于共享矩阵结构和三维层面上的基于高阶张量结构的挖掘模型,并与传统机器学习模型展开对比分析,为交通结构组成的分析和研究提出了新的解决思路。"
829,基于数据挖掘技术的用户异常用电检测系统的研究与实现,"随着电网的快速普及,居民在享受用电便利的同时,供电企业线路损失率居高不下,导致了企业供电成本的提升。而用户的异常用电行为往往就是供电企业线路损失率居高不下的主要原因,严重影响企业的正常运营秩序。在电网信息化程度不断提高的今天,正确的利用信息化电网所提供的海量数据,从大量的用电信息中挖掘有价值的信息用于解决异常用电行为的检测成为了一个热门的研究领域。本文提出了一种基于时间维度和主成分分析法的异常用电检测模型。模型包括数据预处理、基于时间维度的特征构造、主成分分析、xgboost、GBDT、随机森林模型融合这几个部分。然后根据融合的算法模型对异常用电识别系统进行设计与实现。对比传统的机器学习方法模型,本项目着重于通过原始用电负荷数据构造不同时间维度的特征来表征用户用电行为。之后再采用主成分分析法对高维度的特征进行降维,使得最后用于训练的特征都具有不同方面的代表性。在模型的选择方面也不再使用传统的单一模型进行训练,取而代之的是一个融合模型。在模型算法的验证阶段,本文通过使用中国电网提供的真实用电负荷数据做测试,综合三个单一模型的评估结果,及对比本文所采用的融合模型的结果发现,经过融合后的模型检测异常用电用户的能力明显高于三个单一的模型。而且无论是对于异常用电用户还是正常用户的检测其准确度都是较高的,本课题采用模型融合的方法有效的提高了异常用电用户的检测能力。在算法研究的同时,本文还设计实现了用户异常用电检测系统,系统实现了数据预处理、特征构造、模型训练、模型检测结果展示、用户管理等功能,能较好的识别异常用电用户并展示用电行为特征。"
830,蒙古语文本自动分类研究,"随着蒙古语信息技术的发展和蒙语文编码国际标准的公布,蒙古语电子文本数量日益增多,依靠人工处理这些海量文本费时费力。针对这种情形,本研究创建了基于贝叶斯、支持向量机和神经网络等有监督学习方法的文本分类系统,并对这些算法的分类性能进行了比较。本文由绪论、正文及总结等部分组成。绪论部分介绍了选题依据及研究意义、研究概况、研究数据与研究步骤等内容。第一章说明了去噪、词元化、去除停用词和特征选择等相关的文本预处理方面的工作。第二章论述了关于贝叶斯算法的原理和本研究中实施的基于贝叶斯算法的蒙古语文本自动分类实验。第三章论述了支持向量机算法的原理和本研究中实施的基于支持向量机算法的蒙古语文本自动分类实验。第四章论述了神经网络算法的原理及本研究所运用的网络模型结构,并介绍了本研究中实施的基于神经网络算法的蒙古语文本自动分类实验。结论部分总结了全部研究过程及三个有监督机器学习方法的运行结果,并提出了今后需要改进的工作。"
831,用于警情信息分析的实体识别系统的研究与实现,"警情案件具有一定的相似性、可预测性。通过历史的警情信息分析,可以完成警情案件的串并,用以加速破案和防范犯罪。在过去,民警记录警情信息的方式是通过纸质书写的方式记录到特定的档案中,最后将不同的案件进行归档。而现在,民警能够利用在线的警情管理系统完成警情案件的记录与检索。虽然警情信息管理系统极大地提高了记录与检索的效率,但是,仅仅记录警情事件的描述无法有效的完成警情信息的分析,还需要综合警情中报案人、案发地点、涉及到的组织机构等信息进行多维度的分析。基于以上背景,本文从警情信息分析的角度入手,对如何提取警情信息中的有效实体信息进行了研究,设计并实现了一个用于警情信息分析的实体识别系统。本文以警情信息的分析作为目标,对警情信息中有利于案件分析的有效实体进行了研究,并提出了适用于警情信息的实体识别方法。本文对条件随机场与深度神经网络结合条件随机场两种方法进行了实验与对比,两种方法均取得了较高的准确率、召回率和F1值,但从各个类别及整体的评估结果来看,得出了基于深度学习的方法确实优于传统模型的结论。本文完成的主要工作有:第一,对系统中用到的相关技术和算法进行了介绍,包括词的表示、概率图模型、神经网络等理论基础。第二,通过对警情信息的分析,对提取的警情地点进行了细分,并完成了警情实体识别模型搭建的任务。第三,对系统的功能性需求和非功能性需求进行了分析,根据需求分析的结果对系统的层次架构和功能模块进行了设计,并完成了数据库相关设计。最后,给出了系统主要功能模块的具体实现,并对系统的运行界面进行了展示。本文所完成的警情实体识别模型经过测试,已部署至项目合作方的内部系统中。在半年的使用过程中,模型运行良好,识别度高,对方表示赞赏,证明了本模型的有效性。"
832,电信诈骗语义模式抽取系统的设计与实现,"近年来,电信诈骗案件越来越频繁,犯罪分子的作案手段越来越高明,电信诈骗的通信内容越来越复杂多变,导致人民财产蒙受巨大损失。但由于电信诈骗在海量通信记录中仍属于小概率事件,导致诈骗内容占比低、样本少。再加上诈骗分子刻意在通信内容中使用近义词、相关词、非正常语序等手段,规避电信诈骗筛查,进一步加大了使用传统手段进行电信诈骗内容训练和识别的难度。在充分考虑电信诈骗特点的基础上,本论文提出了一种电信诈骗语义模式模型,该模型根据电信诈骗的场景和目标构建语义模式,并通过电信诈骗语义模式抽取原始通信内容的关键信息,从而去除冗余信息,提炼关键内容,解决电信诈骗内容的复杂多变问题。同时,考虑到电信诈骗内容的小概率性,论文建立了疑似诈骗粗筛选模型,通过对原始通信内容进行初步筛选,降低正常通信内容对电信诈骗语义模式识别的干扰,同时应对诈骗内容占比低带来的全量内容信息处理的低效率问题。本论文提出的语义模式模型为后续的电信诈骗识别语义分类提供了高效的判别依据。论文首先阐述了文本分类与序列标注等电信诈骗语义模式抽取相关技术,随后对电信诈骗语义模式抽取系统进行详细的需求分析,并按照需求分析结果确定系统中各个功能模块,对疑似诈骗粗筛算法和语义模式抽取算法进行了详细设计。接下来,论文对系统进行了详细设计与实现,包括系统的数据结构设计、接口设计、交互流程设计、各模块类定义,并详细阐述了各模块的关键实现流程。最后,论文通过系统测试用例以及测试结果分析,验证了电信诈骗语义模式抽取系统的可行性,且系统的设计与实现符合功能需求。"
833,基于SDN的应用感知多路径网络资源分配系统,"物联网技术的发展使“万物互联”逐渐从一个美好的技术愿景变成现实。海量的传感设备互联互通给传统网络架构提出了新的挑战。一是IoT网络设备繁多,承载的应用各不相同,不同的网络应用对网络资源的需求各异。二是网络的异构问题,不同的接入方式意味着网络的链路状态各不相同,并且时刻都在变化。要在如此复杂的网络情况下进行进行网络资源的智能化调度需要解决两个问题:一是实现应用类型感知,即通过某种方式确定当前应用的网络资源需求;二是网络资源规划,即结合当前网络资源状态为应用分配满足其需求的网络资源。针对问题一,传统流量工程中使用的方法主要包括:依据端口等数据报头信息的流量识别技术,采用DPI技术流量识别,基于协议行为模式的流量识别技术。本文深入调研了传统的流量识别方法的所面临的局限性并提出了一种基于机器学习技术的流量识别算法,通过选取适当的流量特征解决了传统识别算法所遇到的问题。针对问题二,本文利用了SDN控制与转发相分离的特点,在控制平面实现了基于流量类型和当前网络资源状态的多路径流量调度算法。在系统架构层面,本文使用NFV技术解决了SDN架构中的流量采样问题,NFV技术的引入将流量识别功能和网络资源调度算法进一步解耦,提高了系统的鲁棒性。实验测试结果表明,系统中的流量分类模型能够达到91.10%的识别准确率。相比其他传统的调度策略,本文提出的基于SDN的应用感知多路径网络资源调度系统能够充分利用网络中的多路径传输资源,保障不同业务的个性化资源需求。"
834,基于信息抽取的物联网能力知识图谱构建方法研究与实现,"物联网能力知识图谱(Internet of Things Capability Knowledge Graph,IoTCKG)融合了知识图谱和物联网的特点,通过抽取物联网的功能及其之间的关系,构建物联网功能的知识图谱,将物联网中的服务结构化,为服务添加语义性信息,是比传统的物联网物体知识图谱粒度更细的描述方式,目的是解决物联网的描述问题,可用于异构物联网平台的融合、服务发现和推荐系统等。由于异构的物联网标准和描述不利于领域的融合和进一步的创新,近年来,传统的物联网(Internet ofThings,IoT)向新兴的WoT(Web of Things)过渡,解决了物联网的部分问题,但大多是构建物联网物体知识图谱,描述粒度相对较大,不能满足物体功能的动态性改变和更高层次的应用需求。基于此背景,本课题创新知识图谱的组成方式,通过构造物联网能力知识图谱,将传统的“物体-关系-属性”的粒度细化为“能力-关系-能力”的物联网能力知识图谱来描述物联网中物体的功能及其之间的关系,同时增加了物联网的语义。为此,本文做了以下方面的具体研究和工作:一、研究描述物联网存在的问题和独有特点,提出了利用物联网能力知识图谱解决这些问题的方案,在此基础上提出了一整套构造物联网能力知识图谱的解决方案。二、研究如何从语料中抽取能力知识词汇,根据物联网特点提出BiLSTM模型,用于从分词后的语料中获取相应的目标能力词汇,为构建知识图谱提供节点数据。三、研究如何从标注好能力词对的语句中抽取关系,研究了监督型和半监督的信息抽取。在监督型领域中,提出了BiLSTM-CNN模型,融合了LSTM和CNN的优点。在半监督领域中,提出了RETAG模型,能够获取更多能力词汇信息,获得更好的关系抽取结果。"
835,基于神经网络的实体识别和关系抽取的联合模型研究,"随着信息时代的到来,网络上的信息越来越呈现出指数形式爆发增长的态势,在这其中,文本信息占据了相当重要的组成部分,如何准确高效的获取知识成为亟待解决的问题。实体识别和关系抽取的联合模型的主要目标是同时从非结构化的文本中抽取实体类别和它们之间的语义关系。作为自然语言处理技术的底层技术,对于上层的应用有着显著的意义。本文围绕着实体识别和关系抽取的联合模型进行了深入的研究,主要工作内容和阶段成果如下:(1)复现了基于神经网络的实体识别和关系抽取的联合模型基线系统,并对当前模型可能存在的问题进行了讨论。(2)提出了一种基于参数共享的双向长短期记忆网络-图卷积神经网络的混合神经网络结构。模型通过引入句法的图卷积神经网络,用于更好的抽取句子中的关系。在公开数据集上,这个联合模型取得了相较之前工作更好的性能。(3)提出了一种基于特殊标注策略的融合自注意力机制的联合模型,将信息抽取任务转化为序列标注任务,通过自注意力子层学习句子内部的词依赖关系,在公开数据集上也取得了较好的表现。(4)初步搭建了基于实体识别关系抽取联合模型的知识图谱构建系统,实现了从非结构化文本中抽取三元组的解决方案。"
836,基于图像模式的Android恶意应用检测系统研究与实现,"移动互联网的蓬勃发展不仅方便了人们的现实生活和通讯,同时也极大引发了恶意软件在移动系统的泛滥。恶意软件利用Android系统的设计缺陷和漏洞,以及恶意代码复用技术,能够短时间内生成海量恶意样本,而已有的检测技术大多存在分析时间长、特征提取单一以及无法对混淆应用保持弹性的缺点。为了可以更加高效准确的检测恶意应用,本文结合图像纹理特征、Dalvik指令序列特征以及机器学习多种方法,提出了基于图像模式的恶意应用检测技术。本文主要工作如下:(1)提出了一种基于AndroidManifest.xml清单文件和DEX字节码文件的灰度图像生成算法检测Android恶意应用。针对传统检测方案特征提取粗略单一、特征处理效率较低的问题,本文结合清单文件和字节码文件来生成灰度图像,然后通过多种纹理特征提取算法提取图像纹理局部和全局特征,并采用直方图均衡化等算法优化图像。实验证明,该方法能够有效全面的提取应用特征,并提高特征提取速度。(2)提出一种简化分类Dalvik指令集并且使用形式化指令符号替代Dalvik指令,以及使用SimHash算法生成Dalvik指令符号序列特征向量的特征提取方案。通过结合纹理特征和文本特征,能够精确的匹配恶意应用的行为模式和空间排列模式,有效提高检测方案的检测能力。(3)设计并实现了Android恶意应用检测系统,并使用多种技术比如消息中间件技术、大数据技术等提高系统的计算和存储能力。该系统以在线APK检测平台为场景需求,分为用户交互层、Web Server层、Redis集群层和分布式集群层,能够成功实现在线分析应用的功能。最后对该系统进行了一定的系统测试,以此验证系统的有效性、健壮性和安全性。"
837,基于深度学习的情感分类系统的研究与实现,"随着互联网和Web2.0的日益发展,用户生成内容(User Generated Content,UGC)层出不穷,UGC往往包含了用户的情感喜好和主观意见,针对UGC的情感分析任务逐渐体现出巨大的学术意义和商业价值。基于此,本文针对UGC的情感分类问题进行了研究与实现。本文主要针对UGC短文本进行情感分析研究,通过考察UGC短文本情感分析的国内外研究现状,并结合当前机器学习和深度学习领域的前沿技术,对深度学习模型的可解释性进行了探索,目标是通过句子的情感分类来提取句子中词语的情感信息,并提高UGC短文本的情感分类准确率。本文所做的工作主要包含以下几个部分:(1)本文在卷积神经网络(CNN)的基础上,提出了“词粒度CNN”情感模型,增加了词粒度情感倾向的计算,并通过实验验证了该模型的有效性,同时对词粒度CNN模型提取的情感词实现了可视化。(2)本文分析并研究了UGC短文本的特点,在神经词袋模型(NBOW)的基础上,提出了基于N-gram的神经词袋模型(NBOWN)。同时,针对引入N-gram导致NBOWN模型存在特征稀疏性的问题,本文提出了“Gram注意力机制”进行了模型优化,并根据文本中每一个特征对句子情感类别的权重影响,实现了词语对句子情感重要性的可视化。实验证明结合Gram注意力机制的NBOWN模型在UGC短文本的情感分析任务中具有较好的分类效果。(3)基于word2vec学习得到的词向量不包含情感信息,本文通过有监督学习方法为只含语义信息的词向量赋予了情感信息,实现了包含情感信息的词向量的正确分离。(4)本文通过使用词粒度CNN和NBOWN模型进行集成学习,得到了词语和句子的情感信息,同时设计并实现了基于CNN和NBOWN的情感分析原型系统,该系统不依靠人工总结的情感知识,可自动对输入的语句进行句子和词语级别的情感分析。"
838,基于深度学习的文本情绪原因发现方法的研究与实现,"随着互联网的飞速发展,人们越来越多地在网络媒体上阐述自己的观点,并表达自己的情绪。在这种背景之下,互联网中包含情绪倾向和观点倾向的文本数据呈现爆炸性的增长。这些文本信息具有非凡的价值,它经常包括发表人的情绪和观点,有助于人们从中提取每一个人的兴趣点与关注点。近年来,人们经常会从文本中的情感信息用于进行决策。近年来,人们还开始利用文本中的情感信息,提取情绪发生的原因。情绪原因提取主要目标使从文本中识别某种情绪表达背后的原因。本文主要研究并实现基于深度学习的情绪原因发现方法。通过深度学习的方法建立情感词与文本中的句子之间的关系,并以此识别文本中的情绪原因。在以往的研究中,基于深度学习的方法通常是去准确地获取情感词与文本中句子之间的语义相关性,并依此来识别文本中的情感原因。本文主要分为四方面内容:(1)针对目前情绪原因发现问题的语料较小,若采用一些相对复杂的深度网络,往往容易过拟合。本文采用了一种新的情绪原因半自动标注方法,扩充了一倍的数据集,并利用目前Gui提出的基于记忆网络的深度模型验证了数据有效性。(2)针对目前情绪原因发现方法只采用了互注意力机制,只考虑了情感词与文本子句之间的关系而没有考虑句子本身,除此之外,以往的模型都尚未考虑注意力权重剪枝,这就导致模型仍会保留不相关的文本,产生噪声。因此本文提出了 CAES网络,在深度模型中结合互注意力机制和自注意力机制,并利用了k-max方式对注意力权重进行剪枝。这个网络在新的实验数据集上获得了0.701的F值。(3)针对目前已有研究的建模方式,大都采用了直接分类的方式进行建模,本文提出了一种新的建模方式,把情绪原因发现方法当成一个排序问题,并利用pairwise rank方式进行建模,并利用了CAES网络的思想,构建了 ABSCNN网络,这个网络在实验数据集上获得了0.7116的F值。(4)设计并实现情绪原因发现原型系统,把本文的算法集成到原型系统当中。"
839,基于强化学习的P2P网络借贷机构风险评估技术研究与实现,"近年来,P2P网络借贷在中国发展迅速,我国P2P网贷规模已经成为世界第一,P2P网络借贷为民众和投资者均带来了便利,然而,随着P2P借贷机构的快速发展,这些机构的风险也逐渐暴露出来,主要表现为停业、提现困难和跑路三种形式。这些风险通常会导致投资人产生或大或小的损失,同时给社会带来不良影响,因此实现对企业风险的自动评估是十分必要的。虽然使用机器学习的方法可以实现对P2P网贷企业风险的自动评估,然而大多数机器学习方法对数据质量的要求较高,而目前P2P行业能够获取的数据量较小且各类风险类型的数据分布比较不平均。因此,为了解决P2P网贷机构数据规模较小且各类数据不平衡的问题,本文引入了强化学习模型。通过对多种强化学习算法的研究与分析,本文提出了一种基于强化学习的P2P网络借贷机构风险评估方法,该方法将风险评估任务看作是文本分类的一种。然而,现存的强化学习模型通常训练时间较长,十分耗时,因此,本文提出了一种改进的强化学习模型,利用经验回放及优先采样的思想,通过动态更新样本权重来加速模型的训练过程。基于以上技术研究,本文提出了基于强化学习的P2P网贷企业风险评估方法研究框架,详细介绍了预处理、文本特征表示、强化学习基线模型构建、风险评估及模型训练改进四个过程。之后通过实验验证模型的有效性。实验结果显示,本文提出的强化学习模型与传统机器学习模型相比,较少受到数据不平衡的影响并且能够达到较好的效果。最后,本文基于强化学习模型实现了一个P2P网络借贷机构风险评估的实验系统。"
840,基于条件随机场与深度学习的蛋白质二级结构预测,"随着生物信息学的发展,蛋白质数据库中的蛋白质序列信息越来越多,尤其是生物信息学的出现,使得人们能够更好地利用这些蛋白质信息了解生物系统。生物信息学可以利用这些序列信息寻找相关的蛋白质,并收集其他信息推测未知蛋白质的结构和功能等可能的特性。蛋白质结构分析预测也经常被用在药物设计中。通过实验方法获取蛋白质二级结构所需的成本高,专业人才紧缺,所以目前面临的核心问题就是利用生物信息学找到一种能够高效地预测蛋白质二级结构的算法。本文使用深度学习算法和条件随机场算法对蛋白质二级结构进行预测。在蛋白质数据处理中,本文用到了位置特异性矩阵(Position-Specific Scoring Matrix,PSSM),同时为了更好的表示氨基酸序列,使用了滑动窗口技术。在蛋白质二级结构预测算法方面,本文提出了两种学习分类方法:第一种是卷积神经网络结合Softmax分类器的算法,此方法改进了卷积神经网络的模型结构,针对梯度消失问题在各卷积层之后添加了修正线性单元(Rectified Linear Units,ReLU)激活层,为了最大限度地保留原始数据的重要特征,提取了全连接层之前的特征数据作为Softmax分类器的输入,对蛋白质二级结构进行分类和预测,与传统的卷积神经网络方法比较,此方法提高了预测精度。第二种是基于集成学习的思想:使用了一种简单的集成策略把卷积神经网络和条件随机场模型进行了结合,使得这两种学习器最大限度的发挥自身的优势同时弥补彼此的缺点,最后用本文的集成分类器对蛋白质二级结构进行分类和预测,提高了预测的精度。实验证明,本文提出的两种方法在公开的蛋白质数据集25PDB数据集上准确率有所提高。实验证明,由卷积神经网络和条件随机场模型基于集成学习策略组成的集成学习器在25PDB数据集上的预测准确率高于CNN-Softmax网络模型,所以,深度学习算法与条件随机场模型结合可以更好地提高蛋白质二级结构的预测准确率。"
841,基于分组式的多分类器的蛋白质二级结构预测的算法研究,"蛋白质二级结构预测是蛋白质结构预测和理解蛋白质结构和功能的重要课题,主要工作是依据蛋白质氨基酸序列的编码特征正确识别出对应的蛋白质二级结构标签。本文采用25PDB蛋白质序列数据集,采用PSSM编码p正交编码和滑动窗口方法将氨基酸处理成伪图像对蛋白质二级结构预测做了研究,在研究过程中选定了三种训练模型,分别是卷积神经网络pLSTM神经网络和随机森林。每个训练模型对应一个分组实验,在每个分组实验中对训练模型做了训练模型的优化设计:在基于卷积神经网络的分组实验中,设计了一个包含两个网络结构单元的一般卷积神经网络,每个网络单元包含主要的卷积层和下采样层,因为蛋白质氨基酸的伪图像对于卷积神经网络来说相对于真正的图像而言数据量较少,所以本文设计了一个可以增加输入冗余,解决一般卷积神经网络梯度偏离的残差卷积神经网络,实验证明这种卷积神经网络更加稳定,预测更准确。在基于LSTM神经网络的分组实验中,分别对伪图像在两个维度上切片生成序列数据对于一般的LSTM神经网络做了实验,因为直接切片会破坏蛋白质氨基酸序列的上下文特,所以本文采用滑动窗口操作在蛋白质序列维度生成了多个BP神经网络隐层,将这些BP神经网络隐层神经元的输出当作序列数据输入LSTM神经网络,实验证明添加BP神经网络隐层的LSTM神经网络能更好的提取蛋白质序列的上下文特征。在基于随机森林的分组实验中,本文将残差卷积神经网络在最后一个平均池化层提取的样本特征作为随机森林的输入,相当于为随机森林做了一个特征提取器,实验证明添加了特征提取器的随机森林预测结果会有很大提升。在分组实验结束之后,本文利用ensemble方法将实验中三种优化设计之后的模型进行了整合,将残差卷积神经网络p加入了BP神经网络隐层的LSTM神经网络和添加了特征提取器的随机森林模型在每个蛋白质二级标签上的输出概率相加,取最大概率对应的标签作为ensemble模型的输出,实验证明ensemble模型相对于三类成员模型的预测结果均有提高。"
842,蛋白质组一站式数据分析及可视化平台的研发及应用,"蛋白质组学是后基因组时代的热点研究领域。随着仪器精度的提升及鉴定算法的完善,蛋白质组学的研究重点已经逐渐从定性研究转移到了定量研究。确定生物体不同状态下的差异表达蛋白质是定量蛋白质组研究的重要方向之一,对理解蛋白质功能以及整个生命活动起到了重要作用。目前已陆续发表了多种差异表达蛋白质计算工具,但它们普遍存在安装更新复杂、上游工具兼容性不佳、功能有限、使用门槛高、分析结果展示效果差等问题。这给蛋白质组技术的推广及应用造成了一定的困难,此时亟待推出一个功能全面、简单易用的组学数据分析工具。针对上面提出的问题,本工作主要关注于蛋白质组一站式分析及可视化平台MyOmics的研发及应用。本文的主要内容包括如下三方面:(1)我们首先调研了差异表达蛋白质筛选分析流程中缺失值处理、数据标准化、统计学分析及功能富集等各个阶段的常用分析方法及适用条件,引入机器学习方法实现高维数据的直观展示。之后我们使用Python及R语言,以多级索引数据框为核心数据结构,完成了主要方法的编程实现与功能对接,并针对组内全样本定量缺失、统计学检验方法择优选择等具体问题进行算法优化。(2)依托于Galaxy计算生物学平台系统,通过编写XML配置文件,我们完成了上述分析程序的网络上线及功能测试,并利用这些工具构建了两类主流组学实验设计类型(单因素二水平设计和单因素多水平设计)的数据分析工作流。为了解决用户访问统计困难、图表展示效果不佳、不能依据输入文件生成动态表单等Galaxy平台本身存在的固有问题,我们额外设计编写了独立的用户界面,并完善了用户注册、使用统计、多类型图表在线展示等诸多功能,基本完成了平台的开发工作。(3)最后,我们将MyOmics中的数据分析及可视化方法应用在了“血清蛋白质测试分析平台指导银屑病诊断标志物及药物响应标志物发现”的研究课题中。我们综合分析了抗体芯片及数据非依赖采集质谱两种来源的定量数据,通过缺失值插补、标准化、统计学检验、相关性分析等步骤筛选到了数十种血清样本的差异表达蛋白质,实现了十个数量级的丰度覆盖。我们成功找出了与银屑病诊断相关的潜在蛋白质生物标志物PI3并在实验中得到验证。最后我们还成功确认了临床指标与血清蛋白质间的相关性。这一应用实例证实了MyOmics平台的可用性。差异表达蛋白质的筛选是蛋白质组学研究的核心问题,对于解决生物学及临床问题意义重大,全面易用的差异表达蛋白质分析工具在研究中必不可少。本研究以差异表达蛋白质的筛选为核心,重点进行了分析流程中各功能的编程实现与功能优化,开发了网络客户端形式的分析及可视化平台MyOmics,平台及方法目前已在生物医学研究中得到了广泛应用。"
843,生物可降解地膜加工过程中的构效关系研究与智能化表征,"我国是农业大国。棚膜、地膜等农膜是实现农业高产、稳产不可缺少的生产材料,2015年世界产量已经超过340万吨。发达国家农膜高档占比为20%,但是,从中国农膜产品结构比例来看,高档的农膜产品供不应求,高档农膜占比只有1 0%左右。在我国,常见的用于制造地膜的材料是聚乙烯,因为它的价格便宜,制造成本低,但是作为难降解的化石燃料的下游产品,聚乙烯最大的问题就是会对环境造成白色污染。因此,人们试图寻找一种生物可降解的材料替代聚乙烯地膜,而这其中比较合适的选择就是聚己二酸对苯二甲酸丁二醇脂(Poly(butyleneadipate-co-terephthalate)),简称PBAT。工业上,地膜一般采用吹膜的方法进行加工。而在生物可降解地膜的加工过程中,存在有很大的问题,如:1)材料的加工稳定性差;2)吹膜制备的薄膜产品难以达到市场要求;3)吹膜制造工艺严重依赖工人经验,导致产品品控不高。所以优化调控加工参数以及对原材料进行改性十分必要。本文针对上述问题,做了如下几项工作:1)吹膜过程中PBAT薄膜加工条件-膜泡结构-性能的关系。为了探究生物可降解地膜PBAT在吹膜过程中的加工条件-膜泡结构-性能的关系,将自制的吹膜机与同步辐射X射线联用,检测了添加有不同含量扩链剂的PBAT在吹膜过程中距离口模不同位置处的膜泡的结构变化以及最终的薄膜性质。我们发现:整个膜泡的演化过程可以分为三个阶段,受到流动场控制的前驱体的生成,受到流动场和温度场控制的晶体的成核以及受到温度场控制的晶体的生长过程。扩链剂ADR的加入改变了分子链长,使得前驱体在生成的过程中对拉伸外场的响应不一致,最终薄膜取向沿着不同的方向,为制备具有不同取向的薄膜提供了新思路。ADR的加入提供了化学交联点,和PBAT结晶形成的物理交联点一起共同组成了膜泡的基本骨架。2)PBAT薄膜单轴拉伸过程中构效关系建立。为了探究后加工过程中拉伸对PBAT薄膜的影响,将自制的拉伸机与同步辐射X射线联用,检测了PBAT在室温拉伸过程中的结构形态演化以及光学性能的变化。结合应力应变曲线,我们将其分为三个区:在Ⅰ区弹性形变区,无定形区的分子链发生了仿射形变;超过了屈服点的Ⅱ区,取向无定形链平行排列形成了亚稳的β晶;Ⅱ区出现了应变硬化,此时出现了从α相到β相的相转变。换句话说,整个拉伸过程中β晶的形成有两种方式。与此同时,透光率的变化与相转变的变化是一致的,这可能是因为在拉伸的过程中,晶相和无定形相的折光指数趋于一致造成的,为制备具有不同透光率的薄膜提供了理论基础指导。3)为了实现吹膜过程的智能化,需要建立加工参数-材料性能的知识图谱,并且采用机器学习算法训练出相应的模型。其中前期的工作就是建立高分子吹膜智能化检测平台。通过改进现有的图像识别算法,实现了对吹膜膜泡外形的捕捉,用来定量的表征吹膜膜泡的稳定性。通过设计自动化的薄膜剪裁系统和拉伸系统,并将其他的光学检测设备集成到平台上,可以实现高分子吹膜膜泡的稳定度表征以及高分子薄膜力学性能和光学性能的自动化表征,为建立知识图谱提供了高通量数据,为实现智能化吹膜打下了基础。"
844,基于交通大数据的道路安全行为分析与预测,"现有定位及通信技术的进步,可精确记录车辆的时空数据存储于交通平台中。这些交通数据中往往隐藏着重要的信息,利用聚类技术对时空轨迹数据进行处理,在无监督的情况下得到轨迹的分类和异常轨迹,并针对事故数据建立有效的道路交通安全预测模型,可为交通运输管理部门的车辆监督和管理提供重要的决策依据,从而达到辅助决策的作用。本文面向交通运输的稽查管理需求,研究道路安全行为的分析与预测方法,主要研究工作包括以下三个方面:(1)针对分布式交通数据存储系统,快速增长的交通数据可能造成系统障碍堵塞或数据丢失,且原有交通数据存储系统集群已经配置了非面向对象存储的数据类型等状况,提出一种从数据存储系统到对象存储集群的透明访问方法,实现大数据文件系统与对象存储服务的融合,提高交通大数据挖掘的效率和可靠性。(2)基于车辆的时空轨迹数据,综合考虑轨迹特征,研究具有时空特征的相似度轨迹聚类与异常检测方法。提出一种MBR-D图形序列相似度度量算法,利用MBR算法划分出子轨迹的最小外接矩形,通过DTW算法计算出子轨迹的时间序列外接值的最小相似距离矩阵作为轨迹聚类的依据,之后通过K-Means聚类算法将相似的轨迹划分得到多个簇集,再利用WCSS误差评价标准找到合适的轨迹聚类结果,最终将其运用到异常轨迹的识别中。(3)研究建立道路交通安全预测模型的方法,将机器学习算法应用于事故安全级别预测,选取对交通事故有重要影响的特征因子,基于历史交通数据建立了三种道路交通安全预测模型,对比分析各种模型的预测准确度,并给出各个特征因子对交通安全影响的重要程度。"
845,跨摄像头车辆再识别与追踪的研究与应用,"随着科技发展,交通问题日益成为城市建设中的重要一环。因此智能交通系统(Intelligent Transportation System,ITS)应运而生。ITS旨在利用计算机的海量数据处理能力,为疏散交通拥堵提供解决方案,减轻城市道路监管方面的人力物力,使城市交通变得易于监管和调度。在视频中进行车辆追踪与再识别作为智能交通系统中的重要一环,成为了计算机视觉领域的研究热点。单摄像头中的车辆追踪已经有较多研究,而目前智能交通系统中的研究热点在于多摄像头中的车辆再识别与追踪问题。对于车辆检测方面,学术界已经有了很多研究成果。本文对传统车辆检测算法和基于机器学习的车辆检测算法进行调研比对,提出了基于YOLOv2的车辆检测算法。对于车辆再识别方面,虽然研究成果较少,但借助行人再识别问题的启发,提出了结合多种特征的车辆再识别策略。基于YOLOv2的车辆检测算法考虑了车辆检测场景的特殊性,力图在检测精确度、运算速度方面对YOLOv2算法进行优化。在文中,分析了车辆检测场景的特点及YOLOv2算法在此场景下可以进行优化的方面,提出了针对这一场景的改进YOLOv2算法,并通过实验证明了其有效性。结合多种特征的车辆再识别策略考虑了车辆再识别时的标识性信息,通过车牌、外观、深度学习、车型特征进行损失函数的设计,并考虑到车牌信息在车辆识别中的重要性,对车牌特征进行权重提升,以降低整体运算量,提升系统计算速度。通过实验,证明了本文提出的车辆再识别系统的有效性。最后,本文设计了一个以车辆检测模块和车辆再识别模块为核心的跨摄像头车辆再识别与追踪平台。在实现过程中使用了文中提出的车辆检测算法和车辆再识别算法,在保证精确率的同时对运算速度进行最大可能的提升。同时实现了跨摄像头车辆轨迹规划模块。通过实验证明了本文提出的跨摄像头车辆再识别与追踪系统的有效性。"
846,基于机器学习的疾病自动诊断研究,"随着人工智能和大数据的飞速发展,大量的医疗数据被有效利用,疾病的诊断分析随之步入智能时代。一方面,传统的疾病诊断主要依靠医生的直接经验,诊断结果受人为、环境等因素影响较大;另一方面,我国医疗资源分布不均,顶级医疗机构人满为患而基层偏远地区医疗资源短缺且服务水平低。为解决这一问题,机器学习算法被应用到人类疾病的自动诊断上,这不仅能够帮助患者及早发现疾病、及时得到治疗,同时可以有效辅助医生对疾病作出正确的诊断,降低误诊漏诊的概率,还能够打破城乡之间的信息屏障,将先进诊疗能力拓展到基层,提升基层的医疗水平。随着医疗领域影像检查技术的发展,医学图像的大数据分析进程不断推进,深度学习方法被有效应用在医学影像数据的识别与处理上。本文以两类数据集为例,一类是小规模文本数据――印度肝脏病人数据集ILPD,一类是大规模病理图像数据――公开的乳腺癌患者数据集BreakHis,针对不同的数据集特征提出了不同的应用策略,在理论研究和实践应用上均取得了一定成果。本文使用了当前机器学习应用领域两种普遍使用并且十分有效的研究方法:比较研究和改进研究。基于ILPD数据集使用多种机器学习模型做了比较研究,首先推导了逻辑回归、SVM和决策树三种常规机器学习方法的构建,分别成功应用到ILPD数据集上,实现了对肝脏病的分类预测;之后利用多种评估方式衡量三个算法模型的实验性能并不断优化算法参数,通过比较分析获得最佳的肝脏病诊断模型。基于BreakHis数据集使用深度学习强大的图像处理能力实现对乳腺癌病理图像的分析,进一步高效完成特征提取,利用改进算法模型的方法进行数据训练。本文提出了改进的DenseNet网络的乳腺癌诊断模型,在当前性能出色的DenseNet网络基础上改进网络结构,结合数据增强与迁移学习策略,训练样本经数据增强后再进行特征提取,并通过优化参数及微调学习,针对不同倍数、不同肿瘤类型的图像均实现了对乳腺癌的自动诊断,并且与以往的研究成果相比该方法具有较强的鲁棒性和泛化能力,其准确率也取得了大幅度的提升,是一种准确、有效的乳腺癌诊断模型。"
847,基于深度学习的中草药图像分类方法研究,"中草药在治疗某些疾病方面都有很好的效果,对人类的健康做出了巨大的贡献,但是中草药种类繁多,同一个种类由于生长环境等因素的影响,也会出现不同的形态.有些不同种类的中草药植物却是十分相似的,对它们进行准确的分类是一个比较艰巨的任务。但是,目前对于中草药分类的研究比较少,现有的研究只是对少数的植物进行分类。本文通过设计基于中草药图像的分类方法,实现对中草药的准确分类。目前,对于中草药图像并没有一个非常全面的数据库,所以我们首先收集并建立了包含数量较多的中草药图像数据集。近几年来,深度学习发展迅速,在分类识别这方面已经取得了非常好的效果,所以我们采用深度学习的方法对收集到的中草药植物图像进行分类。我们首先在原始的中草药图像数据集上进行分类,通过对实验结果分析发现图片的背景对分类结果影响很大。因为大部分图像都是在自然状态下拍摄的,所以难免会有十分复杂的背景,这对于分类来说就造成了相当大的干扰。为了消除中草药图像中存在的复杂背景问题,我们对图像进行了分割。图像分割使用自动图像分割方法和手动图像分割方法相结合的方式来提高图像分割的效果。首先通过图像分割算法得到了一部分分割彻底的图像;之后,对于分割效果不好的图片进行手动分割;把这些分割后的图片进行整理,作为数据集;使用深度学习算法对它们进行分类,最终提升了分类的准确率,得到了TOP-1的准确率为72%,TOP-5的准确率为93.6%。"
848,基于深度学习的lncRNA识别和功能注释及与疾病关系研究,"在真核生物转录组中,只有大约2%的序列可以被翻译为蛋白质,多达70%的人类基因组均被转录成了非编码RNA,而且复杂程度越高的生物中,非编码转录本的比例越高,因此非编码转录本的作用逐渐引起广泛关注。特别的,在非编码RNA中,长链非编码RNA(long non-coding RNA,lncRNA)的研究成为近年来的研究热点。LncRNA是一类长度大于200核苷酸的非编码转录本。LncRNA参与很多重要的细胞过程,因此某些转录本的改变可能导致细胞生命活动的剧烈变化,从而导致某些特定的疾病。越来越多的证据表明,lncRNA在癌症的发生和发展中发挥作用,在癌症细胞中的lncRNA表达谱和正常细胞中的有显著差异,而且不同时期的癌症细胞中lncRNA表达谱也不同。因此,深入了解lncRNA的作用方式和调控目标,并理解lncRNA在癌症等疾病中的作用是一个非常重要的研究方向。而目前,从转录组数据中识别lncRNA并了解特定lncRNA的功能,理解lncRNA在癌症中的作用,仍然是一项巨大的挑战。另一方面,机器学习的研究飞速发展,机器学习已经逐渐成为人类学习和推理的有效途径。深度学习是机器学习的一个分支,是当今最流行的机器学习研究方法之一。深度学习可以通过分析大量复杂数据,找到这些数据之间的潜在关系,从数据中逐层抽取多种特征。深度学习的计算非常复杂,在处理复杂数据时,耗时长且需要占用较大内存,而CPU、GPU等硬件性能的提高促进了深度学习的广泛使用,到目前为止,深度学习逐渐被应用于图像处理、语音识别等领域,对这些领域的研究起到了重要的作用。深度学习的方法同样应用到了生物医学领域,例如在识别不同的功能元件和位点、以及医学影像特征提取等问题中。目前已经提出了很多基于深度学习的方法,这些方法往往具有较高的准确率。因此深度学习的应用对生物医学领域的研究具有重要意义,是传统研究方法的一种突破。随着高通量RNA测序技术(High-throughput RNA sequencing technology)的快速发展,转录组数据得到了快速累积。为采用深度学习方法建立lncRNA智能识别系统提供了重要的数据基础。本文基于深度学习方法,从转录本中识别lncRNA,构建了lnc2Catlas数据库,量化lncRNA和癌症之间的关联程度,进而通过构建LIVE数据库,探索了有实验验证的lncRNA和癌症之间的结合、调控相互作用网络。研究内容主要围绕以下几个方面展开:首先,基于深度学习和机器学习的lncRNA识别算法。通过对相关算法的回顾比较,我们发现,这些算法普遍需要保守性等相关的先验知识,需要花费大量时间计算人工选择的特征,且将序列切分计算,容易给机器学习或深度学习模型引入噪声或丢失信息,影响模型学习的特征,造成准确率低等问题。我们对卷积神经网络和循环神经网络这两种常用的深度学习模型进行了深入的了解,探究了两种网络对数据的数学操作。我们根据序列数据特点,用基于卷积神经网络的DeepSea模型提取序列的表观特征,使用循环神经网络提取序列特征,基于序列特征和表观特征,可以从测试集中识别lncRNA和编码蛋白的RNA,AUC面积达到0.96。实验结果表明,本文提出的模型具有较高的准确率和泛化能力。在lncRNA识别的工作基础上,本研究进一步探究lncRNA在癌症的发生和发展中发挥作用的方式。目前研究lncRNA和癌症之间关系的方式有实验探究和计算预测两种方式。经过实验验证的lncRNA和癌症的关联关系非常少,而通过计算方式预测的lncRNA和癌症之间的关系主要有通过机器学习算法模型和整合lncRNA-miRNA和miRNA-癌症相互作用。我们通过SNP、蛋白和基因将lncRNA和癌症关联起来,使用RNAsnp、Global Score、WGCNA三种方法,分别评估SNP引起的lncRNA二级结构的改变、lncRNA和蛋白的相互作用以及共表达网络,量化lncRNA和相应的癌症之间的关联程度。基于上述数据,构建Lnc2Catlas数据库,便于用户查询和lncRNA可能相关的癌症,并为进一步的实验验证提供候选lncRNA。最后,为了给相关研究者提供支持,我们开发了用于探究lncRNA和癌症关系的数据库。与早期的从实验验证和计算预测研究中提取候选lncRNA的数据库不同,目前已有的数据库着眼于lncRNA的特定功能作用,但是文献中包含的潜在的lncRNA-癌症相互作用网络没有被完全揭示出来。因此,我们构建了LIVE数据库,在PubMed数据库中检索相关的文献,并构建分词系统,对文献摘要进行预处理,抽取物种、实验类型、lncRNA等关键词,并根据关键词对文献分类,详细标注文献中经过实验验证的lncRNA和癌症的相互作用。基于上述手工标注的lncRNA和癌症之间的相互作用关系,我们构建了LIVE(LncRNA Interaction Validated Encyclopedia)数据库。LIVE数据库将这些经过验证的相互关系被分为三类网络,分别是结合相互作用网络、调控网络和疾病关联网络。通过对这三个网络的组合,我们进一步了解lncRNA相互作用网络中包含的不同类型的功能调控元件和相互作用。综上所述,本文的工作围绕lncRNA的识别、功能注释及与疾病关系研究展开,提出了基于混合模型的lncRNA的深度学习识别算法,只使用序列识别lncRNA;构建了Lnc2Catlas数据库,量化lncRNA和癌症的关联程度;构建LIVE数据库,提供手工标注的lncRNA和癌症的关联关系以及完整的lncRNA-癌症相互作用网络,有助于进一步揭示lncRNA和癌症之间的潜在关系和探究lncRNA在癌症治疗中的作用。"
849,基于机器学习的无线电监测技术研究,"随着国家信息化战略的逐步推进,无线通信技术发展迅猛,已经在居民生活、军事工业等多个领域起到了重要的基础支撑作用。无线电监测作为无线通信领域的主要课题之一,旨在对无线环境的频谱参数进行测量,并对频带使用和占用情况进行汇总与分析。通过相关指标的采集,可以更好地提高频谱的利用率,优化频谱资源分配,并对违规、非法使用或干扰无线电磁环境的情况进行监察和处理。无线电监测包含众多环节,其中信号检测和调制方式识别是最为重要的两个部分。因此,本课题主要对无线电监测中的检测和识别算法展开研究。目前传统的信号检测与识别方法,在低信噪比和有干扰信号的环境中检测或识别效果较差。如何提高恶劣环境下信号检测和识别的精度和稳定性是无线电监测领域的重要课题。同时,目前大部分信号检测与识别算法都依赖于特征,如何针对特定研究场景对无线信号进行相应高效的表征是另一个待研究的难点。随着人工智能与机器学习领域的迅猛发展,基于机器学习的无线电监测开始被研究和使用。利用机器学习的信息挖掘与学习能力可以发现更有利于低信噪比检测和识别的信号表征和模型,从而提高在低信噪比环境中信号检测和识别的性能。本文提出一种基于遍历选择与准则学习的合作式信号检测算法。遍历特征选择算法通过综合不同的特征选择方法,对特征进行联合决策,选择出有效的特征子集。此外,融合中心使用准则学习算法在不同场景学习不同的判决准则,克服检测节点不良的影响,显著提高检测性能及稳定性。经过仿真验证本方法可有效提高低信噪比下信号检测性能。基于传统机器学习方法需要大量有标注的信号数据进行训练方能达到良好的效果,在缺少足量信号标注的场景不再适用。为了提升该场景中信号识别在低信噪比下的性能,本课题提出了基于字典学习的无线信号识别算法。该方法使用字典学习模型,利用其去噪能力和高效的信号表征能力,有效地提高信号识别在低信噪比下的性能。我们使用信号的高阶累积量和星座图坐标构成字典原子,使用正交匹配追踪(OMP)算法和奇异值分解(K-SVD)算法对字典原子进行更新,得到可以对信号较好表征的字典,从而在缺少足量有标注信号样本的场景实现低信噪比信号识别。仿真结果进一步证明了本课题所用算法的正确性和有效性。论文最后对本文工作进行了总结,并展望了未来的研究工作。"
850,基于机器学习的高阶调制信号识别技术研究,"随着无线通信技术的不断发展和通信服务需求的日益增长,新型无线通信设备和服务层出不穷,为人们的日常生活带来了极大的便利,同时也使得无线电磁环境愈加复杂。这直接导致简单的信号检测技术或者传统的信号识别方法无法为无线电监测系统提供高精度、高鲁棒性的频谱感知和分析能力。为了解决这一问题,本文旨在采用机器学习方法,解决复杂电磁环境下的高阶调制信号识别问题,以提高调制方式识别的准确性和鲁棒性。本文主要内容如下:1.基于多基因遗传编程与结构风险最小化原则的信号调制方式识别方法本文提出了一种基于多基因遗传编程(Multi-gene genetic programming,MGP)与结构风险最小化原则(Structrual risk minimization principle,SRMP)的信号调制方式识别方法(GPMC)。该方法使用累积量作为原始判别特征,并可分为训练和识别两个阶段。训练阶段中,在基于结构风险最小化原则的目标函数的指导下,基于多基因遗传编程的特征工程将高阶累积量特征转化为MGP特征并迭代优化,直到获得判别能力更强的最优MGP特征。通过上述训练过程,可以获得将原始累积量特征转化为最优MGP特征的特征优化函数,以及基于最优MGP特征的SRMP分类模型。此外,我们设计了自适应遗传运算,用于优化所提出的方法的训练效率与收敛性。在识别阶段,首先使用特征优化函数获取目标信号的最优MGP特征,然后输入到SRMP分类模型中,由其输出判别结果。仿真结果表明,在加性高斯白噪声信道和衰落信道下,提出的GPMC方法在识别正确率和鲁棒性等方面均明显优于其他现有基于累积量的调制方式识别方法。2.基于网格星座矩阵与全卷积对比网络的信号调制方式识别方法鉴于人工设计的统计特征对调制信号表征不完备和表征缺少差异化的缺点,本文将深度学习方法应用于调制识别领域,提出了一种基于网格星座矩阵与全卷积对比网络的信号调制方式识别方法(CFCN),以进一步提升调制识别性能。该方法首先通过计算复杂度极低的预处理方法,将接收到的信号采样转化为网格星座矩阵;然后,使用全卷积网络结构从维度各异的网格星座矩阵中提取多种常用高阶调制信号的高维表征,并构造分类模型。此外,为了扩大不同调制信号在特征空间中的表征差异,我们设计了对比损失函数训练该网络,以增强高维表征的判别能力。大量仿真实验证明,相比于基于统计特征和其他基于深度学习的调制方式识别方法,所提出的CFCN方法具有更显著的性能增益和更低的计算复杂度。最后对本文的主要工作进行了总结,并且对未来相关研究进行了展望。"
851,密集异构认知网络中D2D通信的资源分配研究,"密集异构网络通过引入多种通信制式共享频谱来提升频谱效率,但会带来严重的干扰管理问题。认知无线电技术是解决干扰管理问题的有效途径,所以需要密集异构认知网络来满足未来无线通信的需求。密集异构认知网络中的用户直连通信(Device-to-Device,D2D)作为一种低成本提升频谱利用率的技术,得到了学术界和工业界的广泛关注。D2D通信可以让邻近用户建立直接通信链路,能够有效提升频谱利用率,与此同时,D2D通信复用蜂窝网络的频谱会引入严重的同频干扰,尤其在用户分布密集时干扰问题更加突出,所以密集异构认知网络中D2D通信的干扰管理问题是一个亟待解决的问题。认知无线电技术是解决干扰管理问题的有效途径,D2D通信作为认知网络智能复用蜂窝网络的授权频谱,可以抑制授权网络与认知网络之间的干扰。无线网络资源分配作为认知无线电的关键技术旨在通过合理的资源配置来缓解干扰,提高资源的利用效率,所以有必要研究密集异构认知网络中D2D通信的资源分配。论文选题依托国家自然科学基金项目“密集异构无线环境下极化资源感知与利用研究”(项目编号61571062)。本文研究了D2D通信的资源分配算法来解决密集异构认知网络中引入D2D通信产生的干扰管理问题,分别提出了基于位置感知超图的D2D频谱分配算法和基于深度强化学习的D2D资源分配算法,主要研究内容和贡献如下:在密集异构认知网络中,针对密集分布的D2D通信对与蜂窝用户共享频谱导致的累积干扰问题,提出了基于位置感知超图的D2D频谱分配算法。算法引入超图来建模多个D2D用户间的同层累积干扰关系;引入位置感知区域来建模多个D2D用户对蜂窝用户的跨层累积干扰关系;设计超图着色算法,为D2D用户分配频谱,实现在保证蜂窝用户通信质量的前提下,最大化系统容量;仿真结果表明,所提算法可以将蜂窝用户的中断概率降低到接近0,与此同时,所提算法相比现有的基于图论的方法可以达到更高的系统容量。因此,所提算法可以应用于密集异构认知网络中D2D通信的资源分配,能够可靠的保护蜂窝用户通信质量同时提升频谱利用率。在密集异构认知网络中,现有研究提出的算法会因为设备数量的大幅增长出现信令开销大、计算复杂度高等问题,所以本文提出了两种分布式的基于深度强化学习的资源分配算法,使D2D通信对具备认知能力,实现D2D通信对自主进行频谱选择和功率控制。两种算法分别从单智能体强化学习和多智能体强化学习两个角度建模D2D通信对分布式的频谱分配与功率控制问题,从用户的历史数据中学习策略指导即时的资源分配;结合位置感知区域的选择状态特征;设计回报函数惩罚对蜂窝用户和D2D用户造成有害干扰的策略,奖励能提升D2D链路容量的策略;分别建立单智能体深度强化学习模型和多智能体深度强化学习模型,从而学习出个体优化策略和合作优化策略;仿真结果表明个体优化策略具有更快的收敛速度,合作优化策略可以达到更好的系统性能。因此,两种算法可以分别应用于通信环境快速变化和高通信性能要求场景下的资源分配,在不需要全局信道状态信息的情况下,依然能够保护蜂窝用户和D2D用户的通信质量同时提升频谱利用率。"
852,在线照片打印平台的研究与实现,"目前智能手机已经广泛渗透到人们生活的各个方面,并在人们的衣食住行中逐渐扮演着越来越重要的角色,目前智能手机的功能越来越强大,不仅可以拍出像素很高的照片而且还能够存储成百上千张照片。电子照片在传输,处理方面有着得天独厚的优势,仍然有很多用户希望将照片打印出来作为永久的纪念。传统照相馆冲洗照片存在着费时、效率低而且价格昂贵等因素,目前越来越多的用户想要线上进行照片的预订以及照片的处理。本文针对用户需求,提出并实现了一种在线照片打印平台,为用户提供照片在线预订的功能并结合机器学习相关算法为用户提供图片处理的功能。本系统基于微信公众平台进行二次开发,结合机器学习相关技术理论,形成一个在线智能图片社区平台。系统可以分成三个模块,分别是照片购物车模块、图像处理模块以及后台数据管理模块,本文将从整个系统的需求分析与挖掘到技术研究对比以及整体的设计实现来进行阐述。本文首先对相关技术进行了研究,对微信开发的整体流程以及实现方法进行了深入研究并对比了几种常见的Python后台Web框架,并采用Tornado异步非阻塞框架作为整个系统的框架。在数据存储方面通过对数据库技术进行研究与对比,采用MySql与Redis结合的方式来存储数据。功能界面部分采用JS-SDK接口以及传统的前端开发技术,界面中组件采用JQuery Weui进行布局。图像处理模块分为图像质量评价、图像黑白转换、人脸识别以及图像风格迁移四个部分,采用拉普拉斯方差算法以及卷积神经网络实现。接下来对于整个系统业务部分的设计与实现做了具体的介绍,并采用了微信提供的官方测试工具对系统进行了测试。最后对在线照片打印平台做了总结与展望。"
853,云服务社区中基于深度学习的用户观点发现方法研究,"云计算的快速发展促进了各行业资源的协调整合,越来越多的个人与组织机构将本地的应用资源以Web服务的形式|移到云计算资源池(即云服务社区)中,以便用户选择调用。这种服务部署模式加速了Web服务资源数量与质量的更新,云资源池中的Web服务呈指数型增长。基于SaaS平台的云服务社区的Web服务推荐因生态系统复杂性给服务计算提出新难题。近年来,越来越多的人对消费者评论的情感倾向感兴趣,以评估产品评级和公众偏好,因此,这种分析的研究和技术变得越来越普遍和成熟。然而,对中文API服务的使用评价进行情感分析的深度学习研究却很少有人关注。为了更好地挖掘云服务社区中用户观点文本的有效信息,本文提出了基于深度学习的对用户观点数据进行情感分析的方法。首先,对云服务社区中的原始数据进行人工标注和预处理,利用Gensim和Word2Vec将文本转换为可输入模型的形式;接着设计并实现了LSTM、BiLSTM和GRU三种深度学习模型实现情感分类的任务,并将其与使用K-最近邻、SVM和朴素贝叶斯三种机器学习算法建立的情感倾向模型的实验结果进行对比,结果证明了深度学习方法的有效性;最后对建立的三种深度学习模型的性能进行评估,选择最优的BiLSTM模型作为云服务社区日后使用的模型。通过对BiLSTM模型进行参数对比实验,得到了模型的最优调参,最终使得模型达到89.68%的准确率,具备较好的分类性能。"
854,基于“葵花8号”表观反射率和AOD数据的逐小时地面PM_(2.5)估算,"随着工业化和城市化的发展,中国空气污染形势日益严峻,PM_(2.5)以其粒径小,面积大,活性强,易附带有毒、有害物质,且在大气中的停留时间长、输送距离远的特点,对人体健康和大气环境质量有很大危害。我国在2012年底建成了全国PM_(2.5)地面监测网络,但是站点的空间分布不均匀,且主要集中在中东部城市区域。基于卫星遥感气溶胶光学厚度(Aerosol Optical Depth,AOD)产品数据估算地面PM_(2.5)是国内外的一个研究热点,具有大面积、高密度覆盖等特点,可以弥补地面监测站点的不足。当前,大多数AOD产品由极轨卫星提供,观测时次有限,不能获取PM_(2.5)的逐小时变化趋势,此外AOD反演过程中严格的地表假设使得某些区域或者时间段内无法有效反演AOD。因此本文利用地球静止卫星“葵花8号”的表观反射率(Apparent Reflectance,AR)和AOD数据、气象数据、人口、DEM、LUCC和近地面PM_(2.5)浓度观测数据,运用机器学习算法估算了2016年1月中国区域和2016年全年长三角地区近地面PM_(2.5)浓度,同时利用地基激光雷达数据得到的气溶胶垂直分布特征对AOD进行垂直改正,并用于PM_(2.5)估算。主要研究结论如下:(1)为了揭示基于地球静止卫星的AOD-PM_(2.5)和AR-PM_(2.5)方法在中国区域的优劣,对比分析了两种方法估算的2016年1月的PM_(2.5)浓度。结果表明:深度神经网络(DNN)模型优于梯度提升回归树(GBRT)和随机森林(RF)模型,验证决定系数R~2达到0.86,均方根误差RMSE为26.81μg/m~3。就全国而言,AOD-PM_(2.5)方法表现更佳,而AR-PM_(2.5)方法在站点稀疏地区的训练样本偏少,不足以代表整体估算样本;(2)为了检验AR-PM_(2.5)方法在高密度站点地区的估算能力,以长三角地区为例,对比分析了两种方法估算的2016年全年的PM_(2.5)浓度。结果表明:两者估算结果的季均、月均、小时均值基本一致;但是,由于AOD反演过程中严格的地表假设,导致用于AOD-PM_(2.5)方法的PM_(2.5)样本不足AR-PM_(2.5)方法的二分之一,且多为污染情景(PM_(2.5)>75μg/m~3占比为26.10%),因此估算结果明显高估,且生成的逐日PM_(2.5)空间分布图中缺值较多。相比AOD-PM_(2.5)方法,AR-PM_(2.5)方法更符合实际情况,显示了该方法在高密度站点地区的优势;(3)由于气溶胶垂直分布是影响PM_(2.5)遥感估算的重要因素,采用无锡地区长时间序列(2013-2015年)的地基激光雷达数据,在月均和季均两个尺度上揭示了气溶胶消光系数的垂直分布特征,并基于此改善了AOD-PM_(2.5)的相关性,提高了重污染地区的PM_(2.5)遥感估算精度。"
855,基于特征提取的ICU患者死亡风险预测研究,"随着医疗数据供应的迅速增长,预后系统变得越来越复杂和准确,重症监护室尤其如此。重症监护室是重症病人和危重术后患者的聚集地,目前临床使用的典型ICU预后系统通常使用生理和人口统计数据方法,这些系统主要用于风险调整,而没有过多关注具体患者的病情发展预测。然而,过去十年中,人们对医疗数据的使用兴趣显著增加,利用大型数据集对特定患者病情预测的需求越来越多,随着大数据分析与机器学习方法的兴起,医疗领域与机器学习知识结合已成为ICU患者死亡风险预测问题新的解决思路。目前多数利用机器学习方法的预测模型都专注于训练和改进机器学习算法,通常忽略了数据的分析和处理。由于监护设备的丰富性和复杂性,ICU数据往往存在维度高、采样时间和次数不确定、类别不平衡、数据缺失等问题,这些数据问题往往会影响预测模型性能,因此对原始数据的预处理和特征提取工作对于预测模型来说是不可缺少的。本次研究着重于ICU数据的分析、特征提取和筛选,并采用决策树、随机森林和XGBoost三种机器学习方法建立预测模型,探索各种特征值组合对不同机器学习算法预测模型的影响。本文的主要研究内容分为以下几部分:首先,对研究所使用的ICU数据集进行整体分析,统计样本集中类别分布情况,计算各特征值平均采样次数、缺失率和分布特征等统计学特性,分析这些统计学特性对于分类结果的影响,根据样本特性选择适合的机器学习方法和模型预测结果评价指标。其次,分别对非时间序列特征和时间序列特征进行特征提取,对于心率、血压、呼吸频率等采样次数较多的时间序列特征,根据其生理学意义,提出保留原始点的非均匀插值方法和昼夜分割、差分、反馈系数三种特征值提取方法,并根据单个特征值AUC得分对特征值进行排序和筛选。然后,针对样本集不均衡问题,使用XGBoost算法构建预测模型,设计实验对比五种重采样方法,确定最适合本研究数据集的重采样方法,并将该方法应用于后续研究中。最后,设计实验对比五种特征值组合和三种机器学习方法,实验发现选用基本特征提取方法得到的全部特征值加abs(AUC-0.5)>0.05的时序方法特征值,训练集使用多次随机欠采样方法进行重采样,分类方法选用XGBoost算法时,模型预测结果最好,测试集B上AUC得分为0.856,S1得分为0.509,测试集C上AUC得分为0.853,S1得分为0.516。"
856,特定区域污染物浓度预测模型的研究与实现,"随着我国的现代化建设发展,大气污染问题日益严重,引起了公众的广泛关注。而准确预测污染物浓度的变化规律,有助于国家制定相关政策,改善空气质量。与传统的气象学预测方法相比,基于深度学习的污染物预测方法无须涉及复杂的气象学知识且通用性较强。因此,有必要研究并实现相关技术。针对上述问题,本文使用了 Py thon、MySQL、Keras、数理统计、神经网络等技术,实现了多种特定区域污染物浓度的单步预测和多步预测研究,并建立了相关模型。本文针对单步预测模型,改进了其预测方法并提高了预测的准确度;针对多步预测模型设计并实现了多种新的预测方法,完成了模型的测试和对比工作。本文首先介绍了研究背景与课题内容,之后简单介绍了课题中使用的主要相关技术。为完成研究任务并展示研究成果,经过需求分析和概要设计,实现了一个特定区域污染物浓度预测系统。该系统包括数据采集模块,数据存储模块,模型设计模块和数据展示模块,本文详细介绍了各模块的设计细节、实现逻辑以及模块之间的交互关系。其次,本文详细介绍了模型结构和算法。对于单步预测模型,本文在前人研究基础上实现了通过多点原始数据预测一点的污染物数据,研究并实现了共计五种算法模型,分别为两种基于数理统计的模型和三种基于神经网络的模型。对于多步预测模型,本文设计了两种预测思路,建立了相关算法模型,分别为基于机器学习的模型和基于向量匹配的模型。文章详细介绍了各模型结构和算法原理,给出了研究结论和原理分析。最后,本文描述了模型的评价工作。文中通过多个对比实验测试了各预测模型,展示了量化指标和预测图像,测试数据有效论证了课题结论。文章结尾总结了课题的成果和不足,指出了进一步的研究方向。"
857,基于分形几何的滚动轴承故障诊断方法研究,"滚动轴承在机械设备中被广泛使用,起着重要的作用,它的运行状态是设备正常运转的关键。滚动轴承结构开放,工作环境和受力状况较为恶劣,据统计旋转机械的故障的70%都与滚动轴承有关。因此,滚动轴承的故障诊断一直都是研究的热点,寻找更新、更有效的故障诊断方法对降低机械设备的故障率有着重要意义。在滚动轴承故障诊断方法中最为广泛使用的是基于傅里叶变换技术的时域线性分析法。这种方法可很好地处理线性和平稳信号,但不能很好地适用于非线性和非稳定性信号的处理和故障特征提取,而滚动轴承的振动信号是非线性的复杂信号,因此论文从非线性分析方法入手,对滚动轴承的振动信号进行分析并提取故障信号特征,为非线性、非稳定性故障的诊断方法研究提供参考。论文针对滚动轴承振动信号不但存在分形特征,而且在不同的工作状态下其振动信号的分形特征不同这一关键点,进行一系列基于分形几何的滚动轴承故障诊断方法研究。滚动轴承故障诊断的关键技术是对振动信号中故障特征的提取,因此论文利用分形维数去描述和提取故障特征,并在此基础上开展基于单一分形的滚动轴承故障诊断、基于分形维数和EMD的滚动轴承故障诊断和基于多重分形的滚动轴承故障诊断三种方法的研究,用多种机器学习模型进行实验验证。论文首先运用单一分形方法对滚动轴承信号进行故障特征提取,经实验验证,诊断准确率在75%左右。经分析研究,噪声等可能是影响诊断准确率的因素,单一分形无法很好地处理这类问题。因此,论文提出了基于盒维数法和EMD算法的滚动轴承故障诊断方法,经实验验证并对验证结果对比分析发现:其中SVM和ELM两种模型效果较好,诊断准确率分别达到88.9%和93.1%。针对单一分形存在着不能完整刻画信号特征的缺陷,论文又引入基于多重分形的MF-DFA算法的滚动轴承故障诊断方法,经实验验证,诊断准确率可达94.4%。研究结果表明:分形几何可以有效地用于非线性、非稳定性信号的滚动轴承的故障诊断。"
858,基于大数据机器学习的告警关联分析与预测,"由于移动通信网络的快速发展和移动设备的普及,人们对于移动通信网络的稳定性提出了较高的要求。在这样的情况下,移动网络从业人员必须做到对故障的精准定位和快速修复。虽然网络设备产生的告警数据可以作为排查的依据,但是由于一个设备故障会产生一系列的联动告警,增加故障定位的难度。同时,告警系统将操作记录、异常信息、软件运行情况等记录整合在一个集合中,形成了日志。通信网络每天都会产生海量的日志数据,使得日志的查询和针对此进行操作也异常困难。为了解决以上问题,本论文使用数据挖掘的方法,对于日志分析以及实现故障告警的定位和预测进行了深入研究。本论文的主要研究工作如下:1、本论文从网络告警的维度预测特定告警类型的发生,提出了针对通信网络告警信息的基于FP-Growth算法的关联分析方法,对故障告警之间的相关性进行多方面地分析,重点挖掘出与特定类型告警相关性高的告警,分析获得征兆告警,实现针对特定类型故障告警的预测识别功能。2、本论文分析日志与故障告警之间的关联,提出了基于通信网络日志数据的故障判断和预警方法。首先依据告警发生的时间筛选日志数据,然后使用不同的机器学习算法来分析处理大量的日志数据,最后利用训练好的分类器来对实时的日志数据进行分类,从而实现对于网络设备故障告警的预测。3、本论文基于以上理论基础和仿真结果,设计了日志与告警智能分析系统,首先设计了系统的整体构架,然后重点介绍了各个不同的功能层和工作流程,最后设计了具体的应用呈现。本论文使用数据挖掘的方法,研究分析了通信网络产生的海量告警和日志数据,论证了利用机器辅助人工来进行网络故障管理的有效性和可行性。"
859,基于深度学习的智能眼图分析在光通信中的理论与技术研究,"中短距离光传输技术多应用于光接入和光互连系统中,为新兴的互联网业务与日俱增的带宽和速率需求提供了富有潜力的解决方案。随着未来网络朝着动态和复杂格式特性的方向发展,对系统进行多方位的性能监测以保证网络稳定运行显得至关重要。在中短距离传输系统所适用的强度调制直接检测(IM-DD)系统中,眼图监测显示出更大的优势。目前在进行研究的基于机器学习的监测方案,以其在处理非线性问题上的先天优势,实现了比传统示波器更好的眼图监测。然而由于传统机器学习(ML)算法需要进行人工特征提取且在特征构造的过程中可能会引起信息的丢失,所以其仍不适用于未来灵活动态网络的发展。深度学习(DL)技术以其自动特征提取能力和优异的性能表现为眼图的性能监测提供了一条高精度、智能化的途径。本论文围绕深度学习技术对眼图的智能监测提出了若干技术方案。论文的主要创新点如下:第一,针对传统机器学习眼图监测方法缺乏自动提取能力、表现性能欠佳的问题,提出一种基于卷积神经网络(CNN)的深度学习智能眼图监测方案。实验结果表明,该方案可以实现OOK、NRZ-OOK、DPSK、PAM4多种调制格式下的OSNR估计、调制格式识别,以及OOK和PAM4格式下的光纤链路分析以及Q因子估计,与多种传统ML算法相比,可以在1dB间隔下实现100%准确率的OSNR估计,显著优于其他传统的ML算法。第二,针对上述基于CNN的眼图监测方案训练耗时长、模型难复用的问题,提出一种基于深度迁移学习的智能眼图监测方案,并分别建立了Fine-tune和Frozen两种实现方式。实验结果表明,该方案可以有效复用已有模型的眼图特征信息,两种实现方式均明显地缩短了其他相关眼图监测任务的训练时间,且Frozen的表现更为突出,与无迁移的各个模型相比,Frozen的迁移方式在OOK和PAM4格式下分别降低了至少96.84%和97.69%的训练时间。第三,针对上述基于迁移学习的单任务眼图监测方案中模型重复训练、监测效率低的问题,提出一种基于深度迁移学习的多任务智能眼图监测方案。实验结果表明,该方案基于多任务学习机制能够并行地实现多个眼图参数的联合监测,避免了各个模型的重复训练,显著地提升了眼图监测效率,与单任务迁移模型相比,Frozen的多任务迁移方式在OOK和PAM4格式下仅以一个任务的训练时长实现了多个任务的并行监测。"
860,传感器网络数据异常检测方法的研究与实现,"近年来,伴随着微型计算机技术、电子技术及现代网络与无线通信技术等技术的飞速发展,无线传感器网络孕育而生,其已逐渐成为人类从物理世界获取数据信息的重要渠道,备受各国政府、学术界与工业界的瞩目,其安全威胁与安全问题也越来越被研究者们所重视。无线传感器网络具有节点资源有限、易受攻击的特点,已应用的密码、安全路由等技术虽提高了传感器网络的安全性,但仍缺乏有效方法检测出传感器网络中数据异常,故难以保障传感器网络数据的可靠性。异常检测技术的完善能极大促进传感器网络未来的应用与发展,如何高效、准确地利用数据进行异常检测是当前传感器网络安全领域的热点问题。本文针对无线传感器网络异常检测问题开展研究工作,分析了当前传感器网络异常检测领域内的国内外研究成果,并对现有检测技术进行分类、比较与研究,而后提出了一种基于信息熵与K-means的分级式异常检测算法,并以此为基础设计与实现了传感器网络异常检测系统。本文的主要工作如下:1.针对传感器数据异常检测的核心问题,本文提出了一种基于信息熵计算异常概率的单传感器异常检测方法。该方法将单个传感器滑动窗口内的数据值作为离散随机变量计算出信息熵序列,在此基础上结合数据流的数据值变化计算出数据流的异常概率来检测单个传感器的异常。该方法综合利用了单传感器数据流的时间相关性及统计概率特征,与只利用数据距离的检测方法相比,该方法可以更加准确地区分数据的正常和异常变化。2.在基于信息熵的检测方法基础上,结合现有的基于K-means的异常检测方法,本文提出了综合利用基于信息熵的检测技术和K-means聚类检测技术的分级式异常检测算法。该算法先利用异常概率判别法进行先验检测,当先验检测发现传感器可疑异常之后再结合K-means聚类检测算法的结果进一步确认。其中,信息熵既用于传感器异常概率的计算,也作为重要特征参与K-means聚类检测。该分级式算法能够更合理地利用设备资源,充分发挥设备的性能优势,达到检测准确性与效率之间的均衡,并且该算法可以通过分级协作式异常检测模型灵活地应用到传感器网络中。3.根据提出的基于信息熵与K-means的分级式异常检测算法,本文设计实现了一个传感器网络异常检测系统,对该系统的模块划分和模块内部设计进行了详细介绍,通过模拟异常数据测试了该检测系统的可用性。"
861,草本植物浇灌模型及系统的研究与实现,"随着人们生活质量的提高,越来越多的人们会选择在家庭环境中养护草本植物,但是由于长期离家或工作繁忙等原因,很多时候家庭中的植物不能得到合理的浇灌,为了解决这一问题,本课题的目标是,研究一种草本植物浇灌模型,可以根据草本植物的生长环境、品种等因素智能地决策浇水时间并计算浇水量,同时设计并实现一种草本植物浇灌系统,可以在完全自动的条件下为草本植物浇水。本文使用了Arduino平台及相关设备、SpringMVC框架、Flask框架、Mosquitto软件、MySQL数据库以及Android开发技术设计并实现了草本植物浇灌系统,使用了基于模糊理论的时间序列预测模型以及机器学习回归算法研究并实现了草本植物浇灌模型。首先对草本植物浇灌系统进行了需求分析,其中功能性需求包括:用户管理、设备管理、植物管理以及浇灌控制。基于需求分析,对系统进行了概要设计,得出系统架构、部署结构,划分出4个功能模块,得到数据库ER图,然后对各功能模块进行了详细设计,描述了模块处理流程、类的设计以及利用HTTP协议、MQTT协议通信的接口设计,接着详细描述了数据库表的设计。基于系统的设计,完成系统的初步实现,包括利用Arduino平台实现自动浇灌电子设备、使用MySQL数据库实现数据存储、使用SpringMVC框架实现后台服务器完成业务逻辑处理。在此基础上研究草本植物自动浇灌模型,首先进行了实验,利用实验采集的数据训练得到了两种土壤湿度预测模型,分别是基于模糊理论的土壤湿度时间序列预测模型和基于蒸散发量的土壤湿度预测模型,对比分析了这两种模型的预测效果,最终选择更具优势的基于蒸散发量的土壤湿度预测模型作为系统的预测模型,然后根据植物的喜水程度、花盆体积、土质这些因素形成浇灌方案,得到了完整的草本植物自动浇灌模型,可以在无需土壤湿度传感器的条件下为植物自动浇灌。最后,按照系统的设计,结合草本植物自动浇灌模型,完成全部的系统实现,包括实现Android客户端、实现Web客户端以及利用Flask框架实现逻辑控制服务器等,并对系统的四大模块设计了29个测试用例,均通过测试。"
862,成本最小的Spark作业配置优化算法研究,"随着信息社会的飞速发展,并行计算以其在计算速度和计算能力上的强大优势得到业界广泛使用。一系列以MapReduce和Spark为首的分布式计算平台得到了工业界的青睐。然而在实际使用中,由于分布式计算平台中存在的多样而复杂的配置参数,往往容易引发作业性能问题。研究显示,不合理的作业配置可能导致作业性能急剧下降、集群资源利用率降低,甚至引发作业运行失败。在实际应用场景中,由于集群环境的复杂性、Spark集群内部原理的抽象性以及分布式作业本身的复杂性等,作业性能调优是一件依赖于运维人员的长期经验积累且不具有通用规则的事情。Spark拥有巨大的参数空间,其中有多个参数直接影响作业性能。目前,现有的调优方法多是依赖于用户手动调优,该方法缓慢且效率低下,且随着集群规模的不断扩大,该方法的复杂度剧增。本文设计了一个成本最小的Spark作业配置优化算法,并基于此算法实现了Spark作业配置参数的自动调优。本设计提出的优化算法分为Spark作业性能建模和Spark作业配置最优化两大部分。Spark作业性能建模为每一类具有相似资源利用率特征的Spark作业构建了一个基于梯度提升的性能模型。Spark作业配置最优化模型则是基于本文所构建的性能模型,对作业配置参数进行最优化搜索。基于本文提出的Spark作业配置优化模型,本文搭建了一个Spark作业配置自动化优化系统,实现了自动化的配置优化。并且,该系统包含的作业性能监控子系统不断地收集集群的作业信息,用于离线建模,能够不断优化系统的准确性。最后,本文构建了实验测试系统,通过收集基准测试程序以及实验数据集合,对系统进行了实验测试。实验结果的分析表明,本文构建的Spark作业性能模型和配置优化模型能够有效地预测在线作业运行时间,优化作业配置参数,具有一定的实用性。"
863,面向限量弧路由问题的深度神经网络算法研究,"限量弧路由问题(capacitated arc routing problem,简称CARP)是一类有挑战性的复杂组合优化问题,在现实世界中有着广泛的应用,如市政服务、物流运输、城市垃圾回收、电力线路检查、自动引导车路径规划。在过去数十年的研究中,启发式算法被主要用来求解限量弧路由问题。然而,对于给定的一个待求解的限量弧路由问题样例,大多数启发式算法需要从零开始进行迭代搜索来寻找问题的解。这一过程往往非常耗时,因此现有的启发式算法难以被应用到一些需要实时求解的问题场景中。受近几年快速发展的深度学习研究的启发,本文提出了一种全新的范式来求解限量弧路由问题。预先通过大量的问题样例训练得到的深度神经网络模型作为神经求解器。在新的待求解的问题样例上,求解过程将转化为耗时很低的神经求解器的测试过程。对比启发式算法,神经求解器的目标是在允许小幅度损失解的质量的范围内,极大地提高求解速度。本文针对这一目标展开研究,提出了两个不同的CARP神经求解器。本文首先提出了一个基于序列到序列模型和采用监督学习进行训练的神经求解器。问题样例和启发式算法在对应样例上给出的解作为输入和标记值来构造产生每一个训练样本。通过图嵌入和预排序方法,每一个样本中的输入和标记值被构造为两个序列,限量弧路由问题的求解过程即被转化为一个序列到序列(sequence-to-sequence,简称seq2seq)的预测过程。该方法采用一个编码器-解码器模型(encoder-decoder)作为神经求解器来完成序列到序列的映射,并使用监督学习训练这个模型。通过监督学习,启发式算法在历史数据上的求解经验被转移到神经求解器内,在一定程度上保证了解的质量。鉴于有标记的数据在一些场景下难以获得,本文提出了一个基于集合到序列模型和采用强化学习进行训练的神经求解器。强化学习将最大化累积奖励作为训练目标,不需要额外准备有标记的数据。在该方法中,引入图卷积网络(graph convolutional network,简称GCN)模型和两个编码器-解码器模型将限量弧路由问题的求解过程转化为集合到序列(set-to-sequence)的过程。整个模型被参数化为一个生成有效解的策略。通过将执行策略得到的解对应的代价函数值映射为奖励信号,并使用经典的REINFORCE算法优化策略中的参数,神经求解器能够学习到有效地求解方法。实验结果验证了这两种方法在产生的解不明显差于启发式算法的情况下,求解速度可以得到显著的提升。"
864,基于Python的细胞识别SVM模型参数优化方法研究,"在医学诊断领域,细胞图像的自动分类能有效地提高医学诊断的准确率和速率。因此,细胞图像的自动分类是当前学界研究的重点。由于细胞图像存在复杂的高维特性,而SVM作为一种优秀的自动分类算法,能很好地解决图像的高维特性差的问题,因此,在图像分类的实际应用中被广泛采用。实现细胞图像识别分类的关键是构造性能良好的SVM分类器,而选择有效的SVM核函数参数是构造高性能SVM分类器的主要因素。因此,学界将SVM的核函数参数优化问题作为当前研究的重点。近些年来提出许多算法来自动优化SVM核参数,如网格搜索算法、粒子群算法等。在很大程度上实现了细胞图像的自动分类,但是由于这些SVM参数优化算法的计算量过大,参数优化精度未能达到更优,导致SVM建模速度缓慢,识别精度不够高等一些问题的出现。因此本文也从SVM参数优化方法的角度出发,提出一种基于Python的细胞识别SVM模型参数优化方法。该算法主要是结合Python语言的优点编写优化算法和整个细胞识别分类系统功能模块,优化算法是结合变网格搜索法和量子粒子群QPSO的混合算法对SVM的参数进行寻优。先利用变网格搜索法进行参数寻优,由大网格在大区域内搜索参数,缩小参数范围;再由中网格在该确定区域搜索参数,继续缩小参数范围;然后由小网格在该确定区域继续搜索参数,再度缩小参数范围;最后利用量子粒子群QPSO算法对最后确定的区域进行参数寻优,避免了变网格搜索法的寻优参数精度不够和量子粒子群参数寻优的计算量过大且容易陷入局部最优的问题,大大缩短了寻优的时间,提升了SVM参数寻优的效率和精度,对构造高精度的SVM分类器产生了十分重要的作用。利用构造的SVM分类器对细胞图像进行识别,并与传统的几种参数寻优算法构造的SVM分类器的识别精度进行比较,验证本文提出的参数优化方法的有效性。"
865,基于非接触式睡眠监测系统的呼吸暂停综合征检测研究,"睡眠是一个复杂的生理过程,在人的生命活动中扮演着重要的角色。随着经济的快速发展和人们生活水平的日益提高,人们的睡眠时间却在不断的减少,睡眠的质量也在不断地下降。睡眠呼吸暂停综合征是一种常见与睡眠相关的呼吸系统疾病,严重威胁着人们的睡眠健康。睡眠呼吸暂停综合征的检测可以提供关于睡眠的信息,有利于提高人们的睡眠质量。传统的基于多导睡眠图的睡眠呼吸暂停的检测过程中,人们的睡眠可能会受到干扰,检测设备也容易脱落。本文主要研究了一种基于非接触式睡眠监测系统的睡眠呼吸暂停检测方法。该方法首先通过适用于不同人群的心冲击图信号的心率提取算法,得到心跳间期序列。其次,提取固定的时间长度上心跳间期序列的时域特征、频域特征和相似度特征,使用睡眠呼吸暂停的分类模型来判断固定时间长度内是否发生睡眠呼吸暂停。在较少的空间复杂度的条件下,对睡眠呼吸暂停的特征进行选择,睡眠呼吸暂停的检测算法依旧有较好的表现。采用模型融合技术,可以进一步提高睡眠呼吸暂停分类模型检测的灵敏度、特异度和准确率。通过对受试者人体整晚的生理信号进行整体分析,可以检测受试者是否是睡眠呼吸暂停患者。非接触式睡眠监测系统可以在不改变人们的睡眠环境,不干扰睡眠的情况下,完成睡眠呼吸暂停的检测,在居家健康管理领域有广阔的应用前景。"
866,“人工智能”专业教学与实验系统的研究与实现,"人工智能是当前信息技术方面研究的热点话题,2018年4月份教育部印发了《高等学院人工智能创新行动计划》,鼓励高校拓宽人工智能专业的教学,加强人工智能学科建设。由此人工智能必将是未来的战略性技术,对于提升国家的核心竞争力有着重大意义。毫无疑问,人工智能技术的进步需要加强人才的培养,技术的发展实质是人才的发展。目前我国人工智能方面的人才储备不足,作为高校,人才培养是核心任务,因此想要更多培养出社会所需人才不仅需要加强学科建设,更需要结合需求制定一套完善的教学系统。本文通过对在线实验系统的技术及实现原理进行深入研究,设计并实现了在线实验的实现方案,同时对实验部署中的Docker集群调度算法进行探讨,提H了改进型的优化算法。基于以上研究,最终设计并实现一个能够将教学与实验相结合的人工智能学习平台。本文工作主要分为三大部分,第一部分是在线实验系统的研究,包括容器原理、虚拟机技术、Jupyter和VNC远程控制研究,基于研究结果,进行在线实验实现方案的剖析、设计与实现。第二部分是基于Docker Swarm调度算法的研究,提出一种改进型加权调度算法,有效提高节点负载均衡。第三部分是教学与实验系统Web端的设计与实现,包括人工智能专业课程体系管理、教学管理、用户管理模块的设计和实现。系统平台基于Django搭建后端服务模块,通过Bootstrap框架、Jquery等实现Web前端交互,采用Mysql关系型数据库实现元数据及内容存储,提供的相应服务包括:体系管理、课程发布、课程管理、随堂测试、在线实验、用户管理等。经过实践测试使用,本文实现的“人工智能”专业教学与实验系统具备良好的实用性和扩展性。"
867,传送网拓扑构建与规划系统优化研究,"计算机与通信领域的技术变革推动着新兴业务的不断涌现和用户需求的飞速增长,也对传送网提出了越来越高的要求。网络运营商在进行传送网建设时,为了提供更高质量的网络服务以提升自身竞争力,往往需要花费大量的时间和资源进行网络规划。如何有效提升网络规划效率成为运营商的工作重点和难点之一。网络规划是一个受多因素影响的复杂课题,对它的研究涉及到多种领域与学科。对应到实际工程中,网络规划包含拓扑构建、路由安排和设备配置等多个阶段,每个阶段都需要经历反复的评估和修改。其中,拓扑构建是网络规划最主要的工作之一。高效合理的拓扑构建在降低生产成本方面具有巨大的潜力。近年来,拓扑构建研究在诸多方面都取得了显著的成果,为本文的方案设计提供了丰富的模型和理论支撑。但是已有的研究对现网数据资源的挖掘和利用依然存在欠缺并且大多没有与实际的规划系统相结合。本文结合拓扑构建相关研究以及传送网规划设计系统的实际开发经验,借助网络科学与机器学习等领域的理论与工具,提出了一种传送网拓扑构建方案,验证了方案的可行性和有效性,并将方案应用到实际规划系统中,弥补了规划系统在拓扑构建方面的功能欠缺。本文的主要工作内容如下:1、提出了一种传送网拓扑构建方案。本方案包含初始拓扑构建和链路添加两个模块。其中初始拓扑构建模块将拓扑构建过程抽象为节点对分类问题,简化构建流程的同时,充分挖掘利用了现网数据资源,使构建出的初始拓扑贴合实际工程的需要。链路添加模块提出了一种适用于传送网的链路添加算法,以解决拓扑中存在的孤立节点等问题,提升方案对拓扑整体性能的把控能力。2、验证了方案的可行性和有效性。本文通过对比七种常见的分类算法,证明了随机森林算法和梯度提升决策树算法(Gradient Boosting Decision Tree,GBDT算法)均适用于本方案,两种算法平均准确率都达到98.3%以上。同时,方案对训练数据集占比和数据集划分方式没有严格限定,当占比在30%到70%范围内时,均可以保证良好的实验结果,由数据集变化造成的准确率波动则在1%以下。方案的特征提取过程简洁,仅提取节点间距离、Gabriel模型和Geometric模型三种特征时,即可以保证98.0%以上的准确率。除此之外,方案中的链路添加算法可以稳定优化拓扑性能,方案构建出的拓扑与现网实际拓扑相比,APL减少了 17.9%,链路总数则仅为实际拓扑的93.4%,同时还解决了其他类似算法存在的新增链路过长等问题。3、将方案应用到实际规划系统当中,弥补了规划系统在拓扑构建方面的功能欠缺,并通过路由安排实验证明了方案在网络业务承载能力等方面的优化效果。本文通过建立拓扑与网络资源的映射关系,实现了方案与规划系统的对接。并将现网中的实际业务提为排路需求,进行了路由安排实验。实验结果表明,与实际拓扑相比,方案拓扑在链路使用量减少8.8%的前提下,多排通了百条以上的业务路由,并且使平均路由跳数减少了4.0%,以更少的链路数承载了更多的业务量并且保障了更低的路由跳转次数。同时,方案拓扑的业务分布更加紧凑,减少了部分长链路的使用。另外,通过对比加权拓扑图可以发现,方案拓扑与实际拓扑保持了良好的相似度,这意味着方案不仅可以构建出性能更为优秀的传送网拓扑,并且可以保障拓扑在实际工程中的适用性。"
868,基于实测数据的信道特性分析与特征挖掘研究,"随着多天线的应用和发展,通信系统中的天线数目不断增加,同时无线电波的传播特性随着场景、频段和带宽的改变呈现出复杂多样的特点,而且这些特性和规律都隐含在海量的信道测量数据中,仅仅通过传统的数据处理和分析方法难以高效地得到可靠、准确的变化规律。所以,基于大数据思想并利用机器学习方法的信道特性分析与特征挖掘对信道实测数据的分析和规律总结有着重要的价值和意义。本文从信道测量出发,研究信道测量中发射功率对信道测量结果的影响,为信道测量提供指导性建议。同时,本文采集了 5G重要部署场景之一的农村宏蜂窝场景3D-MIMO信道数据,利用传统数据分析方法总结农村宏蜂窝场景特性,并从相关性的角度分析了信道冲激响应的动态范围和信道特性之间的联系。最后,本文基于数据挖掘的思想并结合机器学习方法,提取信道数据中的有效特征,分析信道数据中的潜在规律,并提出了基于神经网络的场景相似度计算方法。本文的主要研究内容包括:1.信道测量中发射功率对信道特性分析的影响在信道测量中由于测量系统发送功率有限,会导致部分多径信号被淹没在噪声中,对信道特性分析造成一定的影响。本文设计了室内热点场景的信道测量方案,利用信道测量平台采集不同发射功率下的信道实测数据。通过平方和误差、时延扩展和信道互信息三个角度对比不同发射功率下的信道特性,发现在测量过程中接收响应的动态范围在20 dB以上时,才能够采集到比较完整的多径信号。2.农村宏蜂窝场景的信道测量与信道特性分析农村宏蜂窝场景是5G的重要部署场景之一,但目前对该场景三维空间信道的测量和研究仍有不足。本文通过信道测量,对3.5 GHz农村场景的3D-MIMO信道特性进行了分析,针对室外视距、室外非视距与室外覆盖室内三种环境给出了包括大尺度、小尺度、参数间相关性的信道分析结果。同时,由于农村宏蜂窝场景中存在较强的绕射情况,本文基于信道冲激响应的动态范围分析了信道特性的变化,并发现了它们之间存在较强的依赖性。3.基于机器学习的特征挖掘研究为了剖析信道冲激响应在不同信道环境下的分布与特点,本文利用机器学习方法挖掘实测数据中的隐含特征。首先,本文通过主成分分析(Principal Component Analysis,PCA)方法对信道冲激响应的时延维度进行降维,提取有效特征。其次,本文利用降维后的有效特征对信道冲激响应进行聚类,并利用前两个重要维度可视化信道冲激响应的分布,分析和总结不同信道环境下的信道特性。最后,本文基于神经网络模型提出信道场景的相似度计算方法,并利用农村宏蜂窝场景数据进行了实验测试。"
869,基于深度学习的语音情感识别建模研究,"随着计算机技术的发展和人工智能的普及,语音情感识别研究收到学界和工业届的广泛关注。目前的情感识别任务大多采用人工提取多种声学特征并物理降维,构建特征工程的方法,提升识别结果。本文旨在探究语音中情感信息的表达,了解语音中情感信息的变与不变,从语音中提炼出情感的本质特征,并搭建最合适的表征情感信息的网络结构。基于以上研究重点,本文内容包括以下几个部分:1.研究了基于传统声学特征的情感识别网络在大量的声学特征中,对现有数据做统计分析筛选出声学特征及其统计特征,搭建有效且完备的情感特征工程。从物理意义上出发,筛选合理的表达情感的特征并验证它们的有效性;从数学统计层面考虑,使用卡方检验做特征选择,去除特征集合的冗余信息,提高网络训练效率,构建完备的特征工程。2.研究了基于语谱图的深度学习情感识别网络语谱图几乎包含了所有的语音特征,二维频谱结构既可以体现谐波等激励源特征,又可以分析倒谱、共振峰等声道特性。深度神经网络引入非线性信息,具有自主学习输入数据特征的优点。搭建基于语谱图的深度学习情感识别网络,选用局部感知和跳跃连接的ResNet网络,并基于卷积核权重系数做出改进。再此基础上,搭建ResNet-LSTM网络,对ResNet网络学出的高层情感特征进行时序建模。3.引入了注意力机制,研究了低级描述符和高层语义信息的特征融合将经过验证的可以表征情感信息的声学特征集合作,与ResNet-LSTM网络学习到的语音信号的高层语义信息进行融合,将融合后的特征经过DN-N网络分类输出,增加深度学习的解释性和人工辅助。此外,引入注意力机制,探索语音中的关键帧信息。将学习到的注意力作为权重系数加入到人工提取的低级描述符特征中,并将它应用于特征融合实验。本文主要从情感的产生和感知层面出发,落实到特征和网络两个研究重点上展开工作,产生上探究如何构建具有情感表征意义的完备的特征集合,感知上从网络结构入手,尝试搭建具有情感认知的网络结构,并通过注意力机制讨论语音情感的局部关键性,结合产生、感知、和局部特性探讨语音情感的表达。"
870,基于深度学习的多基频提取研究,"多基频提取是指提取多音音乐中的基频。多音音乐是指同一时刻有多个音源的音乐[1]。如果多音音乐的音源是人声音乐和其它乐器音乐的混合音乐,提取人声音乐的旋律,即人声音乐的基频轮廓曲线,称之为主旋律提取(Melody Extraction)。如果多音音乐的音源是同一个乐器的不同琴弦或按键发出的,需要将这样的多音音乐自动转化成曲谱,称之为自动音符转写(Music Transcription)。本论文以主旋律提取和自动音符转写这两个实际应用来研究多基频提取。主要工作包括:1、提出了基于深度谐波网络(DHNN)的主旋律提取算法。针对多音音乐复杂的谐波特性,利用了分谐波叠加的思想[2],将主旋律提取看作是一个多分类问题,基于深度神经网络,借鉴了 Sangeun Kum的网络结构[3][4],提出了深度谐波网络DHNN。本论文通过改变原始频谱的结构信息,只将与候选基频相关的对应频率点及其谐波相关特征输入网络,赋予DHNN谐波结构的先验信息,相当于在深度神经网络的基础上加入了谐波特性的先验信息。本论文实现了 LSTM和Resnet两种方式的深度谐波网络。以MIREX-1K数据集的80%数据做训练,剩下20%做测试,同时将训练的模型在mirex05数据集上做迁移测试,在关键指标overall accuracy上达到了 state-of-the-art的结果,比Dressler的结果提升了 4个百分点。2、提出了改进的DHNN音符转写算法。自动音符转写(AMT)的主要任务是将乐器弹奏的音乐自动转化为对应的音符,AMT分为多基频提取(Multi-pitch Extraction)和Note Tracking两个部分[5]。因为同一时刻可能存在多个音符,因此本论文将AMT的多基频提取看作是一个多标签分类问题,每一时刻最多存在88个音符,每个音符都分别建立一个二分类网络。因为频移不变性,相邻音符的谐波网络共享网络参数。与主旋律提取类似,引入深度谐波网络(DHNN),赋予了深度网络的谐波特性处理多音音乐复杂的谐波结构。考虑到音频频谱的两个维度表示的意义不一样,DHNN用一种特殊的一维卷积highway network去实现,而不是更常用的二维卷积。同时引入attention机制去提取有用的关键帧,并且引入竞争网络机制解决八度错误。实验表明,多基频提取的输出结果基于帧判决在MAPS数据库上得到的F-measure值达到了 0.8134,比Siddharth(state of the art)的结果高出了 10%[6]。借鉴了轮廓线算法[7],提出了一种启发式的Note Tracking轮廓线提取算法,得到的F-measure值为0.6970。"
871,基于大数据的C-RAN无线资源管理,"目前,无线通信技术正在高速发展,无线通信的应用越来越频繁,无线接入设备越来越多,人们对通信质量的要求也越来越高。伴随着这些巨大的变化,整个社会都期待未来的无线网络能够有更加广阔的分布、更加低廉的价格和更加优质的服务。云无线接入网(Cloud-Radio Access Networks,C-RAN)正是为了解决未来无线通信领域的诸多需求提出。C-RAN的集中式管理带给网络更多的可能性,因为集中式管理会带来大量的无线信息数据,而海量的数据则带来了新的机遇。本文的主要工作如下:第一,研究了C-RAN网络下的信干噪比(Signal to Interference plus Noise Ratio,SINR)预测。基于C-RAN网络架构进行数据分析,验证了神经网络算法通过用户占用情况预测用户上行SINR的可能性和有效性。第二,提出了一种加速SINR预测收敛的调度算法。首先,本文提出一种检测用户之间干扰预测准确性的方法,该方法利用神经网络单用户干扰场景下上行SINR预测结果的收敛波动,筛选出各个用户干扰预测不准确的干扰用户。在识别出干扰预测不准确的用户后,通过本文提出的以提高用户上行SINR预测收敛速度为目标的用户调度策略进行用户调度,优先调度预测不准确的用户,有效减少了训练集样本数据量的需求,加速了上行SINR预测收敛。经仿真验证,算法可以有效提高上行SINR预测收敛速度。第三,搭建了用于验证以上算法的仿真平台。本文搭建的仿真平台是系统级动态仿真平台,具有动态性,可以模拟网络中的真实场景。本文搭建的仿真平台可以仿真用户、家庭基站和宏基站三种基本的网络节点,在数据传输过程中,可以根据同频干扰、快衰落和路损计算SINR。本文搭建的仿真平台还支持混合自动重传功能(Hybrid Automatic Repeat Request,HARQ),并且集成了常规的最大载干比算法、轮询算法和比例公平算法。在长期演进(Long Term Evolution,LTE)网络仿真功能的前提下,本文搭建的仿真平台增加了C-RAN相关的模块,主要是用来数据储存和机器学习实现对网络数据的集中存储和对网络行为的集中控制。"
872,基于机器学习的资产类商品估值系统的设计与实现,"改革开放以来我国市场经济飞速发展,资产类商品空前繁荣,房地产作为最重要的资产类商品之一发展迅速。随着我国税制改革的不断推进,房地产税费即将全面征收之际,实现对房产的快速、准确、自动化估值有重要意义。本研究参考大量国内外文献和最新的研究发展趋势,针对房屋自动化估值系统中存在的对非结构化数据挖掘不充分、回归模型单一的状况,提出了基于机器学习的资产类商品估值系统的设计与实现解决方案。分别完成了基于迁移学习的户型图分类研究和基于选择性集成学习的房屋估值模型研究。本文完成的工作主要包括:(1)基于迁移学习的户型图特征提取研究。户型图等非结构化数据中隐藏着大量高价值信息,本文提出了基于迁移学习的户型图特征提取方案:包括墙体线分割算法、墙体线降噪算法在内的户型图预处理方案;VGGNet-16(Visual Geometry Group Net-16)迁移学习ImageNet数据集的权值参数,提取户型图特征方案。(2)基于栈式自编码器的数据降维和基于多层感知器的户型分类研究。户型图的特征向量维度过高不便直接处理,需要对数据进行有效降维。本文设计栈式自编码器对户型图的特征向量实现降维,降维后可以用较少的500维高维特征简洁的表示户型图25088维的特征向量;此外设计4层感知器在户型图数据集上完成户型分类任务,可将户型准确分成6类,精度达到0.894。(3)基于选择性集成学习的房屋估值模型研究。传统的回归模型拟合效果难以继续提升,而模型融合可以继续提升拟合结果。选择性集成学习保持了集成学习的优点,在融合多种个体学习器的同时,还可以通过调节权值,筛选出最合适的个体学习器。本文提出基于选择性集成学习的房屋估值模型,在融合岭回归、随机森林、分解因子机、XGBoost等4种回归模型的基础上,组合出集成模型。该模型在数据集上的均方根误差(Root Mean Square Error,RMSE)稳定在0.0959,证明模型融合有效。"
873,跨媒体话题检测与观点分析研究,"近年来,社交网站中图片及视频爆炸式的增长,当今的互联网呈现跨媒体的趋势。跨媒体数据指多个社交网站中多种模态的数据,它们之间的底层表现异构性,给跨媒体数据语义关联的挖掘带来困难。且由于社交网站是人们获取并讨论热点话题的聚集地,面向社交网站“话题”分析的跨媒体话题检测与观点分析成为舆情分析领域的重要研究课题。但现有研究几乎没有专门针对多个社交网站且多种模态数据的,未能准确抓住跨媒体数据的特点,导致研究结果的片面性。因此,本课题对跨媒体数据的话题检测和观点分析进行研究。该研究课题依托于北京市教育委员会的科学研究与研究生培养共建的科研项目――基于社交感知的跨媒体数据分析与挖掘研究。本论文旨在通过这两个研究,对社交网站上的热门话题进行深入的舆情分析,主要的研究内容和创新成果如下:1.针对跨媒体数据的表现形式异构导致无法直接关联计算的问题,提出了一个基于图的方法对跨媒体数据进行融合的框架,并提出利用社交网站特有的标签信息增强数据相似性的关联。通过采用图的方法,实现有效的将跨媒体数据融合到一个图中;通过借助标签信息作为连接不同社交网站的纽带,实现消除跨媒体数据表现形式异构特点带来的问题。实验表明该方法能够有效提高跨媒体话题检测的性能。2.针对现如今社交网站上跨媒体数据表示多样化且噪声大导致文本观点分析方法结果片面的问题,本研究提出了一个跨媒体观点分析方法,通过利用跨媒体数据之间的相互依赖,分别从文本和视频的角度对社交网站中的观点进行分析,实现有效的判别和控制网络舆情的效果。另外,针对话题相关言论存在大量背景信息从而影响观点聚类效果的问题,提出一个去背景信息的主题模型,该模型通过将词语分为背景词和观点词,实现有效抑制背景词给聚类效果带来的不良影响,在真实数据集上的实验表明该方法的有效性。"
874,基于主题和敏感数据流的Android恶意应用检测方法研究,"Android操作系统的开放性以及繁杂的第三方应用市场使得恶意应用数量爆炸性增长,这些恶意应用给用户带来了严重的经济损失和隐私泄露问题。因此,Android恶意应用检测方法的研究非常重要。传统的Android恶意应用检测方法主要通过研究分析利用静态或动态手段从应用程序中提取的语法特征来检测恶意应用,因为这些语法特征可以从一定程度上反映应用程序的行为。然而,应用程序的行为与其功能息息相关,相同的行为在某些应用中是恶意的,但在特定的功能的应用中却可能是正常的。因此,分析应用程序安全问题时应当将其功能和语法特征都纳入考量范围。本文正是以此为出发点,充分考虑应用程序功能和行为间的联系,提出了一种基于主题和敏感数据流的恶意应用检测方法。本文的具体工作如下:1、提出一种基于自然语言处理的Android应用程序功能分类方法。利用应用程序的描述信息,通过主题建模算法抽象出其中的主题。然后根据应用程序对各主题的相关度对应用进行聚类分析,实现对应用程序的功能分类,为后续的恶意应用检测提供前提条件。2、提出一种基于敏感数据流异常分析的特征抽象方法。通过静态分析的方法提取更能代表应用程序行为的敏感数据流信息。以此为基础,结合应用程序所申请的敏感权限,通过异常分析算法对同一主题类别中的应用程序进行敏感数据流异常分析,抽象出异常值特征向量。该特征向量反映了应用程序在各权限下敏感数据流的异常程度,可以指导研究人员发现潜在的安全问题或者告知用户可能存在潜在风险。此外,异常值特征向量也可以用来训练分类模型以检测恶意应用。3、综合考虑应用程序的功能用途和敏感数据流特征,提出并实现一个基于主题和敏感数据流的Android恶意应用程序检测系统。通过在1 145 1个应用程序样本上进行实验,选取了五种机器学习分类算法中最适合本文方法的算法――随机森林,并进行多组对比实验证明本文所提出的恶意应用检测方法的有效性。除此之外,本文还对几个主题类别内正常应用和恶意应用的敏感数据流进行宏观分析,进一步验证通过结合应用程序功能和敏感数据流来检测Android恶意应用程序方法的合理性。最终,根据本文方法所训练的检测模型取得了不错的效果:整体应用分类正确率到达了98.67%,恶意应用程序识别率达到了98.76%。"
875,基于机器学习的触觉手势识别及身份认证研究,"触屏智能手机的广泛使用导致访问敏感和隐私数据日益增加,从而引起了人们对安全和可用身份认证技术的需求。身份认证的目的是鉴别通信过程中另一端的真实身份,以防止假冒和伪造。基于生物特征的识别技术逐渐取代了传统的身份认证方法,成为新型的身份认证技术。生物特征识别技术是利用人体特有的行为和生理特征,通过模式识别和图像处理的方法进行身份识别的。人的生物特征具有稳定性和唯一性,生物特征识别技术由于保密、不易遗忘、不易被盗等优点,具有广阔的应用前景和市场潜力。生物特征信息的存储安全问题和认证算法的安全性问题等,是现在生物识别技术研究的关键。本文主要研究生物特征中的触觉手势,提出了合适的身份识别算法并且通过矩阵压力传感器进行了系统实现。论文首先对生物识别技术的国内外发展现状进行了总结,然后分析了多用户触觉手势笔划特征,根据这些特征探究了触觉手势识别技术;接着研究热点机器学习算法,使用多种机器学习算法针对Touchalytics触觉手势数据集和UMD主动身份认证(UMDAA)数据集进行了一系列研究实验,最后是系统实现和验证。本文的主要创新点有:(1)对Touchalytics数据集和UMDAA数据集的触觉手势进行了分析,使用MATLAB软件对数据集进行数据预处理,剔除部分错误数据,减少噪声影响,使数据集更加完美。对于每种常见类型的触摸操作,提取并分析静态和动态特征,对用户的触摸行为进行了细粒度表征,之后将特征组合进行分类。(2)在综合研究热点机器学习算法的基础上,利用改进的极限学习机(ELM)算法,针对Touchalytics触觉手势数据集和UMD主动身份认证(UMDAA)数据集,实现了触觉手势识别和身份认证。(3)使用柔性矩阵纺织压力传感器,基于Arduino平台,采集了不同用户的7种触觉信息,验证了改进的极限学习机(ELM)算法。"
876,基于深度学习的印刷蒙古文字体分类与单词图像超分辨率研究,"近年来,随着数字化技术的飞速发展,大量印刷蒙古文文献资源(图书、期刊、杂志等)可以通过采用当下广泛流行的技术――光学字符识别(Optical Character Recognition,OCR),将其转换为相应的电子文档,但在转换过程中会遇到以下两方面问题。第一,现有的印刷蒙古文OCR系统采用基于字元切分的方法对蒙古文单词进行识别,但某些字体下的蒙古文单词很难被准确切分成字元,导致单词无法识别。此外,蒙古文独特的构词方式导致其词汇量巨大(词汇量达数百万),并且文档中多种字体混排的现象普遍存在,这使得训练一个能够识别多种蒙古文字体、大词汇量的整词识别系统的时间代价过高。因此,如果能够确定待识别单词所属字体,可事先为每种字体单独构建各自的整词识别系统,从而有效解决上述问题。第二,某些情况下采集得到的印刷蒙古文文档图像分辨率过低,这将导致文档中各单词图像无法被蒙古文OCR系统有效识别。因此,有必要针对低分辨率图像进行重建,以生成能够被有效识别的高分辨率图像。针对第一个问题,本文以印刷蒙古文单词图像为对象,将字体分类看成是一种特殊的图像分类任务,提出了基于卷积神经网络(Convolutional Neural Network,CNN)的蒙古文字体分类方法,即:蒙古文单词图像作为卷积神经网络的输入,相应蒙古文字体类别作为类标号。根据蒙古文构词方式及其书写特点,本文设计了一种浅层CNN网络结构,在相关数据集上与三种经典CNN网络(包括:LeNet-5、AlexNet和GoogLeNet)进行对比。实验结果表明本文所设计的CNN网络结构的性能优于LeNet-5和AlexNet,并能够达到与GoogLeNet相同的性能,但其网络结构更浅、参数更少,因此本文所设计的CNN网络结构能够有效解决印刷蒙古文字体分类问题。针对第二个问题,本文以低分辨率印刷蒙古文单词图像为对象,采用深度递归卷积网络(Deeply-Recursive Convolutional Network,DRCN)模型对低分辨率单词图像进行重建,得到相应的高分辨率单词图像。在相关数据集上,本文采用的DRCN模型与传统插值算法(临近点插值法、双线性插值法和双三次插值法)进行对比。实验结果表明DRCN模型能够有效重构出高分辨率的蒙古文单词图像,从而解决单词图像的超分辨率问题。"
877,Web应用中的异常HTTP流量与后门检测,"Web服务由于其高度可用性和便利性,已经成为越来越多信息服务的主要提供方式。Web应用规模的快速增长带来便利的同时,数据和用户信息也成为不法分子获利的目标。如何做好安全防护,保障网络和系统的运行稳定,成为服务提供者和安全公司必须解决的问题。入侵检测技术在服务运行过程中通过主动的旁路分析实现对网络攻击行为的实时检测,成为当前Web应用的主要防护手段之一。广泛使用的误用检测技术在当前大规模数据环境下已经无法满足性能需求,并且随着攻击手段的日益丰富,规则的维护难度急剧增大。应用机器学习算法进行异常检测具有识别未知攻击的优势,逐渐成为很多安全解决方案的一部分。本文的研究内容从Web应用中的异常HTTP请求流量检测和Webshell样本识别两个问题展开,具体工作如下:1.由于白名单的存在和规则库不完整,现有的规则过滤只能得到标签准确的异常训练数据,本文采用PU学习方法检测异常HTTP请求。针对高带宽网络环境下流量数据包采集的性能瓶颈,设计应用DPDK的旁路数据采集模块,实现零拷贝数据抓包。在数据包捕获的性能测试中,10G带宽环境下DPDK可以捕获全量数据包。异常检测通过集成算法Bagging优化PU学习两阶段方法中的样本选择过程,选取高可信度的正常HTTP请求数据训练模型。通过真实场景数据实验表明PU学习方法能有效提高异常HTTP请求的检测效果,本文方法的检测召回率为99.47%,与无样本选择直接训练相比,模型的F1值提高了3.9%。2.针对传统模型分词处理维度过高和无法处理袋外词特征两个问题,设计了一种基于深度学习的字符级Webshell样本识别模型。模型接受样本的字符编码输入,在嵌入层映射转化为实值矩阵,通过卷积层学习局部词级特征,循环层提取长序列上下文关联特征。为了突出高贡献特征,引入注意力机制优化特征权重,得到更准确的样本表示。在无需输入预处理的情况下,本文模型取得了较好的检测效果,对Webshell样本的检测召回率为98.86%,整体检测准确率为98.4%。"
878,组织中的用户行为和身份识别,"行为识别旨在通过行为数据识别组织中的用户行为和构建用户的身份标识。在海量的数据面前,传统的基于正则式匹配的行为检测方法难以实施;而机器学习模型,也面临行为数据分散、数据集之间关联困难、环境影响严重等问题。我们在多种机器学习方法中引入了以权限为核心的影响因子,提出了一种资产评估方法和两种具有应用前景的模型,有效地提高了行为检测的准确性和时间性能。本文的主要贡献如下:1.提出了一个基于企业数据的资产评估方法。在所调研的企业中,其数据收集和存储都是分散的。不同业务组之间的需求分析都是通过业务线达到的。我们在此基础上提出了以人为主体的构想,把所有的资产规约到不同的角色,得到对应的资产分布,然后通过不同角色之间的资产量化其权限。这种评估方法得到的权限分布为后续权限分析提供了帮助。2.提出了动态构建RBAC模型的方案。在模型生成的角色控制列表上,给出了最小权限组生成算法,把权限类似的角色分为同一最小权限组。基于最小权限组,通过集成算法stacking融合了三个分类模型NB、ID3和SVM。在对比实验中,分析了不同模型的准确度和时间性能。实验结果表明,我们提出的集成学习方法在不增加时间消耗的前提下,准确度能提高近6%。并且对于传统模型,最小权限组方法能在提高4%准确度的前提下,提高14%的时间性能。3.提出了一个基于最小权限组的数据引力模型。标准数据引力模型根据数据之间的差异,判别其相互作用力大小,从而判断数据之间的关联性。为了进一步关联到用户行为数据,我们修改了数据距离公式和引力加成方式,而后,通过引入最小权限组,将引力范围限定在组员内部,最终,通过质量加权平均,得到测试数据标签。实验结果表明,我们提出的模型识别准确度仅仅比集成学习方法低一个百分点,并且在理论上还可以通过提高机器性能进一步提升。"
879,基于Spark的易制毒化学品数据分析系统的设计与实现,"现有的《易制毒化学品信息监管系统》每天产生大量交易申报记录,传统的集中式数据分析方式无法适应于实时分析需求,存在分析结论有限、时间延迟高等问题。全面应用大数据的相关技术和资源,是提升监管部门监管能力的有效手段,有助于监管部门全面搜集与应用易制毒化学品交易数据,为精确的掌握市场的动态需求提供了可能。本文针对易制毒化学品海量数据实时处理问题和行业内对于易制毒化学品价格预测的实际需求,设计并实现了一套基于Spark的数据分析系统,该系统即可以根据实时交易数据对易制毒化学品的交易情况进行实时分析;也能够对易制毒化学品的价格进行短期预测。采用大数据生态圈内的较为流行的技术方案如Kafka,Flume等,降低了系统开发和维护的复杂性,为进一步的业务拓展奠定了基础。本文主要工作如下:(1)设计并实现了基于Spark的《易制毒化学品数据分析系统》,主要包括ETL模块、数据分析模块和可视化模块。能够对来自多省市的易制毒化学品交易数据进行实时采集,对采集来的数据进行清洗、统计、存储等工作,方便用户查询易制毒化学品实时交易情况。(2)针对易制毒化学品业务中可能存在的实时数据流峰值情况,结合反压机制,对数据流批次间隔的调整提出了优化策略,解决了短时负载高峰导致系统延迟过高的问题。(3)针对企业和监管部门希望能够对易制毒化学品的价格进行短期预测的实际需求,本文应用Spark ML机器学习库,对常用的三种回归分析算法进行了实验,并对结果进行了对比,以均方误差为评价指标,选取了保序回归算法为本系统价格预测的算法。"
880,基于特征融合的立体视觉显著性检测研究,"计算机视觉的目标是正确的理解给定图像或者视频的内容,为此,首先需要确定图像主要目标的位置,这个问题就是图像显著性方向所研究的内容。图像显著性的研究最初通过简单的滤波以及方向颜色等特对人类注视进行模拟,这类利用传统手工特征进行显著性检测的方法已经在公开数据集上取得了较好的成绩。随着深度学习的发展,尤其是深度学习在各类图像识别比赛中逐渐超过人类识别分辨率,深度学习模型提取的大量特征被广泛的利用在包括图像显著性方向的计算机视觉领域。同时,当前立体视觉多媒体设备呈不断增长的趋势,针对立体图像的算法也不断被开发,立体视觉显著性检测作为一个基础的算法处理步骤,也受到了更多的关注。当前已经提出了部分立体视觉显著性检测算法,但仍然存在很多的问题。比如,这些显著性检测方法无法平衡各种特征,检测速度过慢,另外在深度信息的利用上研究还处于起步阶段。针对这些问题,本文尝试利用更为综合、统一的方法检测显著性。在算法设计时尽量使深度信息与颜色信息作为一个整体进行处理,充分利用各个通道之间的关联关系。另外,本文建立了多个端到端的立体视觉深度学习模型,这些模型利用了图像分类的深度学习模型权重作为预训练权重,保证了显著性检测时可以获得充分的图像特征。本文提出的四个模型在多个立体视觉显著性公开数据集中进行了测试,测试结果显示提出的双通道深度学习模型以及编码译码网络模型在CC以及KLDiv指标上超过现有算法0.1以上,其他指标也优于现有方法。提出的四元数频域手工特征方法,在各项评价指标上超过了现有的手工特征方法。而参数共享深度学习模型在KLdiv指标上优于现有算法0.1以上,在CC以及KLDiv指标上同样优于现有算法,仅在NUS数据库中的AUC评价指标上相较最适应方法相差0.055,在NCTU数据库中该指标差距在0.003以内。"
881,轴承声发射信号的特征识别研究,"滚动轴承是旋转机械结构中最基础、最核心的部件,同时也是最容易损坏和失效的零件,因此保证滚动轴承的正常运行是旋转机械安全工作的一个重要环节。声发射检测技术相比其它无损检测技术可以及时的检测出滚动轴承的早期微弱故障,并且能实时监测故障的萌生及发展过程,具有较高的安全性和可靠性。在大数据与人工智能时代背景下,传统人工的信号分析处理技术已经无法满足智能一体化大型机械设备故障诊断的需求。因此针对滚动轴承声发射信号智能识别与故障诊断的研究具有非常重要的现实意义。本文分析了声发射信号产生的原理和声发射信号参数的物理意义,并以滚动轴承原始声发射信号数据为基础,深入学习和研究循环神经网络模型特点与性能,构建了双向长短时记忆网络模型方法,充分挖掘出滚动轴承处于不同故障下原始数据的本质特征与深层次映射关系,避免了依赖复杂的数据处理技术与信号分析技术提取和选择故障特征,端对端的完成了滚动轴承故障声发射信号特征的自适应提取与智能诊断。同时探究了双向长短时记忆网络模型在变工况下对故障声发射信号特征的识别性能。从不同工况下声发射信号分布特征的特点出发,引入了迁移学习与双向长短时记忆网络相结合的方法,打破了传统机器学习方法的训练集与测试集必须满足独立同分布的要求,摆脱了对先验故障数据的过分依赖,可完成多种类型工况下各种故障类型声发射信号的识别,并且大大的缩短了故障识别时间和减小了计算成本,使基于声发射检测技术的滚动轴承故障实时在线监测成为可能。设计了基于声发射检测技术的滚动轴承故障在线监测软件,从软件开发技术角度和实际监测功能需求出发,整个软件系统共设计了声发射信号采集模块、数据导入与处理模块、模型功能选择与训练模块,及实时监测评估与报警模块等四种功能模块。最后,对软件系统及各大模块功能进行多次实验测试并进行不断的改进与优化,实验结果表明,软件系统可长期稳定的对滚动轴承运行状态进行实时在线监测,并完成相应运行状态的识别与诊断任务。"
882,基于机器学习的车联网移动性管理研究,"随着车辆数量的不断增多,针对车联网中移动性管理的需求也越来越迫切。移动通信的快速发展使车联网系统得到了更好的网络和技术支持保障,智能交通系统的实现更进一步。车联网中移动性管理研究可以优化城市车联网中基础网络设备的建设部署,降低交通拥堵,提高用户的通信服务体验,为无人驾驶平台提供技术支持,给智能交通系统的实现带来更多的助力。传统的车联网移动性管理基于移动IP(The mobility-enable protocol for the Internet,Mobile IP)进行管理,大数据时代的来临为研究带来了新的思路。本文基于实际的车辆数据进行车联网移动性管理研究,旨在通过车辆数据的特征分析以及预测等建模方法,实现高效的车联网移动性管理方案,满足智能交通中网络设计需求。本文的主要工作及成果如下:(1)基于车辆密度数据特征的路边单元优化部署研究:在车联网的V2I(Vehicle-to-Infrastructure,车辆到基础设施)中网络系统通信能力与路边单元等基础设施的部署密切相关,其部署影响网络可靠性和信息交换。本研究方案基于北京市出租车实际轨迹数据,首先根据道路拓扑和车辆密度数据得到部署路边单元的候选位置点,然后采用分支定界算法有效解决了时延和部署成本需求多目标优化问题。仿真结果表明本方案在路边单元半径为100米时,节省了约50%的部署成本。(2)基于车辆轨迹数据的车辆个体移动性预测研究:针对车辆移动性预测问题建模为多分类问题,采用经典机器学习算法(随机森林、Adaboost、GBDT、SVM)进行求解车辆移动性预测的准确度,并与传统马尔可夫过程建模方法进行对比。仿真结果表明随机森林的效果最佳,测试集的预测准确度可以达到83%。文中进一步基于随机森林的随机选取特征,引进数据特征知识的重要性加权改进随机森林算法中选取特征和样本集的方法,准确率可以稳定提高1.2%以上。(3)基于车辆数据的车联移动性管理研究:针对道路高峰期车辆的拥堵和高密度聚集导致的通信连接中断率高的问题,设计基于贪婪算法的车辆接入方式管理方案。依据中断概率阈值,通过贪婪算法将一些车辆节点设置为移动中继接入方式进行发送数据,结果降低约25%的中断概率。接着针对自动驾驶车辆应用场景中车辆动力补给问题,基于车辆的历史轨迹结合道路和数据的时间空间特征进行分析,使用DBSCAN聚类算法获得合理的动力补给点的位置,实验结果表明仅需要设置65处便可以达到0.54的覆盖率。"
883,基于运动传感器的车辆行驶状态识别技术研究,"基于机器学习的车辆状态识别技术可以更有效的辅助驾驶人员安全驾驶,降低交通事故率,未来可以为实时监测车辆行驶状态,实现安全自动驾驶提供更好的处理方式。本文利用可装载在车辆上的MPU-6500传感器采集车辆加速度、角速度等姿态数据,利用机器学习算法对车辆行驶状态进行识别。本文主要研究内容如下:为了挖掘出传感器数据的更多特征,本文利用小波时频分析Mallat算法对原始传感器信号进行了多级分解。原始信号被分解为近似系数和多个细节系数。本文分析了信号的时频特征,进而提取了分解系数的细粒度特征,与原始数据信号的粗粒度的时域、频域特征融合作为机器学习算法输入的特征向量。最后,用集成学习算法进行了特征分析与选择,实验结果验证了细粒度特征的有效性。为了解决数据采集过程中,只能使用少量标签样本,而大量未标记样本需要人为标记耗时的问题,本文提出了基于半监督学习算法的扩充训练集策略,结合半监督学习Co-Forest算法和主动学习QBC(Query by committee)算法选择未标记样本。将未标记样本划分为白(可信度高)、灰、黑度(可信度低)三等级样本,在迭代过程中根据聚类假设执行黑度样本的标签选择。充分利用了灰度和黑度样本,最终优化了未标记样本的选择策略,实验结果表明改进的算法识别准确率高于Co-Forest算法。最后,为了使车辆状态识别技术更有效地应用于实时性较高的真实场景,本文提出基于增量更新模型的识别算法,利用在线随机森林算法对数据分布发生变化的数据流进行预测并实时更新模型,实验结果表明,在线随机森林模型的训练效果优于离线随机森林,它可以用于识别真实场景中的时变车辆状态数据流。"
884,基于深度学习的车辆驾驶状态识别算法研究,"车辆驾驶行为识别(Vehicle Driving Behavior Recognition,VDBR)是车辆驾驶和交通安全研究领域具有基础性和挑战性的问题。考虑到复杂多样的路段(高速公路,城市道路,乡村道路等)以及驾驶员驾驶习惯的差异,难以准确、实时地分析和识别驾驶行为信息。车辆驾驶行为识别的主要方法之一是基于惯性传感器数据进行分类和识别。大多研究采用了内置传感器的智能手机作为数据源。虽然使用智能手机作为数据源更加灵活,但是数据干扰会更多。相应地,另一些研究则采用了专用独立传感器,大多研究者使用统计机器学习方法,例如SVM(Support Vector Machine)、KNN(k-Nearest Neighbor)、HMM(Hidden Markov Model)等算法进行分类识别,很少有研究使用深度学习方案解决此问题。与统计机器学习算法相比,基于深度神经网络的方法可以有效提高识别精度。然而,运动传感器采集的数据具有特殊的关联特性,目前还没有学者提出专门的深度神经网络用以解决识别精度的问题。本文提出了一种基于六轴惯性传感器的车辆驾驶行为识别解决方案。该方法使用由板载运动传感器收集的样本数据,通过深度学习算法进行分类识别。论文主要贡献为:(1)为了解决样本量小,模型容易产生过度拟合的问题,本文提出了一种基于惯性传感器时序数据的联合数据增强(Joined Data Augmentation,JDA)方案,包括三个子算法:多轴加权融合(Multi-Axis Weighted Fusion,MAWF)算法,背景噪声融合(Background Noise Fusion,BNF)算法,和随机裁剪(Random Cropping,RC)算法,以构建更符合复杂实际驾驶环境的样本数据集。(2)通过对车辆驾驶样本数据特征分析,提出一种可应用于深度学习的特征构造算法,该特征构造方法提升了原始输入特征的维度,提供了更多初始特征,提高了数据集的特征表达能力,减小解决方案对模型非线性的依赖程度,进而提高模型准确率。(3)提出一种新型神经网络架构:多视角卷积神经网络(Multi-View Convolutional Neural Networks,MV-CNN),实现对输入张量进行多维度的特征提取,充分采集张量的时空特性。对比传统卷积神经网络模型,信息传播的方向得到改善,可以更好的用于驾驶行为的训练,学习和识别。评估结果表明,数据增强方案增加了数据集样本数量,并使样本更加均衡。特征构造方案,减弱了分类效果对模型非线性的依赖程度,提升了准确率,MV-CNN网络结构由于引入了多视角卷积方案,充分提取了数据的时空特性。从实验结果可以看出,MV-CNN有挖掘数据潜在特征的能力。该方案的预测精度可达95.29%,高于经典模型。同时,该方案具有更好的泛化能力,减少了训练方差和偏差,提高了模型训练过程的稳定性。"
885,基于卷积神经网络的X射线图像骨龄自动预测方法研究,"骨龄是生物学年龄主要判定标准之一,它能准确地反应被测试者生长发育情况。但是,人工估测骨龄耗时长且结果波动大,严重依赖于放射科医生的熟练程度。因此,通过计算机视觉技术来辅助实现骨龄的自动预测是很有必要的,是医学图像领域的研究热点之一。基于传统机器学习算法的骨龄自动/半自动预测方法主要是通过分割关键区域和手动提取特征来实现骨龄评估的,但其预测准确度严重依赖于分割的精度和提取到的特征的有效性。基于深度学习的骨龄预测系统则很好地解决了上述问题,BoNet首次将深度学习运用到骨龄预测中,它端到端地从数据中学习提取特征,不需要分割关注区域和手动提取手骨图像的特征,引起了研究人员的广泛关注。本文主要提出了一个手骨X射线图像骨龄全自动预测的方法。首先,本研究提出了一个基于密集连接的骨龄预测卷积神经网络模型BoNet+,同时,研究了不同代价函数在骨龄预测问题中的表现,发现平均绝对误差函数更加适合做骨龄自动预测问题的代价函数。实验结果表明,本文提出的BoNet+模型预测误差为0.76±0.10岁,相较于基于传统机器学习算法的骨龄预测方法,误差降低58.2%,相较于基于VGG的卷积神经网络模型BoNet,降低了3.8%。但其复杂度远低于BoNet,单次训练速度为BoNet的8倍,网络参数量为BoNet的25%。紧接着,考虑到在现实场景可能存在低质量的X射线图像,本文模拟了高泊松噪声、有标签遮挡和低分辨率三种类型的低质量X射线图像。为了减弱图像质量对骨龄预测的不良影响,提出可以使用基于U-Net的卷积神经网络对低质量图像进行质量提升。根据是否对低质量图像的类型首先进行分类再进行提升,本文将真实场景下的骨龄预测系统分为两种。实验结果表明,无论是否对图像进行有针对性的质量提升还是统一进行提升,两者的预测精度相近。为了解释这一现象,本文提出:如果设计的卷积神经网络模型层数够深且层宽够宽,其拟合能力会越强,可以通过单一模型来同时处理多个任务。"
886,基于机器学习的Wi-Fi指纹定位技术研究,"随着无线局域网(Wireless Fidelity,Wi-Fi)以及移动智能终端的普及,人们越来越看重信息传递的就地性与即时性。在这一需求下,基于位置的服务(Location Based Service,LBS)应运而生,LBS与移动智能终端的结合,对人们的消费习惯和生活方式造成了很大的影响[1]。根据用户的实时定位,主动为用户提供需要的服务,这种新型的服务方式就是基于位置的服务。现在,LBS己经在道路辅助与导航、医疗服务以及商业广告等多个领域发挥了重要作用,2m,其中,基于位置的精准营销有着广阔的应用前景,而这一目标的实现需要精确定位用户所在的商铺。但是,相比于室内环境,室内环境中的精确定位技术仍然是一个具有挑战性的问题。本文在研究分析和总结序列向量化表示和深度学习模型原理的基础上,对运用深度学习模型解决Wi-Fi指纹定位问题进行了深入研究。本文的主要研究工作如下:1、针对数据预处理阶段,存在指纹噪声大、指纹维度高的问题,提出了一种特征提取方法,该方法包括参考点选择和Wi-Fi表示:首先通过参考点选择策略去除掉不稳定的参考点,然后采用Wi-Fi2vec机制,将Wi-Fi指纹映射成一个低维度的向量,避免高纬度的输入导致后续定位模型产生维度灾难的问题。同时Wi-Fi2Vec机制训练出来的向量充分考虑了上下文信息,作为后续定位模型的输入,提高了分类器的性能。2、在定位算法阶段,提出适用于Wi-;Fi指纹序列的卷积神经网络结构,用卷积核提取Wi-Fi指纹序列的局部特征,用池化层提取高阶特征,然后将提取到的高阶特征用于Wi-Fi指纹定位,提高Wi-Fi指纹定位的准确率。3、在定位算法阶段,提出适用于Wi-Fi指纹序列的注意力机制模型。首先使用双向循环神经网络模型对Wi-Fi序列进行特征提取,即同时利用Wi-Fi序列当前输入的前后信息对Wi-Fi进行表达;然后使用注意力模型确定当前输入的权重,即构建当前输入与目标状态的相似度模型,两者的相似度越大,当前输入的权重越高。将加权得到的输入用于Wi-Fi指纹定位,提高Wi-Fi指纹定位的准确率。"
887,面向节能的移动边缘计算的卸载策略研究,"无线通信技术的蓬勃发展促进了移动互联网的快速发展,网络边缘的移动设备上每时每刻都在产生庞大的数据量。移动设备相对于网络中心的云服务器来说计算资源、存储资源、电池能耗都十分有限,难以实时处理如此多的数据。为了解决这个日益突出的问题,新兴的计算框架――移动边缘计算(Mobile Edge Computing,MEC)应运而生。移动边缘计算具有时延低、节能、降低核心网拥塞等优势。本文即是面向节能这一优势来研究移动边缘计算。本文共提出三个边缘计算场景,分别是单用户-多MEC服务器场景、多用户-单MEC服务器场景、多用户-多MEC服务器场景。在这三个场景下分别研究卸载决策、资源分配问题。共同点为目标均是在满足任务的时延限制条件下使得系统总能耗最低。在单用户-多MEC服务器场景中,用户移动设备上有若干个计算任务等待卸载,优化变量是任务的卸载决策(即某个任务卸载到哪个MEC服务器上或者不进行卸载)、以及移动设备的发射功率分配(即移动设备分别为每个任务分配多少发射功率)。提出了 AOA(Alternately Optimizing Algorithm)算法,第一步通过KM(Kuhn-Munkras)二部图匹配算法来求得卸载决策,第二步通过数学的单调性证明求得发射功率分配的解析解。在多用户-单MEC服务器场景中,有多个用户移动设备上的任务申请卸载到MEC服务器中,由MEC服务器集中决策分配通信资源(子载波)和计算资源(MEC服务器CPU频率)。由于优化变量一个是离散整数一个是连续小数,一般的优化方法较难解决,所以采用机器学习回归算法。回归算法可用来模拟输入和输出之间的非线性关系,输出为连续值。为了获取训练数据,随机生成10000条数据并通过离散化输入空间来穷举得到标签。然后比较三种回归算法:随机森林、Xgboost、人工神经网络对结果拟合的好坏。通过计算相应的系统能耗发现,人工神经网络能取得接近最优解的资源分配。在多用户-多MEC服务器场景中,研究移动设备如何选择卸载对象能够取得最小系统能耗。优化变量为移动设备的卸载决策。记移动设备个数为K,MEC服务器个数为M,则解空间有K*(M+1)种可能性。应用人工鱼群算法,将优化变量映射为人工鱼的位置坐标(K维),并将目标函数和限制条件转换为食物浓度函数。通过离散化步长和对坐标取值限制上下界,迭代求解。因为算法不能保证跳出局部最小值,因此结果为次优解。通过与随机卸载方式和不卸载方式进行对比发现能够取得更低的系统能耗。"
888,基于移动群智感知的内容共享及能效优化,"随着数据的海量化和能耗的高企化,信息高效共享和安全数据采集的无线通信需求也愈加突出。在无线通信系统和应用场景中,为了解决海量内容共享的问题,本文借助移动群智感知技术,针对通信应用场景中高并发数据的信息共享和信息采集问题进行研究,并对多用户、多社交关系和多元数据的本地内容共享框架以及无人机采集有限寿命数据的路径规划方案,开展了一系列工作。针对信息共享场景,论文提出一个新型的本地事件内容共享框架,通过设计一个精确定义的标签并允许本地用户提供实时的数据消息,来引导用户搜索他们想要得到的其他内容数据。在这个通信场景中,本文应用多对多稳定匹配模型来为用户选择合适的内容共享对象和传输的数据。然后,基于有限的能耗限制,本文利用凸优化等数学方法来优化系统的功率分配,进而提高能效。由于匹配模型内的偏好列表计算和能效分配问题之间的耦合性,本文设计一个启发式算法来松弛原目标函数的约束条件,降低求解复杂度,最后达到收敛。本文通过仿真结果说明所提出的基于多对多稳定匹配的内容共享方案的高效性和实用性。针对信息采集场景,本文设计一个基于无人机辅助数据采集的路径规划方案。对于环境监测等数据时延敏感场景,考虑到数据寿命有限,并且传感器存储空间有限,本文的目标是优化无人机路径,以减少整个网络内因为过期或从传感器存储空间中溢出的数据包数量。考虑到原建模的问题复杂而难以直接求解,本文对一些离散的约束条件进行松弛,进而把原问题转换为一个最小最大化信息年龄的无人机飞行轨迹模型的设计,然后提出一种基于强化学习的框架来优化无人机路径规划。在仿真的验证中,本文通过与其他两个基准算法进行比较,来表现强化学习算法框架的高效性。与贪婪算法相比,基于遗传算法的方案和基于强化学习的方案均可找到更好的路径规划,但是强化学习在算法时间消耗方面比遗传算法的优势更为明显。"
889,基于时间序列的人体行为识别算法研究,"人工智能的发展和行业应用的需求促进人体行为识别研究得到众多关注,当前在该领域主要有两种研究方法,或基于视频数据或基于传感器数据。前者由于受到部署成本以及环境复杂度的影响,实际应用效果不尽人意。得益于可穿戴传感器的发展,众多研究专注于在人体部署多个传感器以期取得良好效果。不同于以往研究,本论文研究仅通过佩戴在手腕的单个三轴加速度计进行人体行为识别,以最大程度减小对个体的干扰并降低传感器部署成本。利用集成于腕带式智能手表中的单个三轴加速度计,采集了Sanitation数据集,包括走、跑、小扫帚扫地、大扫帚扫地、清洁、倒垃圾以及日常活动共七类行为。对时间序列进行校准,消除了其中的读数漂移,并采用三阶巴特沃斯低通滤波器实现噪声滤除工作。提出了一种特征提取算法,共包括57个时域特征和33个频域特征在内的90个特征值,形成人体行为识别样本集。在人体行为识别的算法研究中,多利用传统的机器学习算法,识别效果较好的有支持向量机和k最近邻,还有部分研究采用深度学习算法,但极少有研究应用集成学习算法。本论文提出一种改进的子窗口集成学习算法,实现对人体行为的准确识别。实验结果表明,相比于传统算法,识别准确率得以显著提升,证实了研究成果的有效性。传统的基于时间序列的人体行为识别,主要采用滑动窗口取样分析的方法,该方法面临了多类窗口问题。本论文实现一种利用U-Net进行人体行为识别的算法,可对输入的时间序列进行稠密标记和预测。通过设计适合的U-Net网络,并将三轴加速度时间序列映射为单像素列、多通道的图像,再将映射后的图像送入网络训练得到模型,从而完成逐样本点的预测。结合所采集的Sanitation数据集和4个公开数据集,对所提方案进行了实验测试。实验结果表明,相比于其他五种对比算法,所提出的算法在各个数据集上的准确率和F1-socre都取得最高值,并且表现稳定,具有高鲁棒性。"
890,新闻影响力分析系统的分析与实现,"互联网技术的不断进步,使得新闻的传播相比之前更方便。微博、微信等各种新兴媒体不断涌现,使得传播的主体和内容相比于之前更加的多样化。在这两方面的综合影响下,新闻传播有了十分显著的变化。而且当今网络舆论和社会舆论主要受到网络新闻的影响,所以精准的分析和研究网络新闻的影响力具有十分重要意义。当前对于新闻影响力的研究虽然国内外学者有一定的成果,但是没有一个全面的模型来对新闻影响力各个方面进行度量,大部分只关注于其中一部分如新闻传播速度,新闻源的质量等。而且国内各大新闻网站没有一个足够清晰明了的模型来计算各个新闻事件的影响力指数。各种舆情监测网站也仅是对网民发表的信息进行分析,没有关注于新闻事件影响力的一个全面的影响力监控系统。对于当前的研究现状,需要根据本文提出的新闻事件影响力量化模型的各指标的计算公式,构建一套从新闻数据获取至新闻事件影响力分析,最终进行可视化展示的新闻影响力分析系统。本文对研究的系统架构及各个模块的设计和实现方法详细分析之后,确定本文研究核心为新闻事件影响力的分析和数据挖掘。然后使用网络爬虫、数据挖掘、自然语言处理、可视化展示等技术并使用最终做出新闻影响力分析可视化系统。主要工作如下:1.查阅新闻传播文献以及对新闻影响力进行分析,构建新闻影响力量化模型。本文中经过研究确定新闻影响力由传播力、公信力、说服力、号召力四部分构成,然后针对这四个部分中的各个指标提出定义及计算方式。2.对中国新闻网、腾讯新闻网、新浪新闻网共三个新闻网站设计了与其对应的爬虫程序,最终爬取了这三个网站的2017年6月至12月全部数据,对每条新闻的题目、新闻正文、发布时间、新闻分类、作者、评论数、转发数等关键信息存储在MySQL数据库中。3.新闻数据集获取完毕之后进行预处理操作如:新闻去重、分词、去除停用词等。后续对新闻使用规则和TextCNN模型两种方法进行分类。4.利用Word2vec词向量以及TF-IDF确定关键词权重以及新闻要素关键词权重计算获得对应的新闻文本向量。并根据文本向量找出新闻事件的全部新闻数据,然后计算新闻影响力各个指标。5.把计算之后的新闻事件影响力进行可视化展示,使用Echarts库来绘制可视化图表。本研究中构建了一套新闻影响力量化模型定义、新闻数据获取、处理、指标计算、可视化展示的完整系统。"
891,基于迁移学习的情感分析算法的研究与实现,"随着Web2.0时代的到来,飞速发展的互联网极大地改变了人们表达意见、抒发情感的方式和途径,微博、论坛等社交平台不断涌现,人们逐渐习惯于在这些平台上发表评论,这些评论蕴含许多重要的信息,例如情感倾向性等,通过对评论文本进行情感分析能够辅助人们进行产品推荐、舆情分析等,因此探究性能良好的情感分析算法具有巨大的实际意义。常用的情感分析方法主要分为基于传统机器学习技术、基于情感词典和基于深度学习的方法。基于深度学习的方法依靠无监督训练的词向量来表示文本,但是这种方法没用充分表示出文本的上下文语境关系,而且经常用于处理文本的循环神经网络结构比较复杂,训练难度较大。另外,随着各个领域新产品的不断涌现,新的领域往往缺少大量的有标签数据来训练模型,因此,研究如何利用已有领域的有标签训练数据对新的领域进行情感分析具有重要意义。本文针对现有的情感分析算法存在的问题进行了研究,探究了迁移学习技术在情感分析算法中的应用,主要的工作内容包括以下三个方面:(1)针对无监督训练的词向量无法表示上下文语境关系的问题,本文提出基于模型迁移的分层注意力网络的情感分析算法,利用机器翻译任务训练一个编码器,并将这个编码器模型结构迁移到情感分析任务中,用于生成文本的分布式表示。由于翻译模型需要充分提取上下文中的关键信息才能够尽可能准确地实现一种语言到另一种语言的转换,因此,经过这种方式获得的词向量涵盖了上下文语境关系,对情感分析算法的性能有很大的提升。(2)本文使用分层的注意力机制神经网络完成文本情感分析任务,网络主要分为单词层和句子层,在每层都使用一种称为最小门单元的简化的神经网络结构,减少了模型参数,降低了模型训练难度,并且在每层均引入了注意力机制来提取重要的信息。(3)针对在一个领域内训练的情感分析算法无法应用于其他领域的问题,本文提出了基于特征的跨领域迁移的情感分析算法,利用编码器提取领域无关的公有特征和目标领域的私有特征,然后结合这两种特征利用源领域有标签样本数据和小部分目标领域有标签样本数据训练分类器,实现跨领域情感分类。"
892,基于深度学习的文本分类研究,"随着互联网的发展,产生了大量的非结构化数据,尤其是每天更新的新闻文本。本文从两个方面对新闻文本进行研究,分别是文本的主题分类和文本的情感分析。根据文本的主题内容对文本进行分类,可以使复杂多样的文本变得容易管理,也可以方便学校、公司、医院、以及各类需要处理文本数据的组织机构依照特定的分类准则对源源不断产生的各种文本类数据进行分类。通过对文本的情感倾向性进行分析研究,在电商平台中的商品用户评论中可以反映出某商品受顾客的满意程度;在博客中可以反映群众对于某类事件的情感态度,以及社会舆论的走向;在影视评论中,可以反映出某些影视作品受观众的喜爱程度等。而对于新闻类文本的情感分析可以反映出某行业领域或某些企业的前景是利好还是隐患,或者某些社会热点新闻事件是正能量还是负能量等等。在文本主题分类模型的研究中,利用长短时记忆神经网络(LSTM神经网络)训练文本主题分类模型。首先爬取带有文本主题类别标签的新闻语料,根据语料的特征进行相应的数据清洗工作,之后经过分词、去停用词、将类别标签映射为数字等数据预处理工作,再将文本转化为词向量作为LSTM神经网络的输入,研究了训练神经网络过程中主要的超参数,通过多组基于不同超参数值的对比实验,确定了合适的超参数训练模型,最终还实现了文本主题分类的前端界面设计及应用。在文本情感分析模型的研究中,使用的是fastText神经网络训练文本情感分析模型。首先根据文本特征进行数据清洗,如去除广告类噪音数据、过长过短以及不规范的新闻文本,再经过分词等数据预处理后作为fastText神经网络的输入,训练文本情感分析模型。基于文本情感分析模型研究的基础上又引进了集成学习的思想,通过对训练样本的重采样,训练多个弱分类器,之后再通过基于结合策略为加权投票的bagging集成学习算法联合成为一个强分类器,将弱分类器联合后的强分类器有更高的准确率,而且能适应更多不同的数据集,有更强的泛化性,在文本情感分析的研究中有很大的理论意义和实用价值。"
893,基于机器学习的大规模网络流量识别方法研究,"从上世纪90年代到如今短短几十年间,互联网经历了飞速发展阶段,人们的工作与生活方式发生了极大的变化。用户使用互联网的需求量正在极速上升。通过检测不同的网络流量,能够根据不同应用产生的流量对于网络的影响而采取对应的管理手段,从而实现有针对性的流量管理、网络优化、态势预测和安全防范,对于合理规划网络资源、减少运行成本、维护网络安全与提高服务质量都具有重要的影响意义。本文采用基于机器学习的流量识别方法,选取支持向量机作为流量识别的机器学习算法。由于支持向量机引入了核函数,支持向量机算法可以将低维度线性不可分问题转变为在高维度的线性可分问题。降低了算法复杂度的同时避免了高维度灾难问题。支持向量机遵循结构风险最小原则,提高分类器学习机泛化能力同时避免了训练过程中过度拟合的问题的出现。基于支持向量机的流量识别方法,在不通过训练大样本数据的情况下,也可以避免陷入局部最优解的情况,得到全局最优解。针对高维流量特征灾难的问题,本文提出了基于支持向量机的混合特征选择与主成分降维结合的算法,并与传统的特征选择方法下的支持向量机流量识别算法效果进行对比,实验结果表明,本文提出的特征选择与降维算法具有优良的识别性能。基于机器学习流量识别方法研究的另一个重要课题是多类分类问题。基于支持向量机的流量识别方法传统的多类分类模型在应用类型数目逐渐增加时,其二值分类器的数量也会急剧增加,使得支持向量机分类器的决策效率明显降低。本文提出了一种基于优化纠错码的支持向量机多类分类模型,优化的纠错码生成简单、快捷,并且对于任意的流量类别数目,其都可适用。本文进行了多组多类分类实验,实验对比了传统的多类分类模型与优化纠错码多类分类模型的识别性能。实验结果表明,在流量类别数相同的情况下,优化纠错码多类分类模型的识别性能总是高于传统多类分类模型。并且随着流量类别数目的增加,前者识别性能趋于稳定,而后者识别性能不断下降。因此在本文的流量识别中,基于优化纠错码的支持向量机多类分类模型可以提供稳定且优良的识别性能。"
894,基于行为分析的检测APT攻击方法的研究与实现,"随着互联网的迅猛发展,许多部门和企业的关键业务活动越来越多地依赖于网络,各种网络攻击和信息安全事件发生率在不断攀升。APT(advanced persistent threat)高级持续性威胁已成为针对高度机密的政府、金融企业、军事机构等高安全等级网络的最主要威胁之一。APT攻击主目的是窃取敏感数据信息,APT攻击一旦发生,会给受害主体带来严重的经济、信誉的重大损失。甚至会对国家战略安全造成重大威胁。APT攻击属于攻击时间链长,攻击方式隐蔽、攻击手段高级且不断升级的高级网络攻击行为,对APT整个阶段周期的检测时间复杂度高且需要更高的硬件配置,根据攻击时间链先后对APT攻击进行分阶段分析则能有效降低检测时间复杂度。论文对APT攻击周期进行阶段划分,分为定向情报收集、边缘内部主机入侵、建立监控通道、高级内部主机渗透、数据资源发现与上传、入侵痕迹清除六个阶段。APT攻击目的比较固定,其攻击中通信行为可找到一定规律,根据不同的阶段攻击行为,分析可能的攻击检测场景。在定向情报收集阶段提出针对关联网站的WebShell攻击场景,在建立监控通道阶段和数据资源发现与上传的阶段提出在入侵过程中的C&C(Command And Control)通信攻击场景的检测。论文的主要研究内容如下:1.针对关联网站的WebShell攻击场景的检测,现有检测方法主要是对WebShell源码进行检测且检测准确率偏低,本文主要对Web日志进行检测,日志记录中的APT攻击行为与正常访问行为在访问频次和连续访问度上有较大的区别,提出基于访问频次特征检测与连续访问度检测的两个检测算法对WebShell进行检测,通过这两个检测算法,一方面有效的提高了检测准确度,另一方面在无法获取源码的情况下也能进行检测,降低了检测数据来源的局限性。2.针对C&C通信攻击场景的检测,相对现有研究中检测时间复杂度较高的现状,本文根据同一恶意软件(族)进行下发控制命令时的通信流量有很大的相似度,提出基于下行流量中payload相似度的检算法对C&C通信进行检测,在较高准确率下有效降低时间复杂度。3.根据WebShell攻击场景和C&C通信攻击场景设计真实攻击实验进行验证,对WebShell攻击和C&C通信攻击检测取得了较高的准确率。对于WebShell检测,设定阈值为5‰时准确率达94%以上,对于C&C通信检测,设定相似度阈值为21%时,准确率达88%以上,两项检测指标准确率均比同类基本检测方法高。"
895,基于改进集成学习算法的空气质量离线和在线预测,"空气质量预测关系大气质量和人类疾病。空气环境复杂多变,影响因素众多,且存在复杂的非线性关系。空气质量数据具有实时数据流一般特性,对这样的数据分析需要离线和在线预测相结合的方法。因此,本文针对空气质量分析与预测的研究具有重要的应用价值。本文提出一种集成学习方法且结合PI(plant information)系统对空气质量进行分析与预测。在离线部分中,我们提出了一种基于XGBoost算法的改进方法OPGBoost,主要采用自定义XGBoost损失函数和Bagging集成来优化。根据空气质量数据的特点,采用拉格朗日插值法对数据进行处理,利用错位的方式构建一段时间内空气数据的属性,用于扩充原有的数据特征,并且从中筛选出重要的特征。然后,采用XGBoost、RF、OPGBoost和BP算法建立预测模型,经过模型评估和结果对比,选取OPGBoost算法作为最终的空气质量的预测模型。此外,PI系统通过二次开发,引入机器学习模块,增添数据挖掘功能,实现在线预测功能。运用PI的数据融合功能集成特征子集,并利用滑动窗口缓存数据集,采用衰减函数控制生成模型的权重,最后组合之前生成的模型,在PI系统上采用OPGBoost算法进行在线实时预测。实验表明,针对PM_(2.5)和AQI的空气质量预测,取得了较好的离线建模和在线预测效果,具有较好的实际意义。"
896,基于集成特征选择的冠心病筛查模型研究,"心血管疾病是一种严重威胁人类健康的重大疾病。冠心病作为一种常见的心血管疾病,其发病率和死亡率逐年上升,同时其昂贵的治疗费用给国家和人民带来了巨大的经济负担,给患者家庭带来了巨大的灾难。冠状动脉造影是近几年常用的有创诊断技术,被认为是诊断冠心病的“金标准”,然而其费用较为昂贵,且对做操作者的技术水平要求较高,不适用于冠心病早期的筛查和诊断。因此,研发普适的冠心病早期无损筛查诊断方法,对于降低冠心病的发病率和死亡率具有重大意义。本文首先对国内外冠心病危险因素及其筛查模型的研究现状和发展趋势进行了系统综述,然后利用多种特征选择方法筛选冠心病危险因素,并对冠心病的早期无损筛查模型的构建进行了系统研究。完成的主要创新性工作如下:(1)在某三级甲等医院心内科完成冠心病组和对照组数据的采集,并构建山东地区冠心病危险因素数据库。构建的数据库涵盖的主要信息包括:临床症状、生化指标、人口学信息、生活习惯、个人疾病史、家族疾病史、心电检查结果等信息。(2)提出一种集成多种特征选择方法的特征选择策略。首先利用方差分析、卡方检验、互信息、循环递归消除、随机森林特征权重系数、支持向量机特征权重系数和XGB(Extreme Gradient Boosting,XGB)特征权重系数七种特征选择方法,对上述特征集完成特征重要性评估,筛选出重要的特征;然后,对筛选的特征投票,统计每个特征所得的票数,票数相同的特征构成新的特征集;最后,新特征集分别用支持向量机构建模型,通过模型性能指标得出最重要的特征集。(3)筛选的重要特征基于支持向量机构建了冠心病筛查模型。模型的准确性、敏感性和F1-measure分别达到了89.39%、94.53%、90.68%。与使用原特征集训练的模型、单一特征选择方法训练的模型相比,集成特征选择方法训练的模型准确性分别提高了9%和3.3%。该方法训练的模型能有效识别冠心病,可为临床上冠心病的筛查和诊断提供参考。"
897,基于大数据的区域联系及调度需求研究,"随着互联网技术的发展和移动终端设备的普及,通信数据的体量呈爆炸式增长,这些数据蕴藏了极大的潜在价值,为研究城市空间理论和挖掘人类移动模式提供了可靠的数据保障。合理划分城市区域,并明确区域之间的联系,对城市规划有重要价值。明确用户出行需求可减轻交通系统负担,改善交通环境,为制定交通控制系统的调度策略提供重要依据。本文基于用户移动网络数据,针对区域划分及区域联系、用户出行需求进行了相关研究,具体如下:(1)区域划分及区域联系分析研究特征提取方法与聚类算法,对城市区域进行了划分,并提出了分析区域间联系的相关模型。首先,构建基站流量的时间序列,并对时间序列从统计学、时域、频域三个方面提取了54维特征。其次,运用k-means++算法得到基站的功能类别。结合基站的地理位置特征和基站的功能类别,进一步运用k-means++算法将城区划分成400个功能区。再次,调用百度地图API,获取各个区域的兴趣点(point of interest,POI)信息,对每个区域进行功能区判定,并与本文的分区结果进行对比,得到分区的平均准确率为77.7%。最后,考虑区域中人群的迁入量、迁出量以及区域间的距离,提出基于人口迁移的牛顿引力模型,对区域间的联系进行了分析,并在此基础上研究了区域的重要程度。(2)用户出行需求预测研究统计学和机器学习中的模型,对用户出行需求进行预测。首先,针对每条路线构建用户出行时间序列。为应对城市中复杂的道路结构,本文提出按照人群的出行频度,将路线分为三类:频繁路线、普通路线和稀疏路线。其次,对所有路线构建统计学中的自回归移动平均整合模型(Autoregressive Integrated Moving Average Model,ARIMA)。运用滑窗法对用户出行时间序列进行处理,构建训练集和测试集,并建立三种机器学习模型:支持向量回归(Support Vector Regression,SVR)、梯度提升树(Gradient Boosting Decision Tree,GBDT)、随机森林(Random Forest,RF)。上述四种模型建立之后,分别用其进行用户出行需求预测,即预测每条路线在各个时段的用户出行量。再次,选用平均绝对误差(Mean Absolute Error,MAE)和均方根误差(Root Mean Square Error,RMSE)作为误差指标,对比分析预测结果。结果表明,GBDT模型的预测性能最优,其频繁路线、普通路线和稀疏路线下的平均MAE、平均RMSE分别为(1.479,2.132)、(1.549,2.156)和(1.278,1.745)。最后,将预测结果进行可视化展示。"
898,面向电商网站的用户线上与线下社交网络分析与研究,"随着移动互联网的飞速发展,越来越多的人们选择使用手机上网浏览信息,这也导致了网络数据呈现爆发式的增长。在人工智能迅速崛起的年代,利用数据挖掘和机器学习从这些数据中挖掘信息对用户进行画像,可以使得互联网更好的服务用户。社交网络是一种理论结构,可用于研究人们之间的关系。通过挖掘人们之间的社交关系有助于对用户进行画像,从而实现更加精准的推荐,给用户带来更好的上网体验。本文首先介绍了研究的背景意义以及组织结构。接着介绍了分析的总体架构图,数据处理平台Spark,数据集以及数据预处理。后面主要从线上以及线下这两个角度对社交网络进行详细的构建与分析。一是基于浏览过京东、天猫、淘宝这三个电商网站的用户数据构建线上社交网络,计算网络的相关指标并与传统网络指标进行对比,从商品角度展开多维度的分析,从而丰富商品特性。二是基于浏览过京东这个电商网站的用户数据构建线下社交网络,分析用户在线下的移动特性,并结合线上社交网络探究线上与线下社交网络的重叠性。最后,在重叠性的基础上进一步探索线上与线下社交网络的相互拓展性,通过用户线下行为特征以及线下社交网络特征预测用户之间在线上是否存在好友关系来展开分析。基于用户浏览电商网站的真实流量数据,展开对线上与线下社交网络的分析与研究,对用户特征的刻画以及对用户在线上与线下行为之间的关联性研究起到了至关重要的作用。"
899,网络异常检测研究与应用,"随着IT架构的日益复杂,各种应用也不断涌现,网络和应用的边界变得越来越模糊,这使得基于单一边界和控制点的传统安全设备难以有效掌握整个网络的安全状态。一方面,网络攻击的广泛性、隐蔽性、持续性、复合性、多样性等特征使得传统网络攻击检测技术难以有效应对。另一方面,随着移动互联网、云计算等技术的发展,网络中的威胁情报信息越来越多,因此,如何高效智能的整合、处理外部与内部的大量非结构化数据,对多源数据进行有效关联、检索与情报追踪是网络安全发展的关键。近些年来,随着网络异常检测技术的不断发展、软件定义安全架构的出现、大数据技术的发展,上述的安全挑战带来的问题逐步得到了缓解。本文选取僵尸网络与Web攻击两种在网络中最常见、波及面最大的网络威胁,对僵尸网络C&C服务器检测与HTTP异常检测问题展开研究;同时,将异常检测算法封装为异常检测模块,在软件定义安全架构下实现异常检测模块与安全数据平台的集成,从而实现数据驱动的安全服务器编排。本文的具体研究内容如下:1.利用网络中广泛存在的多源异构数据,借鉴安全威胁情报、用户与实体行为分析(UEBA)等安全领域的新思路,基于统计分析、机器学习、深度学习对网络异常检测的问题展开研究,具体包括:(1)基于城域网采样Netflow的C&C服务器检测(2)借鉴UEBA思想的基于HTTP画像的异常检测(3)基于长短时记忆神经网络(LSTM)的HTTP异常检测2.本文设计了一种将网络异常检测模块与安全数据平台进行集成的方案,实现了网络数据的实时在线异常检测,同时在软件定义安全架构下,根据异常检测结果自动选取防护策略并下发,从而实现数据驱动的安全服务编排,提高安全防护效率。"
900,基于机器学习的建筑空调能耗数据挖掘和模式识别,"大数据时代,建筑运行数据量越来越大且维度越来越高,使用传统技术对这些数据集进行分析是耗时且不现实的。采用机器学习算法对数据进行分析处理并挖掘其价值是目前国内外最新的趋势。本文以中国石油大厦为例,研究了基于机器学习的建筑空调能耗数据挖掘和模式识别。利用时间序列符号化工具SAX和无监督机器学习算法Kmeans,对大厦2017年的空调能耗数据进行了降维聚类分析和模式识别,主要结论和创新成果如下:(1)建立了基于SAX符号化处理、机器学习聚类分析和模式识别的建筑能耗数据分类方法体系。首先进行数据预处理,通过SAX符号化和降维处理得到365组结构化数据和13种粗类能耗模式;然后,根据建筑分时流向图,观察类簇个数,再进行Kmeans聚类处理,得到5条聚类曲线和5种能耗模式;最后,进行模型验证和模式识别。该体系对逐时空调负荷预测和设备故障检测诊断具有指导意义。(2)探讨了建筑空调能耗数据的聚类方法及参数选取。首先,通过分析数据特征和聚类算法实现难度及准确度,选取合适的聚类方法,即Kmeans算法;然后,分析数据的数据结构,选取距离计算函数;再通过轮廓系数,分6种情况讨论并得出了类簇个数K的值;最后,通过聚类系谱图验证了 K值的合理性。(3)对中石油大厦空调系统全年90%的运行时间的能耗数据进行了聚类分析,得到5条能耗曲线(或5级聚类模型),分别对应5个能耗等级。五级模式、四级模式、三级模式、二级模式和一级模式分别对应100-80%、80-60%、60-40%、40-20%和20-0%的实际空调负荷下制冷设备的运行模式。(4)从暖通工艺角度,分模式分时段讨论了五条能耗曲线的物理意义。结合分时电价和逐时空调负荷,分析了不同供冷模式下,3台双工况主机的制冷工况和制冰工况、2台基载主机制冷工况、蓄冰装置的融冰工况及三者的组合情况;明确了五级能耗模式的实际意义。并分别按季节、月份、周细分三个维度对比分析这5种能耗模式,验证了能耗分级的合理性。(5)验证了五级聚类模型正确性。根据机器学习模型验证规则,训练数据集和测试数据集各占总能耗数据的50%,分别用相应模式的测试集来评估聚类模型的泛化能力,得出模型置信度为95.45%。进行初步模式识别,效果良好。"
901,基于机器学习的择优算法在入侵检测中的研究,"入侵检测自提出以来就备受重视。近年来,机器学习的热潮为入侵检测技术的研究带来了新鲜血液,并且得到了广泛的应用。但是由于人们的工作和生活越来越多的依赖互联网,致使网络信息交错复杂,如何从海量数据中提取有用的信息并对其进行分析成为当下解决大数据问题的关键。传统的特征择优方法通过数据降维能在一定程度上提高算法的泛化能力,但是由于忽略了某些重要特征在分类中的作用而导致入侵检测率与误报率失衡;针对小类别样本,现有的大多数入侵检测方法在检测准确率的表现上也不尽如人意。本文针对上述问题,提出了新的基于机器学习的择优算法。论文的主要研究内容及创新如下:(1)由于样本特征的多元化,传统的方法不能很好地表示样本与特征之间的关系,针对此类问题,本文在Fisher分特征选择的基础上引入了超图的概念,提出了一种基于FS-HG特征择优的两级混合入侵检测方法。该方法在训练阶段结合Fisher分和超图的Helly属性做特征择优,得到更有利于分类的样本特征;在测试阶段利用随机森林和改进的K均值作为联合分类器,旨在通过加入密集度阈值来避免单个离群点对簇类中心变化的影响,使聚类结果达到更高的准确率。实验结果表明,级联分类器的方法可以确保算法在检测率和误报率之间达到较好的平衡,对大部分类别的检测准确率也高于单独使用各个分类器。(2)针对传统的神经网络模型训练时间长且容易出现过拟合的问题,提出了基于非对称深度信念网络(ADBN)特征择优的入侵检测方法。该方法在训练阶段采用非对称的方式初始化ADBN模型中的参数,首先通过训练DBN得到ADBN模型中编码器的参数,然后利用服从正态分布的数值初始化解码器各参数并对原始数据进行还原,最后通过计算重构误差来调整模型的参数;在测试阶段利用ADBN中的编码器参数对数据进行特征提取并将其作为分类器的输入数据,达到特征择优的目的。实验结果表明,相较于传统的DBN算法,本文所提方法在检测率和误报率方面具有更大的优势,且对小类别样本也达到了较好的检测准确率。"
902,基于机器学习的RocksDB存储引擎配置优化,"随着大规模分布式存储技术的发展,对传统关系型数据库的改造研究成为热点,出现了诸多以RocksDB作为存储引擎的新型数据库系统。RocksDB是一种基于日志结构合并树的键值对系统,它具有化随机I/O为顺序I/O的优点,是当前大规模数据存储的首选产品。然而,RocksDB也存在存储参数不能适应工作负载变化和读性能低下的缺点。在极端环境中,RocksDB的默认参数配置会由于后台合并操作队列过长,导致出现线程阻塞甚至写停止的状况,性能大幅下降。在读性能方面,RocksDB中的读操作可能会在多个层级中发生I/O,并且不能无限制的通过增加索引和布隆过滤器加以缓解,导致不可避免的性能损失。因此,RocksDB虽然具有显著的写优势,但这些存在的问题也制约了其进一步的应用。针对上述问题,本文以建立工作负载自适应的存储引擎为目标,以机器学习技术为核心方法,对RocksDB存储引擎中的存储参数配置问题与热点数据主动缓存问题进行了深入的研究,论文主要贡献如下:1)针对默认参数不够灵活的问题,本文以提升RocksDB对通用工作负载的感知,自动调整存储参数为目的,设计并实现了基于强化学习的智能调参模块。该模块捕捉工作负载的差异性和动态变化性,对环境建模,构建基于模型的强化学习框架,有效地捕捉到了工作负载与存储参数之间的复杂关系,减少了系统性能因工作负载变动导致的损失。实验结果表明,在工作负载发生明显变化的情况下,调参系统的性能明显好于默认参数性能,在读写混合的工作负载中平均有8%左右的性能提升。2)针对读性能较低的问题,本文以提升面向读的工作负载性能,拟合热点数据分布为目的,设计并实现了利用增量学习进行预测分析的热点数据主动缓存模块。该模块针对访问模式对数据建模,预测潜在热点数据并主动进行数据重放操作,这样热点数据永远在日志结构合并树的较低层级中,减少了在存储介质中的I/O访问次数。实验结果表明,在热点读工作负载模式显著的情况下,主动缓存模型具有良好的性能表现。"
903,C程序内存泄漏的智能化检测方法,"内存泄漏是C语言程序中一种常见的缺陷,会严重影响程序的性能和安全性,其根本原因是开发人员管理内存时的人为疏忽。目前内存泄漏的主要检测方法是静态分析与动态测试。动态测试需要对程序进行插装或者外部监控并实际执行程序,其发现缺陷的能力高度依赖于测试用例,并且需要较高的运行开销;静态分析技术无需实际执行程序,能快速发现缺陷,因此被学术界和工业界广泛使用,但由于庞大的程序规模和复杂的程序结构,静态分析的能力不足可能导致漏报,更多情况下,因为静态分析采用的保守策略往往会导致报告中包含大量误报。误报目前主要是依靠有经验的专业人员人工对警报及关联的程序深度理解后进行确认,费时费力。机器学习技术在软件工程领域对经验知识的挖掘和统计取得进展,因此本文研究面向C语言程序内存泄漏的智能化检测方法,利用机器学习技术挖掘静态分析警报人工确认的历史数据中的经验知识,归纳内存泄漏模式以及静态分析误报原因,用于对静态分析方法获取的内存泄漏特征进行分类,从而优化内存泄漏检测过程以及警报生成质量。本文的主要工作如下:1.构建了内存泄漏检测模型。基于对C语言程序内存泄漏的机理分析,确定内存泄漏特征;基于静态分析警报人工确认的历史数据,利用机器学习技术挖掘警报确认的经验知识,归纳内存泄漏模式以及静态分析误报原因,从而构建了内存泄漏检测模型,并对模型进行了评估和验证。2.提出了内存泄漏的智能化检测方法。本文利用内存泄漏特征定义了基于内存泄漏检测模型的内存泄漏判定规则,然后通过静态分析方法提取待测程序的内存泄漏特征,使用内存泄漏判定规则,直接给出待测程序的内存泄漏判定结果或者输入内存泄漏检测模型进行分类。在此基础上,论文针对其他静态分析工具报告的内存泄漏警报,对警报关联的程序进行二次分析,并使用内存泄漏智能化检测方法对警报进行确认与分类。3.基于上述工作,实现了内存泄漏智能化检测方法的原型工具,并开展了实验研究。基于scikit-learn构建了内存泄漏检测模型,并在开源框架上实现了原型工具。实验中,我们在SPEC2000和Siemens等基准程序集中选取了 16个C程序,并使用原型工具进行了实验,实验结果表明,论文方法能够有效减少静态分析的误报,针对静态分析警报的分类也可以有效地降低需要人工验证的工作量。"
904,在线评论对用户购买行为的影响研究,"随着我国互联网普及率的不断提高和大数据技术的飞速发展,结构化与非结构化在线评论数据规模出现了指数级的增长,消费者利用互联网平台在线发表对产品或服务的意见、投诉和建议已经成为了一种常态。在线评论是指用户发表的对于消费的产品或者服务的文字描述或评分,包含用户使用产品或服务的客观描述以及主观感受。在线评论作为先验用户的阐述,兼具了理性和非理性的要素,满足了用户进行购买行为时的心理诉求。在线评论内容中蕴含了丰富的信息,先验用户提供的在线产品评论已经成为消费者获取产品信息的主要来源。与此同时用户进行购买行为的过程实际上是一个信息不完全对称的过程,当出现信息不对称时,会加剧用户的风险感知,消费者会倾向于通过相关信息的搜寻来减少信息的不对称性,进而来降低自身的感知风险。因此,对在线评论的特征属性以及对用户购买行为的影响研究一方面能够有利于消费者正确全面地了解在线评论平台上的评论信息,另一方面有利于企业更好地把握用户对于在线评论内容的需求,为进行更好的在线评论社区建设提供建议。本研究的研究重点是通过互联网在线评论平台提供的评论数据,利用机器学习和统计学的相关方法提取出在线评论数据在线评论数量,评论有用性、评论情感倾向以及评论差异性四类特征,通过将评论特征作为自变量利用相关分析、回归分析的方法研究对用户购买行为的影响。首先本研究对在线评论理论基础以及消费者购买行为理论进行了梳理和总结,并对本研究使用的研究方法进行了解释。接下来基于整理的理论基础提出了本次研究的概念模型以及针对研究对象提出在线评论数量、在线评论有用性、在线评论情感倾向、在线评论差异性对于购买行为影响的研究假设。然后本研究进行了数据的获取、处理与变量的测量。考虑到研究的深入性,本次研究考虑到了了文本的长度对于实验结果的影响,并且把在线评论情感倾向特征区分为评论评分情感倾向特征与评论内容情感倾向特征分别进行研究。在数据的处理中,本研究首先对文本进行分词,然后采用支持向量机的方法获取在线评论的内容情感倾向特征。最后根据提取的在线评论特征利用相关分析与回归分析的方法对用户购买行为进行实证研究并对研究结果进行分析。本研究基于在线评论的特征属性结合概念模型对用户购买行为的影响进行了实证研究,通过实证结果分析,本研究得出如下结论:(1)在线评论的正向情感倾向越强时,用户对评论的感知更加敏感,进而能够影响用户的购买行为。(2)在线评论的评分情感倾向对于用户的购买行为的影响程度要优于在线评论的内容情感倾向,直观易懂的在线评论的评分能够更好的反映出评论的情感,对影响用户的购买行为产生正向影响。(3)在线评论的有用性越高时,对用户购买行为有促进作用。(4)用户对于专业性更强的长文本数量更为敏感,对用户的购买行为有正向影响。而短文本的数量与用户购买行为之间没有显著影响。(5)用户对于在线评论的差异性并不敏感,用户愿意看到全面分析的,客观真实的在线评论内容。"
905,无线Mesh网络信道分配与节点定位技术研究,"与传统网络相比,无线Mesh网能够实现动态地自配置、自组织和自愈合,有着更高的数据容量和数据速率,可以更稳定的用于商用覆盖或是其他更加复杂的地形环境中,是对过去的各种不同网络接入方法的融合,可以认为无线Mesh网络就是下一代无线网络架构基础。但是随着对无线Mesh网络越来越深的研究,也发现了其许多问题,如多跳之后较高的端到端延迟,扩大通信范围所导致的吞吐量的降低,网络QoS难以达到预期等。因此,通过研究无线Mesh网络的关键技术来进一步提升其性能,更好的发挥无线Mesh网络的特点,为上层应用提供更加有保障的网络基础就成为了当前无线Mesh网络研究的重点问题。论文针对多射频多信道无线Mesh网络信道分配技术以及无线Mesh网络节点定位技术进行了深入研究,通过研究信道分配技术更加充分地利用有限的信道资源,提高无线Mesh网络的总体容量,降低链路间的信道冲突与干扰,提升网络服务质量;通过研究节点定位技术实现对大规模部署的无线Mesh网络节点的无附加设备、无额外开销的定位,使用网络的连通性信息更加快速精确地获得节点的位置信息,有助于提高网络的服务质量,为需求位置信息的网络层以及应用层技术提供支撑。论文中提出了基于链路权重的最小化冲突信道分配算法。结合实际无线Mesh网络的结构特点和流量类型(网络内部流量与经过网关节点到达外部网络的流量),提出了链路权重、链路冲突系数的定义以及计算方法,分别代表网络中链路可能存在的负载大小以及网络中链路之间可能存在的冲突大小,并使用此二者进行了网络中不同信道的链路冲突的量化计算,作为信道分配的依据。算法考虑到算法网络中可能存在的不同流量类型,同时充分利用网络的连通性,首先分别计算网络中所有链路的权重,再根据权重来计算网络中的链路冲突,从而进行最小化链路冲突的信道分配,能够有效的减少网络当中因为链路之间的干扰以及隐藏/暴露终端问题造成的容量衰减。使用网络仿真软件NS-3进行的网络整体性能仿真,对比分析了提出的算法与现有算法在不同业务场景下对网络总体吞吐量性能的提升。论文基于当前最为经典的范围无关DV-Hop定位算法以及其近些年来各种改良算法,提出了一种基于机器学习回归模型的范围无关节点定位技术――基于回归的修正跳数矢量节点定位方法。提出的定位方法直接使用未知节点到达网络中各个已知坐标的锚节点的跳数信息作为未知节点的特征,将节点的实际位置作为标签,进行节点跳数矢量与节点位置的回归关系的训练建模,大幅度减少了现有基于机器学习的定位方法所需建立的机器学习模型数量,有效地提高了定位速度,降低定位时间。提出的方法使用RSSI信息对锚节点一跳范围内的节点的跳数矢量进行修正,将值为1的跳距进行更细粒度的划分,进一步提高节点定位精度的同时不需要全网泛洪节点之间的RSSI信息,不增加额外的开销。通过仿真分析比较了不同机器学习回归模型用于提出的定位方法进行节点定位时的性能差异。提出的节点定位方法可以有效的与现有机器学习回归模型结合大幅提高了节点定位速度,在网络中节点密度相对较高、锚节点数量较多时能够有效的提高的节点定位精度。最后,对论文中所做的研究工作进行了总结,并针对提出的信道分配与节点定位算法的未来优化做出了展望。"
906,基于数据挖掘的网络新闻热点发现系统设计与实现,"随着互联网技术的蓬勃发展,网络媒体已经成为了人们获取新闻的一个重要渠道。网络新闻因其新闻传播速度快、传播范围广等特点,每日产生的新闻数据量极为可观。研究新闻热点的数据挖掘策略能够对推荐优质、高价值的新闻内容有着重要的理论与实用价值。除此之外,优秀的新闻热点发现系统还有助于新闻工作者和政府部门开展新闻舆情追踪等相关工作。目前的新闻热点发现系统相关的研究还处于初级阶段,相关的理论算法和系统的研究较少,基于上述原因需求,本文设计了新闻热点发现系统中的关键算法模型,并基于上述模型完成了一个基于数据挖掘算法的新闻热点发现系统:1)基于新闻文本特征和词向量化算法,本文提出了以标签向量为核心的文本标签向量模型,并针对该模型设计了新闻文本相似度计算公式。2)基于文本标签向量模型,本文设计了基于改进DBSCAN算法的Label-Vec密度聚类算法;Label-Vec算法利用Hash桶对文本空间进行了分割,有效减少了聚类过程中核心对象的比较次数,在减少了算法复杂度的同时也优化了算法性能。3)基于LDA主题模型,本文设计了热点话题发现模型,该模型可以在每个聚类簇下通过LDA模型获取簇的关键主题,并基于此生成热点话题,并设计了相应的热度值计算公式,实现了新闻热点话题热度的直观展示。本文针对新闻热点发现系统进行了一系列的测试,经过测试表明,该系统可以完成海量新闻文本挖掘热点话题的任务;在Label-Vec算法方面,通过与传统的Single-Pass及K-Means聚类算法相比,本系统的算法复杂度更低,聚类速度更快,在聚类性能上也具有更优的内部及外部性能,聚类结果更为准确。"
907,安卓平台移动用户画像算法的研究与实现,"用户画像技术通过分析和挖掘大量、真实的群体用户行为,构建模型实现系统、完整地刻画用户特征,已被广泛应用于各行各业,也成为近几年学术界研究的重点领域。随着通信技术的飞速发展,手机已经成为日常生活中必不可少的移动智能设备,其上承载的数据直接反应了用户的性别、年龄,甚至于性格、爱好等个人信息。因此,移动用户画像的构建更加准确,其应用的价值更高。移动用户画像借助大量机器学习、深度学习算法迅速发展,已取得了一定成就,但仍面临多重挑战。第一,手机数据安全问题。现有算法多在手机侧采集数据,在云侧Web服务器完成计算,数据获取和传输时易发生安全隐患。第二,算法准确性和灵敏性有待提高。用户的动态属性,诸如兴趣点、生活习惯等,数据不稳定,研究如何短时间准确识别,且属性变化时灵活调整极其重要。第三,移动用户画像与推荐系统的结合有待创新。画像最主流的使用场景即为定向智能推荐,如何应用移动用户画像帮助推荐系统实现更精准、更多样地推荐非常重要。首先,针对算法数据获取难、数据传输不安全,动态属性识别算法的准确性和灵敏性不足等问题,本文提出新的移动用户画像算法,实现更准确、更灵敏地识别和预测。本文聚焦用户起床时间和睡眠时间,提出基于屏幕状态数据预测起床睡眠时间的算法――BTP算法(BedTime Prediction,睡眠时间预测)。算法在手机端侧进行计算,数据不上传至Web服务或云计算,避免了在不违反隐私保护规定的情况下收集数据的困境。实验证明算法可以较准确预测用户的起床睡眠时间,起床时间平均误差约10分钟,睡觉时间平均误差约20分钟。接着,针对推荐系统准确性不足、推荐结果同质化严重的问题,本文提出新的推荐方法,实现更准确、更多样推荐。本文聚焦手机APP推荐领域,利用神经网络方法充分学习用户画像特征,提出了一种P-SNN框架(P-SNN,P Stair Neural Network,P阶神经网络),实现更精准的APP推荐。另外,算法提出DAM方法(DAM,Daynamic Adjustment Method,动态调整方法),应用动态调整的思路解决了推荐系统结果同质化问题严重的问题。实验证明算法有评分预测误差较低,且显著提高了推荐结果的多样性。最后,本文提出一种基于手机用户画像算法的安卓APP实现框架,集成采集、存储、计算、可视化等四大功能模块,实现移动用户画像构建的智能化、自动化和一体化。"
908,基于多尺度卷积神经网络的出行目的地预测技术研究,"近年来,移动通讯和导航定位技术的发展使得基于位置服务(Location Based Service,LBS)成为人们日常生活的重要部分。在位置信息服务(互联网+位置信息)兴起的当下,研究目标轨迹运动趋势进行目的地预测有了更多的研究价值:预知用户出行目的地可以优化资源调度,发现位置中隐藏的用户行为偏好,实现定向广告推送、热门地点推荐等。当下普遍使用的目的地预测主要是频繁模式挖掘、Markov等基于历史出行轨迹的位置预测算法。近年来得益于并行计算的发展,深度学习快速兴起,目的地预测在应对海量复杂多样的轨迹数据上有了新的突破,多层感知器(Multi-Layer Perceptron,MLP)、循环神经网络(Recurrent Neural Network,RNN)等诸多机器学习模型在位置预测领域得到广泛应用。但是由于轨迹数据的局部分布、序列过长、密度不均、稀疏以及语义缺失等特性,目前的研究成果仍然普遍存在数据特征利用不充分,且存在不同移动对象间关联性缺失等问题。近年来卷积神经网络(Convolutional Neural Networks,CNN)的出现将深度学习推向了近乎所有机器学习任务的最前沿,传统的经典CNN模型具有较低尺度适应能力,诸多研究者设计出了适合轨迹数据挖掘的卷积神经网络,重点提升网络的特征学习能力,使得CNN在目的地预测技术中普遍应用并取得了不俗的成果。本文对国内外目的地预测的研究现状进行深入分析,提出了一种基于深度学习,带有注意力机制的目的地预测技术,构建出一种新型目的地预测模型:MSCNN(Multi-Scale CNN)。该模型在轨迹预处理的基础上,对ID类、用户信息类数据进行元特征嵌入(Embedding),通过因子分解(Factorization Machine,FM)自动提取二阶组合特征送入多层感知器网络,充分挖掘GPS(Global Position System)数据之外的特征信息;对于CNN部分,使用轨迹随机截断后,对轨迹点进行网格化和像素化处理并作为CNN的输入;针对轨迹数据的多尺度特性、密度差异等影响因素,采用多尺度卷积核的卷积层,并对多尺度卷积过程引入视觉注意机制,获取自学习的权重对特征图进行重标定,进一步提升神经网络的空间注意力,挖掘轨迹矩阵的深层特征;融合多层感知器和卷积神经网络联合训练,结合Mean-Shift热点轨迹簇进行概率加权,预测出行目的地。本文利用葡萄牙波尔图市区真实的出租车轨迹数据进行实验,通过轨迹随机截断和聚类分析,针对随机轨迹前缀来预测该市区的出租车行程目的地,预测结果使用Haversine距离函数计算出偏差仅约2.5千米的距离损失预测结果,通过多组实验对比,本文提出的MSCNN模型效果明显好于传统神经网络的2.75千米和基础卷积神经网络的2.55千米,证明了模型的有效性和可靠性。本文提出的多尺度卷积神经网络为目的地预测研究提供了一种新的方法,在实际场景中有良好的应用价值和发展前景。"
909,带有方差减小技术的随机优化算法的研究及其在大规模机器学习问题中的应用,"优化是机器学习研究的关键一步。几乎所有机器学习问题的模型求解都依赖于优化算法。因此,设计快速、有效的优化算法在机器学习研究中至关重要。本文考虑两种不同类型的机器学习优化问题,并分别提出相应的改进算法。本文首先考虑机器学习领域的一个基本问题――结构风险最小化。本文中,结构风险可以表示成很多凸的损失函数的平均,再加上可能并不光滑的凸正则化项。为了更快,更好地求解出经验风险的最小值点,我们提出一种加速的带有方差减小的随机梯度算法Prox2-SAGA。和传统的算法不同,Prox2-SAGA把对损失函数求梯度换成求其梯度映射(Gradient Mapping)。这会牵涉到对损失函数求临近点算子的操作。此外,Prox2-SAGA还会计算正则化项的临近点算子以应对其非光滑性。这两个临近点算子的计算需要用Douglas-Rachford分裂来处理。损失函数强凸且光滑时,我们证明得到Prox2-SAGA算法可达目前最快的加速线性收敛速率。除此之外,相较于其他加速方法,Prox2-SAGA只有步长这个参数需要调整,因此它更容易应用。当每一个损失函数都光滑且凸时,我们证明Prox2-SAGA能达到O(1/k)的收敛速率,其中k是算法的迭代次数。此外,实验结果表明,Prox2-SAGA对于非光滑损失函数也是有效的,而对于强凸且光滑的损失函数,Prox2-SAGA在损失函数病态时加速效果显著。很多时候,结构风险函数中的正则化项需要是复合形式,以导出结构化稀疏的解,本文的第二部分将考虑带有这种正则化项的函数的优化问题。为了处理非光滑的正则化项,常规做法是使用临近点算子。但是,复合形式的正则化项的临近点算子的值难以被计算得到。最近,临近点平均,一种临近点算子容易计算的函数,被用来近似这种正则化项。进一步地结合带有方差约减的随机算法,基于临近点平均的算法能达到更好的表现。但是当前的工作多采用固定步长,算法的步长需要被设置的较小以使得临近点平均对原正则化项的近似较精确,这种较小的步长将会导致算法的迭代次数非常地多。本文中,我们提出两种基于临近点平均的步长自适应算法,APA-SVRG和APA-SAGA。通过以较大的值初始化步长,并自适应地减小它,两种算法都被证明只需要O(n log 1/ε+m01/ε)次迭代,即可达ε精度的解,其中m0是算法内层循环的起始数目,n是样本的数目。此外,实验结果表明了我们算法的优势。"
910,基于深度学习的超窄间隙焊接质量评估方法研究,"近年来,随着科学技术的飞速发展,各种金属结构需求呈现高强度、大型化及厚板化,目前常用的焊接方法均存在一些不足。焊剂带约束电弧超窄间隙焊接方法是单道多层焊接,满足高效、节能、绿色的焊接理念,因此将该方法应用到焊接生产中意义重大。但是,超窄间隙焊接方法比其它焊接方法过程更复杂,焊接过程中电弧稳定性受各种因素的影响,易出现偏焊与夹渣等焊接缺陷。本文针对超窄间隙焊接中焊接质量无法观察、难以在线检测以及易出现缺陷等问题,结合焊接方法与焊接工艺,将深度学习理论应用到超窄间隙焊接质量评估中,以期能够实现超窄间隙焊接质量的无损评估,为进一步实现超窄间隙焊接质量在线评估与预报奠定基础。主要介绍了超窄间隙焊接试验平台并设计了信号采集系统;在焊接试验平台与信号采集系统的基础上,设计焊接试验,采集了大量的焊接过程信号,并记录了相应的其它焊接过程参数;通过对比,选用滤波效果较好的中值滤波算法对信号进行处理,并从焊接过程参数与焊接过程信号中提取了22个特征参数作为焊接质量评估的样本特征;分析了浅层神经网络存在的不足,并分别运用BP神经网络、支持向量机建立了超窄间隙焊接质量评估模型,评估准确率相对较低,进一步说明传统的神经网络不适用于这种过程复杂、机理不清的焊接过程;介绍了深度学习相关理论,在TensorFlow框架下建立了基于深度学习的超窄间隙焊接质量评估模型,对焊接质量进行评估。为了保证评估结果的准确性,对BP、SVM与DNN分别进行50次试验,通过比较可得,深度神经网络取得了较高的模型识别准确率。综上可得,相对于传统浅层神经网络而言,基于深度学习的超窄间隙焊接质量评估模型能够较好地进行焊接质量评估;此外,试验结果也表明提取的特征参数能够较好地反映焊接质量。"
911,《预测机器：人工智能的简单经济学》（1-4章）英汉翻译实践报告,"人工智能的意义非凡并受到世界瞩目,它不仅改变了商业领域的游戏规则,也让人类的工作变得比以往更加智能和便捷。国外涉及该领域的最新著作对于中国读者进一步了解科技发展形势有着重要作用。本论文是一篇与人工智能有关的英汉翻译实践报告。原文文本节选自《预测机器:人工智能的简单经济学》的前四章,该著作由阿贾依・阿格拉沃尔,约书亚・甘斯和阿维・戈德法布联合撰写。该书重申了智能机器预测的力量和数据的重要性,还讨论了如何通过使用人工智能来优化商业决策、工作流程和管理运营。该报告首先依据凯瑟琳娜・莱斯的文本类型理论将原文划分为信息型文本,其语言充满客观性与逻辑性。在此翻译实践报告中,译者主要讨论了翻译过程中遇到的难题及其解决方法,以使目标读者可以更加准确地了解人工智能。针对翻译难题,译者主要从词汇和句法两个层面进行了分析。在翻译科技、经济领域的术语时,译者采用了加注和移译的方法;针对长难句,译者采用了句式重构的方法;为了保证译文衔接流畅,逻辑关系紧密,译者又从语篇层面出了解决方法,包括照应和替代。通过使用以上方法,译文可以更加准确和流畅。本次翻译实践具有一定的价值,为国内研究人工智能的读者供了建议。尤其是对企业经营者来说,他们可以从译本中获得一些灵感,改变商业模式以获取更大的利润。另外,译者还希望通过从词汇、句法和语篇层面总结出的翻译方法为今后翻译科技类文本供借鉴。"
912,基于机器学习的光网络告警智能分析技术研究,"随着光传送网络(OTN)规模的扩大,光链路和OTN设备的不断增多,网络一旦出现故障,往往会引发一系列设备产生众多告警。传统的人工方法很难短时间内从数量巨大的告警中找到有用的信息,正确地判断出故障的位置,及时对故障进行修复。机器学习是近年来兴起的智能技术,在光通信中发挥着越来越重要的作用,利用其对光网络告警进行分析与处理,具有重要的实用价值。本论文围绕光网络中告警分析存在的数量庞大、信息冗余、时间异步、告警属性重要性不明确等问题展开研究,并结合实际光网络的告警日志对所提算法和方案进行训练和测试验证。论文的主要创新点如下:第一,针对光网络信息冗余、时间异步问题,设计并实现了基于时间序列划分与时间滑动窗口相结合的告警事务提取方法,实验结果表明该方法可以将原始告警划分为若干个时间段告警序列,从而实现告警事务的初步提取,同时通过滑动时间窗口,在告警序列的每个时间段进行告警同步和冗余消除,实现初步的告警压缩。第二,针对告警属性较多但其重要性不明的问题,提出并实现了基于机器学习的告警重要性量化分析算法,该方法能够利用机器学习算法对告警属性重要性进行量化评估,得到每个告警属性的重要性权重。将上述告警事务提取方法和告警重要性评估方法合称为告警预处理方法,它可以更有效、更客观的处理原始告警,有利于后续进一步的告警压缩和分析。第三,针对传统关联挖掘算法视所有告警重要程度相同的问题,提出了基于改进型Apriori的连锁告警挖掘算法,能够有效的分析告警事务集间的关联,得到高频连锁告警关联规则,实现告警进一步压缩,有利于快速定位故障。"
913,基于深度学习的无线信号的识别技术研究,"现如今随着5G和物联网的诞生,海量设备的接入和更多广域低功耗业务信号的出现已成为必然。为了适应不同业务场景涌现出越来越多的业务信号,信号业务类型的识别已经成为一个热门的研究课题。不论在军事领域还是日常生活都有很广阔的应用前景。如今信号识别领域大多数的研究集中在无线信号的调制方式的识别,传统且常用的方法是提取无线信号IQ数据的专家特征如高阶循环谱特征、高阶累积量等,传统专家特征计算复杂而且不能对所有信号进行统一的标识,需要进行多次标记才能实现对一种调制方式进行识别。虽然近几年已经有团队结合深度学习和机器学习来改进信号特征提取,使得无线信号特征提取更加容易且高效,但大多仍旧是基于IQ数据对信号调制方式的识别。随着越来越多业务场景的出现,不同的业务信号类别的涌现,各种业务信号采用了更为复杂的多重调制方式,甚至很多新型的物联网信号的调制方式就是在传统无线信号的调制方式下得到的。所以仅仅识别信号的调制方式并不能获得信号的所有信息,单一的进行调制方式的识别已经不能满足需求。不同于传统的信号识别研究本文主要工作是利用无线信号的功率谱数据结合深度学习算法模型对无线信号的业务类型进行识别。主要成果如下:1、提出了一种基于无线信号功率谱波形曲线的拟合因子的特征提取方法,并构建了神经网络分类器模型利用该方法提取的特征对不同业务的无线信号进行识别,10万次迭代训练之后模型识别准确率在97%以上,给出了识别效果和模型构建的相关信息,并对比了与统计特征提取的差异。2、构建了卷积神经网络模型实现了对无线信号功率谱波形特征的自动提取,给出了模型构建的相关信息和实验结果,500次以上的训练模型识别准确率就达到99%以上。并且与传统机器学习进行了对比实验,还对模型泛化性能和迁移性能进行了实验仿真并给出了结果,数据失真低于80%的情况下,卷积神经网络分类模型的识别准确率仍能保持在90%以上。3、提出了引入空间金字塔池化层改进卷积模型,实现了对任意尺寸输入信号功率谱数据的特征提取和识别。给出了空间金字塔池化层结构信息以及利用空间金字塔池化层对整个卷积模型进行信号识别的影响,实验表明改进后的卷积神经网络针对不同尺寸的数据输入都可以达到99%以上的识别准确率。4、构建了反卷积模型实现了对卷积神经网络模型每一层的可视化。给出了反卷积模型构建参数和可视化结果。5、首次提出了利用卷积自编码器实现对无线信号功率谱波形的模板制作以及利用模板进行匹配识别的相关步骤。给出了卷积自编码器模型结构参数,以及模板匹配的效果可视化。利用模板作为特征向量进行信号业务识别准确率可以达到9 9%以上。6、利用python的Django框架搭建了无线信号业务识别的展示系统。本文通过结合深度学习和机器学习算法对无线信号的功率谱数据进行特征提取并实现业务类型的分类。用有监督和无监督的学习算法来进行特征提取和分类,本文提出的基于拟合因子的特征提取方法相比于传统的信号特征提取方法,计算更加简单,特征标记统一无需对不同信号提取不同特征来进行标记。最终的卷积神经网络分类模型针对几种实验信号的业务识别准确率可以达到99%以上,并且通过一系列的对比实验验证了文中模型的优越性。最后还引入了无监督学习的方法来实现对无线信号的特征提制作模板,利用模板匹配的方法实现信号业务类型的识别。"
914,WiFi环境下基于1D-CNN的动态手势识别关键技术研究,"随着物联网(Internet of Things,IoT)技术和人工智能的不断发展,基于WiFi信号的动态手势识别技术有望提供一种全新的人机交互(Human-Computer Interaction,HCI)方式。近年来利用信道状态信息(Channel State Information,CSI)的手势识别系统虽然己取得巨大进展,但CSI不能通过市面上绝大多数商用网卡直接提取,而易获取的接收信号强度指示(Received Signal Strength Indication,RSSI)在目前研究中还只能识别比较简单的手势动作如手的上下挥动。为了提高系统对手势的识别能力上限,本文从多个独立的物联网WiFi节点中提取瞬时接收信号强度(Instantaneous Received Signal Strength,IRSS)信息,使系统能识别7种复杂的动态手势。为了实现手势的自动检测,本文通过分析手势对信道影响的原理,提出了完整的手势自动检测算法,并特别设计了误触发检测算法,能有效消除手势的误触发问题,使得系统的手势检测准确率能达到91.38%。系统通过状态跳转识别手势的开始和结束,结合线性缩放处理,从而能对用户不同的手势速度进行适应。最后,为了进一步提高系统的识别率,本文就手势检测模块得到的手势分段起点与终点的平移误差问题进行了详细的分析,提出了基于一维卷积神经网络(One-Dimensional Convolutional Neural Network,1D-CNN)的识别架构以及手势截取加长和手势截取平移两种数据采集策略。一维卷积神经网络架构能有效发挥卷积神经网络的平移不变检测原理,消除自动分段误差造成的影响,而两种数据采集策略能在数据采集阶段采集到信息更加丰富的样本,进一步提高系统的整体性能。通过实验验证,该算法的平均识别准确率高达93.03%,优于其他传统的机器学习算法。"
915,基于深度学习的文本情感分析技术研究,"在Web2.0时代,信息技术飞速发展,人们越来越多地在网络平台上发表自己的观点和意见。随着这些评论数据量的爆炸式增长,如何提取利用其中的情感信息也成为人们的关注热点,文本情感分析技术随之兴起。情感分析工作就是对含有情感色彩的主观性文本进行分析,挖掘出其蕴含的情感倾向的过程,而文本的主客观分析是情感态度分析的基础。作为自然语言处理领域的一个重要分支,情感分析在理论方面有着较高的研究意义。随着词向量的提出,基于深度学习的自然语言处理技术快速发展。面对大量的文本数据,深度神经网络强大的学习表达能力得到了展现。本文对基于深度学习的文本情感分析技术进行研究,主要工作如下:第一,构建了基于多头自注意力机制的文本情感分析模型。研究了深度学习中的注意力机制,其中自注意力机制能够关注到文本内部词语之间的依赖关系。因此,在文本情感分析任务上,引入了多头自注意力机制,并通过结合非线性子层双向门控循环单元增强模型的学习能力。实验结果表明,构建的模型在情感分析任务上的准确率得到了提升。第二,针对情感分析的子任务主客观分析,构建了基于线性门控卷积的网络模型。通过对不同的门控机制进行研究,在卷积神经网络的基础上引入了线性门控机制;并使用多个不同尺寸的卷积核提取文本特征。实验结果表明,构建的模型在主客观分析任务上表现突出,性能优于其他模型。论文主要的创新点和贡献是:将多头自注意力机制引入到文本情感分析领域,并通过结合非线性子层对模型进行了改进,提升了模型的准确率;在文本主客观分析任务上,通过线性门控机制对卷积网络进行改进,并根据文本数据的特性构建了不同尺寸的卷积核,有效地提升了模型的性能。"
916,实体关系抽取模型研究与性能提升,"自由文本中包含大量非结构化的重要信息,这些信息难以被直接利用。实体关系抽取是一项将非结构化文本中的信息提取并形成结构化信息的重要技术。近年来,机器学习技术和实体关系抽取的结合得到了研究者们的高度重视。有监督的机器学习方法需要人工标注数据,而人工的高昂成本是阻碍这一研究的重要因素。利用弱监督学习的实体关系抽取又存在错误标注问题,以及机器学习模型自身的的过拟合问题。针对这些问题,本文的主要工作有:针对传统的基于深度学习的方法使用较为浅层的网络作为句子编码器,而对于表达能力较弱的问题,本文设计并实现了一种基于深层次激发-压缩卷积神经网络模型,进行端到端的实体关系抽取。结合软标签的方式,减轻远程监督数据集中的噪音现象,提升模型性能。针对远程监督数据集中样本不均衡和难易样本的问题,本文改进了深度学习中的损失函数,使用聚焦损失函数替代交叉熵函数。聚焦损失函数既能够根据样本的均衡程度对样本加权,又能够根据样本学习的难易程度对损失函数进行加权,从而提升作为分类任务的实体关系抽取模型的性能。针对卷积神经网络应用在自然语言处理任务中常用的最大值池化方式会丢失位置信息等问题,本文设计并实现了双重池化方式。同时针对深度学习容易过拟合的问题,本文还采用了几种适应于弱监督学习的模型正则化方法,包括随机深度算法、随机字舍弃算法和对抗训练。这些方式均不同程度上减轻了过拟合现象,提升了模型性能。"
917,面向新工科教育的工业互联网在线实验平台设计与实现,"随着工业互联网的迅猛发展,相关专业人才需求日渐旺盛,高等院校相关专业教育随之迅速发展。教育部也适时推出了新工科教育建设。工业互联网是一个需要融合机械制造、工业工程、计算机与电子通信等交叉学科知识的新工科领域。工业互联网人才的培养强调面向实际问题,培养工程思维和动手实践能力。融合交叉学科知识的新技术学习将改变现有的传统教学模式,需要高校学生通过一种实践引导的自学模式开展项目式实训,因此需要在线实验平台和工具的支撑。市场上面向工业互联网应用场景的相关教学实验工具还比较匮乏。因此,本论文提出面向新工科教育的工业互联网在线实验平台的解决方案,为工业互联网专业学生提供一站式的教学、实验服务平台。本论文基于软件工程思想和方法,对面向新工科教育的工业互联网在线实验平台进行了需求分析与系统设计、系统实现与测试。系统设计上,通过分析工业互联网专业特点和新工科教育对人才的要求,明确系统的功能需求,设计了PHM实验模块,计算机教程和练习模块,学习社区模块三大功能模块。首先,PHM(Prognostic and Health Management),即故障预测和健康管理,是综合利用现代信息技术而提出的一种管理设备健康状态的解决方案,广泛应用于工业互联网各个领域。PHM实验模块,封装了 PHM技术常用算法,并将PHM实际案例整理成实验,用户在实验过程中学习相关技术。其次,计算机教程和练习模块包含一系列的计算机各领域教程和相应的练习工具。最后,学习社区模块,支持用户在不同的板块发帖和评论。系统实现上,后台实现采用Spring+SpringMVC+Mybtis框架,将表示层,业务逻辑层和数据访问层分离,加强了系统的可维护性。系统采用MySQL关系型数据库存储数据,采用Nginx进行负载均衡,提高系统并发效率;使用Redis缓存数据和解决session一致性问题;使用weka和scikit-learn作为算法引擎。本论文对系统进行了功能测试和性能测试。功能测试结果证明平台各模块可以稳定运行,达到预期效果;性能测试结果表明,平台可用性基本满足需求。"
918,基于机器学习的工业故障预测与健康管理关键技术的研究,"在“智能制造2025”的大背景下,如何用信息技术解决传统制造业中的痛点问题成为了当前的研究焦点。工业界和信息领域为解决设备故障与维修这一痛点,提出了故障预测与健康管理(PHM),其关键技术是基于机器学习进行故障诊断与预测。本文对人工智能在故障诊断与预测中应用的关键技术进行研究,提出了基于深度学习的端到端故障诊断与预测模型及数据集不平衡问题的改进方法,主要工作如下:第一,设备故障数据集维度高专业性强的特点决定了特征工程在本任务中的重要性。本文通过研究该领域的已有方法,利用卷积神经网络(CNN)在空间特征提取上的优势,构建了基于CNN的故障诊断与预测模型,实现自动的特征提取,并通过对比实验验证了 CNN在设备故障数据特征提取工作中的有效性。第二,根据故障数据集时间序列这一特点,将适用于时序分析的长短期记忆网络(LSTM)与CNN结合,处理CNN部分输出的特征序列,以弥补CNN无法充分提取时间特征的不足。同时根据对时序分析问题中LSTM的研究,选定了能学习上下文信息与深层时间特征的栈式双向LSTM结构,提出了端到端的CNN-StBiLSTM故障诊断与预测模型,并通过具体实验设计了合适的预处理方式,验证了该任务中CNN结合LSTM的有效性、栈式双向LSTM结构的优越性、所提模型相比常用模型的优越性。第三,针对故障数据集类别不平衡这一特点,在所提模型的基础上将图像识别领域中处理不平衡问题的Focal Loss引入到故障诊断与预测任务中,通过实验验证了其相比传统方法的有效性。随后本文创新地提出了基于Focal Loss和随机欠采样的集成学习方法,用随机欠采样代替Focal Loss中的类别权重系数,同时结合套袋法集成学习思想,利用其互补优势进一步提升模型效果,并通过对比实验进一步验证了所提模型及改进方法的优越性。"
919,安卓应用中资源滥用行为检测方法研究,"安卓手机是目前最流行的移动平台,各种安卓应用也很大程度上方便了人们的生活。由于安卓系统的内存等系统资源不足时会通过强制结束部分进程的方式来释放内存,为了避免进程被杀死导致无法给用户提供服务,安卓应用会利用各种方式在后台保活。有些应用为了给用户提供更加个性化的服务,还会获取用户的一些隐私数据,比如用户的手机号,地理位置信息等等。目前攻击者通过获取用户的隐私数据,以及安装能后台保活的恶意应用,获取了巨大的利益。由于这些行为在正常应用中也会出现,这使得检测这类行为变得困难。研究者们提出了许多方案来检测隐私数据泄露行为,主要包括静态检测方案和动态检测方案,但目前无论是静态检测方案或者动态检测方案,都是在应用层面进行检测,而没有具体到检测特定的恶意行为。对于应用的后台保活行为,目前相关研究工作中的方法还不足以区分正常的保活行为和恶意的保活行为。针对以上两个问题,本文做了以下的研究工作:1.安卓应用中后台播放无声音频的恶意保活行为的检测安卓应用后台保活的一种方式就是在后台播放无声音频。针对应用后台播放无声音频实现恶意保活,占用系统资源或者伺机窃取用户隐私的行为,本文提出了一个基于一类支持向量机的检测方案。由于安卓应用中也存在着正常的后台播放无声音频来保活的行为,为了有效进行区分,本文对安卓系统进行了修改,收集应用后台播放无声音频保活时的音频数据和传感器数据,再使用一类支持向量机来检测应用中恶意的保活行为。实验中此方案的真负类率(负样本被识别出的数目占所有负样本的比率)达到了96%。2.安卓应用中隐私数据滥用行为的自动化检测针对恶意应用滥用用户的隐私数据的问题,本文实现了一个基于行为相似度对比的恶意隐私数据使用行为的检测模型。此模型利用安卓动态检测技术,获取安卓应用运行时的相关信息,通过对比同类别应用的隐私数据使用行为与当前应用的隐私数据使用行为的相似度,来判断当前应用的隐私数据使用行为是否是恶意的。实验中每个类别的平均真负类率达到了90%以上。"
920,基于骨架程序的并行程序运行时间预测方法研究,"随着超级计算机的发展,对超算平台上运行的并行程序的运行时间预测成为了一个重要的研究问题。面对这一问题,对并行程序构建骨架程序的方法能够在程序的运行环境发生改变的情景下对程序的运行时间作出预测。但是骨架程序无法对程序在不同输入下的运行时间进行预测,导致其适用范围较窄。在骨架程序方法的基础上,本文提出了一套能够对并行程序在不同输入以及不同运行环境下的运行时间进行预测的方法。本文所介绍的主要工作包括:1.使用代码插桩的方法来对并行程序中分支和循环的执行情况进行记录,从而获取程序在不同输入下的执行逻辑,并使用逻辑回归和LASSO回归算法来训练一个能够从程序的输入预测其执行逻辑的预测模型。2.根据获取的执行逻辑来对并行程序的多个进程进行聚类,之后使用Tracing工具来生成并行程序的通信Trace,并根据聚类的结果来对Trace进行合并与压缩的处理。之后,结合通信Trace和对执行逻辑的预测结果来还原并行程序的运行过程,从而得到一个新的反映了原始程序运行过程的还原程序。还原程序的执行时间比原始程序要短,从而能够以较少的时间代价完成对原始程序运行时间的预测。3.对MCB、LULESH和STREAM三个并行程序在不同的输入与运行环境下的运行时间进行了预测,并结合各个程序的特征对实验结果进行了分析。实验结果证明,对于适用范围内的并行程序而言,本文提出的方法能够获得良好的预测性能。"
921,跌倒检测算法研究及其在移动机器人平台系统实现,"随着人口老龄化加剧,世界各国都面临老龄人口增加和医疗资源紧张的社会问题,这其中对老人进行跌倒监测和救护是重点之一。世界各国研究机构和企业针对跌倒检测方案开展了广泛的研究和试验,很多跌倒检测算法和商业产品相继问世,但普遍存在准确率低、实用性有限、用户使用体验差等问题。随着人工智能和自动化技术的发展,移动机器人在各个领域中起到了越来越重要的作用,在跌倒检测任务中亦是如此。移动机器人在改善用户体验和增强人机交互的同时,可以弥补传统检测方案灵活性不足的缺点。本文以此为出发点,旨在研究并实现一套基于移动机器人的跌倒检测算法,提高算法的准确性并且在实际生活场景下改善用户的使用体验。本文的主要工作和贡献总结如下:(1)讨论了目前国内外各种跌倒检测算法存在的优缺点,对老年人的日常行为进行了总结。详细分析了人体在跌倒过程中和跌倒后的姿态特征变化,对跌倒动作进行了定义,指出了检测算法可以根据人体跌倒后的动作特征、人与地面的语义关系两个方面进行设计和实现。(2)利用跌倒过程中人体轮廓特征变化较大的特点,设计并实现了一种基于人体轮廓特征的跌倒检测算法。算法首先使用目标检测算法检测人体目标区域,然后提取人体区域宽高比、质心高度、离地高度和方向角四种特征,训练SVM分类器进行分类,算法在公开数据集上的精确率高于现有算法。(3)提出了一种新的检测算法CRN(Coexistence Relation Network)。CRN在提取目标本身细节特征的同时,有效地利用了全局上下文信息辅助检测任务,提高检测算法的准确率。CRN是端到端的,可以简化训练和测试过程,保证了算法能够快速准确地完成检测任务。多个公开数据集上的实验结果表明CRN可以将目标检测的mAP提高1%左右,动作识别提高1.3%,跌倒检测提高1.7%。(4)搭建了一套基于移动机器人的跌倒检测系统,验证了本文算法在有限计算资源条件下的有效性和实用性。移动机器人负责图像的采集、传输以及进行检测位置的调整,引入云端检测平台来完成接收数据、跌倒检测和报警等任务。在实际场景下,整套系统可以流畅的完成跌倒检测任务,有着较好的用户体验。"
922,基于深度学习的地震事件检测及波形初至拾取方法研究,"近年来,随着国家在防震减灾投入的不断增加,地震监测网络逐步完善,地震台站记录了大量的波形数据,这些波形数据为地震定位、地震分析等研究提供了数据支撑。在处理连续波形数据时,首先从连续的波形数据中检测包含地震事件的波形片段,然后在包含地震事件的波形片段中拾取波形初至时间。相关处理最初由受培训的专业人员人工完成,需要耗费大量的人力成本和时间成本,因此自动化的地震事件检测和波形初至拾取方法成为学术研究的热点。地震台站接收波形数据,收集连续不断的波形记录。在处理波形记录时,首先检测地震事件,然后拾取波形初至。地震事件检测是指从连续的波形数据中找出含有地震事件的波形片段,波形初至拾取是指在地震事件中识别出地震波P波(横波)和S波(纵波)首次到达观测台站的时间。目前流行的自动化处理方法STA/LTA(长短窗均值比法)以及AR-AIC(自回归赤池信息准则法)主要从信号处理的角度出发,通过设计波形相关的属性、设置阈值并进行大量的调参工作以达到最优效果。STA/LTA以及AR-AIC方法不仅需要设计者具备专业的地震知识,而且需要大量的调参工作,虽然处理速度快但其效果受噪声影响大。随着人工神经网络的发展,有学者开始研究基于人工神经网络的自动化处理方法。尽管这些方法省去人工调参的工作,但仍然需要人工设计输入到人工神经网络的特征,人工设计的输入难以完全利用波形数据中包含的信息。本文首先阐述地震事件检测和波形初至拾取的研究背景,介绍和分析了地震事件检测和波形初至拾取的相关算法以及深度学习研究进展。针对地震事件检测任务,目前大多数利用卷积神经网络的方法忽视台站之间因地理位置可能导致的差异,针对所有台站只训练一个检测网络,利用大量数据训练,取得了良好的效果,但是在数据量减少时效果会大幅退化。针对波形初至拾取任务,传统的STA/LTA和AR-AIC方法不能完全利用波形数据的序列性,且受噪声影响大,一些基于深度学习的方法以波形数据为输入取得了良好的拾取效果,但是由于地震数据序列较长,其方法只能用于微小地震。针对上述挑战,结合地震数据的特点,本文主要贡献点如下:(1)针对少样本的地震事件检测问题,本文考虑到地震台站因所处地理位置所导致的差异性,提出了一个基于多任务学习的地震事件检测模型。首先,本文以台站间距离作为聚类的标准,对各地震台站进行聚类并将各地震台站簇检测地震事件视为单个学习任务。其次,对多个任务使用基于硬共享的深度多任务学习方法,联合多台站数据对每个学习任务建立单独的地震事件检测网络。实验表明该方法提高少样本情况下使用卷积神经网络检测地震事件的效果。(2)针对波形初至拾取任务,本文充分利用地震数据的序列性,借助序列标注的思想,提出了一个基于深度学习的拾取模型。首先,本模型设计了一个网络,以序列数据为输入,对序列数据实现降维并利用序列标注得到波形初至的大致到时。其次,利用大致波形初至到时切分波形,并将传统拾取方法应用于切分出的波形数据,从而精确拾取波形初至到时。实验表明该拾取模型鲁棒性好,拾取成功率高,拾取误差小,且所提出的网络具有良好的迁移性。"
923,精准医学知识库构建中的生物医学命名实体识别研究,"精准医学是通过整合分析患者生物医学数据,构建发现个体患病机制的知识图谱,制定个性化诊疗方案的前沿医学理念。以基因-变异-疾病关系为核心内容的生物医学知识库,对精准医学的科学研究和临床实践都具有不可替代的重要作用。面对海量且飞速增长的生物医学文献,通过人工抽取知识将耗费大量的时间与人力,因此利用机器学习技术自动挖掘生物医学文本逐渐成为精准医学知识库构建中的关键环节。生物医学命名实体识别,即用计算机自动识别出文本中表示指定生物医学实体类型的名称,是生物文献知识挖掘过程中基础而关键的一步。本文以精准医学知识库构建为背景,对生物医学文献中的基因、基因变异、疾病三种命名实体识别的方法和技术开展了系统研究,提出了结合深度神经网络和传统方法,用于识别基因变异实体的新算法模型,开发了识别和标注三种实体的软件系统。主要研究结果如下:1.对生物医学命名实体识别算法的研究现状进行了调查,并对算法中采用的各种方法模型展开了研究。调研发现当前主流的疾病与基因变异识别模型大多基于统计机器学习算法,需要繁复的人工特征工程,且依赖设计人员的专业知识背景和自然语言处理经验。同时,基因命名实体识别算法较为成熟,已经存在多种成熟的识别工具,而能够识别基因、基因变异、疾病三种实体的系统鲜见发表,简便的高性能算法和多实体识别系统有待开发。2.提出和实现了一种创新的结合深度神经网络和规则方法的基因变异识别算法。利用作者提出的深度分词策略,将单词根据大小写、数字和特殊符号切分,然后训练可以捕捉变异实体内部结构信息的表征向量。随后将表征向量输入双向长短期记忆网络(Bi-LSTM),得到每个词的单向量表示,再将词的向量序列输入下一级Bi-LSTM网络并连接两个全联接层,输出每个词的标签概率。为进一步提高识别性能,采用Viterbi算法优化神经网络输出,再和正则表达式匹配输出结合得到最终标注结果。该算法在tmVar mutation corpus语料上取得91.59%的F-值,高于其他所知的已报道系统。3.为实现对生物医学文本中的基因、基因变异和疾病三种实体的快速识别定位,组合了已有的基因识别算法和课题组自主开发的疾病识别算法和基因变异识别算法,通过并行的对文本进行标注处理、再采用最长序列覆盖方法综合不同标注算法输出的方式,构建了自动标注文本中基因、基因变异和疾病实体的软件系统。该系统操作简单,可以快速准确的标注目标实体,为实现目标实体间的关系抽取打下了基础。"
924,基于卷积神经网络的腰椎骨质增生检测,"近年来,人工智能技术得到了迅速发展,机器学习技术不断得到改进和发展,深度学习不仅在金融,农业,交通等领域得到广泛应用,而且医学领域的研究也逐渐增多,在医学领域,深度学习在病灶分割、疾病诊断、图像分类等方面取得了突出成就。在癌症、脑肿瘤、心脏病、皮肤病、帕金森病、癫痫、抑郁症等疾病的研究中取得了丰硕的研究成果,不仅缓解了医务人员的工作压力,而且也提升了医疗器械的技术水平,提高疾病的诊断效率,方便患者及时就医。然而,目前人工智能在腰椎疾病方面的相关研究还较少。本课题针对目前人工智能在医学图像领域的研究趋势,以腰椎骨质增生疾病为研究对象,以腰椎X影像图为研究基础,提出了一种基于卷积神经网络的腰椎骨质增生检测分类的神经网络模型,实现对腰椎椎关节骨质增生的智能检测分类,将输入到神经网络模型的腰椎椎关节图像识别出是否患有骨质增生。在研究过程中建立了腰椎骨质增生图像数据集,包括腰椎椎关节正面图像二分类数据集4245张其中包括正面患病、正面正常两个类别,正、侧面腰椎椎关节图像四分类数据集9005张,其中包括正面患病、正面正常、侧面患病、侧面正常等四个类别。在腰椎影像资料中,对搜集到的腰椎图像进行图像预处理,包括对图像进行筛选、截取、扩增、命名、大小统一化以及图像边缘提取等。本课题基于LeNet网络模型的层数设计以及AlexNet网络模型的参数设计的方法,将两种网络进行融合,提出了一个小型、轻便的卷积神经网络模型,能够对小尺寸的腰椎椎关节骨质增生图像进行识别、分类,通过调整卷积核的数量、卷积核的大小、学习率以及Dropout等参数来微调神经网络模型,逐步的优化网络模型,在不断训练模型的过程中得到一个高效的、识别精准的网络模型。在linux系统下,基于TensorFlow的开发框架,利用Python编程语言对腰椎椎关节的骨质增生疾病进行了分类实验,分别进行了腰椎正面椎关节图像的二分类实验,在二分类实验中,测试集上的识别分类精确度达到93.29%,ROC曲线下的面积AUC的值达到0.97;腰椎正、侧面椎关节图像的四分类实验中,测试集上的识别分类精确度达到87.95%;将腰椎椎关节图像输入到几种神经网络模型中,对识别的分类结果进行了对比,融合后卷积神经网络模型分类的准确率高于LeNet网络模型的86.8%,AlexNet模型的83.76%,VGG-16网络模型的90.34%的分类准确率。依托人工智能技术,极大地减轻了医务工作人员的工作压力,降低了临床诊断的误诊率,有效的帮助患者及时就医,避免病情的延误,同时也为腰椎骨质增生疾病的诊断提供了更加科学的诊断依据。"
925,甚高频天线阻抗检测装置的研究与应用,"在甚高频通信中,由于环境、温度等因素的影响,天线的阻抗是一个实时变化的参量。为了高效地传输信号,常采用天线调谐系统对天线阻抗进行匹配,为此需要对天线单元的阻抗进行精确地测量。本文首先调研了常见的几类阻抗检测方法,通过对比各方案的优缺点,结合本文所要设计的阻抗检测装置具体应用环境,选择矢量阻抗检测法作为设计的核心算法。随后根据阻抗检测装置需求指标,完成了基于超外差原理的架构设计以及检测算法设计,并结合方案实际,构建了单端口误差校准模型。之后分析了阻抗检测装置中关键器件的非理想特性,明确了各硬件模块具体指标,并据此对涉及到的硬件模块进行了仿真设计,主要包括频率源、功率分配器、定向耦合器等。其中频率源以1MHz步进输出50MHz-90MHz的正弦信号;定向耦合器耦合度为20dB,隔离度在30dB左右;并实现了插入损耗为3dB的功率分配器。最后,根据测试结果,深入分析了单端口阻抗检测方案的不足,并在现有检测方案基础上,引入了以机器学习为核心的精度提升方案,构建了稳定而可靠的精度提升模型。仿真实验证明,机器学习可以作为一种有效的精度提升方案。"
926,基于机器学习的数字信号解调与识别的研究,"数字信号的调制和解调在通信系统中起着重要作用,随着社会的信息化发展,对多种类型信号进行智能化处理的需求应运而生。本文提出了一种基于机器学习方法的数字信号智能接收机,利用神经网络对未知调制信号进行调制识别及解调。作为一种自适应解决方案,该接收机在保证了良好的解调性能的同时,提高了接收系统的灵活性,具有理论研究意义与实际应用价值。本论文的主要工作由数字信号的调制方式识别与解调两部分构成,通过仿真分析系统模型的识别及解调性能,证明智能接收方案的可行性。首先,针对数字信号的调制方式识别,本文借鉴了Inception网络与残差网络模型的结构优点以及LSTM网络时序建模的特点,从局部特征提取与时序建模相辅相成的角度设计实现了SigNet网络模型。通过引入高阶累积量来扩充信号数据维度,以提高识别准确率。仿真结果表明,针对六种数字信号,SigNet模型的识别准确率随信噪比增加而提高,在AWGN信道下Eb/N0=12dB时达到96%的识别准确率。与目前广泛应用于调制识别的卷积神经网络模型相比,本文提出的SigNet网络模型能够达到约3%的准确率提升。其次,本文设计实现了数字信号通用解调模型,针对不同的调制方式选择对应网络参数对接收信号进行解调。仿真结果表明,在理想AWGN信道下,解调模型的性能与最佳接收机性能相符;在瑞利衰落信道下,通过导频符号在训练数据中的引入,解调模型的性能达到相干解调的误码性能。最后,本文对混叠信号进行了解调尝试,并假定混叠信号由两种己知调制方式的数字信号叠加而成。结果表明,当混叠信号调制阶数较小时,其解调性能相对较好;随着信号调制阶数的增加,解调性能逐渐下降。"
927,基于移动电信数据的个人信用评估研究,"征信市场是社会主义市场经济体系不可分割的一部分,近年来,随着大数据技术的迅猛发展,我国的个人信用评估行业进入新的阶段。其中,基于移动电信数据进行个人信用的评估是目前研究的热点之一。为了更好的对维度众多的移动电信数据进行降维处理,本文研究了经典的特征选择算法ReliefF算法,并在其基础上基于kd-tree算法与互信息进行了优化,创造性地提出了IRfF(Improved ReliefF)算法。进一步地,本文对IRfF算法的性能进行了仿真检验。随后针对移动电信信用评估这一具体应用场景,参考FICO模型将实验数据集中的全部特征划分为6个维度。对实验数据集进行了数据清洗、数据离散化以及数据标准化处理并基于IRfF算法完成了特征选择。在此基础上,基于统计学方法分析各维度典型特征与用户信用的关系,基于K-means聚类方法进行探索性的数据挖掘。在完成对实验数据集的数据预处理以及特征降维处理后,本文进行了个人信用评估模型的搭建。在搭建过程中,借鉴了传统金融申请评分卡的相关思想,使用了逻辑回归、支持向量机、BP神经网络以及Xgboost算法从全维度特征以及各分维度特征分别建立机器学习模型,并比较各模型训练完成后的性能。通过比较准确率、召回率、AUC值以及KS值,发现Xgboost算法训练出的模型的综合性能优于其它模型。为了增强模型的解释性,本文基于全维度特征以及各分维度特征的Xgboost模型输出的预测结果,对用户进行综合性地信用评分。"
928,基于机器学习算法的BOTDA信号提取技术,"随着光通讯产业的快速发展,光纤传感器已经成为了结构健康检测领域的重要组成部分,其广泛应用于国民经济和国防的各个领域。随着分布式光纤传感器的发展,利用传统的Lorentz拟合法,对于“指数级”增长的分布式光纤传感信息,难以满足越来越多的系统对于传感信息提取实时性的要求。如何高效准确地获得分布式光纤传感信息是当下研究的热点。本文在分析总结了分布式光纤传感技术的基础上,以布里渊分布式光纤传感系统为例,深入探讨其信息提取过程中的关键技术,提出了利用Sobel边缘检测算子和BP神经网络来提取布里渊传感信息的方法,具体工作和创新点如下:(1)文中首先分析了频谱相减法在信息提取过程中存在的问题,然后在频谱相减法的基础上进行了优化和改进,提出了利用Sobel边缘检测算子来提取布里渊传感信息的算法;该方法将布里渊频谱视为图像,利用Sobel边缘检测算法对其有效信息进行提取,从而获得频移位置。实验结果表明,与传统的Lorentz拟合法相比,文中算法的时间复杂度约为其1/9,确定频移部分的准确率也提高了 27.9%。(2)文中对上述算法做了进一步改进,提出了基于BP神经网络来提取布里渊传感信息的算法,利用BP神经网络可以实现任何复杂非线性映射的特性,来确定是否发生频移,从而快速获取布里渊光纤传感器中的传感信息;其中BP神经网络中的训练函数、传递函数和隐含层节点数通过控制变量法来确定。实验结果表明,与传统的Lorentz拟合法相比,文中算法的时间复杂度约为其1/12,确定频移部分的准确率也提高了 79.4%。"
929,基于LDA2vec模型的多源数据下科研热点识别研究,"信息过载是当前互联网信息时代值得关注的一大问题,从海量信息中快速抽取、提炼出关键的信息就显得尤为重要。而科技文献作为科技创新知识的主要载体不仅增长迅速,且具有多源分布的特点,如图书、论文、专利与会议文献等作为主要的科技文献,其不同类型的特点使得它们提供了关于同一主题不同角度的描述。所以在科学研究中,从不同源的科技文献中识别挖掘科研热点对于开展下一步的科研工作具有指导意义。所以本文目的就是通过本研究提出的模型方法,对蕴含在多源文本中的主题进行更有效的识别以分析学科热点,为科研创新提供支撑服务。本研究首先采用文献调研法,辨析了科研热点和科研主题概念的基础上,对国内外科研热点识别的主要方法和主题模型的研究进展进行调研,针对具有代表性的研究成果进行总结与述评,梳理了当前进行科研热点识别分析时的专家法、引文分析法、知识单元分析法、图谱分析法和文本挖掘法五种方法,并对主题模型的理论探索现状和其在科研热点识别中的应用研究现状进行了总结。然后在此基础上基于模型研究法,提出一种基于LDA2vec模型的多源文本下科研热点识别的方法并针对科研热点识别构建模型,该方法融合了LDA主题模型对隐含语义挖掘的优势和Word2Vec词向量模型对于上下文关系把握的优势。同时为了验证本文方法的有效性,利用实验分析法、统计分析法等,以机器学习领域的科技文献为例,获取期刊论文和专利文献的题名及摘要数据进行融合以作为实验数据源,一方面利用模型困惑度(perplexity)和主题一致性(topic coherence)两个指标对LDA2vec与LDA在多源文本背景下的主题提取效果进行对比,另一方面对本研究的方法在多数据源和单一数据源的环境下主题提取效果进行观察对比。经过实验,结果表明本文提出的方法在面对多源数据情况下,进行科研热点识别挖掘是可行的且在一定程度上有效果的提升。该方法相对来说能够更加合理、准确地识别出多数据源文本中的热点内容,对利用单一数据源进行主题分析的不足进行补充,对多数据源融合的实践应用进行丰富。"
930,基于数据挖掘技术的交通流量分析与预测,"在机动车数量不断突破新高的大背景下,交通拥堵已成为制约社会发展的重大问题。如果能准确预测路网中各路口的交通流量,相关部门则可以制定更有针对性的疏导措施,从而全方位提升路网利用率,缓解交通拥堵问题。近些年,数据挖掘技术取得了重大进展,该技术与交通流量预测场景的结合令人憧憬。本文基于数据挖掘技术,对交通流量进行分析和预测。第一,以聚类技术为切入点,提出交通流量模式挖掘方法。综合考虑轮廓系数、Calinski-Harabaz 指数和 Davies-Bouldin 指数,利用 K-Means 和Agglomerative Clustering算法确定交通流量模式个数,将交通流量模式分为单峰和双峰两种类型,验证得出节假日与工作日分别对应不同的流量模式,并根据模式对数据集划分,再进行预测。第二,对应不同的原始数据,分别提出基于深度学习的流量预测模型。其一,在仅提供单监测站信息时,传统循环神经网络无法处理交通信息拼接后的无时序性。为了解决这一问题,本文提出Combined-Update Gate Recurrent Neural Network(CUGRNN)模型,利用多个循环神经网络提取交通信息的时序特征。其二,当额外提供上下游监测站信息时,随着输入序列数量增加,CUGRNN复杂度急剧上升,且无法学习监测站间的位置关系。为了解决这一问题,本文提出了 Convolutional-UGRNN(Conv-UGRNN)模型,利用卷积神经网络捕获监测站之间的空间关系并使模型简化。第三,为了解决交通数据集样本数量受限的问题,本文提出基于卷积自编码器(Convolutional Auto-Encoder,CAE)的交通信息数据增强方法。该方法考虑到不同交通信息之间的内在联系,整体重构数据,使CUGRNN和Conv-UGRNN学习到更多的变化规律,提高模型的准确性。实验结果表明,交通流量模式划分提高了训练集的纯度并降低了预测模型的拟合难度;与现有文献中的交通流量预测算法相比,本文提出的CUGRNN和Conv-UGRNN网络结构更加合理,准确性更高;基于CAE的交通数据增强方法行之有效,进一步提升模型的准确率。"
931,基于多摇臂赌博机理论的小基站资源分配问题,"高密度无线网络以及小基站的部署近年来被视为解决指数型增长的数据业务量需求的重要方法。在保证网络性能与控制开销的标准下,结合机器学习手段的自组织网络技术得到了广泛的重视与研究。其中结合强化学习的自组织网络技术由于其有限的人工参与以及自主与环境交互学习的特点,具有极大的研究意义。本论文详细研究了利用强化学习中的多摇臂赌博机(Multi-armed Bandit,MAB)模型解决高密度小基站网络的资源自动分配问题。首先我们考虑企业内部小基站在未知环境下的功率准确自分配问题,此问题的主要特点为在系统环境未知的情况下如何权衡充分的室内用户覆盖与限制对室外用户的干扰。我们基于随机性连续MAB模型来解决此问题,在避免由粗采样带来的固有性能损失的同时,也排除了由过度采样带来的过大初始化工作量。为了最大化网络整体的频谱利用率,我们利用了性能指示函数的单峰性(Unimodality)提出算法来有效地加速全局最优功率的搜索过程。模拟实际场景的仿真分别验证了算法在单个小基站与多个小基站情况下的性能,通过与现有算法的对比可以看出我们所提的算法有明显的性能提升。其次本论文研究了利用通信模型中的固有结构性信息,在随机性组相关性MAB模型的基础上联合解决小基站选址与功率选择的问题。我们利用通信场景中的链路损失模型将小基站的频谱性能表示为由小基站位置与发射功率值决定的具体函数形式,在同一位置处的小基站功率值性能受相同参数影响,由此可以将此问题构造为随机性组相关性MAB模型,通过对位置参数的估计,可以同时估计出不同配置下的性能。对这种模型我们同样提出了适用的算法并对其通过严格的理论分析证明了其量级最优性。通过对实际静态与动态情况下的场景仿真,可以验证我们提出的算法相比之前的工作性能得到了明显提高。"
932,基于主动学习的文本分类系统设计与实现,"随着信息时代的到来,互联网得到了迅速发展,文本数据开始爆发式增长,丰富的信息背后蕴含着巨大的价值。文本分类技术可以有效的整理和组织文本,提高信息检索的效率,挖掘出文本更具价值的深层信息,而且随着数据收集和存储技术的发展,收集海量文本数据已经不再是难题。然而,目前文本分类技术的实际应用仍然局限于大公司或是研究机构,这是因为传统基于监督学习的文本分类需要大量已标注样本,而对大量文本数据进行标注的人工成本过高,使用随机选取部分数据获取标记的方法不仅是对数据资源的浪费,也会影响最终的分类准确率,因此构建一种能够有效利用未标注数据集的文本分类系统具有重要的实际应用价值。为了解决上述问题,本文以主动学习为切入点,设计并实现了一种基于主动学习的文本分类系统,本文完成的主要工作包括:(1)本文基于主动学习算法,采用RCNN模型作为分类器,提出了一种基于主动学习的文本分类框架。同时结合数据挖掘技术和深度文档向量模型,改进了初始样本选择算法,能从未标注数据集中选取出更能代表样本空间的样本,通过对比试验证明改进后的初始样本选择算法能明显提升了分类器对未标注样本的判别能力,提高了主动学习算法的效率。最终实验结果表明,相对当前研究中的其他主动学习算法,本文提出的框架能够以更低的标注成本获取更高的文本分类准确率。(2)在提出的基于主动学习的文本分类框架的基础上,设计并实现了可扩展、高性能、交互设计良好的基于主动学习的文本分类系统。系统功能的测试结果表明该系统能够有效降低用户完成分类预测任务所需的人工标注成本,可以有效解决系统目标用户难以利用未标注文本数据集的难题。"
933,面向屏幕―摄像头通信的动态二维码系统设计与实现,"随着电子产品硬件的发展和智能设备的普及,每个智能设备基本上都配备了具有高分辨率的后置摄像头和屏幕,这为基于屏幕-摄像头的可见光通信(visible light communication)的研究提供了硬件支持。屏幕-摄像头通信过程主要分为发送方和接收方两个部分。发送端把要传输的文件转化成一个由二维码帧构成的视频,以一定的帧速率在屏幕上播放,接收端利用手机摄像头捕捉屏幕上的视频,并解码每一帧,合成原始文件。目前的屏幕-摄像头通信系统主要可以分成两类,一种是对人眼可见的动态彩色二维码系统,其主要研究的内容是提高系统的吞吐量和传输过程的可靠性,现有的设计主要适用于4种颜色及以下的场景,对于更多种颜色比如8种颜色场景下,现有系统没有给出一种比较好的解决方法。另一种是利用的是人眼和摄像头成像原理的区别,即人眼在观看超过一定频率的内容时会有视觉暂留从而得到混合后的图像,而主流智能设备上的摄像头则是会产生果冻效应,从而达到嵌入的图案到对人眼不可见而对摄像头可见的效果。目前的研究要么需要对源视频或者图片本身做处理,要么需要额外的光源,这就造成在源视频切换或者应用场景切换时系统调整代价比较大。在对人眼可见的动态彩色二维码方面,我们设计并实现了一个名为MMCode的系统,着重于解决多种颜色场景下的颜色识别问题。该系统在发送端利用设计好的参考色条作为已打好标签的数据,并在接收端利用基于高斯混合模型的半监督学习算法对这些已打好标签的数据和二维码内容区域未打好标签的数据进行聚类分析,从而实现颜色识别的功能,实验结果证明这种方法是极大的提高了系统的吞吐量。在对人眼不可见的二维码方面,我们利用WinAPI的接口 DirectX在实现了名为I-Code的系统,把嵌入的预设图案添加到到显示器的即时输出中,再加上前后帧颜色互补的设计来实现对人眼不可见的效果,由于这种方法不需要额外的设备或者是对需要展示的源文件的修改,所以更具有通用性和使用的方便性。"
934,事件情节关系识别与推理方法研究,"故事是由一系列事件组成的,故事中事件的整体设计或布局组成了叙事情节结构(plot structure)。利用叙事情节结构组织事件是一个非常自然的想法,这是因为人们就是通过这种方式讲述故事的。本文关注叙事情节结构中事件之间的连接关系,即事件情节关系。事件情节关系是事件之间的解释性关系,它能够表示在叙事中事件之间有意义的连接关系。事件情节关系的识别对于多种自然语言理解任务具有重要的意义,例如文章自动摘要、问答系统和事件共指消解等。事件情节关系识别是一个较新的课题,在已有的工作中关于自动化事件情节关系识别方法的研究较少。本文研究主要关注事件情节关系识别与推理的自动化方法,研究内容如下:(1)基于局部预测的事件情节关系识别方法本文提出了基于局部预测的事件情节关系识别方法。该方法以事件对为基础,对多种特征进行抽取用于训练机器学习概率预测模型,从而预测事件情节关系的分类概率分布。实验结果表明,与基线方法相比,该方法的分类概率分布预测效果较好。(2)基于全局优化的事件情节关系识别方法在基于局部预测的事件情节关系识别方法的基础上,本文提出了基于全局优化的事件情节关系识别方法。该方法基于整数线性规划模型,根据事件情节关系的特点设计了若干种基本约束和反传递性约束,从而获得了全局一致的优化结果。实验结果表明,该模型有一定的性能提升。(3)事件情节关系与事件要素联合推理最后,本文提出了事件要素与事件情节关系联合推理方法。基于事件要素和事件情节关系之间的联系,该方法设计了事件参与者、地点要素数量限制约束和联合推理约束。以基于全局优化的事件情节关系识别方法为框架,该方法通过重新设计优化目标和增加设置多种约束条件对多任务进行联合优化。实验结果表明,该方法的性能有明显提升。除此之外,在基于局部预测方法中的模型训练完成后不需要对数据进行额外标注,因此该方法具有实用性价值。"
935,基于黑盒抽象的复杂代码符号执行研究,"随着现代信息社会的高速发展,软件已经进入人们生活的方方面面,为保障软件质量而对软件进行充分测试的重要性也随之愈发凸显。符号执行是近年来在软件测试领域被广泛使用的技术之一。该技术使用符号化变量而不是具体值变量作为代码的执行输入,在程序路径的分析过程中不断收集分支语句产生的路径约束,然后调用底层求解器对路径约束集合进行求解从而生成触发对应代码路径的测试用例。然而在处理现实世界中复杂的真实程序时,符号执行仍面临不少挑战。一方面,传统约束求解器的求解能力严重制约着符号执行处理复杂路径约束的能力。另一方面,当程序中包含复杂路径结构,如函数调用、循环语句等,符号执行会陷入大量路径的搜索与求解中。这些都极大地影响了符号执行技术在复杂程序上的应用。针对以上问题,本文在前期工作基于机器学习的符号执行框架的基础上,提出了一种基于黑盒抽象的新型符号执行方法。该方法不仅可以处理简单路径约束,也可将函数调用、循环语句等复杂代码片段编码为黑盒路径约束,然后通过底层机器学习指导的约束求解器进行采样、验证求解,提高符号执行对复杂代码的测试生成能力。本文的主要工作如下:●面向函数调用的黑盒抽象符号执行:为提高符号执行对包含函数调用的复杂代码的支持能力,本文提出了一种基于机器学习的函数黑盒抽象执行方法。该方法将符号执行过程中指定函数调用的路径编码为黑盒函数约束。在求解包含黑盒函数的路径约束时,符号执行框架对函数进行黑盒执行,获得的返回值被反馈给底层基于机器学习的约束求解模块进行验证学习求解。借助于函数黑盒抽象执行方法,符号执行框架跳过了对指定函数调用的展开分析,将资源投入在对主程序的路径分析中,更好地支持了包含大量函数调用的真实程序的测试覆盖。●面向循环语句的黑盒抽象符号执行:为降低符号执行在处理循环等复杂路径结构的开销,本文提出了一种对循环等复杂代码片段的预处理方法并在该方法基础上对函数黑盒符号执行功能进行了拓展。通过对循环语句等复杂代码结构的静态分析,复杂代码片段被编码替换为等价功能的黑盒函数调用。在后期符号执行过程中,这些替换的黑盒函数被指定进行黑盒执行,减轻了符号执行框架处理函数内部循环语句的负担。●基于黑盒抽象的复杂代码测试生成系统:为评估黑盒抽象符号执行的效果,本文实现了一个面向Java语言的复杂代码测试生成系统MLB-BS,并将其与传统符号执行测试工具系统进行了一系列实验对比。实验数据表明,MLB-BS在测试覆盖度表现上优于其他工具,尤其是在包含复杂代码结构的大型程序系统的测试覆盖上达到了良好的效果。"
936,基于混合粒子群算法的三轴气浮台平台优化设计,"三轴气浮台是航空航天领域用于模拟卫星在外太空以不同姿态工作所研制的重要工具。其主要利用自身所产生的高压气体,使台体悬浮于半空,近似模拟卫星在外太空所处无摩擦力作用时的工作情况,对卫星的各项性能指标、实时状态等进行全物理仿真。因此如何尽可能地减小地面环境的干扰力矩成为了三轴气浮台设计的关键技术,在所有干扰力矩中因重力产生的不平衡力矩是影响气浮台正常使用的主要原因之一,所以如何在设计中尽可能地减小不平衡力矩对实验造成的影响成为了引起我们高度重视的问题。国内外研究机构对气浮台不平衡力矩进行了一系列的优化研究,建立全仿真模型对气浮台运动进行模拟。近几年学术界通过算法对三轴气浮台的仿真进行一系列优化研究,但在计算不平衡力矩时往往存在陷入局部极小解或运算速度较慢等缺陷,本文首先通过三维建模方式对桁架式气浮台进行模型建立,其次利用有限元方法对圆柱型以及桁架型三轴气浮台模型进行分析,并结合分析软件中相关静力学以及运动学分析方式,最终得出三轴气浮台在各姿态下的不平衡力矩公式,进而限定研究变量的取值范围,即对桁架式气浮台的臂长以及管厚度等相关变量进行相关离散式取值;通过学术界及工业届中最常用的搜索算法中的粒子群优化算法结合退火形式即随着计算时间的推移逐步通过修正步长搜索因子前面的系数等形式,达到控制粒子群算法的搜索速度进而改变算法对三轴气浮台的不平衡力矩的公式进行优化的性能的目的;并且与传统粒子群算法及遗传算法进行比较,使得通过优化之后的计算搜索速度更快并且误差更小,提高三轴气浮台体计算及控制过程的精度及传感器的灵敏度。最终通过观察寻优结果,找出在连续型变量输入范围内最优的取值,对今后的生产制造以及三轴气浮台模拟卫星在外太空仿真实验的性能指标进一步性能优化设计有一定的指导作用。"
937,基于机器学习的Android第三方SDK漏洞检测技术研究,"随着Android应用程序市场的迅速发展,Android第三方SDK的使用也更加广泛,大量应用使用第三方SDK来提高开发效率。第三方SDK已实现各种各样的功能,并通过简单的接口提供给应用。这为应用开发提供了很大的便利,同时也对第三方SDK的安全性提出了很高的要求。但实际中,第三方SDK通常代表其开发者的利益,且没有统一的开发规范和安全管理,因此它们往往会潜在各种各样的安全问题,这将会影响大量Android应用的安全。由此可见,对Android第三方SDK漏洞检测技术的研究具有重要意义。本课题设计并实现一种基于机器学习的Android第三方SDK漏洞检测系统,目的是检测Android第三方SDK中两种常见的漏洞。本文具体研究内容和成果如下:1、对Android第三方SDK安全性进行深入研究,总结出了两种频繁出现的漏洞。然后通过研究这两种漏洞的生成原理、代码特征、攻击方式,总结出了漏洞形成的必要条件,并选取了与漏洞高度相关的特征集。2、通过对Android第三方SDK的全面分析,归纳出SDK中与安全性有关的特征,并对这些特征进行了归类整理。然后设计了合理的特征存储策略对特征数据进行规范化存储,最终建立了适用于漏洞检测的SDK基础特征库。3、训练了基于机器学习与深度学习的SDK漏洞检测模型。首先根据对特征处理技术的研究,制定了特征量化、特征选择和特征转化方式,形成了适用于机器学习模型输入的标准特征数据。然后搭建了多种分类模型,并在训练过程中完成了模型的调优和组合,最终针对每类漏洞形成了最优检测模型,并实现了漏洞检测系统。"
938,基于机器学习的航空收益管理需求预测算法的研究与实现,"航空业在国家综合交通体系中具有不可替代的作用和地位,航空业的发展是一个国家经济发展的重要体现。近年来,我国民航业蓬勃发展,航空公司之间竞争日趋激烈,开发智能高效的收益管理系统成为航空公司在市场竞争中取胜的关键。作为收益管理系统中的核心部分,需求预测是系统进行后续的舱位优化配置、存量控制以及动态定价的基础。准确的需求预测是航空公司进行正确决策和提高收益的关键所在。需求预测的影响因素众多:航空订座数据本身符合一定时间序列趋势,同时又受天气因素、突发事件因素、航空公司之间的竞争等因素的影响。现有需求预测模型大多只考虑单一维度的影响因素,无法将多维度信息融合起来建模分析。并且,现有对需求预测的研究大多集中在航班最终成行人数的预测上,忽略了对航班预售期内每日订座数的成长预测。而对预售期内每日的累积订座数的预测,是实际生产场景中航空公司做出相应调控手段的重要依据,具有重要的实际应用价值。针对上述问题,结合航空公司实际需求,本文对航班预售期内每日的订座数成长预测和航班最终成行人数(航班起飞时的总订座数)预测这两种场景分别进行深入研究,提出了相应算法,并在国内某航空公司的真实订座数据上验证了所提算法的有效性。针对航班预售期内每日订座数预测问题,本文提出一种基于长短时记忆网络的预测算法。利用长短时记忆网络在处理时序数据上的优越性能,融合多维度信息进行特征提取,采用横向时序(预订日期时序)和纵向时序(航班起飞日期时序)分别建立模型,同时捕捉到了航空订座数据的时序特征和相关因素的影响,实现了对航班预售期内每日订座数的有效预测。该模型弥补了对航班日订座数预测这一领域研究的不足,对指导航空公司进行后续的舱位调控及动态定价具有重要作用。针对航班最终成行人数预测问题,本文提出一种基于改进的增量模型的预测算法。在传统增量模型的基础上,引入了舱位加权计算方法,克服了不同日期航班总舱位数不同对预测结果的干扰。并且充分利用了环期、同期订座数据与待预测订座数之间的关系,挖掘了历史数据内在的时间联系性,最终建立基于环期和同期预测数据的回归模型。实验结果表明该模型在不同预测水平上的准确率均高于传统预测模型。最后,基于上述两种预测算法,本文搭建了一个航空订座实时预测系统,实现了从航空公司的数据库获取历史数据,经机器学习模型预测分析之后,将预测结果返回给航空公司,并进行实时显示的功能,具有指导收益管理人员进行票价制定以及为后续收益管理任务提供科学的理论依据的重要意义。"
939,基于深度学习的隧道衬砌病害GPR探测智能反演与识别方法,"随着我国水利、交通、市政等领域投入运行的隧道数量越来越多,隧道衬砌结构健康服役与长寿命运行的重要性日渐突出。隧道运营期内,经常出现裂缝、空洞、脱空、渗水等诸多结构病害,严重威胁隧道健康服役与长寿命运营。研究隧道衬砌内部结构病害的检测与识别方法,保障隧道运营安全,实现隧道衬砌病害的预知养护具有科学意义和工程价值。探地雷达是利用高频电磁脉冲的反射波来探测地下目标体分布形态及特征的一种无损检测技术,具有快速高效、结果直观等优势。然而,由于隧道衬砌结构的复杂性、病害的多样性以及隧道环境下的雷达信号的干扰等原因,衬砌病害的探地雷达数据识别存在精度差、依赖经验、自动化程度低等问题。针对以上问题,本文以实现隧道衬砌介电模型反演与病害类型、位置、轮廓自动识别为主要目标,依托深度神经网络超强的非线性映射能力,通过结合理论分析、数值模拟、模型试验等多种手段,研究基于深度学习的雷达智能反演与隧道衬砌病害识别,提出了基于深度神经网络的雷达数据智能反演方法,实现了隧道衬砌结构病害介电模型的反演;同时基于卷积神经网络实现了隧道结构异常识别与病害自动分类,并加以智能反演结果进行佐证;在智能反演结果基础上,采用SegNet深度学习模型实现了病害形态位置轮廓的细节刻画。最终形成适用于隧道衬砌病害检测数据的智能反演方法和自动识别分类方法,并通过模型试验进行验证,取得了较好的结果。本文的主要研究工作以及成果如下:(1)针对雷达检测数据到相对介电常数模型的反演难题,本文提出基于深度学习网络的雷达检测数据智能反演方法,通过深度神经网络来逼近雷达检测数据与相对介电常数模型之间非线性关系,实现检测数据到介电常数模型的映射,通过设计网络架构及参数来优化深度学习模型,提升智能反演的各项指标,进而确定深度神经网络模型。(2)针对隧道衬砌结构病害介电模型反演问题,基于实现雷达数据智能反演的神经网络,设计符合地质意义的隧道衬砌病害模型,并通过时域有限差分正演(FDTD)研究了典型衬砌结构病害的雷达响应特征,并生成对应的大量雷达检测数据,进而通过训练深度神经网络,实现隧道衬砌病害探测数据的智能反演,且智能反演结果优于传统全波形反演。(3)针对隧道衬砌内部病害类型及分布轮廓的自动识别难题,研究了基于雷达观测数据的隧道病害自动识别方法,通过构建卷积神经网络,实现了隧道衬砌内部异常识别与多种病害的数据整体分类,并加以智能反演结果进行佐证。针对隧道衬砌病害类型及轮廓识别难题,研究了基于SegNet的语义分割深度网络模型,对智能反演的预测模型进行像素级分类,实现病害形态位置的细节刻画。(4)在以上的研究基础上,设计基于深度神经网络的智能反演程序,开展了基于数值模拟的智能反演研究,并构建卷积神经网络实现雷达数据的自动识别。进而通过设计模型试验,验证了本文方法的有效性和可靠性。"
940,基于机器学习的TBM性能预测方法,"当下阶段的TBM(硬岩掘进机)工法,对于地质条件的适应性较差,掘进过程中易出现掘进速度慢、利用率低等情况。虽然现有的TBM大多配备数据采集系统,可实时采集TBM机械、电液参数,但是,对影响TBM掘进的因素及对应相关性缺乏研究,导致操作参数与岩体条件无法良好匹配,无法完全发挥TBM高效的施工优势,从而导致工期延误、成本剧增等问题。因此,如何了解TBM性能参数对地层条件及控制参数的响应规律,实现对TBM性能参数的准确预测,是减少延误、控制成本、提高TBM施工效率、保障隧道施工工期的重要方法。为了解决上述问题,本文以基于循环神经网络(RNN)的TBM掘进速度时序预测方法与基于神经网络-遗传算法(BPNN-GA)的TBM利用率预测方法研究为核心。采用理论分析、算法改进、工程验证等方法,建立了掘进速度以及利用率的预测模型,开发了基于浏览器/服务器模式(B/S)架构的TBM掘进性能在线预测平台。在此基础上,在吉林引松供水工程四标段开展了工程应用,验证模型的准确性和合理性。本文的主要研究工作及成果如下:(1)提出了基于LSTM循环神经网络和光滑约束的RNN净掘进速度时序预测模型。通过研究RNN神经网络在TBM净掘进速度预测问题上的可行性,结合实际TBM掘进情况,在保留LSTM神经网络中“单元状态Ct”保证长序列数据梯度传播稳定性能力的基础上,增加一条名为“岩体状态Rt”参数传播通道,包含一项表征岩体参数的向量,作为另一个“状态参数”以控制网络单元的输出结果;同时,将完整岩体连续开挖阶段岩性及净掘进速度不会产生阶跃性变化作为预测的先验信息加入RNN的TBM净掘进速度预测模型中,作为光滑约束条件,解决了机器参数与岩体参数之间存在的数量矛盾,并提高了模型的预测精度;最后采用TBM掘进循环数据进行了训练和测试,得到了较好的效果,基本满足实际工程需要。(2)本文提出了遗传算法(GA)与BP(Back Propagation))神经网络相结合的算法思想,建立了基于BPNN-GA的TBM掘进利用率预测模型。通过研究影响TBM利用率的岩体参数分析,选择围岩等级,单轴抗压强度UCS以及节理间距DPW作为TBM利用率预测的输入参数,建立基于BPNN-GA的TBM掘进利用率预测模型,通过经验公式确定隐含层的神经元节点数以及超参数,并将BPNN-GA模型的预测结果与传统BPNN模型预测结果进行对比,结果表明,与传统BPNN模型相比,BPNN在遗传算法的优化下得到了提升,在测试集上的预测准确率提升约8.95%左右,均方误差下降约60%左右。BPNN-GA模型在预测时不依赖特定的数据集,展现出良好的可移植性和泛化性。(3)基于TBM掘进地质岩体信息感知与智能决策系统开发了 TBM掘进性能在线预测平台,将掘进速度预测模型以及利用率预测模型嵌入平台中,该平台由模型新建与编辑模块、模型测试与保存模块、模型预测与分析模块三个模块组成,主要具有模型的超参数设置、新模型的训练与测试、已有模型的编辑、预测结果的分析等功能,用户可通过网页的形式访问预测平台并进行相关操作。(4)在吉林引松供水工程4标段进行工程验证,将已建立完成的RNN神经网络模型以及BPNN-GA模型进行性能预测,结果表明掘进速度预测模型以及利用率预测模型都具有良好的准确性以及泛化性,具有较高的工程使用价值。"
941,智能交通系统中位置信息的协作获取与深度挖掘,"随着我国经济的不断发展,城市汽车数量不断增加,同时城市环境也越来越复杂,智能交通系统的发展到达了风口。位置信息是智能交通系统的核心,在复杂的城市环境中,卫星导航面临着信号遮蔽、多径效应等多种问题,定位精度严重下降。协作定位是提升城市环境下定位精度的有效方法之一,但是它同样面临着非视距(none-line-of-sight,NLOS)路径观测带来的问题。目前,城市交通还面临着交通拥堵、环境污染等问题,这些问题都是未来智能交通系统有待解决的。位置信息的准确度日益提升,应该辅助智能交通系统,以更加智能的方式去解决这些城市交通问题。本文设计了一套新颖的智能交通系统处理框架,此框架包含车辆位置的协作获取以及深度挖掘两部分。首先,本文提出了基于地理位置信息增强的车联网协作定位(Geographic Information Enhanced Cooperative Localization,GIE-CL)算法,该算法创新性地设计了基于地理位置信息的区域采样法(Region Sampling Method,RSM)计算两相邻车之间链路属于视距路径(line-of-sight,LOS)的概率,从而将非视距路径的观测剔除,接着利用迭代式的近似消息传递(Generalized Approximate Message Passing,GAMP)算法提升协作定位精度。通过实验证明,在NLOS路径问题较严重的城市环境下,GIE-CL定位效果是优于其他算法的。GIE-CL利用地图信息的不变性和稳定性弥补了车联网拓扑结构的高速变化。基于协作定位,加上其他智能设备的普及,智能交通系统能够周期性地获取系统内所有运动物体地地理位置信息,进而将每个运动对象地位置信息按时间拼接获取到其运动轨迹。在深度挖掘部分,本文提出了一种基于循环神经网络(Recurrent Neural Network,RNN)的交通工具识别算法,能够对运动轨迹进行预处理,提出特征向量,并利用人工智能方式准确的识别交通工具类型。通过识别交通系统中的交通工具类型,我们能够形成实时的城市交通热力图,交警以及交通信号灯也就能实时做出调整,引导车流的移动,从而解决交通拥堵问题。从更加宏观的角度看,出行工具的比例以及区域分布,也能反应城市经济的发展,辅助城市未来的规划和建设。在未来的研究工作中,可以尝试将NLOS路径观测应用到GIE-CL当中,而不是单纯地剔除。如何从运动轨迹中推测出运动对象的运动模式以及生活习惯,并对位置做出预测,也是值得未来研究的课题之一。"
942,基于张量神经网络和集成预测模型的医学影像处理方法研究,"随着近几十年的医学成像技术的发展,磁共振影像已经广泛应用到医院的各种临床场景中,磁共振影像可以无创伤性地显示器官状态,给患者病情的早期检测和治疗计划提供必要的信息支持。脑部磁共振影像能够提供大脑活动状态视图,因此脑部磁共振影像逐渐成为脑科学研究领域的重要研究工具。磁共振影像具有分辨率高、图像体素数多等图像特点,这极大地限制了以传统特征选择和分类为主的机器学习方法在脑部磁共振影像分析中的应用。随着脑部肿瘤疾病发病率的逐渐升高,脑部肿瘤疾病患者的生存周期预测的临床需求也日趋凸显。基于磁共振影像的生存分析研究不仅可以为患者诊疗方案的及时调整提供必要的信息支撑,也能为患者提供有参考价值的治疗心理预期。针对磁共振影像处理中面临的问题和相关临床需求,本文主要研究张量神经网络和集成预测模型在医学影像处理方面的应用,主要的创新和贡献主要在以下两个方面:(1)论文提出了基于张量神经网络的fMRI分类框架。该算法框架利用张量神经网络搭建浅且宽的磁共振影像分类框架,其不仅能够从全脑功能性磁共振影像中提取有效特征以提高大脑状态分析性能,而且能够大幅度压缩神经网络中的整体参数以解决磁共振影像分析中的“维度灾难”问题,从而削弱了应用在磁共振分析中的深度学习系统对设备要求过高的限制。相关分类框架在CMU数据集上进行了测试,实验结果证实,本文所提出的基于张量神经网络的分类框架优于传统方法。(2)论文提出了基于集成预测模型的脑胶质瘤患者生存周期预测框架。该算法框架首先对结构性磁共振影像进行多模态、多角度的特征提取,随后通过Kaplan-Merier生存曲线进行单变量的特征选择以筛选出有益特征,最后将筛选的有用特征通过集成模型完成生存周期的预测。该算法在Brats2018数据集上进行了测试,实验结果证实,本文所提出的基于集成预测模型的脑胶质瘤患者生存周期预测框架优于传统预测模型。"
943,基于集成深度学习的医学图像诊断算法研究,"21世纪,癌症依然是困扰着人们生活的一个严重问题。根据美国癌症组织的调查报告,每年全世界将近180万的新肺癌病例,以及160万的肺癌致死人数。CT图像是最常用的并且鲁棒的成像技术之一,用于肿瘤的检测、诊断和后续治疗。通过基于X射线的吸收来可视化人体组织。放射科医生可以根据肿瘤的密度和形态来评估其恶性程度,但是预测的可靠性高度依赖于医生的经验,并且不同的放射科医生可能做出不同的诊断。由于肿瘤之间复杂的关系,它的出现并不一定意味着癌症的发生。在一些复杂的情况下,即使是有经验的放射科医师也很难达成共识。因此,开发基于CT图像的自动诊断系统来辅助医生进行肺癌的判断有着很大的必要。基于计算机视觉的模型可以在同一水平快速检查肺部CT图像,而且它们不受物理条件和精神状态的影响。计算机辅助诊断(computer aided diagnosis,CAD)系统指的是利用成像技术、图像分析方法配合大量的生物医学技术,建立起稳定可靠的机器学习模型,然后通过计算机的分析计算,辅助专业医师判断病人情况,以此改善机器模型的诊断结果。人工神经网络是医学图像分类中最常用的机器学习模型之一,它通过模仿人的大脑神经元的工作机制,完成对信号的高度非线性处理。并且它具有自主改善、记忆、预测情况等多种优秀的性质,所以能够达到辅助医生诊断的效果。针对医学图像分类以及癌症诊断任务,基于人工神经网络的机器学习模型比传统的方法(例如概率统计)表现出了更加优秀和稳定的性能。近些年,基于深度学习的图像分类算法在各方面取得了引人注目的突破,这得益于开放的大规模注释数据集(例如ImageNet)以及蓬勃发展的深度卷积神经网络(deep convolutional neural network,deep CNN)。对于数据驱动的学习算法来说,具有数据分布特征的注释良好的大规模数据集对训练更精确或者泛化的更好的模型至关重要。然而,由于数据采集困难,质量标注昂贵,目前没有像ImageNet那样大规模的注释好的医学图像数据集。因此用于医学图像分类的机器学习模型更容易陷入过拟合问题,即网络能够在训练样本上拟合的非常好,但是它对于新的病例样本的诊断表现非常差。本论文围绕上述问题提出了相应的研究手段和解决办法,并通过大量的实验完成了对CAD系统中的关键算法的效果的验证。通过大规模集成合适的不同结构的deep CNN模型能够用于完成对CT图像的诊断,实践证明,集成后的网络模型通过投票机制能够表现出更加优秀的诊断能力。最后在两个公共医学图像数据库上面验证并对比了算法的性能,并对实验结果进行了充分的分析。"
944,数据中心光网络中的动态色散补偿及弹性资源管理机制,"当今社会已经步入信息化时代,每天都会有海量的信息产生,各种数据呈爆炸式增长,大数据时代已然来临。为满足由大数据、云服务、人工智能、物联网和5G服务所带来的新兴业务的需求,下一代数据中心光网络需要向高速率、高可扩展性、高可靠性、高能效、弹性、灵活以及低时延的方向发展。而将SDN应用到数据中心光网络的资源管理中,依靠SDN控制器来实现对全网资源的集中控制和综合调度是数据中心光网络满足新兴业务需求的一种优选的解决方案。本论文对数据中心光网络中的动态色散补偿及弹性资源管理机制作了详细的描述,设计了基于铌酸锂波导光栅的可调谐色散补偿器对色度色散进行补偿,提出将机器学习与已有的频谱算法相结合以此来提高频谱资源利用效率的方法。论文的主要工作与创新如下:(1)针对数据中心光网络中的损伤之一――色度色散,对其进行感知。对同一波长不同传输距离下的色度色散值和同一传输距离不同波长下的色度色散值分别进行感知。(2)针对色度色散的补偿,提出了一种基于铌酸锂波导光栅的可调谐色散补偿器,并搭建色散补偿系统,利用该色散补偿器对光网络中的色度色散进行补偿。BER、星座图等仿真结果表明,所设计的基于铌酸锂波导光栅的可调谐色散补偿器在色度色散的补偿上拥有良好的效果。(3)在弹性资源管理机制部分,利用SDN控制器来实现数据中心光网络资源的集中管控,在此基础上,本文将机器学习和常用的频谱分配策略相结合,提出了MLF。MLF首先利用k-means算法对业务请求进行分类,然后当某一业务到达时,就将此业务与之前的分类进行匹配归类,再根据不同的类别进行相应的频谱分配算法选择。该算法的策略是侧重于收敛时间和频谱阻塞率的综合考虑,即在保证阻塞率尽可能低的同时减小收敛时间,从而最大化频谱利用效率。该算法通过matlab仿真验证,能够有效地降低算法的收敛时间及阻塞率,提高带宽利用效率和系统对弹性业务的容纳率。"
945,面向微表情识别的跨源图像识别技术研究,"情绪是人们对周围事件或者事物的一种态度,而面部表情是人们表达内心情感和意图最直接、最自然的一种方式。面部表情主要是人们在受到刺激后所做出的应激反应,主要包括宏表情和微表情两个方面,其差异之处主要在于其持续时间和强度。相比于宏表情来说,微表情具有持续时间短,强度低,难以诱导等特性,是在经历情绪期间非自发的、即时的面部动态,通常可以揭示人想要隐藏的真实情感。基于微表情的检测和识别有许多重要应用,如犯罪检测、商业谈判等,在各领域有着极大的应用价值和广阔的发展前景。随着计算机和模式识别技术的不断发展,基于面部的表情识别已经引起人们的广泛关注,面部表情识别已经成为新兴学科的一个重要研究领域,而微表情识别是面部表情识别中一个重要的研究方向。由于机器学习在分类、聚类、回归等领域已经取得了成功,所以现阶段,微表情识别主要是利用机器学习实现,但是由于受到训练样本大小的限制,导致模型训练不够优化,识别率不高。在传统的机器学习中,需要训练和测试数据均来自相同的特征空间,而跨源学习可以将所有的任务结合,系统地进行学习,解决了数据分布不同的问题,在一定程度上可以解决因数据不足导致的模型训练不够优化的问题。由于宏表情和微表情在情感特性上具有一定的相关性,因此,为了解决微表情识别受训练样本大小限制导致的模型训练不够优化的问题,本文进行了面向微表情识别的跨源图像识别技术研究。具体而言,本文的主要贡献如下:・提出了基于更新标记向量的耦合源域目标化模型,利用样本丰富的宏表情,将宏表情和微表情投影到一个公共子空间,充分利用源域和目标域中的信息,实现宏表情到微表情的跨源学习。・提出了基于联合稀疏字典学习分解的微表情识别模型,将宏表情与微表情共同投影到标签空间进行字典学习,并对各自的字典进行二分解,找到宏表情和微表情的共同表情信息部分,构建了宏表情样本与微表情样本之间的情感联系,从而提升微表情的识别率。通过实验分析表明了所提出的基于联合稀疏字典学习分解的微表情识别模型有效提升了微表情识别率。・提出了多任务多视角学习的特定类强相关张量耦合度量学习模型,借助样本丰富的表情样本,学习特定类的映射将表情和微表情样本同时映射到公共空间。同时,加入了迹范数以增强特定类的样本之间的相关性。为了减少多特征所引入的冗余信息,利用F范数和L21范数对多特征进行特征选择。此外,以特征点为中心对微表情进行分块,进行多任务学习。"
946,应用于短文本情感分类的融合情感信息的神经网络模型,"随着互联网的高速发展,信息爆炸的时代已经到来,人们被各式各样的信息所包围。对此大家已经习以为常,而且开始寻找利用这些信息的有效方法,例如在进行网购时,除了商品本身的介绍,也会参考买家的评价;去电影院看电影时,会根据电影的影评进行取舍。这些信息的背后隐藏了它们巨大的价值,那就是文本所表达的情感对人的帮助,文本情感分析这一自然语言处理领域的任务应运而生。文本情感分析的目的就是自动挖掘文本所表述的情感,其方法有很多,从最初的基于规则和词典的分类到传统的机器学习方法,如贝叶斯分类、决策树、支持向量机(SVM),再到现在热门的深度学习方法如卷积神经网络(CNN)、循环神经网络(RNN)、长短期记忆(LSTM)、递归自动编码器等。深度学习的各种网络模型在情感分析任务上都取得了一定的成就,相比传统机器学习,提高了准确率,增强了泛化能力,但仍旧存在着许多的不足,还远远满足不了人们的需求。本文主要研究应用于短文本情感分类的融合情感信息的神经网络模型,具体任务如下:(1)情感资源如情感词典、否定词、程度副词、句型连词等都具有先验知识,在自然语言处理早期是情感分析的重要组成部分。但在深度学习中却很少见到神经网络中使用情感资源,这是对先验知识的浪费,因此本文尝试了一种先验情感信息与LSTM融合的方式,以提高情感分类的准确率。(2)递归自动编码器、树状长短期记忆(Tree-LSTM)将句法信息融入到神经网络中,大大提高了模型的准确率。但这些模型都需要人工成本很高的短语级标注,这就造成了其应用的限制。本文尝试将情感信息与Tree-LSTM融合,使情感信息与句法信息结合,从而达到替代短语级标注的效果,提高树状模型在句子级标注的数据集上的准确率。(3)融合情感信息的神经网络模型将在两个英文公开数据集上进行验证,并与各种神经网络进行对比,从而证明本文模型的先进性。虽然深度学习迅猛发展,但是在特殊人群上的应用还是不足,因此本文提出的融合模型将在监狱服刑人员的短信上进行实际应用。短信中蕴含了服刑人员的潜在情感,对短信的情感分析有助于提高狱警对服刑人员的了解,从而使狱警更有效地帮助服刑人员进行改造。"
947,基于自然语言处理的互联网舆情高危信息处理模块的研究,"进入互联网2.0的时代以来,进入到互联网信息井喷的时代,互联网媒体的迅速发展使其成为社会信息流通传递、参与社会公共事务的重要渠道,网络舆论监督、大数据分析与应用业已成为政府社会治理的重要途径。目前传统的舆情分析是建立在统计与规则之下的系统架构,通过长期的词表筛选和人工审核来建立更加完善的规则机制。但互联网信息量呈指数级发展,继续加大人力投入,基本成为不可能的事情。因此,探索与寻找一条智能化信息处理方式,能够快速处理当前呈爆炸式增长的数据,成为当前迫在眉睫的主要任务。本文着重对高危预警模块进行研究,建立具有高召回率的模块,分析如何将相关突发事件快速准确的推送给相关部门机构是需要重点突破的研究方向。本文通过重新设计重要度模块,重写重要度预警规则,通过深度学习与机器学习算法结合的方式来提高召回率与准确率。具体完成的工作有以下几点:(1)本文进行了语料的预处理以及粗标注,构建“信息介入”模型的语料。构建多模式字符串匹配算法AC自动机进行语料的筛选。(2)构建深度学习模型BiLSTM神经网络对“信息介入”模型进行文本分类算法的训练,将语料文本分为三大类(介入、非介入、不相关)。数据集采用2017年微博数据。(3)构建不同的机器学习模型,通过流式处理中已经处理的模块,得到相应的特征,例如,自动分类结果,关键词匹配个数,正负指数,地理特征,以及训练好的“信息介入”模型的结果,构建数据集,通过不同算法的训练,最终的得到预测结果。对比不同算法之间的优劣,从而选择最适合的模型进行线上数据的分析。论文第一部分构建“信息介入”模块,运用深度学习算法提取句子信息是否为介入信息,深度学习在此次模块设计中占据非常重要的地位,提取到的介入信息对逻辑回归算法的准确率提高了四个百分点。第二部分为高危舆情判定模块,采取的是机器学习算法而并非深度学习算法,主要是深度学习算法速度上达不到线上使用标准。最终模型采用的是深度神经网络提取部分特征,再将所有特征送入梯度提升树来进一步进行特征组合,最终由逻辑回归算法完成高危舆情的分类推送。本文利用40万条语料对上述模型进行实验并且对传统基于规则的数据处理方式进行对比。实验结果表明深度学习作为特征处理,梯度提升树与逻辑回归模型相结合的方式最适合本次业务的处理,与已有的方法相比,提高了高危信息模块的准确率。"
948,基于SOA的MotorX平台的设计与实现,"随着信息化席卷全球,各种新型的数字化产品和服务不断涌现,一个庞大的数字化共享平台正在逐步呈现。国防数字化信息包含各类新兴技术及各方面前沿军事信息。应实习单位实际需求,论文设计并实现了基于SOA(Service-Oriented Architecture,面向服务的架构)的MotorX平台,旨在运用数字化技术,实现国防数字化的转型升级,建立符合安全保密条例的现代化生产与信息共享模式,增强核心竞争力,全方位整合动力课程、主题文献、智能推优、学习论坛等先进模式,更好地推进科学技术的发展和人才培养计划的实施。论文主要工作如下:分析MotorX平台的开发背景、意义及相关平台的研究现状;对SOA架构的相关技术进行分析、研究;从多个角度对基于SOA架构的MotorX平台做出详细的需求分析;对比多种机器学习分类算法,选取准确率最高的算法加权KNN(K-Nearest Neighbor,K-近邻)算法用于智能推优功能的实现;平台开发采用开源的SSM(Spring+SpringMVC+MyBatis)开发框架,前端结合JavaScript、jQuery以及Ajax的异步请求机制,利用MySQL数据库实现数据的持久化;将SOA架构Dubbo应用于MotorX平台的开发,结合AD域验证机制,实现权限管理、动力课程、智能推优、双创课题、每日新报、主题文献、数据统计等功能;最后对本文工作做出总结,并拟定下一步的研究方向。"
949,基于机器学习组合算法的Webshell检测方法与实现,"Webshell是一种以网页文件形式存在的命令执行程序,也称为后门文件,是黑客入侵网站采用的重要手段。由于Webshell的危害极大,Webshell检测已成为网络安全领域的一个重点研究方向。目前在Webshell检测方面的研究及成果也很多,比如常用的“安全狗”、“D盾”及“河马”等检测工具,这类工具大都是基于特征码来查杀,检测的准确率及召回率都不很理想。而基于机器学习的检测方式,目前大部分都是基于单一的机器学习算法进行检测,其检测只能从特征构造、算法改进或参数优化等方面进行准确率及召回率的提升。本文通过分析当前Webshell检测方法的现状,提出了基于机器学习组合算法的Webshell检测方法,并使用Python编程语言进行实现和测试结果分析。不同的机器学习算法在准确率及召回率方面各有差异,但没有包含与被包含的关系。在一种机器学习算法检测的基础上,再增加另外一个机器学习算法检测,将会提高一定的召回率,但会造成准确率及检测效率的下降。由于应急响应等工作对召回率的要求比较高(对漏报零容忍),因此可以牺牲一定的准确率及效率,以此来提高召回率。本文期望通过利用不同机器学习算法的组合检测方法,通过大量的Webshell检测测试,找到一种较好的机器学习算法组合方式,以实现较高的召回率及一定的准确率。首先,本文利用Python编程语言和SQLite数据库,设计实现了基于机器学习的Webshell检测系统。系统包含机器学习训练子系统和机器学习检测子系统,并分别设计实现了子系统中的字符串读取模块、人工分类模块、文本特征提取模块、数据库模块、机器学习训练模块、文件扫描模块、自动分类器模块和文件定位溯源模块等。然后,重点分析了各个文本特征提取算法模型间的差异,并进行优化。由于文本特征提取方法是机器学习的关键技术,提取的特征是否为关键特征,会直接影响机器学习的判断准确率和效率。因此,我们优化了文本特征提取算法,以便提升机器学习的准确率及召回率。最后,通过实验测试分析,分别测试了 K近邻算法、朴素贝叶斯算法、决策树算法、随机森林算法、逻辑回归算法、支持向量算法SVM和深度学习MLP算法在单独检测和组合检测方面的准确率及召回率情况。通过结果对比分析,发现基于朴素贝叶斯和决策树双重算法组合的召回率达到了99.918%(每1000个文件漏报1个),准确率为88.6%,基本满足应急响应对召回率及准确率的要求。"
950,一种数据驱动的SECaaS的设计与实现,"随着网络安全事件爆发愈发频繁,IaaS用户在其基础资源得到满足的同时,也期望云服务商可以提供监控、检测和响应等安全服务,有利于运维人员进行更合适的安全管理配置,同时也为云服务商带来了新的商机。本文主要利用SD N技术解决传统网络中的安全问题,基于OpenVSwitch交换机实现数据包级别和流量级别的检测,并实现了攻击源定位和响应机制。本文的主要内容如下:(1)分析了云服务使用者所面临的安全威胁。对安全威胁进行分类,并分析了端口扫描攻击和Flooding攻击的特征,对相应的解决措施进行讨论,进而提出了本文中安全即服务需求。(2)提出一种数据驱动的适用于SDN的安全威胁检测和防御机制。基于决策树和其他数据驱动的机器学习方法实现了数据包级别和流量级别检测,并给出决策树转换和流规则部署算法以及其工作机制的具体流程,最后基于原始数据包数据训练机器学习模型。(3)提出了基于本文检测机制的攻击源端口定位方法和攻击响应策略,设计并实现了系统原型。由于决策树数据结构易于扩充,配合SDN转发控制分离的特性可以实现攻击源端口定位和动态的响应策略。同时本文设计了安全服务配置API供用户调用,最终基于OpenVSwitch交换机和Floodlight控制器实现本文所提出的安全即服务并对其进行功能和性能测试。"
951,交叉对比神经网络在心音分类预判中的研究,"心音是心脏跳动周期中各个组织(瓣膜、心肌、血液)运动产生的声音,富含大量器官(心房、心室、大血管、瓣膜)的状态信息,我们可以通过监测血液循环产生的心音,在心血管疾病发生的初期有效开展治疗工作。考虑到我国幅员辽阔、医疗资源相对短缺的基本国情,心音的自动化听诊研究对我国的初级卫生保健工作有着重大意义。本研究结合了深度学习和基于信息的相似度度量理论(IB S),提出了一种新的网络结构――交叉对比神经网络(CCNN)。网络分为两个主要部分,第一部分通过深度网络提取特征,第二部分利用统计学理论度量特征向量之间的相似性进行分类。本研究改进了原始IBS理论中相似性的度量方法,提出了ModIBS理论,使CCNN能够借助深度学习的强大特征挖掘能力,在统计和物理假设的基础上,对动力学结构生成的信号进行分类。CCNN主要有以下几个主要特点:1.使用交叉对比的输入模式,一方面扩充了医学小数据集,另一方面引入了除信号内容信息之外的对比信息。2.利用统计度量的方法将先验知识引入到神经网络的训练过程中,使网络在统计学原理的支撑下,更加适应医学小数据集的训练。3.结构灵活易调整,特征抽取、距离度量部分方法的选择都非常丰富。这种新的网络结构使得它兼具深度网络和统计学习方法的优点,特征提取流程简单,蕴含信息丰富,在一定程度上克服了深度学习在医学应用中的困难(训练数据少,类间差异不明显等)。与传统的手工设计特征方法相比,CCNN中深度学习的引入可以简化特征提取流程,使用机器代替人工的特征设计。与传统的深度学习方法相比,统计学解释的加入使得整个过程更加容易理解,两两对比的方式带入了更多的信息,使得网络更加关注不同类别间的差异性特征。另外,组合数扩充了数据量,使得CCNN适用于数据难以获取,量级较小的医学诊断场景,有较强的应用潜力。本研究在PhysioNet/Cinc 2016心音数据集上实验了CCNN的效果,其敏感度为0.8346,特异性为0.9623,mAcc为0.8985。"
952,无标记样本辅助的深度学习技术研究,"深度学习技术已广泛应用于诸多领域,训练深度模型通常需要大量的标记数据,然而在很多实际应用中获取标记信息需要耗费人力物力。因此,如何利用无标记数据提升深度学习的性能,是一个亟待解决的问题。本文针对此问题进行了研究,取得了如下创新成果:1.对无标记样本辅助提升深度学习技术的监督学习性能进行了研究,提出了一种将半监督学习Tri-training机制融入深度学习模型的方法TDNN(Tri-training Deep Neural Network)。实验结果表明,本文方法能够有效地提升深度学习的监督学习性能。2.对无标记样本辅助提升深度学习技术的迁移学习性能进行了研究,提出了一种联合优化源域/目标域的语义匹配及目标域损失函数的方法SDA-TCL(Source Domain Alignment and Target Classifier Learning)。实验结果表明,本文方法能够有效地提升深度学习的迁移学习性能。3.对无标记样本辅助提升深度学习技术的度量学习性能进行了研究,提出了一种联合优化噪声条件下输出度量的稳定性与监督信息损失函数的方法SDVN(Stable Deep Verification Network)。实验结果表明,本文方法能够有效地提升深度学习的度量学习性能。"
953,基于随机投影的高效自适应次梯度方法,"在线学习是一个计算高效且具备理论保障的通用学习框架,能够利用实时收集的数据快速地进行参数更新。随着大数据时代的来临,为了处理规模大、增长快的数据,在线学习受到越来越多的关注。自适应次梯度方法由于可以动态地利用已观测数据的几何结构去指导参数更新而成为常用的在线学习方法。根据使用的信息量大小,自适应次梯度方法可以被划分为对角矩阵版本和全矩阵版本。由于全矩阵版本处理高维数据时需要难以接受的开销,对角矩阵版本在实践中被广泛应用。然而,对角矩阵版本仅仅维护了梯度外积矩阵的对角线元素,无法捕捉梯度之间的相关性。当高维数据是稠密且具备低秩或近似低秩特性时,它的效果会比全矩阵版本差。本文主要研究如何在不影响性能的前提下降低自适应次梯度方法的复杂度,取得了以下进展:第一,针对全矩阵版本自适应次梯度方法复杂度过高的问题,提出基于梯度投影的高效自适应次梯度方法。该方法的核心思想是利用随机投影方法去生成一个可以近似梯度外积矩阵的低秩矩阵。在后续的计算过程中,我们通过维护和操作这个低秩矩阵去加速梯度外积矩阵的开方和求逆运算,从而得到一种更加高效的自适应次梯度方法。实验结果表明,该方法取得了与全矩阵版本自适应梯度方法相接近的效果,并显著地降低了运行时间。然而,该方法在参数更新过程中存在依赖性问题,我们难以利用现有的数学工具从理论上分析其遗憾上界。第二,针对基于梯度投影的高效自适应梯度方法不具备遗憾上界的问题,进一步提出基于数据投影的高效自适应次梯度方法。具体而言,对于机器学习领域常见的广义线性模型,我们首先提出将全矩阵版本自适应次梯度方法中的梯度外积矩阵替换为数据外积矩阵,这一简单的变化直接避免了基于梯度投影的方法中存在的依赖性问题。然后再利用随机投影方法去生成一个可以近似数据外积矩阵的低秩矩阵,并利用该低秩矩阵加速参数更新,得到与基于梯度投影的方法相同的存储和计算复杂度。更重要的是,我们通过理论分析建立了该方法的遗憾上界。理论结果表明,针对广义线性模型,当数据具备低秩或近似低秩特性时,该方法的性能与全矩阵版本的性能相接近。实验结果表明,该方法取得了与基于梯度投影的方法相似的效果,成功降低了全矩阵版本的复杂度。"
954,基于卫星通信系统的信道预测及自适应编码调制的研究,"随着通信技术的发展,人们对通信质量和通信容量的需求日渐提高。卫星通信具有通信距离远、受地形影响小、通信波束覆盖范围广的特点,可以作为地面通信的补充和延伸,可以有效缓解通信业务多样化所带来的压力。然而卫星通信传输过程中,信道环境复杂、传输时延大、传输资源有限等因素限制卫星通信系统的通信性能。在传输资源极其有限的情况下,提出一种高效且高质量的传输模式是卫星通信传输的研究热点之一。为了解决这个问题,信道估计、信道预测和自适应编码调制技术应时而生。本文在DVB-S2协议(Digital Video Broadcasting-Standard Ⅱ,第二代数字广播协议)和DVB-RCS2协议(Digital Video Broadcasting-Return Channel Standard Ⅱ,第二代数字广播返回信道协议)基础上,对信道估计、信道预测和自适应编码调制技术进行了研究。论文主要内容如下:(1)本文提出两种自适应编码调制感知算法:含补偿项的时间序列算法和基于深度卷积神经网络的信道感知模型。首先对时间序列预测算法提出了补偿算法,有效解决了时间序列预测的误差问题。提出了基于深度卷积神经网络(Deep Convolution Nural Network,DCNN)的信道感知模型,通过仿真验证算法的有效性。仿真结果表明,含补偿项的时间序列算法对信噪比预测的平均预测误差为1.326dB,较传统时间序列算法预测精度提升了 40.67%。在C.Loo模型中,基于深度卷积神经网络的信道感知模型不论在信噪比估计中还是信道预测中都有良好的性能,并且有效地解决由传输时延带来的信噪比估计过时的问题,提高了自适应编码调制技术信道感知部分的性能,经分析,DCNN的估计性能较传统的信道估计算法在C.Loo信道中提升了38.73%。(2)为了进一步优化频谱效率,本文提出一种基于双深度Q学习网络强化学习(Double Deep QNetwork,DDQN)算法的自适应编码调制控制算法。将基于深度卷积神经网络的信道感知模型作为自适应编码调制感知算法,双深度Q学习网络强化学习算法作为自适应编码调制控制算法,提出一种基于DCNN和DDQN的双深度自适应编码调制架构。经仿真,DDQN算法作为控制算法比传统区间法频谱效率提高了 18.9%。新的双深度自适应编码调制架构比传统的ML+区间法架构在频谱效率上平均提升了3 2.6%,误比特率平均降低了3 7.5%。(3)最后本文对DVB-S2协议和DVB-RCS2协议进行深入学习,特别是协议中物理层组帧、编码调制、接受同步和译码部分。并分别基于DVB-S2协议和DVB-RCS2协议搭建了卫星通信物理层仿真平台的前向链路和反向链路。对DVB-S2中的自适应编码调制技术进行了介绍,并通过平台进行仿真,验证了仿真平台的性能。"
955,个人健康管理服务系统的设计与实现,"近些年来,移动互联网技术和通信技术飞速发展,人们的生活发生了翻天覆地的变化,手机成为生活中必不可少的工具。快节奏的生活给了人们物质上的满足,但是,随之而来的健康问题也越来越突出,人们对于健康状况的提升越来越重视。如何将健康管理与移动设备相结合,使健康管理更便捷化和碎片化,已经成为当下互联网医疗领域的一大热门需求,为此开发了“个人健康管理服务系统”以满足这一需求论文基于“个人健康管理服务系统”,介绍了该系统的设计与实现过程。“个人健康管理服务系统”是一款为患有慢性病和亚健康人群设计的个人健康管理和服务系统,为用户提供了服药信息管理、饮食信息管理、体征信息管理、健康备忘录管理以及医生反馈简报等功能。用户在使用本系统的过程中,可以随时随地管理自己的健康信息,从多个方面为身体健康保驾护航。该系统的组成包括手机客户端、Web管理平台以及后台服务器。其中手机客户端以Android操作系统为依托,使用Java语言进行开发。Web管理平台使用PHP语言进行开发,系统管理员和医生用户通过网页浏览器登录使用。后台服务器也采用PHP语言进行开发,使用MySQL数据库进行数据的存取。此外,在医生反馈简报功能中,对径向基函数神经网络进行了合理的分析和改进,通过机器学习的方法,利用系统中收集的数据和专业医生的健康建议,建立了健康反馈的算法。论文开篇对系统的研究背景和开发意义进行了分析,对开发过程中运用到的理论知识进行了归纳总结。在此基础上,根据用户需求模型,设计出Android客户端、Web管理平台的主要功能模块,搭建出完整的系统框架结构,之后完成了系统的概要设计和详细设计,最后编程实现了此系统,并成功通过了所有的测试用例。"
956,基于PLSTM卷积神经网络和共享表示生成器的实体关系抽取的研究和实现,"实体关系抽取是自然语言处理的一个重要任务,由于传统的有监督分类方法往往需要大量的人工标注工作,效率低下,基于远程监督的关系抽取成为了新的研究热点。远程监督有一个强假设条件,如果两个实体存在某种关系,那么所有同时包含这两个实体的句子都在某种程度上表达了这种关系,因为这个假设实际中并不总是成立,导致自动标注的数据集中会引入较多的噪声。如何缓解远程监督中的噪声问题是当前亟待解决的研究难点。本文结合多示例学习,从句子向量表示和包向量表示两个方面来改进关系抽取的性能。在句子向量表示上,为了改进传统分段卷积神经网络忽略了段间语义关联性的问题,本文引入了BiLSTM序列化建模来学习更多关联特征,并提出了基于分段LSTM卷积神经网络PLSTM-CNN进行文本向量表示的方法。在包向量表示上,本文提出了新的共享表示生成器进行特征空间转换,将句子从原始语义空间映射到和目标关系语义相关的特征空间,从而过滤掉无关噪声的表达。和主流的注意力加权机制不同,本文提出的方法具有更强的非线性拟合能力,并且能提取更多的示例共同特征。此外本文还引入了额外的生成器损失来提高其性能。本文提出的改进方法都具有良好的可扩展性,其中共享表示生成器的具体实现是可自定义扩展的。最后本文在两个不同数据集上进行了五组实验,结果表明相比baseline本文的方法有明显的性能提升,能够有效缓解远程监督中的噪声干扰问题。"
957,机器学习模型测评技术研究与实现,"随着大数据时代的到来及计算机技术的发展,人工智能由过去主要依靠专家系统实现变为通过算法实现,机器学习是众多算法的重要分支。机器学习以“模型”形式应用于人工智能软件中,“模型”质量的优劣很大程度上决定了人工智能应用的最终效果。对机器学习模型进行测评是保证“模型”和人工智能应用质量的重要手段。目前,在机器学习模型的性能和稳定性测评方面已有一定研究,但尚未形成完整的测评指标体系,且在测评模型鲁棒性方面存在一定研究空白。本文围绕“如何定义机器学习模型质量”、“如何构建测评指标体系与评价模型”、“如何实施测评”的问题展开研究,构建机器学习模型质量模型、测评指标体系、综合评价模型,提出相关测评技术,并进行指标处理。本研究为测评机器学习模型质量提供全面的指标体系和模型鲁棒性测评思路,在保证模型质量和人工智能应用质量方面有一定意义。首先,提出机器学习模型测评的概念、测评内容、方法分类,并对比分析机器学习模型测评与软件测评的异同,在深入分析机器学习模型特性基础上,提取模型的6个质量要素,即“性能”、“稳定性”、“鲁棒性”、“可实践性”、“工程效率”、“代码安全性”,并建立层次化的初始指标体系。接着,通过文献分析法提炼指标构建原则,并针对机器学习模型面向具体任务的特点,提出基于二次筛选的指标体系构建方法,分别是采用定性分析法做第一次筛选,采取专家问卷调查法与定性分析结合的方法做第二次筛选。接着,针对机器学习模型质量需求多变,指标较多的特点,提出简化的构造判断矩阵的方法,减少了人工定性比较的次数,利用层次分析法确定指标权重,并用所提方法建立手写数字识别模型的指标体系。其次,提出模型数学属性测评的形式化流程。接着对手写数字识别模型和软件缺陷预测模型的性能进行测试,分析了性能度量指标的有效性和局限性。接着提出第一类鲁棒性度量指标robustness_1,并实验验证了指标的有效性。接着在深入分析对抗样本构造原理的基础上,定义了第二类鲁棒性的度量指标Defense,即模型对攻击的防御能力,提出基于对抗样本攻击的第二类鲁棒性测评方法,并实验验证所提指标和测评方法的有效性。接着对各指标进行一致化和无量纲化处理。最后,在理论研究基础上,进行图片分类模型测评系统的设计与实现,并用花卉识别的DNN模型、CNN模型、基于Inception V3的模型进行系统验证。本文重点研究了机器学习模型测评指标体系和模型数学属性的测评技术,所提第一类鲁棒性度量指标能够区分模型对合理性异常数据的处理能力,所提第二类鲁棒性度量指标能够区分模型对对抗样本攻击的抵抗能力。"
958,AST3-2巡天观测中暂现源及变源的搜寻方法研究,"对变源和暂现源的观测是时域天文研究领域的重要组成部分,在光学波段,巡天观测和后随观测是该领域的主要研究手段之一。通过对指定天区开展系统性的观测,并对感兴趣的源进行针对性的跟踪观测,可以得到大量有价值的观测数据。现代天文观测普遍使用先进大视场望远镜开展长期不间断的观测,产生了大量的观测数据,传统的人工分辨和阈值截断方法已经不能满足天文数据的处理要求,引入机器学习模型对数据处理结果进行分类和预测显得很有必要。本文以AST3-2巡天望远镜2016年数据为样本,讨论了探测AST3-2巡天天区的变源和暂现源的方法。AST3-2光学巡天望远镜位于南极大陆穹顶A,该处的气候特征对开展长时间不间断的时域天文巡天观测非常有利。南极通信不便,数据回传有诸多困难,我们希望能够在南极本地自动处理AST3-2观测数据,进行变源和暂现源处理,但是受到低功耗计算机的限制,数据的快速自动处理的实现存在诸多困难。为此我们结合已有的图像相减方案,将AST3-2 2016年观测数据作为测试样本,发展了一套基于随机森林的暂现源及变源的筛选方法。我们使用图像相减法找出可能的存在光度变化的源,再用主成分分析法抽取候选源的特征,并选择随机森林作为机器学习分类器,在测试中对正样本的召回率达到了97%。本文的工作验证了这种方法的可行性,并最终在2016年观测数据中探测出一批变星候选体。本文第一章介绍了国内外大规模时域巡天的设备、流程、及数据处理方法的发展状况,第二章简要描述了各类变星的特征,这些是本文工作的研究背景。第三章描述了CCD的特性及基本的测光方法,第四章介绍了本文工作所使用的算法的原理和特点,第五章介绍了我们的工作所基于的软件,这些构成了我们所讨论的暂现源和变源的搜寻方法的基础,第六章详细介绍了这种结合图像相减法和随机森林的方法及研究结果,并对这种方法未来的发展做出展望。"
959,基于深度学习的棉花异性纤维分类研究,"原棉在生产过程中会混入包括丙纶丝、绒线、地膜以及动物毛发在内的异于棉花纤维的异性纤维,若在棉纺生产过程中混入纱布成品中,会造成布面染色不均及瑕疵等产品降质现象,是影响生产质量的主要因素之一。异纤清除机能在线运行,通过机器学习算法挑出异于棉花的异物纤维,但是传统的该类机器并未实现对异纤种类的自动分拣工作,无法准确得知所检出物品的类别信息。传统的机器学习算法在人工提取特征上难以解决真伪异纤分类问题,而深度神经网络不需要进行人工特征提取而自动的学习图像的特征,能避免无法提取特征的问题,能更广泛的适应实际设备工作状态。研究深度学习对异纤进行分类,进而对棉花进行质量评估的工作具有重要意义。本文首先介绍了棉花图像分类的研究背景和发展现状,阐述了深度学习的理论基础以及深度神经网络的组成,并且介绍了卷积神经网络。其次,使用了基于深度神经网络的棉花图像分类方法。该方法利用传统的深度神经网络包括AlexNet,Vgg16和GoogleNet三种神经网络对棉花进行了分类研究。实验结果表明,深度神经网络可有效学习棉花的特征,达到具有较好的分类准确率。然后,提出一种基于丰富特征的卷积神经网络图像分类方法。该方法在传统的神经网络的基础上做出了改进,主要利用卷积核来增加浅层、中间层到深层的特征信息,并且采用点卷积结合特征,最终全连接层将所有的特征连接起来进行分类。通过本方法和传统的卷积神经网络进行对比实验,实验结果表明,该方法能够进一步提高深度神经网络对棉花图像的分类准确率。最后,对全文的研究进行总结,并展望继续研究方向。"
960,外周血细胞分类与计数在深度学习中的应用,"在医学检验科,外周血细胞检测(血常规)作为一种采样方便、检测准确的检测方法,一直对疾病判断有着非常重要的意义。外周血细胞检测主要通过识别血液中各类细胞、并计算各类细胞的比例是否在正常范围内,从而判断被检测者是否患有某种疾病。不同的血细胞检查结果揭示了多种重要的血液病原理。在医学图像处理领域,随着成像技术的极大进步,用计算机图形学辅助医学诊断成为一大趋势,一方面,成像技术的发展带来了海量的医学数据,另一方面,计算机图形学辅助诊断可以生成血液样本的图像,带来更精确、更高效的诊断结果。总之,如何将深度神经网络应用到医学检测上,将计算机拍出的血液样本图片用深度神经网络进行分类和计数,代替医生的手动操作成为一个广泛关注的热点课题。本课题与南京市鼓楼医院合作,在医学检验科采集临床外周血细胞显微图像,建立外周血细胞数据集。本课题采用深度学习的方法对外周血血细胞进行分类和计数研究。主要研究内容包括:1、在分析了外周血细胞图像的采集难点后,建立了自己的血细胞数据集,这套数据集从实际入手,分类完备,比现有的5类白细胞数据集多出4类,为后续的分类和计数研究奠定了基础。2、针对数据集类间数据量不平衡的问题,做了数据增强并随机采样训练集。针对细胞类间特征差异过小的情况,设计出一种新的数据增强方法,加大差异间的采样频率,将测试准确率提高至99%。3、根据红细胞计数的研究现状,从图像处理入手,采用基于卷积神经网络的计数方法,结合特征金字塔(FPN)和深度残差网络ResNet,将红细胞计数的准确率提高至97.5%。本课题基本完成了血细胞的分类和计数工作,解决了细胞类间相似度过高引起的分类困难问题,并且涵盖了外周血中几乎所有影响疾病判断的细胞类型。该研究极大地节约了人力成本,并为后续的研究奠定了基础。"
961,基于多种深度学习构件的同源及异源多模态数据利用,"随着计算机技术的日益进步,数据的收集来源和应用方式变得越来越多样化、复杂化。这些针对同一对象的从不同来源获取或者从不同角度刻画的数据,我们称之为多模态数据。从不同来源获取的数据,我们称之为异源多模态数据;反之来源单一,但是可以从不同角度刻画的数据,我们称之为同源多模态数据。如何从这些多模态数据中提取特征并加以利用的研究称为多模态学习。近几年,得益于计算机性能的大幅度提升,深度学习技术日益成熟,因而许多研究人员为了能够更有效地从这些多模态数据中提取有价值的特征,结合不同的数据特点以及应用场景特点,提出许多基于不同的深度学习构件的多模态数据应用算法。然而,现有的多模态数据研究中仍然存在着一些问题没有被很好地解决,例如数据的模态不一致、表示复杂以及信息匮乏等。于是,本文分别针对异源及同源多模态数据在多个应用场景中存在的问题,从以下三个方面进行研究,并且提出了相应的解决方法:1.异源多模态数据模态不一致问题研究。大多数现有的异源多模态方法都会利用模态一致性来降低学习问题的复杂性。模态一致性是指同一对象的不同模态示例之间内容一致。为了保持这种模态间的一致性,我们需要保证获取的数据模态完整,否则模态之间信息就存在不对称。但是,由于数据收集失败,数据自身缺陷以及数据私密性等问题,多模态数据在实际应用场景中往往存在模态缺失;此外,即使在完整的多模态数据中也仍然存在模态间不一致异常问题,即事物的不同模态描述之间存在差异或者数据本身与整个数据集的内容存在差异等。这些问题共同导致了异源多模态数据不一致性问题。因此,为了解决这类模态不一致问题,我们提出了一种基于深度能量模型构件的多模态鲁棒学习算法DRUMN。首先,我们采用深度自动编码器框架并引入深度能量模型构件,通过最大化同构多模态数据间一致性来解决模态缺失问题;在此基础之上,我们采用一种自适应权重估计方法来消除异常数据的影响。最终,DRUMN可以有效地解决异源多模态数据不一致问题,并且能提取有判别力的特征表示。2.异源多模态数据复杂表示问题研究。以往多模态算法处理的数据一般满足示例级模态一致性,即同一对象的不同模态示例之间存在对应关系。然而,在很多复杂的应用中,为了能够充分的描述有关对象,往往获得的多模态数据形式复杂,因而可能无法满足示例级模态一致性。例如,一篇文章常常包含多段文字和多张图片。一方面,我们知道这些图片和文字整体之间是对应的(都是对这篇文章内容的描述);但是,另一方面,我们既无法确定图片和文本段数量,也无法确定每一张图片和每一段文字之间的对应关系(无法确认示例级的模态一致性)。在处理这些异源多模态数据的复杂表示问题时,现有的算法无法提供很好的解决方案。因此,我们提出了一种基于消歧模型构件的多模态深度学习算法。我们利用多示例学习中有关方式来处理这类数据的复杂表示问题,同时引入最优传输理论用于解决它们的多标记预测以及标记相关性挖掘等问题。3.同源多模态数据信息匮乏问题研究。异源多模态数据最大特点是来源多样化,这意味着可供挖掘的信息相对较为丰富。相比之下,同源多模态数据由于数据源单一信息相对较少。为了解决单源数据信息匮乏的问题,我们可以从多个角度挖掘数据中的信息,这也是单源多模态数据应用研究的出发点。换句话说,单源多模态提供了一种更加充分挖掘数据特征的研究思路。在不同的具体应用场景中,我们可以结合数据特点利用单源多模态技术提升模型的性能。例如,在短文本匹配场景中,数据源一般只有短文本对,传统文本匹配算法大多从单一角度提出匹配模型,因此模型的效果受限于数据信息匮乏,无法很好地提升。为了能更好的完成任务,我们基于单源多模态思路从多角度、多层次来挖掘文本数据中的信息。我们提出了一种基于局部交互构件的文本匹配算法。我们分别从局部和整体两个角度、低阶高阶两个层次,充分挖掘待匹配文本数据的特征以及文本之间的关系,从而提升文本匹配的准确性。"
962,复杂半监督学习场景的研究,"半监督学习旨在利用大量未标记数据来提高学习算法的性能,是机器学习领域一类基础的研究问题。经过近20年的研究,半监督学习在比较简单的环境下已得到比较好的性能。然而近年来,机器学习在现实应用中不断面临复杂的环境,半监督学习也不例外,需要面对复杂环境给出相应的解决方案。针对复杂环境这个大趋势,本论文从两个方面对复杂环境下的半监督学习开展研究。第一,现实任务的学习对象通常跟多个类别有关,比如一幅图像可以跟多个类别相关。此时,类别标记的缺失情况要比简单环境下的两类半监督学习要复杂很多。为此,本论文首先对半监督弱标记学习问题进行处理。在半监督弱标记学习问题中,数据的标记可能是全部缺失也可以是部分缺失。本文提出半监督弱标记学习算法SSWL,同时利用数据相似性和标记相似性来补充缺失的标记,并通过多个模型的集成来提高学习效果的鲁棒性。学习问题被建模为双凸优化(Bi-Convex)形式,并给出高效块交替优化算法。大量实验结果验证了算法的有效性。第二,现实任务通常面临在线动态场景,例如自适应推荐任务,推荐算法需要动态变化,并与此同时推荐数据的标记常有缺失。为此,本论文进一步对动态在线半监督学习算法的理论基础进行研究。本文展示了一种针对动态环境的在线半监督学习新策略。该策略通过一个平滑假设下的新损失函数,有效利用有用的历史经验信息。本文基于迭代最小二乘算法给出动态在线半监督学习的悔界,即泛化性能在动态环境下的刻画指标,并给出充分条件来判断选择合适的未标记数据。据本文所知,这是首次初步给出未标记数据在动态在线环境下的悔界影响。"
963,基于Spark的迁移学习方法在电网数据分析中的应用研究与实现,"随着信息社会的不断发展,数据挖掘方法在各行各业的研究中逐渐发挥出不可取代的作用,电网系统也迈入到了智能时代。在电力设备的故障诊断、用电预测以及节能减排等问题的研究中,传统的分类、聚类、关联规则等数据挖掘算法都已发挥出重要的作用,并且也取得了不错的效果。但是随着实际应用的不断扩展,传统的数据挖掘方法可能会面临诸多问题,通常情况下,一般的数据挖掘算法都会要求数据源足够充分,而当源领域数据较为稀疏时,一般的数据挖掘算法通常会由于欠拟合的问题很难取得理想的效果。作为一种新兴的机器学习方法,近年来,迁移学习在数据的挖掘分析中已经取得了一定的成果。迁移学习旨在研究不同分布的数据之间的耦合问题,从实际需求出发,选择较为充足的数据源作为迁移学习的源领域,待分析的数据作为目标领域,将源领域中训练出的学习规则应用在目标领域中,以在目标领域中获取更高的起点以及更加精确的数据分析规则。因此,将迁移学习方法应用到稀疏的电力数据中具有极高的实际意义。根据源领域和目标领域之间数据分布的差异,可以将迁移学习分为基于实例的迁移学习方法和基于特征的迁移学习方法。本文从这两个方面出发,完成了以下几个方面的工作。首先,针对现有的迁移学习算法trAdaboost算法中错误率可能收敛过快等问题,本文提出了对trAdaboost算法的改进以及并行化处理,并将改进后的模型应用于变压器设备数据中,完成了负载预测的工作。其次,通过对基于特征的迁移学习算法的研究,本文提出并实现了一种基于平衡领域适应的深度迁移网络模型,并将提出的模型应用到电力数据中,完成了变压器以及开关的故障预测工作。最后,通过对大数据分析平台的集成方法的相关研究,完成了以上两个迁移学习算法在平台中的集成工作。"
964,面向生物医学文本及图谱的知识挖掘与知识发现,"随着生物医学的相关研究迅速发展,大量的领域数据及知识被发现与记录。构造生物信息知识图谱能够有效组织丰富多样的领域知识,从而进行信息检索、数据挖掘与知识发现,为生物学、病理学和药理学提供支持。生物知识图谱的构建过程需要知识提取、知识表示,知识融合以及知识发现等步骤。本文研究这一系列技术步骤中的两个关键问题,分别是面向生物医学文献的信息提取,和面向基因-疾病网络的关联预测,针对这些问题给出了专用的机器学习模型。本文完成的主要工作有:(1)为提取生物医学文献中的事件,提出一种基于混合神经网络的新型组合策略。海量的生物医学以献以非结构化的文本格式记录了大量知识,而事件是一种描述这些知识的有效结构。本文使用了混合深度神经网络模型提取事件相关信息,以消除对人工特征工程的依赖;并使用了一种组合策略作为后处理过程,来改善提取过程中的误差积累。在多个BioNLP公开事件数据集上的实验结果表面本方法的取得了良好的性能表现。(2)为预测基因-疾病关联,给出一个基于关联知识图谱的图卷积模型。众多的数据库记录了的大量的基因和疾病的关联信息,将其组织为知识图谱可以挖掘其中的隐藏知识。本研究使用基于图卷积网络的方法预测其中未知基因-疾病关联,描述了一种邻接矩阵Dropout技术并定义了一个新型的聚簇损失函数,用来增强模型的泛化能力。在DisGeNet数据集上的实验说明了本方法的预测性能达到了已有工作的最佳水平。(3)为解决文献挖掘和关联预测中标注数据不足的问题,给出了基于自训练的半监督学习方法。生物医学数据普遍存在的标记样本数量不足的问题,使得监督学习性能受限。本研究在文本挖掘和基因-疾病关联预测任务上应用了自训练方法,借助已有的标注数据和大量的无标注数据,按照预测结果可信度指标筛选样本,用来扩充标注数据集并迭代训练。对比实验的结果证明了原始模型加入自训练后取得了积极的作用。"
965,基于生成式模型的视频异常场景检测研究与实现,"随着视频监控系统布控密度的增加,依靠人力进行视频异常检测这一任务变得越来越艰巨,实现视频监控系统更高水平的智能化、让系统对异常进行自动监测已经成为一种迫切的需求。对于视频异常检测任务,鉴于异常数据难以获得,通常不使用判别式模型,而是使用生成式模型对正常数据集的样本分布进行建模,随后依据测试样本和训练模式之间的差异性来检测视频中的异常。然而,目前已有的方法对正常模式进行建模时,存在着对于时间信息与空间信息建模不平衡的现象,进而导致了模型进行异常检测时出现对特定类型的检测偏好。本文基于生成式模型,设计实现了视频异常检测算法。论文的主要成果如下:(1)对于使用光流作为模型输入的原理进行了实验探究,并设计了对于模型输入的数据预处理方法。(2)设计实现提出了一个神经网络框架,以更好地结合空间与时间信息来对输入视频样本的正常模式进行建模。框架将两个进行对抗性训练的自编码网络级联起来:一个使用对抗性训练U-net结构,被训练以学习输入视频样本的空间信息特征;而另一个使用改进的对抗训练U-net结构,被训练以学习输入视频样本的时间信息特征。(3)对网络内部结构进行了改进。通过为时间信息网络引入光流,为其引入了更多的时序信息以使网络获得更强的时序建模能力。通过将空间信息网络的输出与时间信息网络的输入进行堆叠,再输入时间信息网络,网络最终可以对未来帧进行预测。(4)通过计算预测未来帧与实际未来帧之间的差异来检测异常,并对差异的度量方式进行了一定的改进。论文在两个数据集上的实验验证了方法的有效性。"
966,经典统计学与机器学习中变量选择方法的比较分析,"当今时代是一个大数据的时代。从计量生物学,基因组学到金融工程,风险管理等诸多学科,都面临着高维性问题。在高维数据面前,变量选择是知识发现的关键。经典统计学研究高维问题历史悠久,新兴的机器学习方法在高维数据处理方面向传统经典统计学发起了挑战。本文的目的在于比较经典统计学中变量选择方法和新兴的机器学习方法在变量选择问题上的表现情况。经典统计学的变量选择方法,我们选择了四种基于系数压缩的方法,分别是Lasso,Adaptive lasso,Elastic net,SCAD方法。机器学习中我们主要研究了决策树方法。论文的第一部分首先对经典统计学变量选择方法和机器学习变量选择方法做了一个比较全面的介绍。第二部分详细介绍了 Lasso,Adaptive lasso,Elastic net,SCAD方法能进行变量选择的原理,参数选择标准,求解算法与其统计性质。在求解算法上,对于前三种方法我们除了介绍了经典的最小角回归方法对问题进行求解之外,也将近端梯度下降算法用到了问题的求解中,而对SCAD方法则用了局部二次逼近对其进行了求解。并且细致的分析了这四种基于系数压缩的方法之间的区别与联系。第三部分我们介绍了决策树方法。决策树的变量选择准则主要介绍了信息增益,信息增益率,基尼指数,DKM准则和基于距离的方法,并比较了这些准则的性能。针对前三种准则我们介绍了其对应的决策树生成方法,分别是ID3算法,C4.5算法,CART算法。此外,我们将第二部分的压缩思想运用到了决策树的剪枝问题上。最后分析了决策树的优缺点,并针对分类树和回归树提出了其对应的性能加强算法。第四部分是数值模拟。数值模拟用了四个模型来生成数据。我们选择了全面且合理的模型评价指标。通过数值模拟我们发现,对于基于系数压缩的那四种方法来说,Lasso和Adaptive lasso选择的变量大致相同,但是Adaptive lasso比Lasso具有更小的标准差和均方误差;Elastic net倾向于选择更多的变量;SCAD方法不仅在其剔除无关变量方面要优于其他三种方法,标准差和均方误差也都要小于其他三种方法,并且样本量越大,SCAD方法选出的变量越接近于真实的模型,这也验证了其Oracle性质。决策树虽然并不擅长做回归问题,但是也能很准确的选出真正的变量,并且通过决策树的性能加强算法得出的变量重要性排序中,真正变量的得分要远远高于无关变量。第五部分是实证分析。数值模拟部分我们用的是回归模型,实证部分我们则选用的是分类模型。该部分首先介绍了如何用Lasso,Adaptive lasso,Elastic net,SCAD方法去做分类问题,即将这四种方法运用到logistic模型上。对于实证一,为了对变量加入模型的顺序进行分析,我们选用了变量个数较小的乳腺癌分类数据集。我们在测试集上拟合模型,在验证集上测试模型的分类正确率。对于经典统计学方法,我们首先给出了基于一次模拟的系数路径图和对应的CV误差图。之后重复模拟 100次,得出 Lasso,Adaptive lasso,Elastic net,SCAD在测试集上的分类正确率分别为96.5366%,96.5877%,96.4781%,96.7756%,并且前三个选入模型的变量都为变量2,3,6,最后加入模型的两个变量都为变量5,9。对于决策树方法,我们先在测试集生成一棵树,之后在验证集上测试得到分类正确率为94.7619%,对该决策树剪枝后得到了相同的结果。之后我们在训练集上生成100棵树,用决策树性能加强算法在测试集上的分类正确率提高到了96.1905%,并且该加强算法得出的前三个重要的变量与经典统计学方法得出的结果相同,为变量2,3,6,但是决策树认为最不重要要的两个变量为4,9,不同于经典统计学方法得出的变量5,9。实证二的实施过程与实证一基本相同,得出Lasso,Adaptive lasso,Elastic net,SCAD在测试集上基于100次模拟的分类正确率分别为90.5807%,91.7963%,90.9354%,99.8387%,决策树性能加强算法在测试集上的分类正确率为93.5484%,并且我们也详细的分析了每种方法选择的变量。第六部分为总结与展望。该部分对经典统计学方法和机器学习方法进行了比较总结,并对本文的不足提出了改进思路。"
967,面向DPI数据的旅游画像系统的研究与实现,"随着互联网的飞速发展,各类互联网应用通过庞大的用户群体催生了海量的用户在网行为数据。越来越多的用户会选择访问旅游网站和使用旅行类App。如何从这部分海量数据中对旅游行业用户进行分析成为目前研究工作中的重点。本文以运营商的DPI(Deep Packet Inspection)流量作为数据源,借助大数据平台处理的相关技术,实现了面向DPI数据的旅游用户画像系统的设计实现与应用。本文的主要工作有以下两个方面:1)基于运营商DPI数据,结合网络爬虫技术获取的辅助旅游信息数据,搭建了面向DPI数据的旅游画像系统,系统包括了数据处理平台以及数据存储平台两个部分。通过Dj ango框架搭建web服务,完成了旅游用户画像的可视化模块,并对旅游用户在网行为进行了分析展示。2)根据DPI流量数据的特性,系统分析了面向网络用户的基于时间戳的、基于报文信息的、基于域名的以及基于网页内容的特征。针对旅游用户身份识别任务,利用上述DPI流量特征,设计了基于机器学习模型的旅游用户身份识别方法,通过实验对提取出的特征进行不同的组合分析,提升了模型的训练与评估效果。"
968,面向运营商资费知识图谱的信息抽取技术研究与应用,"随着移动通信、移动互联网等技术的快速发展,用户间的通信连接需求不断提升。运营商为了满足不同用户的需求,推出了多样化的业务,形成了动态复杂的资费体系。不同运营商、不同地域的资费套餐和促销种类繁多,功能复杂。一方面,给运营商带来运营和管理上的困难,难以对自身资费体系进行科学评估;另一方面,用户在选择资费套餐时也无从下手,难以准确选出合适自身需求的套餐业务。通过建立资费知识图谱,可以系统梳理套餐资费间的知识关联,帮助市场营销人员快速定位用户需要的资费套餐,同时将对手的资费策略、竞争意图知识化,方便营销人员按图索骥、快速决策。本论文基于构建运营商资费知识图谱这一需求,从数据获取、数据标注及处理、资费信息抽取到最后知识图谱的构建,提供了一套完整的解决方案,并通过实验证实了方案的可行性。构建好的资费知识图谱,全面准确地描述了资费、知识关联,为运营商资费业务的智能评估预测建立基础知识支撑。本文主要工作和创新点如下:(1)资费数据的获取与预处理。通过爬虫爬取公众号文章及官网数据获取初始数据集,并通过文本分类提取数据集中的资费文档,为后面资费信息抽取做准备。针对资费文档分类这一任务,在利用卡方值获取特征词向量的基础上通过分析资费文档的特点引入人工特征,对比分析了多种分类模型,经实验验证资费文档分类准确率达到90%以上。(2)针对资费文档的信息抽取,对文档中的表格数据和文本数据分别采用不同方式进行信息抽取。表格数据采用规则加词典的方式抽取。文本数据的抽取在BILSTM+CRF基本模型的基础上引入领域字向量与分词向量,显著提升了实体抽取的效果。(3)采用自顶向下与自底向上相结合的方式构建运营商资费知识图谱。引入专家知识,自顶向下定义了 21种资费实体及其对应的63种属性关系,基本覆盖了目前市面上所有的资费类型。自底向上将信息抽取得到的套餐知识映射到定义好的知识库中,完成资费知识图谱的构建。"
969,股市舆情数据的挖掘与分析研究,"随着计算机科技的高速发展与网络数据信息的激增,数据挖据技术已经逐步成为信息时代下推动金融股票市场创新发展的核心力量。在股票市场中越来越多的股民投资者热衷于在网络论坛中交流股市投资心得,由此产生的非结构化股评舆情数据成为了影响股票市场健康发展的重要因素。在有关网络舆情数据与股票市场关系的各类研究中,传统的股市交易指标已经无法满足投资者把握股票市场运行规律的需求。本文基于机器学习和深度学习技术对股市舆情数据进行了挖掘与分析,力求解决股市舆情潜藏情感倾向挖掘能力不足以及相关交易指标预测结果不佳的问题,相关研究工作如下:1.使用爬虫抓取器,按照特定规则遍历解析东方财富网股吧网页评论信息及其它特定属性列表信息作为股市舆情数据源。借助多个处理工具对原始数据进行去噪声、去干扰以及分词、停用词过滤等预处理工作,在中文分词和特征矩阵构建的结构化过程中引入TF-IDF加权技术和Word2vec表达技术实现非结构文本的量化表示,以提高后续分类预测模型的输入质量与学习效果。2.以挖掘股市舆情数据的情感倾向作为研究目标,基于朴素贝叶斯和卷积神经网络两种思想构建股评舆情数据情感倾向分类器,根据分类器评测指标对比分析了两种分类器的分类效果,结果表明,基于卷积神经网络的股评舆情数据情感倾向分类准确率高于朴素贝叶斯情感分类器,进一步证明了卷积神经网络在股市领域对股评舆情情感倾向分类的准确性。3.研究了股评舆情数据中潜藏情感信息结构化权值强度对股票交易指标成交量的影响,研究结果表明,通过情感词典匹配计算得到的交易日股评舆情情感值在某种程度上可以对相应股市交易日的成交量指标进行行为预测,并较为真实地反应一定时间内股市成交量的走势情况。4.基于支持向量回归机和BP神经网络两种方法,研究了股市舆情数据对股票收益率的影响,并对两种方法的性能评价指标进行了对比分析,结果表明,两种模型的学习结果均能预测股市收益率及其走势情况,且支持向量回归机模型的预测误差小于BP神经网络,进一步验证了支持向量回归机模型在预测股市收益率时可以产生优于BP神经网络的预测结果。"
970,机器学习程序错误分析及其检测技术研究,"近年来统计机器学习在越来越多的领域中被广泛应用,例如数据挖掘、图像识别以及自动驾驶等等。然而,对于机器学习程序的软件质量保障工作仍然处于起步阶段,很多工作都致力于提高数据集的质量或者测试训练好的模型即分类器。与他们不同的是,本文关注的是机器学习程序潜在的代码错误,其中包括学习器部分和分类器部分。测试机器学习程序是很困难的,因为这类程序没有测试预言。这个问题很少被机器学习的研究人员以及从业人员所考虑,并且他们并不打算区分机器学习算法和实现这些算法的代码。机器学习程序中的代码错误会导致一系列的后果,例如程序崩溃、丢失训练数据、性能降低、时间开销增加等等。为了能够给机器学习应用开发者以及使用者提供一个合理指导,本文针对机器学习程序中的代码错误,提出了一系列用于检测代码质量的解决方案。具体工作包括:・我们尝试理解机器学习程序错误。我们利用变异测试生成突变体来模拟程序员在编程中可能犯的错误。我们使用统计假设检验比较突变体与原始程序以及基准程序在性能上的差异。根据在不同数据集组合上的检验结果,我们对突变体进行了分类。有些突变体属于严重错误,例如编译不通过或者导致程序崩溃。有些突变体会严重降低程序性能,而有些会使程序运行超时。另外存在大量没有被执行的突变体,这说明代码覆盖率仍有意义。最后有两类突变体较为重要:一类是统计等价突变体,另一类是统计顽固突变体。・我们尝试区分这两类突变体。统计等价突变体应该被认为是正确的程序,而统计顽固突变体属于隐藏很深的错误,故应该被检测出来。首先我们使用蜕变测试进行区分,发现它能检测出部分统计顽固突变体,但仍有一定漏报率。然后我们使用机器学习算法的性质来进行区分,分别查看程序在学习曲线上的表现以及对于对抗样本的鲁棒性。我们发现有一部分突变体能够明显区分,但仍然存在一部分无法区分的突变体。这说明测试机器学习程序仍然困难,因为缺少有效的先知。・我们设计并实现了MINT系统,它将上面提到的众多测试方法集于一体。我们用实验证明MINT系统对于测试机器学习程序有一定的指导意义,可以为程序员提供一些有效的信息,为机器学习程序测试和使用带来了实质性的便利。"
971,燃气管道腐蚀评估系统的设计与实现,"城镇燃气是城市重要的基础设施之一,城镇燃气管网建设快速发展的同时,埋地燃气管道的安全问题应当得到重视。对于埋地燃气管道,由腐蚀引起的管道损坏是最严重的潜在危害。针对管道腐蚀的风险分析,燃气行业经过多年的研究,取得了一定的成绩,风险分析已逐步规范化。基于层次分析法的模糊综合评价和基于专家打分法的模糊综合评价是目前广为应用的管道腐蚀评估方法,这类方法通常通过层次分析法和专家打分法对造成管道腐蚀的各因素进行权重分析,然后再基于模糊综合评价方法量化燃气管道腐蚀风险。然而这类方法计算量大,且需要权重的确定。近年来,人工智能飞速发展,机器学习在很多领域应用广泛。机器学习技术从数据中获取规律,利用规律预测未知数据的能力,为埋地燃气管道的腐蚀评估提供了新的技术路线。本文在探讨了传统燃气行业腐蚀评估方法并深入研究机器学习算法的基础上,设计了一种基于机器学习方法的燃气管道腐蚀评估模型,并加入环境因素对此模型进行了优化。基于优化的模型,设计与实现了燃气管道腐蚀评估系统。该系统由资源服务器、应用服务器和客户端组成。资源服务器负责燃气管道相关数据及环境数据的存储和数据清洗工作;应用服务器负责提供各类业务接口,包括安全因素分析业务和腐蚀评估业务;客户端负责安全因素分析结果和腐蚀评估结果的可视化工作。论文首先介绍了课题背景及意义,总结目前燃气领域管道腐蚀评估技术的应用现状,并提出了详细的研究目标与研究内容。接着对研究与开发过程中应用的相关技术进行介绍,包括数据库技术、数据可视化技术、JavaEE开发框架及机器学习算法等。然后论文介绍了传统燃气行业的管道腐蚀评估方法,设计了一种基于机器学习方法的腐蚀评估模型,并加入环境因素对该腐蚀评估模型进行了优化。在燃气管道腐蚀评估系统的设计与实现部分,介绍了系统需求分析与总体设计,并详细描述了各功能模块的工作流程和核心类图。最后,论文介绍了系统的测试情况,包括功能测试与性能测试,展示了腐蚀评估系统的使用效果,同时验证了系统的功能完整性和稳定性。"
972,燃气管道风险预测方法的研究与实现,"燃气传输管道是当前大部分城市重要的基础设施,由于燃气的易燃性、易爆性和有毒性,一旦燃气管道发生泄漏,很容易造成重大的安全事故。大部分城市的燃气管道的使用时间已经超过了 20年,管道的腐蚀程度较严重,加上城市建设步伐加快,燃气管道极易被第三方施工破坏,多数管道处于事故多发期。传统的燃气安全管理侧重于燃气泄漏发生后的补救,随着大数据技术的发展,我们已经具备了分析处理大量管道安全数据的能力,并基于这些分析的结果对管道风险进行预测。近几年,随着数据挖掘技术的发展,有些研究者也开始试图使用数据挖掘技术对燃气管道风险进行评估和预测,但是没有针对燃气管道风险的特点选择合适的模型,而且缺少对模型的有效性验证。本文在深入研究机器学习和深度学习及其他相关技术的基础上,针对燃气管道施工破坏风险的特点设计了基于大数据的燃气管道第三方施工破坏风险预测模型。为了使预测结果更加客观准确,我们不仅采集了燃气管道事件报告等燃气公司内部数据,还采集了天气、施工信息和建筑物信息等和燃气管道风险相关的外部数据,并从这些历史数据中提取出数据集用于训练和验证模型。同时,我们还设计并实现了燃气管道风险预测系统,做到实时更新数据集、自动训练模型和实时预测,并且将预测结果实时展现在地图上。本文首先介绍研究背景和意义,总结燃气管道风险预测方法的国内外研究现状;然后具体分析传统的燃气管道风险评估方法和当前一些基于大数据的燃气管道风险评估方法的优缺点;接着针对这些方法的不足之处,我们从数据挖掘的角度设计了一套实用的燃气管道施工破坏风险因子,并用其建立了基于线性回归的燃气管道施工破坏风险预测模型和基于长短期记忆模型的燃气管道施工破坏风险预测模型,然后使用燃气管道安全管理公司提供的数据对模型进行准确性和有效性验证。在此基础上,我们把建立起来的模型整合到燃气管道风险管理平台中,实现了燃气管道风险预测子系统。"
973,面向特定场景的移动网络质量评估方法的研究和实现,"随着移动网络用户量和性能需求的不断上升,移动网络质量评估作为衡量移动网络性能高低的参照依据,逐渐受到各大运营商的重视。目前,主流的移动网络质量评估方法通过建立关键性能指标集合,从多个维度对移动网络质量进行考察。然而,主流方法高度依赖专家意见,且无法给出全维度下的综合评估结果,在应用场景的转换上也欠缺灵活度。因此,建立特定场景下更为智能、全面、灵活的移动网络质量评估体系势在必行。基于以上背景,本论文利用机器学习的相关方法,建立移动网络质量评估模型,并在国内某运营商提供的移动网络质量指标数据集上进行训练和验证。实验流程主要分为数据挖掘、建模和效果验证三个部分。其中,数据挖掘部分包括探究各性能指标变化规律和其两两间的相关性两部分;建模部分的核心是基于多特征时间序列聚类和自编码器的聚类算法,主要分为以下三个步骤:第一步,基于FastDTW方法计算时间序列数据两两间的相似度,构建多维相似度矩阵。第二步,采用自编码器对该相似度矩阵进行降维,获得融合多维相似度矩阵。第三步,基于K-medoids算法对该相似度矩阵中对应的数据进行聚类;效果验证部分就高校这一具体场景,通过在真实数据上建立移动网络质量评估模型,对本文所提评估方法的有效性进行了验证。本论文首先介绍了选题背景和意义,总结和分析目前国内外对于移动网络质量评估方法的研究,并在此基础上提出了详细的研究内容及目标。之后,对本文使用到的背景技术进行介绍,包括移动网络质量评估、FastDTW算法、自编码器、K-medoids算法等。然后本文结合全场景数据分析了不同机器学习算法在移动网络质量评估中的可行性,基于此分析选取合适的算法并设计一套实验流程,之后通过与KPI评估体系对比完成了有效性验证。最后,本文使用此评估方法建立了面向高校场景的移动网络质量评估模型,并根据实验结果详细地分析了该场景下移动网络质量的分布和变化特点。"
974,基于应用行为特征的多任务协同调度瓶颈分析系统的研究与实现,"移动互联网大数据、云计算、机器学习等技术兴起,应用服务不断的复杂化,随之对系统性能的要求也在不断提高,应用性能管理服务成为了企业级应用及服务器管理和优化的关键支撑。面对复杂的系统应用,如何能发现服务集群中的瓶颈成因,有针对性的提出优化建议,更好地提升资源利用率和系统效率,成为了现今应用性能管理服务存在的挑战。论文针对复杂应用服务集群中的多任务调度问题,提出了一种基于应用行为特征的多任务协同调度瓶颈分析方法。论文基于对应用行为历史数据的分析,将应用行为特征划分为应用性能特征和任务调度特征,并提出以下创新点。针对应用性能特征的复杂性,采用应用性能特征聚类算法获得应用性能表征类别,通过聚类和人工辅助方式获得任务调度模式分类;同时,以人工标注的应用性能表征类别对任务调度模式进行描述,减少人工依赖;之后,论文将服务器任务调度模式抽象为元胞状态,建立任务调度状态元胞自动机模型,并通过调度模式学习算法,对应用调度状态变化序列进行学习,计算出可能存在瓶颈的调度模式的状态转移概率。基于论文提出的多任务协同调度瓶颈分析方法,结合应用测试与优化分析项目需求,论文对多任务协同调度瓶颈分析系统进行了需求分析,然后依据需求分析对系统的总体框架进行了构建,对各个模块的静态功能和动态交互进行了详细设计,并给出了关键的实现流程说明。最后,对系统的功能实现进行了测试,验证了系统的有效性。"
975,面向云服务的服务协同与负载均衡策略的设计与实现,"如今互联网的普及以及互联网应用范围的延展对云服务系统的可扩展性和性能带来了巨大的挑战。一方面,架构是解决可扩展性问题的基础。面向服务架构和微服务架构相较于单体架构具有更细的服务拆分、更低的服务耦合和更强的系统伸缩性,已经成为目前主流的云服务系统架构。所以,本文针对应用这两种架构时存在的服务协同问题设计了一个服务协同系统。另一方面,负载均衡技术对于提升云服务系统性能具有重要作用。然而,各种传统的负载均衡策略在实际应用中存在各种各样的问题。所以,本文提出了一种基于线性回归的动态负载均衡策略。首先,本文在服务协同系统中针对服务发现与通信、服务配置管理、负载均衡等服务协同问题,设计了服务注册中心、服务配置中心和网关负载均衡器等主要组件。其中,服务注册中心、服务配置中心基于分布式协调服务Zookeeper对存储结构、访问模型、操作等方面进行了设计;网关负载均衡器基于服务注册中心与服务配置中心提供的服务发现与配置管理功能实现了对动态服务与配置的支持。其次,本文基于Zookeeper的watcher机制设计了针对服务发现与服务配置查询的客户端缓存。针对缓存过期功能,本文设计了一个保证同一时间最多开启一个定时器的超时队列。经测试,客户端缓存的添加大大提高了服务注册中心与服务配置中心的访问性能。最后,本文提出的动态负载均衡策略利用线性回归从服务节点的运行数据中学习每秒完成请求数与负载值的关系进行实时负载值预测。另外,本策略在模型初始参数设置和迭代停止条件中设计了优化方案以提高训练速度;在模型使用条件中通过运用3 σ准则以合理运用模型。测试显示本策略具有一定的负载调节能力,在均衡性和每秒完成请求数性能方面均具有不错的表现。"
976,花生米品质分选系统的关键技术研究,"花生是我国重要的经济作物和油料作物,在农业和工业等领域内具有较高的应用价值及广阔的发展前景。外贸出口对花生米的大小、外形、霉变、破损等方面有着明确的规定,但色选机只能分拣霉变粒,难以满足市场需求。机器视觉技术正越来越多地应用于食品或农作物的品质识别,特别是近几年发展起来的机器视觉技术与机器学习算法相结合的研究与实现。利用机器视觉技术实现花生米品质的自动无损检测,对于提高我国花生的市场竞争力以及花生产业的健康可持续发展,具有重要的理论价值和实际意义。本文研究了花生米品质等级分选系统的关键技术,主要包括花生米各类特征提取方法的分析、研究和对比,以及分选算法的研究、设计与分析。主要研究内容和结论体现在以下几个方面:(1)研究花生米图像的预处理方法。通过试验选择3×3大小的中值滤波器进行滤波去噪;通过分析花生米图像前景背景三个通道的取值,使用RGB的线性组合对花生米图像进行分割,从而减少了光源亮度对分割效果的影响,同时避免大津法循环求取阈值的缺点,具有较高的运行效率。(2)研究花生米图像的纹理特征和颜色特征提取方法。截取纹理分析区域并通过高斯-马尔可夫随机场提取纹理特征;基于HSV颜色空间,分别利用直方图、颜色矩提取颜色特征。(3)提出花生米的轮廓特征提取方法。利用直接最小二乘法拟合得到椭圆,并分别提出了饱满度特征以及对称度特征的提取方法,然后与其他研究人员所采用的饱满度特征提取方法在特征参数分布以及相关系数方面进行对比。实验结果表明,本课题所提出的饱满度特征提取方法可以更加有效地衡量花生米外形的饱满程度和规范程度,相关系数与其他方法相比提高了 0.129以上;两个对称性特征在两类样本上的分布差异较大。而且,这三个特征参数可以同步计算、计算效率高。(4)提出一种计算效率更高的分选算法。算法总体呈分支判断结构,各分类器根据其判别目标不同而输入不同类型的特征。然后介绍了这些分类器的设计及训练方法。分类器A使用神经网络,训练时根据数据集特点对代价函数进行了适当加权;分类器B选取线性判别分析器;分类器C选用线性支持向量机,引入基于分类正确率反馈的特征优选方法,并通过交叉验证探究准确率与特征数量之间的关系。(5)根据近年来其他研究人员所采用的分选算法,设计对比实验,并与本文算法在准确性及运行效率等方面进行对比与分析。实验结果表明,与对比实验相比,本文算法的总体精度提高了3.34个百分点、Kappa系数提高了0.0436,准确性有所上升;提取特征的平均数量从28降低到16,运算量从396降低至76,运行效率大幅提高。"
977,基于计算机视觉的甘蔗茎节识别技术研究,"甘蔗茎节识别是甘蔗种植机械化、智能化的关键技术,只有先对甘蔗茎节进行定位识别,才能实现甘蔗蔗种的自动化切割,从而实现甘蔗种植过程自动化。这不但可以解放大量的人力,节省甘蔗产业成本,同时还可以避免在切种过程中对甘蔗种芽产生物理伤害。针对图像背景相对复杂、各种类型甘蔗表皮颜色差异大、表面纹理混乱、甘蔗目标在图像中的姿态有不同程度的倾斜等原因造成甘蔗茎节难以识别定位的问题,研究提出了分别基于图像处理技术、结构化学习技术、深度学习技术,实现对甘蔗茎节识别定位的三种方案,为甘蔗种植自动化提供理论基础。主要研究内容和结论如下:(1)建立甘蔗图像数据集。对黑皮甘蔗和黄皮甘蔗两种甘蔗实物,分别在白天和晚上有灯光的条件下,在多种背景下进行图像采集。使用软件工具对采集的图像进行正负10度、正负20度、正负30度旋转,最终得到4000幅甘蔗图像数据集。从甘蔗图像数据集中随机选择800幅图像进行人工标记,其中500幅标记的甘蔗图像用于相关模型训练,剩余标记图像用于茎节识别与定位实验结果测试。(2)甘蔗目标分割。利用甘蔗表皮粗糙、纹理混乱和甘蔗目标在图像中呈线性趋势的特点,研究设计了一种迭代线性拟合算法,把甘蔗目标从图像中分割出来。甘蔗茎节识别方案的后续处理步骤均只对甘蔗目标区域进行运算,提高了算法性能和甘蔗茎节完整识别率。(3)甘蔗茎节识别与定位方案。针对所有甘蔗种类其茎节部位的边缘线与其他部位相比差异巨大的特点,提出了三种不同的甘蔗茎节识别定位技术方案:基于小波变换技术、基于结构化学习、基于卷积神经网络。深入研究小波技术理论,分析小波分解系数的各重构组合策略,并选择最佳重构策略进行甘蔗茎节识别;使用甘蔗图像数据和一个公共图像数据集训练一个结构化随机森林模型,然后基于模型输出的边缘概率图像进行茎节识别;设计了一个用于图像边缘检测的卷积神经网络,然后基于卷积神经网络输出的边缘概率图像进行茎节识别。实验结果验证了甘蔗图像边缘线在茎节部位和其它部位的差异性对甘蔗茎节识别有很高的价值。基于该差异特点,研究提出的三种甘蔗茎节识别方案均成功实现了甘蔗茎节定位识别。实验表明三种茎节识别方案的甘蔗茎节完整识别率分别为92%,93%,94%,每幅图像平均执行时间分别为1.96秒、1.50秒、0.90秒。相比之下,基于深度学习的方案时间花销最少。"
978,基于AdaBoost模型的藏文文本分类研究与实现,"目前,藏文大量文献资源已数字化和信息化,通过分类技术对文本进行分类,有利于文献工作者对文献的管理,同时阅读者更能快速方便的查询相关文献。由于藏语语言结构复杂,在自然语言处理领域,人们对其研究时间相对较短,在文本分类处理中,目前还没有一个相对成熟的分类体系,其原因主要是用于分类实验的语料和模型相对较少,即使有些模型也做了实验研究,但是分类效果却不是很理想,阻碍了分类技术的发展,因此本文通过网络收集一定规模的语料并结合当前相对成熟的机器学习AdaBoost分类模型对藏文文本进行了研究与实现,实验结果表明该模型提升了对藏文文本的处理能力以及具有良好的分类性能。本文在研究国内外文本分类的基础上,结合藏语语言本身的特点,把数量不同的多类别样本和当前较为认可的多类型特征作为模型的数据来源,以机器学习中相对成熟的分类模型为核心,建立完成了基于AdaBoost模型的藏文文本分类系统,通过测试达到了预期效果,本文研究成果如下。1.由于当前研究与实验的藏文语料相对较少,所以本文70000多篇语料由个人收集所得并分为7个类别,然后通过文本预处理共形成4392个规范样本,最终完成了对样本集的构建工作。2.把N-Gram和词共4种特征作为提取的对象,利用特征频度排序算法、信息增益算法、信息增益添加算法和前向逐步回归算法依次从成千上万个特征中选取了100个左右具有明显类别区分的特征作为本文实验所用特征,提高了模型的分类效率。3.对KNN、GaussianNB、Logistic回归和SVM常规分类模型进行研究和实验,为本文强分类模型的构建作前期探索,探索中验证了上述分类模型具有稳定的分类性能。4.通过学习AdaBoost模型对文本分类的原理,提出利用上述(3)所列4种机器学习分类模型替换原AdaBoost分类模型中使用迭代算法获取弱分类模型的方法,同时利用排列组合数学算法,共生成11种AdaBoost分类模型并通过5-CV实验结果表明,以一码元、二码元和词为特征的11种分类模型的分类精确率和召回率都达到了90%以上,最低的三码元特征模型的分类精确率和召回率也达到了88%,其中以一码元为特征且基于4种机器学习模型共同组合的AdaBoost模型分类精确率与召回率分别达到了96%和95%,并通过基于AdaBoost模型的多模式分类实验对比,显示出该模型具有良好的分类性能。5.利用AdaBoost分类模型改动算法原理,设计出相对完整的分类系统,以直观的界面对该模型分类性能进行展示。随着自然语言处理技术的不断发展,文本分类技术也越来越成熟,但对藏文文本分类的相关研究还处于起步阶段,探索研究实验也相对较少,本文在分类理论研究的基础上,通过对分类模型进行探索,得出实验数据,因此本文的研究成果对后续的研究具有一定的参考和借鉴价值。"
979,虚拟光网络映射算法研究,"随着数据中心等新的业务出现,现网的架构已经不适应新业务的发展。通过网络虚拟化等经济高效的技术,运营商将物理网络抽象为虚拟资源,根据用户的多样化需求将资源分配成多个独立的虚拟网络。当今的网络,需要有动态加载的功能,也需要实现网络资源按需调配。网络功能虚拟化的出现成为解决网络僵化问题的一个有效的方法。弹性光网络拥有更细粒度的频谱资源,以便实现更灵活的频谱带宽分配,并根据服务请求提供最接近需求的频谱资源,从而减少资源的过量分配,提高频谱利用率。所以未来弹性光网络可以成为网络功能虚拟化的承载网络,这样即可以满足运营商的各式各样的业务需求而无需改变当今的网络架构。而新型的数据中心云计算等多点对多点的业务可以抽象为虚拟光网络业务。因此,在对弹性光网络完成网络虚拟化后,运营商为了增加收入和提供更优质的服务,需要为虚拟光网络业务分配合理的资源,同时需要考虑成本和效率。这是虚拟光网络资源映射算法研究的研究意义。本文的主要研究成果如下:(1)针对虚拟光网络映射中的虚节点优先映射问题,本文提出了一种新的虚节点优先映射算法。该算法在距离自适应的节点优先映射算法基础上,在链路映射阶段增加了对当前虚链路带宽需求和链路频谱使用情况的分析。通过引入基于虚链路带宽请求的辅助图,对不符合要求的物理链路进行剪除,选择一组具有高频谱连续度的候选路径,并按照距离二次排序,选择其中最短的路径。仿真表明,与已有的基于最大计算资源的节点优先映射算法和距离自适应的节点优先映射算法相比,新算法减少了约30%的阻塞率。(2)针对虚拟光网络映射中虚链路优先映射问题,本文提出了一种新的资源加权排序算法。新算法在虚链路和候选路径排序时,将节点资源和链路资源的相对大小进行加权排序,以此确定虚链路映射的顺序和候选路径的优先级。相较于以往使用资源大小的排序算法,新算法的排序更加稳定,可解释性更强,阻塞率性能更加优良。(3)针对虚链路优先映射中候选路径的排序问题,本文提出了一种新的候选路径排序算法。新算法将路径评分的排序问题转化为机器学习二分类问题,即通过算法学习到虚链路映射到当前需要评估路径的成功概率。将所有候选路径依照概率排序,选择成功概率最大的路径。仿真表明,相对于基于最短路径的虚链路优先映射算法,新算法阻塞率性能更加优良,并且可以作为单独的模块与(2)中的资源加权排序算法结合,能取得更优的效果。"
980,下行非正交多址接入系统中干扰用户动态参数检测技术研究,"近年来,移动互联网发展如火如荼,物联网也随之蓬勃兴起,众多智能物联终端设备横空出世。在这种时代背景下,人们对无线通信速率提出了更高的要求。目前第五代移动无线通信技术主要面临高吞吐量、低时延、高可靠性和大连接等方面的挑战。非正交多址接入技术作为5G中重要的候选标准之一,受到了学术界和产业界的广泛关注。非正交多址接入技术有多种实现方式,功率域的非正交就是其中之一。在功率域非正交的实现方式中,多个信道条件差异性较大的用户共享同一时频资源块,并为每个用户分配一个功率因子以保证总功率不变,同时,接收机通过采用串行干扰删除技术提取目标信号。但是为了能够正确提取目标信号,接收机有必要获取有关干扰用户的调制方式。本文针对非正交多址接入系统中干扰用户调制方式的盲检测方法进行了研究。首先,本文研究了已存在的最大似然盲检算法和最大对数似然盲检算法,并指出了这两种算法的优缺点。为了降低最大似然算法的计算复杂度、提高最大对数似然算法的盲检性能,本文充分考虑接收信号的统计特性,优化了最大对数似然算法,并提出了K-最大对数似然算法。同时,本文针对不同的算法进行了检测正确率和吞吐量性能的仿真分析与比较。仿真结果表明,K-最大对数似然算法的检测正确率和吞吐量性能均优于最大对数似然算法,而且在某些场景中,其性能接近于理想情况。此外,本文还比较了最大似然算法、最大对数似然算法和K-最大对数似然算法的计算复杂度,发现K-最大对数似然算法的计算复杂度远远低于最大似然算法,并且与最大对数似然算法非常接近。其次,本文首次提出了基于Anderson-Darling检验的关于干扰用户调制方式的特征,将机器学习算法引入到盲检领域,并提出基于Anderson-Darling检验的机器学习调制方式盲检算法(Machine Learning modulation blind detection algorithm based on Anderson-Darling test,MLAD)。MLAD算法主要由五个步骤构成,分别是聚类、特征提取、分类模型训练、模型参数选取和判决。其中,特征提取阶段使用了 Anderson-Darling检验,而特征映射过程采用了多项式映射。本文通过分析和比较最大对数似然算法、K-最大对数似然算法和MLAD算法的性能,得出MLAD算法的性能是三种算法中最优的结论。因为在绝大多场景中,其性能均接近于理想情况,甚至与理想情况相同。此外,在采用不同机器学习算法时,MLAD算法的性能几乎无差别。因此,实际应用中,MLAD算法更适合采用复杂度较低、易于实现的机器学习算法。"
981,基于机器学习的社交网络信息过滤及推荐系统实现,"随着互联网的飞速发展,信息传递的即时性、共享性得到了大幅度提升,人们的社交方式逐步从线下向线上迁移,线上社交网络以其广大的用户群体、开放的信息传播等特性成为了人们社交的新领域。每天社交网络上产生的数据高达PB级,过量的数据信息导致社交网络面临着信息噪声以及信息过载的问题。即社交网络上存在一些无用信息,且用户无法立刻找到感兴趣的内容,严重影响了用户的社交体验。针对此问题,本文从两个方面来进行解决。一方面,针对信息噪声的问题,本文研究了信息过滤系统的相关技术,其中基于机器学习的信息过滤方法具有准确率高、速度快等优点,但该类方法只利用了互信息等表面词特征,文本特征提取方式单一,且忽略了噪声信息的类间差异性。针对此问题,本文提出了一种改进的基于机器学习的信息过滤算法。即对噪声信息进行精准分类,根据不同的语言使用和分布形式将噪声信息分为四类,每个种类针对性地使用不同的分类器模型,并且将表面词特征与深度学习语义词向量特征相融合,丰富了文本特征表达。经实验证明,本文提出的方法在豆瓣数据上获得了较好的过滤效果。另一方面,针对信息过载的问题,本文研究了信息推荐系统的相关技术,其中基于机器学习的协同过滤推荐算法具有较好的推荐效果,但该类方法只通过分析用户评分或用户评论总体情感倾向来进行推荐,忽略了用户评论中不同属性的情感倾向。针对此问题,本文提出了一种改进的基于机器学习的信息推荐算法。即用关联规则模型提取用户评论中的属性词,利用主题模型将属性词聚合成属性面,情感分析计算出用户在各个属性面上的情感倾向,将深度挖掘出的信息应用至推荐系统中。考虑了社交信息中的文本不规范特性,本文在实验中增加了对未知词汇的情感程度判定等步骤。经实验证明,本文提出的方法在豆瓣数据上获得了较好的推荐效果。综上所述,本文通过对传统算法的改进,提出了基于机器学习的信息过滤算法以及信息推荐算法,设计并实现了基于机器学习的社交网络信息过滤及推荐系统,且具有较好的实验结果。未来研究中将把用户评论间的关联度加以考虑,提升推荐效果。"
982,基于光纤光栅的人体上肢姿态柔性检测与识别研究,"研究柔性高效的人体姿态检测与识别方法对于外骨骼机器人感知人体姿态、理解人类意图、保障使用者人身安全有着重要意义,尤其在当前阶段,实现人-外骨骼信息交互的有效途径还比较少见。随着科学技术的不断革新,人们对姿态检测与识别有了更高的要求,柔性化、便捷化、可穿戴是现在相关传感器的设计方向。本文设计了一种基于光纤布拉格光栅(Fiber Bragg Grating,简称FBG)传感网络的人体上肢姿态检测与识别的实验样机,它既能作为人与外骨骼之间的媒介,为实现人-外骨骼的人机信息交互提供思路,可用于医疗康复领域或动画领域的关节点捕捉和姿态分类。具体研究内容如下:(1)对当前光纤光栅传感技术和姿态检测识别技术的相关文献进行了检索和提炼,并发现了现有传感装置存在的缺陷。对光纤光栅传感和解调原理进行了学习和研究,提出了将光纤光栅应用于姿态检测与识别的构想。(2)结合上肢关节理论和运动范围,本着减少光纤光栅布置冗余和复杂度的原则,将上肢自由度简化,并对简化模型做正向运动学分析,确定了上肢姿态重现和掌心坐标定位算法,然后通过仿真验证了算法的正确性。(3)提出了基于光纤光栅的上肢多关节角度一体化测量的原理和方法,将光纤光栅布置在人体上肢合适的位置以测量关节角度。通过在关节点处直接布置测点的实验,优化了光纤光栅在上肢的布置位置,从而完成用于测量关节角度的柔性传感网络的搭建。接着对测量各个自由度运动角度的光纤光栅进行性能测试,论证了方案的可行性。(4)以以上方案为基础,为了形成具有应用价值的实验样机,设计并制作了可穿戴的关节角度测量织物,采用标定方法建立了织物上的测点信息与人体关节角度的对应关系。针对织物与人体的滑移及多次穿戴位置差异,造成的输出角度信号不准确的问题,通过大量实验进行了修正。建立了基于LabView的姿态检测平台,初步完成实验样机。应用该样机对不同的个体进行五自由度角度测量综合实验,实现了上肢姿态柔性检测的目标。(5)以样机输出的关节信息量为特征,构建上肢姿态数据集。对数据集应用机器学习,分析不同参数对应的实验结果,验证了该实验样机结合机器学习算法应用于姿态识别的可行性。完成了姿态的分类识别。最后对课题完成情况进行了总结,找出并分析了课题研究的不足,提出了部分改进方案,并指出了今后课题的研究方向。"
983,建筑结构表面风压非高斯特性分析方法研究,"建筑结构抗风设计需要充分考虑风荷载的非高斯特征,不容忽视。本文首先回顾了非高斯风荷载研究领域的几个热点问题,综述了研究现状,指出了缺陷和不足。在此基础上,针对非高斯风压概率分布拟合、非高斯风压极值计算、非高斯风压过程模拟以及非高斯风压插值预测四个问题,展开深入研究。全文主要内容及结论如下:(1)现有基于穿越率理论的非高斯风压极值计算方法适用范围有限,且对于短尾侧极值的计算精度明显低于长尾侧。鉴于此,本文开发了“分离描述”(separate description,简称SD)算法以解决这些问题。SD算法采用Johnson变换作为潜在高斯过程与目标非高斯过程之间的转换工具,其适用范围覆盖了整个Pearson平面,适用于任意偏度、峰度组合的非高斯分布。由于短尾侧数据在极大似然函数的计算中所占权重更高,因而提出对母体风压分布拟合两次,以极大似然估计的拟合结果计算短尾侧极值,以矩估计拟合结果计算长尾侧极值,以针对性地改善短尾侧极值计算精度。经对比验证,SD算法的整体计算误差在4%以内,其精度高于传统算法,优势在短尾侧以及处理非高斯性较强的软过程时尤为明显。(2)现有基于极值理论的非高斯风压极值算法需要进行长时间风洞试验,其资源耗费较大。为解决这一问题,本文提出一种试验数据与数值模拟相结合(hybrid measurement and simulation-based,简称HMSB)的算法,通过数值模拟的手段,以前四阶统计量和功率谱密度(power spectral density,简称PSD)为口标,仿真生成大量风压时程,以获取足够多的极值样本,拟合极值分布。考虑到统计量对于极值计算精度影响更大,在保证统计量模拟精度的基础上,为了最大程度地提高模拟效率,提出了一种简化模拟方法,可以实现统计量的精确模拟和PSD的近似模拟。经验证,HMSB法计算精度高于传统方法,整体计算误差在4%左右。其计算效率极高,能在短时间内生成大量模拟时程,从而有效地节省了试验资源。(3)平稳非高斯过程模拟包含频率和概率两方面目标,传统方法大多基于先干涉频率再干涉概率的模拟思路。本文采用新的模拟思路,即先干涉概率再干涉频率,提出了一种新的模拟方法。在此过程中,推导了线性滤波系统输入过程与输出过程低阶统计量之间的转换关系,解决了统计量扭曲问题;探讨了新思路与传统思路所各自面临的不相容问题的成因,证明了两种不相容区间并不完全重叠,新方法可以解决某些传统方法的不相容问题;通过多个算例证明了新方法的有效性和准确性。此外,所提方法还具有模拟高阶相关非高斯过程的潜力。(4)现有非高斯非平稳过程模拟方法较少,且均需要迭代计算,模拟效率较低。本文基于线性滤波技术,提出了新的模拟方法,使用时变自回归(time-varying auto-regressive,简称TVAR)模型将潜在非高斯非平稳白噪声过滤成目标非高斯非平稳过程。新方法无需迭代,计算简便。在其开发过程中,推导了TVAR模型输入过程与输出过程时变低阶统计量之间的变换关系,从而可在模拟前根据目标时变低阶统计量计算出潜在非高斯非平稳白噪声的时变低阶统计量;将传统Johnson变换升级为时变版本,用于生成非平稳白噪声输入;提出了一种简便方法,用于确定TVAR模型阶数;通过算例证明了新方法的可行性和准确性。(5)将高斯过程回归(Gaussian process regression,简称GPR)技术引入到风压统计量的插值估计问题,相比于现有方法中使用的人工神经网络技术,GPR的优势在于超参数自适应选取、输出具有明确的概率意义等方面。对于低阶统计量估计问题,本文所提方法相对于传统方法精度更高,能够实现对未布测点位置和未测量风向角的风压信息的准确补充。对于风压时程估计问题,本文充分利用GPR善于处理小样本问题的特点,提出了时变GPR估计方法,其精度相对传统方法更高,且能够处理风场随时间变化的非平稳情形。尝试估计了高阶统计量和累积密度函数,其中三阶统计量和累积密度函数估计精度较高,可以满足使用要求。而四阶统计量由于其随机性更强、波动幅度更高,精度尚无法满足要求,需进一步提升算法。"
984,基于大数据和机器学习的转子间骨折新型三维分型系统的构建及评估研究,"背景股骨转子间骨折是老年患者最常见的骨折,常导致患者肢体功能障碍和自理能力下降,给社会和家庭带来沉重的医疗和经济负担。骨折端良好的复位是保证手术治疗成功的关键,而如何实现转子间骨折的有效复位,目前尚无定论。合理的骨折分型可以指导骨折临床治疗的选择,并预期治疗后结局,但现有分型多基于二维的X线片,结合形态学特征进行人为归纳。这导致骨折细节描述不清、不同类型间区分不明确的现象。且现有分型系统无法指导术中闭合复位策略,难以预判髓内钉固定术后骨折端稳定性。目的(1)明确股骨近端内侧边重建对于髓内钉固定治疗股骨转子间A2骨折的临床疗效和术后并发症的影响。(2)构建基于大样本量的转子间骨折线走行图谱,探讨股骨近端骨折线在股骨各个面的分布特点,为转子间骨折的三维分型奠定基础,为转子间骨折的临床治疗提供指导。(3)通过提取转子间骨折线的矩阵数据,利用非监督学习K-means聚类分析的方法,实现对转子间骨折的人工智能分类,并验证其在临床中的作用。(4)通过有限元模拟生物力学的分析方法,对新型转子间骨折分型进行生物力学方面的验证,以验证各分型之间的稳定性差异。方法(1)选择性纳入转子间骨折A2型的患者,通过CT切面重建的方法,探索股骨近端内侧边重建质量如何影响髓内钉固定术后结局。(2)纳入504例转子间骨折术前CT数据资料,重建转子间骨折模型,并实现转子间骨折块的复位。在股骨近端的四个面上描绘骨折线,进行描述性分析。(3)基于图谱资料,建立转子间骨折线数据库,并提取转子间骨折线的矩阵数据,计算骨折线数据集间的Hausdorff距离,并通过非监督学习K―means聚类分析的方法,对骨折线进行转子间骨折的分型。随访并记录患者术后的影像学参数、功能指标以及并发症发生情况。(4)建立基于上述分型的骨折模型,重建内固定器械,进行应力、应变、位移的有限元分析。结果(1)实现股骨近端内侧边重建的转子间骨折髓内钉固定术后并发症发病率显著低于未实现的病例(P=0.022),术后功能评分同样高于未实现支撑复位的病例(P"
985,复杂海况下海面弱目标的精准与智能探测研究,"随着人口的不断增加以及科技的快速发展,人类对海洋的开发力度越来越大。海面弱目标探测技术不仅是走向海洋、认知海洋和利用海洋的重要一环,也是实施“建设海洋强国”这一国家战略的基础。然而,复杂的海洋环境使得高精度的海面弱目标智能探测面临诸多特别的挑战。针对此问题,本文对海杂波的特性和检测器的设计进行了深入分析,包括海杂波的分布建模、恒虚警检测器设计以及智能检测器设计等。本文的主要研究内容包括:1、研究了复杂海况下对海杂波机理的精准认知。针对复杂海况,我们提出了一种基于核密度估计的海杂波分布建模框架。在所提框架中,我们考虑了两个基本的关键问题,即核函数和最优窗宽的确定。为了解决这两个问题,我们采用高斯、伽马以及威布尔分布作为核函数,推导了它们各自的最优窗宽的闭式等式,并发现这些闭式等式符合不动点方程的基本特征。基于不动点理论我们提出了快速迭代的窗宽选择算法求解这些不等式,以获得不同核函数的最优窗宽。我们利用核函数与其相应的最优窗宽在所提框架下对海杂波信号进行建模,能有效降低拟合误差并大幅提升目标的检测概率。2、研究了适配海况变化的恒虚警检测器设计。基于所提的海杂波分布模型,我们利用海杂波信号与目标信号在时间相关性上的差异,提出了单元平均时间相关的恒虚警检测算法。为了确定该检测算法中的关键参数(即,去相关时间),我们建立了其与海况参数(即,风速和有效浪高)的线性回归问题,并利用梯度下降法求解该问题,获得了在不同风速和有效浪高下对去相关时间的最优估计。我们基于复杂海况下最优估计的去相关时间以及所提检测算法构建适配海况变化的单元平均时间相关恒虚警检测器,能够有效提升低信杂比和低虚警率环境下目标的检测概率。3、研究了基于多维度特征空间的智能检测器设计。针对动态变化的海况,我们借助人工智能技术在分类问题上的天然优势,设计了基于机器学习的智能检测器。首先,我们利用基于信号处理的特征分析方法在时域和频域中提取了三种具有代表性的特征。然后,我们分析了不同维度的特征空间对海杂波和目标回波的区分度。最后,我们基于这三种特征构造了三维特征空间,并将回波信号在多域特征空间中的表征输入到机器学习分类器中进行训练,实现在复杂海况下对海面弱目标信号的智能检测。特别地,我们改造了传统机器学习算法,将虚警率由输出变为输入,实现了智能检测器的虚警率可控,满足了海面弱目标探测中不同的应用需求。我们基于回波信号的三维特征空间和虚警率可控的机器学习算法构建可感知复杂海况的智能检测器,能够有效提升不同海面检测环境下目标的检测概率。综上所述,本文致力于实现复杂海况下的海杂波精准认知,进而设计适配海况变化的恒虚警检测器以及基于多维度特征空间的智能检测器,从而实现对复杂海况下海面弱目标的精准与智能探测。"
986,共享短租中房客信任影响因素及信任传递研究,"随着共享经济的迅猛发展,共享短租成为人们旅游不可或缺的住宿选择方式,同时也是共享经济最受关注的领域之一。Airbnb作为典型代表,通过P2P模式向全球旅客提供房屋短租服务。房东在该平台上发布自己的闲置房源信息,房客通过平台搜索查找符合自己需求的房源,向房东发起预定请求,双方达成一致后,房客便可付费入住。然而,由于房东和房客往往是互不了解的陌生人,信息不对称带来了众多潜在风险,信任问题随之而来。一方面,房客担心房东所提供信息的真实性,以及短期租住的安全性等。在短租情境下,房东与房客双方不仅涉及在线交易,还需要面对面互动交流甚至共同居住。因此,房客面临的不止是财产风险,还包括附加的人身安全风险。据报道,房客Mike Silverman预定了阿根廷萨尔塔的Airbnb房源,在入住期间遭到房东Rottweiler的袭击,不得不花费两天接受住院治疗。另一方面,房东提供的是一种体验型服务,房客无法提前感知服务质量,加之短租平台中有过住宿体验的房客对房东的在线评级缺乏显著性差异,约95%的评级为4.5或5星(评级分数范围在1星到5星之间),这使得房客很难仅仅依据房东的声誉分值做出决策。在这种情况下,房客如何充分利用可获取的房东其他相关信息,来构建对房东的信任,以减少信息不对称造成的损失,成为短租领域研究的热点问题。现有的针对共享短租中房客信任问题的研究主要是通过问卷调查、实验等方法,探究房东的单一或少数几个维度属性特征对房客信任的影响,数据相对比较主观,数据量较小。少量的针对于短租中客观数据的研究,主要是通过统计分析探究房东的一些数字属性对房客信任的影响。尚未有效利用共享短租平台提供的大量丰富的文本、图片等房东属性信息及高效的大数据分析方法。此外,现有研究主要研究房东属性和声誉对房客信任的影响,并未有研究从信任传递的角度探究先前房客对房东的信任是否会传递给后来房客,从而影响后来房客对房东的信任。基于现有研究以及其存在的不足,本文利用共享短租平台Airbnb上丰富的用户自我描述及行为数据,以房东的自我描述、房东个人照片以及房东收到的房客评论文本为研究对象,基于不确定性减少理论、详尽可能性模型、刻板印象模型、情绪感染以及信任传递理论,运用文本挖掘、人脸识别及统计分析方法对房东的自我描述文本、个人照片进行文本特征及图片特征的提取与量化,定量地分析房东的不同维度属性对房客信任的影响。此外,基于NRC(National Research Council Canada)词典设计面向文本评论的信任及情感分析方法,对房客之间信任的传递进行了研究。本文将管理科学与计算机科学的研究方法进行了融合,运用管理学领域中的相关理论知识提出共享短租平台中影响房客信任的因素并构建了理论模型,通过计算机领域的大数据分析方法对短租平台客观的大数据进行分析,提取并量化各因素变量,通过稳健回归、动态面板回归等计量经济学模型对各因素变量与房客信任之间的关系进行实证研究。最终,提取出了影响房客信任的客观因素,并验证了房客之间信任传递的存在及其影响。本文研究有效弥补了当前研究的不足,并为共享经济中信任研究的相关文献提供了新的研究思路和方法,具有一定的理论和实践意义。本文研究的主要成果如下:第一、基于不确定性减少理论和详尽可能性模型,建立了房东自我描述文本的文本特征对房客信任影响的理论模型,研究了房东自我描述文本的可读性、信息量、情感倾向及语义主题多样性对房客信任的影响,以及不同语义主题对房客信任的差异化影响。本文从社会交换的角度出发,解释和分析了信任在共享短租中的重要影响。共享短租中存在混合的社会交换模式,陌生的房东与房客之间先在线上进行交互,然后转为线下交互。房东本身的属性特征直接影响了房客对房东的信任感知。其中.,房东的自我描述是房东进行自我呈现的一种重要方式,房东通过对自己个人情况的介绍,向房客呈现出自己某些方面的信息,增加房客对自己的了解,减少房客感知的不确定性,从而提升房客的信任。具体地,基于不确定性减少理论和详尽可能性模型,提出房东自我描述文本的可读性、信息量、情感倾向和主题多样性会对房客的信任产生影响,并运用稳健回归模型对所提出的假设进行了验证。运用LDA(Latent Dirichlet Allocation)主题模型对房东描述文本中潜在的主题进行自动识别,通过T检验探究了房东所表达的不同语义主题对房客信任产生的差异化影响。研究发现:(1)与可读性较差的房东自我描述文本相比,可读性较好的房东自我描述文本对房客的说服效果更好,能得到更多房客的信任;(2)房东自我描述文本所包含的信息量以及主题的多样性可以减少房客对房东的不确定性,增加房客的信任;(3)房东对房客的情感态度会通过自我描述体现出来,积极表达自己的热情、友好、欢迎等正向情绪的房东能得到更多房客的信任;(4)在进行自我描述时,更侧重于表达旅行经历,服务态度,对共享住宿的观点和目标以及服务能力的房东相比于主要描述自己的年龄,职业和兴趣的房东能获得更多房客的信任。第二、基于美丽溢价、面部情绪及刻板印象理论,建立了房东个人照片中房东的面部属性特征对房客信任影响的理论模型,研究了房东的面部吸引力、微笑程度、性别和种族对房客信任的影响。本文基于美丽溢价,面部情绪及刻板印象相关理论,提出房东所提供的个人照片中房东的面部属性特征(面部吸引力、微笑程度、性别和种族)对房客信任有显著影响的假设,并对假设进行了实证验证。具体地,抓取了大量Airbnb上真实的房东主页照片,运用Face++人脸分析API对房东个人照片进行人脸分析,并对结果进行json解析,提取出房东的面部吸引力、微笑程度、性别和种族特征。运用稳健回归分析对提出的房东面部特征变量与房客信任之间的关系进行实证研究,检验假设的成立与否。研究发现:(1)房东的面部吸引力对房客的信任有显著的负向影响;该结论与本文的假设相反,通过检验数据发现,面部吸引力高的房东存在美丽溢价,将自己的房源价格定的相对较高,增加了房客对入住成本和风险的感知,进而降低了房客的信任;(2)房东的微笑程度与房客信任之间存在倒U型关系,随着房东微笑的增加,房客感知到的房东的热情、友好就会增加,但是超过某个点,房东微笑再增加会导致房客感知到的房东服务能力的降低,从而降低了房客的信任;(3)短租平台存在性别和种族歧视现象,女性房东和欧美裔房东比男性房东和其他种族的房东更容易得到房客的信任。因为人们往往认为女性和欧美裔人是热情和能力都比较高的群体,而对于短租服务,房东的热情和能力是房客最为关心的,直接影响着房客的入住选择和体验。第三、基于房东的多个维度的属性特征构建了房客信任的影响因素理论模型,并通过R2分解探究和对比了房东单个特征及组特征对房客信任的影响及程度大小;此外,运用深度神经网络和集成学习方法构建了房客信任的预测模型,对房客信任进行了预测。本文聚焦于房东的多维度属性对房客信任的影响,提出了一个房客信任影响因素的计算框架,分别从房东的数字属性(包括声誉、认证、回复行为模式)、自我描述(包括信息质量、情感、语义主题特征)及个人照片(包括照片中人物的情感特征)各维度进行深入、全面分析,运用回归分析探究了各特征变量与房客信任之间的关系,并通过R2分解得到了各维度单个特征变量及组特征变量对房客信任的影响及程度大小,最后运用深度神经网络(Deep Neural Networks,简称为DNN)、集成机器学习算法构建了房客信任的预测模型。研究发现:(1)房东的声誉在各个特征组变量中对房客信任的影响是最大的。其中,“超级房东”标识和累积评论量对房客信任有显著的正向影响,而评论打分并未对房客的信任产生显著的影响。(2)在房东自我描述时,积极表达正向情绪(热情、欢迎、期待等),关注于描述其沟通、交流及服务能力的房东能得到更多房客的信任。(3)房东提供包含正向情绪的个人照片会对房客的信任产生显著的正向影响。(4)构建的房客信任预测模型的正确率、F值和AUC值分别达到了72.32%、71.56%和71.56%。该研究成果可用于短租平台中房东推荐的方法设计中。第四、基于信任传递理论和情绪感染理论,对短租平台中房客之间的信任及情感传递进行研究,探究了信任与情感传递对房客信任的影响。本文基于信任传递和情绪感染理论,提出共享短租中房客之间存在信任及情感传递的理论假设。通过基于情感词典的文本情感分析方法,对先前房客评论文本进行信任和七个维度情感(愤怒、期待、厌恶、恐惧、喜悦、悲伤和惊讶)的识别和度量,量化房客评论文本中所体现的房客对房东的信任度和不同维度的情感值。运用动态面板回归分析,探究先前房客评论文本所表达出的房客对房东的信任及情感是否会影响后来房客评论文本所体现出的房客对房东的信任及情感,以此来验证房客之间是否存在信任及情感的传递。此外,对先前房客评论所表达的房客对房东的信任及情感是否会对后来房客评论文本所表达的房客对房东的信任产生影响进行检验,以此探究先前房客对房东的信任及情感是否会影响到后来房客对房东的信任。研究发现:(1)先前房客评论文本所体现出的房客对房东的信任度会显著正向影响后来房客评论文本所表达的信任度;先前房客评论文本所体现出的七种情感分别会显著正向影响后来房客评论文本所表达的七种情感。说明短租平台的房客之间存在显著的信任和情感传递,而且结果显示信任及负向情绪比正向情绪的传递更为强烈。(2)信任和不同情感对信任传递的影响不同:先前房客评论文本所表达的房客对房东的信任度对信任传递有显著的正向影响,且影响作用最大;其他七种情绪中,正向情绪喜悦对信任传递有显著的正向影响,期待、惊讶和厌恶对信任的传递有显著的负向影响。但是,包含有轻度负向情绪的恐惧情绪对信任传递却有显著的正向影响,这可能是因为先前房客的评论文本所表达出的恐惧与其他的正向情绪混合会增加后来房客对该评论的客观性和有用性的感知,具体原因还需要将来进行进一步的验证。"
987,基于非线性优化建模的激光诱导击穿光谱定量分析方法,"智能制造的发展目标对冶金生产过程的物料、产品及中间产物成分快速检测提出了更高的要求。常规的元素成分检测技术,如火花直读光谱、电感耦合等离子体发射光谱等,对制样要求高,操作繁琐,实时性较差。研究和开发适用于工业现场的元素成分快速分析技术,对于提高冶金自动化水平、降低冶炼能耗和优化冶炼工艺具有重要意义。激光诱导击穿光谱(Laser-Induced Breakdown Spectroscopy,LIBS)是一种新兴的原子发射光谱分析技术,具有制样简单、快速、实时检测以及多元素分析等优势,在原位、快速、远程分析等方面展现出突出的应用价值。鉴于矿冶领域成分检测的应用需求和LIBS技术的自身优势,本论文提出了面向矿冶多元素成分快速检测的LIBS定量分析方法。由于矿冶产品成分复杂,多元素共生,高温环境标样数量少、分析元素特征谱线和元素含量间存在非线性,本论文从实验系统多参数优化和光谱数据非线性建模两方面入手开展了一系列研究,以获得高质量的LIBS发射光谱数据,提升分析模型准确度并促进其在矿冶现场分析上的应用。具体研究内容如下:(1)针对LIBS实验系统多参数优化问题,提出了基于多谱线光谱强度-信背比的光谱质量评价方法和LIBS实验参数多因素优化模型。以合金钢标样和钒渣为分析对象,设计了 LIBS光谱实验采集系统,研究了激光脉冲能量、积分时间、延迟时间、透镜与样品表面距离等关键参数对光谱信号的影响规律,提出了基于多谱线光谱强度-信背比的光谱质量评价方法,能够同时兼顾不同的分析线;并利用二次回归正交设计建立了 LIBS实验参数多因素优化模型,重点优化了积分时间和延迟时间,获得的优化后的实验条件是:合金钢标样的积分时间为5.7μs,延迟时间2.4μs;钒渣样品的积分时间为9.8μs,延迟时间2.3μs。(2)针对多元素共生情况下LIBS光谱干扰问题,提出了基于选择性集成学习的多元素LIBS定量分析方法。以钒渣和球团矿为分析对象,将分析元素备选干扰谱线的不同组合加入到回归建模过程中并训练产生一系列的个体回归器,利用K-均值聚类和选择性集成对筛选出的一部分差异性大且准确度高的个体回归器加权集成得到回归模型,预测钒渣和球团矿测试样本。该方法不需要依赖经验选择分析线和干扰谱线,预测结果由多个个体回归器共同决定。实验结果表明:相比于忽略干扰谱线影响的回归模型,该方法对3个钒渣测试样本中CaO、MgO、Si02、TiO2和V205预测含量的平均相对误差由18.430%、12.721%、8.777%、7.475%和 12.483%分别降低到 1.403%、4.390、4.532%、2.438%和2.086%;3个球团矿测试样本中CaO、MgO、Si02和Ti02预测含量的平均相对误差由14.586%、14.544%、12.972%和12.583%分别降低到3.728%、3.642%、2.813%和3.768%。(3)针对高温环境下标样数量不足的问题,提出了基于改进TrAdaboost迁移学习的高温环境下LIBS定量分析方法。以合金钢标样为分析对象,将相对容易获取且与高温光谱数据不同但关联性较强的常温光谱数据的建模信息“迁移”至高温光谱数据的回归建模中,对常温和高温训练样本分别采取不同的权重调整策略,对训练得到的所有个体回归器加权集成,预测高温环境下的合金钢测试样本。该方法充分利用迁移数据解决了少标样对LIBS定量准确度的影响。实验结果表明,相比于利用传统机器学习建立的少标样回归模型,该方法对3个高温合金钢测试样本中Cr、Ni、Mn和Fe预测含量的平均相对误差由15.182%、52.678%、22.279%和9.437%分别降低到4.619%、5.804%、7.032%和2.966%。(4)针对很难获取标样的情况,提出了基于改进内标线自吸收校正和等离子体温度优化估计的LIBS自由定标定量分析方法。以合金钢标样为分析对象,依据分析线跃迁几率和下能级设计了内标线自动筛选方法,并分别校正了内标线和分析线的自吸收效应,最后引入粒子群算法对等离子体温度进行了优化估计,获得了性能良好的自由定标定量分析模型。该方法所需的参数少且容易获得,进一步拓展了 LIBS技术的应用范围。实验结果表明:相比于传统的LIBS自由定标方法,该方法对22个合金钢样品中Cr、Ni、Mn和Fe预测含量的平均相对误差由26.756%、30.652%、26.644%和9.764%分别下降到4.733%、7.135%、7.207%和3.926%。本论文针对矿冶元素检测需求在LIBS多实验参数优化、多元素谱线干扰、高温少标样建模和自由定标定量分析等方面开展的相关研究方法和思路,可推广到荧光光谱、拉曼光谱等其他光谱分析技术中,在电力、化工、生物、环保等领域也具有广阔的应用前景。"
988,合金元素对半连铸7×××铝合金微观组织和热裂敏感性的影响研究,"7xxx铝合金由于其优异的性能在航空航天领域得到了广泛应用。目前,为了获得高的比强度、高的损伤容限以及优异的抗腐蚀能力等性能,新型7xxx合金正朝向高合金化和大尺寸铸锭等方向发展。这些趋势将可能导致在半连续铸造期间产生热裂缺陷。在所有影响热裂出现的因素中,合金元素无疑起到了十分重要的作用。然而,截至目前,有关合金元素(包括晶粒细化剂、主合金元素及微量元素)影响半连铸7xxx合金微观组织及热裂敏感性的研究报道非常有限。本文将基于多种实验和理论预测方法对它们三者之间的关系进行深入研究。通过采用收缩棒铸造模具和自行设计的模拟半连铸条件的“T”型模具,系统研究了不同含量晶粒细化剂添加对AA7050合金微观组织和热裂敏感性的影响。研究发现:适量添加Al-5Ti-lB细化剂使合金的微观组织由粗大的柱状晶转变为细小的球状等轴晶。与此同时,合金的热裂敏感性也显著降低。这归因于晶粒细化的合金具有更低的刚性温度、更好的液体补给能力、承受了更低的应变和应变速率以及具有更加复杂的热裂纹扩展通道。然而,过量添加晶粒细化剂不仅未细化晶粒,反而由于细化剂中第二相粒子的团聚,合金的热裂抗性被显著降低。提出了一套适用于半连铸7xxx铝合金热裂评估的实验和理论预测方法(包括模拟半连铸条件的“T”型载荷测量装置、凝固路径计算以及SKK热裂判据预测),并系统研究了三种主合金元素和两种微量元素对未细化和晶粒细化Al-Zn-Mg-Cu模型合金热裂敏感性的影响。研究发现:在未细化的Al-xZn-2Mg-2Cu合金中,最小和最大热裂敏感性分别出现在Zn含量为4和12%(质量百分比,下同);而在细化的合金中,最小和最大热裂敏感性分别出现在Zn含量为4～6和9%。Mg和Cu的添加分别改善和恶化了晶粒细化的Al-9Zn-yMg-zCu合金的热裂抗性。微量元素Fe含量的改变对晶粒细化Al-9Zn-2Mg-2Cu-mFe合金的热裂敏感性基本没有影响,而Si含量的增加却明显降低了晶粒细化Al-9Zn-2Mg-2Cu-nSi合金的热裂敏感性。这些趋势可以被归因于所承受的拉应力、液体补给能力、非平衡共晶析出以及固态搭桥等因素之间的综合作用。此外,发现非平衡固相线处的载荷值以及Suyitno等人提议的SKK判据(测量的载荷进展被输入到该判据中)很好地预测了这些模型合金的热裂敏感性。然而,由于高Si合金中固态搭桥的早期形成,相反的热裂预测结果出现在Al-9Zn-2Mg-2Cu-nSi合金中。最终,在四个商用7xxx合金中,上述主合金元素的热裂影响规律以及提议的热裂实验和理论预测方法也得到进一步验证。三维大尺寸铸锭晶粒尺寸是工业铸锭热裂敏感性预测的一个重要微观组织输入参数。目前,铸态Kampmann-Wagnernumerical(KWN)模型有望被扩展并应用于预测三维大尺寸7xxx合金铸锭的晶粒尺寸分布。然而,模拟所需的Gibbs-Thomson相图数据库质量以及访问数据库需要消耗大量运行内存是阻碍该扩展的两个关键问题。该部分研究落在材料信息学的研究范畴。这一新兴领域的目标是高速稳健地获取、管理、分析以及传播各种材料数据。在此,两个智能的相图数据处理技术被开发:(1)基于非监督学习算法的大尺寸相图数据质量智能诊断技术;(2)基于人工神经网络的相图参数化和压缩技术。相比先前7xxx合金的相图大小,使用上述技术获得的参数化相图被压缩了2×105倍。该获得的参数化相图也被成功输入到KWN模型中来预测实验室级别的7xxx合金铸态晶粒尺寸。在模拟过程中,计算占用的内存被显著降低,而计算精度几乎没有损失,并且改善了计算质量。下一步,该方法将被应用于7xxx合金大尺寸铸锭的晶粒尺寸分布预测。"
989,移动边缘计算任务迁移与资源管理研究,"近年来,增强/虚拟现实、智慧城市和自动驾驶等新兴移动应用快速发展,其计算和存储资源需求远超移动终端能力。随着软件定义网络和网络功能虚拟化技术的发展,边缘网络设备逐渐变为可编程的通用处理设备,并具备强大的计算、存储和通信能力。移动边缘计算(Mobile Edge Computing,MEC)技术利用上述计算、存储和通信能力,在边缘网络对复杂任务进行分布式处理,提升网络数据处理能力,并提供低时延高可靠计算服务,以满足未来移动应用对计算能力与服务质量的需求。其中,任务迁移和资源管理直接影响系统处理能力、服务时延及开销,是移动边缘计算的关键研究问题。针对移动边缘计算的任务迁移和资源管理问题,本论文分别从用户任务迁移、多用户―单小区任务迁移与资源管理以及边缘计算组网三个方面展开研究,对系统吞吐量、服务时延、系统稳定性以及能耗进行优化。主要工作和创新点如下。第一,考虑边缘计算中无线信道、任务到达和计算资源等环境动态特性,分别针对单用户―边缘服务器任务迁移和多移动用户协作场景进行研究。具体地,对于单用户―边缘服务器场景,将边缘计算的复杂环境变化建模为控制理论中不可测的系统随机扰动,并通过滚动时域控制技术和多目标动态规划方法提出了自适应任务迁移方案,从而显著提升动态边缘计算环境下的任务迁移性能。另一方面,对于多用户协作计算场景,考虑移动用户自私特性,基于李雅普诺夫优化理论和点对点文件共享中的投桃报李激励方案,提出了多用户协作计算的分布式在线任务迁移方案,在时延网络中保证用户参与并通过多跳方式协作处理任务。相比现有单跳集中式协作方案,能显著减少系统能耗,并提升系统吞吐量。第二,在多用户―单小区移动边缘计算场景中,考虑系统频谱和计算资源的稀缺性,分别针对普通移动应用、时延敏感任务以及海量设备连接的物联网应用的任务迁移与资源管理进行优化。首先,对于普通移动应用,给出了均衡任务计算时延与处理能耗的效用函数,并结合凸优化、准凸优化和次模优化技术,对任务卸载决策、无线资源管理和计算资源分配进行联合优化,提升系统性能。其次,对于时延敏感任务,基于量化动态规划技术提出了接入控制和资源分配联合优化方案,并调节量化区间实现方案最优性损失和复杂度的权衡。最后,对于物联网应用,基于加扰李雅普诺夫优化提出了物联网边缘计算在线资源调度方案,最大化系统效用,并设计了用户选择性上报策略,显著降低网络信令开销,保证海量设备连接的可扩展性。第三,在移动边缘计算组网场景中,考虑边缘服务器的广地域分布和处理能力异构性,分别针对普通应用的大规模边缘计算和分布式机器学习的组网资源管理进行优化。具体地,针对普通应用的大规模边缘计算组网资源管理,提出了大规模边缘计算分布式资源管理和协作域划分方案,以在动态网络环境中最小化时间平均系统开销。首次提出的边缘计算协作域分布式优化可为每个计算节点确定其到达任务的卸载区域,在保证方案最优性同时,避免扩大协作域所增加的时延和开销,提升边缘计算在大规模异构网络中的性能。另一方面,针对分布式机器学习的边缘计算组网资源管理,设计了针对分布式机器学习的数据均匀度指标,并基于随机梯度下降技术提出了数据接入、分配和处理的联合在线优化方案,在保证网络稳定条件下最大化系统效益,并减小分布式机器学习参数同步频率与开销。"
990,基于组稀疏的子集选择应用研究,"从大规模数据中提取有用的信息是人工智能面临的一个主要挑战。作为一种有效的信息过滤和数据摘要手段,子集选择方法通过从大规模数据中选取一个最具信息量的子集来代表整个数据集以减小需要处理的数据规模。此外,子集选择方法也用于改进相关领域中的模型以提高其泛化性能。本文主要研究基于组稀疏的子集选择方法在多核学习和多任务学习中的应用,其中在多核学习中分别利用具有代表性的核来减少不同相似性度量和不同数据源信息的冗余,而在多任务学习中则利用具有代表性的任务来充分发掘任务的潜在聚类结构。首先,本文提出了一种有效的多核聚类方法,其通过选择具有代表性的核函数来增强基础核之间的多样性。具体来说,我们首先设计一种策略从预先指定的核函数中选择一个具有代表性的子集,然后将这种代表性核选择策略合并到多核聚类的目标函数中,最后提出一种交替优化方法来优化聚类成员和核函数的权重。特别地,我们设计了一种定制的优化方法,通过交替方向乘子法来减少优化核权重的时间复杂度。基准数据集和实际数据集上的实验结果验证了所提出的方法的有效性。与现有方法相比,所提方法的优势表明由代表性核选择诱导的正则化可以有效改善组合核函数的质量。接着,基于非负矩阵分解,本文在多核学习框架下提出了一种新颖的数据融合方法来整合来自不同数据源的表示信息以得到高质量的数据表示。不同于直接以凸方式组合多个不同数据源的信息对应的核矩阵,我们引入正则化项来表征这些成对核矩阵之间的相似性以减少不同数据源的信息中存在的冗余。值得注意的是,得到的目标函数可以被视为代表性核选择的变体。接着,一种基于交替方向乘子法的优化方法被设计用于目标函数的求解。我们通过人脸识别任务来评估所提方法,其在三个数据集上的实验结果证明了多样性数据融合的优势。最后,基于假设――多任务学习中每个任务可以通过一些具有代表性的任务的线性组合来表示,本文通过选择具有代表性的任务为聚类多任务学习提供了一种鲁棒的任务分组方法。具体而言,我们通过选择与其它任务共享最多信息的代表性任务来发掘任务的潜在聚类结构。基于共享的代表性任务,相关任务被划分为不同的组,使得组内任务之间可以在一定程度上共享信息。此外,鲁棒的损失函数用于度量每个任务与其代表性任务线性组合得到的表示之间的误差,这可以有效减小异常任务的影响。人工和实际数据集上的实验结果表明所提出的方法优于许多现有的多任务学习方法。"
991,基于超限学习机的无设备定位方法研究,"无设备定位(Device-Free Localization,DFL)是一种目标无需佩戴任何电子设备的无线定位技术,该技术在老年人照护、紧急救援和入侵检测等领域都有着巨大的潜在应用价值。DFL技术可以根据目标对监测区域内无线信号的影响而实现对目标位置的估计。实际应用中,无线射频信号在复杂环境中传播往往会受到多重因素的干扰,如环境时变、非视距、多路径信号传播等,导致所采集到的数据通常包含大量的噪声,严重影响了定位精度。基于机理模型的DFL虽然可以有效解释信号的传播机理,并且能够取得较为理想的定位效果,但是其对环境的变化十分敏感,鲁棒性相对较差。因此,在噪声环境下,如何构建鲁棒性强的DFL模型十分必要。本文基于超限学习机(Extreme Learning Machine,ELM)理论构建了快速、高效、准确且鲁棒性强的DFL方法。本文首先研究了未考虑噪声分布对建模的影响、假设噪声服从高斯分布和噪声服从任意分布情况下的实现对目标位置准确估计的机器学习方法:接着实现了大规模复杂区域的DFL;最后基于ELM和深度学习理论,不仅实现了对链路特征的自动、高效提取,还将DFL转化为概率问题,提升了定位精度。本文的主要研究工作及创新性成果如下:(1)针对DFL建模特征单一,不足以建立精确模型的问题,提出了链路参数化几何表示与特征提取方法,扩展了可用于建模的特征种类,并利用扩展后的特征建立了基于ELM的DFL模型,该模型鲁棒性较强,且能够获得较为理想的定位精度。(2)无线射频信号在传播的过程中,由于不确定性因素的影响,会导致其产生大量的噪声干扰。因此,提出了多层残差补偿机制,构建了残差补偿超限学习机(Residual Compensation ELM,RC-ELM)方法。该方法利用多个残差补偿层对建模误差进行重新建模,实现了对模型整体性能的修正,从而得到鲁棒性更强、泛化能力更好的DFL模型。(3)无线射频信号中的噪声十分复杂,可能服从高斯、拉普拉斯或者混合分布,因此传统机器学习方法难以取得较为理想的效果。针对该问题,基于混合高斯方法提出了鲁棒超限学习机(Robust ELM,R-ELM)方法,该方法可以实现对任意连续噪声分布的逼近,实现了在随机干扰下的快速、准确DFL。(4)现有DFL方法大多只适用于较小规模区域,因此局限性较大。为了扩大DFL技术的应用范围,进一步提升其实用性,基于ELM理论和K-means聚类提出了可用于大规模复杂区域DFL的分层递阶方法。该方法首先利用K-means聚类根据整个区域内数据的分布特征将其划分为多个面积相对较小的子区域;然后为每个子区域建立了一个相应的DFL模型,从而将其分而治之;另外,考虑到大规模复杂区域所采集到的数据通常包含的噪声较大,基于RC-ELM提出了适用于非高斯噪声的扩展RC-ELM(Extended RC-ELM,ERC-ELM)。相比于RC-ELM,ERC-ELM摒弃了在深度方面的延伸,采取了在宽度方面的拓展,使得该算法更加高效,且在处理非高斯噪声时鲁棒性更强。(5)由多个无线节点所构成的无线传感网络中存在着大量无用、冗余链路,浅层机器学习方法有时无法很好地提取和学习这些链路所提供的有用信息,该方法所依赖的人工特征提取方式不仅十分耗费时间,而且还仅能适用于特定的场景。因此,本文结合深度学习理论提出了多层概率ELM(Multilayer Probability ELM,MP-ELM),该方法不仅实现了对链路特征的自动提取,而且还将DFL转化为概率问题,从而能减小了建模过程中的误差累积对定位精度的影响,进一步提升了定位精度。"
992,基于语义时空数据的人类移动性预测,"基于位置服务运行过程中积累了大量记录用户行为的语义时空数据,利用这些语义时空数据对人类移动性建模和预测在很多应用中具有重要价值。人类移动性建模问题可以分为个体移动预测和群体移动建模,个体移动预测是通过研究用户个体行为规律,预测未来的活动和位置,可以为兴趣点推荐、出行规划和精准广告等应用提供帮助,群体移动建模是在一定地理维度上建模人类群体的流动和集散,在交通管理和智慧城市等场景中有着重要作用。相比传统的时空数据,语义时空数据中包含用户的活动信息和地理位置的语义信息,为个体移动预测和群体移动建模带来了新的机遇,同时语义时空数据特有的稀疏性也为相关研究问题带来了新的挑战。在调研和分析了相关研究之后,我们在基于语义时空数据的个体和群体移动建模领域开展了若干研究工作。首先本文研究了如何利用语义时空数据中的活动信息来提升个体位置预测能力的问题。考虑到用户的活动目的影响位置选择,很多研究者将位置预测问题分成两个子问题,个体活动预测和给定活动目的的位置预测。然而现有研究提出的方法无法有效地整合个体行为的序列规律和时间特征,同时在建模给定活动目的下个体位置偏好时忽略了时间情景的影响。我们设计了一个两阶段个体移动预测方法,首先在第一阶段提出了情景感知模型堆叠方法,集成序列模型和时间特征模型来预测个体活动,然后在第二阶段为了应对语义数据的稀疏性,用贝叶斯方法预测个体在给定活动目的下的位置选择概率。基于公开的签到数据集,我们通过大量的实验验证了本章提出的两阶段方法优于现有位置预测方法。其次本文研究了如何建模个体活动和位置间的相互影响,并且利用这种相互影响来进一步提升个体活动和位置预测准确率。我们提出了个体“活动-位置主题”来刻画个体活动和位置偏好的内在联系,并基于此设计了多任务深度循环神经网络来建模“活动-位置主题”,同时预测个体活动和位置。为了应对语义数据稀疏带来的序列关系不稳定,并且整合个体行为的时间特征,我们设计了情景感知循环单元;为了利用位置的地理空间特征和活动类型特征,我们设计了基于图嵌人的表示学习方法来学习位置和活动的低维嵌入向量。通过大量实验,我们对比了该模型和现有工作的活动和位置预测能力,并且通过一个案例研究展示了“活动-位置”主题刻画个体活动和位置内在联系的合理性。最后本文研究了基于语义时空数据的兴趣点人流量建模问题。预测兴趣点人流量对兴趣点的访客和经营者都有重要意义,也能为基于位置服务提供搜索和推荐服务提供帮助。研究人员尝试使用非参数时序模型和参数化的机器学习模型来建模兴趣点人流量的时间规律。我们收集了8000个兴趣点的人流量数据,对这些数据分析发现兴趣点人流量除了呈现时间规律,还会出现意外波动情况。基于此我们提出一个常规-意外访客混合模型。在该模型中,采用非参数估计的方式来提取兴趣点访客的时间规律特征,设计了图卷积神经网络来预测区域人流量,并用区域-活动转移模式矩阵建模人群活动目的分布,然后将时间规律特征、区域人流量和活动目的分布整合在一起用回归模型预测兴趣点人流量。通过大量在Foursquare兴趣点人流量数据集上的实验验证,证明了我们提出方法的有效性和优越性。"
993,机器学习在量子物理学中的应用,"随着机器学习技术在图像识别,决策和逻辑推断等领域的高效应用,机器学习的算法越来越受到物理学家的关注。机器学习算法擅长的是找到数据之间的内在规律,而物理学中的问题通常是具备逻辑性和规律性的,因此机器学习算法很适合被用来解决物理学中的问题。在经典物理学领域,机器学习可以学习牛顿力学里的规律。在量子物理学领域,机器学习可以求解薛定谔方程的基态波函数,找到相变的位置,表示量子多体系统的态,找到多体系统里的序参量等等。机器学习算法分为监督性学习,非监督性学习和强化学习。监督性学习是先利用样本训练机器,比如训练一个神经网络,然后利用训练好的神经网络做预测,做预测时输入的样本可能不在训练时使用的样本内。非监督性学习不需要训练样本,而是针对一个优化目标对输入的数据直接优化,最终可以将数据按照类别区分开来。强化学习是通过反复尝试训练一个反馈机制,使得获得的奖励最大,这种算法适合做仪器的控制。虽然机器学习算法的产生不是为了解决物理学问题而设计,但理解并合理得使用机器学习算法,可以帮助物理学家用新的角度理解物理学同时发现新的物理学。同时随着量子计算的发展,人们开始尝试在量子计算机上运行机器学习算法,并且获得了比较高的加速比。因此,机器学习技术会帮助物理学家解决物理学中的问题,同时物理学能够推动机器学习向更高效的途径发展。在未来的时间里,机器学习和物理学会相互促进,相辅相成。本论文讲述了我们利用机器学习解决量子物理学中的问题的实例,主要包括三部分:第一部分着重讲述了如何利用深度的神经网络生成玻色―爱因斯坦凝聚体(BEC)的基态波函数。在BEC中,所有粒子具有相同的相位,BEC的基态波函数是个空间上的概率分布。这个基态波函数是通过求解Gross-Pitaevskii方程(GP方程)得到的,我们可以利用神经网络建立一个GP方程到基态波函数的映射。我们测试了两种情况:1、同样的势场和不同的排斥系数;2、同样的排斥系数和不同的势场。利用深度神经网络做监督性学习,训练后的神经网络可以高精度地生成玻色―爱因斯坦凝聚体的基态波函数。当输入的高斯随机势场的相干长度小到σD=0.39时,深度神经网络依然可以高精度地生成基态波函数。同时,我们输入不同类型的势场依然得到了高精度的波函数输出,说明利用高斯随机势场训练的神经网络学习到了求解GP方程的方法。第二部分着重讲述了如何设计一个合理的卷积神经网络作为变分波函数来有效地求解二维量子自旋多体系统。当前求解量子多体系统依赖于张量网络,而张量网络的计算复杂度比较高。利用神经网络替代张量网络似乎是有可能的,因此,我们需要测试神经网络对非平凡的多体哈密顿的基态的表述能力,比如阻挫比较强的J1-J2模型。我们搭建了一个卷积神经网络可以用来作为二维量子自旋系统的变分波函数,利用目前主流的神经网络构成元素:卷积层,最大值池化层和反卷积层。为了尽可能得回避局域极小值,我们使用副本交换的动力学方法优化。在优化时,我们首先设定一系列不同的温度,然后用随机值初始化神经网络里的每个参数,最终会得到不用温度的解,零温下的解就是我们认为的基态解。经过计算表明,我们设计的卷积神经网络在基态能量的精度上能够优于已有的String-Bond-State。因此使用卷积神经网络加速解决量子多体系统成为了可能。第三部分着重讲述了量子版本的鸡尾酒会问题(CPP)。CPP是一个古老但很重要的问题,即利用多个探测器的探测信号,把混合在一起的信号源提取出来。对于经典的CPP,可以用独立成分分析算法(ICA)求解。我们考虑了一个量子版的CPP,即信号源发出的是纯态,各个纯态是互相不正交的。这些纯态的希尔伯特空间大于探测器能够响应的希尔伯特空间,因此探测器探测到的是混态。基于经典的ICA算法,我们重新设计了损失函数,通过只测量混态的密度矩阵,能够还原出纯态的密度矩阵。经过数值计算验证,利用牛顿法还原得到的纯态的保真度在0.99以上。同时,我们把损失函数转化成一个spin-1/2的多体自旋耦合哈密顿,这个哈密顿的基态即是损失函数达到极小值的解。通过模拟退火的方法,纯态的还原保真度依然在0.99以上。"
994,基于可编程网卡的高性能数据中心系统,"数据中心是支持当今世界各种互联网服务的基础设施,面临硬件和应用两方面的挑战。硬件方面,通用处理器的性能提升逐渐放缓;应用方面,大数据与机器学习对算力的需求与日俱增。不同于容易并行的Web服务,大数据与机器学习需要各计算节点间更多的通信,这推动了数据中心网络性能的快速提高,也对共享数据存储的性能提出了更高的要求。然而,数据中心的网络和存储基础设施主要使用通用处理器上的软件处理,其性能落后于快速增长的网络、存储、定制化计算硬件性能,日益成为系统的瓶颈。与此同时,在云化的数据中心中,灵活性也是一项重要需求。为了同时提供高性能和灵活性,近年来,可编程网卡在数据中心被广泛部署,利用现场可编程门阵列(FPGA)等定制化硬件加速虚拟网络。本文旨在探索基于可编程网卡的高性能数据中心系统。可编程网卡在加速虚拟网络之外,还可以加速网络功能、数据结构、操作系统等。为此,本文用FPGA可编程网卡实现云计算数据中心计算、网络、内存存储节点的全栈加速。首先,本文提出用可编程网卡加速云计算中的虚拟网络功能,设计和实现了首个在商用服务器中用FPGA加速的高灵活性、高性能网络功能处理平台ClickNP。为了简化FPGA编程,本文设计了类C的ClickNP语言和模块化的编程模型,并开发了一系列优化技术,以充分利用FPGA的海量并行性;实现了ClickNP开发工具链,可以与多种商用高层次综合工具集成;基于ClickNP设计和实现了200多个网络元件,并用这些元件组建起多种网络功能。相比基于CPU的软件网络功能,ClickNP的吞吐量提高了10倍,延迟降低到1/10。其次,本文提出用可编程网卡加速远程数据结构访问。本文基于ClickNP编程框架,设计实现了一个高性能内存键值存储系统KV-Direct,在服务器端绕过CPU,用可编程网卡通过PCIe直接访问远程主机内存中的数据结构。通过把单边RDMA的内存操作语义扩展到键值操作语义,KV-Direct解决了单边RDMA操作数据结构时通信和同步开销高的问题。利用FPGA可重配置的特性,KV-Direct允许用户实现更复杂的数据结构。面对网卡与主机内存之间PCIe带宽较低、延迟较高的性能挑战,通过哈希表、内存分配器、乱序执行引擎、负载均衡和缓存、向量操作等一系列性能优化,KV-Direct实现了 10倍于CPU的能耗效率和微秒级的延迟,是首个单机性能达到10亿次每秒的通用键值存储系统。最后,本文提出用可编程网卡和用户态运行库相结合的方法为应用程序提供套接字通信原语,从而绕过操作系统内核。本文设计和实现了一个用户态套接字系统SocksDirect,与现有应用程序完全兼容,能实现接近硬件极限的吞吐量和延迟,多核性能具有可扩放性,并在高并发负载下保持高性能。主机内和主机间的通信分别使用共享内存和RDMA实现。为了支持高并发连接数,本文基于KV-Direct实现了一个RDMA可编程网卡。通过消除线程间同步、缓冲区管理、大数据拷贝、进程唤醒等一系列开销,SocksDirect相比Linux提升了7至20倍吞吐量,降低延迟到1/17至1/35,并将Web服务器的HTTP延迟降低到1/5.5。"
995,强热带气旋及大规模断电影响下的孕妇健康风险及脆弱性研究,"背景和目的在气候变化背景下,热带气旋活动发生频率和强度增强。强热带气旋(台风或飓风)严重威胁着人群健康。孕妇是极端天气事件的重要脆弱群体。然而,目前有关飓风与孕期健康的研究报道很少,尤其是飓风的长期健康影响研究更少。另外,近年来与飓风相关的大规模断电更为频繁,然而,暂未发现有关大规模断电与孕期健康关系的研究报道。开展飓风健康脆弱性评估有利于识别地区风险或优化资源配置,然而,目前飓风脆弱性评估存在一定的局限性。近年来,机器学习技术应用越来越广泛,其在指标筛选和模型预测等方面具一定优势。基于此,本文拟研究强热带气旋及大规模断电影响下孕妇的健康风险,并应用机器学习方法开展飓风的健康脆弱性研究。研究方法本课题以2012年“桑迪”超级飓风事件为案例,以美国纽约州为研究点。我们采用时间序列分析方法和反事实推理方法研究“桑迪”飓风影响下,纽约州8个受飓风严重影响县的孕妇的健康风险,分析飓风对孕妇短期健康风险和长期健康影响,并按疾病、年龄、社会经济状态分层分析不同孕妇群体的风险。研究还采用混合线性模型分析方法研究大规模断电背景下纽约州8个受影响县妊娠合并症就诊量与断电覆盖率和断电持续时间之间的关系。此外,本研究对传统脆弱性评估方法加以改进,借助随机森林模型筛选影响飓风健康脆弱性的关键因素,基于各因素与健康风险之间的关系建立模型预测这8个县每个社区孕妇对飓风的健康脆弱性。结果纽约州8个县在飓风期的总妊娠合并症发生风险增加了6.3%(95%CI:2.2%,10.5%),并且该飓风影响可持续几个月甚至2年。不同疾病和社会群体的风险不一样,例如早产和妊娠合并糖尿病,低社会经济状态的孕妇群体发生风险较高。我们发现飓风之后的大规模断电可能影响孕妇健康,断电覆盖率每升高10%和断电持续时间每升高10个小时对应妊娠合并症增加的风险分别为2.4%(95%CI:0.8%,4.1%)和 11.2%(95%CI:2.9%，20.2%)。主要受断电影响的妊娠合并症包括流产和早产等,高龄和低社会经济状态的孕妇风险更高。脆弱性评估研究中,我们发现洪涝暴露较高、社会经济状况较差的地区对飓风的健康脆弱性较高。基于随机森林的地区健康脆弱性预测精度较高,AUC值为0.81。结论强热带气旋(诸如“桑迪”飓风)对孕妇妊娠健康不仅具有短期的作用还有长期的影响;飓风相关断电可导致妊娠健康风险增高;早产疾病和低社会经济状态群体对飓风和断电的健康风险较高;基于机器学习方法的脆弱性评估具有一定实用性,可为健康脆弱性评估提供一种新的思路。"
996,基于全国卒中筛查数据的卒中风险预测及经济负担模拟研究,"近年来,随着我国经济的发展、居民生活方式的改变、人口老龄化等变化,我国慢性病问题逐渐凸显。在慢性病的疾病谱中,卒中具有发病率高、患病率高、复发率高、致残率高、死亡率高的特点,已成为我国居民第一位死亡原因。然而,从世界发达国家的经验看,卒中是可防可控的。通过合理控制卒中的危险因素,实现关口前移,可以有效降低卒中给家庭、社会带来的经济负担。为了遏制卒中在我国的高发态势,2009年5月,我国卫生部计划在全国实施“脑卒中高危人群筛查和干预项目”,对全国范围内40岁以上居民进行卒中危险因素筛查及卒中干预。卒中高危人群筛查和干预项目分为初筛和复筛两步,在初筛中,卒中危险因素包括高血压、糖尿病、血脂异常、房颤、吸烟、缺乏运动、明显超重或肥胖、卒中家族史,若被筛查者患有三项或三项以上卒中风险因素,或有卒中史或短暂性脑缺血发作史,则被判定为卒中“高危”人群,需进入复筛进行诸如影像等检查,并对发现有卒中前兆的被筛查者采取相应的治疗手段;若被筛查者患有两项卒中风险因素,则被判定为卒中“中危”人群。针对仅有风险因素的“高危”和“中危”人群给与相应的预防性建议,并通过随访对危险因素进行干预和指导。与卒中带来的巨大经济负担相比,卒中筛查项目干预效果好,经济性高。截止目前,项目已累计收集了700余万条卒中筛查数据。但是,现阶段的卒中筛查的风险等级判断标准和卒中防控策略均是由专家根据经验给出,且针对卒中经济负担模拟的研究不足。本文利用全国卒中筛查横断面数据和队列数据,改进了卒中筛查项目中使用的卒中风险评估模型,构建模型预测了不同特征人群的卒中风险,模拟了卒中可能造成的经济负担并实现了卒中经济负担模拟系统。通过对卒中筛查数据的研究和利用,能够进一步提高卒中筛查项目的筛查干预效率,为制订更加及时有效的卒中防控策略提供有力的科学依据。本文的主要研究结果如下:1.探索了卒中筛查项目中卒中风险判定方法的合理性。基于2012年全国卒中筛查横断面数据和2013-2017年全国卒中筛查队列数据,利用贝叶斯网络研究了卒中与其风险因素的关系。从总体上来说,同时患有三个卒中危险因素的人群卒中发病率及卒中患病可能性高于同时患有两个卒中风险因素的人群,同时患有两个卒中风险因素的人群的卒中发病率及卒中患病可能性高于仅有一个卒中风险因素的人群。但是,某些同时患有两个风险因素情况下的卒中发病率及卒中患病可能性可能高于某些患有三种风险因素组合的情况,单一风险因素导致的卒中发生率及卒中患病可能性也可能高于两种甚至三种风险因素组合的情况。卒中筛查项目可以考虑将患有风险因素情况下卒中发病率与没有任何风险因素下卒中发病率之比作为一个可变的阈值,通过调整阈值确定卒中风险判定指标,实现筛查项目经济性与筛查效率之间的平衡。2.为了解决在初筛中部分风险因素为“未知”时无法判断卒中风险等级的问题,构建了卒中危险等级分类模型。基于2017年全国卒中筛查横断面数据,分别选择机器学习算法中的逻辑回归算法、朴素贝叶斯算法、贝叶斯网络算法、决策树算法、神经网络算法、随机森林算法、基于决策树的Bagging算法、基于决策树的Boosting算法、投票算法进行卒中风险等级分类。在测试中,随机有放回地从实验数据集中抽取2,000个测试样本,计算模型准确率、召回率、F1-分数和AUC的平均值及95%CI。除了从完整的实验数据集中抽取样本外,还从无法使用现行的筛查方法判定危险等级的数据中抽取样本对模型进行测试。实验结果表明,使用C4.5决策树作为子分类器的Boosting算法的召回率最高(分别为0.9992和0.9582),随机森林模型的准确率最高(分别为0.9733和0.5134)。卒中筛查项目可以结合实际情况选择模型,在保证卒中筛查项目经济性的同时,提高对卒中高危人群干预的效率。3.研究了中年慢性病患者10年内的卒中风险。利用我国2013-2017年卒中筛查队列数据,基于马尔可夫模型对我国40-59岁不同起始状态的人群(高血压、糖尿病、血脂异常)10年内发展为卒中的可能性进行了研究。从实验结果来看,高血压患者发生卒中的概率高于糖尿病患者和血脂异常患者,考虑到我国高血压患者的基数较大,因此控制高血压对卒中的防控有着重要的作用。同时,针对糖尿病和血脂异常患者,应该分性别采取相应的干预措施。对卒中发病情况的模拟结果可以为国家层面上的卒中防控提供决策依据,指导卒中防控重点人群。4.基于均衡模型对我国卒中经济负担进行了模拟。本文研究的卒中经济负担包括对卒中发病率、患病率、死亡率、住院费用、伤残调整生命年以及卒中带来的GDP损失。结合Leslie模型对我国人口的预测结果,构建了基于均衡模型的卒中经济负担模型,可以对不同程度的卒中发病率、患病率和死亡率下所产生的经济负担进行模拟。以此为基础实现了卒中经济负担模拟系统,能够以图表的形式直观的展示我国卒中经济负担的变化,为建立我国卒中预警图,制定全国层面上的预警机制提供研究工具和参考依据。本研究完成了对卒中风险因素及卒中筛查风险等级判定方法的研究,构建了慢性病人群卒中风险预测模型及卒中经济负担模拟模型,实现了卒中经济负担模拟系统。为我国卒中高危人群筛查和干预项目的高效推进、为制定更加及时有效的卒中防控策略提供了有力的科学依据。"
997,深度学习在乳腺癌磁共振诊断的探索性研究,"第一章深度学习对乳腺癌磁共振图像的分类及定位目的:探讨在动态增强磁共振图像中,三维深度卷积神经网络(CNN)以弱监督的方式对乳腺癌的诊断和定位的价值。材料和方法:乳腺癌回顾性研究是在机构伦理审查委员会批准后进行的。该研究共纳入1537例乳腺动态增强MRI扫描和非脂肪抑制的平扫图像(平均年龄47.5岁±11.8),包括女性1529人,男性8人,其中14个女性双侧都有孤立性病灶,共1551个病灶,包括恶性肿瘤1033个病灶,良性病变518个病灶;时间跨度从2013年3月到2017年12月。所有病例均有穿刺或手术的病理结果证实,影像学结果由具有10年以上经验的放射科医生团队给出具体的BI-RADS分类。先把乳腺MRI图像的数据做预处理,进行乳腺分割,用MRI的2D切片应用Frangi的方法来获得乳房-空气边界,胸肌边界以及乳腺和脂肪之间的边界。再进行一系列形态学处理,包括滤波切片的阈值处理,连通分量分析和空洞填充,最终获得每个2D切片中乳房区域的二元掩模。然后,我们堆叠所有切片的2D蒙板,并获得每个MRI体积数据的3D乳房分割掩模。接下来,我们使用3D高斯滤波器来平滑乳房蒙板。使用3D二元掩模,我们获得了覆盖整个乳房区域的边界框。采用弱监督学习的方式进行乳房中病灶的定位,考虑到在网络的早期层中提取的特征具有更高的分辨率,我们建议从早期层而不是最后一个预测层推断病变的位置。为了有效捕获MRI图像的体积空间信息,我们采用3D CNN作为深度学习模型的基础设施。使用3D DenseNet,即我们网络中的层密集连接,提倡提取特征的重复使用,并有助于提高模型的性能。在医学影像图像的监督下,对CNN进行训练,实现对病灶的良恶性分类,鉴别癌和非癌,并在诊断恶性的基础上,实现对癌肿的定位。整个数据集被随机分为训练集(1073例)、验证集(157例)和测试集(307例)。计算模型诊断乳腺癌的准确性、敏感性、特异性和受试者工作特征曲线下面积(AUC)。结果:乳腺癌病灶的定位在视觉上是令人满意的。CNN在保持相当高的癌症检出率的同时提高了特异性。307例验证集中,有206例病理诊断乳腺癌,深度学习卷积神经网络187例判读正确,19例假阴性;101例病理证实非癌,CNN有70例判读正确,31例假阳性。CNN诊断乳腺癌的准确率为83.7%,敏感性为90.8%,特异性为69.3%。BI-RADS评估诊断乳腺癌的准确性为85.7%,敏感性为98.5%,特异性为59.4%。MRI是用于筛选乳腺癌最高灵敏度的成像模态,比较显示CNN模型与经验丰富的放射科医师在诊断准确性方面相当,特异性优于人工判读,敏感性低于BI-RADS评估。结论:三维卷积神经网络(3D CNN)深度学习对乳腺癌诊断具有较高的价值;且弱监督学习方法有望在仅使用图像级标签的容积放射学图像中定位病灶。第二章基于机器学习的乳腺癌磁共振预测的可视化分析目的:设计一套基于机器学习方法的乳腺癌磁共振预测模型,并以可视化的方式显示。材料与方法:选取2013.3-2017.12期间做过乳腺磁共振扫描,有完整病理结果的乳腺肿块型病变134例,扫描方案采用标准乳腺平扫及动态增强扫描,按照BI-RADS分类系统对乳腺的构成、BPE的程度、分布及病变的形态、边缘、内部强化进行详细描述,并测量病灶的ADC值、2min强化幅度、强化峰值及TIC类型等。采用SOM聚类分析方法对数据进行可视化分析。结果:134例肿块型病变,其中良性49例,恶性85例,年龄(48.24±12.35)岁,肿瘤直径(2.34±1.40)cm,最大直径8.8 cm,最小直径0.5 cm,89人处于绝经前状态,45人绝经。根据乳腺癌的临床特点,提出了五种临床候选特征和12种病灶影像特征预测乳腺癌的恶性程度。通过统计分析和数据挖掘,边缘清晰度、ADC值、肿瘤大小、年龄、最大强化峰值、内部强化情况6个特征被证明是恶性肿瘤的显著预测因子。SOM聚类分析方法将17维数据映射到2维平面,通过U-Matrix进行可视化分析,显示良性和恶性样本在二维平面上有较好的划分,良性样本点(绿色)的多分布在左上角,恶性的多分布在右下角。基于决策树模型诊断乳腺恶性肿瘤(AUC:0.989)的准确性相较于传统的BI-RADS评估分类提高了7%。结论:基于6种影像特征的决策树模型,表现出优于BI-RADS评估更好的良恶性鉴别能力。第三章磁共振波谱成像预测乳腺癌新辅助化疗非向心性退缩模式的疗效目的:利用磁共振波谱成像预测乳腺癌新辅助化疗非向心性退缩模式的疗效。材料与方法:收集我院2013.3-2014.12间行乳腺MRI检查患者1300人次,选择首次确诊乳腺癌,并在我院进行新辅助治疗,在第2、4、6周期接受乳腺MRI疗效评估的患者,剔除化疗后无可测量病灶、前后定位不一致、基线不稳者,共114人次42例患者,其中肿瘤退缩模式为非向心性的共计25例患者。所有患者的联合化疗方案均为蒽环联合紫衫作为一线治疗。所有患者在新辅助治疗6~8周期后行手术治疗,术后病理作为金标准。在新辅助治疗第2、4、6周期后分别行常规乳腺磁共振平扫加动态增强扫描及波谱成像,在后处理工作站测量病灶最大径,并记录胆碱(tCho)峰值下面积(I*)。按照实体瘤评价标准(RECIST)计算缓解组和非缓解组在基线扫描(baseline)、第一次复查(the first follow-up)即第2周期完成后、第二次复查(the second follow-up)即第4周期完成后的胆碱含量变化差异。统计学分析采用非参数检验,以P<0.05有统计学意义。比较胆碱变化率和肿瘤大小变化率对预测肿瘤缓解的能力,并绘制ROC曲线,计算AUC值。结果:第一次复查有6例测不到胆碱波,14例在第二次复查测不到胆碱波。按照Miller&Payne system病理分类系统,16例肿瘤缓解,9例非缓解。在第二次复查中,缓解组和非缓解组的胆碱量有显著差异(P=0.027),肿瘤大小的变化没有差异(P>0.05)。基线和两次复查的胆碱量和肿瘤大小变化率的ROC曲线比较,第二次复查胆碱含量的变化率AUC值最大(0.747),预测肿瘤缓解的敏感性为93.75%,阳性预测值为78.9%。结论:乳腺癌在新辅助化疗后肿瘤非向心性退缩模式中,肿瘤大小很难反映肿瘤是否缓解,胆碱含量减少可能是一个预测因子。"
998,针对若干数据挖掘问题的量子算法研究,"作为计算机科学和统计学的交叉子领域,数据挖掘旨在从大量数据中挖掘出其中隐藏的重要信息,是知识发现的关键步骤。此外,数据挖掘可用于挖掘密码系统中明密文隐藏的模式以分析其安全性,因此也是密码分析的一个重要工具。然而,随着信息技术的高速发展,全球数据总量每年指数增长,这使得经典数据挖掘算法未来处理大数据时将面临计算性能的巨大挑战。量子计算利用量子力学基本原理(如量子叠加和量子纠缠)实现计算任务,在解决某些特定问题上相比经典计算具有显著的速度优势。例如,Shor量子算法能够快速分解大数因子,相对经典算法具有指数加速,对被广泛应用的RSA密码系统安全构成严重威胁。近年来,量子计算已被应用到数据挖掘领域,且解决多种数据挖掘问题的高效量子算法已被提出。然而,量子数据挖掘算法研究仍处于初始阶段,许多数据挖掘问题尚无高效量子算法解决。本文对此展开进一步研究,针对若干重要的数据挖掘问题,提出相比经典算法具有显著加速的量子算法。这些量子数据挖掘算法也将为密码分析量子算法研究提供重要参考。具体来说,本文研究包括以下四个方面。1、针对关联规则挖掘的核心任务――从候选项集中找出频繁项集,提出一个量子关联规则挖掘算法。具体来说,对于Mc(k)个候选k项集中存在Mf(k)个频繁k项集(Mf(k)≤Mc(l))的情况,所提算法通过并行幅度估计和幅度放大能够有效地挖掘出这些频繁k项集并估计它们的支持度。该算法的复杂度为O(k(?),其中ε为支持度估计误差。与复杂度为O(kMk)/ε2)的经典算法相比,所提量子算法当Mf(k)<"
999,基于深度学习的城市尺度无线流量预测,"5G/6G无线通信系统正在加速拥抱AI,不断朝着智能化的方向发展。无线业务流量精准预测是通信系统迈向智能化,实现自组织管理、自优化配置的必经之路。无线业务流量预测不仅能够服务于动态网络拥塞控制,提升管理效率,还能辅助基站实现业务感知的动态覆盖,增强网络能效。然而,由于人的移动行为的复杂性、业务请求的随机性以及多源跨域数据对流量产生的空间约束性,无线业务流量的精准预测面临着诸多挑战。特别是当进行城市尺度无线业务流量预测时,涉及众多小区流量间的复杂时空依赖关系,需要精准捕捉。现有的解决方案还有较多不足,存在预测不准确、不能联合跨域数据分析以及预测趋于均值等问题,无法满足未来智能通信系统中高精度流量感知和预测的需求。因此,对无线业务流量的时空特性进行深度理解并联合跨域数据来提升城市尺度无线业务流量预测的准确性是本文研究的关键问题。本文将详细阐述如何借助深度学习技术实现无线业务流量的精准预测。主要聚焦在如何用卷积网络对无线业务流量的时空依赖性进行捕捉、如何借助跨域大数据和迁移学习对预测性能进行提升以及如何设计高效的预测框架解决城市尺度无线流量预测趋于均值的问题。具体创新点总结如下:1)为同时捕捉无线业务流量数据在时间和空间的复杂依赖性关系,提出基于密集连接卷积神经网络的城市尺度无线业务流量预测框架STDenseNet。所提框架采用卷积操作对时空依赖性进行建模,利用两个深度网络分别对时间依赖的近邻性和周期性学习,并基于参数化矩阵的融合方案对两者的重要性进行差异化表示。为加强不同层之间的特征传播和复用,STDenseNet采用密集连接的模式进行特征学习。在实际数据上的仿真结果表明,STDenseNet能够高效地同时捕捉无线业务流量数据的时空依赖性,显著降低预测误差。此外,相比于特征同权重相加,所提参数化矩阵融合方案能够进一步提升预测性能。2)无线业务流量除了受时间和空间因素影响之外,还跟小区范围内包含的跨域数据强相关。基站的数量、社交活动程度、城市的兴趣点分布等都会对流量产生形成空间约束。为同时捕捉时空依赖性和多源数据空间依赖性,提出基于跨域数据和迁移学习的无线业务流量预测框架STCNet。所提框架采用卷积长短期记忆网络对时空依赖性以及流量之间的序列性进行同时捕捉,采用卷积网络对跨域数据进行学习,并通过特征融合的方式将多种数据进行统一表示。为对不同城市功能区的流量模式进行刻画,提出一种基于谱聚类的城市尺度无线业务流量的聚类算法,并采用逐次类间迁移学习的思想对学到的流量模式复用。在此基础上,为进一步利用不同业务流量之间的相似性,提出基于STCNet模型的深度迁移学习策略。实验表明,STCNet在多种无线业务数据上的预测值跟真实值误差较小。特别的,采用迁移学习的策略能够大幅提升预测性能(4%-13%),给无线业务流量预测的性能提升开辟了新维度。3)城市尺度无线业务流量的分布不严格符合高斯特性,而是多模态分布。采用lp损失进行优化时,所得模型的预测趋于多种模态的均值。针对这一问题,提出基于对抗生成网络的城市尺度无线业务流量预测方法TPGAN。该框架的生成器网络部分利用STCNet架构进行时空依赖性与跨域数据的特征学习,在传统lp损失的前提下,引入对抗损失来避免均值预测现象。在实际数据上的实验结果表明,引入对抗损失能够提升流量预测的性能,可有效避免预测均值现象。相比于不考虑对抗损失,所得结果跟真实数据分布更接近。此外,探讨了对抗损失所占比重对预测结果的影响,给出了取值规则,能够为后续工作开展提供指导意义。综上所述,针对城市尺度无线业务流量预测现有方法的不足,本文在无线业务流量时空依赖性的同时捕捉、多源跨域数据的特征学习、多模态分布下的高效预测等方面做了深入研究和改进,所提方案能够大幅提升预测准确性,提高预测值与真实值在分布上的相似性。"
1000,MOOC讨论区讨论深度评价模型研究,"在线讨论深度对学习者在线学习的质量和效果具有巨大的影响,然而目前对MOOC讨论区讨论深度还未有太多研究,尤其是MOOC讨论区讨论深度的评价研究。目前针对在线讨论的评价主要采用内容分析法和量表法,这些方法是在课程结束后进行人工抽样分析来预测全样本,不能全面、及时且自动地分析MOOC讨论区中的海量讨论帖。本研究采用大数据分析方法构建讨论深度评价模型,以此有效评估MOOC学习者的在线讨论深度,从而实现精准预测和及时干预。本研究以中国大学MOOC平台《现代教育技术》课程讨论区为研究对象,首先通过文献分析法假设影响MOOC讨论区在线讨论深度的关键要素,包括问题类型、知识类型、问题回应情况与持续时间、课程参与角色等;其次分析本课程讨论区在线讨论深度现状:本课程在线讨论深度明显处于浅度讨论和中度讨论阶段,学习者之间的交流不够深入;第三,利用卡方检验和皮尔逊相关系数法对各个影响因素的不同类型与讨论深度各个阶段之间的关系进行验证,统计结果表明:MOOC讨论区讨论深度与问题类型、回复数、提问者回应次数、教师参与性、问题持续时间、知识点类型均呈正相关且相关系数较大,这些因素较大程度上影响讨论区在线讨论深度。问题定义情况、知识点重要度与在线讨论深度呈现微弱的相关性,两者对讨论区在线讨论深度影响程度很小。本研究具体实施为:(1)通过特征变量预筛选实验,选取问题类型、知识点类型、问题持续时间与回复数、提问者主持情况、教师参与性六个特征变量,建立MOOC讨论区讨论深度评价模型的特征指标体系。(2)构建评价模型:将构建的特征集运用在逻辑斯蒂回归、决策树、线性支持向量机和随机森林四种分类模型上,并对建立的各评价模型进行调参、根据分类算法本身输出的特征重要性排序结果进而选取不同个数特征变量进行组合以训练各评价模型的最佳分类效果。(3)评价模型特征重要度分析:选取影响各评价模型性能最关键的几个特征进行分析。实验结果表明:(1)本文构建的特征集是各评价模型的最优特征集,在最优特征集上决策树模型和随机森林模型的性能表现比逻辑斯蒂回归、线性支持向量机分类模型更优越,决策树和随机森林模型的准确率、精度、召回率和F值均在80%以上。(2)各评价模型对六个特征变量的重要性排序结果基本一致,其中:问题类型、问题持续时间、问题回复数、问题主持情况是影响MOOC讨论区讨论深度最重要的四个特征变量。"
1001,语音与文本在情感识别中的比较研究,"情感在人类交流中起重要作用,因此在人机交互领域中情感识别具有重要研究意义,使得机器能够感知并识别情感具有重要意义。在情感识别研究中,研究者通过使用不同通道的信息,使用不同的特征,不同的分类器模型去识别情感,并取得不同的识别效果。根据我们日常的生活经验可以发现,语音声音信息和文本内容信息中都包含有丰富的情感信息,其中语音和文本是情感识别中最常用的两个通道。但是根据之前研究分析发现,语音与文本在情感识别中,对于指定的某类情感或某几类情感的识别具有不同的表现。本研究基于此,试图去分析语音与文本在情感识别中的不同表现。本研究的研究目标主要有以下两点:1)分别使用语音和文本进行情感识别,比较语音和文本在情感识别中的不同表现,分析语音和文本中各自在情感识别中对指定情感的倾向性。2)在特征水平上进行特征分析,进一步从根本上分析造成语音和文本在情感识别时的不同表现造成的原因,选择出两通道中各自包含的重要情感特征,为后续研究提供可以参考的特征信息。本研究实验分为两部分:1)语音与文本情感识别实验。分别使用语音和文本特征训练情感识别分类器模型,并通过使用混淆矩阵的方式对各类情感识别结果进行可视化。根据可视化结果比较分析语音和文本在各类情感识别的不同作用与表现。2)语音与文本情感特征分析实验。使用基于注意力机制的LSTM作为特征选择方式,根据注意力矩阵对特征进行选择。分别选取出重要的语音声学特征和重要的文本情感关键词,从根源上分析两通道中包含的情感信息,以及造成上一个实验中情感识别结果的原因。通过对实验结果进行分析发现,实验一从两个角度对语音与文本的情感识别结果进行了比较:1)在离散情感模型中,语音对愤怒和悲伤两类情感的识别表现更好,文本对中性和开心两类情感识别更好。2)在维度情感模型中,语音在激活度中情感识别效果更好,文本在效价度上的情感识别效果更好。在实验二中,通过特征分析再发现:1)根据注意力权重对语音声学特征进行排序发现,F0基频、F2带宽、MFCC等声学特征在情感识别中具有重要的作用。2)根据注意力权重对文本关键词特征进行排序发现,―些本身包含情感的词汇,或修饰情感的形容词,或在情感状态下表现出的感叹词和语气词在文本情感识别中具有重要作用。本研究的结论:语音和文本中确实包含有大量的情感信息,可以有效的进行情感识别。语音和文本中包含的情感信息具有的不同表现形式和作用,在情感识别时具有不同的倾向性。本研究的结论可以有效的解释为何将语音和文本信息融合后情感识别率为何会增加。此外,发现了重要的语音声学情感特征和文本关键词特征,对后续研究中的特征选择具有重要借鉴意义。本文的创新点如下:1)通过使用混淆矩阵对识别结果进行可视化分析,比较语音与文本在情感识别中的不同作用与表现。2)从不同角度对语音与文本识别的表现进行了比较,分别从离散情感模型,维度情感模型,对语音和文本情感识别的表现进行了详细的分析。3)将基于注意力机制的LSTM迁移作为特征选择方式。常见的注意力机制用以选择片段中的重要部分,本文将其引入作为特征选择方式。根据注意力矩阵对特征进行选择排序,并结合之前情感识别表现对特征选择结果进行了分析。"
1002,基于多模型的问答社区答案质量评价研究,"信息技术的快速发展为人们获取、共享知识提供了新的工具。具有代表性的问答社区在人们学习、生活、工作、娱乐等各个方面扮演着重要的角色,随着其信息量的指数级增长,如何有效的评价问答社区内的答案质量便成为了一项重要的工作。本文为了评价问答社区中用户生成的答案质量,提出了基于多种模型,深度挖掘问答社区内可用作答案质量评价的语义特征和非语义特征,通过机器学习分类方法实现了对答案质量的评价。主要包含以下内容:(1)基于主题相关性的答案质量评价针对问答社区的问题和答案文本具有的文本特征矩阵稀疏,上下文信息丢失,以及问题文本的长度和答案文本的长度严重不匹配这一问题和现状,本文提出了基于问题文本语义扩展的答案质量评价模型。首先,根据使用问题和正确答案构成的文本集,通过Word2Vec训练词向量,在词粒度上挖掘文本语义信息,对问题文本的主干词计算与其相关的词集,从而实现了对问题文本的语义扩展。其次,使用LDA主题挖掘模型,通过对问题和答案文本的主题推断,将文本表示成为主题向量,并使用JS距离计算了问题和答案文本的主题相关性。最后以问题和答案的主题相关性为特征,采用机器学习常用算法SVM、LR和决策树C4.5学习构建了答案质量评价分类器。在此基础上进行实验,发现本文所提出的基于语义扩展的方法计算得到的主题相关性对答案质量的分类效果上明显高于基于LDA的主题相关性计算的方法,但是对答案分类的精确率低于现有研究间接评价方法。(2)融合多特征的答案质量评价本文融合了文本特征、用户特征、社会交互特征和时序特征,对问答社区内数据深入挖掘,提出使用层次分析法计算用户权威度,通过朴素贝叶斯算法挖掘了答案文本的情感极性,同时计算抽取了答案及时性、答案丰富程度和答案得票数并结合上文计算得到的问题答案主题相关性训练答案质量的分类模型,实现SVM、LR和决策树C4.5答案质量分类器。通过实验发现本文模型对答案质量的分类效果明显高于仅基于问题答案主题相关性的分类方法。"
1003,多模态特征融合的情感识别研究,"情感识别在人机交互中具有重要意义。一般来说,人的情感主要通过面部表情、姿态表情和言语表情表现。而语音作为人类表达自身的最重要的通道之一,能够有效的表达情感,已被成功用于情感的自动识别中。然而,语音只是情感表达的一种方式,并未包含全部的情感信息,文本信息也能传递说话人的情感。因此,多模态特征融合的情感识别是一个重要的研究方向。本研究的研究目标是使用语音与文本特征融合的方式,来提高情感识别的准确率。基于此目标设计了如下实验:首先,对语音数据进行预处理,通过提取低层次声学特征,在低层次声学特征上应用了各种统计函数构建全局声学特征,并将其用于语音情感识别。用语音训练的识别模型作为基线系统与后续的识别模型进行比较。其次,对文本语句进行预处理,提取不同特征的提取,共生成3类特征,分别为词袋特征、词向量和句向量,用于文本情感识别,选择三类特征中识别准确率最高的文本特征用于后续与语音特征融合。最后,将语音与表现最好的文本特征进行特征融合进行情感识别,比较它们在IEMOCAP数据集上情感识别的性能。在特征融合时,采用了两种特征融合方式,分别为特征层融合和决策层融合。最终,本研究根据语音与文本特征融合后的情感识别结果与单语音通道的识别结果进行比较,同时比较融合方式对识别结果的影响。实验结果发现,语音与文本特征融合后训练的情感识别模型比单一模态特征训练的情感识别模型取得了更好的识别效果,得到了更高的识别准确率。具体来说,语音与文本特征融合后的情感识别模型比语音情感识别模型识别率更高,同时也比文本情感识别模型识别率更高;其次,决策层融合比特征层融合在情感识别中表现更好。通过决策层融合的语音和文本情感识别模型的识别率高于特征层融合的语音和文本情感识别模型。总体来说,相比于单模态的语音情感识别方式或单模态的文本情感识别来说,利用多模态特征融合的方式可有效提高情感识别准确率。"
1004,基于深度学习的信贷违约识别方法的研究,"风险控制是金融领域的核心,随着互联网金融的发展和大数据时代的到来,贷款交易次数和金额数目大幅度提升,风险管理具有重要意义。传统的机器学习模型在处理海量、高维度和复杂数据下时的训练和预测都遇到瓶颈。近几年,深度学习技术的出现解决了神经网络的浅层缺陷,能够构建多层非线性关系,在很多领域得到广泛应用。通过基于深度学习的方法减少信贷违约的风险,加强金融监管,降低金融机构的损失具有现实意义。本文从有监督和半监督学习两个方面入手,构建了两种基于深度学习的信贷违约识别模型。针对信贷违约识别的研究难点在于缺乏实时海量交易数据的标注数据这一问题,本文鉴于半监督深度学习模型的深度信念网络需要较少的标签数据,并且可对大量无标签数据充分使用,达到特征的有效提取的目的,提出了一种基于半监督深度学习的模型。考虑到传统的无监督学习孤立森林算法(Isolation Forest,iForest)在处理高维数据时存在的局限以及其在异常检测方面的优势,提出了一种基于DBN-iForest的半监督信贷违约识别模型,并且通过模拟退火算法和粒子群优化算法,实现对孤立森林算法主要参数的优化,相比优化之前,在模型的分类性能和分类精度方面得到了更进一步的提高。其次,针对传统的基于机器学习的信贷违约识别模型,在处理高维不平衡的金融交易数据上分类精度较低的问题,本文提出了一种结合卷积神经元网络和随机森林算法的监督信贷违约识别模型,实现从高维不平衡的信贷金融交易数据中识别欺诈交易。算法核心思想在于构建了两阶段工作模型CNN-RF。通过构建卷积神经网络自动进行交易数据的特征提取,然后通过随机森林算法进行分类预测。该模型充分利用了CNN能够对复杂数据进行特征提取的优势以及随机森林算法较强的泛化能力的优点。最后,本文以Kaggle比赛提供的Loan-Default-Prediction作为数据集,对本文提出的两种模型进行了验证,实验结果证实,本文提出的信贷违约识别模型相对而言,其分类性能表现的更佳。"
1005,基于机器学习的理财产品推荐算法的研究,"受益于互联网技术的发展和用户行为观念的改变,互联网金融成为经济生活的新热点。互联网金融蓬勃发展的同时,也因理财产品的多样化,给投资者带来了不知如何挑选适合自己理财产品的困扰。进行个性化推荐是解决此问题最有效的方法之一。目前,基于机器学习的推荐算法较广泛的应用于电子商务平台,以及音乐、视频和新闻的个性化推荐。但在理财产品领域还未被广泛研究。因而,利用机器学习进行高效的理财产品推荐对每一位投资者和经营商都具有重大意义。针对上述问题,本课题主要研究理财产品的推荐算法。数据为某金融APP里的理财产品和用户行为信息。理财产品为现有的直销银行旗下的产品,主要包括银行发行的理财和基金公司发行的基金类(货币基金和纯债基金)产品。将推荐分为召回和排序两个部分。召回部分主要采用了两种方法。一是针对传统的协同过滤存在没有考虑时间因子的问题,根据理财产品的自身生命周期和用户对理财产品的兴趣变化,拟合时间衰减函数,并将其加入到协同过滤算法中,使得推荐结果体现时间效应。二是提出改进的随机游走图模式推荐算法,为游走加入权重,减少了随机游走的算法中存在的个性化程度不高和推荐结果冷门产品占比较高的现象出现。对于理财产品推荐的准确率和召回率都有了一定的提升。最后,加入重排序阶段,增大召回结果,并对其进行重排序,借助机器学习的方法,使用XGBoost模型来综合多方面的因子进行排序。更深层地挖掘用户的行为,更全面地了解到用户偏好。实验证明,重排序可以更好地满足用户的需求,更准确地预测用户的点击概率,提升推荐效果。"
1006,基于深度学习的连锁便利店销量预测的研究与应用,"在新的零售业蓬勃发展下,连锁便利店具有营业时间长,空间小,资产模式轻的优势,在消费者中越来越受欢迎。在消费升级和新零售的两轮驱动下,中国的便利店行业正在全面展开,各大零售巨头纷纷投入大量资金参与其中,苏宁店和天猫店等新的便利小店如雨后春笋般涌现并迅速扩大,如何在激烈的市场竞争中脱颖而出是一个值得思考的问题。商品销量准确预测可以有效指导便利店的后端运营,进行合理的库存管理,及时调整商品定价策略,满足周边居民日常购物需求,有效地提高品牌知名度和市场竞争力。由此可见,销量预测技术是便利行业市场竞争中的关键。连锁便利店在地区上分布广泛、商品种类多样、季节影响复杂、市场需求难以预测,这些因素给商品销量预测增加了困难。通过分析参考文献的相关研究,发现传统的回归预测算法,对于受多因素影响的零售商品销量的预测效果并不理想,本文为了提高便利店商品销量预测的准确性,基于机器学习和深度学习的相关理论,将深度信念网络(DBN)、神经网络(NN)和支持向量回归(SVR)方法相结合,建立一种新的回归预测组合模型。实验中以便利店历史销量数据集为研究对象,对数据进行预处理和特征提取等操作,使用组合模型与传统的神经网络(NN)、支持向量回归(SVR)和深度信念网络(DBN)做对比实验,实验结果表明,组合模型具有更好的预测效果。最后,本文从应用的角度出发,分析潜在的便利店用户需求,设计了一种便利店销量预测系统,包括系统的架构设计、功能设计和数据库设计,通过相关技术将组合模型整合到系统中,并使用相关开发技术对系统进行了实现。"
1007,数据挖掘在智能手机销售数据中的应用,"手机作为目前人们使用最多的电子设备,一方面既承担着网络购物的终端作用,另一方面,本身也是消费人群最多的商品之一,现在社会几乎是人手一部。目前来看,手机还同时有逐渐取代传统钱包以及银行卡的趋势。每年都有大量的各式各样的手机通过线上渠道或者实体店被销售出去,然而不同的手机商品销量却是大不相同,这其中影响手机销量的因素有哪些呢?这是销售手机的商家十分关注的问题,也正是本文要研究的问题。本文首先简单介绍了网络爬虫,利用网络爬虫从某大型电商网站爬取所有在架销售手机的详细信息,包括各种参数配置信息以及销量,评论数等等,其次对数据进行清洗,提取各种字段用于后续建模分析。通过特征信息度以及Spearman相关系数对影响手机销量水平的因素进行了相关分析。为了预测一款特定手机商品的销量水平情况,根据数据的特点,文中分别利用决策树算法,Bagging算法,随机森林算法三种机器学习方法进行建模分析,并利用交叉验证以及网格搜索选取随机森林模型最优的超参数。最后对各种算法的结果进行比较发现,基于决策树的集成算法随机森林算法要优于其它两种算法。当选取合适的超参数后,随机森林算法的结果明显好于使用其默认参数的结果,并且当变量减少时,随机森林算法依然能够保持较高的精度和AUC值。"
1008,基于BP_Adaboost改进算法的电影首轮融资时总票房分类预测研究,"在电影产业迅速发展的同时,大部分电影处于亏损状态且票房收入差异大,给电影投资者投资造成极大风险。电影投资方若能在电影首轮融资时预测电影票房,对保证电影投资方盈利及电影产业的长远发展都有非常重要的意义。以往电影票房预测研究集中于电影即将上映或电影上映后,未发现对电影首轮融资时影响因素的研究。将电影首轮融资时与电影即将上映、电影上映后对比发现,首轮融资时可获得的电影票房影响因素更少,无法精确预测电影票房,因此,可用机器学习方法进行分类预测。BP_Adaboost算法是常用的分类预测方法,其广泛适用于医疗诊断、环境检测、故障诊断等各领域的预测中,但还未运用于电影票房分类预测。BP神经网络有着学习效率低、收敛速度慢及易陷入局部最优值等不足,BP神经网络也是BP_Adaboost算法的弱分类器,亦存在上述问题。针对上述不足,本文主要研究三个问题,探究电影首轮融资时票房影响因素,提出BP_Adaboost算法的三种改进算法,进行首轮融资时总票房分类预测研究并找出最优方法用于首轮融资时总票房分类预测。具体进行了如下工作。首先,探究BP_Adaboost算法在首轮融资时总票房分类预测的适用性。探究电影首轮融资时电影票房的影响因素,构建并验证基于BP_Adaboost算法的电影首轮融资时总票房的分类预测方法。然后,提出三种BP_Adaboost改进算法,用思维进化算法(MEA)、列文伯格-马夸尔特法(LM算法)和两种算法相结合等三种算法改进BP_Adaboost算法。之后将改进算法应用于首轮融资时的总票房分类预测中,用电影样本数据集验证三种改进算法的有效性,并对比得到电影首轮融资时总票房分类预测的最优预测方法。最后,比较改进BP_Adaboost算法与其他算法的整体性能,将BP、BP_Adaboost、MEA-BP、LM-BP、MEA-LM-BP、MEA-BP_Adaboost、LM-BP_Adaboost、MEA-LM-BP_Adaboost等8种预测模型在模型准确率、模型稳定性、模型K折交叉验证等三个方面进行比较。结果显示,BP_Adaboost算法可用于电影首轮融资时的电影总票房分类预测,得到了电影制片方、主创方、发行方、剧本等四类影响因素下的共11个变量,将此11个变量作为输入变量,将电影总票房分类成四个等级,将分类值作为输出变量。经MEA、LM算法、结合MEA和LM算法改进的BP_Adaboost算法预测准确率均得到提升,证明三种改进算法均有效。其中结合MEA和LM算法的BP_Adaboost算法的总票房分类准确率可达73.3%,可用作首轮融资时总票房分类预测方法。将8种预测模型进行整体性能比较,比较结果发现本文提出的结合MEA和LM算法改进的BP_Adaboost算法模型的整体性能最好。另外,LM算法对提高模型预测准确率的效果好,MEA有提高模型稳定性的作用。"
1009,基于机器学习的移动视频QoE评价方法研究,"近年来,随着移动通信和多媒体技术的飞速发展,移动视频业务呈现爆发式的增长趋势,新业务不断涌现。如何保障移动视频业务的用户体验质量(Quality of Experience,QoE)是移动视频产业和整个移动互联网行业需要重点解决的关键问题。为此,对移动视频业务的用户QoE进行准确评价是十分必要的。影响用户QoE的各种因素众多,既涵盖主观因素,又涵盖客观因素。QoE评价的本质就在于建立各类影响因素与用户主观感受之间的映射模型,表征QoE与其影响因素之间的内在关联关系。QoE的主客观影响因素之间相互作用,给准确建立QoE评价模型带来了巨大的挑战。本文深入开展了移动视频QoE评价方法的研究工作,利用机器学习方法,从发送端、网络端和客户端等不同角度出发,分别建立了三种移动视频QoE评价模型,具体研究内容包括:首先,提出了一种基于内容特性的H.264视频质量评价模型,用以对发送端的H.264码流主观感受质量进行准确评价。通过对H.264的码流结构的深入解析,提取出了质量参数QP、运动矢量MV、视频帧内宏块的编码类型以及ICT非零系数等码流参数。接下来,对提取出的码流参数进行处理,提出了两个描述视频内容特性的指标,定义为视频运动复杂度和视频纹理丰富度。与目前被普遍采用的描述视频时间特性和空间特性的TI、SI两个指标相比,本文提出的指标能更好地表征视频的时空特性,并且与人眼的主观感受相符合。最后,本文将这两个视频内容特性指标与其它的H.264码流参数组合成特征参数矢量。以此作为输入,以主观MOS分值作为输出,利用深度神经网络,在包含180个视频的数据集上进行训练,建立了一种基于H.264的视频质量评价模型。从实验结果上可以发现,采用本文提出的模型,皮尔逊线性相关系数PLCC和斯皮尔曼秩相关系数SROCC可以分别达到0.9941和0.9893,足以验证该模型在预测H.264视频码流主观感受质量的准确性上具有良好效果。其次,提出了一种基于DASH协议的移动视频QoE评价模型,用以对网络传输后的H.264视频码流质量进行评价。该模型依据DASH协议,提取出视频的初始缓存时间、卡顿次数及时间、码率向上或向下切换次数等参数,结合视频内容特性参数-视频运动复杂度和视频纹理丰富度,形成特征参数矢量。以此作为输入,以MOS分值作为输出,利用深度神经网络建立输入特征参数矢量和输出之间的映射关系模型,用于对移动视频业务的QoE进行评价。在对Waterloo SQoE-III公开数据集进行测试后发现,采用本文提出的模型,PLCC和SROCC分别达到0.9632和0.9574,证明本模型可以准确预测移动视频的QoE。最后,提出了一种基于深度时空特性的客户端视频质量评价模型,用以对客户端的播放视频质量进行评价。该模型将3D CNN和LSTM深度神经网络结合起来,提取客户端播放视频的深度时空特征,以此作为输入的特征参数矢量,以MOS分值作为输出,利用深度神经网络建立播放视频的质量评价模型。实验结果表明,该模型的预测准确率可以达到99.16%,RMSE仅为0.1104,证明了本模型可以准确预测客户端播放的视频质量。"
1010,基于移动最小二乘法的小区均价预测模型研究,"房地产产业对中国经济发展而言是基石和推动力,随着房地产交易行为日益活跃,对房地产估价的需求也随之增大。近年来主流的估价方法为特征价格法,该方法以价格由商品的特征决定作为基础原理,结合数理模型,对价格进行综合评估。有大量研究使用特征价格法对住宅进行评估,建模时选用的特征较多,需要人工实地考察采集住宅特征,在实际应用中成本较高。有研究者提出以小区作为房价评估的切入点,小区是一定区域内住宅的集合,特征相较住宅更少且更宏观,易于采集。对小区进行总体的均价判断有助于全面地了解区域内的房价水平和发展趋势,并从侧面反映出小区内住宅个体的价格水平。目前有关小区均价的研究较少,主要使用特征价格法中常用的多元线性回归的方式进行数据的建模与分析,这种方式依赖于数据线性假定与固定的拟合函数设置,容易造成较大误差。通过总结前人工作,引入移动最小二乘法对小区特征数据的内在规律进行挖掘分析,主要进行了以下几方面工作:(1)小区特征数据集构建。在特征价格法的理论框架内,在住宅常用特征中对小区可用特征进行了筛选提炼,提出使用经纬度数据替代传统的区位特征,减少特征维度。选取北京市东城区与西城区作为实证研究区域,以网络为媒介,使用自动化采集特征数据的方式收集研究区域内2018年全年的小区特征与均价数据,通过数据整合、清洗、归一化等数据预处理流程,共得到908个小区的10486例7维数据样本作为用于建模分析的数据集。(2)小区均价预测模型研究。首次在特征价格法中引入具有较高拟合精度的移动最小二乘法以替代多元线性回归,对算法所使用的基函数、权函数进行了讨论和选择,并在原始算法的基础上提出了动态影响半径设置方法,以解决小区均价预测场景下数据分布不均造成的预测异常等问题。与多元线性回归所构建的模型进行对比研究,结果表明使用移动最小二乘法所构建模型的预测结果有着较高的稳定性和准确度,同时模型易于解释有效性,值得推广应用。(3)设计实现可视化原型系统。根据完成的数据集与模型,围绕功能需求研究提出原型系统架构、数据流转逻辑、底层数据库设计、界面实现方法等,实现小区查找、筛选、均价预测、数据呈现等功能,并对系统功能进行了测试,从软件工程的角度为模型应用提供直观参考。"
1011,基于XGBoost方法的ND公司门店销售预测研究,"ND公司是一家以提供城市出行智能解决方案的高科技创新公司,专注于为全球出行用户提供更环保、更便捷、更智能的城市出行交通工具。业务主要包括智能电动自行车的设计、生产、销售等。有效的销售预测能够帮助线下门店管理者建立高效的工作团队,并帮助门店管理者发现在日常销售中影响客户和团队的重要影响因素,从而改进生产模式,提高门店的赢利能力。本文以ND公司748家线下门店的日常销售数据及门店信息数据为研究对象,对门店销售现状以及现有门店销售数据进行分析,基于XGBoost方法预测未来门店销量。首先对ND公司门店销售现状进行研究,分析了ND公司门店销售预测中存在的问题。通过观察数据,分析数据缺失情况,同时对数据进行预处理。剔除缺失比例较大的数据变量,并且针对数据的分布情况使用恰当的方法插补缺失值。在对数据集中的变量进行处理后,挑选与业务场景契合的变量以及重要的变量作为数据特征集,构建模型的特征工程。最终选择门店属性特征、地理位置特征、服务特征、时间特征等四个特征作为特征集。最后分别使用XGBoost、线性回归、决策树和随机森林等四个模型对零售门店销量进行预测。通过比较分析真实数据与预测值之间的平均绝对百分误差,XGBoost模型的效果更好。并且模型预测的运行速度由于XGBoost模型的并行运算能力而得到了提高。本论文不仅适用于ND公司门店销售预测,还可以将此方法应用于国内零售实体业甚至电商平台的销售预测,对于提高门店的运营效率、商品的价格、提高销量及针对性的精准销售具有重要的意义。"
1012,路面裂缝检测与识别分类研究及FPGA实现,"中国高速公路的发展引起了全世界的关注,同时道路护养的压力也与日俱增,使得传统的路面破损人工目测检测无法满足需求,人工方法存在效率低、安全性不高等问题,因此,迫切需要一种高效的、高智能化的路面检测装置用于检测路面破损检测。随着计算机视觉技术的发展,许多研究人员提出了路面破损的智能检测方法,并对其进行了系统的开发。本文根据现有方法与系统的不足,以路面破损中的路面裂缝为例,将裂缝分为横向、纵向、块状和龟裂四类,提出了一种实时在线的路面裂缝和位置检测系统,该系统通过图像处理识别技术来初步判定采集的路面图像是否存在裂缝,应用北斗导航系统进行裂缝定位,并通过移动通信系统实现裂缝图片和位置信息进行实时传输,最后结合当前非常热门的人工智能理论,通过卷积神经网络对裂缝进行精确的识别分类。整个系统分上位机和下位机两部分,下位机主要采用FPGA加以实现,裂缝图片信息和定位信息通过4G传输模块传输到上位机,系统上位机软件显示裂缝图片、裂缝类型、位置和地图标注等信息。本文完成的主要任务包括:(1)对采集的路面图像在FPGA上做预处理,并对Sobel边缘检测算子进行了改进。根据现有的图像预处理算法,对采集的裂缝图像进行图像滤波降噪、采用改进的Sobel边缘检测算法进行图像分割,得到图像的二值化边缘信息,然后进行形态学上的膨胀腐蚀算法进一步处理,得到理想的裂缝边缘轮廓信息,最后对图像的投影特征进行计算,根据不同阈值来初步对裂缝进行检测与分类。(2)通过FPGA控制整个下位机系统,获取北斗定位信息,控制4G传输模块实现图像数据的传输以及驱动LCD实现检测结果的本地显示,编写上位机实现下位机上传数据的保存和接收。(3)对基于机器学习的图像分类算法进行深入的研究,比较了各种分类算法的性能优劣,自定义了裂缝图像数据集,针对本文的需求修改了VGG卷积神经网络结构,最后通过卷积神经网络对接收到的图像进行进一步的精确识别和分类,提高了识别分类的正确率。"
1013,基于机器学习算法的风机叶片结冰预测,"风力发电是一种很重要的可再生清洁能源,在国民经济中的重要性与日俱增。风力发电的主要机械是电力装置,风力发电机组经常位于高海拔或者高纬度等资源不错的地区。然而在温度低的气候状况下,机组有着表面结冰的问题。其中,以机组叶片覆冰的问题最为严重。为了确保易覆冰地区的风力发电机正常安全地运转,叶片结冰的观测以及清除至关重要。低温引发的风力发电机叶片覆冰、材质及固有的结构发生变化、电路电流电压改变的现象等,会严重影响风力发电机的正常运行和良好的工作性能。传统的方法大多是研究某种测量方法检测风力发电机叶片是否结冰,比如基于振动检测的风力发电机叶片覆冰状态诊断技术、基于压电陶瓷技术的风力发电机叶片覆冰监测方法等。也有极少数文献基于机器学习的角度来考虑该问题,本文在前人的基础上创新性地采用多模型融合的方式来解决该问题,并且更进一步推出了能够用于实际的更优方案,即模型能够不断进行自我更新。本文基于某风场真实数据,首先通过多种算法对15号风力发电机数据进行预处理,包括但不限于基于拉格朗日差值法的缺失值处理、基于SMOTE过采样算法的样本不平衡问题处理和基于聚类的小簇划分法及非典型离群点检测法。其次综合采用了方差筛选法、卡方检验法、互信息法、递归特征消除法、基于L1惩罚项的特征选择法和基于模型的特征选择法等来对特征进行筛选,根据汇总对比结果筛选出强相关性特征,去掉不必要的特征。然后基于该数据进行建模,经过对比多种模型方案,最终创新性地选择多模型融合方案建模。最后利用已建立模型对风力发电机组的21号风力发电机进行结冰预测,最后结果显示预测效果良好,证明该方案是有效的。为了能使本方案可以投入到实际使用,考虑到未来数据规模的增加,本文创新性地选择了基于Spark MLlib的大数据平台。实现了模型能够不断地进行自我更新,不断地提高自我预测能力。"
1014,基于深度学习的电力系统扰动后动态频率特征预测,"电力系统的频率稳定是电网安全稳定运行的重要指标,然而现代电力系统中区域的互联以及大量的新能源并网,给电网的频率稳定性带来了新的风险与挑战。一方面,电力系统通过超特高压交直流进行区域互联,大大增加了系统的复杂程度,同时也增大了输电走廊破坏、大容量机组故障导致的风险及其影响范围。另一方面,大量的新能源机组并网,增强了系统的随机波动性和安全风险,削弱了系统的惯性和频率控制能力。基于物理模型的电力系统频率预测方法存在准确性与实时性上的矛盾,而传统的浅层机器学习方法难以适应具有复杂非线性特征的现代电力系统。近年来,深度学习的热潮给电力系统安全稳定分析带来了新的思路,以卷积神经网络为代表的深度学习算法在处理具有空间特征的图像数据上获得了成功的应用,也展现了其在处理具有空间分布特征的电力系统数据上的应用潜力。本文围绕电力系统频率预测,开展了基于卷积神经网络的电力系统扰动后动态频率特征预测的研究;针对物理模型与机器学习方法各自的优势,研究了基于物理-信息融合的动态频率特征预测方法。论文主要研究内容概括如下:阐述了电力系统动态频率的基本概念,介绍和总结了在电力系统频率预测领域常用的若干机器学习模型的结构与原理,包括:支持向量回归,人工神经网络,多层感知机。详细阐述了卷积神经网络的基本概念,结构以及训练过程。通过与几种机器学习模型之间的对比,指出了卷积神经网络在电力系统频率预测应用上的适用性与优势。针对卷积神经网络在电力系统扰动后频率预测的应用,首先提出了一种卷积神经网络输入特征筛选以及系统运行状态数据库生成方法,基于电力系统受到功率扰动下的动态频率过程筛选了关键的电力系统运行数据信息作为卷积神经网络的输入特征量,以扰动后系统最低频率作为输出,利用PSS/E自动大批量生成了电力系统运行状态数据库。在电力系统运行状态数据基础上提出了一种卷积神经网络张量输入构建方法,利用电气距离描述电力系统节点的高维空间位置,利用t分布随机临近嵌入算法将系统节点降维映射到二维平面,并实现了从原始向量运行状态数据到张量数据的重构,保留了系统节点状态数据的空间信息。利用张量样本数据完成了对基于卷积神经网络的频率分析模型的训练。在改进的含风电场新英格兰39节点系统和美国南卡罗莱纳州实际电网上对该方法进行了验证,证明了该方法的优越性以及实时性。针对用于电力系统频率预测的物理模型和机器学习模型各自的优势和不足,提出了一种物理-信息融合的电力系统扰动后频率预测方法。首先使用一种计及风电场的电力系统等值物理模型建立电力系统扰动与动态频率之间的关键物理联系,然后利用卷积神经网络建立基于电力系统运行状态信息的机器学习模型,最后使用自适应神经模糊推理系统对两个子模型的频率预测结果进行有机融合实现集成学习,得到物理-信息融合后的最低频率预测结果。利用改进的含风电场新英格兰39节点系统验证了所提方法对频率预测精度的有效提升。"
1015,日喀则地区滑坡泥石流孕灾环境遥感监测研究,"发生灾害的环境背景就是孕灾环境,由自然因素和社会因素作用而成。孕灾环境的改善,能够有效减轻灾害的发生与危害程度。因此,对区域灾害孕灾环境进行有效的监测成为灾害预警与防护的重要课题。本文将时下热门的机器学习算法与遥感技术相结合应用到环境监测中,并融合多元遥感数据,提高监测的范围与准确性。本文以日喀则地区为主要研究区,以历史灾害数据和卫星遥感数据为主,辅以地面气象数据建立滑坡泥石流孕灾环境敏感性分析模型,完成对滑坡泥石流孕灾环境的监测研究。通过对灾害数据的影响因素研究,重点分析研究区的土地覆盖时空变化,为滑坡泥石流孕灾环境的遥感监测提供支撑,为该地区防灾减灾提供科学依据。首先,完成对灾害数据的数据清洗工作,得出滑坡泥石流灾害空间分布,并基于Xgboost算法的特征重要度计算得到特征重要性排序,从中提取出相关程度最高的8个致灾因子,建立致灾因子与孕灾环境评估模型,定量分析致灾因子时空分布特征与灾害数据的相关性。然后,完成对MODIS数据MOD09A1的图像预处理工作,得到2001至2017年多时相遥感数据,应用集成学习的代表算法随机森林进行遥感图像土地覆盖分类,并通过高分辨率数据和MCD12Q1产品进行精度验证。结果表明,分类总精度和Kappa系数均能满足土地覆盖变化分析的要求,可以作为环境监测的可靠数据来源。最后,采用GIS软件和无监督学习的典型算法聚类分析,完成对研究区各项环境因子的变化分析。包括地面气象数据长时间变化的分析、地形因子坡度坡向与灾害数据分布关系的分析、土地覆盖分类数据时空变化的分析、滑坡泥石流灾害数据危险程度的分析以及滑坡泥石流孕灾环境敏感性的分析,结合这些环境因子的变化分析,完成对滑坡泥石流孕灾环境的变化监测。研究结果表明,日喀则地区的孕灾环境需要引起极大的重视,当地政府应当制定合理的土地利用规划和防灾减灾政策,并切实采取相应的措施改善研究区孕灾环境。"
1016,基于机器学习的京津冀地区PM_(2.5)浓度及能见度预报,"近年来,随着经济的发展、人口的增长,我国的大气污染的问题越发的严重,很多区域都出现了重污染天气,且时间长、范围大,尤其是京津冀及周边地区的污染问题最为严重。因此,寻找并研究实时高效的空气质量预报方案非常重要,不仅能指导民众出行,还能为防治天气污染提供有效的技术支撑,具有重要的探索意义。空气污染预报模型是当前空气污染研究领域的一个热点,但由于体质及技术发展等原因,国内外数值预报及传统的统计预报模型难以满足我国的空气污染预报及预警的业务需要。针对以上情况,本文针对京津冀地区构建了基于分层稀疏表示的PM_(2.5)浓度预报模型,并结合环境要素构建了基于分层稀疏表示的能见度预报模型。首先,选取京津冀地区内海拔高度均低于1km的气象及环境站点,对污染物PM_(2.5)浓度的全年分布特征及能见度全年分布特征进行分析、同时对PM2.5浓度、能见度及气象因子进行了pearson相关系数分析。分析结果表明:京津冀城市污染状况相对而言比较严重,PM_(2.5)的污染比例较大,主要集中在1月、2月、3月、11月和12月。其次,以北京等站点为例,并根据PM_(2.5)的相关影响因子结合模糊C均值聚类(FCM)算法及稀疏表示算法,建立了PM_(2.5)浓度的预报模型,对京津冀主要站点的PM_(2.5)浓度进行了预报,与现有模式对比,并对预报结果进行了多方面的分析。结果表明,该模型能有效缩短预报时间,提高PM_(2.5)浓度的预报准确率。最后,根据能见度的相关性分析,选取预报因子,根据模糊C均值聚类(FCM)算法及稀疏表示算法构建能见度预报模型,对冬季京津冀主要站点的能见度进行了预报,并与现有模式及BP神经网络法对比,对预报结果进行了多方面的分析。结果表明,预报因子结合了污染物浓度后能够有效提高低能见度天气的预报准确度。可见,以模糊C均值聚类(FCM)算法及分层稀疏表示算法建立的PM_(2.5)浓度及能见度预报模型,能进行有效预报,验证了该方法在PM_(2.5)浓度及能见度预报上的潜力。且以分层稀疏表示法建模简单易扩展,提高了PM_(2.5)浓度及能见度预报的精度,便于应用于其他气象分析。"
1017,基于机器学习的麦克风阵列声源定位算法研究,"基于麦克风阵列的声源定位技术是阵列信号处理领域的一个重要的研究方向,它在车载免提电话、视频会议系统以及军事领域都有着广泛的应用。近年来,基于统计学习和深度学习的声源定位技术开始备受关注,基于这类算法的声源定位方法比起传统声源定位算法有更强的鲁棒性和精确性,本文深入研究并做了如下几方面的工作:1、对基于麦克风阵列的声源定位技术的研究现状和应用背景进行深入研究,建立麦克风阵列语音信号模型,并对语音信号进行预处理。2、针对MUSIC(Multiple Signal Classification,MUSIC)归一化算法低信噪比时DOA(Direction of Arrival,DOA)估计性能下降问题,提出了基于支持向量机可控功率响应的MUSIC-DOA算法。首先对宽带信号进行快速傅里叶变换,然后用MUSIC算法进行DOA估计,最后通过SVM(Support Vector Machine,SVM)对每个子带信号的DOA估计结果进行分类,选择分类后DOA估计结果较为准确的子带信号进行融合,得到宽带信号的DOA估计,有效解决了MUSIC归一化算法在低信噪比时,定位精度不高的问题。3、针对基于均方根的多层感知器声源定位算法在低信噪比等恶劣环境下,定位性能不高,提出了基于GCC-PHAT的多层感知器声源定位方法。首先,对麦克风接收信号进行分帧加窗处理并求出信号的互相关函数,再将其作为特征输入到多层感知器中得到声源到的方位坐标,提高了定位的精确性。4、针对基于传统神经网络DOA估计方法稳定性差、定位精度不高的问题,提出了基于局部加权LSTM(Long Short-Term Memory,LSTM)神经网络的DOA估计方法。首先使用阵列协方差矩阵上三角阵作为DOA估计特征,将特征放入神经网络中训练,在训练时通过核函数对LSTM神经网络损失函数和反向传播中权重的偏导引入局部加权回归,得到DOA估计结果,提高了定位的精确性。5、分析前面提出的声源定位算法,并对第三、四和五章的算法进行语音定位系统实现。实测结果表明,本文提出的语音定位算法定位精度高,能满足实际定位需要。最后,总结本文所完成的工作,对存在的改进之处做出展望。"
1018,基于微博文本的暴雨内涝灾情判别与舆情研究,"暴雨内涝灾害是指由于暴雨急而大,城市排水不畅引起积水成涝,造成市区严重积水,影响公共安全的气象灾害。它的主要特征为突发性、群发性、持续频发性、造成经济损失巨大。随着中国城市化进程加快,如何预防和减少暴雨内涝灾害造成的经济损失及人员伤亡成为人们关注的热点和难点问题。同时,传统的媒体传播途径时效性及准确度较低,微博作为新兴的社交媒体时效性强。因此,急需一种基于微博文本暴雨内涝灾情判别与舆情研究方法进行应对。本文提出了基于微博文本进行暴雨内涝灾情的判别方法。微博作为新兴的社交媒体即时性强、用户数多。因此基于微博文本使用文本分类算法进行暴雨内涝的灾情判别具有一定理论和实践意义。本文首先获取了暴雨内涝灾害发生后的微博数据,使用三种文本分类算法进行文本分类,对微博文本进行有无灾情的二元分类判断;基于文本分类算法的三个常用的性能评价指标对三种文本分类算法进行分类性能比较,实验表明,朴素贝叶斯算法分类性能最优,可运用到基于微博文本进行暴雨内涝灾情判别的实践中。在实现了暴雨内涝灾情判别的基础上,本文还提出了基于微博文本进行暴雨内涝灾害舆情研究的新思路。在暴雨内涝灾害发生后,使用文本分类算法对获取到的微博文本数据进行灾情判别,对判别为有灾情的微博文本进行舆情研究,将暴雨内涝灾情以及公众情绪可视化,以便相关部门进行有针对性的应急管理与救援,以减少暴雨内涝灾害造成的人员伤亡以及经济损失。"
1019,原发性失眠病辨证算法优化研究,"研究目的:以原发性失眠病的辨证过程作为研究对象,依据“症状是指用疾病产生原因、疾病发生的位置、疾病的性质、病情发展趋势,即'因位性势'来反映其内涵的异常生命现象”[12]理论,优化本团队前期建立的46位辨证因子及权值,构建特定病种的辨证算法模型,从而提高整个系统对原发性失眠病的辨证准确率。本研究隶属四川省科技厅重点研发项目2018年3月-2019年9月“中医人工智能诊疗系统的开发研究”(NO:2018SZ0065)的一部分,是在2003年杨殿兴教授、彭明德教授领导团队创建的“基于多维空间数学模型的智能中医辨证论治系统研究”基础上进行的延续研究。研究方法:(1)针对原发性失眠病,优化46位“因位性势”辨证因子。通过查阅中国知网近20年有原发性失眠病病案记录的文献资料,纳入文献358篇,收集到195例有完整病案记录的原发性失眠病病案;以及于2017.11至2018.11在成都中医药大学名医馆门诊部以填写表格方式采集到103例原发性失眠病病案,采用频数统计、因子分析及主成分分析方法分别对文献数据与临床数据中的症状与证型进行分析,根据结果,优化适用常见疾病的46位“因位性势”辨证因子,得到适合原发性失眠辨证的21位“因位性势”辨证因子。(2)辨证因子权值的调优。根据第一部分症状对公因子的载荷系数值、频数分析结果及原发性失眠病症状特征,对症状-21位辨证因子进行编码,得到初始权值,通过训练样本,进行以y(ki)=(?)Si÷(?)为基础的机器学习,再根据中医理论知识对失眠病的认识,判断证型权值的偏差,反复7次进行症状-辨证因子权值的调节及机器学习,得到21位辨证因子-证型的最终权值及症状-21位辨证因子的最终权值。(3)检验优化后算法模型的准确率。以2018.12至2019.3于成都中医药大学附属医院针灸学院至真堂教学门诊收集的32例原发性失眠病病人与四川省中医辨证论治大数据平台的762条病例为检验样本,将样本中的症状逐一输入软件(软件是以优化后算法模型为基础而开发),对比软件智能推选的证型与临床结果是否一致,若一致则准确,否则为不准确。研究结果:(1)优化46位辨证因子,得到适合原发性失眠辨证的21位辨证因子(简称PI-d-21):心、神、肝、阳亢、血瘀、气滞、胃、肾、血虚、胆、内风、痰、阴虚、阳虚、积食、寒、热、气虚、脾、湿、饮。(2)调节症状-辨证因子的权值,得到辨证因子-证型的最终权值,其中辨证因子心、神在证型中的权值高;辨证因子胃在痰热内扰证的权值大于在肝郁犯胃证的权值;辨证因子饮、血瘀在证型中的权值低;其余辨证因子在证型中的权值,反映了原发性失眠中证型的病理程度。(3)根据症状-21位辨证因子的初始权值,经过机器学习及对权值进行7次调优后,得到21位辨证因子-证型的最终权值,建立了原发性失眠病症状-证型辨证算法模型。(4)优化后的症状-证型辨证算法模型,对原发性失眠病的辨证准确率为92.19%。研究结论:(1)21位“因位性势”辨证因子能够诠释原发性失眠病的大部分证型。(2)构建的症状-证型辨证算法模型,对原发性失眠病的辨证准确率提高了8.57%。"
1020,基于主动学习与半监督学习的交通方式识别模型与应用,"出行的交通方式信息在交通规划、交通控制管理方面有着重要的作用和价值。随着大数据技术、机器学习算法的发展以及手机用户规模的逐渐增大,越来越多的研究集中于采用手机数据挖掘的方式获取交通方式信息,其中手机信令数据由于其获取无需用户主动参与以及用户出行活动信息的完整性等优势,利用信令数据挖掘交通方式信息成为交通方式识别领域的热点,由于信令数据质量参差不齐且挖掘难度大,设计更有效率的挖掘算法仍是当前的研究重点及难点。本文首先针对信令数据特性建立数据质量评价体系,在数据预处理的基础上,提取多维度的出行特征,进而研究改进的交通方式人工识别流程和基于主动学习和半监督学习的信令数据挖掘方法,并以周期性定位的信令数据进行实例测试,以期提升交通方式识别效率与准确性,促进手机信令数据挖掘技术的研究,为优化城市未来交通运输方式结构提供科学的决策依据。首先,建立数据质量评价体系并对信令数据进行预处理。从质量特征、采样特征、定位特征三方面建立信令数据质量评价体系,并说明数据预处理方法。以HY市信令数据进行实例应用,对其进行质量评价,清洗“乒乓切换”、“漂移”等数据噪音,采用识别高频点、长时点的组合特征,刻画出行OD。为方便数据分析,将清洗、刻画后的信令数据整理成为只包含一次交通行为的出行链。其次,提取了出行链的出行特征。将出行特征划分为距离、时间、速度、出行者属性等四类,在验证常用的出行距离、平均速度、出行时间可以作为半监督训练特征的基础上,结合数据质量,进一步细分距离类、时间类、速度类的特征,形成多维度特征模型,并对HY市7.6万条出行链进行实例应用。然后,研究了改进的交通方式人工判别流程。在提取出行特征的基础上,改进已有的贝叶斯决策树和基于第三方导航数据方法,研究结合两种方法的交通方式人工识别流程。实例分析结果显示改进的交通方式人工识别流程可以提升人工标注效率35%左右。最后,研究了结合主动学习与Tri-training半监督支持向量机的交通方式识别算法。针对大量未标记数据,运用结合改进的人工判别流程的主动学习方法构造富含信息的已标记样本,运用已标记样本与大量未标记样本训练Tri-training半监督支持向量机。从不同样本集、不同分类方法的角度设计实验案例进行对比分析。结果表明,主动学习构造的富含信息的已标记样本集可以减少半监督学习的迭代次数,Tri-training半监督支持向量机可以通过大量未标记样本提升分类器准确率,结合主动学习与Tri-training半监督支持向量机算法可以有效地判别信令数据出行链的交通方式。"
1021,基于集成学习的信用评分模型应用研究,"随着我国经济体制改革的深入发展和市场经济体系的不断完善,个人信贷业务快速发展。但是在个人信贷业务不断发展的同时,也面临风险控制的问题。信用评分模型是在银行信贷中提供正确指导决策的有效工具。良好的信用评分模型不仅可以减少放贷机构的风险,并且能够节省时间提高效率。在过去几十年中,信用评分已成为金融机构日益关注的问题,目前仍是一个热门的研究课题。信用评分是一种二分类技术。当前构建信用评分模型有三种主流分类方法,一是传统的统计学方法,如逻辑回归、线性判别分析等;第二种采用机器学习方法,如朴素贝叶斯、决策树等;第三种就是集成学习方法,包括随机森林、GBDT(Gradient Boosting Decision Tree)等。近期的许多研究已经证明,集成学习模型相比较于传统分类算法在信用评分领域有明显的优势。但是,大多数的研究只追求模型的性能表现,忽视了现实信用评分业务中的数据不平衡问题和模型可解释性。为了解决上述现实信用评分业务中的两大问题,本文提出了基于集成学习的信用评分模型EL-CSM(Ensemble Learning Credit Scoring Model),使其可以适应不平衡数据的挖掘并具有良好的模型可解释性。对于数据不平衡问题,针对性的构建了模型的评价指标,提出了基于集成学习改进的不平衡数据下采样方法。并且在模型的构建过程中,充分考虑到了模型的可解释性,在建模前、建模中进行了一系列的优化,并提出了基于集成学习的特征选择算法。使用贝叶斯模型进行了超参数优化。并且在三个信用评分数据集上设计了完整的实验过程进行了模型性能和可解释性的验证。通过数据预处理、超参数优化、四组对照实验以及模型解释,证明了本文提出的模型拥有良好的性能,同时具有良好的可解释性,在模型的实用性上有明显的优势。"
1022,基于改进FSVM的滚动轴承故障诊断研究,"智能时代已悄然而至,各类机械设备的智能化程度也越来越高。大众在享受设备智能化给生活带来高效、便捷的同时,也要面临因设备出现故障而带来的各种损失。滚动轴承是机械设备中普遍存在且非常容易发生故障的器件,据统计由滚动轴承损伤而引起的故障占比大约是30%。因此对机械设备滚动轴承各种故障状态进行精准的分类预测具有不容忽视的现实意义和工程价值。基于此,本文通过对采集到的轴承数据进行分解处理,并将提取到的信号特征用于轴承的故障预测分类,由此展开一系列的研究分析。主要研究内容如下:(1)采用一种基于希尔伯特振动分解(Hilbert Vibration Decomposition,HVD)的滚动轴承信号分析方法。首先介绍了经验模态分解(Empirical Mode Decomposition,EMD)方法的思想,然后针对EMD方法容易出现模态混叠现象这一缺点,引入HVD方法对故障信号进行分解处理。HVD方法把原始的故障信号分解为若干个幅值不同的分量,具有较高的分解精度,有效地克服了EMD分解模态混叠的弊端。但是HVD方法在分解过程中由于要对数据进行截断处理,无法规避边界效应的出现。为了解决这一问题,本文采用一种新的自适应波形匹配的延拓方法,通过对比实验可以看出改进后的HVD相比较HVD和EMD而言,具有更好的分解性能。然后挑选出包含特征信息较多的几个分量并求得相应样本熵,把样本熵构造成机器可识别的特征向量为下面的工作做准备。(2)采用一种基于密度函数改进噪声聚类的隶属度计算方法。在分析了几种常见隶属度求解方法受噪声影响较大的基础之上,引入了模糊噪声聚类的概念。该方法将噪声视为独立的一类,所以在很大程度上降低了噪声对算法稳定性的影响。但是其初始聚类中心是随机初始化的,一旦误选噪声点作为初始聚类中心将导致聚类结果出现严重偏差。因此本文采用密度函数取代随机赋值来对聚类中心进行初始化,最终的实验结果很好地证明了该方法的有效性。(3)采用鲸鱼算法(Whale Optimization Algorithm,WOA)对模糊支持向量机(Fuzzy Support Vector Machines,FSVM)进行参数优化。首先介绍了鲸鱼算法的原理,然后针对鲸鱼算法中存在的问题,比如种群随机初始化容易造成种群多样性缺失、收敛因子及权重因子的取值大小对算法性能的影响、算法后期容易陷入局部最优等问题做出相对应的优化方案,从而获得改进鲸鱼算法(Improved Whale Optimization Algorithm,IWOA)。最终通过设计对比实验来验证本文所提的优化算法具有较好的鲁棒性。(4)采用一种新的改进鲸鱼算法优化模糊支持向量机(IWOA-FSVM)故障分类模型,结合特征提取工作,最终完成滚动轴承的故障诊断。"
1023,太赫兹光谱自动特征提取及识别研究,"太赫兹时域光谱技术是一种具有高分辨率、相干性、低能量、指纹谱和高信噪比的检测技术,使得该技术在毒品、爆炸物、药品、食品及农产品等物质的定量与定性分析方面得到广泛应用。针对目前在使用太赫兹时域光谱技术对物质进行定性和定量分析中,经常遇到太赫兹时域光谱没有明显的特征谱峰情况,如何对这些光谱进行特征提取及分析。为此,本文围绕太赫兹光谱的特征提取及有效识别分类展开研究,取得以下成果:本文提出了一种基于双向长短期记忆网络(Bidirectional Long Short-term Memory Recurrent Neural Network,BLSTM-RNN)自动提取太赫兹光谱特征的识别方法。利用其长短期记忆单元可以有效解决原始太赫兹光谱数据维数较高使得模型难以训练问题;再结合模型的双向频谱信息利用架构模式,可以增强模型对相似太赫兹光谱数据自动提取有效特征信息的能力。实验结果表明,利用该方法具有对太赫兹光谱直接自动提取有效特征的优势,从而达到了对复杂太赫兹光谱数据的有效识别分类。由于上述模型自动提取太赫兹光谱特征及识别的方法存在调参难度大以及模型不能根据数据集的大小自伸缩模型复杂度,所以本文另外提出了一种基于多粒度级联森林算法(multi-Grained Cascade Forest,gcForest)自动提取太赫兹光谱特征的识别方法。利用其多粒度扫描阶段对太赫兹光谱样本进行特征增强,尽可能地挖掘太赫兹光谱序列数据特征的顺序关系,再利用级联森林阶段对数据特性进行逐层处理,加强对算法的表征学习能力,提高模型的预测精准度。实验结果表明,利用该方法具有对复杂太赫兹光谱直接自动提取有效特征的能力,而且该方法模型复杂度可以自适应伸缩,适用于不同大小规模的太赫兹光谱数据集的高精度识别。上述两种方法试验结果表明对三类十五种化合物不同复杂度的太赫兹光谱数据集都具有较好的识别效果。可应用于药物分析、质量控制、爆炸物和食品检测等领域的定性鉴别。"
1024,基于广义回归神经网络的网页排序学习研究,"随着互联网的飞速发展,用户通过互联网发布的博客和文章等数据的数量呈指数级增长,大数据的时代已经到来。例如Google、百度、Yahoo等网页搜索引擎中包含着数以TB,乃至PB级别的存储数据。在实际生活中,用户每天主要的任务是从互联网上检索出需要的数据,而搜索引擎的任务就是从如此庞大的数据集中快速地查找到令用户满意的数据资源并且按照相关性进行排序返回给用户。在如今的搜索引擎中,网页排序学习模型起着一个至关重要的作用。如何从如此大规模的数据集中快速地检索数据并且按照相关度进行排序成为排序学习模型中一个重要的研究课题。传统的网页排序学习模型在进行信息检索时面临着训练时间长、准确率低等缺点。本文结合了广义回归神经网络的特点,进行了基于广义回归神经网络的网页排序学习模型的研究。首先,本文引入广义回归神经网络对网页排序学习模型进行构建。广义回归神经网络是一种基于径向基函数网络改进的模型,它具有学习速度快、训练样本少、实时性高以及收敛于全局最优解等优点,能够改善传统排序学习模型训练时间长的问题。其次,本文使用遗传算法对光滑因子参数的最优值进行搜索,从而改善排序学习模型的准确度低的问题。再次,广义回归神经网络有一个空间复杂度高的缺点,本文提出使用分块的技术进行改进。它利用计算机的局部性原理来解决广义回归神经网络的空间复杂度过高的问题。最后进行实验分析,实验结果显示基于广义回归神经网络的排序学习模型具有较高的查询效果。"
1025,健康领域中文自动问答的问题解析研究,"【目的】本研究针对中文消费者健康问题自动问答系统的问题解析部分,以肺癌健康领域为例,构建高质量的问题解析模型,实现对肺癌领域消费者健康问题的自动解析(包括问题类型、问题实体识别以及实体间关系抽取),为开发健康领域自动问答系统打下基础,本研究旨在(1)形成肺癌领域消费者健康问题的关键信息标注体系;(2)利用人工标注技术生成标注语料库;(3)实现基于深度学习方法的肺癌领域消费者健康问题自动解析。【方法】基于从在线医疗问答平台爬取的10000条真实的肺癌领域消费者健康问题,构建基于BiLSTM模型的问题解析模型。运用统计与对比方法构建中文肺癌领域消费者健康问题的关键信息标注体系;利用人工标注技术标注语料;运用BiLSTM-CRF模型识别问题的提问意向及关键语义成分;使用Attention-Based BiLSTM模型实现实体之间(问题类型与实体间)的关系抽取;将上述解析结果使用通用数据交换格式JSON储存。【结果】根据本研究构建的关键信息标注体系(含20种问题实体、22种问题类型)通过3轮标注与专家校对,对10000条真实肺癌领域消费者健康问题进行人工标注,形成了包含38505个问题实体与10361个问题类型的标注语料库;对该语料库进行问题解析,问题实体和问题类型识别的平均F1值分别达到了81.47%与80.31%;实体间关系抽取的平均F1值达到了85.27%;对解析结果进行了可视化展示并将其存储为JSON数据交换格式。【结论】本研究通过标注体系构建、语料库人工标注、问题解析模型的设计与实现等步骤,对问题实体、问题类型、实体间关系等语义信息进行了抽取,实现了高效的中文肺癌领域消费者健康问题自动解析,为构建肺癌领域的消费者健康问题自动问答系统打下了基础。同时,本研究实现中文肺癌领域消费者健康问题自动解析的过程具有一定的泛化能力,为研究者向其他健康领域扩展提供了参考。"
1026,基于神经网络的事件时序关系识别方法研究,"事件时序关系识别是对具有时序关联的事件对进行识别,并对它们之间的时序关系进行分类的一项任务。它对任何试图深入理解自然语言的系统来说都至关重要,如自动问答、信息抽取、文本摘要等。早期的事件时序关系识别研究通常专注于提取各种语言学特征,这些研究工作严重依赖人工标注的特征和外部知识库,而对形式上更加灵活且更具泛化能力的神经网络的应用却相对较少。本文工作聚焦于神经网络方法在事件时序关系识别任务上的应用,研究内容如下:(1)基于深度双向长短期记忆网络的事件时序关系识别方法与传统的基于特征工程的统计机器学习方法相比,神经网络方法在事件时序关系识别上显现出明显的优势。但是,现有的神经网络架构往往较为浅显(如单层循环神经网络或卷积神经网络),导致它们可能无法在不同的抽象层次上探索潜在的语义表示空间。针对这一问题,本文提出使用深度双向长短期记忆网络进行事件时序关系识别。该方法将多层网络中的所有前置层输出进行拼接作为后续层的输入,从而使其中的信息充分流动。实验结果表明该方法能有效提升事件时序关系的识别性能。(2)结合自注意力和神经网络的事件时序关系识别方法对于传统的循环神经网络或卷积神经网络而言,处理结构化信息和捕获句子的长距离依赖关系仍然是一个重大挑战。针对这个问题,本文提出一种结合自注意力机制的事件时序关系识别模型,它可以直接捕获句子中任意两个词例之间的关系。将自注意力机制与非线性神经网络层相结合,可以使事件时序关系识别性能得到显著提高。对比实验证明所提方法优于现有的大多数神经网络方法。(3)基于神经网络的事件时序与因果关系联合识别方法事件之间的时序关系和因果关系密切相关,两种事件关系往往相互影响。然而,对这两种关系进行联合学习的研究却极为有限。本文提出一种基于神经网络的联合学习框架来整合时序关系识别和因果关系识别两个任务,通过共享两个任务模型的网络层信息来实现两种关系的相互作用。实验结果表明,通过利用事件之间的因果信息,联合学习框架能够显著提升时序关系的识别性能。本文提出了三种有效的事件时序关系识别方法。针对事件时序关系识别方法中存在的问题,例如网络架构浅显、难以处理结构化信息和捕获长距离依赖关系、忽略时序关系和其它事件关系的关联等,给出了不同的解决方法,并显著提升了事件时序关系识别的性能。这些方法在学术研究和实际应用中有着良好的研究价值。"
1027,双子空间迁移学习方法的跨库语音情感识别,"随着人工智能的快速发展,语音作为人类传达情感的重要方式之一,占据着越来越重要的位置。传统的语音情感识别技术都基于一个共同的假设:训练数据和测试数据都来源于同一个数据库,即训练集和测试集具有同样的特征空间分布。然而,由于不同语料库的情感获取方法、情感种类以及录音环境有所不同,此时训练集和测试集存在分布差异,从而导致基于同分布假设的传统语音情感识别方法不能够很好地解决跨库识别问题。而迁移学习的引入己被证明可以显著减少不同域之间特征分布的差异性,因此,本文提出了双子空间迁移学习框架(Dual-Subspace Transfer Learning,DSTL)以提高跨语料库的情感识别性能。针对特征映射迁移学习方法忽略特有信息的缺陷,本文工作提出了融合共性与特性的双子空间迁移学习框架,对仅利用共性的特征映射迁移学习进行改进,以提高情感识别性能。本文具体研究内容如下:(1)为进行跨库语音情感识别的性能比较,本文工作建立了汉语情感语音数据库(Mandarin Emotional Speech Dataset Portrayed,MES-P)。该数据库是由说话人根据离散情感标签录制完成,随后由标注者通过听觉感知及主观判断将每个语音样本的情感定量转化到效价度/唤醒度(Valence/Arousal,VA)空间。因此,该数据库不仅为本文的跨库语音情感识别研究提供了重要的数据基础,还可用于离散情感到维度空间转换的后续研究。(2)研究了全局与局部分布差异约束作为正则项的特征映射迁移学习方法。本文工作将基于类间距离和类内距离特征分组的改进主成分分析方法作为基础方法,利用全局相关的最大均值差异和局部相关的图嵌入方法分别作为正则项对其进行分布差异约束,得到三种不同的特征映射迁移学习方法。实验结果表明,与传统机器学习方法相比,特征映射迁移学习方法的召回率提升了 8.11%。并且全局与局部分布差异算法在平衡库与不平衡库方案下展现出不同的识别性能。(3)针对主流特征映射迁移学习方法仅利用共性,而忽略特性的缺陷,提出融合共性与特性的双子空间迁移学习框架,双子空间指的是:a)公共子空间:利用特征映射迁移学习方法学习公共子空间,在该子空间中通过减少源域和目标域的分布差异以保留域之间的共有信息;b)特性子空间:针对特征映射迁移学习方法未利用特有信息的不足之处,提出了目标化源域特有信息(Source-specific Mapping to Target subspace,SMT)方法,能够在特性子空间中保留源域和目标域的特有信息。因此,该双子空间框架通过引入特有信息,能够对仅利用共性的特征映射迁移学习方法进行改进。结果表明,双子空间迁移学习方法的平均召回率较其基线方法得到3.05%的提升,并且召回率高达61.67%。"
1028,疾病名称识别和规范化,"近年来,随着生物医学实验方法的变革,生物医学方面的实验数据和文献资料呈指数级增长,如何从如此庞大的科学文献数据中快速有效地抽取有价值的信息,是当前亟待解决的问题。生物医学领域(如基因/蛋白质、化学物和疾病等)的实体识别与规范化是生物医学文本挖掘的基础,它对生物医学实体关系的抽取和生物医学知识库的建立等方面都有着重要的研究意义。其中,疾病名称识别与规范化是从生物医学文献资料中自动抽取疾病名称并且链接到指定疾病数据库中。针对这一任务,本文进行了以下三个方面的研究工作:(1)基于句法和语义特征的疾病名称识别。针对目前疾病名称识别中存在的问题,在条件随机场模型的基础上,提出了一系列新的句法特征和语义特征来获取疾病名称在句子中的结构信息以及在数据库中的语义信息。实验结果表明,本文的特征能够在疾病实体识别任务中取得较好的结果。(2)基于深度学习的疾病名称识别。为了缓解传统机器学习中特征稀疏性问题,本文采用了高性能的深度学习模型BiLSTM-CRF来实现疾病名称识别,探讨了不同的句法特征以及语义特征对疾病名称识别的影响。实验表明,深度学习模型获得了与当前最高性能相当的结果。(3)基于上下文信息的疾病名称规范化。将疾病名称规范化看做一个分类任务,首先针对疾病名称的特点,采用两种模糊匹配算法生成候选集,提高候选集的召回率;然后通过融入上下文信息的神经网络对候选集进行消歧。实验结果表明,本文采用的规范化方法在疾病领域取得了较好的性能。"
1029,校正最大化偏差的异策略强化学习方法研究,"强化学习是机器学习领域中的重要分支。强化学习通过与环境交互获得奖赏信号,使期望奖赏最大化,以获得最优策略。根据行为策略与目标策略是否相同,强化学习方法可分为同策略方法和异策略方法。异策略方法是行为策略与目标策略不同的方法,具有实现简单、计算快速等特点,被广泛应用到实际问题中。Q-Learning是一种重要的异策略时间差分控制方法,但是在一些随机环境中,如在具有高随机奖赏和高折扣因子的最优控制问题中,Q-Learning会产生很高的统计误差。造成这种现象的原因是在更新时使用估计值的最大值作为真实最大值的估计而引入的正偏差,这种正偏差被称为最大化偏差,会损害策略的质量,影响算法的收敛速度。针对上述问题,提出三种校正最大化偏差的异策略强化学习方法。主要研究包括以下三部分内容:(1)面向Q-Learning的异策略最大化偏差校正算法的研究。针对传统Q-Learning在解决最优控制问题时会产生最大化偏差这一问题,从实践角度出发,给出Q-Learning更新方程的累加形式,分析了正偏差的产生原因以及正偏差影响Q-Learning收敛速度的原因;其次,给出更新方程的一种泛化形式,以方便对估计器进行改进;在此基础上提出一种新的基于Q-Learning的异策略最大化偏差校正算法。该算法使用当前估计值替代之前所有有偏的估计值,重新构造估计器以修正状态动作值函数,减少最大化偏差对于值函数收敛的影响,提高收敛速度和收敛精度。(2)面向资格迹的异策略最大化偏差校正算法的研究。针对在大规模离散状态空间中,使用资格迹进行信度分配会加剧最大化偏差的问题,提出了一种面向资格迹的异策略最大化偏差校正算法,由改进的估计器得到较准确的估计值进行值函数更新,使用资格迹将当前的TD误差传播到整个值函数空间,提高数据利用率,加快值函数的修正速度,提高算法的收敛性能。(3)面向Dyna框架的异策略最大化偏差校正算法的研究。针对在模型可知的复杂任务中,Dyna-Q算法将学习过程和规划过程结合起来以提高数据利用率,但在两个过程中都会产生最大化偏差,导致算法收敛较慢且难以适应变化环境等问题,提出了一种面向Dyna框架的异策略最大化偏差校正算法。该算法通过优化值函数更新时使用的估计器,减少在学习过程和规划过程中估计值函数产生最大化偏差,使用规划进一步提高算法的收敛速度,使算法在环境模型改变时能够快速做出反应。"
1030,基于深度学习的有毒重气点源扩散浓度实时预测研究,"准确、高效的气体扩散浓度预测模型在突发性有毒重质气体泄漏应急救援中发挥着至关重要的作用。然而,现有的扩散模型很难同时满足预测精度和实时性要求。为解决这一困局,论文基于深度学习理论提出了可用于重气扩散浓度实时预测的新型模型,并将模型预测结果与地理信息系统(Geographic Information System,GIS)耦合,为应急救援行动提供更直观的决策依据。论文首先以平原、郊区(非城市)环境为研究对象,利用Prairie Grass野外实验数据分别构建了基于深度信念网络(Deep belief networks,DBN)及卷积神经网络(Convolution Neural Networks,CNN)的有毒重气扩散浓度预测模型,通过交叉验证法和网格寻优法确定模型的关键参数。将模型预测结果与实际数据进行比较,评价预测数据与原始数据的拟合度。此外,分别利用现有的计算流体力学(Computational Fluid Dynamics,CFD)方法以及基于传统机器学习的预测模型对相同条件下同样的泄漏场景进行浓度预测,并从时间和精度两方面,将深度学习模型与现有的预测方法进行分析比较,评价优劣。结果表明,CNN扩散浓度预测模型有着显著的优势。然后,对城市环境下的有毒重气扩散浓度预测模型进行研究。针对城市环境气体释放实验数据量过少无法构建模型的难题,利用CFD模型模拟仿真大量氯气泄露数据并以此来构建CNN扩散浓度预测模型,在保证预测精度与CFD模型相近的同时,大大降低其时间成本,为有毒重气扩散浓度预测提供一种新思路。此外,为进一步提高CNN预测模型的学习效率和预测精度,在上述研究的基础上,引入遗传算法(Genetic Algorithm,GA),实现CNN模型结构参数及训练参数的自适应寻优,并采取优化的权重及偏置初始化方式,提高CNN模型的预测效果。将优化后的CNN预测模型的预测结果同现有的一些预测模型进行对比,结果表明,CNN预测模型的性能最佳。最终,将CNN预测模型的预测结果按照氯气浓度危险等级进行划分,并将划分结果与在Arc Map中构建的二维建筑模型相耦合,实现氯气泄漏扩散的可视化表达。为有毒重气泄露后的应急救援行动提供更丰富、更直观的决策依据。"
1031,面向表面缺陷检测的小样本机器学习方法研究,"在现代工业化生产中,产品的外观检测是质量控制过程中一道至关重要的环节。因此,研发强大的智能外观缺陷检测技术日趋重要。传统的视觉检测方法需要针对被检对象,提取对象的特征,设计相对应的检测算法。随着机器学习的推进与发展,很多强大的机器学习算法也渐渐应用到表面缺陷检测中,并取得了很好的效果。在工业生产中,大量的缺陷样本往往难以获取。同时,在训练样本数量极其有限的情况下,使用机器学习算法进行缺陷检测往往效果不理想。针对该情况,本文进行了面向表面缺陷检测的机器学习方法研究。首先,针对缺陷种类较少,缺陷样本数量特别稀少的情况,本文提出一种贝叶斯小样本学习模型。该模型将数字图像处理与Naive Bayes分析相结合。在该模型的学习阶段,首先针对不同种类的样本进行分类,然后对不同类型的图像进行相应的增强处理,并对增强后的图像数据进行信息提取与特征量化。在该模型的检测阶段,同样先进行图像的增强以及特征的提取与量化,之后根据两部分样本的种类与分布建立相应的Bayes模型。模型中将图像信息转化为模型可接受的概率信息。在学习阶段的特征信息通过Bayes模型转化为先验概率,检测阶段中利用先验概率计算待测对象的后验概率完成检测。相比于现有的机器视觉方法,该模型检测效率更高,所需训练样本更少。其次,现有的深度神经网络在图像的检测与分类中可以达到非常高的精度,但深度神经网络需要大量训练样本的支撑才能充分优化。因此,在样本不足的情况下,利用GAN(Generative Adversarial Networks)对数据集进行扩增,可以有效的解决因训练样本不足而导致的模型过拟合、检测精度低等问题。但常规的GAN模型难以生成高质量的训练样本,因此本文提出缺陷增强生成对抗(Defect Enhancement GAN,DEGAN)模型。该模型可生成高清晰度、高多样性的缺陷数据。模型首先通过计算真实样本和生成样本的距离,得到网络后续训练的激励,其次对网络中判别模型的输出进行可梯度化处理。经本文模型生成图片的质量显著提高。随后,本文还提出了DEGAN与深度神经网络组合的缺陷检测模型。实验证明,该模型在小样本情况下较深度神经网络的检测精度更高,具有更强的适应性。再次,GAN中对抗学习的思想与迁移学习相结合在表面缺陷检测领域也能取得非常突出的表现。在此基础上本文提出了一种基于域对抗的迁移学习缺陷检测网络。该网络在小样本织物数据的情况下,借助大量的磁环数据建立迁移学习模型进行织物缺陷检测。本文设计的迁移学习网络模型中,包含特征提取模块,缺陷检测模块,域分类模块。训练过程中,首先提取目标数据集和辅助数据集的特征,然后通过域分类器对两类数据样本共同的特征进行学习,最后利用缺陷检测模块与域分类模块进行对抗学习,从而学习出两类数据集共有的特征。此时可以通过共有的特征进行检测网络的训练和优化。实验证明该模型可以借助相似的辅助数据进行迁移学习,有效减少了数据和计算资源的浪费。与深度神经网络相比,该检测网络在样本数据很少的情况下能达到更高的检测精度。最后,对本文所做的工作进行总结,并对表面缺陷检测方法的后续研究方向进行展望。"
1032,基于生物信息学的温脾汤治疗慢性肾病的活性成分虚拟筛选研究,"慢性肾脏病(Chronic kidney disease,CKD)是全球性疾病,可持续进展为慢性肾衰竭(Chronic Renal Failure,CRF)。近年来研究发现中医药在治疗CKD中具有应用潜力。中药复方的临床应用重视整体调节、辨证论治,具有多成分、多靶点整合的作用特点。温脾汤出自孙思邈《备急千金要方》,由附子、干姜、人参、甘草、大黄组成。尽管温脾汤已有治疗CKD的临床实验研究报道,但是目前有关温脾汤治疗CKD的有效成分仍有待进一步探究。随着人工智能与计算机辅助药物设计的发展,药物虚拟筛选技术的准确性不断提高,这种生物信息学计算为从网络药理学层面揭示中药复方活性成分和作用机制提供了新的策略。利用数据库资源和生物信息学研究工具,构建“疾病-基因-药物”的相互作用关系网络,预测疾病调控过程中的关键靶点,分析慢性肾病相关的靶向药物。药物虚拟筛选可分为基于配体的药物虚拟筛选和基于受体的药物虚拟筛选,例如分子相似性计算、药效团模型技术以及分子对接对。本研究分别采用分子相似性计算,基于机器学习的配体预测模型和分子对接方法筛选温脾汤治疗慢性肾病的潜在活性成分。实验一温脾汤与配体化合物数据库构建目的收集温脾汤中药成分,构建关键靶点配体库。方法通过文献调研和TCMSP、BATMAN-TCM数据库获取温脾汤中化合物成分,获取温脾汤潜在靶点,并利用DAVID数据库进行KEGG通路富集分析。基于文献和通路富集结果,确定从NF-κB信号通路、MAPK信号通路、JAK/STAT信号通路、TGF-β/SMAD信号通路、氧化应激通路收集关键靶点配体库。结果共收集温脾汤化合物588个,利用类药性指数与口服生物利用度指数筛选化合物共156个。由PubChem获取生物实验共12个,包含高通量筛选活性化合物数据23525例。实验二基于分子相似性计算的温脾汤活性成分筛选目的构建分子相似性筛选模型,筛选温脾汤中与活性配体相似性较高成分,并分析温脾汤活性成分靶点网络。方法基于RDKit模块,采用谷本系数将温脾汤化合物与活性配体库进行化合物相似性计算,初步选取相似性50%以上的化合物作为温脾汤活性化合物。综合TCMSP数据库与分子相似性计算活性成分的靶点预测结果,使用Cytoscape(V3.7.1)完成“化合物-靶点”拓扑结构网络构建。结果温脾汤中已知的588个化合物与活性配体库23525个化合物进行计算。最终,得出相似性大于30%的化合物对共4790对,其中360对相似性大于50%。温脾汤的潜在活性成分化合物构成的化合物靶点相互作用网络,可以形成3个簇群。实验三基于机器学习的温脾汤活性成分虚拟筛选研究目的构建基于机器学习的活性化合物筛选模型,并对温脾汤活性化合物进行筛选。方法采用纤维化相关通路实验数据作为训练集与测试集。基于Scikit-Learn模块,构建机器学习算法,选择实验数据分别构建随机森林(RF)模型、梯度提升决策树(GBDT)模型、人工神经网络模型(ANN),并构建了随机森林+逻辑回归、梯度提升决策树+逻辑回归、人工神经网络+逻辑回归等混合模型。基于准确率、召回率、F1值与ROC曲线评价各模型的性能。使用已知的具有抗纤维化活性中药化合物进行分子对接实验和模型性能验证。随后,用该模型对温脾汤中的化合物进行筛选,将预测概率高于90%的化合物作为温脾汤活性成分。结果梯度提升决策树+逻辑回顾模型具有较好的预测性能和稳定性,其准确率为0.80、召回率为0.80、F1值为0.79、AUC值为0.872。温脾汤化合物中预测概率值高于90%的化合物共28个,甘草素A、人参皂苷Rh1、人参皂苷Rf、苯甲酰新乌头原碱、芦荟大黄素葡萄糖苷等均具有较高的预测概率。实验四基于分子对接的温脾汤活性虚拟筛选研究目的基于分子对接模拟方法计算温脾汤中11种化合物与Smad3、Smad7、Nox4、p22phox靶点的结合活性。方法通过PubChem获取儿茶素、没食子酸、大黄素、大黄酸、次乌头碱、乌头碱、甘草酸、人参皂苷Rg1、人参皂苷Rf、6-姜酚、姜酮的三维分子结构,使用CDocer软件对化合物与Smad3、Smad7、Nox4、p22phox靶点依次进行分子对接模拟实验。结果温脾汤中与p22phox结合活性前六的化合物为甘草酸(24.9754)、人参皂苷Rf(22.6292)、乌头碱(22.4404)、人参皂苷Rg1(20.4986)、次乌头碱(20.3279)、6-姜酚(18.2458);与Nox4结合活性前六的化合物为人参皂苷Rf(54.0621)、甘草酸(51.4306)、人参皂苷Rg1(45.433)、儿茶素(39.5441)、次乌头碱(37.7516)、乌头碱(34.0981);与Smad3结合活性前六的化合物为甘草酸(41.5171)、人参皂苷Rg1(37.2358)、人参皂苷Rf(31.6412)、乌头碱(30.3829)、次乌头碱(26.9489)、儿茶素(24.0615);与Smad7结合活性前六的化合物为人参皂苷Rf(51.2196)、人参皂苷Rg1(46.8617)、甘草酸(46.497)、乌头碱(42.4877)、次乌头碱(35.3275)、儿茶素(31.9764)。小结药物虚拟筛选是药物发现和设计的重要内容,也逐渐成为初步解释药理机制的重要方法之一。药物虚拟筛选主要包括基于配体的药物虚拟筛选技术和基于受体的药物虚拟筛选技术。本文中分别利用上述方法,针对温脾汤治疗慢性衰竭的活性化合物进行了筛选研究。首先收集相关配体化合物数据23525例。基于文献、TCMSP和BATMAN-TCM得到温脾汤化合物588个,利用口服利用度和类药性指数筛选得到156个生物活性较好的化合物。随后,构建了分子相似性计算模型,将温脾汤化合物与配体化合物库进行了相似性计算,得出相似性大于30%的化合物对共4790对,其中360对相似性大于50%。随后结合使用分子指纹和机器学习算法,构建可用于筛选活性化合物的筛选模型,并对温脾汤进行活性化合物筛选。最后,将温脾汤化合物儿茶素、没食子酸、大黄素、大黄酸、次乌头碱、乌头碱、甘草酸、人参皂苷Rg1、人参皂苷Rf、6-姜酚、姜酮,使用CDocer软件对化合物与Smad3、Smad7、Nox4、p22phox靶点依次进行分子对接模拟实验。结果表明人参皂苷Rg1、人参皂苷Rf、甘草酸、乌头碱等与4个靶点均表现出较好的结合活性。"
1033,基于力和振动融合的刀具磨损状态辨识方法研究,"随着“中国制造2025”战略的不断推进,制造业的地位日趋重要,以智能制造为代表的新一轮工业革命,已经成为了国际竞争的新战略高地。在机械加工领域随着生产加工过程的智能化与自动化程度不断提高,如何实时准确地监控刀具的磨损状态,成为保障生产节拍、提高生产效率和产品质量的关键问题。在数控批量加工过程中,刀具磨损不可避免,当刀具磨损较为严重时会对工件质量产生影响甚至引起机床事故,因此需要在刀具发生严重磨损前对其进行更换或刃磨。但是如果在刀具的剩余寿命较多时便进行换刀则会降低刀具的使用经济性,提高企业生产成本,在批量加工过程中还会造成生产节拍中断,生产效率降低等问题。因此通过对刀具磨损状态的准确识别来为换刀策略提供依据是非常有必要的。在如今大力推进工厂智能化和自动化的时代,可以通过实时监测与刀具磨损相关的物理信号的方式来识别刀具所处磨损状态,本文在了解了现阶段国内外对刀具磨损状态辨识研究的基础上,进行铣削加工试验,并以振动和力信号为监测信号,对刀具磨损状态分阶段进行辨识。本文的主要工作内容如下:(1)搭建实验台,开展切削试验并采集数据。研究了切削过程中各类信号的特点,最终选择以力信号和振动信号为监测信号,搭建了铣削加工试验平台,设计了四因素三水平正交试验,通过试验采集了刀具从新刀至磨钝的振动信号和力信号,以及刀具磨损量和工件表面粗糙度信息。(2)提出了结合工件表面质量的刀具磨损阶段划分方法。研究了刀具磨损机理,制定了刀具磨钝标准,并结合试验情况,通过后刀面磨损带宽度VB值及其对工件表面粗糙度Ra的影响分析,将刀具磨损划分为磨损初期、稳定磨损期、急剧磨损期和刀具失效期四个磨损阶段。(3)提出了基于多维特征融合的刀具磨损阶段辨识方法。基于试验数据和刀具磨损阶段划分,提取了刀具磨损的时域、频域和时频域特征并进行融合,再利用主成分分析PCA对融合的特征向量进行降维优化,构建了刀具磨损状态表征模型,在此基础上进一步构建了基于最小二乘支持向量机LS-SVM的刀具磨损状态辨识模型,并利用粒子群算法PSO对模型中识别率影响大的参数c和g进行了优化,提高了辨识精度。(4)提出了基于深度学习网络LSTM的刀具磨损阶段辨识方法。针对传统机器学习在特征提取时需要依靠个人经验,以及模型只根据当前的信息来对刀具磨损状态进行识别等问题,提出了基于深度学习网络LSTM的刀具磨损状态辨识模型并优化了模型参数,以振动和力信号的原始数据为输入,通过设计三层网络结构实现刀具磨损特征的自动提取和辨识,测试结果表明该模型的识别精度优于传统机器学习模型。"
1034,半监督稀疏拉普拉斯支持向量机研究,"支持向量机(Support Vector Machine,SVM)是基于统计学理论的一种通用有监督机器学习算法。支持向量机实现了结构风险最小化原则,具有高拟合度、参数较少、推广能力强以及全局最优等优点。支持向量机作为解决小样本非线性问题的有效工具之一,一直以来都备受研究人员的关注。然而,实际获得的数据往往是无标签的。由于其易于获取,因而数量庞大。给所有的数据都打上标签是一件费时又费力的事。如何能有效地利用少量有标签样本和大量无标签样本,是半监督学习要考虑的问题。拉普拉斯支持向量机(Laplacian SVM,LapSVM)把拉普拉斯正则引入到支持向量机中,成功将支持向量机从有监督学习领域延伸至半监督学习领域,实现了支持向量机对无标签数据的利用。真实数据包含着各种噪声,例如冗余特征或样本等,这些噪声将对模型性能产生负面影响。为了消除噪音或冗余的影响,生成一个稀疏决策模型来实现数据约减则显得尤为必要。为了解决拉普拉斯支持向量机不具有稀疏决策模型的问题,本文对稀疏拉普拉斯支持向量机进行了研究,并应用到分类、降维和去噪等典型半监督学习任务中。论文的主要研究工作和创新点如下:(1)基于拉普拉斯支持向量机,本文引入L1范数正则,提出一种半监督的稀疏支持向量机算法―L1范数拉普拉斯支持向量机(L1-norm Laplacian Support Vector Machine,L1-norm LapSVM)。与拉普拉斯支持向量机不同,L1范数拉普拉斯支持向量机的求解是在原空间中进行的。此外,目标函数中Hinge损失函数和L1范数正则同时保证了解的稀疏性。该方法可以同时实现特征约减与样本分类。也就是说,该方法既可以被视作是一种分类器,也可被认为是一种特征选择方法。实验证明了在对比的线性方法中,L1范数LapSVM具有较好的性能。(2)为处理非线性数据,通过引入高斯核来拓展线性半监督稀疏拉普拉斯支持向量机算法,提出了核L1范数拉普拉斯支持向量机(Kernel L1-norm Laplacian Support Vector Machine,Kernel L1-norm LapSVM)。核L1范数拉普拉斯支持向量机的目标函数中也包含了 Hinge损失函数和L1范数正则,因此模型的稀疏性也得到了保证。该方法可以同时实现样本约减与样本分类。实验证明了在对比的非线性方法中,核L1范数拉普拉斯支持向量机具有较好的分类性能。(3)提出了一种半监督的流形保持图约减算法,利用该算法可以对数据进行预处理。当样本数量比较大时,核L1范数拉普拉斯支持向量机有很高的计算复杂度。为了解决这个问题,我们提出了 SMPGR以及它的核版本进行数据预处理以提高样本质量。进行预处理后,既可以将样本规模缩小,又能保持住数据的原始结构信息。把该预处理方法和半监督稀疏拉普拉斯支持向量机相结合,进一步实现了样本数据的约减,实验也验证了其在半监督学习中的有效性。"
1035,基于机器学习的胃食管反流病中医证候分类的应用研究,"目的胃食管反流病(gastro-esophageal reflux disease,GERD)为消化系统常见病、多发病。随着对流行病学特点,典型症状表现及生活质量影响的深入研究,有关发病机制及治疗方法的探索已成为当下热点。针对本病易复发、难治性、周期长的特点,运用中医理论指导用药,临床疗效显著。然中医学之精髓在于“辨证论治”,归根结底是“证”的判别,辨证准确性是临床疗效的保障。但症状的隐匿性及重叠性增加了辨证的难度,又受个人主观性的制约,导致辨证的结果存在差异。因此,本研究以胃食管反流病为切入点,借鉴循证医学理念,运用统计学方法,对胃食管反流病的中医证候、证素分布及流行病学特点进行研究,得出本病的证候分布特点。并在此基础上,筛选肝胃郁热证及中虚气逆证临床病例,应用支持向量机、神经网络及自动编码器分别构建GERD智能辨证模型,比较证候预测的准确性。方法本论文由文献综述和临床研究两部分组成。文献综述包括三个部分。第一部分为“胃食管反流病的中医学认识”,主要论述胃食管反流病的中医病名、病机、辨证论治等方面。第二部分为“胃食管反流病的西医诊疗进展”,从胃食管反流病的流行病学、病因、发病机制及诊疗等方面进行探讨。第三部分为“机器学习技术在中医证候研究中的应用”,重点为机器学习于中医学证候学中的应用及中医智能化研究进展。临床研究部分:基于统一的中医证候量表,于东直门医院收集病例233例。将所收集的一般信息及四诊资料导入Excel,基于SPSS 25.0统计软件运用聚类分析、因子分析方法,得出胃食管反流病患者常见的中医证素、病性和证候分布规律。最后,从中筛选符合肝胃郁热证、中虚气逆证共98个样本,两类各49个样本,并按照类别之间1:1比例,全部数据的70%作为训练集,30%作为测试集。应用支持向量机(Support Vector Machine,SVM)、神经网络(Neural Networks,NNs)和自动编码器(Autoencoder)分别构建GERD智能辨证模型,比较证候预测的准确性。结果(1)本课题共收集233例GERD患者,其中男性108例(46.4%),女性125例(53.6%),男女比例为:0.86:1;年龄最小为20岁,年龄最大为79岁,平均年龄为52.35±12.33岁,年龄与性别分布相关(P<0.05);反流性食管炎167例(71.7%),非糜烂性反流病62例(26.6%),Barrett食管4例(1.7%);国家机关工作人员多发(29.5%),冬季(28.2%)、春季好发(33.8%)。饮食、情志、气候为发病的诱因,其中饮食偏嗜以甜食39例(16.7%)、辛辣30例(12.9%)、进食快25例(10.7%)居多;情志以急躁易怒(38.2%)、焦虑(29.2%)、忧虑(29.2%)为甚。GerdQ评分≥8分的人数(72.1%)远高于<8分的人数(27.9%)。纳入患者睡眠质量尚可(91.4%),未发现与疾病及其亚型的相关性。(2)相关性研究中,Hp感染情况、BMI指数与疾病亚型分布有关(P<0.05)。(3)胃食管反流病的证型主要有以下10种:类肝胃郁热证、类胆经郁热证、类胆胃不和证、类胃火炽盛证、类肝脾不调证、类脾胃湿热证、类气郁痰阻证、类脾失健运证、类中虚气逆证、类肺脾气虚证。病位证素在脾、胃、肝、胆、肺,病性证素中实证以气滞、湿热、热为主,虚证以气虚、阳虚为主。病机关键为虚、滞、湿、热。(4)98例GERD患者中,肝胃郁热证、中虚气逆证的畏寒、疲乏、腰背酸痛、胃中漉漉有声、排便不爽、胸闷、心烦、脉细、脉弦症状比较,差异具有统计学意义(P<0.05)。(5)在相同训练、测试样本数据下,SVM、NNs及Autoencoder三种算法对胃食管反流病肝胃郁热证及中虚气逆证的识别准确率分别为78.3%和79.2%和79.2%。结论(1)运用聚类分析法和因子分析法,归纳GERD中医证型为以下10种:类肝胃郁热证、类胆经郁热证、类胆胃不和证、类胃火炽盛证、类肝脾不调证、类脾胃湿热证、类气郁痰阻证、类脾失健运证、类中虚气逆证、类肺脾气虚证。上述方法客观真实的反映了GERD的中医证候分布和证素特点,为本病的诊治提供了参考。(2)NNs及Autoencoder降维基础上的NNs模型具有很好的诊断、预测能力,机器学习技术应用于GERD辨证模型的构建具有方法学上的可行性。"
1036,气道内窥OCT图象分割算法研究,"呼吸系统疾病是全世界范围内流行的疾病,有相当高的发病率和死亡率,早期诊断和干预对降低死亡率有积极意义。早期诊断的一个重要指标是气道重塑,而目前对其研究的一个主要障碍是无法准确地观察气道的重塑变化。光学相干层析成像技术(Optical Coherence Tomography,OCT)是一种新的成像技术,能以接近组织学的分辨率观察到气道表面2～3mm深度的组织结构。利用OCT成像系统对气道成像,通过分割算法可以准确地量化患者气道重塑的程度,检测吸烟者早期癌前病变,纵向追踪疾病的进程并有助于评估当前和未来治疗方法的有效性。本文对目前常用的医学图像分割算法进行了研究,并将相关算法用于分割气道OCT图像,通过分析相关的实验结果选用图论和动态规划算法进行改进用于气道OCT图像分割。首先根据气道OCT图像特点和存在的问题对图像进行预处理:针对图像中存在的伪影、灰度不均匀等问题提出了基于A-scan的图像增强方法,该方法能较好的去除图像中的伪影并增强图像的对比度;为了便于分割,利用了塑料鞘、肺泡和软骨的位置将气道壁内、外边界限定在一个较小的感兴趣区域内。其次,由于气道OCT图像存在边界崎岖、干扰因素多的问题,原始图论结合动态规划算法分割准确率偏低,为了提高分割的准确率,提出了基于灰度信息的边界加权图论算法。该算法将灰度信息加入权函数中,能有效的分割出干扰因素多、崎岖的气道组织边界。最后,根据OCT采集的相邻图像组织结构相似的特点,提出采用序列图像分割方法,即利用相邻图像分割信息来获取目标边界的感兴趣区域。将所提算法在72幅气道OCT图像上进行分割测试,实验结果表明,本文提出的算法分割结果与手动标注的边界误差在7.2个像素以内,优于传统分割算法结果。用序列图像分割方法分割气道壁外边界的结果与手动标注误差在5个像素左右,其结果优于单幅图像分割结果,而且,其算法分割的速度和稳定性也优于单幅图像分割算法。"
1037,基于机器学习的气象因素对小麦产量影响的分析预测,"近年来,随着机器学习技术的不断完善,依据气象数据来预测小麦产量也逐渐有了新的发展。针对传统方法预测小麦产量的局限性,运用机器学习预测核心算法来提高小麦产量的预测精度,将再一次推动气象预测领域的进步。机器学习回归算法通常用于处理“函数逼近”问题,通过特征提取筛选出关键影响因子来构建预测模型。本文基于机器学习回归算法对小麦各性状及产量的气象预测技术进行研究。以周口市农业科学院遵循国家区试标准的小麦生育期各性状及产量的农业数据,以及相对应的基于地面气象观测点采集的气象数据为研究对象,共收集2007至2017年近10年间的部分数据内容,经数据预处理、显著性检验等操作,研究基于机器学习算法的小麦产量气象预测模型,实现对小麦的气象综合分析。文章通过皮尔逊相关分析来筛选关键影响因子,具体包括影响小麦产量的关键性状因子相关分析、影响小麦性状的关键气象因子相关分析和影响小麦产量的关键气象因子相关分析。在机器学习回归算法的基础上,建立基于K近邻、支持向量机回归、线性回归、决策树、随机森林、梯度提升树六种算法的预测模型,来实现小麦产量及其各性状的气象预测。经调参后,分析不同模型的预测效果,通过均方误差和均方根误差等性能指标展开评价。结果表明,使用线性回归模型效果较好,预测模型的均方根误差仅有0.027058。通过学习曲线对模型进行拟合判断,得出线性模型存在“过拟合”问题,引入岭回归和套索回归两个惩罚线性回归模型,并对其进行超参数遍历,选取alpha为0.00009时的Lasso模型进行小麦产量气象预测,此时模型均方根误差仅达0.000159。说明在小麦产量的气象预测方面的研究使用机器学习算法是可行的,且能够有效提高预测的精度,减少误差。"
1038,农业舆情监测与分析系统研究,"随着互联网的迅速发展,我国的互联网现已成为当今最大的最多样化的传播媒介以及舆论平台。而在这个过程当中,农业民情及其舆论的集合产生了农业舆情。在我国,农业舆情即为“三农”舆情问题,在十九大中习近平强调,“三农”问题是关系国计民生的根本性问题,必须始终把解决好“三农”问题作为全党工作重中之重。社交网络当今已经是舆情突发的集中地带,面对多种多样的突发状况,如果缺乏对于社交网络的监测,就很容易让相关部门处于被动状态。所以针对社交网络的分析可以很好的弥补其不足,防止负面舆论的过度发酵而导致经济损失和相关部门的被动处境,对提高针对农业网络舆情监测的能力有重要的意义。因此对于农业舆情的监测与分析成为了公共领域的一个研究问题。在农业领域数据获取方面,现有的舆情监测系统大多针对农业门户网站或论坛农业板块作为研究重点,对社交网络的研究工作较少;在农业舆情发现方面,对于社交网络领域的舆情热点研究只是针对人工选取的问题做验证,并没有应用在社交网络环境对于社交网络的舆情热点研究较少;在舆情判断方面,目前的研究数据主要来源于人工选择,并不能满足如今网络环境多变的需求。针对舆情的突发性和现有农业舆情研究的局限性,使用网络爬虫技术对新浪微博和今日头条进行信息采集,以便及时获得社交媒体信息。针对网络舆情的难控制特点采用文本处理和分析技术对其进行处理,对网络文本进行文本分类,然后利用聚类标引不同农业热点主题,利用情感词典方法进行情感分析,方便对农业舆情做出对应的处理。最后对农业舆情监测与分析系统进行设计与实现。本文主要进行了以下几个研究内容:(1)针对社交网络文本,设计了基于贝叶斯的社交文本分类方法和基于kmeans的农业舆情主题标引。构建爬虫器并采集社交文本,分析文本信息利用贝叶斯算法构建出社交文本分类器并进行优化和验证,通过实验得到准确率达到96%其最后进行主题标引来发现社交文本中的农业热点。(2)设计了基于情感词典的农业舆情分析方法,利用波森情感词典构建了农业领域的情感词典、程度副词词典和否定词词典,并利用情感词典方法进行情感计算,经过验证其召回率、正确率、f1值至少达到85.5%,宏平均至少达到83%,表明本文采用的情感分类方法具有很好的效果;利用无监督学习达成了自动词典更新,满足情感词典对于时效性的需求。(3)设计并实现农业舆情监测与分析系统的原型系统。设计并实现了系统的采集模块,处理模块和分析模块。系统通过可爬取的社交媒体信息进行舆情处理与分析,将舆情结果反馈。系统采集的数据同时也会经过无监督学习扩充系统的词典。本文通过针对社交媒体进行农业舆情的处理和分析,设计并实现的农业舆情监测与分析原型系统,扩展了农业舆情研究的范围,对农业舆情的引导与控制有一定的应用价值。"
1039,基于LDA的煤矿事故调查报告主题发现研究,"近年来,我国重特大煤矿安全事故频发,其造成死伤人数多,经济损失大,影响极其恶劣,引起广大社会群众关注。事故发生后,由相关政府部门牵头,成立了事故调查小组,聘请有关专家一同对事故进行调查,出具权威、专业的事故调查报告。报告中包含有大量关于事故的隐患信息和整改措施建议信息。本文以2012年到目前为止,各省市煤矿安全监督局公布的44份重大煤矿事故调查报告为数据来源,对其进行挖掘分析。首先简介了狄利克雷模型,并说明其与传统文本挖掘方法区别,接着对挖掘过程进行阐述:数据清洗、分词、过滤停止词、建立“文档―词语”矩阵。并对事故报告的基本信息通过提取高频词汇和逆文档概率的关键词进行描述,进行可视化展示;对事故报告的隐藏信息,采用狄利克雷主题模型进行主题挖掘,发现事故调查报告中大致包含有隐患主题、处罚主题以及整改措施主题三个主题内容。经过机器学习后得到的隐患主题,通过主题强度比较,最终分析得到关于作业人员与安全管理方面的隐患,在事故中占据更大比例,需要作业人员、管理人员和监管人员特别注意,在排除隐患时,应该优先解决作业人员的不安全行为和完善企业自身管理;对于处罚主题,在调查报告中,对相关责任人员的处罚信息包含有人员的不安全行为的行为记录,对处罚信息的主题分析实质上是对隐患主题的补充;对于整改措施主题,关键的是煤矿应完善管理制度,加强管理工作,监管部门应落实法律法规,严格把控煤矿企业复工复产。最后对上述三个主题内容进行可视化展示,便于更加直观理解各个主题内容,和主题与主题词之间的联系。狄利克雷主题模型实质上是将机器学习和概率模型的综合挖掘模式,将之应用于调查报告中,利用文章最小构成单元――“词语”,用一种半自主无监督的方式对调查报告进行主题提取和分析。这种方法,在读者面对大量事故调查报告时,它可以提供一种研究事故调查报告,找到事故报告主要主题、关键隐患等重要信息的一种新思路。"
1040,光电成像系统激光干扰效果分析与评估技术研究,"激光因其单色性、方向性、高亮度等特点有望被应用于光电成像系统的对抗过程中,因此开展激光对光电成像系统的干扰效果评估技术研究,具有重要的军事价值和现实意义。本文从激光干扰图像质量评价和激光干扰对目标检测的影响两个角度展开,具体研究工作可以归纳为以下几点:目前,全参考的激光干扰图像质量评价算法大部分都需要预先知道干扰光斑和目标的位置信息,使得评估处理时受到先验知识和预处理方法的制约。针对该问题,本文提出了一种基于卷积特征相似度的激光干扰图像质量评价算法(CNNSIM),通过分析激光干扰前后图像在卷积网络中的输出特征变化,利用特征的层次性和对遮挡的敏感性,对干扰图像中关键信息的被遮挡程度进行评价,避免了目标/光斑位置信息的输入需求,仿真实验验证了不同场景下新评估算法的有效性。针对实际应用中参考图像难以获得的问题,本文首先从被遮挡信息的预测处理入手,对马尔科夫随机场估计算法(MRF)进行了提速改进,实现了光斑遮挡区域信息的实时估计;然后结合自然场景中激光干扰图像的统计特点,采用机器学习的方法,提出了一种基于自然场景统计和遮挡区域信息估计的无参考评价算法(NSSIE)。与传统算法相比,新算法不需要参考图像,并能较准确地反映激光干扰图像的质量损失。大规模的仿真实验验证了新评价算法的有效性。另一方面,本文也从对目标检测影响的角度进行了干扰效果分析方法的研究。首先从目标遮挡率、目标相似度两个方面系统的分析比较了激光干扰对Faster-RCNN和YOLO-V3两种检测算法的影响。然后,提出了一种面向目标的干扰光斑有效干扰区域划分方法(TOEDZ),该方法利用仿真图像、目标与模板相似度、目标检测算法,确定目标在该检测算法下的有效干扰相似度阈值,将其迁移到其他光斑图像的干扰有效区域划分中,大规模的仿真实验验证了划分的有效性。"
1041,淀粉相变人工智能监控体系的构建及应用研究,"作为自然界第二丰富的天然高分子原料,淀粉及其衍生物已广泛应用在食品、医药、纺织和化工等领域。相变是淀粉体系中组分形态、超分子结构、多组分构效关系和行为响应的直观表达,可为新产品的研发及品质改善提供预测和理论指导。热台-偏光显微镜观察法是一种对淀粉相变行为进行在线研究的重要方法。然而传统的研究手段主要是通过在线数据采集和线下人工处理的方法对相变进程中淀粉的颗粒形态、溶胀能力、糊化特性等变化进行定量分析,存在时间消耗长、主观判定误差大等缺陷,而且无法对关键转变点进行在线即时界定和精准评估。如何使用更多元化的定量分析指标与智能化分析手段相结合的方式,实现对淀粉结构和相变行为的深入表征及调控已成为国内外研究的热点及突破口。本文在传统的显微镜观察和表征技术基础上,开发和设计出基于淀粉特征变化的人工智能算法模型(神经网络、边缘检测和数学形态学处理),通过研究相变过程中淀粉形态结构和光学结构特征的变化,构建出可对淀粉相变行为进行在线检测和结果评估的新型研究方法和体系,进而实现反应过程中淀粉形态结构和反应行为精准调控,主要研究结果如下:1.机器学习在淀粉溶胀特性研究中的应用:由于淀粉在正常光下呈现独特的透明、不规则颗粒形态,传统图像处理技术和软件无法对淀粉的颗粒形态和溶胀特性进行定量分析。本文采用Canny边缘检测和形态学处理两种机器学习算法联用的方式,对淀粉外部轮廓进行精准识别,并通过检测整体颗粒面积变化,建立了淀粉溶胀进程的智能化评估体系。2.淀粉糊化特性智能检测体系的建立:基于淀粉糊化过程中双折射特征的变化,将热台-偏光显微观察技术与卷积神经网络结合,开发出可对双折射特征在线检测、定位和分类的卷积神经网络算法模型Starch-SSD,利用该算法模型对淀粉的转变温度及糊化度等指标进行人工智能检测,相关评估可在4 s内完成。3、淀粉相变过程中在线调控体系的设计及构建:在淀粉溶胀进程智能化分析体系和新型淀粉糊化行为评估方法Starch-SSD的研究基础上,结合模糊逻辑控制器理论将传统的热台温度控制系统改进和优化,开发出可对淀粉糊化程度(Degree of gelatinizaiton,缩写DG)进行在线调控的DG控制体系,并对不同反应程度淀粉的颗粒形态、相变特性对比分析。"
1042,基于表情识别的交互康复训练系统,"面部表情识别(Facial Expression Recognition,FER)是根据已有的情感认知理论对人脸图像进行情绪识别的过程。在日常沟通交流中表情能够传递丰富的信息,如能理解交互者的情感状态,则能使对话更顺利;同样地,基于计算机、算法的发展应运而生的人-机交互(Human-Computer Interface,HCI)系统,如能感知人类的情感状态,则能够增强沉浸度,显著提高HCI交互体验。交互体验的提高如应用于康复训练,则可提高认知障碍者的情绪认知能力。本文以此为出发点,通过对具有实时性、计算量小的表情识别算法展开研究,并结合FER和情绪认知障碍者的认知特征,搭建HCI交互康复训练系统。研究内容主要分为以下三个方面:其一,采用深度可分离卷积运算、多尺度信息感知运算结合特征拼接运算,提出Concat_Xception轻量级的卷积神经网络(Convolution Neutral Network,CNN)。通过深度可分离卷积、全局平均池化层代替全连接层以减少网络参数;学习聚合运算后的特征通道的权值信息以获取更具表征能力的特征;并引入全局信息聚合的特征拼接运算以辅助softmax分类决策。网络在facial expression recognition challenge dataset(Fer2013)数据集取得70.13%的准确率。其二,基于Concat_Xception算法,在自然场景下的低算力平台搭建实时的FER系统。采用方向梯度直方图(Histogram of Oriented Gradient,HOG)算法实现人脸识别,再调用Concat_Xception算法模型实现表情识别,最后FER系统在NVIDIA Jetson TX2上取得6.52fps,基本满足实时性的要求。其三,将FER系统结合情绪认知障碍者(例如自闭症)的情绪特征,提出具有交互性的康复训练范式。参考康复师意见设计情绪诱因实验,分析患者的表情特征;再结合FER系统及情绪干预课程设计实验范式,并部署于Jetson TX2、Android移动端,以期能辅助医师进行康复训练。对情绪康复辅助训练系统的研究,通过分析正常人的交互测试数据验证了系统的可行性,其中通过可视化的表情模仿界面、系统的反馈信号都能提高交互者的积极性。"
1043,基于机器学习的股市行业轮动量化投资策略研究,"近年来,随着金融科技的飞速发展,依托量化模型算法与人工智能进行自动交易成为一种全新、高效的交易方式。与西方成熟的资本市场相比,A股市场长期存在着机构化程度低,市场有效性较弱以及行业风格变化特异性强的市场特征,这为量化交易提供了肥硕的土壤。机器学习作为人工智能重要的分支,其已经在诸多领域如图像识别、自然语言处理被证明是针对模糊非线性数据进行建模的强有力工具,而资本市场是一个低信噪比、复杂的非线性系统,本文将时下热门的机器学习算法应用于量化投资策略建模,利用“机器”辅助探索资本市场那些不为人知的非线性特征,深化对资本市场的理解并辅助投资者投资决策。本文主要研究A股市场行业板块的风格轮动,首先,本文研究A股市场行业轮动的基本特征,并在此基础上构建了可能会带来超额收益的因子,通过对四大类因子研究测试,选出了七个相对有效且相关性低的因子作为机器学习输入变量的备选特征因子。其次,本文通过理论分析和实证测试构建了支持向量回归、神经网络的监督机器学习模型以及多因子模型,模型均能很好地解释行业收益率并获取有效的超额收益。之后,为了综合各个模型的预测能力来获取更多的超额收益,利用Stacking集成学习思想将上述三个子模型集成为一个复杂有效的机器学习模型,最终得到了月度胜率为59.26%,年化收益15.26%,多空对冲夏普比率为1.06的集成学习策略,通过绩效分析,集成后的模型无论在收益指标还是风险指标上都有了超越子模型的良好表现。最后,本文介绍了自主开发的交互式回测平台APP,为策略的回测展示和实际投资提供了便利。本文一方面研究了A股市场行业风格轮动的基本特征,比较了其与个股市场的差异并构建了有效因子库,使投资者能在技术面和基本面的视角下更好地理解市场行业风格轮动。另一方面,本文在构建交易策略的过程中使用了前沿的机器学习算法,并通过自主开发的可视化交互式回测平台展示了优秀的回测结果,为投资者的实际投资提供了指导。"
1044,基于~1H-NMR和机器学习的檀香、沉香快速识别模型建立及化学组成分析,"快速识别模型是指借助计算机手段,具有快速真伪鉴别效用的模型。由于檀香和沉香的珍稀与名贵,加之目前市场上流通的样品质量参差不齐,真假混杂,因此急需对其进行快捷而有效的鉴别。本研究利用核磁共振氢谱技术,分别对巴里黄檀,交趾黄檀,绒毛黄檀,奥氏黄檀,刺猬紫檀,大果紫檀和檀香紫檀等7种国标檀香,及胶漆树和染料紫檀等2种非国标檀香样本构建~1H-NMR特征图谱,利用机器学习算法构建快速识别模型,其中包括以简单计算样本间欧氏距离的k最近邻算法,以信息增益率为基础的决策树算法和以Logistic回归结合线性核函数为原理的支持向量机算法,筛选其中表现最佳的模型,并添加Ada Boost算法提高模型的准确率。并结合超高效液相色谱-质谱串联技术,对不同种类的檀香醇提液化学成分进行鉴别,总结其质谱裂解规律。结果显示,基于决策树法的檀香识别模型具有较好表现,且模型易解释,而Ada Boost决策树模型对训练集和测试集的正确率均达95%以上。此外,利用UPLC/Q-TOF-MS对9类檀香共鉴别出183个化合物,其中已知化合物为99个,未知化合物为84个。结合UPLC/Q-TOF-MS鉴定结果,本文还对9种檀香的~1H-NMR和~（13C）-NMR图谱进行信号归属,共归属得到14个化合物。基于上述结果可知,本研究中的檀香甲醇提取液中富含黄酮类成分。分析构建模型贡献率较大的变量可初步推断,构成檀香间差异较大的原因如下:第一,应是黄酮类化合物C3结构上H的变化,即黄酮母核中芳香基与C3结构的不同连接部位所致;第二,应是黄酮母核中芳香基连接的简单烷基的不同。本研究建立了基于~1H-NMR和决策树算法为基础的快速识别模型方法,利用沉香对该方法进行考察。选取4种35批次,共35个沉香及其混淆品样本建立沉香的快速识别模型,并将其与聚类分析,主成分分析和偏最小二乘判别分析等分类模型进行对比。结果显示,决策树模型对训练集和测试集的正确率分别达90%和85%以上。通过比对可知决策树模型的分类性能远远高于上述三类模型。分析构建模型贡献率较大的变量可初步推断,构成组间差异较大的一个原因应是2-(2-苯乙基)色酮类成分的含量高低,沉香组的2-(2-苯乙基)色酮类成分含量较高,而非沉香组的2-(2-苯乙基)色酮类成分含量较低。"
1045,基于机器学习的车辆行程时间影响因素分析及预测,"随着社会的进步和经济的发展,汽车保有量不断提高,城市道路的汽车拥堵现象日趋严重。智能交通系统是道路交通的重要组成部分,当前,我国智能交通处于发展阶段,智能交通系统不断完善。运用机器学习技术对车辆行程时间数据进行分析,可以更好了解影响车辆行程时间的因素,预知短时间内的交通状况,从而可以推荐最佳通行路线,提高用户驾驶体验,节省社会成本。本文以国际数据挖掘领域顶级赛事KDD CUP 2017数据集作为实证研究数据,利用机器学习技术,对影响车辆行程时间的众多要素进行分析。在此基础上,提出一种多模型融合算法,这种算法可以获得更高的车辆行程时间预测精度。具体研究内容包括:(1)数据清洗与探索性分析。对车辆行程时间数据中的异常值和缺失值进行探索分析,识别异常并将异常值看作缺失值进行合理填补。根据清洗处理后的数据,构造三大类特征,包括时间特征、道路特征和天气特征。(2)分析车辆行程时间的影响因素。根据构造的特征变量,分析这些变量对车辆行程时间影响的重要程度。使用随机森林(RF)、一般梯度提升算法(GBM)和极端梯度提升算法(Xgboost)三种模型对车辆行程时间的影响因素重要性进行综合分析,按照重要性排序对比三种模型的差异,结合实际情况得出影响车辆行程时间的主要因素。(3)车辆行程时间预测。选用K-近邻、随机森林、GBM、Xgboost模型四种算法,分别建立车辆行程时间预测模型,并对这些模型通过加权的方法进行融合。采用MAE、RMSE、MAPE三个评估指标对模型的预测效果进行对比分析。结果表明:单个模型中,Xgboost相对优于其他模型,加权融合模型的预测效果优于单一模型,评估指标更优,更适用于车辆行程时间的短时预测。"
1046,基于机器学习的金融产品推荐算法研究,"现如今,推荐系统无论是在电子商务还是在社交网络都占据着举足轻重的位置.而传统的以银行为代表的金融机构在个性化推荐方面的应用,较之于互联网行业略有不足.本文根据基于机器学习方法的隐语义模型,并结合用户的特征,生成一种融合用户特征的改进隐语义模型,并对金融产品进行推荐.在解决冷启动问题时,可以通过用户的人口统计学特征给新用户进行产品推荐.该方法计算用户的特征关于物品的兴趣度,将所有特征关于物品的兴趣度进行累积,从而得到用户关于物品的兴趣度.而隐语义模型(Latent Factor Model,LFM)是通过将物品分类,计算用户关于类的兴趣度_(,6)),和物品关于类的权重_(4),6)),将二者相乘得到用户关于物品的兴趣度.两种推荐方法的结合点正是用户关于物品的兴趣度.本文将基于用户特征计算出来的用户关于物品的兴趣度与LFM计算出来的兴趣度进行线性组合,二者的权重则利用用户的活跃度进行衡量.利用训练出的模型对目标用户兴趣度较高的前个物品进行推荐(TopN).通过在Movielens数据集和银行理财产品数据集上的实验测试,融合用户特征的改进隐语义模型在样本量较少和应对用户冷启动问题时,具有更好的推荐性能."
1047,基于语义分割的单木三维重建与参数提取,"树木参数是生态系统生产力模拟、碳循环研究、林业管理等领域应用的重要支撑。传统手工测量树木参数方法大多费时费力且通常具有破坏性。基于2D光学遥感数据的树木参数提取方法通常仅能够提取树木顶部表面参数。地面激光雷达(Terrestrial Laser Scanning,TLS)为提取树木参数提供了一种快速有效的技术手段。为提高树木参数准确度和降低参数提取过程的计算复杂度,研究人员通常需要分割树叶和枝干(即语义分割)并对枝干进行三维重建。本研究在树叶与枝干分割、枝干三维重建和枝干参数提取三个方面开展了以下工作:(1)将单最优尺度分割方法推广为多最优尺度分割方法。首先,在预定义的备选尺度集中为每个数据点选择多个最优尺度。其次,在最优尺度集上计算12个常用的3D和2D几何特征。最后,提取到的几何特征被用于训练一个线性判别分析(Linear Discriminant Analysis,LDA)模型并进行树叶和枝干分割。与单最优尺度分割方法相比,多最优尺度分割方法分割准确度更高。与随机多尺度方法相比,多最优尺度方法在尺度较少的情况下稳定性更好。(2)改进了枝干三维重建方法。首先,采用K近邻(K-Nearest Neighbors,KNN)区域增长并结合密度聚类将枝干TLS数据切割成为类圆柱状数据块。其次,将这些类圆柱状数据块的几何质心作为枝干骨架点。再其次,构建每个枝干骨架点到最近邻的10个枝干骨架点的邻接图并采用最小生成树(Minimum Spanning Tree,MST)算法提取枝干骨架图。最重要的是,利用主成分分析(Principal Component Analysis,PCA)将给定类圆柱状数据块变换到另一个正交空间,变换过程中协方差矩阵的特征值被用于计算枝干半径。最后,利用圆柱拟合方法重建枝干三维模型。实验结果表明改进的枝干三维重建方法较好地重建了枝干三维结构。与SimpleTree软件重建的枝干三维模型相比,改进的枝干三维重建方法抗噪声性更强、准确度更高(尤其是细枝)。(3)基于重建的枝干三维模型提取了每棵实验树木的树高、胸径、枝干体积和枝干表面积。与实测值相比,我们的方法提取的枝干表面积平均误差为28.72%,其余参数的平均误差在8%以内。SimpleTree软件提取的树高和胸径的平均误差在6%以内,提取的枝干体积和枝干表面积平均误差分别高达246.35%和185.24%。与SimpleTree软件提取的参数值相比,我们的方法提取的胸径、枝干体积和枝干表面积更加准确。数据完整性和噪声对我们的方法和SimpleTree软件提取的参数的准确度影响都很大。"
1048,基于机器学习的教学评价模型的研究与实现,"教学评价是针对教师教学和学生学习价值的判断,已经成为高校教学管理和教学过程中的重要组成部分。常见的教学评价体系众多,大多数是评价教师的行为表现,而学生的学习过程及效果很少提及。同时,实施教学评价的工作流程比较繁琐,往往需要完成大量的数据计算任务。因此如何采用现代科学技术建立完善、客观可行的课堂教学评价体系和优化评价流程是亟需解决的重要问题。本文从构建以学习为中心的高校教学评价体系出发,通过采用数据相关性分析、关联规则等方法优化了学生教学评价指标。同时,将机器学习算法引入教学评价过程中,构建教学评价模型,实现教学评价过程的自动化。首先,针对获取的教学评价数据集,采用线性回归方法和基于密度的离群点检测方法进行了异常数据的清洗。为验证评价属性的独立性,本文提出一种基于关联规则算法的相关性分析方法,根据规则的置信度判断属性间的依赖关系,然后结合属性间的相关系数确定出相关性较强的特征项,去除冗余项,优化了评价体系。其次,提出基于加权朴素贝叶斯算法的教学评价模型。根据不同属性对评价结果的影响程度,提出一种利用类属性的相关概率确定各个评价属性的权值的方法,为各评价指标设置相应的权重,从而构建出适合教学评价的分类模型。最后,采用加权贝叶斯增量学习方法,解决新增样本分批抵达的问题。通过这一策略不必耗时重新训练旧样本数据,只需根据新样本数据调整模型参数。为验证算法的可行性,本文收集某高校学生对课堂教学的评教数据进行实验。实验结果表明,采用加权朴素贝叶斯算法构建模型进行分类的准确率可达到75%,相比传统的贝叶斯分类算法,平均准确率可提高3%左右。同时,面对数据的快速增长,增量学习方法不仅可以完善分类模型的分类性能,也可提高算法的时间效率。该教学评价模型的构建过程对教育信息化领域研究具有较强的理论与实践参考价值,也可提高实际教学评价的工作效率。"
1049,融合词汇语义的深度学习电子病历诊断模型研究,"电子病历(Electronic Medical Record,EMR)是医疗知识高度密集的数据集合,对EMR数据进行分析挖掘能产生有价值的结果。目前,电子病历的二次应用集中在辅助医疗诊断,以提高临床诊断的准确率。由于信息安全和隐私问题,庞大EMR数据集构建存在问题,再加上深度学习的先验知识缺失问题,导致以卷积神经网络(Convolutional Neural Networks,CNN)为代表的深度学习模型在EMR辅助诊断上的准确性还远未能达到实用水平。针对上述挑战性问题,本文研究融合词汇语义的深度学习儿科EMR诊断模型。分别提出词汇语义向量(LSV)和词汇语义预判模态(SDG)两种策略来提升基于CNN的EMR诊断模型性能。总结来,论文的主要研究内容和创新工作如下:1.基于LSV-CNN的EMR诊断模型研究.针对以word2vec为代表的基于大数据驱动的词嵌入向量缺少词法特征和知识表示,难以真正理解EMR词汇语义信息的缺陷,而提出一种融合词汇语义向量和词嵌入向量的EMR诊断模型LSV-CNN(Lexical Semantic Vector Convolutional Neural Network)。该模型将词汇语义向量和word2vec词嵌入向量进行拼接合成,形成新的词向量表达作为深度学习模型的输入,以获得更加丰富的特征表达。实验结果表明,LSV-CNN模型比单纯CNN模型性能更有优势。2.基于SDG-CNN的EMR诊断模型研究.针对以卷积神经网络为代表的基于数据统计特征的模型优化方法缺乏EMR背景知识和语义信息,信息模态单一的缺陷,而提出一种融合词汇语义预判模式的EMR诊断模型SDG-CNN(Semantic Decision Guide Convolutional Neural Network)。该模型在模式识别层融合深度学习决策模式和词汇语义预判模式,旨在利用词汇语义预判模式结果对深度学习模型的训练进行指导,以期在训练中增加背景知识和语义信息,使得模型更贴近人类的思考方式。实验表明,SDGCNN模型比单纯CNN模型的准确率和F1-score有很大程度的提升。3.基于LSV-SDG-CNN的EMR诊断模型研究.为了充分利用LSV和SDG两种方式所提取到的电子病历所蕴含的大量丰富语义信息,提出融合LSV和SDG的EMR诊断模型LSV-SDG-CNN。实验结果证明,LSV-SDG-CNN模型的F值最高达到86.2%。本文有效解决了基于专家的领域知识与基于大数据的深度学习有效融合的问题,探索人工智能研究中人工+智能的耦合模式,对深度学习模型和人工智能的研究路径有积极的意义。"
1050,基于深度学习模型的表面肌电信号手势动作识别算法研究,"表面肌电信号(Surface Electromyography,sEMG)是通过表面电极记录的肌肉运动生物电信号,它可以反映神经和肌肉的功能状态。随着科技的不断进步,国内外研究学者对sEMG信号的研究也逐步深入,尤其是在运动训练、术后复健、临床医学等领域得到广泛的应用。目前在单自由度的假肢控制中sEMG信号已逐步应用,并趋近达到商业化的目的。但针对多自由度智能设备的控制,sEMG信号仍然存在诸多问题有待解决,多通道表面肌电信号的特征提取与分类识别更是其中亟待突破的难题。随着深度学习领域的异军突起,深度学习模型对sEMG信号手势动作的精准程度有显著提升。深度神经网络,对建立多模态的感知计算模型具有很强的应用价值,但同时也要求具有足够的数据量作为支持。市场上现存的精密假肢价格一般较高,实验室肌电处理方法主要在计算机仿真平台上进行测试,与实际使用还存在一定差距。为解决sEMG信号在实际应用上存在的问题,本文提出了一种基于深度学习模型的sEMG信号手势动作识别算法,通过深度学习模型完成对sEMG信号手势动作的识别,未来可以作为深度智能仪器控制系统。首先,本文选用瑞士 Ninapro公开数据库,对其中提供的sEMG信号原始数据进行预处理。由于原始采集的sEMG信号具有很多的噪声干扰,使得sEMG的波形特性受到一定程度上的干扰,影响了最终的识别效果,因此本文采用2阶巴特沃斯带阻滤波器对sEMG信号去除噪声干扰。其次,在实验过程中发现原始的sEMG信号存在着部分波段幅值极低的情况,导致实验结果具有较大的偏差,因此本文对滤波后的sEMG信号计算标准偏差并滤除无信号段,以确保每段信号具有sEMG信号原始特性,便以取得最佳的识别精度。同时采用时间窗重叠的方式对已有sEMG信号进行扩充,以满足深度学习模型对数据样本的需求。最后,通过重构的残差网络模型对sEMG信号进行分类识别。从信号本质上来讲,sEMG信号为1维信号,本算法通过构建1维残差网络的方式,提出了一种适合sEMG信号手势动作分类识别的32层ResNet V2残差网络,将本文提出的算法与现有的sEMG信号的势识别算法进行对比实验,通过分析实验结果得出,本文提出的基于深度学习模型的表面肌电信号手势动作算法可以有效提升多分类手势动作的精确率,为开发具有准确率高、鲁棒性强的智能假肢设备提供了可靠的技术支持。"
1051,基于深度学习的跨语言文本情感分类技术研究,"随着互联网技术的飞速发展,人们越来越热衷于在网上发表自己对某一事件或者事物的看法,这些评论背后隐藏着巨大的商业价值,所以近年来文本情感分析越来越引起人们的关注。但是一些语言较其他语言起步晚,缺乏高质量的语料资源,人工标注又需要投入巨大的人力物力资源,这在一定程度上阻碍了其文本情感分类技术的研究。跨语言文本情感分类任务就是利用语料资源丰富的一种语言,辅助另一种语料资源匮乏的语言实现文本情感分类。为了进一步提高跨语言文本情感的分类性能,本文做了多方面的融合和改进,提出了以下跨语言文本情感分类方法:(1)针对传统的单语言词向量表示方法不能很好地进行双语交互学习这一问题,提出了一种对抗长短时记忆网络的跨语言文本情感分类方法。该方法设置源语言和目标语言独立的特征提取网络以及双语共享特征提取网络,建立源语言和目标语言的联系,减少双语之间的语义鸿沟。同时,在共享特征提取网络中,设置语言分类器进行对抗训练,使分类器尽可能分不清特征是来自源语言还是目标语言,以获得双语的不变特征,从而使双语之间达到更好的知识迁移效果。相比较之前的研究方法,这种方法既保留了双语各自独立的特征,又可以获取到双语的不变特征。在NLPCC 2013跨语言文本情感分类公开数据集上做了实验,实验结果表明该方法提高了跨语言文本情感分类性能。(2)考虑到情感词典依旧是不可忽略的资源,以及情感词上下文信息对整段语料的情感极性贡献较大这一因素,提出了一种结合局部和全局特征的跨语言文本情感分类方法。该方法结合情感词典,利用卷积神经网络获取情感词上下文特征,将其作为整段语料的局部特征。同时,利用加入注意力机制的双向长短时记忆网络获取整段语料的全局特征。最后,将局部特征和全局特征进行拼接融合作为最终的分类特征,输入到分类器进行文本情感极性分类。在包含多语言的数据集上分别做了实验,实验结果表明该方法可以提高跨语言文本情感分类性能。"
1052,基于对抗训练的文本情感分析研究,"随着社交软件和电商平台等应用的蓬勃发展,存在于这些应用的海量文本数据蕴含着大众对某些热点事件的情感态度,对文本数据进行情感分析,挖掘其包含的情感态度在舆情监控和策略制定等方面具有深远意义。传统的文本情感分析方法为挖掘情感态度提供了技术支持,但系统的鲁棒性较低,在文本被恶意添加扰动或被破坏时,对情感分析系统会造成一定的干扰,从而导致结果的误判。为了提高文本情感分析系统的稳定性和准确性,本文重点研究在强鲁棒性前提下的文本情感分类问题,具体的研究内容如下:(1)针对文本情感分析系统鲁棒性不高的问题,本文提出融合对抗训练和对抗Dropout方法的文本情感分析模型。采用对抗训练在输入层对文本添加对抗扰动来训练对抗样本,同时在网络的隐藏层进行对抗性Dropout,以动态遮蔽适当数量的神经元,从而提高模型鲁棒性和情感分类效果。(2)为了在强鲁棒性的条件下进一步提高情感分类的性能,本文提出结合注意力机制与对抗训练的文本情感分析模型。注意力包含基于情感词的全局注意力机制和基于自适应尺度的局部注意力机制,前者既关注到情感词又保留了文本信息的完整性,后者既可以自适应地选择合适的尺度又捕捉到重要的局部信息。将两种注意力机制与融合了对抗训练和对抗Dropout的方法进行结合,不仅可以提升情感分类的性能,而且不明显增加训练时间。(3)针对文本特征提取器单一性的问题,且为了进一步提升情感分类的性能,本文提出结合循环自注意力机制与对抗训练的文本情感分析模型。使用基于循环自注意力机制的模块代替循环神经网络和卷积神经网络作为文本特征提取器,并在该模块中使用残差网络结构以保证深度网络的性能。同时将该模块与融合了对抗训练和对抗Dropout的方法进行结合,确保模型在强鲁棒性的前提下提升情感分类性能。在IMDB、ELEC和MR数据集的实验结果表明,本文方法有效提高了模型的鲁棒性和分类性能。"
1053,带置信度的多标记图像模型研究与应用,"随着信息技术与多媒体技术迅速发展,图像呈现指数级的增长,如何应对这些图像分类是个亟待解决的问题。现实生活中,一幅图像往往存在多义性,图像分类是典型的多标记问题。另外,在高风险领域,分类失败将导致严重的后果。本文通过把卷积神经网络(Convolutional Neural Networks,CNN)引入归纳一致性预测器学习框架(Inductive Conformal Predictor,ICP),提出MLICP-CNN多标记置信预测模型,能对输出结果附带可校准的置信度评估。最后将MLICP-CNN模型应用于X线胸片多标记诊断问题中,构建X线胸片置信诊断原型系统。总结来说,论文的主要研究内容如下:(1)提出一种基于卷积神经网络与归纳一致性预测器的多标记学习模型MLICP-CNN。该模型包括基于CNN的训练集推理规则抽取阶段和基于ICP的多标记置信预测阶段,能充分利用CNN进行样本特征的自动、多层次和多角度提取,又利用ICP具有置信机制和时间复杂度低特性,来解决多标记图像分类置信问题,使得预测结果能够被置信度所校准。(2)设计了符合MLICP-CNN学习框架的奇异值函数,提出IO-MLICP-CNN与LS-MLICP-CNN两种算法。并通过标准多标记数据集验证和对比了两种模型的可校准性、域预测效率及多标记分类效果。(3)将性能较优的LS-MLICP-CNN模型应用于X线胸片置信诊断,构建胸片诊断原型系统,使得该系统能对临床胸片进行预处理、并输出附带置信度评估的多标记诊断结果。另外,还利用CNN产生肺炎热点图,实现有效的辅助病灶区域定位。最后,对本文的工作进行了总结,并对今后的研究工作提出了展望。"
1054,巴州区降雨型滑坡预警研究,"滑坡灾害具有分布范围广、发生频次高、多发性、区域性和严重性等特点,对国民经济和生命财产都造成不可估量的损失。根据自然资源部统计,近年来,滑坡灾害占全部地质灾害总数的70%以上。在已经发生的滑坡灾害中,有90%的滑坡灾害都是由降雨直接诱发或者跟降雨有间接关系。巴中市巴州区地理位置具备滑坡发生的内外部因素,且气候属于亚热带季风湿润气候,发生降雨型滑坡的比例占总地质灾害的70%以上。因此,本论文进行巴州区的滑坡敏感性和降雨量模型研究,从而实现巴州区降雨型滑坡预警。本论文构建机器学习算法开展巴州区滑坡敏感性研究,建立巴州区降雨强度-降雨历时模型开展降雨量模型研究,并根据两个研究结果建立巴州区降雨型滑坡气象预警模型。本论文主要研究工作如下:(1)基于地理信息系统技术,结合巴州区历史滑坡灾害数据,采用4种机器学习算法开展巴州区滑坡敏感性研究。研究结果表明BP神经网络分类总体精度最高,达到98.00%,高于其他算法2.00~6.00%,Kappa系数为0.96,高于其他算法0.04~0.12。3组测试数据的总体精度平均值为95.33%,高于其他算法2.66~9.33%,Kappa系数平均值为0.91,高于其他算法0.06~0.19。(2)利用TRMM 3B42降雨产品数据,建立巴州区降雨强度-降雨历时模型,得到巴州区降雨量模型参数,对巴州区降雨型滑坡时间进行预测。研究结果表明对降雨型滑坡预测精度为81.82%。基于建立的模型,对滑坡隐患点进行预测,精度为100.00%。综上,对降雨型滑坡及滑坡隐患点进行预测,精度为90.91%。因此,本论文建立的巴州区降雨强度-降雨历时模型,对降雨型滑坡和滑坡隐患点预测均有较好的参考价值。(3)建立巴州区地质灾害致灾因素的概率量化模型进行气象预警,地质因子的概率量化采用滑坡敏感性研究的实验方式,气象因子的概率量化采用降雨量模型研究的实验方式,改进基于统计滑坡次数与降雨量大小关系的量化方式,研究结果表明模型预警结果与实际排查工作结果一致。因此,本论文的气象预警模型可以作为巴州区降雨型滑坡预警的参考模型。"
1055,电容型设备缺陷预测模型研究,"在电力系统中,电容型设备数量众多,占变电站设备总量的40%~50%,电容型设备的健康运行对于电力系统至关重要。随着电网信息化建设的大力推进,各种电力数据呈爆炸式增长,这为电容型设备健康运行提供了强大的数据支撑。传统的统计方法已无法满足实际的分析需求。本论文以重要性高、数据量大、数据种类丰富的电容型设备数据为数据源,并检验随机森林(Random Forest,RF)、多层感知机(Multi-Layer Perceptron,MLP)、支持向量机(Support Vector Machine,SVM)、集成树(Extreme Gradient Boosting,XGBoost)和线性分类算法等五种不同机器学习算法在电容型设备缺陷预测中的适用性,构建缺陷发生预测和缺陷等级预测模型,并将金融领域的评分卡模型应用在电容型数据分析中,探索出最优缺陷预测模型。本论文的研究内容与研究结果如下:(1)针对一般的编码方法,在各种缺陷发生预测以及缺陷等级预测模型中的效果较差,在对电容型设备数据进行清洗和数据均衡化基础上,结合电容型数据的特点,加入基于评分卡模型的证据权重(Weight of Evidence,WOE)特征编码,用于改进缺陷发生预测以及缺陷发生模型的性能。(2)针对设备是否发生缺陷进行预测,将五种机器学习算法应用在缺陷发生预测中,进行模型训练和参数调优,对各算法使用普通编码和评分卡模型WOE特征编码的预测结果进行比较,并分析特征重要性。实验结果表明,加入评分卡模型的WOE特征编码后,各算法的分类效果均得到改善,支持向量机、集成树和线性分类的精度提高0.07以上,多层感知机和随机森林分别提高0.02和0.03。随机森林各综合评价指标均最优,精度达到0.95。因此,基于WOE的随机森林算法(WOE_RF)缺陷发生预测模型最优。(3)在预测设备是否发生缺陷的基础上,进一步预测设备可能发生缺陷的等级。同样使用上述五种机器学习算法对两种特征编码方法下的缺陷等级预测结果进行比较,并分析特征重要性。研究结果表明,加入基于评分卡模型的WOE特征编码,可以有效改善各算法的分类能力,随机森林、多层感知机和支持向量机精度提高0.05以上,集成树和线性分类分别提高0.01和0.02。但同样是随机森林表现最佳,精度达到0.78。因此,WOE_RF缺陷等级预测模型最优。"
1056,基于机器学习的MIMO系统收发机设计理论与方法,"智能设备和物联网的高速发展所衍生的新应用对无线通信网络的传输速率和灵活性均提出了新的挑战。传统设计方法过于依赖简化的模型假设且难以针对不同应用需求定制化设计。为克服上述困难,本文将数据驱动的机器学习与多输入多输出(Multiple-Input Multiple-Output,MIMO)无线通信系统结合,研究了如何利用MIMO系统特征定制机器学习算法以提高无线通信系统的传输效率和灵活性。基于MIMO接收信号的成簇特征,本文针对时分双工(Time-Division Duplex,TDD)MIMO系统提出一种基于聚类学习算法的信号检测系统设计方案。基于该方案可以在统一的聚类收发机框架下根据性能需求灵活设计非线性和线性检测算法。该方案无需显式的信道估计但性能可以逼近信道已知的信号检测算法。进一步的,基于MIMO信道与数字调制的特征,本文提出一种用于MIMO信号检测的调制约束聚类算法。通过理论分析,本文证明了该方法可降低算法的样本复杂度,并使得聚类检测所需估计的参数数量与调制阶数无关。最后,本文分别针对最大似然检测和线性检测算法两类典型算法提出基于调制约束聚类学习的收发机设计方法,并在典型衰落信道条件下进行了性能测试与评估。针对频分双工(Frequency-Division Duplex,FDD)大规模MIMO系统下行信道估计问题,本文基于大规模MIMO信道的稀疏性特征研究了基于字典学习算法的信道估计方法。该方法能够针对小区特定的地理环境学习到定制的字典并取得性能增益。进一步的,通过理论和实验分析,本文讨论了基于字典学习的信道估计方法能带来性能增益的原因以及字典学习结果的物理意义。在此基础上,本文提出字典应具备块稀疏结构特征,并率先设计了一种表征地理特性的块稀疏联合字典学习算法。最后,本文基于3GPP标准文档仿真了基于地理信息的信道环境,并在此环境中测试和评估了基于字典学习算法的性能。本文成功地实现了机器学习与无线通信领域的交叉融合,提供了一种数据驱动的MIMO系统设计方法,并分别针对TDD MIMO信号检测问题和FDD MIMO信道估计问题提出利用了无线通信领域特征的高效机器学习算法和系统设计。理论分析和数值仿真表明,本文所提出的基于机器学习的信号检测与信道估计算法相比于传统算法和直接应用原始机器学习算法有着显著的性能增益,为大规模MIMO系统的设计和研究提供了新的视角。"
1057,基于机器学习的布匹疵点检测算法研究,"衣食住行是人民的生活所需,在衣物方面,布匹是制作衣物不可或缺的一种原材料。因此纺织业需要生产大量的布匹,以满足人们对衣物的需求。随着生活水平地提高,人们对于衣物质量的追求也变得更加严苛。由于机械操作不当、客观环境等因素会让纺织机在生产布匹的过程中出现疵点,常见的疵点有破洞、污渍、错纱、断纱等。决定布匹质量好坏的一大关键因素是布匹表面是否存在疵点,存在疵点的布匹其售价远远低于没有疵点的布匹,售价的下降会导致企业利润降低,轻则减少收入,重则导致企业或者工厂倒闭。为了提高企业收益,需要剔除出有疵点的布匹,而目前许多企业还保持着人工检测的方式。由于工人的熟练度会影响检测效率,而且长期利用肉眼会产生视觉疲劳,导致检测速度下降,不适应于实际的生产。因此,利用机器视觉去替代人眼,实现布匹疵点的自动化检测显得尤为重要。实现机器视觉检测的关键是需要合适的检测算法,能够快速有效地检测出布匹疵点。近年来,随着机器学习在图像处理、目标检测等领域的广泛应用,使得布匹疵点检测算法的实现变为可能。本文提出了基于机器学习的布匹疵点检测算法,旨在更好地实现布匹疵点的自动化检测。主要研究工作如下:(1)提出一种基于特征提取和支持向量机的布匹疵点检测算法,主要包括特征提取和分类学习两个部分。布匹表面纹理具有周期性变化的特点以及表面结构组织排列具有均匀性的特点,同时具备方向性和均匀性,当布匹表面出现疵点时,布匹纹理的完整性和结构性就被破坏,疵点出现位置的特征值相比于无疵点位置的特征值发生了变化。本文考察MFS、HOG、SIFT、PHOG、HOG-NMF这五种视觉描述子算法用于表征布匹图像,以更好地区分有无疵点。由于布匹生产线的限制,布匹缺陷图像样品量有限,故检测分类可采用支持向量机。支持向量机适合小样本训练,能够很好地弥补样本量有限的问题。检测算法先提取训练样本的布匹块特征,标记已知图像块的含疵点信息,将布匹块特征和疵点标记信息输入支持向量机进行训练,得到网络模型。然后提取待检测布匹块的特征,输入训练好的网络结构,根据网络的输出结果判断疵点情况。(2)提出一种基于卷积神经网络的布匹疵点检测算法。由于特征提取的检测方法特别依赖特征提取算法,不能自适应学习,通用性差。利用卷积神经网络良好的自适应学习能力,提取合适的布匹纹理特征,可以实现高效的检测。本文利用AlexNet、VGG16、VGG19、GoogleNet和改进的CNN这5种网络模型进行布匹疵点检测,判断布匹是否包含疵点。(3)提出一种基于Faster RCNN的布匹疵点检测算法。由于卷积神经网络适合于疵点分类,而不能实现布匹疵点的定位。因此,采用Faster RCNN来实现布匹疵点区域的定位以及疵点的分类。先用RPN网络(Region Proposal Network)确定可能包含疵点的候选窗口,之后利用卷积神经网络的分类判断疵点类型,然后利用回归判断候选窗口的精确位置,实现疵点的准确定位和辨别。本文实验图像数据来自TILDA标准布匹图像库,利用条纹布、方格布、斜纹布、平纹布这四种类型的布匹来验证算法的有效性,其中疵点类型是错纱、污渍、断纱、破洞这四种。通过大量实验结果的分析,本文的算法能够有效地检测出布匹疵点,实现疵点区域定位和疵点类型分类,能够为企业、工厂实现布匹疵点检测提供参考借鉴。"
1058,基于数据分析与集成学习的4D航迹预测,"4D航迹预测是未来的发展趋势,可在未来的空中交通中的自动化系统中发挥重要作用。同时,它还是冲突探测与解脱、航班排序、间隔管理等的基础,被视为解决全世界空中交通管制问题的有效解决方案。在本文中,一种创新的4D航迹预测混合模型被提出,经由应用主流数据分析和机器学习手段处理终端机动区(Terminal Maneuvering Area,TMA)中短期尺度的4D航迹预测问题。所提出的模型由两部分组成:基于聚类的数据预处理模型和基于集成学习思想的多细胞神经网络(Multi-Cells Neural Network,MCNN)预测模型。预处理部分首先将对航迹原始数据进行清理,过滤和重采样。为了削减航迹矢量的变量维度,引入并使用主成分分析。随后,降维后得到的航迹矩阵经由聚类算法,被聚类成多个航迹簇。在预测模型中,使用嵌套交叉验证,针对每一个聚类簇,分别训练不同的MCNN模型,获得不同聚类簇对应的预测预计到达时间(Estimated Time of Arrival,ETA)的子模型。最终,引入并使用决策树对应的分类算法,将新航班分类到不同的聚类簇,并输入到已经训练完毕的预测模型,得到ETA。为了具体评估MCNN模型,提出了多元线性回归(Multiple Linear Regression,MLR)作为对比,并将K-means与DBSCAN算法作为预处理步骤中的聚类模型互相对比。仿真实验所使用的数据为北京首都国际机场的实际4D航迹数据,具体位于终端机动区区域之内。结果阐明:基于DBSCAN算法的预处理模型和多细胞神经网络的混合模型为最佳模型,在航迹聚类短时4D航迹预测任务中,平均绝对误差(Mean Absolute Error,MAE)和均方根误差(Root Mean Squared Error,RMSE)均为最低,可以进行精确的4D航迹预测。"
1059,单件小批量注塑模具高精加工过程刀具磨损预测,"高精加工过程作为工件成型的最后一道加工工序,直接决定着工件的加工质量,因此对高精加工过程实现刀具磨损监测,是提高该过程加工精度、提高刀具利用率的有效措施。本文结合单件小批量注塑模具高精加工过程,开展关于固定参数与变参数情况下高精加工过程中平底立铣刀的刀具磨损监测方法研究。结合模具加工过程中单件小批量、刀具尺寸小、刀具磨损变化量小、模具结构多变、产品精度要求高的特点,本文的研究主要涉及以下几个方面:首先分析了单件小批量注塑模具加工过程、加工特点及成品模具的质量变化特点,并通过模具质量变化趋势范围与刀具磨损值的对比分析,提出了注塑模具高精加工过程中磨损值量化的方法。在此基础上,结合对工厂模具加工过程中存在问题的分析,完成了注塑模具高精加工过程中刀具磨损检测的数据采集方案。确定了注塑高精加工信号的降噪方法及有效的特征提取、特征选择方法。结合注塑模具高精加工过程切削量极小、加工过程信号极易受到噪声污染的情况,确定了基于小波阈值降噪的处理方法;并将小波分解与时频统计特征结合提取加工信号特征,同时完成了基于灰度分析方法的特征选择。研究了基于BP与LSTM两种神经网络算法的刀具磨损预测建模方法,并在分别改变高精加工过程切削余量及模具拔模角度的情形下研究了两种建模方法的泛化性,并完成了两种方法在建模精度及模型泛化性方面的对比。最后通过对不同时间采集到的模具加工数据进行分析,验证了模型的预测性能不受机床劣化性能的影响;然后将模型应用到工厂实际模具生产加工过程,模型的实际预测误差维持在1-2?m内,效果较好。"
1060,基于机器学习算法的企业用电预测模型研究,"为了提高电力服务的质量和保障水平,近年来,电力负荷预测受到工业界和学术界的广泛关注。而随着科技的发展,机器学习已应用到各种领域。如何利用机器学习相关技术,结合历史用电数据和当前电力消费影响因素对电力负荷进行高精度的预测已成为一个研究热点。电力负荷预测的基础数据目前主要来源于数据采集与监视控制系统(Supervisory Control And Data Acquisition,简称SCADA),但存在异常数据等问题,而数据预处理是提高基础数据质量、改善预测准确度的必要前提。本文针对企业用电预测缺乏异常检测模块、数据量大,无样本标签等特点,结合机器学习技术,在数据预处理阶段加入一种基于无监督学习的企业用电异常检测模块。使用孤立森林算法(Isolation Forest,简称iForest)与拉依达法则(3?法则)相结合对企业用电进行异常检测,并与K-means算法检测结果进行比较。仿真测试结果显示,当数据规模较小时,两种异常检测模型的检测率差别不大,但当数据规模变大时,该模块的异常检测率明显高于基于K-means算法的异常检测率,当数据量达到6174维时,其检测精度比基于K-means的异常检测模型高30.5%,达到93.5%。针对目前大多数企业用电预测采用单一模型存在局限性的问题,本文结合气温、节假日等因素对企业用电数据的影响,提出一种基于自回归滑动平均算法(Autoregressive Moving Average Model,ARMA)与极限梯度提升(Extreme Gradient Boosting,Xgboost)的机器学习组合方法的企业用电预测模型,并分别与目前流行的基于ARMA的企业用电预测模型、基于Xgboost的企业用电预测模型和基于反馈神经网络的企业用电预测模型的预测结果进行对比。仿真测试结果表明:该模型预测精度达到97.02%,相比于三种分离模型的预测精度平均提高了2.76%。总之,结合数据预处理,本文提出的组合预测模型具有预测时间短、针对性强、预测精度高等特点,能基于预测结果有效揭示企业用电变化规律,适用于电力系统领域。"
1061,基于组分特征的tracrRNA识别和预测,"CRISPR-Cas系统是细菌和古菌的RNA介导的适应性免疫系统,可以针对性切割外源核酸序列,目前已发展为使用最为普遍的基因编辑工具。II型CRISPR-Cas的部分亚型(如A、B、C)依赖于反式激活CRISPR RNA(tracrRNA)干扰入侵序列及使pre-crRNA成熟。经RNA酶III处理后,tracrRNA与crRNA复合体激活CRISPR相关核酸内切酶Cas9(Csn1)切割位点特异性同源的靶DNA。因此识别tracrRNA对于研究开发新的CRISPR-Cas系统的基因组编辑工具有着重要的作用。本文收集了54条已知的tracrRNA构成阳性训练集,对已知的tracrRNA随机改组,构造具有tracrRNA结构特征并且与已有tracrRNA具有相同核苷酸组成的“假tracrRNA”数据集,构成阴性训练集。通过伪核苷酸组分PseKNC方法表征原始训练集,作为训练分类器的特征数据集。采用机器学习的方法构造分类器,在训练过程中,使用留一法交叉检验评估分类器的性能,使用基于方差分析的特征选择技术进行特征优化,去除模型构建过程中包含的不相关的冗余特征,最终获得基于最优PseKNC参数的特征数最小,性能最好的tracrRNA分类器。使用支持向量机和朴素贝叶斯、随机森林等其他机器学习算法进行比较时,支持向量机在训练模型过程中的预测性能明显优于其他方法。基于支持向量机,通过特征选择筛选以及留一法评估,当PseKNC参数k为5,j为1,w为0.5,特征数为171时,训练的tracrRNA分类器具有最优的预测性能,其敏感性为98.15%,特异性为100%,准确率为99.07%,MCC为98.16%,ROC曲线下面积为0.998。该结果说明,该分类器在区分tracrRNA与具有tracrRNA结构特征和氨基酸组成的“假tracrRNA”具有非常好的区分能力,为识别新的tracrRNA以及实验过程中设计优化tracrRNA提供了强有力的辅助手段。"
1062,基于深度卷积循环神经网络的刀具状态监测技术研究,"随着铣削技术向着高速、高精、高质的方向不断发展,铣削过程中刀具磨损已成为影响工件尺寸精度、表面质量、加工效率及生产安全的关键因素,因此对刀具状态监测技术的研究至关重要。本文以铣削加工过程中刀具的磨损状态为研究对象,利用加工过程中的振动信号,采用多种机器学习方法对刀具磨损特征进行学习,实现对刀具磨损状态的识别,主要工作如下:首先,结合铣削加工试验过程中刀具的不同磨损状态,利用振动信号包含的复杂数据信息,通过时域分析、频域分析、小波包技术提取原始高维特征,利用MLLE算法进行特征降维,减少多个特征参数之间的冗余性和不相关性,并将所有低维特征输入XGBoost模型进行刀具状态识别,并使用GA算法对XGBoost参数进行寻优,实验结果验证了该模型在刀具状态识别上的具有一定可行性和有效性。其次,为了改善原始数据特征工程的低效性,利用DenseNet网络、BILSTM网络能够自适应的提取空间、时间特征的优势,将振动信号丰富的特征映射到刀具磨损状态,采用了一种基于注意力机制的CRNN刀具状态识别模型,实验结果表明该模型在刀具状态识别任务上有更高的准确率。最后,为了解决刀具磨损对加工精度造成的影响,利用CRNN模型建立刀具磨损量与振动信号的关系,实时识别刀具磨损量,并采用分段式刀具磨损补偿模型及时补偿加工过程中刀具磨损造成的误差,保证铣削加工工件的精度要求。"
1063,鱼种回波信号特征提取及分类方法研究,"渔业资源的科学评估对渔业的可持续发展具有重要意义。相比于生物取样,渔业资源声学评估具有快捷、取样率大且不干扰群体自然状态等优点。现有的信号特征提取与分类方法种类繁多,且性能随应用环境的不同而有所差别,为全面评估相关方法在鱼种回波特征提取及分类的性能,论文首先在现有的经典鱼群回波仿真模型基础上,基于实际中鱼群和船载声呐可能存在的相对运动特点,通过融合回波的多普勒信息对模型进行改进,改进后的模型更符合实际的回波数据,为后续分析和评估相关方法的性能奠定基础。鱼种分类框架主要由两个基本部分组成:针对观测数据进行特征提取和基于分类方法对特征进行分类。对于鱼种回波的特征提取方法,由于鱼体内部结构和鱼种聚集模式的复杂多变性,目前常用的鱼种回波特征提取方法通常难以挖掘隐藏在鱼种回波中深层次的有用信息,导致获得的特征较少,物种分辨率较低。论文在综合分析常用回波特征提取方法的基础上,利用卷积神经网络提取鱼种回波特征,该方法通过卷积层级联的网络结构可提取鱼种回波中隐含的更复杂和深层次的特征。对于鱼种回波的分类方法,目前的研究工作较少涉及特定分类方法对于特定特征的适用性分析,以及融合不同特征和不同学习方法所带来的性能提升效果的评估。论文将经典的机器学习分类方法应用于鱼种分类,在此基础上,根据鱼种回波特征对Stacking集成学习分类方法进行优化改进,改善了鱼种分类的性能。最后,为进一步验证鱼种回波特征提取和分类方法的有效性,开展了水池实验研究,通过对三种典型鱼种的回波数据分析,显示实验结果与仿真具有较好的一致性。"
1064,Object Detection and Recognition Techniques for Indoor Scene Using Deep ConvNets,"Object detection is one of the most classical computer vision task that is used to detect objects from an image.Efficient and accurate object detection plays a vital role in the advancement of computer vision that makes it able to detect the objects in real time applications with more accuracy and less processing time.With recent advancement in machine learning and deep learning techniques,the accuracy for object detection has significantly increased.Existing Convolutional Neural Network(CNN)based object detection techniques achieve much better accuracy than classical detection algorithms but it suffers from more training and testing time that limits the overall performance of system and make it impractical for real time applications.In order to deal with the aforementioned issues,we have proposed two techniques that not only increase the accuracy of system but also reduce the training and testing time which makes it practical for real time object detection applications.Firstly,we have created two indoor datasets which have never been created by anyone before and then data augmentation is applied to one indoor dataset which increase the data size that results better accuracy and avoids the issue of over-fitting.Further,we do transfer learning in Faster R-CNN and SSD techniques from layer 7 by setting different learning rates and weights along with different mini batch size of 64,128 and so on.In addition,we have used data reduction techniques to our proposed methods.Due to this,our proposed methods take less training and testing time(with very slight reduction in accuracy)while consume less memory and power that makes it more efficient than existing Faster R-CNN and SSD techniques.Simulation results validates that our proposed methods achieve better accuracy and take less training and testing time than existing techniques.Thus,it can be concluded that our proposed framework is applicable for real time indoor object detection."
1065,基于深度神经网络集成和信息论学习的时间序列预测,"时间序列预测研究的是如何利用时间序列数据的历史观测值对其未来发展变化做出合理有效地推断,涉及统计学、计算机科学等多个学科。时间序列数据几乎无处不在,与人们的生产生活息息相关。近年来,伴随着信息科学和计算机技术的飞速发展,越来越多的技术方法被应用于解决时间序列预测问题。传统的基于时间序列模型的分析方法能够很好地解决低维线性数据的预测问题,但是它们在处理普遍存在的高维非线性时间序列数据时,表现出许多不足之处。人工神经网络是一类非线性、基于数据驱动的机器学习方法,它经过几十年的发展,衍生出目前较为成熟的深度学习技术。本文重点研究了深度学习技术在时间序列预测问题中的应用,充分利用深度神经网络模型对非线性系统的学习能力,提高时间序列预测的精度。本文的主要工作是基于两种典型的深度神经网络,对时间序列预测模型进行了两方面的改进研究,其中包括考虑非高斯噪声等复杂环境的影响以及改进预测模型自身的不足。具体内容如下:首先,基于长短期记忆网络和卷积神经网络,我们实现了两种面向时间序列单步预测问题的深度神经网络预测模型,作为后续对时间序列预测模型改进研究的基础,并分别在混沌时间序列模拟数据集和交通流量数据集上进行了测试。然后,考虑到实际生产生活中的时间序列数据往往会受到非高斯噪声的影响,本文进一步研究了将信息论学习方法应用于对深度神经网络预测模型的改进,提出了基于中心化误差熵损失函数的深度神经网络预测模型。最后,针对深度神经网络模型训练不稳定的不足,本文研究了将集成学习方法应用于对深度神经网络预测模型的改进,提出了基于噪声扰动集成方法的深度神经网络集成模型。"
1066,基于机器学习构建数字化诊脉系统的应用研究,"中医已经有两千余年的历史,其中脉象作为“望闻问切”四诊中的关键组成之一,在中医辨证施治体系中起着非常重要的作用。然而,在脉诊的临床实践过程中,脉象主要通过医生手指感知桡动脉的搏动获取,影响因素众多,而且缺乏客观的评价标准,诊断的准确性和医生的临床经验也密切相关。从中医发展角度考虑,通过现代仪器和技术将主观性较强的脉诊客观化,以此构建数字化的脉诊体系对临床有重要意义,也是推动中医现代化的主要途径。根据中医理论,妊娠期和非妊娠女性的脉象有明显的差异,脉诊是早期诊断妊娠的重要手段,因此本研究将以妊娠的检测作为应用场景,结合信号处理和机器学习技术来构建数字化的脉诊体系。本研究集成脉象信号的采集、特征提取、模式识别为一体。我们采用敏感性和稳定性更高的数字脉象仪收集了 495例女性的脉象,其中妊娠者264例,非妊娠女性231例,将传统中医脉象的主观感受转化为客观化的时间-压力二维数据,建立初步的脉象数据库。然后,在提取脉象时域波形特征的基础上,提出了一种脉象小波特征提取方法,使用小波变换对脉象信号进行了四层分解,提取了小波能量和小波熵作为小波特征。这些特征被输入到不同的机器学习模型以进行妊娠的脉象识别,包括极端梯度增强、支持向量机和概率神经网络,贝叶斯优化被用于模型训练过程中的超参数寻优,比传统网格搜索取得了更好的效果。我们采用留一交叉验证严谨地评估了识别模型的性能,结果显示本研究提出的基于脉象时频域特征的贝叶斯优化――极端梯度增强模型对妊娠脉象有最佳的检测精度,其识别率达到了 87.5%,受试者工作特征曲线下的面积为0.94。我们发现妊娠的识别率和妊娠阶段有关,妊娠中期的识别率为91.3%,妊娠后期为90.7%,明显高于妊娠早期的85.4%。我们也比较了留一交叉验证与传统方法划分单独测试集在评估稳定性方面差异,前者有更好的稳定性。本研究所构建的数字化诊脉系统可以客观收集并分析传统中医脉象,具有无辐射、非侵入及更精确的优点,随着数据的不断积累和体系的优化,在基于脉象的中医辨证施治方面将发挥巨大的潜力,从而进一步提升中医的社会和经济价值。"
1067,深度学习算法的FPGA硬件加速研究与实现,"近年来,人工智能在理论和应用上都取得了巨大成功,深度学习作为人工智能最重要的研究方向,可以解决更加抽象复杂的问题。然而,由于问题变得更加抽象和复杂,深度学习网络的规模也在逐渐增加,模型的学习时间也随之剧增。所以对深度学习算法加速技术的研究成为大势所趋。相比于中央处理器(Central Processing Unit,CPU)、图形处理器(Graphics Processing Unit,GPU)和专用集成电路(Application Specific Integrated Circuit,ASIC),现场可编程门阵列(Field Programmable Gate Array,FPGA)在深度学习算法加速上具有高速度、低功耗、稳定而又延迟极低、适用于流式的计算密集型任务和通信密集型任务、灵活而开发周期短、成本低、便于携带等优势。目前,对深度学习算法的FPGA实现的具体架构的研究并不多,对训练过程的FPGA加速设计研究也较少。卷积神经网络(Convolutional Neural Network,CNN)算法是最常见最重要的深度学习算法之一,它在语音和图像识别等常见应用中取得了突破性成就,因此本文主要基于CNN,从算法基本原理,优化模型并仿真建模,通用硬件架构设计和FPGA实现四个方面对深度学习算法的FPGA加速进行研究与实现。首先,本文介绍了深度神经网络(Deep Neural Network,DNN)算法和CNN算法等深度学习理论。并对模型基本参数的优化选择和正则化、弃权技术等其他优化方法进行了研究,提出了一个具体的Lenet CNN模型,该模型在小规模的简化模型前提下,拥有良好的性能,准确率可达96.64%。然后,本文研究了CNN前向预测过程及后向训练过程的通用硬件架构,提出了基于移位寄存器的串矩转换结构和基于脉动阵列(Systolic Array,SA)的卷积层和池化层的主要运算单元的硬件架构。该架构具有模块化和可扩展性,可搭建任意规模的CNN模型,并且提高了频率和计算吞吐量,减小了I/O带宽需求。同时综合考虑计算时间及资源消耗后,提出了分段拟合逼近的Softmax层硬件设计框架。最后,基于硬件实现架构,分别对Lenet CNN的预测和训练过程进行FPGA实现和系统性能分析验证。首先对预测和训练过程进行Matlab定点仿真验证,然后搭建系统模块,并在Modelsim中进行功能仿真验证,随后分别在XC7K325T-2FFG900和XC7VX690T-2FFG1157上进行FPGA实现。最后分析对比了FPGA实现系统与CPU和GPU等在速度和功耗上的性能,在速度上FPGA比CPU有了3倍左右的提高,在功率上CPU和GPU是FPGA的100倍以上。"
1068,基于机器学习算法的光伏电站故障诊断研究,"随着全球能源和环保需求的持续增加,作为几种重要清洁能源技术之一的光伏发电在近年来取得了迅猛发展。然而,由于长期在户外运行,多样的环境气候条件容易导致光伏电站发生故障,因此,开发一套能够快速发现光伏电站运行故障的实时诊断系统对于确保光伏电站的安全运行显得极为重要。在光伏电站的各种诊断方法中,人工智能被认为具有较好的技术优势和应用前景,因此本文以实际光伏电站和光伏电站加速模拟装置为研究对象,采用机器学习算法,对光伏电站的故障诊断技术进行了以下研究。首先,本文对处于阴影遮挡状态下光伏电站的输出特性进行了研究,实验结果表明发生遮挡时光伏电站的输出电流数据具有“马氏性”,符合马尔可夫链的条件。据此,本文成功利用马尔可夫模型计算出光伏电站遮挡概率,并通过分析遮挡概率的波动性判断出是否存在阴影遮挡以及遮挡类型。为期一月的户外工程验证表明,该算法计算结果与实际电站观察结果相一致,证明了该算法的可行性和准确性。其次,由于构建机器学习算法模型需要大量数据进行训练,而不同故障状态下户外光伏电站的状态参数获取难度较大且时间周期较长,因此本文基于光伏发电原理和光伏电站结构,设计了光伏电站加速模拟装置,并从多个方面验证了该装置的科学性与可行性,证明其可以用于获取无故障运行、固定物阴影遮挡、云层遮挡和光伏组件老化这四种状态下的光伏电站运行数据。最后,本文提出了一种基于支持向量机的光伏电站故障分类方法,与现有其他方法不同,该方法以时间序列数据为输入条件,从而实现了云层遮挡、固定物遮挡以及光伏组件老化三类电气衰减特征相近故障的有效分类。基于光伏电站加速模拟装置对该算法进行了训练和验证,实验结果表明该方法具有良好性能和准确度。"
1069,大规模物联网设备的识别与定位,"物联网已经成为智慧城市、智慧小区等关系国计民生应用的重要组成部分。近年来,越来越多的物联网设备接入网络空间,包括网络摄像头、打印机、路由器、工业控制设备、智能家电等等,这些设备的安全问题引起了工业界和学术界的关注。物联网设备和设备地理位置信息对于保障网络空间安全起着关键作用。然而,目前的商业地理位置数据库只能提供粗粒度位置信息,定位到国家或者城市级别,无法满足细粒度物联网设备识别和定位的需求。本篇论文提出了大规模物联网设备的识别和定位算法,提高设备识别精确度和定位精度。本篇论文,首先实现了基于机器学习的物联网设备指纹生成算法。基于应用层数据报文内容,论文提取文本信息,结合通用的机器学习算法,生成物联网设备指纹,提高网络空间物联网设备识别精确率。其次,论文提出了基于测量的定位算法。具体来说,论文通过命名实体识别和正则表达式,提取可靠地理位置信息,生成大量的被动地标信息,作为测量的锚节点。论文基于欧几里得距离将地标节点分簇,获得高质量的地标信息,结合时延信息、网络拓扑结构和路由信息,计算目标物联网设备的经纬度信息,提高设备定位的精度。此外,论文通过调用谷歌地图接口实现图形化展示物联网设备的位置信息。本篇论文,通过搭建原型系统来验证算法的可行性。实验结果表明,物联网设备的识别达到了98%的识别精度和98%的覆盖率。在公开数据集合(近10000万数据报文)上,物联网设备指纹发现552万个物联网设备。在设备定位方面,论文提取了6万个具有经纬度信息的地标信息,定位精度控制在100公里以内。"
1070,边缘计算下无线通信接入认证技术研究,"边缘计算因其就近接入的特点,能实现更快的网络服务响应,满足多个行业在实时业务控制、安全隐私保护等方面的需求。在海量异构终端通过边缘设备接入网络过程中,实现快速可靠的认证极具挑战。物理层认证技术通过信道特性进行认证,具有轻量级的特点能很好地适应海量异构终端接入的认证场景。边缘计算提供的非对称资源,尤其适合物理层技术的接入认证。本文就边缘计算下的无线通信接入认证技术,完成了以下几个方面的工作:为解决门限难以寻找的问题,提出了一种基于AdaBoost的物理层信道认证方案。结合物理层认证和AdaBoost算法,建立基于一维特征的认证模型,实现门限的动态确定,在采用一维特征情况下,相较于人工遍历寻找最优门限的方案,采用所提AdaBoost算法不仅能够实现物理层接入认证的自适应判决,还能提升约3个百分点的认证率。为提高认证率,提出了一种基于机器学习的物理层信道认证方案。建立基于二维特征的认证模型,采集实际的USRP平台通信信道数据,结合多种机器学习分类算法验证了模型的可行性,相较于人工遍历门限方案,采用二维特征情况下,多种机器学习分类算法都能明显提升认证率,最高可将认证率提升到0.99,并且认证时间大幅度降低。将接入认证方案变得自适应和智能化,充分满足实时控制接入的需求。为识别恶意节点,提出了一种边缘计算下恶意节点攻击识别方案。首先对未知待接入节点的身份进行判别,确定是克隆节点还是Sybil节点。再进一步结合机器学习分类算法对其进行训练和学习,采用开源数据库数据进行验证。结果表明四种场景下的认证率均较高,使得对恶意节点的识别方案更加完整和自适应。综上所述,本文以边缘计算为应用背景,主要研究了无线通信下的接入认证技术,模型建立,算法推导,算法举例,仿真分析,平台验证,不断深入,取得了一定的研究成果。"
1071,基于局部特征的人体重识别技术研究,"人体重识别技术是指在不同的时间点,对于出现在两个非重叠摄像机下的行人进行检索和追踪的方法。在机场、地铁站等人员密集场所,基于人体特征的重识别技术有着十分重要的应用价值,受到了越来越多的研究者的关注。对人体重识别技术的研究方法分为有监督和无监督两大类,有监督方法主要包括传统机器学习方法和深度学习方法。本文将结合人体的局部特征,使用深度学习方法对人体重识别技术进行研究。在基于视频数据的人体重识别研究中,大多数基于深度学习的模型方法在提取视频中的行人特征时,处理的数据都是整帧图像序列,所以得到的特征表示是行人的整体特征。为进一步准确描述行人的特征,本文提出了一种基于人体局部特征的空间时序特征混合模型(STFMM),先提取视频序列中不同部位的特征,再利用这些特征构建行人的特征表示。在模型的构建中,首先将原始视频序列水平切割为W个子部位视频序列,然后利用深度学习网络进行各个部位的特征信息提取,最后将各个子部位特征融合到一起作为原始视频序列中行人的特征表示。在数据集iLIDS-VID和PRID-2011上进行了实验验证,实验结果表明所提出的模型在指标CMC rank-1上分别达到了 73.6%和81.3%的识别精度,与目前最好的空间时序池化注意力模型(ASTPN)模型相比分别提高了 11.3%和4.0%。在测试模型稳定性的交叉实验中,STFMM模型在数据集PRID-2011上的CMC rank-1达到了47.8%,比 ASTPN 模型提高了 17.1%。胶囊网络是深度学习领域新出现的一类模型网络,其在图片分类领域有着很好的表现。本文首次将胶囊网络应用到人体重识别领域中来,并提出了两个模型:CapsReId模型和CapsPartReId模型。CapsReId模型结合了胶囊网络和Siamese网络,其中将胶囊网络融入到了 Siamese网络的子网络中。CapsPartReId模型是在CapsReId模型基础上结合了人体的局部特征,将胶囊网络融入到扩展后的Siamese网络的子网络中。在数据集VIPeR,CUHK01,GRID,PRID450S和CUHK03上进行了实验验证,融入局部特征的CapsPartReId模型比CapsReId模型在指标CMC rank-1 上的识别精度分别高了 3.7%,0.4%,1.3%,3.1%和 5.5%。"
1072,面向SDN网络的DoS攻击检测与防御方法的研究,"软件定义网络(Software Defined Network,SDN)通过将控制平面和数据平面解耦和为未来网络管理带来了许多优势。然而SDN与拒绝式服务攻击(Denail of Attack,DoS)有着矛盾的关系。一方面,由于SDN的一些特性,它能够为检测和防御DoS攻击提供更方便、更有效的策略和方法。另一方面,由于数据层和控制层的分离,这也使得SDN网络容易引入一些新型的攻击。本文在对SDN网络架构特点和DoS攻击原理分析的基础,将面向SDN网络的DoS攻击分为三类即针对客户主机的DoS攻击、针对控制层的泛洪DDoS攻击和针对数据层的低速率DDoS攻击。然后通过分析三种攻击在SDN网络下的实现原理和攻击特点,提取三个流表统计特征:最大匹配包增速、源地址熵值和流表相似度,将每个特征作为后向传播(Back Propagation,BP)神经网络的输入特征,提出基于BP神经网络的DoS攻击检测方法,该方法能够同时检测针对客户主机的DoS攻击和针对控制层的高速率DDoS攻击;另外提取六个流规则的字段特征,将每个特征进行数值化处理得到因子分解机(Factorization Machine,FM)机器学习算法的输入特征,提出基于FM机器学习的DoS攻击检测方法,该方法能够检测针对数据层的低速率DDoS攻击。此外,根据SDN流表下发机制,提出了一种基于动态删除流规则的DoS攻击防御方法。在Mininet仿真平台下对本文的检测方法和防御方法进行验证,采集多种DoS攻击的流表特征。实验结果表明基于BP神经网络的DoS攻击检测方法和基于FM机器学习的DoS攻击检测方法能够分别有效地检测三种面向SDN网络的DoS攻击,与其他算法进行对比,这两种算法有更高的检测率。从控制流表容量和提高包转发速率两个角度验证了基于动态删除流规则的DoS攻击防御方法的有效性。"
1073,基于机器学习的地质统计学随机建模方法研究,"地质统计学随机建模方法是进行地质属性模拟的重要技术之一。其核心思想是通过已知测井数据计算实验变差函数,然后按照随机路径构建并求解克里金方程进行插值模拟,来重现地质模型可能的样子。在传统地质统计学随机建模中一般存在如下问题:传统地质统计学随机建模方法通常不考虑地震相的划分对随机建模过程的影响,导致建模结果不能全面整体地反映地质空间结构特征,为解决此问题产生了相控随机建模方法。但传统相控随机建模方法仍然存在不足:1)传统相控随机建模方法在对地震相进行分类时,往往要处理大量地质属性数据点,计算速度非常缓慢;2)传统相控随机建模中在插值时采用的仍然是传统克里金方法,该方法构建出的克里金方程在对未知点进行插值时只考虑了属于同类地震相已知数据点的影响因素,未考虑来自不同地震相的已知数据点对待插值点的影响因素。我们有理由认为,哪怕属于不同地震相的数据点之间的相关性小于属于同类地震相数据点之间的相关性,仍然有必要将这种相关性考虑进去。为解决以上问题,本文引入机器学习分类技术中的稀疏表示谱聚类方法对地震相进行加速聚类,并且在考虑属于不同地震相的已知数据点的影响下进行地质属性变量的随机建模。在地震相分类过程中往往需要处理大规模地质属性数据,其计算量和复杂度在实际研究中通常让人难以接受。为此本文在传统谱聚类算法的基础上,提出基于真实测井数据的稀疏表示谱聚类方法,来加速计算过程。通常情况下加速聚类的代价,是聚类效果的损失,但本文提出的基于真实测井数据的稀疏表示方法在一定程度上可以减少这种损失。同时,在随机建模的插值过程中,本文对传统简单克里金方程进行一定程度的改进,在方程中引入属于不同地震相的点之间的相关性,使得建模结果可以更全面地展现空间地质结构特征。地震相对于地质分析具有重要参考意义。本文力求对地震相进行快速准确划分,在对未知点进行插值时尽量考虑属于不同地震相的点相互之间的相关性,对传统相控随机建模方法分别在相划分和插值方面进行了一定改进,对地质勘探和地质储层预测具有一定意义。"
1074,数据挖掘支撑下的城市功能区识别研究,"土地是国家最重要的自然资源,土地利用分析对于认识和理解土地的情况有着重要的意义。近年来,随着数据挖掘和大数据等技术的快速发展,除了传统的土地相关数据外,城市居民的打车出行数据也对了解和认识城市用地有着很大的帮助。城市居民的出行行为能够反映城市用地之间的相互作用,蕴含着城市用地的利用情况和相关规律,透过对出行数据进行数据挖掘对于深入理解城市用地有着重要的意义。同时,不同城市用地承担着不同的社会功能,有着不一样的社会经济属性,对城市功能区的识别对于理解城市的空间结构和加强对城市用地的理解有着深刻的意义,这也使得城市功能区识别问题成为了城市土地利用和城市规划方面的一个研究热点。因此,本文通过成都市2016年的滴滴出行数据对城市用地进行了多个维度分析,并基于城市静态数据和出行动态数据建立了城市功能区识别模型。本文的主要研究工作具体如下:(1)数据获取及预处理。本文数据涵盖成都市主城区及其周边区域,数据包括城市POI数据、路网数据、滴滴出行数据和城市用地数据等。数据来源于高德地图平台、OpenStreetMap和滴滴出行公司。本文对上述数据进行了包括坐标、投影与格式转换、空间分析与处理、数据清洗、数据分割、数据标注和路网划分在内的多种预处理。(2)通过滴滴出行数据对城市用地进行分析。本文基于滴滴出行数据对多种城市用地(包括住宅,商业,绿地,办公和公共服务等)从时间,空间等多个层面进行统计和可视化展示,并对比分析不同城市用地上人员流动的差异,有助于更好地理解不同城市功能区的特点。同时从打车出行的角度剖析部分城市用地的供需情况。(3)城市土地功能区识别模型研究。本文先是通过对城市静态数据做统计分析和数值计算,选取XGBoost和LightGBM作为基模型建立城市功能区识别模型,并通过分层抽样做5折交叉验证,计算各类的准确率、召回率以及平均准确率来评估模型。然后使用滴滴出行动态数据做相关统计分析和数值计算,并由出行数据构造文本文件,将Skip-gram模型、doc2vec模型和LDA模型等自然语言处理技术迁移到城市功能区识别问题中,训练相应神经网络或模型并得到城市用地向量和城市用地-隐功能区分布,以此提升机器学习模型的识别效果,最后对两种标注数据较少的城市用地使用Balanced Sampling过采样技术,改善了分类数据类别不平衡的问题。实验结果表明城市用地上的人员流动规律可以反映城市用地的特性及城市用地间的差异。基于多源数据(静态数据和动态数据)的模型效果要明显好于基于单一数据源的模型。XGBoost和LightGBM这样的提升树模型作为机器学习基模型有着十分优越的效果。合理地迁移doc2vec、LDA等自然语言处理技术和Balanced Sampling过采样技术能够稳定提升城市功能区识别模型的平均准确率,同时也可以改善分类类别不平衡的问题。"
1075,FPSO软刚臂单点系泊系统智能损伤识别研究,"在我国渤海海域,浮式生产储油卸油装置(Floating Production Storage and Offloading,FPSO)一般有十年以上的船龄,它们的系泊方式以永久式的单点系泊为主。海上的单点系泊系统除了风浪流等复杂环境荷载外,还承受着来自FPSO船体的作用,特别是连接二者的铰接点处极易产生人眼不易判别的损伤。基于环境荷载的结构特征提取和损伤识别都假设荷载是平稳的宽带随机过程,但是,对于海洋浮式平台来说,这样的假设很难满足;另一方面,非平稳的海洋环境荷载作用在非线性的海洋结构上,在不同时段结构的固有特征是不同的,说明需要对结构进行长期的定点监测。针对FPSO软刚臂单点系泊结构的特点,本文采用重相干函数进行了特征提取的方法,并利用机器学习的方法进行智能参数分类。利用软件进行了仿真和模拟,还利用海上现场实际监测数据进行了分析和验证,从而避免了环境荷载的假设,主要工作如下:1.利用Matlab/Simulink进行二阶非线性系统仿真,得到不同参数设置时非线性系统输入和输出数据,利用重相干函数进行特征提取、利用SVM与BP神经网络进行特征分类。2.利用ADAMS动力学软件进行软刚臂动力学模拟计算,得到不同结构参数条件下的软刚臂输入和输出数据,利用重相干函数进行特征提取、利用SVM和BP神经网络分类器进行特征分类。3.利用重相干函数对渤海海域现场监测得到的损伤前后软刚臂单点系泊系统输入和输出进行特征提取和特征识别,提取结构输入和输出之间的重相干函数特征,结果表明基于重相干函数的方法可以识别到软刚臂单点系泊系统结构固有属性的改变,即可以通过重相干函数的方法能够识别到结构发生了损伤。本文所提出的基于重相干函数和机器学习分类的智能特征提取和损伤识别的方法,避免了环境荷载的假设,该方法的准确性在上述三个非线性系统中均得到了验证,说明当非线性系统参数变化时即结构出现损伤时,能够通过该方法从重相干函数特征的变化规律中识别出参数改变;得到的结构损伤识别结果准确率较高,验证了该方法的在实际工程中的有效性。对软刚臂单点系泊系统结构监测提供了新方法和新思路,为软刚臂单点系泊系统结构这类存在输入和输出的多刚体结构的健康监测和损伤识别提供一定的理论参考。"
1076,非均衡数据处理算法的研究与应用,"近年来,随着计算机科学和电子通信技术的发展,人们已经进入了大数据时代。原始数据的数据量以及数据种类的爆炸式增长,使各行各业对数据处理技术的需求极为迫切,为数据挖掘和机器学习提供了巨大的机遇。传统的算法都建立在数据集类分布均衡以及误分代价相等的基础之上,但在实际任务场景中,我们需要处理的绝大部分数据都是非均衡的,例如指纹识别、面部识别、面部年龄估计等。因此对非均衡数据分类算法的研究已成为机器学习和数据挖掘领域的热点。本文主要研究非均衡数据的处理算法,并且从以下三个方面开展研究工作:首先,传统算法在处理非均衡数据时通常仅考虑数据的空间分布而忽略空间距离,针对这一不足,本文提出基于K-means和改进MaxDistance规则的集成方法。该方法结合了原始数据的空间分布和空间距离的特点,在不丢失任何有用信息、不增加任何人造数据的条件下将二类非均衡问题转化成均衡问题。与现有的二类非均衡数据处理算法相比,实验证明了此方法在处理相同的标准公开数据集时具有更好的分类效果。其次,本文提出一种基于特征权重和聚类方法相结合的欠采样算法―Uscfk算法。该方法针对二类非均衡数据,通过将对分类结果影响较大的特征权重值增大的同时将对分类结果影响较小的特征权重值减小,使其在与K-Means方法结合使用时能够抽样得到比较适合分类的多数类数据。具体来说是提出了一种改善特征权重赋值的方法,抽样出更有利于分类决策的样本数据,并将其与聚类算法相结合以构建出针对非均衡数据的分类模型,最后将此算法在KEEL数据集上进行实验,结果证明该方法不但提高了分类器对于非均衡数据的分类性能且鲁棒性强。最后在机器学习经典数据集wine数据集上对本文提出的算法进行了验证,通过与传统分类算法的对比,本文算法可以有效提高分类效果,而且在葡萄酒分类中的应用也展现出不错的性能。"
1077,支持汽车配件销售预测的方法研究与实现,"随着汽车销量及保有量的不断增大,汽车生产及售后服务过程中的汽车配件需求量也与日剧增,中国的汽车配件市场也将迎来新一轮爆发期。面对汽车配件庞大的市场空间,中国的汽车配件企业想要在激烈的汽车配件市场竞争环境中抢占市场份额并获取利润,除了不断提升配件质量外,还需要大大提高配件协同管理能力,降低配件管理成本。然而,尽管近年来汽配企业部署了供应链协同及仓储系统的应用而提升了汽配企业的管理水平,但汽车零配件的及时供给率低下与库存积压严重却始终是两大困扰汽车零配件企业的突出和难点问题。为了解决这些问题,企业需要从海量的历史销售数据中抽取出有用的信息,实现对汽车配件的市场需求进行有效地预测。为此,针对汽车配件需求量预测存在预测模型单一、未对影响汽车配件需求量的特征进行特征抽取等导致预测的准确性低等问题,本文围绕国家重点研发计划课题“分布式资源巨系统及资源协同理论”(课题编号:2017YFB1400301)中的第三方“基于ASP/SaaS的制造业产业价值链协同平台”中近10年汽车配件企业积累的配件销售业务数据展开研究。本文在分析汽车配件销售预测存在的问题及需求的基础上,完成面向平台的汽车配件销售预测的方案设计。针对配件销售业务数据中存在的缺失值、异常值、数据格式不规范等问题,采用数据处理工具Pandas和Numpy完成对配件销售历史数据的清洗和转换,为后续研究工作提供数据质量的保障;在分析汽车零配件数据特征及不同零配件特征影响力的差异特点的基础上,根据不同特征抽取方法的优劣,同时考虑抽取效率和抽取准确率,提出基于Filter和Wrapper模式的双阶段特征抽取方法,基于此方法完成平台中配件销售业务数据特征的抽取;针对更换周期短、数据规模大的汽车零配件,提出基于长短期记忆,即LSTM(Long Short Term Memory)的预测模型;针对更换周期长、数据规模小的汽车零配件,提出基于机器学习的多模型融合预测模型,并对算法进行了实验验证。"
1078,基于中医症状的方药功用预测分析研究,"辨证论治是中医认识和治疗疾病的基本原则。辩证是指医生根据四诊获得的疾病信息辨清疾病的病因、性质、部位、邪正关系等。中医将这些诊断结果称为“证”,认为“证”反映出疾病发展过程中某一阶段的病理变化的本质,比“症状”更能揭示疾病的本质。论治则是根据辩证的结果提出治疗方法,中医治疗疾病的主要方法是方剂,即根据“证”给出相应功用的药物,结合配伍理论开出相应功用的处方。在中医临床诊疗过程中,辩证是关键一环,是决定治疗方法的前提和依据。但是辩证的结果依赖于医生个人的临床经验以及本人对中医理论的认知理解水平。不同医生可能会给同一病人开出疗效不同甚至相反的处方,造成中医诊疗结果缺乏一致性和疗效评价标准。如何减少中医诊疗过程对医生主观因素的依赖,提高中医诊疗的整体质量和水平,是目前中医临床研究中的热点问题。针对这一问题,本文提出减少辩证环节、直接由中医症状推荐方药功用进而推荐中药处方的解决思路。为验证该思路的可行性,需要首先研究中医症状与方药功用间的关联关系。为此,本文利用中医现代方剂数据、中华本草数据及少量古籍方剂数据,采用机器学习方法建立中医症状与中医方药功用之间的预测模型,根据预测结果分析中医症状与方药功用间的关联关系。本文主要开展了以下研究工作:(1)调查分析了中医基于症状群推荐方药功用方面的研究现状,提出了基于多种分类模型预测症状-功用关系的方法;(2)构建了现代方剂医案、中医药典及古籍方剂的关系数据集。运用余弦相似度和Dice距离实现了症状特征的规范,解决了数据特征中一词多义、多词一义、词义模糊、词义交叉或涵盖的噪声数据问题,实现了基于TF-IDF算法的中医文本数据向量化转化;(3)建立了基于机器学习算法的中医症状-方药功用预测模型。采用SVM算法、朴素贝叶斯算法、KNN算法、CART算法等多种通用机器学习算法建立中医症状-方药功用预测模型,实现基于中医症状预测方药功用,并对预测结果及模型性能进行对比分析和评估。本文构建的预测模型准确率达到80%,研究结果表明中医症状与方药功用之间存在较强的关联关系,为下一步构建基于中医症状的中药处方推荐模型、开发中医辅助临床决策系统奠定了必要的理论基础。"
1079,面向微博文本的命名实体识别方法研究,"命名实体识别作为自然语言处理领域的基本任务之一,在信息检索,自动问答,知识图谱等领域发挥着重要作用。目前,关于命名实体对规范性文本的识别研究相对成熟,但对微博等非标准文本的命名实体识别研究相对较少,而微博文本的命名实体识别效果不如规范性文本。面向微博文本的命名实体识别任务已成为研究的热点。随着深度学习方法在自然语言处理领域中的广泛应用,通过深度学习方法来提升命名实体识别任务的性能已经成为一种普遍流行的方式,因此,如何充分利用网络文本特性并结合深度学习方法,进而提出适用于网络文本的命名实体识别框架成为了本文的研究重点。鉴于微博媒体行业的文本内容较为口语化的特点,本文将微博文本规范化过程与命名实体识别任务联合建模,提出联合文本规范化的命名实体识别框架;将非规范的网络文本通过查找非规范词典替换非规范词的方式进行规范化处理,并提出了融合注意力机制的实体识别模型进一步改善了面向微博文本的实体识别性能。本文的主要创新点和贡献如下:1.提出一种基于非规范词特征的word2vec训练词向量的方法计算相似度,通过训练非规范词的高维词表,将组合实体向量表示与高维词表的向量进行相似度计算;提出K-means聚类和Brown聚类算法对微博实体进行聚类,得到候选规范词集合以确定最佳候选的实体,最后将非规范实体替换成规范的实体。2.提出一种确定候选规范词数目的方法,使用规则对其过滤;最后依照非规范词典对文本进行规范化处理。3.提出一种融入Attention机制的长短时记忆网络(LSTM),用于关注与实体相关的信息,并缓解上下文信息冗余或出现噪音的问题。在设计编码层时,将双层双向长短时记忆网络(SC-BiLSTM)模型作为向量的编码层,提取上下文的深层语义信息,来辅助实体识别任务。本文针对以上方法进行对比实验,实验结果表明:相较于Hassan提出的文本规范化模型的精度提升了 4%,SC-BiLSTM_ATT模型的精度在基线系统的基础上提升了 10%;由此可见,本文提出的联合规范化的实体识别框架适用于面向微博文本的命名实体识别任务,并且提出的SC-BiLSTM_ATT模型与传统模型相比较能有效提升实体识别的性能。"
1080,基于机器学习方法的彩票终端机异常检测,"彩票是国家为筹集社会公益基金,促进社会公益事业发展而特许发行、依法销售,自然人自愿购买,并按照特定规则获得中奖机会的一种凭证。其中比较主流的彩票有体育彩票、福利彩票等。彩票行业的参与者包括彩票的监督机构、管理机构、发行机构、销售点、服务机构和购买彩票的大众群体等。为保障彩票行业健康稳定的运行以及发行机构和彩民的切身利益,营造良好的社会环境,及时检测出有异常情况的彩票终端机具有十分重要的意义。早期彩票销售点较少、工作人员较多,专业技术人员可以通过经验方法检测出异常终端机。但随着销售点的激增和自助售票机的试用,传统的人工检测方法已满足不了彩票行业的需求,需要既智能又高效的方法对异常终端机进行检测。故本文从彩票终端机日志数据出发,利用基于机器学习的方法实现了对异常终端机的自动检测。本文选取某彩票终端机的日志文件,通过对日志数据研读、数据清洗、特征提取之后利用KNN、Logistic Regression、随机森林和Adaboost四种机器学习分类模型进行终端机异常检测,结果表明随机森林和Adaboost两种集成模型检测准确率较高。最后利用ROC曲线对随机森林和Adaboost两种模型进行评估,结果表明Adaboost模型分类效果更加显著,AUC值达0.89。整个过程通过python语言编码完成。"
1081,基于NLOS误差识别与消除的TOA无线定位算法研究,"随着无线通信网络和物联网的发展,基于位置的服务(Location Based Service,LBS)及其应用日趋流行。无论是在室内还是室外,人们对定位精度的要求越来越高。但由于密集的城市建筑和复杂的室内环境,往往存在诸多干扰,导致定位精度严重受损。在所有干扰中,影响最大的是非视距(Non-Line-of-Sight,NLOS)干扰,因此如何有效地识别NLOS误差并进行消除成为当前研究的热点。本文重点对NLOS误差识别与消除算法中先对NLOS信号进行识别然后再消除的算法进行了学习研究。因为如果识别出NLOS信号并进行丢弃,仅使用视距(Line-of-Sight,LOS)信号进行位置估计会使得定位精度大幅度提高。通过对文献的查阅和研究,本文对目前NLOS误差识别与消除技术的发展现状进行了归纳分析。总结了在混合LOS/NLOS环境下,为了提高定位精度,国内外针对缓解NLOS误差的研究现状。NLOS误差缓解技术可以分为两种:第一种是直接对NLOS误差进行抑制,第二种是先识别出含有NLOS误差的信号然后丢弃,仅使用LOS信号进行定位。本文具体相关工作如下:首先,本文介绍了 NLOS误差传播模型,并以残差加权算法及其改进算法为例分析了 NLOS误差对定位精度的影响。通过对传统RWGH算法及其改进算法定位性能的仿真对比分析,发现三种算法虽然能在一定程度上缓解NLOS误差。但在NLOS基站数目较多和NLOS误差较大的情景下,并不能达到很好的缓解作用。其次,本文讨论了基于信号参数和信号检测法的NLOS识别算法。分别研究了广泛应用于室内的UWB定位系统中基于信道参数的似然比检验和非参数机器学习的识别算法和应用在范围更大场景中的基于极大似然和Neyman-Person准则的NLOS识别算法。仿真结果表明,在特定场景中使用信号检测的NLOS识别算法可以有效地识别出包含NLOS误差的信号。然后,本文利用Cayley-Menger行列式设计了应用在无线传感网络定位系统中的NLOS识别与消除算法。该算法首先对所有锚点进行分组,对每组锚点应用NLOS检测算法检测出组合中的锚点是否存在NLOS信号。然后遍历所有组合的检测结果,确定具体的LOS和NLOS锚点。最后,结合LS/RWGH定位算法,仅使用LOS锚点进行定位。仿真结果表明,该算法具有良好的抗NLOS特性,能够在混合LOS/NLOS环境下保持良好的定位精度。最后,对本文所做的研究内容进行了归纳总结,分析了文章的不足以及可改进之处。"
1082,面向脑网络的特征选择方法研究及应用,"在机器学习领域,随着样本特征维数的增加,学习算法常常遇到小样本高维数的问题。特征选择方法由于能够简化模型并且极大程度上提高了学习性能,已被广泛应用到机器学习和医学图像分析等领域。近来,特征选择方法也被应用到复杂结构化的数据分析中,例如脑网络分析。然而,这些研究通常使用机器学习中的典型的特征选择方法,而忽略了脑网络自身内在的特性,如网络自身的拓扑结构的信息,以及网络数据的整体分布信息,从而可能影响脑网络分析的性能;同时,在脑网络分析中,构建的脑网络通常为加权连接网络。例如基于功能性核磁共振成像(functional magnetic resonance imaging,fMRI)构建的功能性脑网络是一个全连接的加权网络。为了刻画脑网络拓扑结构信息,需要对网络进行阈值化处理。一方面,目前仍没有一个好的标准去确定相应的阈值。另一方面,不同的阈值化的脑网络展现不同的拓扑特性,这些拓扑特性可能包含互补信息,能够进一步提升脑网络分析性能。基于此背景,本文展开了面向脑网络的特征选择研究工作,具体工作如下:(1)针对处理网络数据研究,通常是提取网络的局部测量作为特征向量被用于随后的特征选择和分类,存在忽略了自身固有的网络拓扑结构信息导致分类性能降低的问题,本文提出一种面向脑网络的单阈值下基于图核的特征选择方法(gk-SFS)。提出的gk-SFS方法不仅保留了网络数据自身拓扑结构信息,而且保留了网络数据的整体分布信息。具体而言就是:提出的gk-SFS方法首先引入图核(构建在图上的核)来计算脑网络的相似性,并将其嵌入到了一个Laplacian正则化项,其次,使用一个L_1范式稀疏化项,保证只有少量的特征能被选择。在两个真实脑网络数据集上,实验结果表明,相比较已有的方法,提出的gk-SFS方法能够取得更好的分类性能。(2)为了充分利用网络拓扑结构信息和不同阈值下脑网络的互补信息,本文进一步将提出的gk-SFS方法扩展到多阈值下的特征选择,提出了一种面向脑网络的多阈值下基于图核的多任务的特征选择方法(gk-MTFS)。通过同时选取多个不同阈值的网络互补信息进一步提升网络分析的性能。具体而言,通过多任务的方式探索不同阈值下脑网络传达的互补信息,利用L_(2,1)范式将会使少量的特征从多个阈值任务中被联合选择,并利用基于图核的Laplacian正则化项,用于保留网络的拓扑结构信息和网络数据分布信息。在两个真实脑网络数据集上的实验上验证了提出gk-MTFS方法能够进一步提升脑网络分析性能。"
1083,基于隐式随机梯度下降法的研究,"在统计和机器学习等领域,参数估计是一类值得研究的问题,广泛采取通过对目标函数进行优化的思想。然而,随着计算机的出现和信息时代的到来,有时需要处理数百万甚至数十亿个训练样本的优化问题,统计机器学习方法的能力受到计算时间而不是样本大小的限制,广泛使用的基于优化的估计方法无法应用于这些大规模的现代数据集中。在这样的背景下,随机梯度下降法逐渐引起人们的关注,这是一种递归估计方法,相比于传统的优化方法每一次估计都要遍历所有的数据集,这种方法每一步只需要利用少量的数据对模型参数进行更新,因此可以很方便的对大规模数据集求解参数估计。然而,传统的随机梯度下降法是数值不稳定的,如果选取较小的学习速率参数,收敛会变得缓慢;如果选取较大的学习速率参数,既会导致较大的渐进方差,同时也可能会导致数值发散。因此,需要谨慎选取学习速率参数的值。一些参数选择方法不断的被提出和改进,本文将会研究一种基于标准的随机梯度下降法的变体方法,即采取隐式更新的思路对传统的方法进行改进,本文称之为隐式随机梯度下降法,为了便于区分,称传统的随机梯度下降法为显式随机梯度下降法。本文的核心部分将会分别应用显式随机梯度下降法和隐式随机梯度下降法对两种经典的统计模型求解参数估计,为了保证结果的全面性和可靠性,分别选取一个典型的回归问题和一个典型的分类问题,即线性回归模型和logistic回归模型。针对两种随机梯度下降法,选取常用的三种参数选择方法,同时以R语言统计软件中最经典的方法1m(.)和glm(.)作为基准方法。通过实验结果可以看出,无论是对于回归问题,还是对于分类问题,相比于传统的方法,两种随机梯度下降法大大减少了执行时间,因此更适用于大规模的数据集。具体的,在某些参数选择方法下,应用显式随机梯度下降法估计的参数值与实际参数偏离较大,表现出了不稳定性,因此在实际应用的过程中需要对参数进行谨慎的选取。而相比较而言,隐式随机梯度下降法在三种参数选择方法下都是很稳定的。因此,相比于显式随机梯度下降法对学习速率参数的不稳定性,本文建议隐式随机梯度下降法是更优的,值得进一步研究和关注。"
1084,多模数据驱动的胃癌筛查智能辅助决策方法研究,"胃镜检查是发现胃部可疑病灶、实施胃癌筛查和早期诊断的重要手段。不同等级医疗机构的胃癌筛查能力存在较大差异,基层医疗机构的胃癌筛查水平相对较低,导致胃癌早期诊断的敏感性在全球范围内长期处于较低水平,胃镜报告辅助分析系统是解决该问题的关键。因此,对胃癌筛查智能辅助决策方法的研究具有重大的理论意义与实践价值。本文围绕现有胃癌筛查智能辅助决策方法面临的非结构化胃镜报告文本处理困难、易过拟合、胃癌误诊与漏诊的负面影响非均等的问题,提出一种基于同质集成学习的胃癌筛查智能辅助决策方法Endo-GCS;在此基础上,考虑到Endo-GCS方法依赖手工特征构造、无法处理多模态医学数据、诊断缺乏可解释性等问题,提出一种基于多模语义融合的胃癌筛查智能辅助决策方法ID-GCS。本文具体研究内容和创新点如下:(1)提出了一种基于同质集成学习的胃癌筛查智能辅助决策方法Endo-GCS,构建了递进式局部权重求解算法PLWA,设计了分类阈值最优估计算法OTEA,用于提升Endo-GCS方法对胃癌筛查的特异性和敏感性。最后使用真实的胃镜检查报告开展对比实验,验证Endo-GCS方法对胃癌筛查效率与敏感性的提升。(2)提出了一种基于多模语义融合的胃癌筛查智能辅助决策方法ID-GCS,构建了胃镜图像语义抽取网络GCSNet和胃镜报告文本语义抽取网络TextGCS,设计了多模语义融合方法并融合了多模态医学数据的语义表示。使用真实的胃镜检查报告和胃镜图像数据进行对比实验以验证ID-GCS的胃癌筛查性能,并进行语义可视化以突显其可解释性。"
1085,LHC/ALICE实验中奇异开粲强子信号的研究,"大型强子对撞机(LHC)上所进行的每核子对质心系能量((?)SNN)高达2-5 TeV的极端相对论重离子碰撞实验旨在通过模拟净重子数趋于零的早期宇宙的极端高温、高能量密度环境,研究其所处的核物质新型态―夸克-胶子等离子体(亦称为夸克物质)态的产生和演化特性。对夸克物质性质的研究,不仅将有利于深入揭示强核力相互作用在高温、高密多粒子体系中的特性、行为,深刻理解物质深层次结构及其特征,还将为了解早期宇宙的演化历史提供重要参考,是当前基础前沿研究领域的重大科学问题之一。在极相对论重离子碰撞中,重夸克(粲、底夸克)是探究夸克物质的优良探针。在夸克物质中,重夸克将以弹性(碰撞)和非弹(诱导胶子辐射)两种方式与夸克物质发生相互作用,记录夸克物质内部信息。重夸克与夸克物质间的能、动量交换所导致的能量损失还将使部分重夸克在夸克物质内热化,并参与夸克物质的流体动力学演化过程。这不仅将改变末态重味粒子的分布特性,还将影响重夸克在夸克物质中的强子化行为。通过对奇异开粲强子(Ds,∧c....)信号的测量,不仅为探究上述特性提供了极其有利的途径,还将为深入认识重夸克在真空中的强子化机制及特性提供了优良契机。本论文第一章主要介绍工作背景,包括:量子色动力学相图,夸克-胶子等离子体物理及重夸克物理。第二章是对ALICE实验装置、物理分析软件环境以及奇异开粲强子的重建方法的简要介绍。第三章详细介绍了传统序列截断分析法和机器学习方法对信号粒子提取的分析流程,并分别给出了运用以上两种方法在不同横动量区间通过Ds→KS0K+ → π+π-K+强子衰变道对质子-铅核碰撞中Ds信号的重建结果。在第四章中,通过两种方法对比,对机器学习方法进行优化和改进,进一步提高其对信号提取的显著性和信噪比,实现对Ds信号更为高效和精确的提取。(写到总结中)此研究将为在ALICE LHC第二期运行最后一轮数据采集所获取的大统计量铅核-铅核碰撞数据中实现对开粲强子的精确测量奠定重要基础基础。"
1086,基于深度学习的超材料电磁仿真技术研究,"超材料以其特殊的电磁特性被科学界广泛关注,并成功地应用于雷达、天线、传感器和其他微波器件上。在传统的超材料的设计与仿真中,往往需要利用HFSS、CST等电磁仿真软件进行复杂的建模与大量的数值计算,如何快速、准确地对超材料进行分析成为目前超材料研究领域的一大问题。近年来,部分学者提出利用深度学习的思想构建神经网络来对超材料进行特性参数计算和结构设计的方法,为超材料设计与仿真提供了另一种思路。利用深度学习设计超材料是一种较为通用的方法,不需要考虑超材料的建模过程,也不需要对其各种参数进行电磁计算,只需要学习不同结构以及其对应的特性即可对超材料进行特性计算和结构设计,这对于超材料的研究具有很强的现实意义。本文介绍了超材料的特性以及传统电磁数值计算方法,学习了基于深度学习研究超材料结构与特性的思想,并将其应用于周期性阵列型超材料结构特性参数的计算。对于周期性超材料阵列结构,将其抽象为“0”、“1”矩阵的形式,使用Matlab与CST微波工作室联合仿真的方法对其进行建模与仿真,得到模型结构和其对应的S参数作为样本数据集,然后运用深度学习思想构建卷积神经网络,分析了卷积层深度、池化方式、激活函数和优化器选取对神经网络性能的影响,使用GPU加速的方法对仿真得到的部分样本数据集进行训练,从而构建超材料结构和其特性参数之间的映射关系,最后利用构建的映射关系对样本数据集里的训练集进行验证,实现对超材料特性参数计算的效果,为进一步通过超材料的特性进行结构的逆向设计做出了铺垫。"
1087,基于集成学习模型下的蛋白质交互作用预测方法研究,"随着后基因组发展,蛋白质组的研究正在如火如荼地进行.蛋白质相互作用的研究不仅有助于揭示生命活动的本质,而且还有助于理解疾病活动的机制和有效药物的开发.机器学习的快速发展为理解蛋白质相互作用的机制提供了新的机遇和挑战.它在蛋白质组学研究领域发挥着重要作用.近年来,已经开发了越来越多的用于预测蛋白质相互作用的计算方法.本文的模型是基于集成学习的思想,结合随机森林和支持向量机算法来预测蛋白质间相互作用.本文的主要工作包含以下几点:(1)蛋白质-蛋白质相互作用在各种生物过程中起关键作用.已经开发了许多方法来预测蛋白质-蛋白质相互作用.然而,许多现有的应用是有局限的,因为它们依赖于大量的同源蛋白和相互作用标记.在本文中,我们提出了一种新的集成学习方法(RF-Ada-DF),和基于氨基酸序列的特征提取方法,用于识别蛋白质-蛋白质相互作用.我们的方法首先通过多元互信息和归一化Moreau-Broto自相关描述符技术构建基于蛋白质序列的特征向量来表示每对蛋白质.然后,我们将提取的638维特征输入到用于判断交互对和非交互对的集成学习模型中.此外,该集成模型在AdaBoost框架中嵌入随机森林,并将弱分类器转换为单个强分类器.同时,我们还采用双误度量故障检测,以抑制训练过程中的过度适应.为了评估新方法的性能,我们对蛋白质间相互作用预测进行了几项综合测试,同时与现有的最优方法的性能进行了比较.在Heli.pylori数据集上,我们的方法实现了88.16%的准确率和87.68%的灵敏度,我们的方法的准确率提高了0.57%.在S.cerevisiae数据集上,我们的方法实现了95.77%的准确率和93.36%的灵敏度,我们的方法的准确率提高了0.76%.在Human数据集上,我们的方法准确率达到98.16%,灵敏度达到96.80%,我们的方法准确率提高了0.6%.实验表明,我们提出的方法可以很有效地提取蛋白质的相互作用信息.(2)配体-受体相互作用在细胞分化,增殖和免疫应答过程所需的信号转导中起重要作用.配体-受体相互作用的分析有助于更深入地了解细胞增殖/分化和其他细胞过程.计算技术将用于促进未来蛋白质组学研究中的配体-受体相互作用研究.在本文中,我们通过定向梯度直方图和离散余弦变换从配体和受体蛋白质序列中提取特征向量.然后我们提出了一种新的计算方法,通过机器学习方法从氨基酸序列预测配体-受体相互作用.我们在配体-受体数据集(不平衡数据集)上提出了两种模型.Neighborhood Fuzzy模型是使用模糊C均值聚类算法将正负类数据集分成若干个子平衡数据集并使用支持向量机算法得到若干个子分类器,然后使用相似性度量(距离度量)选择最优子分类器进行预测.Ensemble Fuzzy模型是使用模糊C均值聚类和bootstrap的方法将数据集平均分为若干个子数据集,然后训练若干个子分类器,最终结果由这些子分类器投票表决的方式得到.为了验证两种模型的性能,我们对配体-受体相互作用数据集进行了五折交叉验证,准确度达到80.08%,灵敏度达到82.98%,特异性达到80.02%.相比于使用单一的支持向量机分类器(灵敏度值是46.28%),模型的灵敏度提高了36.7%.然后,我们在两个蛋白质-蛋白质相互作用数据集上测试我们提取的特征提取方法,并分别达到93.79%和87.46%的准确率.我们提出的方法是鉴定配体-受体相互作用的有用工具."
1088,基于fMRI动态功能网络的智商个体差异研究,"智商作为个体认知及相关神经系统疾病判断的重要生理参数,一直是认知神经科学领域关注的热点。静息态功能磁共振成像(fMRI)是研究人脑功能的重要技术之一,对脑功能网络的动态属性进行分析是目前脑功能研究的热点。目前绝大多数关于智商个体差异的研究是基于时间平稳性假设,忽略了不同脑区间功能连接的动态变化。本研究分析了动态功能连接网络与智商间的关系。具体地,基于97名健康儿童fMRI数据,本文开展了如下三个方面的研究:(1)脑网络动态属性与智商关系研究。本研究从两方面分析人脑功能网络的动态属性与智商间关系,一是功能网络状态(state)之间的动态切换;二是功能连接时间序列的动态波动。实验结果表明,儿童部分动态功能网络的状态停留时间与智商有一定的相关关系;另外,发现部分脑区之间的动态功能连接的动态波动与智商有显著相关关系,这一结果为后续开展基于动态功能连接特征的智商预测研究提供了重要基础。(2)基于动态功能连接特征的儿童智商预测研究。考虑从特征和算法角度拓展预测模型,提取时域、频域共四种动态功能连接特征,并通过多种回归算法开展儿童智商预测研究。实验结果表明,部分动态功能连接特征(基于动态功能连接的时窗波动均值(DFC_Mean)特征及特定频段(0.075-0.1Hz)的频域特征(FFT_Feature))能够对智商实现较好预测;且最小角回归算法与时域特征的组合预测结果最佳(预测值和真实值的相关系数R=0.54),超过前人基于动态功能连接特征的智商预测结果(R=0.42)。(3)基于多视角学习的智商评估。由于动态特征和静态特征都对智商预测有贡献,多视角学习可以用于融合不同特征间的互补信息,我们率先引入多视角学习方法开展个体智商预测研究。实验结果表明,基于功能连接的静态和动态特征的多视角学习方法最优预测结果未能超过单视角预测结果,分析原因可能在于静态和动态特征都是基于fMRI数据提取的,特征之间的互补性有限。本研究的创新性在于:(1)从动态功能连接角度对智商个体差异开展研究;(2)在充分分析了基于动态功能连接的多种时域特征的预测效果之外,率先引入动态功能连接的频域特征,开展智商预测研究;(3)引入适用于高维小样本数据的最小角回归算法,并取得较好预测结果;(4)引入多视角学习方法,从特征融合角度为个体智商评估研究提供新思路。"
1089,有机化合物对水生生物毒性的预测方法研究,"随着重工业以及水产养殖业的不断发展,大量的有机污染物进入到水环境中,对人类的健康以及水生系统造成了严重的危害。目前,机器学习方法可以有效地处理数据以及建立优质的模型。集成学习基于多个基分类器建立而成,它通常比任何单个模型的性能具有更好的预测能力。因此,本研究基于文献搜集筛选的实验数据,利用机器学习以及集成学习方法,对有机化合物的生物富集因子以及水生生物的急性毒性两个指标进行预测,进而分析有机化合物对水生生物的毒性机理。在评估有机污染物对水生生态系统造成的风险方面,生物富集因子和半数致死浓度(LC_(50)s)是十分关键的参数。目前,已经开发了多种定量结构-活性关系(quantitative structure-activity relationships,QSAR)模型来预测生物富集因子以及对水生生物的急性毒性进行分类。在建立生物富集因子预测模型中,本文使用递归特征消除方法分别结合支持向量机和多元线性回归算法开发了回归模型。在回归模型中,本文从包含500种不同化合物的数据集中计算出2D分子描述符。在急性毒性的分类预测中,本文使用三种机器学习算法构建了三个集合模型,并且在分类模型中从包含400种不同化学物质的数据集中计算12种分子指纹。在回归模型中,RFE-SVM模型呈现了更好的预测能力,R~2和_(??)分别为0.860和0.757,通过其他指标也可以表明本研究的回归模型可以做出良好的预测,并且符合Golbraikh,Tropsha和Roy设定的标准,对新型化合物进行有效地预测。在分类模型中,ensemble-SVM分类模型在五折交叉验证中的总体准确率、敏感性、特异性以及AUC(受试者工作特征曲线下面积)分别为92.2%、95.1%、86.0%和0.965,在外部验证中分别是87.3%、92.6%、76.0%和0.940。本研究的ensemble-SVM模型比以前报道的模型更加稳定,并且能够给出更加准确的预测。因此,该模型能够有效地预测水生生物的急性毒性以及为对水生生态系统的风险评价做出贡献。此外,通过分析两种模型,本研究鉴定了一些与生物富集因子和急性毒性相关联的化学结构,特别是结构aaCH,芳香结构,氢键基团和水分配系数,在今后的水生毒理学实验和水生生态系统的风险评估中应当被更加关注。综上所述,本文具有以下创新性的工作:(1)建立了针对水生急性毒性的集成分类模型,获得了更优的性能参数;(2)将生物富集因子与急性毒性两类关键参数结合分析有机化合物对水生系统的风险评价。"
1090,基于矩阵分解算法的改进及在长非编RNA调控预测中的应用研究,"随着大数据时代的到来,在生物信息领域,越来越多数据有待挖掘。然而,目前的生物数据大部分是经过生物医学实验得出的,显然,其花费的成本以及耗费的精力是巨大的。最近几年,随着人工智能的普及发展,越来越多的科研人员将智能算法应用在生物大数据挖掘和分析的方向。其中,长非编码RNA是一种最近才被重视的生物大分子,其可以调控蛋白质以及微小RNA,从而对疾病产生影响。运用智能算法来研究长非编码RNA与其他分子的关系预测是当前的研究热点。在本文中,我们提出了基于矩阵分解的改进算法。该算法主要在隐语义模型的基础上,将矩阵分解后的隐因子向量用逻辑函数表示成概率值,该值表明了对应的用户和项目的关系得分。通过带逻辑函数的隐语义模型能够对推荐的结果有更好的解释,同时也有利于计算和表示,但是该方法并没有利用到协同过滤,对于用户和项目各自之间的相邻关系没有考虑。因此,我们引入了图正则化的思想将用户和项目的相似性融入到目标函数,相似性越强则对应的隐因子向量越接近。加入图正则化的逻辑矩阵分解可以实现协同过滤,但是实际中往往相似性越高的用户会对同一项目产生偏好,因此我们又根据K近邻的思想保留样本间的最强相似性,提高其在协同过滤中的影响,从而提高预测精确度。最后,我们将改进的矩阵分解算法应用在了生物信息学领域,分别是长非编码RNA-蛋白质相互作用预测和长非编码RNA-微小RNA相互作用预测。我们将长非编码RNA-蛋白质以及长非编码RNA-微小RNA近似为用户-项目模型,其中交互信息可以等价为用户对项目的评分,而长非编码RNA,蛋白质和微小RNA的序列相似性则用作协同过滤信息加入到模型中。在留一交叉验证实验中,两个模型分别取得了0.9025和0.9319的AUC值。进一步地我们又分别基于不同测试集对两个实验做案例分析验证模型的有效性。所有结果表明,虽然增加了邻接正则化会降低计算效率,但是改进的算法在预测准确性上优于其他算法,显示了算法改进后的良好的预测能力和可扩展性。"
1091,生物关联预测算法的系统分析和应用研究,"生命科学或医学中常常需要预测某些实体之间的关联,例如疾病和基因之间的关系。当前,大多数生物关联研究都是通过实验的方式来进行。通过生物实验的方法通常需要消耗大量的人力、物力和财力,而生物实体数据规模大,其组合很难穷尽,因此存在大量未被实验验证的关联。因此实验之前确定可能的关联候选集合是一个重要的问题。通过计算确定可能的潜在关联候选集合成为生物信息学当前的研究热点。例如在lncRNA与蛋白质、miRNA与疾病和药物与靶标的领域有很多基于计算的关联预测算法,也有比较新的关联问题,例如病毒与宿主的关系预测问题上还较少有基于计算方法。一般期望生物关联预测的算法具有很强的通用性,可以迁移到其他领域的关联预测问题。为了调查当前这些算法的适用性和效果,本文系统综述了预测生物关联的计算方法方面5个当前性能最好的算法。本文系统综述了这些算法的构造和应用,并根据lncRNA与蛋白质、miRNA与疾病和病毒与宿主三个生物领域关联数据的特点分别选取了合适的相似矩阵构造方法,作为算法的输入,从而在不同的领域应用,发现了不同领域最适合的相似性和最适合的算法。综合分析在相似性和算法对预测结果的影响,分析了算法对相似度变化的稳定性和对数据变化的稳定性。最后综合考虑性能和稳定性分别对三个不同领域选取最适合的算法。综上,本文在系统研究和评估了三个生物关联领域五个具体的算法,提出了针对数据特点合理设计相似度矩阵和选择适合的算法,可以有效的提高算法的预测准确度。当前生物关联预测方法的研究比较分散独立,研究者常常忽略了这些问题之间的共性和不同,本文对当前关联预测算法进行了系统分析和评估,这为不同问题的预测算法选择和数据输入提供了有价值的参考。本文所预测的潜在可能连接,为进一步生物实验确定了可行的研究范围,也为更深入地了解生物属性提供了潜在的候选。"
1092,地学空间数据三维可视化关键算法研究及软件研发,"随着大数据时代空间信息技术的飞速发展,地学空间数据的数量和规模越来越庞大。建立地学空间数据模型是解释地学现象、模拟地质过程和开展空间分析的基础,通过运用统计学、地学以及计算机科学等多学科交叉的理论与技术,对地学空间数据进行三维可视化建模与数据分析,进而搭建面向地学空间数据统计和分析的三维可视化软件平台,对于提高地学空间数据处理的直观性和准确性具有重要作用。本文从数据特征分析、空间模型设计、可视化表达方法以及空间分析算法等方面入手对地学空间数据进行了研究,建立了一系列针对地学空间数据的三维可视化建模方法,并开发出一款具有丰富交互操作的三维可视化软件平台。该研究成果将有效提高地学空间数据的三维可视化建模效率和空间分析能力,具有较好的理论研究意义和实际应用价值。本文的主要研究内容如下:1.对地学空间数据的基本特征进行分析,阐述了地学空间数据的三维空间特性以及海量、多尺度、多维、非结构化等特点;通过对多种可视化技术特点与地学空间数据特征的综合考虑,选取VTK图形库作为可视化工具包。2.对常见的点模型、线模型、面元模型(主要包括TIN模型、GRID模型等),体元模型(主要包括三棱柱模型、六面体模型等)进行研究,并根据地学空间数据的特点,设计相应的数据结构与三维可视化建模方法。3.基于地学空间数据的三维可视化模型,设计了通用的体元网格模型剖切算法,研究了空间插值算法、RF-Kriging预测算法等,有效提高了可视化建模效率和空间分析能力。4.按照软件工程方法,基于Visual Studio 2012开发环境和MFC框架设计开发了一款三维可视化软件平台,实现了地学空间数据的三维可视化构建、管理、编辑、运算及表达等功能,并对真实的地学空间数据进行了三维可视化展示。"
1093,基于随机森林的湟水流域土地利用/土地覆被变化检测,"土地利用/土地覆被变化已成为当前全球环境变化研究的热点领域之一。中等分辨率的美国陆地资源卫星数据由于其具有连续的档案的数据提供因而成为全球及区域尺度上土地利用/土地覆被重要的遥感数据源。在土地利用类型多样、垂直差异性明显、空间异质性高的复杂地形区,很难获取较高的土地利用分类精度。研究随机森林方法对复杂地形区的适应性,对复杂地形下遥感分类准确性的提高以及探索复杂地形区湟水流域土地利用/土地覆被时空变化规律具有重要意义。本文以高海拔、地形复杂破碎的湟水流域为研究区,基于1999年Landsat7ETM+、2011年Landsat5TM以及2017年Landsat8OLI影像,结合光谱、纹理、地形信息,采用随机森林方法对湟水流域三期遥感影像分区进行土地利用/土地覆被信息提取及精度评价,最后选择分类后比较的变化检测方法对湟水流域近18年来土地利用/土地覆被变化进行动态分析。主要结论如下:(1)采用随机森林算法对1999年Landsat7 ETM+、2011年Landsat 5TM、2017年Landsat 8OLI三期湟水流域遥感影像多光谱数据的脑山区、浅山区、川水区进行土地利用/土地覆被信息提取,研究表明:1999年脑山区、浅山区、川水区的总体精度分别达到了88.53%、87.05%和84.70%,kappa系数分别为0.85、0.84和0.82;2011年脑山区、浅山区、川水区的总体精度分别达到88.50%、87.54%和85.04%,Kappa系数分别为0.85、0.84和0.82;2017年脑山区、浅山区、川水区的总体分类精度分别达到了89.17%、87.42%、85.43%,Kappa分别为0.86、0.84、0.83;以上分类结果表明,随机森林方法在对湟水流域土地利用分类时,可以得到较好的分类精度,进而表明了随机森林算法在复杂地形区土地分类的适用性。(2)对比随机森林算法下的脑山区、浅山区、川水区1999年与2017年融合与未融合影像的分类精度,得到1999年融合后脑山区、浅山区、川水区总体精度分别为88.83%、87.45%、85.01%,融合后的影像分类精度比未融合影像的分类精度分别提高了0.3%、0.4%和0.31%;2017年融合后脑山区、浅山区、川水区总体精度分别为90.01%、87.88%、85.80%,融合影像的分类精度比未融合影像的分类精度分别提高了0.84%、0.46%和0.37%。表明空间分辨率较高的影像光谱信息与纹理信息更为明显,使得分类精度明显提高,同时也证明了分辨率较高的影像可以更好的提取复杂地形区土地利用/土地覆被信息。(3)本文在构建随机森林模型时,定量的分析了各地理分区决策树的数目和特征变量,分别构建了适应于三个地理分区的随机森林模型,并采用OOB精度评估各地理分区构建的随机森林模型的有效性。研究发现,在三个地理分区均以500棵决策树构建的随机森林模型OOB精度最优。(4)湟水流域各地理分区的土地利用/土地覆被变化检测表明,从1999年到2017年的近18年期间,脑山区土地利用类型中,草地和水域的面积分别减少了88.86km~2和0.99km~2,林地和未利用土地的面积则分别增加了15.92km~2和73.93km~2,草地和水域土地利用类型面积的年变化率较大分别为0.11%和0.43%。浅山区的土地利用类型中,草地与城乡工矿居住用地的面积变化较为明显,草地面积减少了94.93km~2,城乡工矿居民用地面积增加了115.17km~2,其年变化率较大为10.28%,耕地的面积减少了53.59km~2,而林地的面积增加了33.26km~2。川水区的土地利用类型中,耕地的面积减少较为明显,减少了528.3km~2,草地和城乡工矿居住用地的面积分别增加了288.67km~2和237.32km~2,水域与未利用土地的变化相对较稳定分别减少了3.41km~2和2.6km~2,其中城乡工矿居住用地和水域的年变化率较大分别为7.49%和1.25%。"
1094,云环境基于属性约简与贝叶斯的气象数据分析,"现下是大数据发展的高速阶段,数据中潜在的价值知识让众多的科研工作者热力追捧,利用数据挖掘技术挖掘气象领域数据中的潜在规律,对于提高气象预报能力意义重大。在目前的研究中,传统的机器学习算法只适合小数据量的分析,将传统机器学习方法直接应用在大数据分析中效果往往不够理想,算法运行效率和准确率都达不到预期效果,且传统方法投入成本大。气象数据之间存在高维度、依赖性强的特点,而传统的贝叶斯方法假设属性间相互对立,直接使用该方法分类的准确率较低。云计算的低成本运算快成为当前大数据运算的热门途径,但需要适当的体系结构、高效率的分布式密集型任务。因此挑选合适的机器学习算法可以高效率地处理与分析大规模的数据。并行性以及运算效率是大数据计算需要攻克的难题。本文分析了机器学习与气象数据分析存在的问题,主要从并行性与运算效率两方面出发,设计了云环境下气象数据的相关性分析策略。本文基于中国气象局气象数据中心和南宁市环保局环境监测站历年气象数据,设计云环境下使用知识约简算法和改进的贝叶斯方法对气象数据进行分析。首先考虑应用知识约简的思想降低数据的维度,在此基础上基于MapReduce设计属性关联的贝叶斯方法,探讨气象因子的相关性。实验以大气能见度为决策条件,将时间性能与分类准确率作为评估实验性能优劣的主要指标。实验结果证明本文设计的方法与传统的贝叶斯方法比较,实验运算时间与分类准确率都更优。本文基于云环境的气象数据相关性分析方案,一定程度上有效地解决了传统的气象数据挖掘存在的不足。鉴于云计算成本低、可扩展性高的特点,该方案具有较好的应用价值。"
1095,基于机器学习的全天空极光图像分类与割方法研究,"极光是一种出现在地球南北两极高纬度地区绚丽多彩的发光现象,是极区日地物理过程(特别是磁层-电离层相互作用)的最集中的表现形式。通过对极光的长期观测和研究,有助于人们分析极光的发生机制和理解极光快速复杂的演变过程,对研究地球磁场变化和日地空间电磁活动有着非常重要的意义。我国每年通过光学成像仪采集的全天空极光图像数以百万,仅用人眼去观察海量极光图像的方式显得尤为繁重。因此,如何对这些海量的极光图像进行高效、准确地分类和分割是极光研究领域的重要课题。本文针对极光图像的特点分别提出了一种极光图像自动分类方法和一种弱监督极光图像自动分割策略。在极光图像自动分类方法研究中,本文将空间转换网络(Spatial Transformer Networks,STN)与卷积神经网络(Convolutionalneuralnetwork,CNN)结合,为了使网络模型在训练过程中可以自适应对极光图像进行空间变换;采用Large-margin softmax(L-softmax)损失函数对分类模型监督优化,使得同属于一类极光类型之间的类内距离越来越小,不属于同一类极光类型之间的类间距离越来越大。本文利用2003-2009年北极黄河站越冬观测的10184幅全天空极光图像进行了分类实验,通过特征可视化分析和准确率比较,实验结果显示,本文提出的方法表征能力更强,分类准确率更高。在弱监督极光图像自动分割策略研究中,本文将全卷积神经网络作为基础网络架构,通过传统机器学习种子区域生长算法(Seeded Region Growing,SRG)生成数据标签,极大解决了深度学习图像分割网络人工标注数据难的压力。首先利用简单单弧状极光图像训练一个初始分割模型Model1,然后基于该模型,结合热点状和复杂多弧状极光图像获得一个增强的分割模型Mode12,最后对分割结果做进一步优化。本文利用2003-2007年北极黄河站越冬观测的2715幅全天空极光图像进行了分割实验,并和最新论文结果及人工标签进行了定性和定量比较,其中分割结果与人工标签的“交并比”高达60%,证明了本文训练策略的有效性。"
1096,基于化学芯片技术的混合氨基酸ML识别的实验研究,"随着当下经济社会飞速的发展,人类对物质生活的需求也在不断提高。氨基酸作为一切生命的基础组成,在物质分解过程中对自然环境有着极其重要的影响。因此,氨基酸自然而然的成为了人们关注的重点,与氨基酸有关的商业和工业所带来的环境污染也会随即产生。为了更好的了解氨基酸在高蛋白分解或人类健康生活中所存在的环境行为,必须及时对氨基酸进行相关分析研究。在自然环境中,包括生命活动所需的氨基酸在内的绝大多数物质均以复杂化学体系的形式所存在。因此,针对于混合氨基酸的识别分析研究往往会因其内部物质之间的交互反应而显得非常困难。传统科学研究中通常会选择大型的仪器对混合氨基酸进行成分检测,亦或是通过成千上万次的实验来寻找三四种氨基酸之间互相作用关系而进行相关的分析推断。但传统仪器只能检测出某一类物质或者污染物的存在和含量,却无法深入了解其所具有的环境效应。同时,传统研究方法均存在繁琐、实验周期长、昂贵的实验费用等缺点。面对传统技术对复杂化学体系进行研究时所存在的弊端,本课题组通过数年的努力探索出了一种技术手段。该技术既能将混合氨基酸内部信息进行记录与呈现,又能通过相关模型对混合氨基酸进行相关预测。依据物质之间的动态平衡关系,我们提出了一种通过化学扰动剂与化学显色剂对复杂化学体系下氨基酸所具有的内部信息进行记录与呈现的策略。我们在高通量技术的指导下,采用喷墨打印技术将化学扰动剂与化学显色剂在相应的印刷载体上进行了成千上万个有机组合。使它们按照一定规律独立的分布在印刷载体上,最终形成了可发生数量级微反应的化学芯片。同样,我们可借助于喷墨打印技术将氨基酸以不同的量同时覆盖在数百个化学芯片上。届时,复杂化学体系下氨基酸内部信息将会被化学芯片以颜色变化的形式进行记录与呈现,形成反应芯片图像。通过对反应芯片图像的初步数字化分析,我们对混合氨基酸的内部信息有了简单了解。之后又通过机器学习(Machine Learning,ML)对其内部信息构建了相关的模型。通过此模型可以复杂化学体系下氨基酸进行识别分析研究,为有关于混合氨基酸的研究提供了一定的参考。主要结论:(1)对自然环境中混合氨基酸内部信息进行记录与呈现方法的建立。基于物质内部动态平衡关系筛选出相应的化学试剂后,在高通量技术指导下通过喷墨打印技术使化学试剂均精准分布在印刷载体上形成化学芯片。化学芯片可通过颜色变化的形式对混合氨基酸内部信息进行记录与表达。(2)对反应芯片图像的数字化处理。通过相关软件提取反应芯片图像的RGB值或灰度值,并提出以等高线图、RGB直方图、以及三维曲线图的形式将反应芯片图像所蕴含的信息更直观的呈现出来,以便我们对其对比分析。(3)对混合氨基酸内部信息的初步探究。在对反应芯片图像数字化处理之后,通过对各种实验条件下所对应的数字化结果进行一系列的对比分析,初步了解了混合氨基酸内部信息。(4)对化学芯片性能的探究。通过对反应芯片的误差分析间接表明了本研究中所制备的化学芯片具有较好的精确性。同时,我们在化学芯片适用性的讨论中为它在其它领域的应用提出了一些建议。(5)对混合氨基酸识别分析模型的建立。通过反应芯片图像与反应样品的量和种类之间的对应关系,通过ML对原始网络进行了深度训练学习。最终建立一种属于混合氨基酸内部信息的网络模型,为混合氨基酸的识别分析提供了支撑。"
1097,锂离子电池极板冲裁毛刺的成形机理及对电池失效行为影响的研究,"锂离子电池安全性能一直为大众关注,也是锂电池研究的重点。正、负极板是锂离子电池的重要组成部分,在冲裁过程中,极板可能会产生集流体毛刺过长的缺陷,影响电池的使用寿命与安全性能,而目前尚未有针对此问题的具体研究。本文结合实验与仿真,尝试从不同角度对锂离子电池极板的冲裁行为及其冲裁毛刺的影响进行研究,从而获得理论模型,并为实际生产过程提供指导性建议。(1)对正、负极板及组成进行力学性能试验,并进行力学建模。发现负极集流体(铜箔)的极限应力及应变明显比正极集流体(铝箔)高;在集流体两面涂布的电池材料层拉伸性能差,且具有明显的压缩行为;隔膜的拉伸行为存在各向异性。在有限元软件ABAQUS中对极板进行建模并仿真上述力学试验,最终确定模型使用符合实际情况的可压缩泡沫―金属―可压缩泡沫三层结构,层与层之间使用绑定连接。(2)在ABAQUS中使用极板材料模型进行冲裁过程仿真,并将其与实际冲裁对比。发现在冲裁过程中,脆弱的上下电池材料层对冲裁力起缓冲作用,使中层集流体受弯矩发生明显弯曲,并被拉裂,造成集流体毛刺过长现象;使用冲裁模型研究冲裁间隙与模具圆角大小对于冲裁集流体毛刺长度的影响,发现随着二者增加,毛刺长度均有增加,且间隙的改变对长度影响大于圆角。(3)研究冲裁毛刺对于软包锂离子电池抵抗外载失效能力的影响。结合实际压头压入试验与仿真分析,发现冲裁毛刺会导致电池过早地发生内部短路,而不影响电池宏观力学响应。(4)探究使用神经网络分析极板材料属性对冲裁集流体毛刺长度影响的可行性。使用已有数据建立了一个三层神经网络模型,结合蒙特卡洛模拟与敏感性分析,发现毛刺长度对于电池材料层颗粒粒径和电池材料层与集流体之间的结合力最为敏感,因此在设计与测试极板时需要重点考虑其影响。"
1098,基于支持向量机与模糊贝叶斯方法的煤矿事故致因研究,"中国是全球最大的煤炭生产与消费国,煤炭于我国能源结构中占据主导地位。煤炭安全稳定生产事关我国经济的可持续发展,对保证我国的能源安全具有十分重要的意义。近年来,我国煤矿的安全生产水平取得了可喜的进步。但是,随着煤矿机械化、信息化程度的加深,现如今煤矿已经成为一个复杂的非线性系统,其数据繁多,事故致因隐藏深,事故与致因间的联系模糊,对煤矿进行致因分析与事故预防造成了很大的困难。因此,本文以煤矿事故致因为研究对象,利用机器学习方法对其进行研究,解决了煤矿事故致因分析困难的问题,旨在对煤矿企业生产中存在的事故进行及时的预测,对事故致因进行有效的排查,达到预防和减少煤矿事故发生的目的。本文进行的研究如下:对如何快速准确地识别煤矿事故类型进行了研究。针对煤矿系统获取到的数据信息庞杂,无法通过理论模型直接进行致因分析,事故类型难以得到准确预测的问题,提出了煤矿事故支持向量机分类推荐模型。并对传统支持向量机无法高效获取较好模型参数的缺陷,利用启发式算法对其进行改进,分别提出基于粒子群算法和人工鱼群算法的支持向量机参数改进方法,介绍了两种算法的参数优化流程,对两种方法进行了对比验证,选取分类推荐效果较好的人工鱼群支持向量机用于煤矿事故分类模型的构建,给出了基于改进支持向量机煤矿事故分类模型的应用流程;对如何确定具体类型煤矿事故的致因影响进行了研究。针对煤矿系统中致因变量不确定性强,事故形成机理复杂,不好进行致因排查分析的问题,提出了煤矿事故模糊贝叶斯致因分析模型。将模糊理论应用于贝叶斯模型中,解决了致因变量的不确定性问题。运用结构学习与参数学习方法更好地挖掘出致因间的联系,使得致因变量间关系的表达和推理变得更加直观清晰。并针对传统结构学习方法K2算法构建模型效率不高,容易过学习的缺陷,结合人工鱼群算法对其进行了改进,提出基于人工鱼群-K2算法的结构学习方法。另外,基于煤矿事故模糊贝叶斯致因分析模型给出了模型的分析计算方法与分析流程。应用X煤电集团实例进行验证,结果表明:煤矿事故支持向量机分类推荐模型能有效对煤矿事故进行分类推荐与识别;煤矿事故模糊贝叶斯致因模型能快速准确确定具体类型事故的发生率、关键致因变量与致因变量排查顺序。这将大幅降低煤矿事故预防的工作量,提高致因排查的效率,减少事故的发生,具有很好的实际应用价值。该论文有图38幅,表22个,参考文献96篇。"
1099,基于深度迁移学习的数控系统领域技术术语识别,"近年来,随着工业4.0、互联网+等科技产业变革范式的提出,科技创新发展迅速,数控系统技术作为一种战略性技术无疑属于国家重大技术领域,大力发展数控加工技术是由制造大国走向制造强国的重要条件。在此背景下,研究识别数控系统领域新兴技术术语,预测领域发展趋势,对于国家和企业制定战略性发展规划具有重大意义。专利文献是技术情报的最新来源,被广泛的用于新兴技术预见,专利文献易于使用,但术语难以挖掘、抽取难度大,存在缺乏术语标签的问题,因此如何针对专利文献抽取技术术语是本文研究的重点。针对现有研究的不足,本文首先引入深度迁移学习的思想,基于命名实体识别技术,构建了数控系统领域新兴术语识别、技术类别划分和专利趋势分析的整体方案;然后,本文基于语言模型和基于命名实体识别模型的迁移学习技术术语识别方案,利用成熟的公共领域源数据,运用Bi-LSTM(双向长短时记忆)模型实现跨领域迁移,有效识别技术术语并过滤高频非术语词串;最后,本文通过构建术语词向量,选用WMD(词移距离)技术计算文档相似度,通过K-means对文档和技术术语划分技术类别,聚类结果以术语形式呈现,更为准确易懂,可解释性更强。基于上述步骤,本文收集了2013年~2018年数控系统(CNC)领域专利文献,通过将新闻领域源数据已有知识迁移到数控系统领域目标数据,解决了专利文献缺少标注的问题,通过构建术语词向量和文档聚类,将数控系统领域分为硬件化、软件化、工艺化、网络化、智能化五大类。本文结合专利分析的方法,整合划分的技术类别,对2013年~2018年数控系统领域发展动向进行综合分析。"
1100,基于半监督机器学习的数控机床领域关键技术识别研究,"2015年,中国工程院启动了“中国工程科技2035发展战略研究”项目,拟提出面向未来二十年的中国工程科技领域技术清单,支持中国工程科技战略布局。关键技术识别是制定数控机床领域技术清单的核心步骤。目前基于专家经验和文献计量分析的关键技术识别方法存在识别周期长、主观性大、技术所属领域不明确、技术识别不全面等问题。针对这些问题,本文进行了一系列的改进。本文首先提出了融合专家知识的交互式主题模型,并对数控机床全领域论文数据进行了关键技术识别,解决了“识别周期长、主观性大”的问题。为了改进仅采用交互式主题模型进行关键技术识别的不足,本文提出了融合文本级must-link知识的TM-GSDMM半监督文本聚类算法,并对数控机床领域论文数据进行划分,得到了数控系统、工艺系统、智能化、网络化、机床部件五个子领域,解决了“技术所属领域不明确”的问题。为了对子领域论文数据进行关键技术识别,本文提出了融合词语级must-link知识的WM-ATM半监督作者主题模型,并分别对五个子领域进行了关键技术识别,解决了“技术识别不全面”的问题。最后,基于本文提出的方法总结出了全领域关键技术识别、技术领域划分与子领域关键技术识别支持技术清单制定的流程,依此搭建了“聚类清单工具”,在中国工程院中长期项目组被广泛使用;并以数控机床全领域的论文数据为输入,输出了数控机床领域技术清单,得到了专家认可。"
1101,基于残差卷积网和支持向量机的机器人铣削颤振辨识研究,"采用机器人铣削,不仅可以降低铣削加工成本,还可以提高制造自动化水平。但是,与传统机床相比,机器人刚性较弱,容易发生振动问题,且刀具端动态特性存在位姿依赖性,采用传统的以加工系统参数为模型输入的解析法,辨识机器人铣削颤振,难度大且精度有限。通过构建不同机器人铣削颤振状态下的振动数据集,基于机器学习算法,可以建立以直接的物理振动信号为输入的颤振辨识模型,从而准确辨识机器人铣削颤振。基于解析法,建立机器人刀具端动力学方程,通过时域法求解动力学方程,并预测稳定性叶瓣图,据此设计实际平面铣削实验,采集振动信号和工件表面振纹,建立了机器人不同铣削颤振状态下的振动数据样本集。通过观察表面振纹,结合频域和时频域方法,分析了机器人铣削振动信号中的时变颤振成分,并将机器人铣削颤振分为:稳定、过渡、规则颤振和无规则颤振,共四类状态。将机器人铣削振动信号转换为相应的时频谱图,推导建立深度残差卷积神经网络模型,将时频谱图当作图像进行分类。通过使用输入归一化和提升小波分解尺度,提升了模型的分类精度和收敛速度,采用VMD算法对振动信号进行预处理,使模型平均辨识精度进一步提升,达到95.28%。同时,使用Python语言和Qt软件,编写了基于深度颤振辨识算法的可视化软件模块,实现了离线状态下,对所选机器人铣削颤振时频谱图的状态辨识。为了实现机器人铣削颤振在线辨识,基于VMD对机器人铣削振动信号进行分解,得到一定数量的颤振频带,计算不同颤振频带的信息熵作为机器人的铣削颤振特征,使用SVM算法对提取到的铣削颤振特征进行分类,从而建立了VMD-SVM在线辨识算法。同时,提出了kMap算法,在避免计算全局解的前提下,分三个阶段对VMD-SVM模型的三个超参数进行优化,与传统计算方法,kMap可以快速的计算得到与全局最优解相差不大的全局次优解,最后实现的平均辨识精度为92.43%。搭建了机器人铣削振动采集硬件模块,布置振动传感器,对机器人铣削过程中的主轴端振动信号进行在线监测和采集,使用C#语言,编写了基于VMD-SVM算法的机器人铣削颤振在线监测与辨识软件模块,同时,设计实际切削实验,使用所编软件,对机器人铣削过程中的振动信号进行在线监测和辨识,通过分析铣削振动信号的FFT频谱图和工件表面信息,验证了软件的监测和辨识效果。"
1102,基于智能床垫的睡眠检测系统,"睡眠状态下的人体健康状况检测是近年来的智慧医疗领域的研究热点之一。由于现有的状态检测设备均需要贴身使用,这直接影响使用者睡眠期间的舒适度。本文提出一种非接触式的基于智能床垫睡眠检测系统,通过采集睡眠过程中床垫感知的人体压力数据,并结合智能信号处理算法实时获取睡眠状态下的人体健康信息。针对人体不同的生物特征,本文提出了以下三种检测方案:(1)提出了基于规则和基于卷积神经网络的睡眠动作识别方案。基于规则的睡眠动作识别算法根据人体动作的特点,使用方差和阈值对动作数据进行分析进而对动作进行识别。后者将睡眠动作识别问题转化为机器学习中的分类问题,利用卷积神经网络对传感器阵列数据进行分类从而实现睡眠动作识别。(2)提出了针对人体呼吸速率的计算方案。考虑到传感器阵列所采集的数据中包含许多无用通道,首先采用主通道选取算法选取合适的主通道信号,而后通过平滑滤波算法和基线漂移消除算法对数据进行预处理,以消除主通道信号中的噪声干扰和趋势项。最后,依据呼吸动作的规律性,本文根据呼吸频率选取合适层数小波进行呼吸波形重构并通过极值点计数法计算出用户的呼吸率。(3)提出了基于多小波重构和基于长短期记忆神经网络的人体心率信号计算方案。考虑心跳信号的规律性及微弱性,本文使用了多小波重构信号组合模型还原心率信号,避免了单小波重构波形失真情况,优化了重构波形。同时根据床垫数据的时序特征,本文提出长向量和长序列两种长短记忆网络,通过实验对比选取了长序列网络以提取心跳波形。最后,将各方案的计算数据与医用设备数据进行实验对比。实验结果表明本睡眠检测系统可以准确获取人体的生理状态信息,充分满足日常生活检测睡眠状态的需求。"
1103,基于深度学习的烤烟分选算法研究,"烤烟生产和收购过程中的烟叶质量分选工作目前是由工人完成的。工人分选主观性强、分级效率低等问题,催生了烟叶自动分选技术的研究。随着机器视觉的发展,基于视觉算法研究烟叶自动分选技术已经成为了一个热门课题。但目前仍然面临着一些挑战:现有的在线图像采集系统得到的数据和理想数据之间存在差异且数据有限;用传统方法手工设计的特征分类准确率不高;基于深度学习得到深层特征需要大量的已标注数据参与训练,但烟叶数据标注困难。针对上述问题,本文设计了烟叶现场数据的预处理流程,并基于深度卷积网络和迁移学习研究烟叶分组和分级。主要贡献如下:通过分析现场采集的烟叶图像,提出了烟叶现场数据的预处理方法。采用中值滤波减少图像噪声,计算Lab空间b通道频数直方图,用直方图双峰法,有效分割烟叶前景部分,并采用形态学的方法分析烟叶图像姿态剔除异常图像,使参与训练的数据尽可能趋于理想。提出了基于深度卷积网络的烟叶分组和分级模型。本文针对烟叶训练样本少、类别单一的问题,基于AlexNet模型采用两步修改法进行参数优化,防止过拟合;删去局部响应归一层同时引入批量归一层,优化网络结构。并提出主动增量学习的方法,通过计算信息熵挖掘困难样本,来避免冗余样本参与训练,从而优化训练过程中标注样本的使用数量。通过在中部橘色烟叶上的对比实验证明,参数优化可以使模型拟合得更好,网络结构优化可以改善训练过程Loss震荡问题,主动增量学习的训练优化可以使用更少的数据训练一个较优的模型。基于迁移学习算法进一步优化烟叶分级性能。针对分级过程训练样本少,准确率不高的问题,提出用训练好的烟叶分组模型迁移学习烟叶分级的低维深层特征表达。之后将其与传统方法手工设计的颜色、形状和纹理特征结合起来表征烟叶分级特征。针对烟叶数据获取实时性和不同批次数据差异影响分类准确率的问题,提出了在线迁移学习的方法。已有数据训练一个分类器,新来的数据再训练一个分类器,在接收到新数据时,用两个分类器的预测结果的加权来表示新数据的类别标签。而且这两个分类器的权重是根据错分样本情况在线更新的。实验证明,融合迁移学习和传统的特征提取方法的特征表达要优于仅用深层特征或传统特征的方法;基于在线迁移学习算法要优于只有新数据进行训练的机器学习算法,其分类错误率更小。"
1104,一种相似青梅品级半监督智能认知方法研究,"水果是世界主要农产品之一,虽然我国拥有较大的水果种植面积和较高的水果产量,但是处于初级阶段的国内水果采摘后商品化处理水平和处理能力成为制约国内水果出口的主要因素。青梅作为一种具有多重保健功能的药食资源,深受广大群众的喜欢。人工分拣模式的性能易受到操作人员经验、责任心等主观因素的影响,因此,基于机器视觉的自动分拣成为水果分级的主要技术手段。然而,相似样本的大量存在以及样本标签的获取困难是机器分拣性能不佳的主要原因。因此,如何利用大量无标签样本,以及获取局部细微差异特征是区分相似样本的关键。针对监督学习机制和深层神经网络结构的固有缺陷,本文提出了一种具有不确定认知结果熵测度指标约束的深度半监督学习相似青梅品级智能认知方法。本文的主要工作如下:(1)针对有标签相似青梅图像样本难以获取的难题,基于图的半监督学习方法利用较少的有标签数据,对大量无标签数据进行标定,用于扩充训练青梅图像样本集,降低了人工劳动强度。(2)针对相似青梅图像间差异化特征表征不充分的难题,在极大信息熵性能指标约束下构建自适应架构深层神经网络,获取相似青梅图像由全局到局部的多层面充分差异化特征空间表征,并基于可分性度量测度指标和变精度粗糙集,在有限论域不确定条件下,从信息论角度建立认知智能决策信息系统模型,提取与相似青梅品级有明确品级映射关系的简约多层面充分差异化特征空间数据结构。(3)针对深层神经网络中softmax层泛化能力不足的缺陷,以及图半监督学习无法预测新加入样本的难题,本文采用集成RVFL分类器,构建相似青梅图像简约多层面充分差异化特征空间的分类认知准则,并基于前向传播和反向更新的交替优化策略,全局迭代更新深层神经网络和集成RVFL分类器的参数。(4)针对不确定认知结果后验统计评测以及固定特征空间适用度差的难题,基于广义误差和广义熵理论定义了一种相似青梅品级不确定认知结果误差熵测度指标,实时评测相似青梅品级不确定认知结果的可信度,自寻优交替调节认知精度、网络层级和中和因子,更新简约多层面充分差异化特征空间、分类认知准则和无标签样本标定的可信度,对可信度低的相似青梅图像样本通过调节参数进行品级再认知。为了验证本文算法的有效性,对3000幅相似青梅图像样本进行了仿真实验,平均认知正确率达到98.26%,为后续在线分拣系统设计提供了理论支持。"
1105,基于视频的复杂场景火灾检测技术研究,"火灾是人类生产生活中最为常见且危害性强的灾害之一,及时有效的火灾预警技术成为近年来研究的重点。随着摄像头的普及,计算机视觉技术的发展与人们生产生活的需要,通过分析监控设备采集的视频实现火灾报警的方法逐步成为火灾检测技术的革新方向之一。与传统的基于传感器的火灾探测技术相比,基于视频内容分析的火灾检测技术不需要另外安装火灾传感器,通过对监控视频进行分析即可实现火情检测,能够避免火灾传感器因传感器灵敏程度低导致的一些漏报与误报情况;同时具有安装简单、探测范围大、不易受环境干扰、火情存档方便、扩展性强、准确性高和实时性强等优点,因此适用于山林、隧道、仓库等空间较为开阔且不适合安装传统火灾传感器的环境。基于上述优势,视频火灾检测技术己经成为当前研究的热点,且随着人工智能、计算机视觉与视频处理技术的发展,越来越高效的火灾检测技术不断出现。视频火灾检测技术主要是通过对视频内容进行分析以提取火焰特征,进行目标识别实现火灾检测。但是由于自然环境的复杂性与随机性,以及火焰无规则的形状与运动特点,目前基于计算机视觉技术的火灾检测方法仍存在误报率高、检测速度慢和抗干扰能力弱等问题。针对目前视频火灾检测技术存在的问题,本文提出一种基于目标提取、多目标跟踪和机器学习的视频火灾检测方法。该方法首先通过高斯混合模型运动检测算法对视频中的运动目标进行提取,再经过HSI与RGB结合的颜色模型对火灾目标进行分别筛选,得到疑似火焰目标,最后通过深度学习算法进行火焰与烟雾的识别,实现火灾检测。针对火灾目标的运动特点,使用基于帧间目标距离匹配的多目标跟踪算法,实现疑似火灾目标的稳定跟踪。为适应复杂场景的火灾检测任务,在火灾识别模块使用卷积神经网络的算法,以AlexNet网络结构为基础,使用微调的方式进行训练,得到具有火焰与烟雾识别能力的网络模型。最后,经实验证明,本文提出的视频火灾检测技术能对各种复杂场景的火灾区域进行有效识别,并排除非火灾物体的干扰,能够适应实时检测火灾的需求,并具有较好的扩展能力与移植能力。"
1106,基于数据挖掘的典型车辆排放因子预测研究,"随着经济的飞速发展和城市规模的不断壮大,交通运输产生的尾气排放已经成为大气污染的重要来源。为了采取有效的路网机动车.排放控制策略,减少交通尾气对环境造成的污染,构筑绿色交通体系,需要根据车辆排放因子来对机动车排放情况进行科学量化评估。然而,排放因子计算方案的相关研究绝大多数集中在交通领域,使用计算机领域相关技术来计算排放因子的研究却是一片空白。本文从计算机领域相关技术出发,对机器学习算法在解决交通领域中的机动车排放因子的计算及预测问题上的可行性进行了研究。通过使用数据挖掘中比较成熟的机器学习算法,对采集到的机动车排放数据分析建模,最终取得了较好的预测效果。本文的主要工作内容及创新点如下:(1)本文通过对采集到的机动车排放数据分析建模,最终实现了 7个预测模型来对机动车排放因子进行预测,并给出了具体的实现过程与各个模型的效果评估。通过与MOVES模型效果的对比,证明了机器学习算法在解决机动车排放因子的计算及预测问题上的可行性,为交通领域中机动车排放因子的计算及预测方法提供了新思路。(2)本文通过对实现的7个预测模型的效果进行评估,最终发现随机森林回归模型在解决机动车排放因子的计算及预测问题上可以取得良好的效果,并给出了在本数据集上,构建随机森林回归模型所使用的具体参数。(3)本文给出了影响机动车排放因子的最重要的5个特征,即机动车瞬时速度、机动车瞬时加速度、机动车车重、机动车发动机排气量与机动车燃油类型,并给出了其相对重要性比例,这为后续在机动车排放因子的计算及预测研究中对各个特征的权重调整提供了参考。"
1107,水相铜、镍、汞联合毒性HTE的检测技术研究,"随着社会经济的快速发展,水环境污染问题也越来越严重,尤其是工业废水对周边环境的污染,而在工业废水中往往是由多种污染物造成的复合污染。而采用检测手段一次只能检测出特定的一个或多个污染物指标。所以,现在需要一种方便快捷有效方法来检测工业废水中的复合污染,并且可以将污染物之间的联合效应直接或间接反映出来的一种检测方式。目前为止,也有很多的学者在研究复合污染,但是这些研究还远远不够,并且研究深度较浅。所以需要对符合污染有更多更深层次的研究。铜、镍、汞三种重金属属于工业废水中的重要污染物,并且对环境的影响都比较大。本文旨在研究出一种高通量快速检测技术,能够对Cu2+、Ni2+、Hg2+三种重金属离子的联合毒性进行快速检测分析。主要分为三个部分:混合金属溶液的联合毒性的可视化检测、混合金属溶液的联合毒性的量化、建立运算模型检测混合金属溶液。首先制备一种以酶催化反应为原理的生物化学芯片,并用所制备的生物化学芯上进行Cu2+、Ni2+、Hg2+三种重金属离子溶液联合急性毒性试验,将Cu2+、Ni2+、Hg2+三种重金属离子的联合毒性在芯片上可视化呈现。其次,在200个孔穴中进行萝卜种子水培试验。根据萝卜种子的发芽率、芽和根的长势来量化各个孔穴中的Cu2+、Ni2+、Hg2+三种重金属离子混合污水联合毒性。最后将所得图片进行标准化处理并随机分为两部分,分别用于机器学习算法的训练和运算模型系统的检测,构建GoogLeNet V1神经网络,通过在GoogLeNet V1神经网络框架中进行多次模拟训练学习,建立出生物化学芯片所记录的联合毒性和萝卜种子发芽抑制率之间关系的运算模型。所建立起运算模型可以预测暴露在Cu2+、Ni2+、Hg2+三种重金属离子混合污水环境下的萝卜种子相对发芽率。主要结论:(1)经过筛选,最终确定瓷白纸作为制备芯片的载体材料,显色体系为葡萄糖氧化酶-过氧化氢酶-邻联甲苯胺,抑制剂使用乙酸铅,碱性扰动剂碳酸钠溶液,激活剂使用铁卟啉溶液,解毒剂和酸性扰动剂使用柠檬酸溶液。该芯片会由于生物化学扰动体系和酶催化反应显色体系会显现出丰富的颜色花纹图案信息。因此可以利用构建的生物化学扰动体系来辅助检测毒性物质对生物急性毒性效应。(2)制备的生物化学芯片不仅可以记录单个金属化合物的毒性,还可以记录硝酸铜、乙酸镍和氯化汞的混合溶液的联合毒性,根据所记录芯片差值图片可以将硝酸铜、乙酸镍和氯化汞的混合溶液产生急性联合毒性进行可视化。(3)通过暴露在Cu2+、Ni2+、Hg2+三种金属离子混合溶液中萝卜种子的发芽率、芽和根的长势情况是可以将Cu2+、Ni2+、Hg2+三种金属离子混合溶液联合毒性进行量化。并且也可以通过Cu2+、Ni2+、Hg2+三种金属离子混合溶液配比可以预测萝卜种子的发芽率及根和芽的长势情况。(4)根据所建立起运算模型对测试集样本的差值图片进行其记录联合毒性和生物标签值预测。再将萝卜种子相对发芽率的预测值进行相关系数的检测并真实值进行比对。发现真实值和预测值的相关系数很高,可以通过所建立的运算模型,用萝卜种子相对发芽率来量化芯片所检测的硝酸铜、乙酸镍和氯化汞的混合溶液的联合急性毒性。"
1108,基于生成对抗网络的遥感图像场景分类研究,"遥感图像分类有着重要的应用需求,被广泛应用于自然灾害检测、土地资源利用与覆盖管理等。基于深度特征学习的方法由于能够自动提取特征,不需要大量工程技能和领域专家知识,而且通过多层提取可以学习到更好的特征表达,因此成为研究热点。生成对抗网络(GAN)作为近年来最具潜力的深度学习方法,将其引入遥感图像分类领域是一个新的思路。采用合适的数据增广方法和提高判别器的特征提取能力是开展图像分类研究的关键技术与难点,本文以GAN理论为基础,针对遥感图像场景分类提出了更具泛化性能的分类模型。主要研究内容包括:分析了现有遥感图像数据集的局限,以及分类方法存在的不足,指出其数据集较小,以及由于本身纹理特征难以提取有判别力的特征的困难。通过对GAN现状的分析,指出其特征提取过程是无监督这一局限,以及训练过程不稳定会影响分类结果这一困难。对机器学习中半监督学习的特点进行了分析,指出半监督学习在GAN中的适用性。结合半监督学习和GAN,充分利用标签信息和生成的数据,对属于无监督特征提取的原始GAN做了改进,建立了基于半监督特征提取的生成对抗网络分类模型。与现有的监督特征提取和无监督特征提取的方法相比,半监督学习对于网络特征提取能力的提高起到了一定的作用,其分类结果有所提高。通过对原始GAN存在的问题进行分析,指出原始GAN存在训练不稳定、生成图像多样性不足的问题,其根本原因在于损失函数设计不合理。而WGAN-GP中引入了Wasserstein距离以及梯度惩罚,很好地度量了生成分布和真实分布之间的距离。在WGAN-GP的基础上,建立了基于WGAN-GP的分类模型。与原始GAN相比,采用合理的损失函数能够提高生成图像质量以及多样性,训练结果趋于稳定。通过对经验风险最小化理论和邻域风险最小化理论的分析,指出前者在数据量不足的情况下存在的过拟合问题,以及在邻域风险最小化理论的基础上提出的mixup数据增强方法具有与数据无关的优越性。针对半监督特征提取网络设计了基于mixup数据增广的生成对抗网络,该方法有效增广了数据,且稳定了训练过程,提高了分类结果。"
1109,基于IASE的铸件打磨粉尘治理装置设计,"TRIZ理论和可拓学是目前存在的创新理论中成体系、可操作性强、应用广泛的创新理论。为解决创新工具选择困难、效率低的问题,提出基于难度系数的创新工具选择策略,在此基础上建立了IASE创新方法,并将其应用于铸件打磨粉尘治理装置的方案设计中。IASE创新方法是Identification、Analysis、Solve和Evaluation四个英文单词的缩写。本文的主要内容包括两大部分,第一部分为IASE创新方法的建立,以及IASE在铸件打磨粉尘治理装置设计上的应用;第二部分为铸件打磨粉尘治理装置的分析,包括正逆运动学、流道、感知系统和控制系统分析,并在上述分析基础上进行仿真研究,以最终验证设计方案的合理性。IASE创新方法建立的基础为TRIZ理论和可拓学中创新工具的结合使用,这得益于TRIZ理论与可拓学具有较深厚的研究和应用基础。IASE创新方法的主要思想在于将问题求解流程划分为问题识别、问题分析、问题求解以及方案评价四个阶段。在此前提下,将TRIZ与可拓学的各个创新工具按照问题识别、分析、求解、评价的各个阶段进行重组,构建了IASE工具库。IASE创新方法的关键在于建立创新工具的选择策略。本文首先建立了工具难度描述模型,并根据问卷调查结果,计算和确定了IASE工具库中所有工具的难度系数,最终构建了基于难度系数的创新工具选择策略。在创新理论研究的最后阶段,将IASE的求解流程建模为树状结构,提出一种路径搜索算法,该算法能够有效地减少创新工具失败尝试次数,进而提高问题求解效率。为验证IASE创新方法的可行性,将其应用于铸件打磨粉尘治理装置的方案设计上:首先根据路径搜索算法的指导使用初始路径进行求解,使用每阶段难度系数最小的工具。然后根据求解结果的反馈和难度系数决定下次求解时使用的创新工具,最终获得若干方案,优选其中一种作为最终方案,并根据该方案进行粉尘治理装置的结构设计。在上述研究基础上,对设计的粉尘治理装置进行分析。首先对粉尘治理装置的吸尘管臂进行正、逆运动学分析和工作空间分析,并使用Matlab Robotics Toolbox进行验证。其次,分析了粉尘治理装置的感知系统,研究和讨论了基于图像处理、经典机器学习、深度学习三种打磨工具识别方法,并进行比较和总结。接着,分析了粉尘治理装置的控制系统,决定了采用吸尘管臂各关节独立控制的策略,并且各关节使用串级PID控制器。然后,建立了仿真环境的三维模型和粉尘治理装置的URDF模型。基于上述粉尘治理装置的分析结果,应用C++和Python编程语言编写相关ROS节点。在Gazebo环境下进行粉尘治理装置自动化除尘的仿真,并最终成功开发了粉尘装置的软件系统,初步验证IASE创新方法对机电系统的创新设计具有实用意义。"
1110,基于退化模型复原与卷积神经网络的光学元器件损伤在线检测技术研究,"伴随着科技的不断发展,基于计算机技术的视觉处理方法开始在视觉领域大放异彩。在大型光学装置领域,传统的离线检测技术需要对光学装置中的元器件拆卸后进行分析,所以离线检测技术不仅效率无法保证而且还会影响装置的使用成本以及使用寿命。因此光学元器件损伤在线检测技术的研究成为了一个急需解决的问题。在光学元器件在线检测的研究中,近些年国内外的相关研究也提出了多种方法,但这些方法都是基于传统的图像处理方法的研究。近年来随着机器学习与人工智能等技术的发展,采用卷积神经网络进行图像处理成为了计算机图像处理领域的热门方法。在此背景下,本文提出了基于退化模型复原与卷积神经网络的光学元器件损伤在线检测方法,将卷积神经网络技术与传统的图像处理技术中的复原技术进行结合,对损伤图像进行在线检测。首先,本文通过退化模型复原技术对图像进行建模,随后根据损伤图像中已有的先验知识,对损伤图像设计复原算法,并将该算法应用到损伤图像的退化模型复原中去,观察实验的结果并和国内外所采用的基于传统图像处理的方法进行对比分析。随后,由于大型光学装置的特殊性,获取光学损伤图像成本极高。为了便于后续分类器的训练,本文中设计了一种数据集制作方案,将数据先划分成小的区域,进而对区域中的损伤点进行准确检测。随后将图像区域进行伪样本扩充,进而使其可以作为训练样本对分类器进行训练。最后,本文设计了一个基于卷积神经网络进行分类检测的分类器,然后用制作好的数据集对其进行训练、检测,并将该分类器与其他的机器学习或深度学习方法进行对比,观察分类的结果并对结果进行分析。随后将经过复原处理后的图像和未复原的图像数据集分别用此网络进行训练、检测,进而证实了复原算法对于损伤图像识别检测是有效果的。"
1111,民航旅客个体出行价值预测应用研究,"近年来,中国民用航空旅客人数呈现出逐年增长的态势,形成了庞大的旅客消费群体。面对激烈的市场竞争,及时发现旅客的价值变化逐渐成为了众多民航公司关注的焦点。如果依据旅客的历史消费行为数据能够判定其未来的市场表现和价值,将有助于航空公司为旅客提供精准的营销和贴心的服务,提升旅客满意度和忠诚度。首先,正确的衡量一个旅客民航领域的市场价值是本文整个研究工作的基础。本文通过对多种用户价值度量方式的研究,提出一种可以应用于民航领域的旅客价值评估参数化模型(Recency,Frequency,Unit-revenue,Mile,RFUM)。该模型从不同维度出发,对旅客在民航市场中的价值做了评估。然后借助参数化过程,分别对几种属性赋予不同的权重值,将旅客的价值转化为了介于0到1之间的数值标量。RFUM模型在全面衡量旅客价值的基础上,为民航市场决策者提供了一定程度的便利,能够直观地观察出旅客价值的差异性。其次,民航领域的客户价值预测问题是本文研究工作的重点内容。本文提出了一种时间感知的多任务价值预测模型(Time-aware Multi-task Value Prediction,TMVP)来预测旅客的价值。首先,旅客的消费行为和消费价值具有时序性的特点,TMVP模型尝试通过时间感知的方式来捕获此类特性。其次,旅客的价值是通过旅客的消费行为间接体现的,TMVP模型也尝试通过深度学习的方式来自动捕获旅客消费行为和价值之前的间接映射关系。最后,旅客的价值和旅客的消费意愿之间存在着潜在的联系,TMVP模型通过建立多任务学习的方式来描绘两者之间的连接关系,进一步地提升模型对旅客价值预测的精准性。最后,本文在某航空公司的真实数据集上进行了相关实验。实验表明:在旅客价值衡量方面,本文提出的旅客参数化价值模型RFUM能够较为合理地衡量旅客的市场价值。在旅客价值预测方面,与传统的用户价值预测模型相比,本文提出的价值预测模型也能够更加精准的预测旅客未来的价值。"
1112,面向飞行器自主着舰问题的行动者-评论家算法模型研究与实现,"舰载机是航空母舰的重要战斗力量,舰载机在航母上的安全起降始终都是航母/舰载机系统顺利完成战斗任务的重点与难点。我国目前已经实现了舰载机的人工起降,但是人工起降技术高度依赖良好的气象条件,并且着舰指挥官的培养难度较大等因素制约了着舰技术的发展。对于自动着舰技术,我国尚处于理论研究阶段。舰载机着舰是一个顺序的决策控制问题,而强化学习在最优控制与顺序决策问题上有着成功应用的先例与天然优势。本文为探索强化学习在航母舰载机领域的应用,将深度强化学习的方法应用于自动着舰控制,研究了面向着舰问题的行动者-评论家算法。论文主要工作如下:(1)设计了面向着舰问题的行动者-评论家算法,针对舰载机着舰任务的特定业务背景,在没有控制模型和动力学模型的情况下,采用行动者-评论家算法和确定性策略梯度思想,对舰载机自动着舰过程的状态空间、动作空间以及奖励函数进行了研究,给出了符合问题背景的马尔科夫决策过程模型。(2)针对着舰过程中奖励稀疏的问题,本文提出了一个奖励重塑模型,有效解决了着舰过程中的奖励稀疏问题。首次利用仿真飞行软件X-Plane作为强化学习实验环境,以F/A-18型舰载机为例实现了平稳飞行并成功着舰,形成了一套完整的演示平台解决方案。(3)提出了行动者-适应者-评论家算法,提高了算法在非稳态环境下的泛化性。本文在行动者-评论家算法框架的基础上进行了针对性的改进,加入的适应者能够对行动者输出的动作给予修正,以适应环境的变化。为了测试算法对非稳态环境的适应性,本文对强化学习集成环境中智能体的物理模型进行了不同程度的修改,以模拟环境的变化,在Gym与MoJoCo环境下的测试结果验证了本文提出算法的有效性,同时对环境的变化也有较好的适应性。此外,本文还将改进的算法应用于仿真环境中舰载机的自动着舰任务,也显示出了一定的适应性。本文实现了以专业飞行软件X-plane为仿真环境的强化学习自动着舰算法,并且提出了一个能有效适应环境变化的强化学习算法,算法在集成强化学习环境和专业飞行软件中进行了非稳态环境的测试,显示出了良好的环境适应性。"
1113,基于协同学和迁移学习的无人机避障系统的设计与实现,"由于无人机被广泛的应用到各个领域,如航拍,巡检,侦察等,使无人机相关领域成为近些年来热门的研究方向,并促使无人机技术得到蓬勃发展。在无人机技术的发展中,自动避障技术是一个研究重点,其主要通过各类传感器单独或协同工作完成对无人机飞行路径中出现的障碍物进行检测,并采用合适的避障策略保证无人机的安全飞行。深度学习是当今科学领域中热门方向之一,多种关于深度学习的理论层见迭出,本文研究的课题是基于协同学与迁移学习实现无人机避障。构建的深度协同神经网络在性能上相比传统的协同神经网络有明显提升,并拓展使其具有目标检测的功能,最终将其应用在无人机避障系统中。首先,介绍协同学的相关概念和基本思想,以及基于协同学思想建立的协同神经网络,并阐述协同神经网络的数学模型和运行过程。接着介绍了迁移学习的基本概念和实现方法,阐述了使用的模型迁移的方式实现迁移学习,该方式是利用深度卷积神经网络对样本进行特征提取时,底层存储通用特征,高层存储分类特征的特性。采用基于Inception预训练模型的目标检测算法SSD实现目标检测,并对预训练模型的全连接层进行重新定义,从而使预训练模型在目标领域和任务中能够完成检测识别功能。其次,根据协同神经网络和目标检测算法SSD对无人机避障算法进行设计。在深度协同神经网络的基础上,结合目标检测算法SSD的边框回归思想,设计一种可以用于检测识别目标的避障算法,先对目标进行检测,确定其位置后使用深度协同神经网络完成目标识别。并提出使用生成对抗网络产生原型模式,参与网络的演化。在协同神经网络的基础上,结合深度学习的思想,通过增加网络层数使其达到更好的识别效果。并使用迁移学习提高模型的泛化能力,充分利用先验知识解决当前问题。最后,完成对无人机避障系统的整体设计和实现。根据障碍物在视野中的相对位置,制定相应的避障策略,使无人机能够安全避开障碍物实现飞行。此外,设计一款简易的上位机实现对无人机和机载运动相机的操控。最后对无人机进行实际飞行测试,验证本系统的可行性和实用性。"
1114,机器人加工轨迹高精度控制研究,"大型复杂曲面零件在航空航天上的应用非常广泛,其制造精度和加工质量直接影响着航天设备的性能和安全。目前大型复杂曲面零件大多采用多轴数控专机进行加工,主要存在设备昂贵、配置复杂等问题。随着机器人加工技术的不断成熟,机器人加工柔性、配置灵活等优势越来越明显,采用机器人实现大型复杂曲面零件的高效精密加工成为了新的研究热点。但是,机器人存在刚度低、绝对精度差、非线性耦合强等问题,导致机器人的加工精度难以保证。因此,本文针对大型复杂曲面零件机器人加工精度差的问题,开展了机器人加工轨迹高精度控制算法的研究。为了提高大型复杂曲面零件加工绝对跟踪精度,本文采用轮廓误差描述机器人绝对跟踪精度,重点针对机器人关节空间运动控制、任务空间轨迹跟踪、任务空间轮廓控制以及任务空间轮廓误差补偿展开了研究。首先针对机器人关节提出分数阶滑模控制策略,其次基于任务轨迹设计线性模型预测控制器,然后引入轮廓误差设计轮廓控制器,最后研究基于数据驱动的轮廓误差补偿策略,并逐一在实验平台上进行验证。本文主要研究内容及创新性成果如下:1、机器人关节空间运动控制。建立六关节串联机器人的运动学和微分运动学模型,同时辨识机器人的动力学模型参数;为实现各关节高精度的跟踪性能,基于动力学模型依靠分数阶微积分理论和滑模变结构控制理论设计分数阶滑模控制器。在巨轮六关节机器人上对控制器进行验证,结果表明所提方法相较于滑模控制器可有效提升关节跟踪精度至±0.003rad的范围。2、机器人任务空间轨迹跟踪。分析关节空间运动控制的局限:未考虑关节之间的耦合。针对这个问题进行任务空间轨迹控制的研究,基于模型预测控制的原理设计线性化模型预测控制算法。在MATLAB中仿真巨轮六关节串联机器人对控制器进行验证,结果表明所提方法相较于PID控制器,可提升X方向74.82%、Y方向72.58%、Z方向27.78%的跟踪精度。3、机器人任务空间轮廓控制。分析轮廓误差估计分量通过加权求和的方式引入至传统轮廓控制框架进行轮廓控制的过程中存在的两个问题:轮廓误差在加工的整个区域没有规范减小,局部出现不减反增的情况;轮廓误差的减小有限,最高为37.5%。针对这两个问题提出误差向量范数加权求和算法和新的轮廓控制框架。对所提出的控制策略进行对比实验验证,结果表明所提策略相较于传统策略,可在加工的整个区域一致地减小85.4%的位置轮廓误差和88.89%的方向轮廓误差。4、机器人任务空间轮廓误差补偿。分析轮廓控制过程中存在的问题:轮廓误差在线估计或控制器设计复杂。针对这个问题提出基于深度神经网络建立机器人输入输出完整映射的模型,并基于模型修调匹配更优的参考输入。对所提出的补偿策略进行实验验证,结果表明所提策略可有效减小43.84%的位置轮廓误差和52.14%的方向轮廓误差。"
1115,基于机器学习的高速铁路无线信道多径分量聚簇研究,"随着我国高速铁路的飞速发展与高铁技术体系的日趋成熟,宽带无线移动通信已经成为高铁服务中不可或缺的一部分。对于高铁无线通信系统而言,无线信道的传播特性是其设计部署的重要依据,只有在充分了解系统无线信道特性的基础上,才能采取相应的各种物理层技术,从而充分挖掘该系统的容量,进一步优化系统的性能。而在无线信道中,由于聚簇能够较为直观地描述无线信道多径分量的分布特性,所以近些年来,基于多径簇的无线信道建模已经越来越被人们熟知与认可。本文将在这一基础上,融合机器学习理论与无线电波传播理论,对高铁无线信道中的多径分量使用相关聚簇算法进行有效分簇,并对列车运行过程中连续时刻的功率时延谱进行聚簇后的生灭状态追踪,以此可以精确完成高速铁路时变信道的建模,同时深入研究分析时变无线信道的数据特征。本文首先介绍了常用的无线信道聚簇算法与最优分类数评价指标,同时依据不同算法的特性进行了算法的优劣比较与评价。其次通过对高铁LTE铁路专网实测数据进行提取,建立了高铁无线信道数据库。在分析现有基本聚簇算法的基础上,联系现有实测数据的特点,改进、应用了多种聚簇算法,并对这些聚簇算法进行了结合,完成了对高铁无线信道多径分量的聚簇与簇延迟线模型的构建。在此期间,还通过将不同的聚簇评价指标用于同一功率时延谱,完成了聚簇评价指标间的优劣性能比对,同时结合实测数据选择了合适的评价指标,并以此评价指标完成了聚簇所需簇数K值的选取。此外,本文还构建了一种自动聚簇的方法,该方法以前述聚簇算法的结合应用为基底,可以实现从输入功率时延谱数据到完成聚簇的自动化流程,以此可用于单天线测量场景下大批量高铁无线信道多径分量数据的聚簇以及多径信道建模,从而可以更好地帮助我们准确认知高速铁路无线信道。此外,本文还在前述研究工作的基础上,将高铁LTE铁路专网实测数据进行了部分截取,在对各追踪算法进行适应性分析并与单天线测量场景下的无线信道数据进行结合后,选取了特定的追踪算法,同时按照实测数据的特征对前述自动聚簇算法做了适应性改进。最终,通过对以上算法的结合运用,完成了高铁列车运行过程中多径簇的生灭状态追踪。通过对所选时间范围内多径分量的变化情况与文中所得生灭结果进行对比可以得出,算法的使用与创新均取得了合理可信的结果,这对于精准研究分析高速铁路时变无线信道具有重要意义。"
1116,基于集成学习的列车能耗预测方法研究及系统设计,"中国铁路在经济和社会快速发展中扮演着越来越重要的角色,尤其是铁路货运已成为影响经济的一个重要因素。但目前我国货运列车运行能耗高、运输效率低、运行秩序复杂的困境业已成为日益增加货运发送需求所面临的挑战。突破这一挑战的首要任务就是实现列车能耗的精准统计和预测,从而为强化列车运输能耗管理、提高运输效率、优化运输组织提供方法和技术支撑。针对这一挑战,本文在系统分析货运列车运行状态数据基础上,从统计理论、决策理论和机器学习的角度出发,开展基于集成学习的列车能耗预测方法研究。所取得主要研究成果如下:(1)提出了基于证据推理理论的集成支持向量机。首先,基于训练数据构建若干个支持向量机作为基分类器。其次,基于基分类器在训练集上的AUC值量化其权重。然后,利用证据推理理论将各基分类器输出结果进行融合,融合结果作为分类依据。最后,将本文提出的集成支持向量机与传统集成算法进行对比,结果验证了所提出集成支持向量机的可行性和有效性。(2)提出了网格化的货运列车能耗预测方法。首先,考虑到所获取列车运行数据在时间上的稠密性,每个单位时间间隔内的平均能耗可视为一个样本,从而构建相应货运列车运行能耗的数据集。然后,基于集成支持向量机实现基于上述样本的学习模型。最后,针对某一区段的能耗问题,可将该区段实现均匀网格剖分,剖分后的每一段的平均能耗通过学习模型求解,所有网格的能耗计算平均等级作为区段的能耗分类等级。实验结果表明,该能耗预测算法在数据样本充足情况下,可精准地实现能耗预测,为优化列车驾驶提供技术支撑。(3)基于列车运行数据和上述研究结果,设计了列车能耗分析系统。首先,基于列车运行数据,基于数据清洗、数据转化和数据拼接匹配技术,构建了相应的数据库。然后依托数据库和上述网格化能耗预测模型,开发了列车能耗分析系统。该系统实现了能耗数据的精准统计、对比和预测功能,为货运列车实际应用提供了支撑条件。"
1117,基于改进型卷积神经网络的动车组滚动轴承故障诊断方法研究,"滚动轴承作为高速动车组走行部的关键旋转部件之一,其运行状态直接影响动车组的运行品质与行车安全,因此,深入开展动车组滚动轴承故障诊断技术研究具有重要的意义。目前,广泛应用于轨道车辆滚动轴承故障领域的基于信号处理的振动分析诊断法和基于机器学习浅层模型的智能诊断法在通用性和智能化方面还存在一定的不足,研究更加通用、智能的诊断方法对动车组走行部关键部件的智能运维有积极的推动作用。针对传统智能诊断方法依赖信号处理技术与专家诊断经验来提取故障特征,深度学习模型仅被当作分类器使用,诊断模型识别准确率不高、泛化性不强以及诊断模型的建模分析未考虑实际故障诊断中的“正常状态”样本与“故障状态”样本的数据不平衡等问题,本文主要开展了以下四个方面的研究工作:(1)首先,使用CWRU轴承标准数据集进行建模分析,验证卷积神经网络从原始一维振动信号逐层卷积池化来抽取故障特征,并实现不同类型、不同程度故障准确分类的算法可行性;然后,通过引入Dropout、BN、SVM等算法来提升诊断模型的收敛速度、识别准确率与泛化能力;最后考虑噪声干扰下的识别准确率以及统计学指标P、R、F1客观地评估了 CNN-BN-SVM模型的分类性能。(2)研制了高速动车组走行部轴承故障检测系统,根据动车组常见故障类型使用电火花加工实验故障轴承,设计了基于高速滚振试验台的动车组轴箱轴承故障数据采集实验方案并利用该检测系统进行了轴承振动数据采集,为后续针对动车组滚动轴承故障诊断模型的建立提供试验数据支持。(3)首先,基于动车组滚动轴承故障数据集建立CNN-BN-SVM诊断模型,重点分析了正常状态样本与故障状态样本的数据不平衡问题对分类模型性能的影响;然后,通过引入数据重采样和代价敏感学习的策略提升CNN模型对不平衡样本的分类能力;最后通过与几种经典的传统智能诊断方法的对比说明了CNN-CSSVM模型在抗噪性和处理不平衡数据方面的优越性能。(4)将本文研究的CNN-CSSVM诊断算法作为高速动车组走行部轴承故障检测软件智能识别模块的支持算法,基于C#以及TensorflowSharp、Libsvm等开源框架设计了诊断模型的部署方案。图61幅,表24个,参考文献75篇。"
1118,基于机器学习的高铁开行方案编制方法研究,"开行方案是高铁开行的基本依据,是根据需求匹配运力的基本载体,其编制方法及优化一直是研究的热点。在开行方案编制及优化过程中,既有研究主要利用经典数学优化方法及现代演化方法进行建模及求解,但此类问题目标多且约束复杂,使算法复杂性与计算量均很大。当前,机器学习研究在各领域已取得广泛应用,适于解决数据挖掘等问题,加之高铁数据的不断积累,为利用机器学习解决开行方案编制问题提供了新的途径。为此,本文提出了一套基于机器学习的高铁开行方案编制方法,主要研究工作包含以下四个方面:(1)构建了高铁开行方案编制的求解框架。结合编制开行方案时的实际及理论业务流程,对本文所要解决的问题进一步准确描述;根据问题描述,提出研究所需的假设条件,建立了宽约束条件下以机器学习模型作为目标函数的高铁开行方案模型,并提出了高铁开行方案求解框架。(2)建立了基于机器学习的高铁开行方案评估模型。通过分析高铁相关指标选取客座率作为评估开行方案的关键指标;对高铁开行方案的相关数据经特征提取、数据标准化、特征选择三个步骤构建出可适用于机器学习的输入数据特征;其次,根据高铁开行方案特征维度高,各车次具有时空相关性的特点,选取LSTM深度学习模型作为评估模型,并设计了基于LSTM的高铁开行方案评估模型;最后,研究了使用高铁开行方案及客座率数据训练LSTM模型的算法,并对模型的性能评价进一步优化。(3)提出了一种基于机器学习的高铁开行方案编制方法。因高铁开行方案初始可行集对搜索过程影响较大,设计了面向高铁开行方案的初始化方法,降低了算法的搜索空间,并提高了算法的起点。通过聚类的方法,计算出“保留”列车的集合,使之在迭代计算中保持不变,并设计了针对可变列车部分的交叉与变异遗传算子。接着给出基于机器学习评估模型及遗传算法的高铁开行方案编制算法流程,并对算法可行性及收敛性等进一步分析。(4)针对京沪高铁开行方案的编制进行了案例验证实验。首先描述了京沪高铁的现有的背景,其次说明了实验数据及环境的准备工作,对实验所用的方法进行具体说明:通过实验,验证了本文所提出的基于机器学习的高铁开行方案编制方法的可行性,并对结果进行了分析讨论。"
1119,关于公路货运详情页的推荐模型研究与应用,"近年来,物流领域高速发展,其相关产品已经渗入到人们生活的方方面面。在互联网时代的智能生活下,物联网生活也在逐步到来。因此,对物联网产业链的研究逐渐展开。其中,公路物流领域的发展显得尤为突出,2018年公路物流的货物运输量占整个物流体系75%以上[1]。借助于公路货运调度平台信息,司机输入搜索信息后出现的货物详情页面。其传统的推荐逻辑展示的推荐列表,准确度低、司机在选择货物信息时的决策成本较高、决策时间较长、货车空驶情况较严重。随着近年来人工智能和云计算技术的迅猛发展,越来越多的电子商务企业在其商品展示详情页中的推荐模型研究均给公司带来了较大获益。而目前公路货运调度平台还尚未在此方面做出显著研究成果。因此,构建高效、高稳定性的货物详情页推荐模型对物流领域的发展显得至关重要。本文研究是在传统推荐算法研究基础上,将整个推荐模型分为召回模型和打分模型两大部分。其中,召回模型是从百万实时货物信息中召回k条与目标货物最相关的货物信息,打分模型是求得召回的k条货物信息会被点击的概率值。本文以货运调度平台的真实数据信息构建模型,真实线上效果评估模型的合理性和有效性。对于召回模型,分别通过协同过滤算法和改进后的协同过滤算法得到召回结果,打分模型通过逻辑回归和Xg-boost(Extreme Gradient Boosting)求得货物被点击的概率值。基于AUC(Area Under Curve)线下评估模型的拟合能力,基于A/B测试线上评估模型效果的真实性和可推广性。在召回模型阶段,改进后的协同过滤算法得到的货物推荐具有更高的AUC值。在打分模型阶段,通过卡方检验和递归特征消除将数据特征分别从19个筛选至11个再筛选至6个。改进的协同过滤算法+Xg-boost模型得到的AUC值为0.75,高于其他模型表现。但Xg-boost的线上运行效率不高、可解释性不强,真实线上运行模型采用改进的协同过滤算法+逻辑回归。线下AUC值为0.65，线上点击率每天稳定提升9%,模型结果实现了研究目标,为货运调度平台带来重要经济价值。"
1120,基于重点营运车辆数据的高速公路交通状态识别与行程速度预测,"“两客一危”车辆由于载客量较多或者运输危化品,一旦发生交通事故,将会带来更严重的损失。由于此类的营运车辆车辆体积大,速度较低,是交通拥堵发生的重要因素之一。北斗车载终端的安装实现了重点营运车辆的实时监控,也为道路交通状态识别和交通流预测提供了数据。基于此,本文以营运车辆数据为基础,对高速公路交通状态识别和行程速度预测展开研究,旨在提高重点营运车辆的监管水平,为减少交通事故发生、有效缓解交通拥堵提供技术支撑,主要内容有:(1)针对重点营运车辆异常数据和缺失数据问题,制定了异常数据处理规则,并提出了趋势―历史缺失数据填充算法。通过对营运车辆数据大量的统计分析,总结出了七大类异常数据表现形式,并根据异常数据的特点提出了相应的处理规则;针对时间序列数据的缺失问题,提出了趋势―历史填充算法。以试验路段营运车辆数据为例,验证了数据处理方法有效可行性。(2)基于道路的行程速度和单位行程时间延迟特征,构建了一种基于FCM的高速公路交通状态识别算法模型。该算法模型以欧氏距离为度量标准,通过迭代求解得到畅通、基本畅通、一般拥堵、中度拥堵、严重拥堵五类交通状态的聚类中心点,并通过隶属度矩阵实现交通状态的识别。实例验证表明所提算法能有效识别出道路的交通状态。(3)构建了一种基于SA-SVR的高速公路行程速度预测算法模型。利用模拟退火优化算法的全局搜索特性,对SVR的核函数因子和惩罚因子进行优化,进而实现行程速度的预测。以三个实验路段为例,证明了优化后的算法能有效增加预测结果的稳定性和预测精度。(4)构建了一种基于LSTM的高速公路行程速度预测算法模型。该算法模型以道路的行程速度为输入,利用算法的长时间记忆能力对未来的行程速度进行预测,并提出三种自适应调整学习率的梯度下降算法对模型进行优化。实验路段验证表明,adam梯度下降优化策略最好。最后以adam梯度下降的LSTM和SA-SVR在未发生交通事故和发生交通事故两种情景下进行验证对比分析,结果表明,两种情景下LSTM预测结果优于SA-SVR。"
1121,基于阿里云大数据平台的交通运输综合行政执法案件的智能分析和研究,"交通运输综合执法案件数据的全面、准确是从事综合行政执法工作的基础,在交通运输行政执法行业,建立交通运输行政执法模型可以有效、深入分析行政违法案件的特点,并且为行政执法人员和决策者提供参考建议。因此,随着大数据技术在各行业领域的深入融合发展,建立交通运输综合行政执法案件大数据模型具有现实意义。阿里云大数据平台在众多行业领域中应用广泛,其机器学习PAI平台拥有先进的数据分析能力和机器学习能力,可以通过统计学算法,对大量的历史数据进行学习从而生成经验模型,利用经验模型指导业务。阿里云机器学习平台是建立在阿里云MaxCompute计算平台之上,集数据预处理、建模、预测为一体的机器学习平台,非常适合用于预测交通运输综合行政执法案件类型的模型建立和分析,让人工智能服务于政府部门的行政管理。本文的重点是采集了2012年至2018年期间,广东省开平市交通运输综合行政执法案件,通过几种机器学习方法对该地区交通违法案件的违法类型进行预测,具体算法是通过提取了违法案件数据中的违法时间、违法地点、违法主体等6个特征用于预测违法案件行政分类,建立了逻辑回归(logistic regression)、朴素贝叶斯分类(Naive Bayesian Model)、GBDT+逻辑回归模型,采用混淆矩阵和ROC曲线对模型进行比较。通过实验发现,GBDT+LR的模型对预测交通运输违法案件类型有较好的实验效果,其次是逻辑回归模型,最后是朴素贝叶斯分类模型。在GBDT+LR分类模型构建中,采用特征编码的方式,可以利用机器学习方法挖掘新特征,同时有效的将GBDT非线性特征转换为线性特征。研究结果表明,GBDT+LR的实验模型对交通运输行政违法案件的违法类型具有很好的分类效果,较单纯的统计方法而言,大数据预测挖掘技术可以更加精准地找出输入特征和输出结果的内在联系,可以根据不同的行政类别对违法案件进行分类,进而去引导行政行为更加合理和高效,具有辅助执法人员办案的作用。同时该实验模型可以推广至广东省、全国交通运输执法系统,通过全国交通运输违法案件大数据,进一步优化模型效果。"
1122,基于机器学习方法的打车需求量预测研究,"随着国家经济的迅猛发展,城市化进程的不断推进,城市道路交通给居民的日常生活带来了许多便利,但与此同时,人口的持续增长、车辆的日益增多,以及随之而来的居民日常交通出行需求大幅度增长,使得交通拥堵现象越来越频繁。智能交通系统是解决城市道路交通问题较为有效的途径,交通预测则是智能交通系统研究的重要内容。在城市公共交通运输系统中,出租车和网约车是其中的重要组成部分,但由于乘客的出行需求具有较大的波动性与随机性,出租车通过巡游的方式来寻找乘客具有较大的盲目性,同时网约车使用者的不断增加导致出现在某些时段、某些区域网约车供不应求,在另外的一些区域却运力过剩的现象。通过供需预测进行运力调度是解决乘客出行需求与车辆服务之间供需矛盾最为有效的途径。供需预测属于短时交通流预测领域,通过预测在某一时段、某一区域的乘客打车需求,指向性地把过剩的运力向周围特定区域进行调度,从而有效解决供需矛盾。本文通过查阅大量相关文献,从打车需求量预测和短时交通流预测两个方面进行国内外相关文献的综述,对打车需求量的预测展开研究。首先,建立基于极端梯度提升的打车需求量预测模型,从理论推导上分析了极端梯度提升算法相比较于传统的梯度提升算法的优势,通过对样本数据进行预处理,对打车需求量进行分析,构造模型特征,并通过实验对比验证了基于极端梯度提升的预测模型在预测打车需求量方面的有效性以及较其它预测模型更具优越性。其次,建立单变量线性回归模型提取打车需求量的月趋势,建立样条曲线模型提取打车需求量的日趋势,对基于极端梯度提升的打车需求量预测模型的特征进行优化,新增月趋势特征和日趋势特征,并通过实验验证了新增特征对提升模型预测精度的有效性。最后,基于本文所做的研究进行打车需求量预测系统的设计与实现,系统的功能由实时需求量、历史需求量和系统管理三大模块组成,而系统的实现则验证了本文所做研究的有效性与实用性。"
1123,基于机器学习混凝土路面裂缝检测算法研究,"近年来,随着计算机计算性能的提高,机器学习开始被大量地应用各个领域的研究当中,其中传统的机器学习算法在手势识别、手写数字识别能够达到很好的效果,但是在传统的土木行业中,由于混凝土路面裂缝出现特征随机性大,图像特征提取困难,降维困难,在高维度样本的条件下用传统机器学习方法进行裂缝识别,准确率较低,与传统机器学习方法相比,在高维度样本量大的条件下,深度学习在准确率上更加具有优势,其中卷积神经网络CNN是具有代表性的深度学习算法,在图像检测领域受到广泛的应用。因此,本文从特征提取与机器学习的原理出发,对比了多种特征提取算法,对裂缝图片做预处理,介绍了传统的机器学习算法与深度学习算法,并对使用了传统的机器学习方法SVM与深度学习算法CNN对预处理后混凝土裂缝图片进行训练检测识别,最后开发了混凝土路面裂缝检测用户图形界面程序。本文主要的工作内容:(1)裂缝样本的获取与预处理:设计了裂缝拍摄过程,将所得裂缝图片拷贝成4组,分别通过Laplacian算子、Sobel算子、Canny算子分别对图片进行特征提取处理,剩下一组只做灰度化处理来作为原生对比组,结合网上数据集得到4组训练样本集与测试样本集。(2)基于传统机器学习的SVM算法对裂缝检测识别:分别使用线性核函数与RBF核函数的SVM算法对4组训练样本进行训练,使用对应的4组测试样本进行裂缝检测。(3)基于深度学习的CNN算法对裂缝检测识别:使用基于卷积神经网络inception V3模型通过迁移学习的方法对4组训练样本与测试样本进行裂缝检测。并且与传统的机器学习方法做对比分析。(4)开发基于CNN裂缝检测平台:将机器学习、用户图形界面、图像处理三者结合,开发了具有良好扩展性的裂缝检测平台,最后结合本程序提出对路面健康状况进行评估的流程。"
1124,基于嵌入式的智能车载终端研究与实现,"随着人类经济水平不断提升,人们对于品质的需求也越来越高。卫星导航、人工智能、5G、物联网等深入人们的生活,人们对于位置服务不仅仅满足于导航定位的功能,对于其衍生服务的需求也越来越大,如基于位置的推荐服务,基于位置的网约车等服务。传统车载导航仪启动时间长、地图更新困难、交互界面落后,手机导航的兴起,导致了传统车载导航仪的逐步淘汰。因此研发一种新型车载导航仪尤为迫切。本文针对车载导航仪缺陷,设计一种启动时间短、地图更新方便、交互界面友好的车载导航仪,全面提升驾驶员的驾驶体验。针对卫星定位固有缺陷,卫星信号极易受到外部影响,造成定位信息丢失无法进行导航,基于上述原因,本研究设计一种基于卫星/基站的组合式定位系统,充分利用两种定位方式的特点解决卫星信号丢失场景下的持续导航以及卫星定位冷启动问题。对于传统车载导航仪缺陷如地图更新问题,交互界面问题。本研究采用结合时下热门的小程序开发,将传统的交互界面转移到小程序中。针对时下网约车问题,设计一种用户常用位置聚类模型,有效解决网约车分布不合理造成的资源浪费问题。实验结果表明新型车载导航仪有效解决丢星、冷启动、地图更新问题,优化驾驶员使用体验。本文主要工作如下:(1)研究卫星定位原理,分析国内外车载导航仪市场,提出一种新型交互模式的车载导航仪。(2)分析卫星定位固有缺陷,针对卫星定位信号易丢失,冷启动等问题设计一种基于联邦卡尔曼滤波算法的卫星/基站组合式导航定位系统。(3)分析市场车载导航仪硬件设备,针对功耗问题,选用低功耗设备搭建车载导航仪,并进行Linux系统搭建。针对传统导航仪交互、地图更新不及时等问题,设计基于微信小程序的人机交互界面和联网地图系统。(4)编写各模块驱动程序,实现定位信息采集发送以及陀螺仪信息采集使用。将定位信息结合K-means算法进行用户常用位置聚类,采用Calinski-Harabasz算法提升聚类算法的准确度。"
1125,基于视觉的驾驶员情绪识别研究,"近年来驾驶员状态监测系统在道路交通安全中正扮演越来越重要的角色,当前驾驶员状态监测系统多专注于监测驾驶员是否疲劳、分心等状态,对驾驶行为有重要影响的驾驶员情绪状态的关注不是很多。当前城乡道路交通情况复杂多变,驾驶员行车过程中应保持积极稳定的情绪状态,集中注意力于随时可能发生变化的路况及车况,而驾驶员个人心理素质的差异使得通过驾驶员依靠自身维持良好的驾驶情绪仍有很大难度,因此有必要在行车过程中实时监测驾驶员情绪状态,一旦发现异常驾驶情绪及时发出警告提醒,预防危险驾驶行为。因此本文选择非接触式的视觉技术监测驾驶员情绪状态,具体工作概括如下:(1)讨论了驾驶员情绪识别基本方法的研究现状,以及基于视觉的情绪识别研究现状,通过分析表情与情绪的关系,确定了本文通过微表情识别情绪的思路与研究方向。(2)研究了基于视觉的驾驶员情绪识别的相关技术,并将情绪类别与微表情类别相关联,同时把基于视觉的驾驶员情绪识别分为图像预处理,特征提取和情绪分类三个步骤,最后论述了评估算法性能的实验方法与性能度量作为后续研究实验的基础。(3)引入端到端的深度学习方法识别微表情,并通过迁移学习方法迁移人脸识别领域的预训练模型进行微调,以解决训练深度学习模型的数据稀缺问题。同时分析了微表情数据集中的类别不均衡问题,引入聚焦损失函数作为目标函数来降低数据不均衡的影响,通过对比实验验证了算法模型的有效性。(4)提出基于循环神经网路提取微表情时域特征结合迁移模型提取空间特征的方法识别视频图像序列微表情,利用时间插值模型进行序列归一化处理,将得到的图像帧序列作为循环神经网络模型的输入,并设计VGGFace-LSTM模型提取微表情空间-时域特征,实现了视频情绪的分类,通过对比准确率与_1F值验证了本文提出模型的有效性与优越性。"
1126,纯电动汽车和燃油汽车的社会生命周期评价,"生命周期可持续评价理论框架中,对产品的评价有三个维度:环境、经济和社会。当前对产品的生命周期评价研究大多集中在环境和经济维度,随着可持续发展的理念日益深入人心,更多的企业和学者更加关注产品对社会产生的影响。已有的社会生命周期评价体系涉及工人、消费者、当地社区、社会和价值链参与者五个利益相关者,既可单独对某款产品进行定量或定性评估,也可以对比评价若干款功能相似的不同产品,分析出产品存在的优势和不足,指导企业发挥优势并弥补不足,促进产品的改进以更好地实现可持续发展。本文参考了已有的社会生命周期评价框架和近些年国内外学者的研究成果,结合我国汽车产业发展的实际情况,建立了一个较为完善的社会生命周期评价指标体系。不仅考虑了原有的五个利益相关者,还加入了政府作为第六个利益相关者,共涉及20个子类和25个评价指标。此外还探索互联网汽车文本口碑大数据在汽车社会生命周期评价中的应用,利用自然语言处理技术将非结构化的互联网文本大数据转化为可直接用于社会生命周期评价的结构化数据,突破传统的问卷调查和企业调研等数据获取方式。并对两家不同厂商生产的纯电动汽车和燃油汽车进行实例研究,对比分析了两款汽车社会影响的优劣,分析出纯电动汽车相对普通燃油汽车的优缺点,据此提出一些有建设性的建议,为纯电动汽车的可持续发展提供参考。"
1127,基于社区问答文本的汽车知识问答系统研究,"在复杂产品制造企业例如汽车企业中,知识服务是企业的核心竞争力之一。而自动问答系统(Question and Answering)是非常适合企业的一种知识服务技术。问答系统能够直接解析自然语言问句,并返回简练的答案,提高了用户信息获取效率。针对问答系统的整体复杂性和汽车行业的特殊性,研究了面向汽车制造企业的问答系统架构设计,并针对问答系统流程中关键技术给出对应改进算法。首先,本文对汽车行业用户服务进行需求分析,设计了基于社区问答文本的汽车问答系统框架,使得问答系统更加切合汽车领域用户的需求,并有助于汽车企业对用户关注的热点问题进行主动获取;其次,针对基于汽车社区问答文本所面临的用户问题纷繁复杂、口语化严重的情况,提出了基于深度学习的汽车问题文本分类改进算法,研究了深度学习模型和注意力机制在文本分类任务中的应用;最后,研究了汽车问答文本联合建模答案选择算法,为问答系统的答案抽取及答案排序提供理论支持。为说明两个改进算法对问答系统性能的提升有效性,分别采用对比试验进行验证分析,实验证明算法达到了预期的研究效果。"
1128,机器学习在智能家居监控系统中的应用,"长久以来,家庭安全防护都是备受民众关注的热点问题,视频监控则是保障家庭安全的一种重要手段,需求持续增长。传统的家庭监测系统大多都由中央监测站的工作人员来完成,分析和响应每一个异常事件。显然这种传统的模式要耗费大量的人力成本,而随着机器学习算法的发展,智能化的监控系统成为了新的发展趋势。本文主要对基于视频监控的图像预处理、家庭入侵检测和摔倒检测这几个方面进行了深入研究。本文研究了各种常用的图像预处理方法,最终在实验中采用了基于拉普拉斯滤波和离散余弦变换的方法。通过拉普拉斯滤波突出图像纹理特征,然后利用离散余弦变换提取图像低频系数之后复原图像,最后达到了突出纹理、削弱噪声、降低图像维度的效果。对于家庭入侵检测,在经过图像预处理的基础上提出了一种HOG-LBP特征加权融合的人脸识别算法。首先通过正对房门的摄像头采集入室人员的图像,并对图像进行预处理。然后利用HOG特征与LBP特征存在的优势互补特性,采用HOG算子与LBP算子分别提取人脸特征并进行加权融合得到人脸图像的最终特征,最后使用SVM分类器进行识别。在多个人脸数据集下的实验结果表明在室内场景下,该算法相比绝大多数传统算法具有更优秀的识别性能和鲁棒性。对于摔倒事件的检测,论文提出了一种基于单应性变换的前景投影重合率算法。人在正常行走和摔倒时,在两路视频中的形成的运动前景之间的关系是不同的,本文通过单应性变换将这种特征描述了出来。将一路视频中人的运动前景经过地面单应性矩阵投影到另一路视频中,会与另一路视频的运动前景产生重合。在实验中发现,重合率的大小表征了人与地面的接近程度,而重合率变化的速率则代表了动作的运动强度。本文基于这两个特征来初步判断摔倒事件,为了进一步的排除下蹲等干扰,使用椭圆拟合法提取人体外接椭圆分析姿态信息,最终综合判断出事件是否为一次摔倒。经过多个摔倒数据集的测试,表明了该方法可以有效地检测出摔倒,并具有良好的实时性。"
1129,建筑物爆破拆除塌落振动效应初探,"伴随着我国城镇化程度大幅度提升,大量老旧建筑达到设计使用年限;同时,当年的城市规划设计逐渐在目前的生活中暴露出不足,大规模工程拆除的需求日益急迫。爆破拆除因其高效、经济、安全性愈发得到业界的认可而成为首选拆除方法。但爆破拆除同样伴随着诸多有害的附加效应,如爆破振动,塌落振动等。本论文通过分析爆破拆除工程实测数据,进行了以下研究并得到了相关结论:(1)介绍了工程爆破拆除过程产生的振动效应的危害。以某群楼爆破拆除工程为例,分析其数据特征,与《爆破安全规程》与《结构抗震设计规范》对比,证明了合理的设计下群楼爆破拆除的安全性与高效性;(2)类比近断层地震研究思路量化塌落振动的方向性效应特征。通过分析倒塌过程中塌落体与地面的碰撞过程,建立了合理的物理、力学、数学模型,将之与地震动常用的断层开裂模型进行对比分析,论证了二者的相似性;参考国内学者对近断层地震动方向性效应研究思路,得到了塌落振动的方向性效应规律及其量化特征;(3)通过深度学习利用地面振动数据对场地类别进行判断。在PEER数据库中随机选取合理容量的样本,参照场地分类的相关研究成果,训练机器学习分类模型利用台站地震动记录对所在场地类别进行判别,并验证了该方法的可行性;(4)对工程爆破实测数据进行研究,得到NERPH分类标准下C类场地的塌落振动的能量分布特征;通过HHT变换对爆破拆除工程实测数据进行分解、重构,利用Hilbert能量边际谱,得到塌落振动的能量密度频谱;为方便工程应用,对频域进行合理划分,并给出塌落振动各频段的能量占比;(5)针对现行《爆破安全规程》中针对塌落振动的安全判据以及其他相关安全判据进行分析,根据其不足并参照塌落振动的能量分布特征,提出了新的安全判据(TEDI)并对其合理性、完备性与可行性进行了论证;利用工程爆破实测数据给出了针对C类场地的塌落振动的PGV、频谱、持时与TEDI值之间的对应关系。"
1130,基于频率和光纤光栅识别纤维增强复合材料梁的分层损伤,"纤维增强复合材料(Fiber Reinforced Polymer,FRP)因其轻质高强、耐高温、耐腐蚀、抗疲劳、抗振动、吸波透波、绝缘隔音、外观设计灵活和可塑性强等综合特性,现已被广泛应用于航空航天、海陆交通、民用基础设施、体育器材和建筑医疗等工程领域。常见的FRP材料以层合结构为主,层与层之间是树脂基体,力学性能较薄弱,极易导致FRP材料在加工、储存、运输、服役及维修过程中因遭受中低速冲击而产生分层损伤,大大降低了FRP层合结构的承载能力,最终在低于设计载荷水平下失效,带来严重的安全事故和重大的生命财产损失。因此,对FRP层合结构进行早期损伤诊断和识别显得尤为重要。本文以FRP复合材料层合梁为研究对象,分别以损伤发生前后的振动参数(模态频率)变化值和光纤光栅波长漂移值为损伤指标,通过构建多种机器学习算法,包括人工神经网络、支持向量机、极限学习机和遗传算法等,实现对FRP层合梁的分层损伤位置、大小和分层界面等参数的一一识别。对文中提出的用于分层损伤识别的机器学习算法进行了数值模拟案例和试验实测案例的双重验证:(1)数值模型案例验证中,首先建立了层合梁的理论模型、有限元模型以及基于BP(back propagation)神经网络和支持向量机的代理模型等三种数值模型,基于这些数值模型生成了“分层损伤参数-频率变化值”数据库和一系列数值验证案例用于验证构建的机器学习算法,并对比了分别采用三种数值模型进行分层识别的精度和所需运算时间。(2)试验测量案例验证中,首先制作了无损和含分层损伤的FRP层合梁试件,在一端固定的边界条件下分别对其进行模态频率测试和光纤光栅波长测试,实测的多阶频率变化值和光纤光栅波长漂移值被用于对构建的机器学习算法进行试验验证。此外,基于频率变化指标的损伤识别方法中还对各机器学习算法的可变参数进行了分析讨论,如数据库大小、隐含层节点数、是否归一化、输入和输出形式及网络参数优化方法等,最终确定适用于算法的最佳参数。基于频率变化的数值验证结果表明,BP神经网络的预测效果最佳,案例数为165时的界面正确率高达98.15%,损伤位置和大小的绝对预测误差分别为0.14%和0.17%。试验验证结果表明,支持向量机的识别效果最佳,其次是极限学习机、基于代理模型的遗传算法和BP神经网络,四种机器学习算法对损伤位置和大小的绝对预测误差均控制在3.3%以内,而对于分层界面的识别,以支持向量机的分类识别效果最佳,正确率为100%。基于波长漂移的试验验证表明,将各光纤光栅的波长漂移、加载坐标和加载值作为算法输入时,BP神经网络和支持向量机均能正确输出加载点和损伤之间的方位关系。综上,本文得出的结论是,基于频率变化和波长漂移的四种机器学习算法均能够较为准确地识别FRP梁的分层损伤,其中以支持向量机识别效果最佳。本文将频率预测与光纤光栅的局部预测相融合,减少了利用光纤光栅识别的工作量,同时对直接基于频率指标的损伤位置和大小做进一步验证和细化。"
1131,基于长短期记忆网络的制冷剂剩余量的预测研究,"随着生产力的迅速发展,能源消耗量也在不断增加,其中建筑物的能耗大约占全球能耗的20~40%,而采暖,通风和空调能耗约占建筑物能耗的40%。多联机空调系统作为一种能够最大限度降低运营和维护成本的高效冷却系统,加上其较高的灵活性、舒适性、可靠性等优点,现已被广泛运用于建筑中。但是设备的老化与各种故障,会对其性能产生较大的影响。鉴于多联机的系统复杂,设备繁多,无法全部进行研究。制冷剂泄漏作为多联机系统中较为常见的问题,以往的研究多集中在制冷剂充注量的诊断上,对制冷剂含量的预测研究较少。因此,本文针对多联机系统中的制冷剂剩余量,借助数据驱动的方法对制冷剂剩余量进行预测。由于在系统运行中,制冷剂的含量较难测量,因此本文采用前人所建立的经验关系式,根据实际运行数据计算出当前时刻的制冷剂含量。为了获得稳态数据,采用高斯稳态判别算法提取稳态数据,结果表明该方法能够较好的剔除原始数据中的非稳态数据。通过使用皮尔逊相关系数与最大互信息系数选取相关性较高的5个特征,作为长短期记忆网络(long short-term memory,LSTM)模型以及反向传播神经网络(back propagation neural network,BPNN)模型的输入特征,建立多联机系统制冷剂剩余量预测模型。结果表明,通过稳态判别算法对原始数据清洗后,制冷剂泄漏所引起的趋势波动被较好的保留,提升了数据的质量,有利于提升模型预测精度。在模型优化前,LSTM模型较BP模型的平均绝对误差与均方误差更小,预测曲线与实际趋势更加吻合,但是LSTM模型在计算花销上较大。在使用动态学习率和添加Dropout层之后,两模型的性能均有提升,LSTM模型的平均绝对误差从0.93提升到0.38,BP模型的平均绝对误差从2.89提升到1.12,表明了使用动态学习率与Dropout层的有效性。为了能够更加贴近于应用,使用LSTM模型进行了多步预测,预测当前时刻后10个时间步长的数据。同时为了检测LSTM模型的泛化能力,使用不同工况下的数据对模型进行了验证,最后对比了单变量与多变量时序预测的效果差异。本文提出的多联机制冷剂剩余量预测模型,将深度学习算法LSTM引入到制冷空调领域并取得了较好的预测效果,可以为机组维护人员制定维护计划提供参考。未来可以将其应用在其他多联机系统当中,值得深入探究。"
1132,基于机器学习的办公建筑暖通空调系统能耗预测及优化调度,"在当今不断加剧的恶劣天气影响下,建筑作为能源资源不可忽视的消费者,如何对其进行有效的能源管理,节约能源资源,优化其用能结构受到了广泛的关注。而暖通空调作为建筑中最主要的耗能设备之一,针对其进行能耗预测以及节能优化对于降低建筑整体能耗、缩减成本,都具有重要的现实意义和实际指导作用。本论文利用数据驱动的方法对我国北部某大型办公建筑的能耗进行了预测、全年能耗仿真以及优化调度。本文首先采集了该建筑2016年11月至2017年3月以来的能耗数据以及空调运行数据。在人为进行了整理、消除异常数据、坏样本点之后,利用主元分析算法对其进行降维处理,将降维之后的样本集利用一种基于集成学习算法的能耗预测模型进行预测,再对照Energy+仿真结果获得全年能耗数据。最后,综合分析其整体能耗、热负荷以及暖通空调能耗搭建了一种具有优化调度功能的能源枢纽模型。基于集成学习算法Adaboost-BP模型在提高BP神经网络算法模型的预测精度的同时,可以修正BP神经网络算法的已陷入局部极小值、收敛速度慢等缺陷。且该集成学习算法对于弱分类器的要求很低,几乎不需要对其参数进行调整,因此使用范围广,鲁棒性好。对于每月的预测精度分别由86%,89.01%,89.89%和81.16%分别提高至88.13%,90.31%,90.14%,89.16%和85.91%,尤其对于自身分类效果不佳的算法模型具有更为明显的提升效果。根据该办公建筑的物理特征及气候特点,本文将能耗预测所得到的数据结合仿真手段Energy Plus得到了有参考意义的该建筑全年能耗,包括热、电、暖通空调能耗等等数据。根据其能耗特点在Matlab环境下搭建了一个具有多个优化目标协同的能源枢纽系统,并对其进行优化。最终形成了一个具有灵活热电比热电联产设备的能源枢纽系统,该热电比是响应暖通空调耗电量与建筑整体热负荷的比例在一定区间内变化的。最终利用MATLAB求解可知,对比之前稳定热电比的能源枢纽系统,具有灵活热电比的能源枢纽在2017年该地区的气候条件下一年可以节约4.5%的经济成本,2.9%的天然气,3.3%的电量输入以及3.2%的CO2排放。此外,该能源枢纽系统有利于实现能源的梯级利用并对于可再生能源的消纳应用具有现实指导意义。总之,本论文提出的基于数据驱动的能耗预测以及优化调度对于优化办公建筑能耗结构、节约能源资源、降低温室气体排放、降低用电高峰期用户端需求量增大对电网造成的冲击都具有良好效果,也为分布式能源网络格局的设计提供了一种设计思路。"
1133,电力巡检中的小样本机器学习方法研究,"巡检无人机成本低廉,智能化程度高,可对输电线路进行快速且安全的巡检工作,具有广阔应用前景,是当前电力巡检领域的热点研究项目。然而,电力巡检中类别繁杂,难以为每个类别都收集到足够的训练样本,且为训练样本人工标注的代价过于高昂。小样本分类算法适合于解决此类给定了丰富基础类别的训练样例,却缺乏新类标记实例的情况。但针对电力巡检这一具体的业务场景,仍缺乏相应研究。因此,需要进一步研究小样本分类算法,理清其原理、明确其数据基础,以期能将其成功应用于智能电力巡检系统。本文在经典分类神经网络模型的基础上进行了两个方法改进:增加了基于注意力机制的小样本分类权重发生器;将卷积神经网络模型的分类器更改为测试样本特征向量与类向量之间的余弦相似性函数。该方法在保留了其它小样本分类方法能较好地减少类内方差这一优点的基础上,对于较高域差异的训练集也体现了较好的自适应能力。综上所述,本文首先总结了近年来小样本学习方法的进展与成果,并阐述各算法的特点、主要针对的问题,比较分析了几种典型的小样本学习方法,包括匹配网络、原型网络、关系网络以及模型无关元学习方法。其次,设计了一个一致性的实验方案,减少因各小样本算法复杂的算法结构以及差异化的训练细节而导致的性能差异,并以此定量分析了各算法实际性能。此后探讨了小样本学习方法的训练目标,证明了更深的骨干网络显著降低了各方法之间的性能差异,并通过实验发现类内方差是造成小样本学习性能差异的主要因素之一。最后,实验结果还表明随着域差异增大,增强对于少数新类实例的自适应能力将比减少类内方差更能提高算法的准确率,该结果也对电力巡检领域数据集的制备工作提供了参考。"
1134,同步型分布式电源的被动式孤岛检测方法研究,"随着传统化石燃料的迅速枯竭以及其对环境污染带来的严重影响,人类希望通过风能、太阳能等清洁能源实现对传统化石能源的替代。分布式发电技术就是利用负荷侧的各种清洁能源进行发电,其能源能利用率高,供电可靠性高,清洁环保,因而成为近年来研究的热点。分布式电源的非计划孤岛检测是保证其安全稳定运行的基础。为此,本文对同步型分布式电源的孤岛检测展开了研究,主要工作和成果如下:首先,建立了同步型分布式电源发生孤岛事件后的数学模型,得到了同步型分布式电源发生孤岛事件后,频率、频率变化率和功角特征量随时间变化的特性,并分析了影响特征量变化的因素。分析和仿真验证了过/欠频防孤岛保护的特性,给出了同步型分布式电源检测盲区的概念,并在典型的含分布式电源系统得到了分布式电源的检测盲区。其次,提出了一种基于LSTM的分布式电源被动式孤岛检测方法。由同步型分布式电源发生孤岛事件后,其频率、电压等特征量随时间变化的特点,提出一种深度学习模型,该模型能有效处理时序信号。对LSTM模型的结构进行了优化选取,得到三种典型LSTM模型结构,并分析其性能,仿真结果表明,模型参数过多会产生过拟合,过少则会发生欠拟合。将本文所提方法和已有的分布式电源孤岛检测方法在检测准确率上进行了对比,并与传统的过/欠频防孤岛保护在检测盲区上进行了对比,仿真结果表明,该方法能够有效提高分布式电源孤岛检测的正确率和减少其检测盲区。最后,提出了一种基于迁移学习的分布式电源孤岛检测方法。该方法在训练数据集过少的情况下,能将已有的分布式电源孤岛检测的LSTM模型迁移到其它的分布式电源上,从而满足实际应用的要求。对迁移过程中应该保留的LSTM层的参数和应该迁移的LSTM层的参数进行了分析验证,结果表明迁移过程中应该保留已有模型的前面两层参数。此外,还对比分析了直接采用少量训练数据集训练得到的模型和在已有模型上采用迁移学习得到的模型的性能,仿真结果表明采用迁移学习得到的分布式电源孤岛检测模型其性能要优于直接采用少量训练数据集训练所得到的模型。"
1135,电能计量装置故障诊断与状态评估建模研究,"电能计量装置是发电公司、电网公司、售电公司及电力用户之间进行准确计量、精准贸易结算、公平交易的重要工具,其运行的准确性和稳定性直接关系到贸易双方的经济利益。传统的电能计量装置监测方式为周期性现场校验,该方式存在着运行管理粗放不规范、工作效率低、故障发现及排查难度大、监测时效性差等问题。本文依托电能计量装置远程校验监测平台,对电能计量装置故障诊断与状态评估进行了建模研究。本文概述了电能计量装置的故障类型及诊断方法、状态评估指标及评估方法。设计了一套以规则推理为主、以机器学习算法为辅的故障诊断系统,可准确判断故障所属类型和定位故障发生位置。对于电能计量装置的状态评估,建立了完备的状态指标层次模型,在评估方法上应用了模糊层次分析法和灰色聚类法,全面客观地对电能计量装置的状态进行评估。在此基础上,本文设计并开发了电能计量装置故障诊断与状态评估软件系统。它可以对二次回路的失压、失流、误差超差、接线错误等常见典型故障进行定位与诊断,对电能表显示模块故障、计量模块故障、电源模块故障等的功能性故障进行智能识别;可根据电能计量装置出厂数据、实验室检定数据、周期校验数据等多项状态指标,对电压互感器、电流互感器、电能表及二次回路的健康状态、可靠性、精度等方面进行分析和评估。与传统的周期性现场校验模式相比,故障诊断与状态评估系统可对电能计量装置进行故障的实时监测,在调整校验计划、排除故障隐患等方面为运维人员提供依据,具备监测全面、时效性好、可预测性强等优点。最后,针对电能计量装置故障诊断和状态评估软件系统在故障诊断和状态评估准确性方面进行了仿真测试。仿真结果表明,系统对于各类电能计量装置的故障和运行状态均能进行合理有效的诊断和评估,具有良好的实用性能。"
1136,基于深度学习的中文电子病历实体及其修饰识别技术研究,"智慧医疗是当前人工智能领域的研究热点,而在各种医疗数据中,电子病历具有重要价值。电子病历是医务人员通过电子病历系统在医疗活动过程中产生的一种临床文本信息,是一种记录患者信息的数字化信息。通过对电子病历的分析与挖掘,可以得到大量的与患者密切相关的医疗信息,这对临床决策能起到很大的帮助。自然语言处理技术可以帮助我们实现对电子病历文本信息的挖掘,如命名实体识别、实体修饰识别等技术。其中实体识别旨在识别出病历中不同实体的实体边界与类别,实体修饰旨在识别出特定实体与患者之间的修饰关系。但是与其他文本相比,中文电子病历存在大量包括书写不规范、专业术语较多、特殊字符频繁、句子结构不完整等问题。同时,由于涉及到患者的隐私,导致目前开源的电子病历数据不多。这些问题加大了对电子病历的信息进行挖掘和识别的难度。因此为了更好地对电子病历信息进行抽取,本文利用深度学习方法在自主标注的数据集上对中文电子病历的医疗实体与修饰识别及其联合识别技术进行了研究:(1)基于知识注意力机制增强的实体识别。虽然以往的相关工作都取得了较好的成果,但是却忽略了能够提供丰富实体信息的外部医疗知识,因此本文提出了基于医疗知识注意力增强的CNN-BLSTM-CRF方法。通过使用注意力机制,对医疗词典中的医疗实体的定义与边界信息进行编码,来增强神经网络模型的性能。其中,在BLSTM对文本信息编码前,先用CNN预先提取了文本的字级别表示并作为文本信息的补充信息,有效地解决了上文中提出的电子病历存在的书写不规范和特殊词频繁等问题。(2)基于CNN-GRU神经网络的实体修饰识别。使用了 GRU网络对电子病历文本信息进行了编码,并使用Softmax进行解码。其中,GRU网络是循环神经网络(RNN)一个变体,与之相比GRU更好地解决了远距离依赖的问题且计算方式更简单。同时使用了 CNN网络预先提取了字符级表示以解决书写不规范和特殊字符频繁等问题。(3)实体及其修饰联合识别。在联合识别任务中本文提出了一种基于多标签方案的联合识别方法,并使用BLSTM-LSTM模型进行识别。与传统的串联式识别方法相比,基于多标签方案的方法,可以成功的将两个步骤转换为一个步骤:通过多标签方案,使用端到端模型一步识别。实验结果表明,在相同的数据集上,本文的方法相较于其他方法取得了较好的性能。"
1137,基于sentence2vec的疾病提前诊断和风险预测,"在这个信息化的时代,随着医疗技术以及科学技术的迅猛发展,智慧医疗、互联网医疗等新概念随之被提出,利用数据驱动来对医疗数据进行分析方法也应运而生。因此,建立完整的电子健康记录(Electronic Healthcare Records,EHR)系统显得越来越重要。人们通过对获取到的医疗数据进行合理的分析,可以对其进行预测建模,从而实现对于疾病的提前诊断。或者通过对病人的EHR数据来对其身体健康状况进行分析,从而预测该患者在将来患有某种疾病的风险。电子健康记录(EHR)系统和其他的健康数字化系统一样,可以使医疗保健变得更为高效、安全、智能。电子健康记录与自然语言处理相结合,可以减少人类去做常规、耗时、高重复型的工作,腾出来的人员可以被重新部署,以便于支持更为高端的工作,大大推动了医疗保健事业的发展。但是也有很多原因使得我们在EHR数据集上进行疾病风险预测仍然面临很多的挑战。比如说EHR数据集中相关字段的缺失,可能导致我们提取到特征不完整。另外,由于人工失误,错记、漏记、甚至多记可能给我们分析数据造成噪声,影响我们对特征的提取。因此,能够高效分析电子医疗健康记录对于提升医疗卫生水平至关重要。在本文中,我们创新性的使用sentence2vec和CNN相结合的方法,首先使用sentenc2vec对于患者的电子健康记录指标进行向量化,然后将对应生成的向量放入训练好的CNN分类网络中,然后将所得到的结果进行类比,以此来得到对于疾病的提前诊断以及风险预测的结果。与传统的EHR数据集处理方法相比,本文提出的方法不仅可以忽略患者电子健康记录长度差别过大即EHR数据集高维稀疏性对实验结果造成的影响,更加完整地保存患者的相关信息。同时,它也考虑到了患者不同身体指标之间的联系,从而可以更加有效的提取表征信息。实验结果表明,对于充血性心力衰竭和糖尿病,本文中所提出的方法可以提前180天预测更准确的结果,并且在提前90天的时候,准确度达到了99%以上。提前得知某种疾病的患病风险,可以争取更多的时间让医生为患者制定更准确的治疗方案,这在医疗保健史上是一件非常有意义的事情。"
1138,MSM人群PrEP服药依从性的预测模型研究,"目的:对MSM人群PrEP服药依从性建立良好的预测模型,预测其依从性,并针对依从性较差的人群进行精准干预,提高他们的依从性,进而减少HIV感染风险。同时也为“十三五”国家科技重大专项“基于智能提醒系统提高MSM人群暴露前预防用药依从性以降低HIV新发感染的研究”提供参考,改善提高依从性的策略。方法:2013年4月至2015年3月在广西、四川、重庆、新疆四个省份,通过在同志网站发布信息、与非政府组织合作、利用核心人员滚雪球等非概率抽样方式,招募男男性行为者进行问卷调查和HIV检测。先对MSM人群PrEP用药依从性的影响因素进行单因素分析和多因素的Logistic回归分析;然后把数据随机分为756例的训练集和100例的测试集,以多因素Logistic回归分析有意义的变量作为输入和以依从性作为输出,通过训练集构建几种预测模型,通过测试集预测依从性;最后通过预测一致率和ROC曲线下面积(AUC)对几种预测模型的预测效果进行比较。结果:(1)在纳入分析的856例研究对象中,以30岁及以下,城镇户口,大专、本科及以上文化程度,未婚居多;艾滋病知识得分小于8分者占78.15%,焦虑症状者和为抑郁症状者分别占48.60%和20.56%。(2)多因素logistics回归分析显示,MSM人群PrEP用药依从性影响因素为:研究中心、试验分组、与男性性伴肛交时使用安全套情况、通过互联网寻找性伴情况。研究中心为重庆医科大学、广西医科大学、四川大学华西医学院相比新疆医科大学的被调查者依从性高,其OR值分别为OR=1.552(95%CI:1.086~2.219)、OR=32.32.878(95%CI:9.825~110.028)、OR=3.367(95%CI:2.147~5.280);每日服药组相对于性行为前后服药组依从性低(OR=0.585(95%CI:0.426~0.804));与男性性伴肛交时均使用安全套相对于均未使用的被调查者依从性高(OR=1.782(95%CI:1.001~3.173));经常通过互联网寻找性伴的相对于完全没有的依从性高(OR=1.910(95%CI:1.020~3.573))。(3)几种预测模型的预测一致率和ROC曲线下面积(AUC)如下:logistic回归预测模型的预测一致率为64.00%,AUC为0.608,灵敏度为47.37%,特异度为74.19%;遗传算法优化后的BP神经网络模型的预测一致率为69.00%,AUC为0.699,灵敏度为73.68%,特异度为66.13%;LVQ神经网络模型的预测一致率为73.00%,AUC为0.736,灵敏度为76.32%,特异度为70.97%;SVM模型的预测一致率为69.00%,AUC为0.704,灵敏度为76.32%,特异度为64.52%;决策树模型的预测一致率为69.00%,AUC为0.684,灵敏度为73.68%,特异度为62.90%。logistic回归预测模型的预测结果AUC与0.5比较差异没有统计学意义(P>0.05),其余几种预测模型的预测结果ROC曲线下面积与0.5比较差异均有统计学意义(P<0.05)。结论:MSM人群PrEP服药依从性是受多种因素综合作用影响的,研究中心、试验分组、与男性性伴肛交时使用安全套频率、通过互联网寻找性伴频率方面密切相关。MSM人群PrEP服药依从性的预测模型中,logistic回归预测模型预测效果欠佳,而遗传算法优化的BP神经网络模型、LVQ神经网络模型、SVM模型、以及决策树模型预测效果良好,后几种模型可以应用于以后针对依从性的预测研究中。"
1139,护理领域命名实体抽取方案研究,"随着我国老龄化的愈发严重,老人的日常护理需求越来越多,尤其是患病后的护理。但不同情况下的老人所需的护理方法不同,某些细致的护理方法并非所有人都了解。虽然常见疾病一般都有相关的护理指南等文献资料,但当老人患有多种疾病时,就需要查阅大量的护理指南,十分费时。且有时要根据老人的实际情况,来制定专门的方案,这些特定的方案往往写在老人的病历或体检报告中,不易统计。如果能够自动地从这些自然语言文本中抽取命名实体,就能够快速、准确获得老人所需的护理措施。因此,本文研究了从自然语言文本中获取护理领域命名实体的方法,来实现老人所需护理措施的自动获取。本文主要工作如下:1)提出了一种基于条件随机场的命名实体抽取方法。为收集到的护理领域文献添加实体标签后,加入外部特征,使用条件随机场模型进行命名实体抽取。为了消除模型训练时冗余特征模板过多造成的负面影响,使用遗传算法对特征模板进行了优化,提高了命名实体抽取的准确率。最终,实体抽取的准确率达到80%。2)提出了一种基于Bi-LSTM与条件随机场相结合的命名实体抽取方法。将护理领域文献转化为字向量,再通过神经网络对句子特征进行计算,最后使用条件随机场进行实体标注。为了提高实体抽取的准确率,使用遗传算法对神经网络训练时所需的各类参数进行优化,使模型更适合文献的结构。最终,实体抽取的精确率达到85.2%,较直接进行抽取提高了3%。"
1140,基于MRI影像组学分析对乳腺癌新辅助化疗病理缓解早期术前预测,"目的探讨MRI影像组学技术对于乳腺癌新辅助化疗病理缓解的术前疗效预测的准确性。方法回顾性收集经病理证实为局部进展期乳腺癌患者的术前基线增强MRI(CE-MRI)共55例(年龄23-70岁)。所有患者接受乳腺癌新辅助化疗,根据术后病理评估,17例获得病理完全缓解,38例未获得病理完全缓解。使用“3DQI”影像组学分析平台,在基线CE-MRI上进行病灶分割,计算出88个CE-MRI病灶容积纹理特征(形状,直方图、灰度共生矩阵、灰度游程矩阵、灰度区域大小矩阵等共6类),77个病灶边界容积纹理特征,以及616个小波分解的容积纹理特征,共计781个纹理特征。采用随机森林的机器学习方法,对所有纹理特征首先进行特征筛选,选出重要特征建立预测模型,然后采用10倍交叉验证方法,结合ROC曲线验证预测模型的准确性。我们对所有55例乳腺癌患者,34例肿块型乳腺癌患者和21例非肿块型乳腺癌患者分别进行了影像组学预测模型的训练和验证。结果对所有乳腺癌患者,预测模型选出5个(LHH_RL_srlgle,HHH_RL_sre,HHH_RL_srlgle,LLH_GLCM_infoCorr1,HLL_RL_gln)纹理特征,其ROC的AUC值为0.737(敏感性79.6%、特异性54.5%)。针对肿块型与非肿块强化型乳腺癌,预测模型分别筛选出3个(HHL_RL_lgre,LLL_RL_srhgle,LLH_RL_hgre)和4个(HHH_GLCM_infoCorr1,LLL_RL_sre,SHAPE_compact2,HLL_RL_gln)纹理特征,模型ROC的AUC值分别为0.861(敏感性90.1%、特异性65.8%)和0.926(敏感性89.2%、特异性68.0%)。结论基于乳腺癌强化类型分组的影像组学分析可以显著提高乳腺癌新辅助化疗的术前疗效预测的准确性。"
1141,阿尔茨海默病与遗忘型轻度认知障碍患者磁共振脑功能及影像组学研究,"目的:(1)旨在识别海马影像组学生物标志物,为遗忘型轻度认知障碍(Amnestic mild cognitive impairment,a MCI)的诊断建立分类模型。(2)探讨阿尔茨海默病(Alzheimer’s disease,AD)患者海马功能连接(Functional connectivity,FC)与MRI影像组学特征的相关性。对象与方法:(1)招募了42例a MCI受试者和44例正常对照组(normal control,NC)。首先,采用一种高效的学习方法,对每个受试者的左右海马分别进行分割。然后,应用A.K(Artificial Intelligence Kit)软件计算和选择影像组学特征。最后,根据左右海马体所选取的特征,建立相应的logistic回归模型。(2)研究共纳入AD患者67例和NC组44例。采用静息态功能磁共振成像(Resting-state functional magnetic resonance imaging,rs-f MRI)对双侧海马为种子点的全脑FC进行研究,分别从双侧海马提取FC值。应用A.K软件计算和选择双侧海马的影像组学特征。将双侧海马影像组学特征与海马FC值进行Pearson相关分析。结果:(1)aMCI影像组学计算得到的特征共有385个,每组数据特征选择后保留了4个特征。右侧海马模型的曲线下平均面积(area under the receiver operating characteristic curve,AUC)、特异性、敏感性和准确性分别为0.76、0.71、0.69和0.69,左侧海马模型的预测指标分别为0.79、0.71、0.54和0.64。(2)笔者观察到在左侧海马功能网络中,AD患者部分脑区的FC被破坏,这些区域包括右侧直回、右侧前扣带回和旁扣带回、额中回右眶部、右尾状核、左楔前叶和右楔前叶、左中扣带回和旁扣带回、左右角回和左右枕中回等。还观察到右侧海马功能网络中FC减少的部分脑区,包括左侧和右侧前扣带回和旁扣带回、右侧中扣带回和旁扣带回、右背外侧额上回和右侧中央前回等。Pearson相关分析显示,左侧海马中有两个游程长矩阵(run-length matrix,RLM)和一个灰度共生矩阵(gray level co-occurrence matrix,GLCM)影像组学特征与FC值有弱相关性。然而,右侧海马的影像组学特征与FC值之间没有显著相关性。结论:结果表明,海马影像组学生物标志物对a MCI的诊断具有潜在的价值,随着进一步的改进和验证,基于MRI的影像组学模型可用于鉴别a MCI患者和指导个体化治疗。另外,研究揭示了AD患者MRI影像组学特征与rs-f MRI的相关性,几个左侧海马影像组学特征与功能连接存在弱相关性。"
1142,影像组学在鼻咽癌靶区勾画部分问题中的初步应用研究,"影像组学是一种新兴的计算机辅助图像处理和分析诊断工具,主要用于临床预后预测、肿瘤微环境研究、与病理检验结合的分析等用途。由于影像检查和放射治疗技术的发展,个体化的放射治疗方案成为可能,催生了大量先进的图像处理和分析技术及此类研究,影像组学因其深度挖掘图像中包含的数据信息的能力得到较为广泛的研究。本文论述了影像组学应用于解决鼻咽癌个体化放疗中现存问题的工作,针对肿瘤与邻近组织区分、肿瘤内部乏氧等不同异质性表现区域的分割、小体积转移淋巴结鉴别等问题,在完善鼻咽癌个体化放疗中具有一定的参考价值。本文重点介绍了影像组学的研究方法和技术特点,并进行了应用。文中共选取了108例鼻咽癌患者,分别搜集患者CT、MRI、PET、病理学检查结果等数据,在量化分析肿瘤与肌肉组织、区分肿瘤内部乏氧和非乏氧区域等前期研究中使用统计学方法获取有实际使用价值的特征,在鉴别颈部转移淋巴结时使用机器学习方法对数据进行建模和鉴别。(1)在量化分析肿瘤与肌肉组织的研究中,在CT图像中获得部分影像组学特征随图像增强状态变化,可反映肿瘤异质性的动态变化用以量化肿瘤与正常组织的差异,用于排除靶区勾画时增强剂对各期CT图像的影响;(2)在区分肿瘤内部乏氧和非乏氧状态区域的研究中,MRI T1、T1+、T2图像中存在4个影像组学特征变化超过90%,量化和追踪这些特征的变化有利于对鼻咽癌肿瘤乏氧区域的识别;(3)在鉴别颈部转移淋巴结的研究中,由CT影像宏观指标和影像组学特征构成的机器学习预测模型可准确预测鼻咽癌转移淋巴结,对转移淋巴结鉴别精度达到91.7%,为临床中鉴别小体积鼻咽癌转移淋巴结提供一定的参考。上述研究结果在鼻咽癌放疗中肿瘤分割、乏氧区域识别和转移淋巴结鉴别中有一定的参考价值,有利于进行更为精细的肿瘤靶区、淋巴结引流区分割和施行不同处方剂量或同步加量放射治疗等个体化治疗方案。"
1143,磁共振3D纹理分析应用于胶质母细胞瘤和原发性中枢淋巴瘤的术前鉴别诊断,"目的:纹理分析可以客观的反应图像的结构特征。本研究拟探究磁共振3D纹理分析对胶质母细胞瘤和原发性中枢神经系统淋巴瘤的术前鉴别诊断价值。提取纹理参数时,我们同时提取肿瘤影像的形态参数,用以探究肿瘤形态对两者的鉴别价值。方法:本研究中我们回顾了协和医院神经外科在2012/1-2017/9的经过病理学证实为GBM和PCNSL的患者,最终筛选纳入了82名患者,其中,60名胶质母细胞瘤患者,22名中枢淋巴瘤患者(表1)。我们依据肿瘤影像,对肿瘤图像进行分割,将分割出的3D肿瘤图像进行标准化处理后提取出图像的纹理及形态参数。由于纹理及形态参数数量庞大,我们依据机器学习模型,选取了较具特征性的纹理及形态参数。统计学方法上,我们运用曼-惠特尼U检验,受试者工作特征曲线(ROC曲线)分析以及相应的灵敏度,特异度,正确率和曲线下面积(AUC)来做诊断试验评价。由于两组数据间标本量存在较大不平衡性(60对比22),我们运用十折交叉验证(ten-fold cross-validation)的方法来保证运算的精度。结果:最终从T1增强象上选取的三组参数,Firstorder_Skewness,Firstorder_Kurtosis,and Ngtdm_Busyness,根据曼-惠特尼U检验,三者均为P"
1144,基于图像处理的糖尿病视网膜病变辅助诊断研究,"糖尿病视网膜病变(DR)是糖尿病一种极为常见的并发症,目前已经成为我国导致失明的重要疾病之一,而及时的诊断和治疗可以有效的避免其对视力的危害。但是由于医疗资源的相对紧缺,DR的筛查预防工作变得极为困难,从而使得大量的DR患者错过了治疗的最佳时间,最终导致视力受损甚至失明。为此利用数字图像处理及图像分类等方法,实现糖尿病视网膜病变的自动诊断,对于实现大规模眼底普查具有十分重要的意义。论文主要针对眼底图像分割和糖尿病视网膜病变的分期诊断进行了研究,基于图像处理及图像分类算法,提出了一种基于图像处理的糖尿病视网膜病变分期辅助诊断算法。具体内容和创新结果如下:(1)为去除血管网对于病变提取的干扰,提出了一种基于数字形态学方法的血管网分割算法。首先通过底帽变换得到血管网粗分割结果,之后基于形态学重建理论完成了血管网的精分割。(2)为去除视盘对于病变提取的干扰,提出了一种基于滑动窗口的快速的视盘定位方法,能够在较短时间内完成视盘的定位工作。(3)为实现硬性渗出物的分割提取,从渗出物特征出发,提出了一种基于图像融合的硬性渗出物的分割算法。与同领域其他算法相比,本文算法具有特异性和准确率高、耗时短的特点。(4)为实现糖尿病视网膜病变的分期诊断,提出了一种基于支持向量机(SVM)的糖尿病视网膜病变分期辅助诊断算法,从糖尿病视网膜病变的病理特征出发提取特征向量,对分类器进行训练与测试,测试集结果表明该模型对于单纯型糖尿病视网膜病前中期诊断效果良好。"
1145,基于机器学习的鼻咽癌放射治疗自动计划,"本研究的目的是基于重叠体积直方图(OVH)建立两种鲁棒性好的机器学习算法模型,并实现鼻咽癌静态调强放射治疗(IMRT)自动计划。本研究选取福建省肿瘤医院行根治性放射治疗的115名鼻咽癌患者组建病例模版数据库。每例鼻咽癌病例的计算机断层扫描(CT)图像上均有7个靶区(GTV_T_P、CTV1_P、CTV2_P、GTV_NL/R_P和CTV_NL/R_P)和10个危及器官(左右侧腮腺、脑干、脊髓、左右侧晶体、左右侧视神经、垂体和视交叉)。在建立机器学习模型之前,提取病例模版数据库中每一例鼻咽癌患者影像的OVH,并获得对应病例手工高质量IMRT计划的目标函数。然后,以OVH为输入特征,目标函数为输出标签,建立基于神经网络(NN)和基于k近邻(kNN)的两种机器学习模型。选取25名鼻咽癌患者作为测试病例,把测试病例的OVH分别输入NN和kNN机器学习模型中,获得测试病例的两种目标函数。将所获目标函数与利用Perl语言编写的Pinnacle~3计划系统脚本嵌入式自动化程序相结合,自动设计仅优化一次的IMRT放疗计划,得到NN和kNN两种自动计划。由一名有经验的物理师对25例测试病例设计手工计划。最后,由另一名有经验的临床医师将NN和kNN自动计划分别与手工计划进行计划整体质量比较。同时,用配对样本t检验分析三种计划的靶区和危及器官的剂量学数据和计划设计所耗费的时间。研究结果显示,20例NN自动计划质量与对应手工计划的质量相当,19例kNN自动计划质量与对应手工计划的质量相当。NN自动计划、kNN自动计划和手工计划在GTV_T_P、GTV_NL/R_P、CTV_NL/R_P的适形性指数相似(P>0.05)。同时,相比手工计划,NN自动计划右侧晶体有更低的最大剂量(4.70±0.72 Gy vs.5.02±0.70 Gy,P=0.001)。两种自动计划的左右侧视神经最大剂量也均低于手工计划(P<0.05)。NN自动计划的平均用时为9.73±1.80分钟,kNN自动计划平均用时为10.18±2.17分钟,而手工计划的平均用时为57.12±6.35分钟。研究表明,相比手工计划,两种机器学习算法的自动计划均大大减少了设计时间,并且还能更好地保护危及器官,因此更为高效。并且,仅优化一次的两种自动计划与手工计划质量相当,说明两种自动计划均具有可行性。"
1146,集成学习算法在细胞毒性预测方面的研究与实现,"在每种药物的开发过程中都需要检测其所含化合物是否具有毒性作用,其中细胞毒性由于其对人体潜在的危害进而导致很多药物在研发后期甚至上市之后才被撤回,不仅造成了巨大的经济损失还会对患者造成无法挽回的伤害。因此对于化合物细胞毒性的检测逐渐成为药物开发过程的重要部分。随着传统方法弊端愈发显著和计算机技术的飞速发展,采用计算机模拟对细胞毒性进行预测的方法吸引了越来越多的毒理学研究者。然而,目前该领域还没有取得一个令人满意的研究进展,究其原因是细胞毒性数据集是高通量的并且具有类不平衡问题。在本文中针对典型的AID364数据集的细胞毒性终点,在以十种分子指纹和随机森林算法建立的基础模型上应用了AdaBoost集成方法以及其他六种数据平衡方法以解决类不平衡问题。综合比较五折交叉验证的评估结果之后,发现使用MACCS分子指纹的集成模型是预测性能最优,其AUC为85.2±0.35%,灵敏度为81.8±0.65%,特异度为76.0±0.12%。在外部验证中,AUC为78.8%,灵敏度为55.5%,特异度为78.5%。然后将该模型在其他不同数据量和不平衡程度的数据集上进行验证,同样也表现出了良好的预测性能。本系统以MACCS分子指纹构建的集成模型为核心算法,围绕功能性和非功能性两方面需求,将整个系统分为注册登录模块、数据准备模块、分类预测模块、结果分析模块和系统管理模块。采用Bootstrap和Sweetalert框架使得前端页面简洁美观,熟练运用R和PHP语言使得后端功能流畅强大。整个系统部署在搭载了Linux操作系统的Apache服务器上,经过全面的测试保证了系统的长期运行。"
1147,基于多维度特征与随机森林的对外汉语文本可读性评估,"随着汉语国际推广事业的蓬勃发展,将汉语作为第二语言学习的人数与日俱增,对外汉语基础研究事业随之兴起,对外汉语文本可读性评估就是其中一个重要且不可或缺的研究方向。可读性指文本易于阅读的程度或性质,为第二语言学习者提供可读性与其语言掌握水平相匹配的阅读文本十分重要:难度过高的阅读文本会使其困顿不前从而受到打击,难度较低的阅读文本则会让学习者很快失去阅读兴趣并且不能使其学习到新的语言知识从而提高阅读水平。然而人工评估对外汉语文本可读性无论是对教师还是对学习者而言都费时费力且常常带有很强的主观性。本文针对此问题展开研究,主要贡献如下:(1)综述了国内外相关研究的发展、现状及研究成果:首先总结了国外可读性研究的三个阶段,分别是可读性公式、基于认知理论的可读性研究和基于机器学习的可读性分析。接着综述了对外汉语文本可读性研究的两个阶段:前期的基于传统文本特征的可读性公式,以及现阶段的基于机器学习的文本可读性评估。(2)提出了一种“基于多维度特征与随机森林的对外汉语文本可读性评估”(以下简称:Multi-D RF-CFLE)方法:随机森林是一种以决策树为基学习器的集成学习算法,因结构简单、泛化能力强在各个领域应用广泛,在各大数据挖掘竞赛上表现优异。所以本文尝试使用随机森林算法对对外汉语文本可读性进行评估。首先参考国内外第二语言文本可读性评价指标,从基础特征、词性特征、等级特征、语法特征这四个维度提取特征共计86个,进行特征选择后在训练集上利用随机森林算法训练分类器,并在测试集上证实了该方法的有效性。(3)展开了“基于多维度特征与支持向量机的对外汉语文本可读性评估”(以下简称:Multi-D SVM-CFLE)对比实验:此组对比实验不同之处主要在于特征选择和分类器训练模块。其中Multi-D RF-CFLE实验使用了过滤式特征选择,分类器训练使用的是随机森林算法;Multi-D SVM-CFLE实验使用了过滤式特征选择与包裹式特征选择相结合的方法,分类器训练使用的是支持向量机算法。完成这组对比实验后对实验结果进行了分析:Multi-D RF-CFLE实验的各项单分类评价指标以及总体的精度和相邻准确度,都要优于Multi-D SVM-CFLE实验。"
1148,基于第二十一届成都国际汽车展览会的数据挖掘,"第二十一届成都国际汽车展览会于2018年8月31日至9月9日举行。成都车展稳居中国四大A级车展之列。基于第二十一届成都国际汽车展览会这一大盛事,利用机器学习技术和计算机技术对数据进行深层挖掘显得尤为必要,也非常有意义。本文首先通过随机森林、多层前馈神经网络、支持向量机这三种机器学习方法构建汽车品牌及车系的自动识别模型,将太平洋汽车、新浪汽车、搜狐汽车、网上车市、一猫汽车、凤凰汽车、网易汽车、腾讯汽车这八个汽车网站的汽车品牌别名和车系别名自动统一对齐到标准品牌名称和标准车系名称,并以步进的方式更新训练集得到一个标准品牌名称和标准车系名称的数据库。此数据库包含brand_name、brand_id、car_name、car_id、standard_brand、standard_car、web这七项指标的17972条信息。然后采用LDA模型,从三个维度对8月28日至9月12日期间关于成都车展的新闻报道进行话题推断,得到车型测试、产品性能、品牌战略、消费者口碑营销、新车上市、产品规划这六个话题以及每天谈论每个话题的新闻篇数。本文有以下几个创新点:第一,研究所使用的数据是最新的,尤其是进行话题推断所使用的新闻数据是每天更新的,具有时效性。第二,得到了一个标准品牌名称和标准车系名称的数据库,这为计算用户的汽车品牌偏好以及车系偏好提供支撑,也为日后对其他车展进行研究提供了方便。第三,从品牌这个维度进行话题推断的结果发现某些品牌在展前、展中、展后这三个阶段对六个话题的关注度有转移趋势,在一定程度上为这些品牌提供了商机。"
1149,基于L1正则化Logistic回归模型的P2P网络贷款风险测度应用研究,"P2P网络贷款是一种点对点的借款行为方式,它作为整个借贷环节的中介方,为借款方、投资方提供借贷服务,并以收取相应的费用作为盈利模式。该贷款方式创新性地把现代民间借贷业务的资本市场、互联网人工智能信息技术、金融服务项目和电子信息商务平台综合起来,通过互联网平台把汇聚在一起的小额资本以类似债券的形式借贷给有需求的人或者中小微型等企业。至2018年底,类似网络借贷功能的平台已经超过6000家,这些平台与传统正规的金融业务不同,他们容易获取大量资金和利润。由于个人信用问题、政策未及时落实等因素造成借款方未按期还款、平台中介“卷款跑路”等现象,使得该领域成为一个高风险行业。2018年我国存在异常的平台共4672家,占总平台数的比值高达77.4%。本文从引发网贷款信用风险的原因作为切入口,深度剖析其风险成因,结合实证分析,对我国提出政策性建议。由于国内P2P网贷的规模较小以及数据的完整性不高,因此本文针对目前全球规模最大的P2P网络贷款平台,美国Lending Club。研究中收集了2016年至2018年共三年的数据库,多达1340797个样本,其中有效样本为43041个。文章分为四个模块进行阐述。首先介绍了信用和风险的相关理论以及目前我国P2P网贷行业存在的问题和政府的整顿措施。其次分析了机器学习思想及其核心技术。针对所收集的数据样本,讨论和比较了不同机器学习模型的优劣,最终选择Logistic回归模型对P2P网络贷款风险测度进行研究。再次,为了寻找最优模型,文中还引入了L1、L2正则项对该模型进行优化。通过机器学习方法的研究,发现L1正则化Logistic回归的风险评估效能(AUC=0.838)显著优于传统Logistic回归(AUC=0.740)和L2正则化Logistic回归(AUC=0.791)。实际结果符合理论情况,说明Logistic回归模型对P2P网络贷款风险测度研究是可行和可靠的。最后总结了风险测度方向是P2P网贷行业稳步发展的必要条件等结论。与此同时,对未来P2P网络贷款业务提出政策建设建议,这对我国后期完善P2P网络贷款服务体系具有非常重要的参考价值。"
1150,在线协作学习（CSCL）平台的研究与实现,"在计算机技术快速发展的今天,学习者日益增长的学习需求已经无法仅凭传统课堂得到满足。依托计算机技术建立的学习环境,能够给予学习者丰富的学习资源和便捷的智能交互。因此,CSCL(计算机支持的协作学习,Computer Supported Collaborative Learning)等线上学习平台,受到了越来越多的学习者的青睐。作为协同学习平台,如何实现学习者之间的紧密合作,提升其团队合作能力和自主学习意识,以及如何提高平台资源利用率,为学习者创造一加一大于二的学习效果,始终是CSCL研究的热点。本文主要完成了一个CSCL平台的设计与实现,具体如下。首先,本文针对CSCL的学习环节,对平台整体需求进行了分析,完成了平台功能和数据库的设计;然后,基于学习者个人能力与笔记偏好,建立了学习者模型;接着在人岗匹配的视角下,参考人才划分机制构建了五类组内角色,基于上述学习者模型,依据改进的K-means算法实现学习者的自动分组;同时,针对学习笔记的时效性和学术性等特点,定义了学术关联度、偏好关联度和社交关联度三个主要特征,设计了融合多维特征的笔记推荐算法;最后,本文在My Eclipse环境下,采用MVC架构完成了CSCL平台的研发,实现了自动分组、任务管理、学习笔记推荐、线上测试、学习效果评价等功能,基本满足了教师和学习者在CSCL各个环节的需求。该CSCL平台经过测试,其功能基本达到了预期设定的目标。CSCL平台提供了以学习者为主体的协同学习环境,凭借人岗匹配的形式提升了小组成员的积极性,使学习者个人特质得到发挥,达成了提升学习者协同学习效果、为教师减负的目标。考虑到平台使用者会持续增加,下一步研究将利用大数据计算模型减轻平台计算耗时,并进一步解决分组算法的冷启动问题。"
1151,网络学习空间在线讨论语义分析工具的实现与应用,"随着教育信息化不断深化发展,网络学习已经成为一种被广泛认可的学习方式。网络学习空间的建设与应用也受到了国家各级教育部门和教育研究者的重视。在一系列国家政策的推动下,网络学习空间如雨后春笋不断涌现。在网络学习空间中,在线讨论、学习计划、教学反思等以文本为主要形式的非结构化数据大量积累,其中蕴涵了丰富的学习过程信息。由于文本处理的复杂性,教学领域中的文本数据研究发展一直受限于人工编码的时效及范围。如何打破限制,高效挖掘文本数据的内涵信息、结构及规律,以及拓展到更大量级的数据集研究,对于网络学习空间的发展与应用具有良好的研究价值和现实意义。针对该问题,本论文以网络学习空间中学习者产生的在线讨论数据为研究对象,研制了在线讨论的自动化语义分析工具,用于快速挖掘讨论中蕴涵的学习过程信息,提高分析效率,缓解人工分析中存在的人力和时间成本耗费大、拓展大量级数据分析难等问题。具体的研究内容包括:(1)在线讨论语义分析方法研究。从在线讨论数据的语义特征出发,结合短文本分类技术,提出在线讨论语义分析的一般模型,通过计算机的高速运算实现在线分析流程自动化。(2)在线讨论语义分析工具的设计与实现。在一般模型的基础上,结合实际功能需求分析,将工具结构划分为数据预处理、构造分类器等九个主要模块,并根据详细设计,基于Bottle框架创建了一个Python Web项目,完成在线讨论自动化语义分析基本功能的实现。(3)在线讨论语义分析工具的应用研究。选择某师范类院校公共选修课《现代教育技术》的在线讨论数据,基于工具开展数据分析研究,在验证工具的可操作性与有效性的同时,也基于实验分析结果对课堂教学和工具改进提出了意见与建议。受限于各方面条件限制,本论文仍存在许多不足之处,但通过网络学习空间在线讨论语义分析工具的实现与应用,验证了短文本分类技术在文本分析研究中应用的可行性、有效性以及便利性,期望能为后续研究提供一定的借鉴和参考。"
1152,基于传统课堂的教师话语情感识别研究,"教师情感作为教师专业发展的基础,深刻影响着教师的自我认知、课堂教学效果和学生学习效果,语音情感识别是实现和谐自然人机交互的重要途径。本文将语音情感识别应用到传统课堂,分析教师的话语情绪,及时帮助教师调整课堂状态,促进教师专业发展。本文针对离散情感语料库包含的情感种类单一,无法满足人们对复杂情感的需求,与传统课堂环境不相匹配这一问题,主要在维度情感语料库上进行特征提取、特征选择、特征融合、情感识别等工作,最终得到教师情感愉悦度变化曲线,给教师提供参考。本文的主要工作和创新点如下:首先,采用opensmile不同特征集提取CASIA离散语料库和TAL维度语料库情感特征,使用传统机器学习方法进行识别,与传统方法提取的5类特征对比,实验结果说明了 opensmile提取情感特征的有效性。其次,针对TAL维度语料库,使用opensmile不同特征集提取了全局特征和时序特征,并提出了一种基于全连接网络(FC)和一维卷积神经网络(1D-CNN)分别对两类特征进行选择的方法,实验结果表明,特征集IS10+IS13的组合全局特征效果较好,特征集IS10lld+IS13lld的组合时序特征效果较好。再次,针对全局特征和时序特征,提出了一种基于相关神经网络(CorrNet)融合特征的方法,以减少全局特征和时序特征之间的相关性,实验结果表明,采用基于CorrNet的融合特征,可以得到更好的预测效果。最后,在上述研究的基础上设计了一套适用于传统课堂环境中分析教师话语情感的具体模型,通过小样本测试,表明了该模型可有效分析课堂教师的话语情感。"
1153,基于修辞使用的小学作文自动分类评价方法研究,"目前,随着信息技术的快速发展,学生已经可以在课外利用计算机和网络进行作文的自主学习,其中作文的自动评价是支持学生进行课外作文自主学习的重要部分。目前关于作文自动评价的研究不少,也有一些较为成熟的作文自动评分平台,但它们几乎都是针对高考自动阅卷和英文作文的。针对这一问题,本文面向小学语文信息化教学中的需求,开展了针对小学作文的自动评价方法研究。考虑到小学生作文较高考作文来说种类较多,一般有写人、写景、写事、状物这几类,且小学作文的评价标准较高考作文来说较为简单明了,故根据这一特点本文研究并提出了一种基于修辞使用的小学作文自动分类评价方法。本文的主要研究工作如下:(1)根据研究方案,本文分析了相关的、当前可用的技术,阐述了它们的基本原理和特点,确立了方案的基本技术路线。(2)本文选用TextRank结合字符级卷积神经网络的方案实现了小学作文自动分类方法。首先运用基于TextRank的关键句提取算法为范文素材去除部分冗余的语义信息,然后,应用word embedding对数据集进行文本表示并将其作为卷积神经网络的输入,通过不断地迭代训练和测试,最终实现了该模型。实验表明了该方法对于作文分类任务能显著地提高分类的性能。(3)本文对小学作文中的排比句、比喻句、拟人句和引用句中的自动提取方法进行了研究。通过分析各类修辞句的特点,有针对性地提出了具体的实现方案。其中,排比句的自动提取使用基于规则的方法;比喻和拟人句的自动提取使用的是基于深度学习的方法;引用句的自动提取方法使用的是建立引用库的方法。这几种方法针对数据集测试,表现出了较好的效果。(4)本文使用详实的数据集,通过训练不同的机器学习分类器并进行对比,最终确定了基于修辞使用的小学作文自动分类评分器实现机制。同时还根据各个评分特征设计了相应的评语。最后,将之前研究的各个模块进行整合得到了基于修辞使用的小学作文自动分类评价器并进行了对比测试,验证了本方法思路的正确性。"
1154,小学人工智能教育机器人的设计与应用研究,"随着数字信息化社会的崛起,人工智能作为科学技术三大产物之一被引进2018年政府工作报告之中,吸引了社会各界尤其是教育领域的广泛关注。进入20世纪后,我国的教育重心逐渐转向科学技术,编程、创客教育受到了前所未有的关注,越来越多的专家学者在小学人工智能教学方向进行了有益尝试。《新一代人工智能发展规划》将中小学人工智能核心技术知识的普及作为推动人工智能进步的一项重要举措[1]。人工智能是连接未来的教育,人工智能教育从娃娃抓起,推助人工智能课程启蒙教育落地小学课堂是未来开展智能教育的必经之路,定会为教育行业的蓬勃提供新的发展空间。本论文主要采用问卷调查、访谈以及内容分析三种研究方法。基于开源硬件Raspberry Pi和一些开源软件,研发了一款融合人工智能思想以及人工智能技术的教育机器人小车,通过语音交互的教学实践活动,一方面为小学生营造寓教于乐的人工智能环境,加快人工智能人才的培养,另一方面探索人工智能课程普及的有效形式从而促进人工智能教育在小学的顺利开展,共同为未来人工智能知识体系的构建以及人工智能课程实践发展做出些许努力。本论文主要包括四部分:一是中小学人工智能教育和教育机器人相关文献概述。笔者考究了目前中小学人工智能教育的发展现状以及教育机器人的研究方向,总结出中小学人工智能教育的普及难点。二是人工智能知识的梳理以及小学人工智能课堂教学内容的筛选。笔者通过问卷调查以及软件分析,最终确定10个概念作为教学内容,以探究人工智能启蒙教育在小学开展的可行性。三是为小学人工智能课堂量身定制的人工智能教育机器人小车的开发。与教学内容相对应,确定了教育机器人语音识别、图像识别、语音控制、图形化编程以及拆卸组合的功能设计。四是基于人工智能教育机器人的小学人工智能教学设计与实践。将10个概念应用于小学五年级课堂,论文中以语音识别一课进行教学展示。五是促进小学人工智能课程发展的有效措施。笔者从师资培训、教学策略、教学资源三方面给出建议。"
1155,基于深度学习的学生课堂行为识别,"随着智慧校园建设的蓬勃发展,高校信息化和网络化建设已经从数字化迈向智能化。在教学过程中,学生的课堂行为对教学活动的展开与教学策略的调整具有重要的借鉴意义。在传统课堂教学中,学生行为识别主要通过人工观察实现,但该方法不仅繁琐且耗时,显然无法满足教育大数据时代的需求。因此探索如何利用机器自动识别学生行为成为一个亟待解决的问题。本论文主要采用迁移学习的方式,利用深度学习模型强大的特征学习能力,探讨解决学生课堂行为自动识别的有效途径。论文主要工作如下:(1)构建数据集。目前并无公开的学生行为图像数据库,本文采集了300名学生的七类行为共计2100幅图像构建学生课堂行为识别数据库,具体的课堂行为包括:看书、睡觉、举手、写字、听讲、站立与左顾右盼。(2)数据预处理。为了提升模型训练效果,本研究对训练集进行了预处理,主要包括学生检测和数据增强。学生检测使用Yolo_v3对图像中学生的位置进行了检测,并对图像进行裁剪。数据增强过程中本文共采用了 12种方式扩大训练集。(3)基于深度学习的学生课堂行为识别。本文使用在ImageNet上训练的ResNet 50网络作为预训练模型,通过迁移学习训练得到深度模型用于学生行为识别。同时,本文还通过大量实验探讨了主要参数对识别性能的影响。最后,本文开发了基于深度学习的学生课堂行为识别演示系统,用于演示模型训练和测试。"
1156,频谱共享网络动态资源管理算法研究,"各种新型无线业务的不断涌现导致无线通信的数据流量呈爆炸式增长,促进了第五代移动通信系统(The Fifth Generation Mobile Communication System,5G)的发展。由于频谱资源稀缺性的限制,频谱共享成为5G的关键技术之一,可以满足5G高容量、高频谱利用率等性能指标。但是由于典型的超密集5G应用场景中存在干扰、信道有效分配等无线资源管理问题,频谱共享网络的应用仍存在很大的挑战,故本文针对频谱共享网络的动态资源管理问题展开了一系列的研究。针对频谱共享网络中多个次用户(Secondary User,SU)对主用户(Primary User,PU)产生的累积干扰问题,为更好地保护主用户,本文提出一种基于神经网络的累积干扰预测算法。该算法适用于复杂的无线网络环境,可以在未知无线环境参数(如路径损耗系数等)的情况下,通过训练历史数据对用户的状态参数信息和累积干扰之间的函数关系进行建模。本文还进一步地分析了影响累积干扰预测准确性的主要因素,包括输入层输入参数的数量、输入参数的表示形式以及隐藏层节点的数量。针对频谱共享网络次用户间的频谱资源分配问题,首先,本文提出一种基于干扰重叠图的主信道分配方案。该方案在构建干扰重叠图时,考虑到了终端用户设备的实际状态,且为保证主信道分配的有效性,以对整个网络所受干扰的变化量尽可能小为目标,提出干扰重叠图中边调整的方法。其中,提出四种新参数作为调整边的依据:顶点覆盖重叠区域内用户终端设备的信干噪比及其裕量、顶点覆盖重叠区域内用户终端设备数量或密度、顶点内无线接入基站的数量以及顶点内受影响的基站所占比例。另外,针对次用户间的频谱资源分配问题,本文还提出一种基于机器学习的扩展信道分配算法,适用于基站负载动态变化的场景。基站可根据自身的频谱需求,利用多臂老虎机(Multi-Armed Bandits,MAB)算法进行频谱扩展,该算法可减少基站的测量开销以及系统间的信息交互开销。本文在算法中还引入了“冲突调节因子”,用以减少多个扩展信道请求发生冲突的概率。最后,本文利用MATLAB仿真工具对上述所提的针对频谱共享网络的解决方案进行了可行性及有效性的验证。并利用多方面的仿真结果对算法中的性能指标进行了深入的分析。"
1157,空天地一体化网络无线资源管理与传输协议优化研究,"空天地一体化网络是由卫星、空中网络和地面通信集成的新兴网络架构,可以提供全球范围内的无缝连接,能够广泛应用于对地观测、智能交通、军事任务,应急通信等实际领域。然而,有限的能量和频谱资源并不能满足日益增长的通信需求,以及其具有的高异构性、复杂多变性和长短时滞混合变性等特点,影响了业务可靠高效的端到端传输。因此,本文聚焦空天地一体化网络的无线资源管理和传输协议优化问题,提出了空天地一体化应急通信场景下能效优化的资源联合分配策略和混合网络下基于丢包区分的可靠传输协议拥塞控制改进算法。本文主要包括两方面的研究工作:(1)研究了基于空中平台的Massive MIMO系统下行链路的资源分配问题。针对空中平台能效问题和Massive MIMO系统的特点,提出了联合天线选择、用户调度和功率分配的能效优化资源分配算法。首先,根据空地通信的信道特点和功耗模型,给出了系统能效的表达式,对天线、用户和功率等资源进行联合考虑,在保证用户最低传输速率和卫星回程容量约束的前提下,达到最大化系统能效的目标。其次,在选择天线数目确定的情况下,提出了基于有效信道增益的迭代交换天线选择策略,并通过数学公式推导证明了该策略的可实施性。最后,考虑用户不等功率分配对系统能效的影响,在发射功率分配阶段,引入拉格朗日乘子通过多次迭代求解满足约束的最优功率分配。仿真结果表明了不同选择天线数目、选择用户数目和总发射功率对系统能效的影响,同时也验证了本文提出的天线选择策略提高了能效。(2)研究了空天地一体化有线/无线混合网络的丢包区分问题。针对有线环境和无线环境下的不同丢包特性,提出了使用朴素贝叶斯区分丢包类型的拥塞控制改进算法。首先,通过分析空天地一体化网络传输的特性,探讨了混合网络下造成丢包的不同原因以及不同丢包类型的行为特征,并提取了特征参数。其次,提出了基于丢包分类的拥塞控制改进算法,使用机器学习的朴素贝叶斯方法训练分类模型。最后,根据反馈的丢包分类结果,采取不同的拥塞控制行为。仿真结果表明该算法具有较好的吞吐量性能和较高的准确率,并且公平性和友好性也表现良好,同时也验证了正确区分丢包类别可以提升混合网络性能。"
1158,基于移动蜂窝网络的位置指纹室内定位,"随着无线通信技术的发展,基于位置的服务和应用日益普及,在紧急救援、社交网络等方面有着非常广泛的应用。室外环境中GPS等系统能够提供精准的定位服务,而在室内由于建筑物的遮挡和多径效应等因素影响,GPS定位服务不可达或者精度急剧恶化。因此室内定位技术成为研究的热点之一。近年来,基于位置指纹的定位方法,受环境影响小、定位精度较高,受到广泛的关注。本文主要研究基于移动蜂窝网络的位置指纹室内定位方法,通过优化算法,提高定位的精度和提高楼层分辨的准确率。本文的主要研究工作如下:1.将定位空间划分为网格,确定采样点,测量每个采样点处的信号强度信息,并对获取的数据进行解析。2.为减小噪声干扰、采集数据缺失和原始数据的压缩等对定位匹配带来的影响,完成了数据滤波、数据补全、指数变换等预处理工作,建立了指纹数据库。3.以权重近邻算法(Weighted K-Nearest Neighbor,WKNN)为基础,将欧式距离(Euclidean distance,EuD)、马氏距离(Mahalanobis distance,MaD)、切比雪夫距离(Chebyshev distance,ChD)等作为相似度的度量标准,进行数据实验,结果表明,数据预处理能够降低定位误差,提升定位效果;进一步分析了 WKNN算法中K值对于定位误差的影响,提出了一种改进算法,根据指纹点和中心点之间的距离、赋予指纹点不同的权重,进行加权平均,用于终端定位。实验结果表明改进算法将定位精度提高了约12%。4.将定位算法拓展到三维空间,解决终端位置的楼层区分问题。提出一种基于基站匹配的WKNN算法,实验结果表明,与WKNN算法比较,改进算法将楼层区分准确率提高了约10%。"
1159,基于设备指纹的无线设备识别研究,"随着5G时代的到来以及物联网应用的普及,无线网络发挥着越来越重要的作用。无线通信媒介的开放性使得恶意用户能通过伪装身份,对合法用户之间的通信进行干扰、窃听,严重影响无线网络通信安全。传统的基于加密技术的身份认证机制在新型物联网应用环境中受到越来越大的挑战。无线网络物理层身份鉴权技术由于其较强的抗伪装攻击能力,受到越来越多关注。本论文研究利用物理层特性构建提取无线设备个体特有的设备指纹,并利用设备指纹进行无线设备身份的识别。本论文首先提出了一种基于多差分间隔星座轨迹图的设备指纹提取方法。该方法根据不同发射机之间载波频率存在的固有差异,通过分析接收信号的差分星座图的旋转角度作为发射机个体身份识别的依据。具体地,通过对接收信号进行差分运算,可以把载波频偏转化为星座图中的相位旋转,直观地表示不同程度的载波频偏。相位旋转角度与差分间隔有关。差分运算中使用较短的差分间隔,能适用于更宽的载波频偏范围,而不会产生相位混淆;而使用较长的差分间隔则可以区分更小的载波频率差异,达到更高的频率分辨率。本文提出融合较短、中等、较长等三种不同长度的差分间隔所产生的星座轨迹图作为设备指纹,解决传统单一差分间隔星座轨迹图不能兼顾频偏分辨力和频偏适用范围的问题。实验结果表明,使用多差分间隔星座轨迹图的设备指纹识别准确率优于传统的方法。尤其在低信噪比情况下,基于多差分间隔设备指纹比单一差分间隔设备指纹的识别准确率提高2%。进一步,本文提出了基于生成对抗网络的无线设备身份识别算法。与以往多数研究将身份识别问题建模成分类问题不同,本文提出的算法检测待测设备是否为合法用户设备,并能够对合法设备身份进行识别。算法主要思想是利用对抗式的训练模式,在仅已知合法用户信号样本的情况下,学习合法用户潜在空间的最优表示及其分布情况,并通过编码器对此最优表示重编码。当待检测信号来自于合法用户时,潜在空间的表示与其重构向量差别较小;而当待测信号来自于非法用户时,潜在空间的表示与其重构向量差别较大。以此作为待测信号是否来自于合法用户的依据。潜在空间的最优表示被进一步用于合法用户身份识别的特征。结果表明,基于生成对抗网络的无线设备身份识别算法能够准确地发现非法用户,并且能够准确地实现合法用户的身份识别。实验结果同时表明,利用多差分间隔星座轨迹图的进行非法用户检测与合法用户身份识别的效果优于传统单差分间隔星座轨迹图。"
1160,面向智慧健身的物联网动作监控系统研究,"近年来,随着人们工作强度日益增加、生活压力越来越大,人们的身体健康正面临着诸多挑战。在这种背景下,健康生活成为了人们关心的话题,越来越多的人选择通过健身来促进身体。另一方面,电子技术的飞速发展也使得越来越多的人使用基于MEMS的惯性传感器来监测人们的运动情况。这种方式可以更好地辅助体育锻炼,对于促进身体健康具有重要意义。目前,基于MEMS的动作识别研究主要有如下特点:在数据传输方面,以面向个域网的蓝牙和Zigbee为主要通信方式,这种方式尚不支持面向多用户的场景;在动作识别算法方面,以经典机器学习算法为主,如支持向量机、朴素贝叶斯、决策树等,而理解能力更强的深度神经网络并未被使用;在应用场景方面,以人体活动识别为主,即识别人体站立、躺、坐、骑行等状态,而对于更加具体的肢体类运动识别的研究较少。此外,在为数不多的肢体动作识别研究中,并未涉及对动作周期这一重要信息的分析。针对动作识别研究中上述现存问题,本文设计并实现了一种基于MEMS的多用户动作监测系统,用以实现对于肢体活动中动作类型、动作次数和动作周期这三个重要参数的监测,并支持多用户同时使用,具体的研究内容如下:(1)在系统设计方面,考虑到面向智慧健身的动作监控场景,提出了基于物联网的动作监控系统框架。该框架包含动作采集节点、无线接入点、数据处理服务器以及终端等组成部分。(2)在算法方面,进行了动作模式识别和周期计算方法的相关研究。对于动作模式识别,分别基于SVM和深度神经网络(基于1D CNN和LSTM构建)提出了两类具有不同复杂度的分类算法,以适应计算能力不同的场景。对于周期计算,提出了基于过零检测和小波变换的方法,用以统计动作次数并计算每一次动作的周期。通过动作识别算法和周期计算方法,实现了对于动作类型、动作次数和动作周期这三个重要参数的计算,从而生成对于肢体动作较为全面的描述。(3)在系统开发方面,开发出了包括数据采集手环、无线接入点和PC的硬件平台,以及集成了数据接收、动作识别以及周期计算模块的软件平台。硬件平台和软件平台共同组成了实验平台。基于开发的软硬件平台进行了相关实验。对7类动作的识别实验表明,提出的深度神经网络在小型数据集上学习效果良好,达到了97.61%的动作识别准确率,SVM也达到了96%以上的识别准确率。在50次的动作周期计算实验中,次数统计算法达到了 100%的计算精度,动作周期计算结果也与真实值接近,证明了周期计算方法的有效性。该系统提供了面向多用户的通信方式,实现了准确、可靠的人体动作监测,在体育教学及康复训练等领域具有广泛的应用前景。"
1161,基于稀疏编码的藏语语音识别研究,"相对于汉语和英语等大语种语音识别,藏语语音识别研究始于2005年,起步较晚,且不同语种间存在差异,采用新技术以提升藏语语音识别系统性能,将成为藏语语音识别研究领域亟待解决的问题。针对藏语单音节识别系统,本研究主要进行了以下工作:1.特征提取。以梅尔频率倒谱系数作为输入的卷积神经网络可同时获取时序信息和空间位置信息。实验中提取了两类特征,即静态与动态的梅尔频率倒谱系数。2.稀疏编码。为了尽可能地消除特征间的相关性,减少与分类无关的信息,使用稀疏编码获取两种梅尔频率倒谱系数的稀疏表示。稀疏编码采用K-SVD算法。3.分类器设计。以多维矩阵作为输入的卷积神经网络可保持输入数据维数不变。为了捕捉空间位置特征,选择卷积神经网络作为分类器。4.基于稀疏编码的藏语语音识别系统。该系统将稀疏表示后的梅尔频率倒谱系数输入卷积神经网络用以识别藏语单音节语音。本研究将稀疏编码与卷积神经网络两种技术相结合,以改善语音识别系统性能。通过实验得出以下结论:1.相对于深度神经网络,卷积神经网络更适合处理高维数据;2.动态梅尔频率倒谱系数和稀疏编码可提升藏语语音识别系统性能;3.本系统可用于藏语语音识别任务。本研究主要贡献是将稀疏编码与卷积神经网络相结合构成基于稀疏编码的藏语语音识别系统以进行藏语语音识别。"
1162,基于梯度提升算法的WiFi室内定位研究,"近年来,随着无线网络的快速普及和移动智能终端的广泛使用,LBS(基于位置服务)的需求迅速增长。目前,LBS已经迅速发展并普及到了社会生活的方方面面,定位技术已与LBS的发展紧密联系在一起。随着现代社会的不断发展,城镇化进程加快,大型建筑日益增多,人们80%以上的时间在室内环境中度过。各种移动通讯设备的快速普及,餐饮、购物、娱乐、地铁交通成为人们重要的生活方式,使得室内定位导航成为生活中不可或缺的部分。由于WiFi技术的快速发展,基于无线局域网和信号接收强度的室内定位技术利用现有的公共WLAN基础设施,不需要任何其他专业设备,只需要特定的定位软件即可实现定位。基于WLAN的室内定位技术成本较低,可以满足室内定位对定位精度的要求,已成为研究热点。本文首先基于电商平台的用户WiFi数据和位置信息,在原有特征群的基础上分析处理之后对原始数据特征提取,找出影响用户定位的关键特征。本文提出了基于信息增益的AP选择算法。提取出切合业务场景的特征群,以此来最大限度地还原出用户真实的行为习惯。其次,利用基于梯度提升树模型的特征选择减少数据维度,降低计算的复杂度,以此得到特征重要性的排序结果。最后,使用不同的特征组合检验模型,利用K近邻算法、随机森林与XGBoost对模型进行交叉验证。XGBoost对梯度提升树进行了扩展和改进,使得XGBoost的算法速度更快,准确率也更高。针对KNN中需要手动设置K的数值的缺陷,本文使用管道方法,即一次性输入多个k值,不仅节省了时间,还能更快的找出最好的k值。本文对XGBoost改进主要是对XGBoost的模型中正则化的改进以及对于模型参数的调节,以得到一个最好的实验结果。实验表明,本文提出的改进的XGBoost的算法在定位用户的准确度和运行效率都得到了提升。"
1163,基于生理信号多模态情感识别研究,"情感计算是实现人机交互的桥梁,其中情感计算中情感识别是一个至关重要的过程。情感识别根据情绪表达方法不同,可分为基于言语行为与基于非言语行为。在基于言语行为方面,研究者们大多关注于使用表情与语音分析用户情感状态,而在非言语行为方面,由于生理状态也包含大量情感信息,且被试者不受某些原因的影响,如刻意隐藏消极等,因此,基于非言语情感识别越来越受到研究者们的重视。基于非言语情感识别又可分为基于单模态和基于多模态情感识别,由于基于多模态情感识别可以利用多种信号,从多个方面去识别用户情感,其结果更加具有客观性和准确性,因此,基于多模态情感识别已经成为研究者们探索的焦点。在基于多模态情感识别中,由于脑电信号(EEG)反映用户中枢神经系统的情绪变化,外周生理信号反映用户自主神经系统的情绪反应,因此这两种信号得到了广泛使用。然而研究存在一个现实问题,脑电信号(EEG)需专业设备采集,所以采集过程比较困难和昂贵。基于上述原因,可以将脑电信号作为辅助信息来提高情感识别性能,因此本文提出基于典型性相关分析(CCA)、判别型典型性相关分析(DCCA)、加核判别型典型性相关分析(KDCCA)以及深度判别型典型性相关分析(DDCCA)的脑电信号辅助外周生理信号多模态情感识别。在训练期间,先提取外周生理信号及脑电信号,在脑电信号的辅助下,使用多种相关性分析算法创建情感判别空间,然后使用机器学习方法构建情感模型;在测试期间,只使用外周生理信号测试。本文分别从两个公开数据集DEAP数据集与DECAF数据集上进行实验,前期完成数据集的预处理、特征提取等操作,后期实现分类方法的模型训练及结果分析。在两个数据集上的多组实验结果统计分析数据表明本文使用多种特征融合技术中深度判别型典型性相关分析(DDCCA)的脑电信号辅助外周生理信号的方法可以提高情感识别性能,与之前同领域方法相比准确率提高9.31%,F1系数提高0.1467,根据多组实验证明结果具备一定程度可比性。本方法达到了较好的情感识别效果,可以实现在现实生活中非线性问题下情感识别目标。"
1164,结合声速反演的水声传感网络定位误差修正方法研究,"水声传感网络(Underwater Acoustic Sensor Network,UASN)的出现大大提高了海洋环境探测的潜在能力。在大多数UASN的应用中,节点定位都是一项基础而重要的任务。节点的位置信息有助于其它水下任务的完成。在位置相关的数据采集任务中,如果缺失了位置信息,数据将变得无用。目前大多数的水下定位模型使用单一的声速值进行距离估计和节点定位,忽略了水体的分层效应以及声速剖面的时间变化特性对定位结果的影响。然而,受水下介质不均匀以及海洋环境动态变化的影响,水下定位存在不确定性。因此,本文就基于UASN的声速估计和定位误差修正开展研究工作。论文的第一部分以UASN中的距离估计问题为例,通过求解克拉美罗界(Cramer-Rao Bound,CRB),讨论了声速剖面误差对距离估计性能的影响。研究结果表明,声速误差和时间测量误差以及深度测量误差一样,是影响水下传感器网络定位性能的重要因素。另外,海洋环境的动态变化也会造成声速剖面的扰动,导致声线路径和信号传播时间的变化,影响模型定位结果的稳定性。因此,为了降低声速误差对水下传感器网络中定位算法性能的影响,为定位模型提供更加准确的声速剖面信息是必要的。论文的第二部分研究了可适用于变化声速环境的高精度定位算法。通过对声速剖面的线性分段近似,建立了节点间声线路径的解析表达式,并将任意两点间声线路径跟踪转化为多项式求根问题。在此基础上,提出了一种利用到达时间差(Time Differenceof Arrival,TDoA)测量的水下节点定位优化算法。仿真结果与实验数据分析表明,相比于传统方法,新提出的算法能够给出更加稳定和准确的水下节点位置估计。论文的第三部分讨论了UASN中的声速反演以及定位误差修正方法。基于微扰法以及声速剖面的经验正交函数(Empirical Orthogonal Function,EOF)表征,建立了网络节点间信号传播时间扰动和EOF系数之间的线性关系。仿真结果表明,在该线性关系的基础上,通过最小二乘等逆问题求解方法,可以实现网络覆盖区域平均声速的反演,并且通过增加节点数量和引入先验信息进行序贯滤波可以有效地提高估计效果。结合论文第二部分的定位模型,论文以节点间距离估计和TDoA定位为例,验证了声速估计能够带来的定位性能改善。仿真结果与实验数据分析表明,结合声速反演的定位模型,节点定位误差能够进一步降低并接近CRB。此外,论文第三部分还讨论了神经网络方法在解逆问题中的应用。仿真结果表明,相比于传统方法,在稀疏EOF系数的估计中,基于神经网络的模型更有机会搜索到全局最优解,并获得更高的估计精度。论文的研究工作丰富了UASN定位方法,通过结合基于网络节点间信号传播时间扰动测量的声速剖面反演,为定位模型更新声速信息;通过声线路径的分段建模,建立了适用于可变声速环境的高精度定位算法,为水下定位提供声速剖面自修正的无偏估计;同时探讨了神经网络模型在解稀疏逆问题中的应用,提供了一种改进传统求逆算法的思路。"
1165,基于工业物联网的生产状态监测及数据分析系统,"在工业生产向智能化转型的时期,仍有大量制造业处于传统的生产模式,存在信息传递慢、综合生产管理难,以及工艺参数调控复杂等问题,导致决策与实际生产脱节。针对这一问题,本文以包装行业中铝箔内衬纸生产为研究对象,设计了一套基于物联网的生产设备状态监测系统,对生产车间的各个工位设备生产状态数据进行采集与实时监测,以及时应对生产中出现的各种异常情况,同时以直观的方式监测生产;同时本文针对工业生产中的产品质量预测方面,提出了一种具有普遍适用性的分析方法,通过集成学习中的XGBoost算法构建产品质量预测模型,进行产品良品率的预测,以改善质量控制中人工调控的低效率、低准确率现象。首先,提出了车间设备生产状态监测与数据分析系统的总设计方案与整体结构,包括由传感器终端设备与上位机监控组态软件组成的监测系统,以及基于XGBoost算法构建的数据分析预测模型。其次,设计了一套基于物联网的数据采集监测系统,通过传感器仪表组合架构完成多工位设备的状态数据采集,并通过灵活的组网方式实现网络通信功能;同时在上位机中对工业组态软件进行组态界面及功能的设计,完成生产监测系统。综合搭建了车间监测网络,为生产管理及数据分析预测提供信息来源。在数据分析方面,利用采集到的数据进行内衬纸复合表面质量预测。针对数据中存在的杂乱、变量类型多样化(数值、文本、图像、音频等)特点,以及数据分布不均的情况,引入机器学习中对数据适应性较强的集成学习,并利用其中表现优异的极端梯度提升算法(XGBoost)建立工业产品质量预测模型,输入数据进行模型训练与评估。通过实验分析了极端梯度增强(Extreme Gradient Boosting,XGBoost)、随机森林(Random Forest)模型与梯度提升树(Gradient Boosting Decision Tree)三种模型在质量预测上的效果,结果对比证明前者XGBoost的表现要优于后两种模型,且对于不平衡数据处理有良好表现,以此验证了该算法模型的性能与有效性。"
1166,基于网络游记文本挖掘的赴三亚国内旅游者偏好研究,"随着我国人民经济水平的日益提高和旅游业的发展,游旅者的个性化需求日益凸显,掌握旅游者的偏好规律,成为满足游客个性化旅游需求,从而提高旅游服务水平的重要基础。另一方面随着我国互联网技术的普及和电子商务的发展,越来越多的旅游者通过网络选择旅游产品,实现旅游消费,分享旅游体验,记录旅游经历。因此,网络上积累了海量以自然语言文本为载体的网络游记。这些游记中包含了丰富旅游者行为信息,为研究旅游者偏好提供了新的途径。如何准确、高效地对网络游记文本中蕴含的信息进行挖掘,成为实现基于网络游记研究旅游者偏好这一新途径的核心问题。本研究即是围绕该问题展开,其主要研究内容如下:(1)研究适合网络游记数据的爬虫策略及网络游记数据预处理方法;(2)基于文本挖掘相关理论,构建旅游者偏好模型;(3)根据所构建的偏好模型,以三亚旅游者的游记数据为例进行实例研究,挖掘赴三亚国内游客偏好,为三亚市旅游业发展提供建议。传统的旅游者偏好研究主要通过问卷获取旅游者行为数据,数据获取成本高,且数据的客观性不强,量级有限。本文通过网络上积累的海量富含旅游者行为信息的网络游记数据,将文本挖掘相关理论引入到旅游者偏好的研究中,为准确、高效的掌握旅游者偏好提供了新的方法,具有较大的理论和实践意义。"
1167,基于机器学习的人脸识别研究,"机器学习专门研究计算机怎样模拟或实现人类的学习行为,以获取新的知识或技能,为包括人脸识别领域的人工智能的发展做出了极大的贡献。本文探索如何应用机器学习中的一些技术,使计算机更好地完成人脸识别领域中的人脸检测和人脸验证。在人脸检测方面,针对如何快速、准确地检出人脸的问题,提出了一种使用特征融合的卷积神经网络。首先快速提取图像的梯度方向直方图(HOG),然后使用能快速对多种物体进行检测的卷积神经网络YOLO提取图像特征,最后将YOLO提取出的特征与HOG进行融合,并将融合后的特征作为特征图。在训练过程中,引入了多任务学习和复杂样本处理,使本文提出的卷积神经网络能够进行目标定位与分类,并提高训练效果。随后为进一步提高算法的性能,对学习器进行了改进,使用随机森林替换全连接层。在通用的人脸检测数据集FDDB进行的实验分析,证实了上述方法可大幅提高检测人脸的性能。在人脸验证任务中,为准确地对人脸图像进行身份验证,本文同样应用了使用特征融合的卷积神经网络,并在损失函数方面进行了修改。根据最邻近算法的思想,本文使用了三元损失函数,令人脸图片之间的相似度能被更好地量化,从而提高人脸验证的准确率。为了在使用三元损失函数训练算法时时加速算法收敛,对三元组的组成成分进行了优化。通过在通用数据集LFW上进行实验,证实了该方法能提高人脸验证的准确率。"
1168,基于机器学习的评论文本分析,"人民群众的物质财富已经获得了极大的丰富,外出旅游成为大众追求精神财富的一种流行形式。游客在出行前可以通过在线平台完成酒店预订,他们会阅读过往游客发表的体验评论来给自己提供意见参考。酒店本身也会密切关注那些评论,从中发现提高自身服务水平的立足点和着力点。评论信息杂乱且数量巨大,通过人工阅读的方式无法准确而全面地了解酒店情况。使用机器学习技术对评论文本进行精确分类并对其中蕴含的信息进行挖掘就显得极具意义和价值。本文立足于文本分类和LDA主题模型的相关理论,对某品牌酒店的评论文本进行实证研究。首先,数据的收集是基于网络爬虫技术完成的,通过数据清洗、中文分词以及文本向量化完成数据的预处理。对完成预处理的数据作了描述统计说明。其次,构建了逻辑回归、支持向量机、随机森林和人工神经网络四个分类器模型,计算召回率、精确度和AUC值等指标来评价它们的实际性能。支持向量机模型表现最好,可以在线上进行推广,用于实现对该品牌酒店评论文本的精确分类,弥补一些平台完全没有考虑将评论文本进行分类或者分类效果不佳的缺陷。最后,在正向评论类别和负向评论类别中分别构建LDA主题模型,挖掘潜在主题,提取不同主题对应的特征词进行对比分析。正向评论和负向评论的关注点主要集中在地理位置、设施配套、房间大小和隔音效果等方面。基于从评论文本中挖掘到的潜在信息,为出行游客和该品牌酒店提供针对性的意见和建议。"
1169,基于聚类中心选取策略的混合属性聚类技术研究,"数据的爆炸式增长为数据挖掘技术的应用带来了契机,聚类分析是数据挖掘领域中极为活跃的研究方向之一,旨在分析数据的分布、研究数据的特征,发现数据潜在的内部结构。它在数据探索和机器学习中扮演着重要角色,并广泛应用于推荐系统、客户分割、商业智能、生物信息等领域。本文在研究现有的聚类分析算法基础上,结合聚类中心选取技术,针对高维空间中混合属性数据聚类算法存在精度较低、参数敏感且过多、聚类中心选取偏差等问题展开研究,论文的主要创新工作如下:(1)依据核心对象与非核心对象的分布差异,提出了一种基于过滤模型的聚类算法CA-FM。算法采用提出的过滤模型FM去除干扰聚类过程的非核心对象;并根据核心对象间的近邻关系构建邻接矩阵,通过遍历矩阵统计连通子图数量,即为聚类原型个数;然后将对象按密度因子进行降序排序,选出聚类原型;最后将剩余对象依据划分原则分配到相应的簇中,形成最终聚类。在合成数据集、UCI机器学习数据集以及人脸识别数据集上的实验结果验证了算法的有效性,与同类算法相比,CA-FM算法具有较高的聚类精度。(2)依据聚类中心的空间分布特征,提出了一种基于中心选取模型的聚类算法CSC。算法以提出的无参数局部核密度度量方法和边界度度量方法为依据,建立了聚类中心选取模型CSM,从而自动确定聚类中心;并按照密度峰值聚类算法的划分原则,将剩余对象划分到相应的簇中,形成最终聚类。在合成数据集和真实数据集上的实验结果验证了聚类中心选取模型的鲁棒性和聚类算法的有效性。与同类算法相比,CSC算法具有较高的聚类精度和参数鲁棒性。(3)针对混合属性数据聚类任务,提出了一种基于残差分析的混合属性数据聚类算法RA-Clust。算法在基于熵权重的混合属性相似性度量基础上,提出了基于KNN和Parzen窗技术的局部密度计算方法;并通过线性回归和残差分析技术对聚类中心进行预选取,然后依据提出的聚类中心目标优化模型对预选取阶段得到的对象进行迭代优化,得到期望的聚类中心;最后将剩余对象按距高密度对象最小距离原则进行划分,完成聚类任务。在数值属性、分类属性以及混合属性数据集上的实验结果验证了RA-Clust算法的有效性。与同类算法相比,RA-Clust算法参数较少且具有较高的聚类精度。本文的研究工作展示了聚类分析技术从低维、数值属性向高维、混合属性处理领域的演变,同时为聚类中心选取过程提出了一种思路、机制、模型。在医疗诊断、金融信贷、生物信息、人脸识别等领域的实验与分析,进一步加速了混合属性数据聚类算法由理论研究向实际应用的迁移。"
1170,基于Attention自动编码机制的图像自动评论方法研究,"随着电子商务的普及,在线旅游、在线购物等也随之蓬勃发展。越来越多的消费者依据自己的消费经验通过网络对产品或服务发表评论。对于在线旅游或者在线购物网站,网站上的图像至关重要。商家需要通过学习用户发表的评论来推测用户的喜好和购物心理,在此基础上设计宣传图像。此背景下,本文做了学术性探究,尝试对图像进行自动评论,首次提出图像自动评论模型。在现实场景中,用户对图像的判断主观性很强,难以形成统一的评价标准。因此本文使用深度学习方法,去挖掘影响用户判断的图像属性,以及如何有效融合这些属性对图像进行评价。本文拟实现的图像自动评论算法是计算机视觉、自然语言处理与机器学习的交叉研究方向。本文的模型可以模拟用户对拍摄的图像自动生成简短评论,以便于商家根据用户的喜好对图像进行调整。本文的主要工作有:1、借鉴图像描述的方法和模型,本文首次提出图像简短评论模型,参考编码器-解码器模型算法,同时加入Attention自动编码机制来构建本文的图像自动评论模型。使用本文制作的图像评论数据集对模型进行训练调参,对拍摄的照片自动生成简短的评论。同时,基于BLEU、CIDEr等评价指标对模型进行调整以达到最佳效果。2、本文基于爬取的图片和评论,制作图像评论数据集。本文爬取了蜂鸟网的摄影论坛中和58汽车网站中的图像和评论数据,再去除异常数据和噪音,对收集的数据进行初步筛选。最后本文根据词频统计删除高频词,将图像和评论相对应,根据摄影和汽车等的专业词汇,做好图像标注,形成图像评论数据集。"
1171,基于移动教学APP的学习状态预警系统的研究与实现,"随着信息技术特别是无线互联网的高速发展,移动终端应用已经成为人们日常生活中不可分割的一部分,移动终端应用为高等教育提供了新的机遇。移动教育类应用对传统课堂教学模式与理念造成了强烈的冲击,特别是教学理念与“互联网+教育”概念的不断推广和影响,使得新型的移动教学模式逐渐的完善,市面上也随即出现了大量的教育类APP,例如“网易云课堂”、“流利阅读”等。纵观这些教育类APP会发现,这些教育类APP大部分都是线上类的,即教师用户与学生用户仅在线上交流互动。对于在校大学生而言,大部分的学习时间都在传统课堂上,而且学生在传统课堂上会产生大量的行为数据,将这些数据进行收集并对这些数据进行数据挖掘,分析数据之间的关联性,再将发现的规律反馈到传统课堂上,这将会对辅助教师教学、提高教学质量提供帮助。本文基于“翻转课堂”移动教学辅助系统软件原型开发的基础上,重新设计该款软件并进行跨平台开发,新增“作业发布”、“课堂测试”等功能,该款软件旨在将传统教学的教学方式用一款APP来实现并从中获取学生用户的行为数据。而后在“翻转课堂”移动教学辅助系统软件获取数据的基础上,设计并研发了学生学习状态预警系统,引入机器学习的思想,采用Adaboost机器学习算法对数据进行挖掘和分析,对学生的近期学习状态进行预测,达到学业预警效果,最终将预警结果展示给老师和同学,给于学生一定警示效果的同时也可为教师调整教学计划提供数据参考。本文提出的基于移动教学APP的学习状态预警系统,在实际投入使用的过程中,学生和教师反馈良好。该系统的投入使用提高了教师教学质量和教学效率,同时给于学生学习警示,促使学生更好的投入到学习当中,达到了系统设计需求。"
1172,场景自适应人群密度估计算法研究,"随着经济的不断增长,集体活动也不断丰富,随之而来的因人群拥塞而引起的事故也已屡见不鲜。因此及时地对公共场所的人群密度做出准确估计以避免危险发生就成为了视频监控领域的重要任务。人群密度估计是通过提取人群的分布特征进行分析计算,从而估算出密度分布并进行人群计数的任务。而实际场景转换为图片数据集时,会因为存在多尺度特征而无法被准确提取,导致估算的准确性下降的问题。现存的人群密度估计算法主要利用多尺度卷积神经网络分别对不同尺度的人群分布进行特征提取,最后平均融合得到计算结果。但传统的卷积神经网络为了提取全局特征,基本会对输入图片进行下采样,这样会丢失部分人群信息;且平均融合多通道卷积神经网络,对于多尺度特征提取计算结果的提升也很有限。针对上述问题,本文提出场景自适应人群密度估计算法。场景自适应人群密度估计算法以深度卷积网络为载体,利用扩张卷积对输入的人群场景图进行特征提取,在保持参数个数不变的情况下增大卷积核的感受野,这样既可以学习到全局特征,又不会增大计算量,同时也可以保证输出的特征映射(feature map)的大小保持不变。此外扩张卷积在上下文模型中通过设置不同大小的扩张系数来聚合多尺度上下文信息,提高了密集预测框架的性能。算法在模型的训练中利用对抗式损失函数将网络中提取的不同尺度的特征信息以合作式的方式融合。一般解决该问题的网络会选择欧式距离损失函数作为网络训练的优化,但这样只会平均融合每个通道各自的输出结果,失去了提取多尺度人群特征对于密度估计结果准确度提升的意义。对抗式损失可以使网络输出的结果最接近于真实的密度分布,极大地提高了密度估计的准确性。场景自适应人群密度估计算法提出利用扩张卷积在不损失分辨率的情况下对输入图像进行特征提取,通过对抗式损失函数将网络中提取的不同尺度的特征信息以合作方式融合的方法,解决了现有方法中卷积神经网络的池化层对图像的下采样操作会丢失部分人群信息,且平均融合方式会使多尺度效应平均化,使人群密度估计不准确的问题。实验结果表明,在人群分布差异较大的场景中构建的算法模型有较好的自适应性,能根据不同的场景提取特征估算密度分布,并对人群进行准确计数。另外本文借助基于几何适应高斯核转换得到的密度图作为标签进行网络的训练,使网络的预测结果更加准确。"
1173,融合标签迁移的跨领域推荐技术研究,"身处移动互联网时代,用户获取信息的渠道与日俱增,因此很难迅速对内容做出有效判断。信息过载等问题的出现使得推荐系统应运而生,并在各个领域展开了丰富的运用。但是,推荐系统面临的数据稀疏、冷启动等问题依然难以被有效地解决。因此,越来越多的机器学习技术开始运用于改进推荐算法。迁移学习技术能够通过迁移其他领域的知识至目标领域,为推荐结果增加可学习数据、强化推荐模型,缓解目标领域的数据稀疏和冷启动问题。因而本文开展了基于知识迁移的跨领域推荐模型和算法的研究,完成的主要工作如下:(1)大多数跨领域推荐算法常采用迁移学习技术,然而现有的迁移学习方法大多基于单一的评分模式迁移,在领域不相关的场景下,往往会导致负迁移、推荐结果不佳等问题。本文将评分知识与行为知识相结合,共同辅助目标领域的学习任务。在行为数据中,项目标签与用户的真实偏好相关,能够从另一个侧面反映用户或项目的隐式特征。为了缓解负迁移,考虑将辅助领域和目标领域的标签进行聚合,共同获得可迁移的知识。在此基础上,提出了融合标签的跨领域迁移推荐算法ITTCF(Item-based Tag Transfer Collaborative Filtering)。算法摒弃了仅对评分模式进行迁移的单一辅助方式,结合了用户评分和项目标签这两种异构知识,并融合了目标领域的标签,在一定程度上改善了目标领域数据的稀疏性和负迁移问题。(2)在现实场景中,用户更关心的是推荐的结果而不是评分,通过预测评分进行推荐并不能准确地捕获用户的偏好。基于此,进一步提出了面向对级排序的知识迁移推荐算法 RBT(Ranking-oriented Behavioral knowledge Transfer recommendation)。将算法的推荐目标从评分预测转向排名预测。通过迁移包括评分、标签在内的领域信息,得到更多的项目偏好,从而能够构建更为丰富的项目偏序对,用以训练排序模型,最终为目标用户生成候选推荐列表。(3)选取了豆瓣电影、豆瓣图书、MovieLens等数据集开展上述算法的对比实验。实验结果表明,ITTCF在RMSE和MAE上较对比算法分别提升了 1.61%-6.67%和1.97%-8.83%。通过排序学习,RBT在准确率、召回率、NDCG等面向排序的推荐评价指标上也均得到提升。"
1174,基于深度迁移学习的图像分类方法研究,"随着深度学习的不断发展,卷积神经网络在通用对象分类任务方面取得重大突破。相比于人工定义特征的分类方法,基于深度卷积神经网络的分类方法具有更强大的特征提取和图像表征能力,能够获取更准确、稳定的分类效果。然而,图像识别方法应用于从同一分布中提取的训练数据和测试数据时具有良好性能,但在现实场景中并不适用从而导致精度降低。与此同时,在实际应用中,不仅要从图像中识别出目标基本类型,还需进行细粒度图像分类。现有的细粒度分类模型除了使用图像的类别标签,还使用部件标注点或目标标注框等额外信息。本文对基于深度迁移学习的图像分类方法展开研究,通过基于注意力迁移机制的联合平衡方法提高领域自适应图像分类效果,并深入分析层次化的深度迁移学习方法以提高细粒度微数据集图像分类效果。本文主要研究内容如下:1.阐述深度迁移学习的研究背景和现状。针对传统的迁移学习方法进行深入的分析与研究,包括其中的关键技术和重要理论。详细描述卷积神经网络的组成、特性及优化方法,论述经典卷积网络的原理及特点。对深度迁移学习图像分类的常见方法及其特点进行系统的分析,详细对比迁移学习领域自适应中若干经典方法的优劣。2.通过对数据分布的分析,通过领域自适应深度迁移学习方法,使用注意力迁移机制和联合平衡领域自适应将源域有标签数据中提取的图像特征迁移至无标签的目标域。首先,使用注意力迁移机制将有标签源域数据的空间类别信息迁移至无标签的目标域。本文通过定义卷积神经网络的注意力,使用关注信息来提高图像识别精度。然后,基于目标数据集引入网络参数的先验分布,并且赋予网络自动调整每个领域对齐层特征对齐的能力。最后,通过跨域偏差来描述特定领域的特征对齐层的输入分布,定量地表示每层学习到的领域适应性程度。本文方法不仅在多数公开数据集上获得较高的识别精度,而且远优于传统手工特征方法。3.针对细粒度样本标签获取成本高,数据集类间差异较小而类内差异较大的问题,通过深度迁移学习模型,将大规模有标签细粒度数据集上学习到的图像特征有效地迁移至细粒度微数据集中。首先,通过衔接域定量计算域间任务的关联度。然后,根据度量反馈调整源域卷积神经网络,以便选择适合于转移到目标域的任务特定特征。最后,使用细粒度数据集视图类标签表示多任务学习的细粒度数据固有属性,从而进行辅助学习,通过联合学习所有属性来获取更多的特征表示。实验表明微数据集深度迁移学习方法不仅可以获得较高图像分类精度,而且能够有效减少模型训练时间,同时也验证了进行域间特征迁移可以加速网络学习与优化这一结论。"
1175,基于神经网络时序建模的连续手语翻译研究,"现如今,随着大数据技术的发展和计算机硬件运算速度的不断提高,人工智能与机器学习技术得以飞速发展。在计算机视觉领域,基于神经网络与深度学习的机器学习算法可以通过模拟人脑来理解图像和视频等多媒体信息。近年来,由于神经网络模型具有强大的拟合与回归学习能力,其在视频翻译问题上取得了突破性进展。连续手语视频翻译是计算机视觉领域的一个重要分支,在现实生活中有着重要的实用价值。手语是聋哑人日常生活中进行信息交流最自然的方式,连续手语视频翻译技术的发展为聋哑人的日常生活提供便利,实现听力障碍人群和正常人的自由沟通交流。手语翻译作为人机交互的一种方式,通过机器学习算法将连续手语动作翻译成对应的文字序列。手语视频自动翻译属于广义的序列到序列问题,其难点在于视频中视觉信息的识别,不仅要考虑当前时刻的图像帧信息,同时关系到连续帧之间复杂的动态变化关系。本文运用循环神经网络算法,使用编码解码结构和级联时序分类的实时翻译结构,对手语翻译问题进行时序建模。在编码解码模型中,提出时序池化操作,嵌入在翻译系统的分层编码器中,有效解决了连续视频数据的信息冗余问题,使得翻译效率和效果均得到显著提升。由于编码解码模型在长时手语视频翻译上存在梯度消失问题,本文随后提出了一种端对端的基于级联时序分类优化方法的双路并行学习模型,其中,在卷积神经网络和循环神经网络并行的双路网络结构中,卷积神经网络模块专注于二维图像上的局部感知,而循环神经网络侧重于连续动作的时序建模,突出了全局序列在时间维度上传递的内在关系。最后将两个模块输出的得分矩阵进行融合,结合级联时序分类优化方法,端对端地输出翻译语句序列。该方法能够同时有效兼顾视频中长时和短时的时空视觉信息,在长时手语视频翻译任务中取得良好效果。"
1176,基于过程数据关联性的ICS异常检测方法研究,"工业控制系统(Industrial control system,ICS)被广泛应用于能源、化工、污水处理等关键基础设施的监督和控制。近年来,工业控制系统遭受攻击的事件频繁发生,不仅造成重大经济损失,甚至威胁到国家基础设施和人的生命财产安全。现有的基于工业控制系统过程数据异常检测方法多采用机器学习方法检测异常,但此类异常检测方法并不解释异常结果,且难以确定异常原因,因此本文提出基于过程数据关联性的ICS异常检测方法,主要工作如下:(1)针对离散型控制变量的工业控制系统,设计基于一阶差分累积和的异常检测方法,利用变量间控制关系进行关联和异常分析。首先,针对基于累积和方法在检测噪声数据转折点的不足,设计基于一阶差分累积和的转折点确定方法;然后,根据转折点分析执行器变量与传感器变量间的控制关系,遍历执行器变量集确定传感器变量的控制集;随后,将执行器状态与传感器特征关联,利用关联特征表达执行器变量对传感器变量的控制效应,避免构建精确物理模型;最后,根据关联特征检测异常,并基于一阶差分累积和的转折点发现算法确定异常区间以及异常原因。(2)针对连续型控制变量的工业控制系统,设计基于拓展边界的一类支持向量机异常检测方法,解决一类支持向量机在高噪声数据分类方面存在的问题并根据过程数据的相关关系进行异常溯源。首先,利用基于最大正交距离的转折点算法确定过程变量的转折点,该过程自适应确定迭代终止条件,适用于不同噪声水平的过程数据;然后,根据原因先于结果发生和原因变化必导致结果变化这两个特征分析变量间的因果关系,构建因果图用于异常结果溯源;使用非监督机器学习一类支持向量机训练过程数据获得正常数据的分类边界,拓展该分类边界作为异常判断边界,允许一定范围内的噪声干扰,可降低异常检测的误报率;最后对出现异常的变量根据因果图分析异常源。(3)分别利用安全水处理系统以及田纳西仿真平台数据验证本文两种异常检测方法的有效性。实验结果表明,本文基于过程数据关联性的异常检测方法能够准确检测系统异常,且具有较低的漏报率和误报率。同时,对比现有的相关性分析方法,本文的基于转折点的相关关系分析方法准确性更高,且能有效定位异常区间和溯源。"
1177,基于在线数据的迁移学习分类方法研究,"实际应用领域产生了大量的在线数据,如异常检测和信用卡欺诈检测等。这些在线数据多缺乏标记信息,且在线数据中隐含的信息随时间发生变化,这都给在线数据分析任务带来极大的挑战。近年来,利用有标记的源领域信息实现在线迁移学习的方法得到了广泛的关注。现有的在线迁移学习方法多根据分类准确度来更新模型,在实际应用中难以达到理想的效果。为此,本文面向不同特点的应用领域开展在线迁移学习方法研究,主要研究内容如下:1)介绍了在线迁移学习的定义,并对当前主流的在线迁移学习方法进行了分析和介绍。2)在信用卡欺诈等在线应用领域中,分类代价比准确率更为重要,且在线数据的代价通常会随着时间发生变化。针对这一问题,本文综合考虑分类代价和准确度提出一种基于自适应代价的在线迁移学习分类方法(OLAC)。该方法引入标记分布参数用于代价的自适应计算,并通过组合参数将源域和目标域结合,从而实现源域模型到目标域的在线迁移;最后,根据代价和准确度来动态更新学习分类模型。实验结果表明该方法可以取得比基线算法更好的分类准确度和最小的代价。3)针对多数线性分类模型无法解决在线数据中的线性不可分问题,而解决在线线性不可分问题的核方法在在线环境下又存在支持向量无边界增长的问题,本文提出了一种基于核的在线迁移分类方法(KOTL)。该方法首先将目标函数直接映射到再生希尔伯特空间从而忽略原来目标域数据在低维空间是否线性可分问题;然后引入一种缓冲策略解决核函数支持向量的无边界增长问题;最后,通过同时优化结构损失函数、域间分布差异以及流行正则化函数来实现分类模型的更新。在多个图像数据集上的实验表明,KOTL算法的性能显著优于基准算法。"
1178,基于情感的中文新闻分类与推荐研究,"近年来,互联网时代的迅速发展使得个性化推荐技术被广泛应用,同时人工智能技术的进步带动了机器人技术的革新,新一代的机器人具有更加人性化的情感计算能力。从服务于空巢老人的思路出发,提出了融合用户情感的新闻推荐系统项目,本文主要研究该项目中的两个子任务:基于情感的新闻分类任务和基于用户情感的新闻推荐模型构建任务,以此可以为整个项目做技术铺垫。本文主要工作总结如下:(1)首先介绍了本文的研究背景与意义,并分别对文本情感分析和个性化新闻推荐的研究现状进行了总结与概括。然后从文本情感分类的角度,介绍了基于机器学习的分类方法所用到的相关技术,包括数据预处理、文本表示、文本特征提取、以及常用机器学习方法,同时还介绍了两种基本的人工神经网络模型。接着介绍了两种比较成熟的推荐算法,并简单介绍了推荐系统中常用的推荐方法、评测指标以及实验方法。(2)其次对于基于情感的新闻分类问题,根据新闻的特征以及对常用文本情感分类方法的比较,最终以卷积神经网络为原型提出了多输入通道卷积神经网络模型(MIC-CNN)对新闻标题做情感分类。MIC-CNN模型的输入层有三个输入通道,在卷积池化层将三个通道进行加权组合,最终由softmax函数完成情感分类。通过对比实验验证了该方法是可行的,而且比其他方法的分类效果有所提高。(3)最后针对基于用户情感的新闻推荐问题,主要分析了如何获取具有情感信息的新闻数据、如何获取用户的情绪信息以及如何融合情感做兴趣推荐三个难点。经过研究本文利用前文的新闻情感分类方法来获取具有情感信息的新闻;利用现有技术如语音情感识别、面部表情检测等方法可以一定程度获取情绪;通过分析人情绪的特点提出了五种情感推荐策略来做兴趣推荐。然后给出了融合用户情感的新闻推荐系统框架,最后以用户调查的实验方法验证了基于情感的新闻推荐系统方案的可行性和有效性。"
1179,基于概率依赖关系的命名实体识别方法研究,"在信息爆炸的大数据时代,如何从庞杂的数据中获取简单有效的信息显得日益重要。命名实体识别是在文本中定位和分类专有名词(例如人名、地名等)的手段。在中文领域,这类命名实体发挥着巨大的作用,因而将其更好的发现与提取是一项有意义的工作。文本数据具有上下文依赖关系,本文将数据作为随机变量的集合,挖掘随机变量中实体与其他信息的概率依赖关系。考虑到命名实体识别任务的特殊性,我们从依存句法分析和子序列分割入手,提出了对其算法的改进,本文主要工作如下:(1)提出了融合依存句法信息的神经网络结构以识别命名实体,通过单向信息的传递,得到与双向信息传递可以匹敌的效果。该方法考虑到将依存句法分析获得的句子中与物理位置无关的信息之间的语义关系作为特征以提高命名实体识别性能。提出将基于词语级别的依存句法分析转化为基于字符的依存句法信息,以获得更多的额外信息并减少错误的依存句法分析结果带来的影响。并引入树状长短期记忆神经网络,挖掘以依存句法分析表示的树状序列信息。(2)提出了神经网络与半马尔科夫条件随机场结合的命名实体识别方法,该方法将序列看成是一个个子序列的集合,并将子序列作为一个整体进行标记,解决了条件随机场中存在局部依赖的问题,从而使得最终的识别性能有所提高。"
1180,路径规划中的价值迭代网络对抗性样本生成研究,"当前,机器学习领域内的研究大多关注如何对机器学习的算法、模型进行优化,而忽略了模型的安全性问题。尽管在输入理想的样本时,这些模型有着近乎完美的表现,但在实际环境中,这些模型在训练阶段和模型推理阶段都有可能受到对抗性样本攻击。本文以机器人路径规划问题为对抗性攻击的应用场景,强化学习模型价值迭代网络(ValueIteration Network,VIN)为攻击目标,进行对抗性样本生成方法的研究。本研究以VIN模型实现的机器人路径规划为基础,分别提出了在黑盒和白盒两种场景下的对抗性样本生成方法。基于黑盒场景,分析了 VIN模型进行路径规划的样本,提出了黑盒场景下的对抗性样本生成方法。文中提出了攻击点威胁值的定义并给出了计算规则,综合了可攻击点与原路径、终点、以及原路径拐点之间的距离三条因素量化计算规则。在仅添加一个攻击点的情况下,黑盒场景下提出的对抗性样本生成方法的准确率为34.54%。基于白盒场景,提出了单步攻击和多步攻击两种对抗性样本生成方法。在单步攻击方法中,通过分析VIN模型的价值矩阵、寻路失败样本的特征和添加攻击点前后价值矩阵的变化,得出攻击点发现方法。方法中综合了价值矩阵和原路径的双重影响,找出添加干扰后可能使模型寻路陷入困境的攻击点。在仅添加一个攻击点的情况下,单步攻击方法的准确率为65.71%。在多步攻击方法中,首先不断的输入对抗性样本,向模型发起寻路请求,推测出可攻击点与样本价值矩阵的内在关联。然后根据可攻击点的特征,将样本划分栅格并计算区域价值平滑度,缩小可攻击点选取范围。多步攻击生成对抗性样本方法的准确率可达92.53%。本研究的主要贡献为:基于黑盒和白盒两种场景,提出了针对VIN路径规划模型生成对抗性样本的方法,模拟了 VIN在模型推理阶段受到恶意攻击的情况。实验结果表明本文所生成的对抗性样本会使VIN模型出现寻路错误,这证明了 VIN确实存在着安全性的问题,并且本文所提出的对抗性样本生成方法确实有效。"
1181,融合情感分析和用户行为的关键评论提取方法研究,"在Web2.0以后,人们已经习惯在社交网站上,对自己熟悉或感兴趣的商品、景点、美食以及电影等发表自己的观点,如:对景点的评论、特色美食的点评、酒店评论或者对某品牌产品的体验。所以,用户网络评论具有公开、可用和共享性,是社会舆论的一种重要的表达形式,用户也习惯于从商品的评论文本中检索重要的信息,为自己的决定找到一个准确的参考。但是目前互联网中信息量较大,比如:在电商系统中,对于某个商品的评价内容多达成千上万条,如何针对这些评论找到符合自己需求的观点显得尤为重要但实现起来比较困难。因此,如何对关键信息进行准确的提取则显得非常具有现实意义。现阶段在关键信息提取方法中存在两个问题:(1)现阶段在计算句子情感极性时,大多都是考虑纯文字句子的情感极性,很少考虑到表情符的情感极性对句子情感极性产生的影响,使句子的情感极性计算不够精确;(2)大多数学者在分析用户评论时,大多只分析评论数、点赞数以及转发数等表面行为,极少对评论内容以及回复评论内容进行考虑,显然分析的片面性对关键信息的提取存在着很大的偏差,使计算结果差强人意。因此,为了解决上述存在的问题,本文提出了融合情感分析和用户行为的关键评论提取方法,主要工作分为以下两部分:(1)提出了基于表情符分析的情感关键句提取方法。该方法对情感关键句抽取方法进行了改进,在计算句子情感极性得分时,着重考虑了表情符的情感极性对句子情感极性的影响,使计算的句子情感极性更加精确;(2)提出了融合评论内容和回复支持率的评论关键句的提取方法,解决了现有方法中缺乏对商品评论内容质量的考虑以及对回复评论内容的用户态度的考虑,既考虑了评论内容的质量,又考虑了回复评论所蕴含的支持与否的态度,计算回复评论的支持率和点赞率,从而提高了评论关键句的提取效率。分别对基于表情符分析的情感关键句提取方法、融合评论内容和回复支持率的评论关键句的提取方法以及将两种方法结合后得到的融合情感分析和用户行为的关键评论提取方法进行有效的实验验证。实验结果表明,本文提出的基于表情符分析的情感关键句提取方法,较其它主流方法具有较高的准确率、召回率和F值,能够更精确的提取出情感关键句;本文融合评论内容和回复支持率的评论关键句的提取方法能够更贴合用户真实情感;两者结合后的融合情感分析和用户行为的关键评论提取方法考虑因素更全面,提取效果更好。"
1182,基于品牌社群划分的个性化商品推荐方法研究,"随着信息技术的高速发展和移动终端设备的广泛应用,互联网全面进入Web2.0时代,电子商务随之迅速发展成为人们日常生活中必不可少的商品交易方式,人类社会急速进入信息爆炸时代,由此产生了信息过载问题。一方面,用户无法从海量的信息中找到符合自己需要的信息;另一方面,信息提供者也无法针对用户的个性化特点向用户提供有效的信息。面对信息过载的困境,推荐系统成为解决此问题的有效手段。伴随着用户对个性化信息准确性的要求越发严格,传统的推荐模型已经不能满足用户的需求,推荐系统的发展需要不断进步。尤其在电子商务方面,提高商品推荐的准确性显得尤为重要。目前推荐系统研究的主要问题:一是冷启动问题,包括用户冷启动,即新用户刚进入系统,没有与其相关的历史交易记录,系统无法为用户提供准确的推荐。物品冷启动,即新商品刚进入市场没有与其相关的评价和购买信息,无法将其推荐给相关用户;二是数据稀疏问题,与网站销售的庞大数量商品相比,用户做过评分的商品只占其冰山一角,这就导致了用户项目评分矩阵的数据极端稀疏,在计算用户或项目的最近邻时准确率就会比较低,从而使得推荐系统的服务质量急剧下降。针对上述问题,本文提出基于品牌社群划分的个性化商品推荐方法,第一,通过品牌认可度和用户信任度划分用户社群;第二,在划分的用户群组中利用耦合卷积神经网络模型进行评分预测,将高评分商品推荐给用户,以此来提高商品推荐的效果。本文主要针对物品冷启动和数据稀疏问题两方面进行改进,该方法首先进行用户品牌社群划分,对通过分析用户购买记录和评价记录得到的用户品牌认可度和用户活跃度利用DBSCAN算法进行聚类,初步形成群组。与此同时将通过用户交流信息,计算得到的用户信任度与初步群组进行矩阵融合,形成最终品牌社群;然后在用户群组内进行商品评分预测,选取高评分商品推荐给用户。评分预测模型由两个耦合并行的神经网络构成,一个用户网络和一个项目网络,分四层结构(输入层、隐含层、输出层、共享层);用户评论数据和商品评论数据将分别从用户网络和商品网络输入,在评论语义分析方面,将分别从字向量角度进行实验,并且改变传统的使用单一大小的卷积核处理句子的模式,使用多个并行的卷积层,利用多个大小不同的卷积核对句子进行特征提取;接着两个网络的输出将共同汇聚于共享层,在共享层使用机器学习FM算法进行评分预测;最后将群组中的高评分商品推荐给用户,提高商品推荐的准确率。本文通过与包括经典协同过滤算法在内的主流推荐方法进行对比实验,从准确率、召回率和F1值三方面来进行比较,实验结果表明,本文提出的基于品牌社群划分的个性化商品推荐方法拥有更好的推荐效果。"
1183,基于神经网络模型的文本语义通顺度计算研究,"随着文本数据的急剧增加,对文本的智能化处理和分析成为了解决信息过载问题的重要途径之一,而文本的语义研究则是其中的关键。作为文本语义研究的一个重要方向,文本语义的通顺度研究目前相对较少。不可否认,文本通顺度研究对机器翻译,文章智能批改等领域也至关重要,但怎样判断句子是否通顺以及句子的组织是否合理则是一个非常重要且颇具挑战性的研究课题。传统的人工处理方式不仅需要耗费大量的人力成本和时间资源,而且存在着较大的不准确性,差异性等问题。若能通过对文本语义通顺度研究来构建一个有效模型,让计算机以类似人类的方式去评判一句话是否通顺,那么将有望缓解传统人工批改所存在的如无法批改大量文本、低效及一致性评价等问题。本文提出了一种依存句法分析下的语义通顺度计算方法,该方法通过融合句子主干以及句子细节的语义通顺度和语法通顺度的联合概率来计算通顺度。本文还提出了一种神经网络模型和机器学习算法结合下的语义通顺度计算方法,该方法先对文章进行分词,通过word2vec进行词向量表示,然后在模型中加入卷积神经网络(CNN)层学习字向量,并通过注意力机制联合词向量与字向量,然后通过双向长短时记忆网络模型(Bi-LSTM)进行学习,最后输入到条件随机场层(CRF)进行计算输出。在实验过程中,针对申论议论文数据集正负样本不平衡的问题,使用欠采样等方法进行了数据增强处理。实验结果表明,相对于依存句法分析,神经网络模型与机器学习算法结合的模型更适用于文本的语义通顺度计算,我们在一个人工标注数据集上进行了实验验证,初步证明了上述模型的可行性和有效性。"
1184,在线学习社区学习者学业成绩预测系统的设计与实现,"近年来,互联网技术得到了飞速发展,推动了在线学习社区的发展,使得教育更加公平化。越来越多的学习者选择从在线学习社区获取知识,通过在线课堂、与他人通过Web短文本讨论等方式进行学习。但因为在线学习社区这种无人监管的学习环境,大量的学习者因为这种学习环境和无法预测自己学业课程的学习情况,从而在学业课程上产生懈怠,导致最终课程考核不及格。因此,为了使学习者在学习社区中更加顺利的“毕业”,大量的学者专家都积极致力于学习者学业成绩预测方面的研究。但令人不满意的两个地方,(1)从先前专家、学者的研究中发现,使用决策树、朴素贝叶斯、支持向量机等比较陈旧的传统机器学习方法的预测效果(预测准确率)不如深度学习方法;(2)到目前为止,几乎还没有一个可直接使用的通用的预测工具,对学习者学业成绩进行分析预测。为了实现在线学习者学业成绩预测系统,本文在在线学习社区的背景下,针对在线学习者学业成绩数据集的特点,主要做了如下工作:首先,设计并实现在线学习环境,以获得在线学习者学业成绩数据集;接着,实现数据预处理功能,针对数据集的特点,对数据进行数值化、归一化、降维等操作,将数据转化成可直接计算且消除量纲差异;然后,实现学业成绩预测功能,在数据预处理的基础上,对学业成绩进行预测,将学习者的学业成绩按照学业成绩层次进行分类预测。在预测算法上,以提升准确率为目的,选择目前较为火热的深度学习方法对学习者学业成绩进行分类预测;最后,实现数据可视化功能,基于原始数据集及预测后的学业成绩,将其以图表的形式展示给学习者。"
1185,基于CNN和BLSTM特征融合的情感分析研究,"互联网的快速发展方便了人们的沟通交流,众多的网民通过微博,微信等公开平台发表自己的言论,由此产生大量具有主观情绪的社交网络数据。情感分析技术通过分析、研究大量社交网络数据,挖掘出其潜在的信息,以此来分析网民对社会热点话题的关注度和情感倾向情况,从而为相关部门的政策制定提供支持及正确引导网民的情绪传播。早期情感分析领域研究的文本主要集中在新闻,博客等长文本数据,随着新浪微博,微信等社交网络的迅速发展,基于产品评论、电影评论、社会热点事件评论等短文本情感分析逐渐成为情感分析领域的研究热点之一。伴随着研究的不断深入,针对短文本的粗粒度情感分析现已较为完善,但细粒度的情感分析还有很大的发展空间。然而,针对细粒度的中文评论情感分析数据集还很缺乏。基于这一问题,本文以新浪微博平台中的社会热点话题的微博评论为研究对象,分别爬取了不同话题的评论数据,包括计划生育二胎政策、扶贫政策、环保事件以及雾霾事件,并依据一定的数据处理准则和标注标准对数据集进行了预处理和细粒度的情感标注,从而得到了面向不同话题的情感分析数据集。在此基础上,本文构建了基于卷积神经网络(CNN)和双向长短期记忆网络(BLSTM)特征融合的情感分析模型CNN-BLSTM,该模型基于现有模型中将卷积神经网络建模和循环神经网络(RNN)建模分离的状况,提出将CNN提取的短语特征和BLSTM提取的序列特征结合,用于有效地增强对文本信息的提取能力。鉴于文本中特定情感词对文本情感分析具有更重要的影响,本文在CNN-BLSTM模型的基础上,进一步提出CNN-BLSTMATT模型,该模型通过引入注意力(attention)机制,将CNN提取的局部特征表示引入到BLSTM模块的情感特征表示上,有效增强了BLSTM对情感语义信息的捕获能力,从而达到文本情感特征增强效果。最后,在构建的数据集和公开的英文数据集Stanford Sentiment Treebank(SST)[1]上的实验结果表明,本文提出的CNN-BLSTM模型比使用单一的CNN或者BLSTM模型能取得更好的实验效果。此外,本文提出的(CNN-BLSTMATT模型相较于CNN-BLSTM模型,在显式情感表达的文本中具有更好的情感分类精度。"
1186,自然语言处理―中文词和短文本向量化的研究,"近年来计算科学飞速发展,尤其是计算机的计算能力大幅提升,机器学习和深度学习的应用越来越广泛,因此我们在自然语言处理领域的研究越来越多的运用了机器学习和深度学习的方法作为工具,在这样的情况下,自然语言处理也得到了大幅度的发展。在自然语言处理中,如何将词转换为计算机能够识别的语言是一项基础性的研究,因此词向量化和文本向量化方法的研究就显得尤为重要。传统针对文本数据的分析,往往基于词频、词频逆文本统计量作为文本的表示特征。这类方法往往只反映了文本的部分信息,忽略了文本的内在语义特征。尤其是对于短文本数据而言,关键词出现的频率通常较低,这给基于词频原理的统计模型带来了巨大的挑战。因而,本文提出了中文词语衔接的概率语言模型,其基本思想在于根据文本中词语出现的先后顺序进行建模分析,该模型在短文本数据挖掘中能够很好地针对文本语义进行量化分析。主要解决两类问题:一、如何合理地将中文词转化为数字向量,并且保证中文近义词在数字空间特征上的相似性;二、如何建立恰当的向量空间,将中文文本的语义和结构特征等信息保留在向量空间中。最后结合金庸小说人物验证中文词向量化的合理性;另一方面应用某城市房屋管理部门留言板的实际留言文本数据,借助BP神经网络和循环神经网络(RNN)两种算法,实现概率语言模型的求解。与传统文本处理方法的对比说明,本文的模型方法针对短文本语义挖掘问题具有一定的优势性。"
1187,基于弱监督和注意机制神经网络的生物实体关系抽取研究,"关系抽取是自然语言处理(Nature Language Processing,NLP)任务的一个重要分支,关系抽取任务的主要内容是获取语料中目标实体间的关系信息,其实是一个多分类的过程。关系抽取在“知识图谱构建”、“问答系统”等任务中都有很广泛的应用。关系抽取任务早期使用“条件随机场”等传统方法比较多,但面对日益复杂的数据结构和海量的待处理数据,传统方法逐渐无法达到期望的效果。近年来,随着深度学习技术的发展,使用卷积神经网络、循环神经网络等进行关系抽取任务可以获取更多的语料信息,抽取结果也更加准确。与此同时,关系抽取在生物医学实体中的应用也越来越广泛。生物知识库的构建、医学数据的整理都离不开关系抽取。在关系抽取任务中,存在着处理的过程中对目标词的集中度不够,对词的语义信息缺乏利用等问题。同时鉴于生物医学实体的特殊性,需要对网络模型进行针对性的调整。本文设计了两个关系抽取模型:(1)针对长文本上下文信息容易丢失的问题和语料中不同句子以及句中不同词对实体关系抽取结果影响不同的情况,提出了多重注意机制门控循环单元模型(Multiple Attention GRU,MAGRU)。模型以双向长短期记忆网络(Long Short-Term Memory,LSTM)的变型门控循环单元(Gated Recurrent Unit,GRU)为基础,并在此基础上分别在对词和句子进行处理的时候增加注意机制,形成多重注意机制GRU模型。同时考虑到生物医学文本的特殊性,通过调整模型的注意机制来适应生物医学实体关系抽取的要求。使用模型分别在传统数据集和生物医学数据集上与现有效果较好的方法进行对比实验,实验结果表明,MAGRU模型比现有模型F值有至少1%的优势。(2)针对关系抽取任务对语料中的语义信息利用不足,尤其是生物医学文本中语义信息对关系抽取效果影响更大的情况,本文在多重注意机制模型(MAGRU)的基础上引入词的命名体信息和词性信息等其他语义信息作为输入数据的补充,同时在生物医学文本关系抽取实验中增加具有生物医学背景的语义信息,并结合注意机制进行调整。本文使用模型分别在传统数据集和生物医学数据集上进行与现有效果较好的方法以及无语义信息的MAGRU模型进行对比实验,实验结果表明,引入语义信息的MAGRU模型比其他模型在F值上有3%左右的提升。"
1188,基于文本挖掘的学术文献内容智能识别方法研究,"作为人工智能领域的前沿课题之一,文本挖掘(Text Mining)是以文本数据为研究对象,以数理统计分析为理论基础,结合机器学习与自然语言处理等相关方法,提取文本隐含信息以及知识的计算机处理技术。为解决传统人力分析方法在处理规模化学术文档集时效率低下的问题,本文以切割布局问题(Cutting and Packing Problem,C&P)学术文献为研究对象,旨在结合文本挖掘与机器学习相关方法,实现该类文献内容类别的智能化解析及识别,从而为规模化学术文档集的分析和处理提供更加高效的途径。主要研究工作包括以下几个方面:(1)根据本文的研究对象和研究目标,研究了 C&P问题的基本概念和该类学术文献的主要内容类别,并以国际主流运筹学期刊为数据来源,建立了文档数据集,作为本文算法模型的测试对象。(2)基于Python编程语言及其第三方库,构建了包括文档格式的转换、文本数据降噪、文本切分、停用词去除、词性标注以及词干提取等步骤在内的文本数据预处理流程。(3)对比经典特征提取方法,选择并建立了基于人工神经网络(ANN)的文本特征提取模型。主要包括样本训练数据的生成、全连接神经网络的设计、卷积核数量和大小的确定、池化操作的选择、模型超参数的设置和可视化处理、训练算法的实现。(4)为解决全局式智能解析算法识别效率低下的问题,提出了分步识别方法:首先,采用基于文本排序算法的关键信息提取,缩减目标文档的数据规模;其次,采用基于编辑距离的模糊识别算法对所提取的关键信息进行搜索匹配,从而实现了学术文献内容的智能化解析和识别。(5)基于整体研究方案搭建了学术文献智能挖掘原型系统,实现了主要流程的模块化、集成化以及自动化。为验证所提方法的有效性,对文档数据集进行了规模化测试,并采用分类模型评价体系分析了测试结果。结果表明,本文所提方法主要性能指标均能取得较好结果,综合可接受度为81.19%,说明本文对相关研究及应用具有一定的参考意义。"
1189,基于文本挖掘与排序学习的内容推荐系统设计与实现,"随着信息技术尤其是移动互联网技术的飞速发展,网络平台上的信息量呈现指数级增长,如何从海量数据中发现感兴趣的内容对用户来说是一大挑战。作为应对这种挑战的有效手段,推荐系统被越来越多地用于为用户提供个性化服务。然而文本主题多元化和用户兴趣变化的时序性,使得传统的推荐策略很难满足用户的个性化需要。如何深层挖掘文本信息、结合机器学习算法召回推荐商品并精准排序成为本系统研究的重点。针对上述问题,本文设计了一种基于文本挖掘与排序学习的推荐系统,研究了新型推荐方案,包括文本建模算法、候选集召回算法及候选集排序算法,然后基于该推荐策略设计并实现了内容推荐系统。主要工作内容如下:(1)结合文本主题概率模型和深度神经网络,提出了一种推荐候选集触发策略。该策略使用深度神经网络挖掘用户与商品的深层属性,使用梯度下降与反向传播对模型进行训练,计算用户与商品在相同空间下的特征序列,通过近邻计算找到与用户喜好最相关的商品集合。尝试性的利用隐含狄利克雷分布计算文本主题分布,嵌入到用户阅读历史兴趣序列作为模型的预训练数据,不仅提高了深度神经网络模型计算的准确率,也使模型损失函数快速收敛,提高了计算效率。(2)结合深度神经网络与因子分解机构建了融合模型,该模型通过构造用户与商品的低阶特征组合和高阶特征组合,挖掘用户与商品复杂的隐含联系,实现了对推荐商品的点击率预测,从而在客户端展示数量有限的情况下,对召回推荐列表精准筛选与排序。线上A/B测试表明,该算法使得用户的点击率比原有基于标签的推荐提高了 14%。(3)结合用户和系统需求,设计了内容推荐系统的整体架构,并基于Spring Boot框架设计实现了推荐系统的在线服务,能够有效处理用户请求,将推荐算法与复杂业务逻辑筛选出的推荐商品列表及时返回给客户端,并验证了系统的功能与性能。目前该系统已成功运用于得到APP大规模文章推荐,很大程度上改善了用户体验。图40幅,表16个,参考文献42篇。"
1190,基于社交网络分析的用户群情感倾向研究,"随着Web2.0时代的飞速发展,网络空间越来越成为用户开放、自由的公共舆论场,与现实世界相比,网络世界也具有隐秘性、多样性、无权威性、扁平性等特质,网络用户可以在各种社交媒体畅所欲言,表达个人意见和对社会生活的见解,诸如微博、朋友圈、论坛、贴吧、电商评价网站等已成为用户传播海量信息的平台,其中包含着丰富的公众评论意见和情感信息,在一定程度上可形成社会舆论,影响着突发事件或者社会公共事件等的发展和走向。因此对用户情感的判断不仅可以反映出公众的情绪走向,便于网络舆情态势监测,实现社会稳定,更可以在各种微领域具有重要价值,如在线产品评论分析评价好坏、股票市场情绪分析进行风险控制,电影风评分析预测票房收入等。然而互联网内容传播过程中也显现出现实世界中的巴尔干化现象,即网络用户个体逐渐演化为具有相同利益或者情感倾向的群体。传统情感分析方法在文本特征提取上已取得一定成果,忽略了用户本身的社交关系,假定数据样本都是符合独立同分布假设的,只分析单个用户的情感。但是,用户之间必然普遍存在着关联,用户社交群体的整体情感倾向性会比单个用户更加明显和稳定,因此,以基于社交网络分析的方式对用户群情感研究有重要的意义。本文展开的研究工作包含以下几个方面:第一,社交网络关联挖掘。本文从相似用户节点会有相似的群体倾向的角度出发,提出了一种基于FRAP的网络社区划分方法。本方法首先在向量空间层面刻画出用户节点的位置信息,定义了能量函数嵌入力引导空间,通过不断降低能量大小得到收敛位置向量,并利用多级邻居信息融合为节点差异度矩阵;然后经差异度的置信值传递聚类得到核心节点,聚类后通过标签优化转移的方式实现模块值的局部收敛,最终借由衡量系数的标签聚合更新节点的类标签,通过归属值指导生成的历史标签序列得到社区划分结果。实验证明了FRAP方法得到的社区划分在测试集上有更好的表现效果。第二,面向用户群的情感倾向分析。从用户群的角度对情感进行多粒度的评判,首先提出基于单用户情感偏好的研究假设,并通过建立情感强度和扩散热度的一级指标验证关于用户情感的子假设,针对评论数据中喜悦等正向情感的显著偏向性以及情感扩散等规律展开分析;其次给出了面向用户群的情感倾向分析方法,通过社区划分的方法确立了联系紧密的用户群体,从历时和共时的角度对用户群的情感趋势变化进行分析,并基于用户群的规模、密度、分布等相关属性给出情感差异性的探讨并进行实验对比。"
1191,基于深度学习的不文明文本过滤方法研究,"随着互联网的普及,网络社交平台已经深深的融入了人们的生活。人们可以自由的在微博、贴吧、新闻等网络平台上发表自己的观点。由于网络平台的开放性,网络平台中出现了很多不文明的语言,对网络环境造成了极大的负面影响。为了构建和谐的网络语言环境,本文对不文明文本的过滤进行了相关研究。针对网络文本数量巨大和形式多变的特点,本文将深度学习技术应用于不文明文本的分类识别。对比传统的过滤方法在分类识别的精度上取得了一定的提高。本文的主要工作包括以下三个部分:第一,构建不文明文本数据集。目前对网络不文明文本的研究工作相对较少,没有标准的不文明文本数据集可供研究。针对数据匮乏的问题,本文爬取新浪微博、百度贴吧、腾讯新闻等相关网络平台的文本数据,制定数据筛选方法,通过人工标注的方式构建了一个不文明文本数据集。第二,构建不文明文本分类模型,区分不文明文本和正常文本。根据网络不文明文本的特点,引入卷积神经网络对不文明文本进行分类。针对不文明词汇在文本分词过程中精度不足的问题,本文构建了一种融合字粒度和词粒度特征提取的并行卷积神经网络模型(CW-CNN模型)。CW-CNN模型很好的解决了不文明词汇分词不准确导致的性能下降问题。CW-CNN模型对比词粒度特征输入的卷积神经网络模型,在精确率上提高了9.3%、召回率提高了9.9%、F1值提高了9.2%。第三,构建不文明文本不文明程度分析模型,区分不文明程度高的文本和不文明程度低的文本。卷积神经网络模型在不文明文本分类任务上确实具有较好的效果,但是其在特征提取的时候受到卷积核大小的影响,只能提取文本的局部特征,无法捕获长距离词语之间的特征相关性,在不文明文本的不文明程度分析任务上卷积神经网络存在一定的不足。针对其不足,本文结合卷积神经网络、循环神经网络和注意力机制构建了一种用于不文明文本不文明程度分析的深度学习模型(BiLSTM-CNN模型)。通过实验对比,在不文明文本不文明程度分析上,BiLSTM-CNN模型比CW-CNN模型在精确率、召回率和F1值上均提高了约3.4%。"
1192,基于GAN的不平衡数据增强算法及其应用研究,"随着机器学习和数据挖掘的快速发展,越来越多的研究通过学习挖掘海量数据中的规律和特征,来实现更加准确的预测和推断。对海量数据进行自动分类能够大大的提高人们获取信息的效率。传统的分类方法是建立在类分布大致平衡的假设基础上,然而,现实生活中的很多数据都是不平衡的,例如癌症检测、网络攻击识别等,因此,不平衡数据增强算法的研究课题,近两年来受到越来越多的关注。现有的解决不平衡数据分类问题的主流方法有采样和集成学习相结合的方法,例如SMOTEBoost、RUSBoost、EUSBoost等算法。以上算法在初始化时给每个样本赋予相同的权重,然后分别训练分类器,根据误差率的反馈不断地调整样本的权重,最后得到表现较好的分类器。这些算法在某些特定情况下会过度依赖原始数据集。针对上述问题,本文中提出了用生成式对抗网络进行数据增强以解决不平衡数据分类的问题。本文主要贡献如下:(1)针对训练数据集样本不足的情况,提出了基于GAN的不平衡数据增强算法,利用该算法生成图像组成新的数据集,然后提取图像特征并分类,实验证明,生成的图像在样本多样性上有较好的效果,并且通过该方法进行数据增强后,数据的分类结果有了较好的提升。(2)针对生成的数据中部分图像质量不高,从而影响最终分类结果的情况,提出了基于GAN的集成学习的不平衡数据增强算法。利用ENN和Tomek Link进行数据选择,提出一个基于投票的集成学习分类器模型。这个分类器将多个单学习分类器结合起来,得到一个统一的集成学习分类器模型。通过这个方法,能够获得更准确、稳定、鲁棒性更好的分类结果。论文上述的两个研究通过实验验证都达到了预期的目的,在四个数据集上进行实验,实验结果表明基于GAN的不平衡数据增强算法的分类精度有明显的提高,同时还能有效地合成逼真的图像。"
1193,结合注意力机制与长短期记忆网络的中文事件抽取方法研究,"互联网如今已经成为人们获取信息的主要途径之一,人们可以轻松快速地从互联网上获取各种各样的信息。但是,伴随着互联网上的信息呈指数式增长,人们置身于一个信息爆炸的环境中,每天面对铺天盖地的各种信息,甚至已经严重超出了人们的承受范围。因此,如何从海量的信息中找到人们真正关心的信息已成为当前亟待解决的一个问题,信息抽取由此而成为大家关注的重点。事件抽取技术研究是信息抽取研究领域中一个极为重要的子任务,也是当前信息抽取研究任务中的难点和热点之一。事件抽取的任务就是从自然语言描述的海量非结构化文本中抽取用户关心和感兴趣的事件(包括事件的类型和子类型以及事件所涉及的实体、时间及数值等元素),然后用结构化的形式保存和呈现,提供给用户浏览。抽取的事件还可以作为输入信息,提供给机器翻译、文本检索、知识图谱、推荐系统等多种应用,具有重要的实际应用价值和学术研究意义。本文主要面对中文事件抽取,研究中文事件的检测与分类以及中文事件的元素角色抽取。事件检测与分类任务其实是识别事件触发词的过程,这个过程分为两步:触发词识别和触发词分类。本文结合注意力机制和长短期记忆神经网络,提出了 ATT-BiLSTM算法,不依赖词性标注和实体识别,不需要人工设置特征,合二为一地进行事件检测与分类。该方法可以捕捉文本的局部信息和全局信息,通过在ACE 2005中文事件语料集上设置对比实验,相对于传统的模式匹配方法、机器学习方法以及一些现有的深度学习方法,ATT-BiLSTM算法在性能方面有了明显提升。事件元素角色抽取任务分为元素识别和元素角色分类两步。结合通过事件检测与分类获得的事件触发词信息,本文提出了一种结合注意力机制和双层BiLSTM的ATT-DBiLSTM算法,用来完成事件元素角色的抽取。通过引入触发词信息,弥补了事件元素角色抽取中结构特征过于松散的缺陷。通过在ACE2005中文事件语料集与其他现有方法进行对比,本文提出的ATT-DBiLSTM算法明显提高了事件元素角色抽取的性能。"
1194,基于集成学习的目标感知与应用,"数字信息洪流时代的来临使得目标感知的性能显得尤为重要。传统模型在面对不同表现形式的感知目标时,很难达到满足目标感知性能的目的。因此基于集成学习的感知方案由于其性能优越性在目标感知中愈发显示出其重要意义。本文针对数字图像设备感知,可见光图像内容感知和SAR图像信号感知,三种目标感知场景进行深入研究。从目标感知的应用性和集成学习算法在特定感知表现的适用性进行深入研究,对于三种表现形式的感知目标均提出基于集成学习的感知性能提升方案,本文的主要研究工作如下:(1)对于数字图像设备感知,本文提出基于多相机指纹集成的实时相机溯源决策方法。本文构建了由25部手机拍摄的100部视频集来建立该任务的数据库。对于视频流溯源任务,我们提出实时视频相机感知计算方式和基于集成策略的最终溯源方案。该集成方案显著提升了溯源的性能,对于安卓手机达到98.161%的溯源准确率,性能显著高于单模型。(2)对于可见光图像内容感知,本文提出多样性主动约束和被动约束的深度集成方案,分析了主动约束深度方案的参数不稳定性,以及被动约束深度集成方案的网络多样性生成原理。对于深度集成网络参数过大的问题,提出基于多样性被动约束的深度集成蒸馏方案。对于传统集成网络蒸馏方案训练次数过多的问题,本文提出惰性再生网络(Lazy Born Again Network),基于循环学习率的学习模式,利用训练过程中周期生成的历史网络快照蒸馏后面的训练过程,在单次训练中就能达到传统集成蒸馏网络的性能。(3)对于SAR图像信号感知,本文提出Flexible py-StackNet(FPS)集成学习框架。该框架将原始的Stacking思想拆解为学习层、数据流层和效果评估层,基于学习层实现了多模型的一站式学习方案、基于数据流层实现了灵活的特征组合和特征流向方案、基于效果评估层实现了实时评估和自适应的模型选择方案。基于该FPS框架的SAR图像信号感知方案取得了首届航天星图杯高分软件大赛SAR图像分类任务的冠军,验证了该框架的有效性。"
1195,基于生成对抗网络的人脸遮挡图像修复方法研究,"人脸识别技术近年来得到了显著的发展。但识别有部分遮挡的人脸对于现存的人脸识别技术依旧是一个挑战。在实际应用中,对于有遮挡的人脸图像修复的需求越来越多,如监控和公共安全领域。为了能更好的识别人脸图像,提高识别效率,需要在识别前对有遮挡的人脸图像进行修复还原,因为被遮挡部分通常包含有影响整个面部变化的关键特征信息(例如鼻子、眼睛、嘴巴等)。人脸图像的修复是图像复原领域研究中的一个重要课题。图像复原作为一种常见的图像编辑操作,旨在用合理的内容填充图像中的缺失区域。生成的内容既需要与原始内容保持相似,也要完全符合整体图像,使得复原的图像看上去是真实的。在过去的几十年里,由于其固有的模糊性和自然图像的复杂性,图像复原(图像修复)一直是计算机视觉和图像图形界具有挑战性的研究热点。本文结合传统的基于结构和纹理的图像修复、基于深度学习的图像修复和生成对抗网络的相关知识,分析了人脸的关键点和结构特征信息,提出了一种改进的边界均衡生成对抗网络(BEGAN)模型对遮挡的人脸图像进行生成修复,首先在CelebA数据集上训练BEGAN生成对抗网络,接着将遮挡的人脸图像输入BEGAN中,尝试将遮挡部分进行生成修复;其次为了使得生成的图像与原脸图像更相似和更自然,算法中定义了两个判别网络:全局的结构判别网络负责优化人脸修复图像全局的边缘结构信息和特征信息以保证修复的人脸图像结果符合视觉认知;而局部的纹理判别网络则负责优化所生成的遮挡区域与原脸图像的其它面部内容相似(例如皮肤纹理、色泽等),使生成的人脸图像更加自然连贯。最后综合全局和局部两个判别网络的损失函数,利用反向传播算法,把待修复的人脸图像映射到较小的潜在空间,将映射后的矢量数据输入到BEGAN中生成最佳的人脸修复图像,从而实现人脸遮挡图像的生成修复。本文在CelebA人脸图像数据集中进行了大量的实验,并对实验结果进行了分析对比,主要分为主观评价和客观评价。在主观评价上,主要是让行内和行外人员在视觉感官上对人脸图像修复效果进行评分;在客观评价上,将本文模型与PatchMatch模型和Context Encoder模型做对比实验,使用峰值信噪比和结构相似性指数来比较模型修复效果的优劣。结果表明,本模型能对遮挡的人脸图像实现良好的修复,并优于进行对比实验的两个模型。"
1196,基于BiGRU-CapsNet模型的文本分类研究,"随着科学技术水平不断提高,互联网得到迅速发展,以互联网为纽带带动了包括商业贸易、服务业、娱乐休闲、公益等各个行业迅速发展,人们的生活方式、工作方式也产生了巨大的改变。文本作为网络信息的主要承载形式,数据量飞速增长,涉及的领域也更加广泛,例如产生了大量电影评论、新闻信息、论坛交流信息、微博评论、商品评论等涉及多个产业领域的网络文本信息。这些文本信息数据量巨大,包含丰富的信息。将这些文本进行自动分类后可以了解发布信息者的真正意图,有助于经济的发展、各个行业带头企业的方向导航、政府的决策完善。近年来,深度学习(Deep Learning)作为人工智能领域最重要的进展,在诸多领域都有着惊人的表现。大量研究表明,相比于传统的机器学习算法,深度学习中的许多网络模型都能够获得更加出色的性能。基于BiGRU模型的文本分类是目前最主流的文本分类方法,在分类效果上有不错的表现。本文尝试在BiGRU模型的基础上,采用更加适合文本分类的深度学习算法进行文本分类模型搭建,主要工作包括以下几个方面:首先对文本分类的一般流程进行了概述,包括文本预处理、文本表示、文本特征提取、文本分类训练、文本分类以及性能评估。通过对各个步骤常用方法的研究以及文本分类本身特点的分析,进一步阐述了文本分类传统方法的诸多问题与难点,为后文分类方法的选取和分类网络模型的设计奠定了基础。其次阐述了 BiGRU网络与CapsNet网络的原理以及在文本分类领域的应用。为提高BiGRU网络模型文本分类性能,文中深入研究了 CapsNet的神经胶囊工作流程与动态路由机制,分别分析了 BiGRU网络和CapsNet网络在文本分类中的优势与不足,将BiGRU网络的双向循环机制与CapsNet网络的神经胶囊与动态路由机制结合起来,构建基于BiGRU-CapsNet的文本分类模型,对文本进行分类。最后在keras框架平台上搭建BiGRU-CapsNet模型对文本进行分类,并讨论影响BiGRU-CapsNet文本分类模型性能的各种因素。从神经网络迭代次数、截取文本的长度、激活函数的选择三个方面分别设置对比实验,对实验结果进行分析,得到最优的参数与函数设置。在此基础上利用该模型对其他数据集进行分类训练,验证模型的适用性,并将相同数据集分别在BiGRU文本分类模型与BiGRU-CapsNet文本分类模型上进行实验并对比分析。实验结果表明,相较于BiGRU文本分类模型,BiGRU-CapsNet文本分类模型能更有效的对文本进行分类,分类准确率更高,而且具有更好的适用性。"
1197,基于多元方法的游客情感分类挖掘技术研究,"随着旅游业和互联网的快速发展,“互联网+旅游”不但为老百姓旅游带来了便捷和实惠,而且由于游客在旅游中大量使用社交媒体(自媒体)分享旅游体验,社交媒体以惊人的速度产生着旅游大数据。其中,旅游文本大数据以其方便、简单、快捷和低门槛的特点为游客进行情感表达和信息交流提供了极大便利,在旅游大数据中占有了越来越重要的位置,已经成为旅游大数据的主要来源之一。这些文本数据中隐含了丰富的情感信息,挖掘这些文本信息,有助于感知游客的情感状态,获取游客对旅游产品的观点、态度,对旅游规划、旅游产品开发以及旅游营销等旅游活动有着非常重要的商业价值和社会意义。基于旅游大数据的游客情感研究已成为旅游研究的热点,而情感分类技术是构建游客情感评价模型的基础,技术手段和情感分类方法的先进与否直接影响着游客情感评价模型构建的效果。本文在大数据理论和情感理论的指导下,以文本大数据为数据源,以游客情感分类为研究对象,在全面梳理国内外游客情感研究、情感分析研究、情感分类技术研究等相关成果的基础上,利用人工智能中的逻辑/算法编程方法、机器学习方法、深度学习方法对旅游文本大数据进行挖掘,探索最佳的基于文本大数据的游客情感分类技术。主要研究内容和结论如下:(1)在对基于情感词典的游客情感分类方法全面梳理的基础上,该方法的技术范式为:构建情感词典――分词――设计情感计算规则――计算情感值。此方法的核心是构建情感词典和设计情感计算规则。思想简单,容易实现,适用语料范围广是其优点,其缺点有:词典匹配由于自然语言语义表达的丰富性使其精确度难以提高;对词典的依赖致使人工构建高质量情感词典的代价高昂;设计情感计算规则取决于人工经验,推广能力较差。(2)对现有游客情感研究中使用机器学习方法的进行归纳和分析,总结出此方法的技术范式为:分词――文本表示――特征提取与选择――选择机器学习分类模型并训练模型――计算情感值。此方法使用统计学方式抽取文本中的特征项,其非线性特征相对于情感词典方法的线性特征提高了情感分类的可靠性。基于机器学习的情感分类过程较易实现且计算量小,但受训练数据规模和专业性及文本特征选择的影响,在一定程度上限制其在复杂问题上的泛化能力。(3)探索性地将深度学习技术应用于游客情感分类研究,通过word2vec实现高维向量表示词语,构建了基于word2vec的RNN深度学习情感分类模型。通过实验对比,基于深度学习技术的游客情感分类也能取得良好的效果,准确率达到了85%以上。此方法使用word2vec在产生词向量时可以自动发现特征,同时降低特征维度,很好的解决了词序信息和语义特征问题。训练多领域的文本语料易于移植,实用性强且泛化能力好,更适用于大数据时代游客情感分类研究。然而,这种方法对数据的需求量更大,缺乏大规模旅游相关训练数据集成为使用深度学习开展游客情感分类研究的瓶颈。(4)在具体游客情感分类实践应用中,技术手段的使用不单纯要考虑其准确程度、误差、先进程度等情况,还应该考虑其运行的速度(时间复杂度)、资源消耗程度(空间复杂度)、实施性、稳定性是否可接受。本文的创新点有两个:一是对现有游客情感研究中使用的情感词典方法及机器学习方法进行归纳和分析,总结出这两种方法的通用技术范式,为后续开展相关研究及企业应用提供参考帮助;二是探索性地将深度学习技术应用于游客情感分类中,并取得了良好的效果,为大数据背景下游客情感分类研究提供了一个新的思路方法,具有技术引导意义。"
1198,基于N-Gram的SQL注入检测研究,"随着互联网的飞速发展,Web安全也变得愈发重要,注入类漏洞在OWASP(Open Web Application Security Project)发布的最严重的前10名Web安全漏洞中排名第一,SQL注入攻击是目前Web面临的主要安全威胁。SQL注入利用Web应用程序,把恶意的SQL注入语句传递到后台数据库,使之不能按照设计者的意图去执行SQL语句。在Web应用程序中添加一道检测和阻截SQL注入攻击的防御系统是Web安全的重要保障,虽然国内外已提出多种SQL注入检测方法,但大部分检测方法只考虑了个别条件下的SQL注入攻击检测,无法检测多种SQL注入攻击。因此,针对SQL注入隐蔽性非常高、种类繁多、普通网络防火墙难以预防的特点,本研究将提出一种基于N-Gram的SQL注入检测方法,主要工作如下:1.基于N-Gram提出一种特征提取方案,结合自然语言处理中N-Gram模型假设某个词出现的概率只与该词前面N-1个词相关的特点,把SQL语句中连续的N个词看作一个整体进行特征提取,使原本由单个单词构成的特征子序列变为了由若干个单词构成。接着从所有特征子序列中根据出现频次和信息增益挑选出对分类影响最大的一些特征子序列,根据这些特征子序列将SQL语句转换成固定维数的特征向量。2.基于抽象语法树提出一种特征提取方案,在对SQL语句进行N-Gram特征提取的同时,把该语句转换成抽象语法树,然后将该树的所有深度为2的子树所对应的文字序列作为特征子序列。最后把这些特征子序列与N-Gram特征子序列一起进行特征选择,确定特征向量。3.基于卡方检验和神经网络提出一种SQL注入检测方案,在前两部分将语料库中的SQL语句转换成特征向量的基础上,先计算安全SQL语句的平均特征向量,然后计算各SQL语句与平均特征向量距离确定距离的阈值,接着根据待测SQL语句与平均特征向量的距离与阈值进行对比以判断待测SQL语句的安全性。此外,本文提出以特征子序列的顺序和信息增益为依据改变不同特征子序列权重的方法改进距离,改变原有的距离计算公式。最后,本文通过BP神经网络将上述两种改进距离和原卡方距离作为输入,与安全SQL语句的平均特征向量的距离为输出,把三种距离合而为一。实验结果表明,与直接使用单词构成的特征向量相比,本文所提方法能有效提高检测率、降低误报率。"
1199,基于TF-IDF和BiGRU神经网络的SQL注入攻击检测研究,"互联网技术的高速发展,让Web应用程序逐渐成为互联网用户日常生活中非常重要的一部分。Web应用程序常常受到攻击,因此,用户在享受Web应用程序服务的同时,也面临着个人隐私信息泄露、财产遭受损失的风险。其中SQL注入攻击(Structured Query Language Injection Attack)是Web安全中最常见,同时也是对用户危害程度最大的攻击手段之一。因此,如何对SQL注入攻击进行准确有效地检测,是Web应用发展的重要前提,也是Web安全领域研究中重要的课题。目前,对于SQL注入攻击的主要检测方案包括用户输入过滤、解析树分析、指令集随机化以及参数查询等,但是这些方案存在对Web应用程序源代码的改动较大、开发周期长、部署难度高等问题。针对上述问题,本文对SQL注入攻击进行深入研究,提出一种工作在HTTP应用层,在不修改后台应用程序情况下的SQL注入检测方法。该方法通过对输入的SQL语句进行检测,将其分为正常SQL语句和SQL注入攻击语句两类。以此判断用户输入是否存在SQL注入攻击。本文的主要研究工作和成果如下:(1)针对词频-逆文本频率(Term Frequency-Inverse Document Frequency，TF-IDF)算法忽略特征词在SQL语句中位置与重要性的关系的不足,提出一种基于改进TF-IDF算法的SQL注入攻击检测方法。改进方案通过增加特征词的位置权重来修正TF-IDF。其中特征词的位置关系通过SQL语句的抽象语法树体现。并且在利用改进TF-IDF算法计算出SQL语句中特征词的权重后,按照降序排序,提取出满足任务要求的前K个特征词,达到对特征空间降维的目的,避免维数灾难的发生。其中,在SQL语句分词处理上,保留了 SQL注入攻击中容易出现的敏感符号,进一步保证了 SQL注入攻击检测特征词选取的完备性。通过与其他方法进行实验对比,结果表明基于改进TF-IDF算法的SQL注入攻击检测方法在数据集上的准确率,召回率,F1分数均提高了 10%以上。(2)提出一种基于AT-BiGRU-AdaBoost模型的SQL注入攻击检测方法。该方法采用双向门控循环单元(Bidirectional Gated Recurrent Unit,BiGRU)神经网络模型提取特征。另外,在BiGRU对SQL语句进行特征提取的同时,加入Attention机制加强对SQL语句的理解,提高重要部分的权重,降低非重要部分的权重,解决噪声的干扰问题。并且针对Softmax作为BiGRU神经网络分类器泛化能力不足的问题,在BiGRU神经网络提取特征后使用AdaBoost进行训练预测。AdaBoost的基分类器具有低方差高偏差等优势,使得集成模型更具稳定性,在一定程度上弥补了 Softmax作为BiGRU神经网络分类器泛化能力不足的问题。最后实验表明,在SQL注入攻击检测中,AT-BiGRU-AdaBoost模型相比BiGRU模型,在数据集上准确率和F1分数上均提高了 1.2%以上。"
1200,稀疏资源条件下的藏汉机器翻译研究,"机器翻译是指运用特定的计算机程序将一种自然语言转换为另一种自然语言的过程。自上世纪50年代提出机器翻译的思想以来,机器翻译领域的研究经历了从规则到统计再到深度学习的理论和技术的多次迭代,是整个人工智能领域中最为活跃的研究方向,取得了巨大的进展,并且在未来有广阔的发展前景。藏汉机器翻译研究作为藏语自然语言处理领域中主要的课题之一,一直是我国少数民族语言信息化研究的重要工作。本文着眼于藏汉机器翻译研究中的数据稀疏问题,在Transformer神经网络翻译模型基础上,运用百万句子单语数据大规模迭代式回译策略和译文自动筛选机制,使最终的模型比基准模型有4个BLEU值的提升,证实了回译方法的有效性。除此之外,论文还实现了基于短语的统计翻译模型和三类基于主流神经网络构架的藏汉机器翻译基准模型,并对面向神经网络藏汉机器翻译的分词方法进行了研究分析。本篇论文的主要内容包括:・研究和分析了面向神经网络的藏汉机器翻译的分词方法,以实验方式证实了基于字节对编码的子词分词模型有最好的表现;・实现了用于辨别藏汉句对翻译等效性的端对端分类器;・结合翻译等效性的分类器和大规模对偶迭代式的回译策略,实现了藏汉翻译在稀疏资源条件下使用单语数据提升神经网络机器翻译性能的有效模型。"
1201,隐朴素贝叶斯在情感分类中的应用研究,"随着互联网的迅速发展,人们对互联网的热爱也日渐增强。在互联网诞生与发展的过程中伴随着各种平台产生,用户也通过互联网平台来抒发自己的内心想法与意见。随着用户越来越多,在这些数据当中涉及了社会、商品等各种信息,同时这些信息也形成了庞大的数据库。在数据库形成的过程中伴随着也带来了自然语言处理领域的舆情问题。因此,需要对这些数据实施处理与监测。在自然语言处理领域研究的学者们为了实现这一目标,近些年来不断的对其探索。为了对庞大的信息进行情感的研究,此领域的研究学者们采用词典、统计、机器学习的方法对其处理,最终实现自动化文本处理方法。在之前学者们的研究成果基础之上,本文采用了改进的TF-IDF与隐朴素贝叶斯的结合对文本情感分类,与改进的TF-IDF与朴素贝叶斯的结合以及特征加权融合的朴素贝叶斯情感分类算法进行了比较。然后对情感词典的扩充进行了研究,采用了基word2vec方法对词典进行扩充,然后使用隐朴素贝叶斯作为分类器进行情感分类。本文使用了书籍、电脑、酒店评论数据作为实验研究的对象,通过对数据的分析与处理进行了情感分类与词典扩展的相关工作。本文的主要研究内容如下:在本文的情感分类相关技术的研究下,对于文本情感分类的流程,使用模型融合的办法。对文本预处理,使用Python中jieba分词工具进行分词,去除停用词等等。对特征提取和情感分类模型进行了研究,其中包括互信息、CHI统计、TF-IDF等,详细的研究了改进的TF-IDF算法特征提取过程。情感分类算法研究了隐朴素贝叶斯的分类过程的使用,分析了此情感分类算法的优点。基于改进的TF-IDF与隐朴素贝叶斯算法结合的情感分类。使用改进的TF-IDF算法对文本特征提取,把文本改变成向量化,使用隐朴素贝叶斯分类算法作为分类器对文本情感分类。使用评论数据进行试验,并使用评价指标对试验结果进行分析,与上述两种方法进行对比,试验结果优于其他两种方法。情感词典的扩充。在自然语言处理领域的情感分类或者情感分析的方法都包含着基于情感词典。目前,具有代表性的情感词典包括:知网情感词典(Hownet)、台湾大学词典(NTUSD)以及大连理工大学中文情感词汇本体库(无辅助情感分类)等等。但是,网络中的新词可能会被忽略,本文使用了word2vec算法进行词典的扩充,对文本的内容与词典相匹配选出情感词,对网络新词使用word2vec的方法进计算与词语之间的关系,最后使用隐朴素贝叶斯作为分类器对文本情感分类,实验证明加入了情感词典使情感分类效果更好。"
1202,基于谱特征分析和卡方检验的特征选择方法研究,"维度降低是处理大型高维度数据必须面临的一个重要问题。特征选择就是在大型数据集上选择原始特征的一个子集,预处理数据以获得一组较小的有代表性的特征集合。从有无类标签参与特征选择的角度,将特征选择方法分为监督型特征选择、无监督特征选择和半监督特征选择。由于无监督特征选择方法只考虑了特征之间的相关性,而忽略了特征与类别之间的相关性,导致了无监督特征选择获得的特征子集的分类能力较弱,比如基于谱图理论的谱特征选择。而一些监督特征选择方法只考虑了特征与分类类别之间的相关性,不能很好的考虑到特征之间的冗余,造成了特征子集中有很多特征是相互关联的,影响了特征的独立性以及分类的准确性。因此本文提出了一种基于谱特征分析和卡方检验的特征选择方法。使用谱分析评价特征之间的相关性,使用卡方检验评价特征与类别标签之间的相关性。监督学习部分的卡方检验通过观察值和理论值之间的偏差来判断理论值的正确率,特征选择时应该更优先选择卡方值更高的特征。无监督学习部分的谱聚类方法首先需要计算给定的样本数据集中每对样本点之间的相似性,来得到一个相似性矩阵,进而构建出一个邻接图,最后通过图的归一化切分(Normalized Cut)得到特征的评价准则,通过这一评价指标来进行特征选择。基于谱特征分析和卡方检验的特征选择方法(SpeChi)结合监督学习和无监督学习的特点,计算过程中卡方检验使用已标记数据,谱特征分析使用未标记数据进行特征选择,通过特征评分进行特征选择,弥补了谱特征分析没有考虑类别相关性的不足。最终选择出特征之间低冗余且特征与类别之间高相关性的特征子集。验证实验使用了4种不同分类器,和8个公开数据集,在与其他4种特征选择方法进行对比后表明:该算法提高了特征集合的分类准确率,并且能提前获得较好的分类效果。最后这里还研究SpeChi方法中不同参数设置对特征选择结果的影响,实验表明,设置参数为0.4、0.5、0.6的分类准确率要优于参数为0或者1。设置不同的参数值时,由于特征选择所考虑到两种相关性所占的权重不同,因此实验结果略有不同。"
1203,基于AdaBoost和ELM的语音情感识别研究,"情感是人类的本能,因为情感我们得以在工作和生活中更好地做出行为决策。同时,为了更好地实现人机交互,国内外研究学者把情感融入其中进行识别。现如今情感识别的类别主要有:人脸情感识别、语音情感识别、生理模式情感识别等,这些情感识别处理技术促进人机相互协作从而做出正确的行为决策以应用于工作生活中的各个领域。由于语音信号包含说话人多种混合信息,较具代表性,近年来,语音情感识别越来越受到人们的广泛关注,它是实现人机交互、在线交流等的重要途径。现如今深度学习已贯穿人工智能的各个领域,在语音情感识别上正发挥着如火如荼的作用,而机器学习算法的单分类器在分类效果上则表现出了劣势。然而实验时我们还需要具体问题具体分析,在处理小样本特征数据时,单隐层的神经网络模型较深度学习在分类测试的时间上有较好地体现。同时为了解决单一的弱分类器在语音情感识别中数据过拟合导致分类正确率偏低的问题,本文提出了基于AdaBoost和ELM(超限学习机)结合的提升分类模型。实验中分别提取三种不同的语音情感特征,然后分别将这些样本特征数据进行归一化、降维后放入到本文涉及到的情感分类模型中。与相关工作进行对比来说明SVM(支持向量机)和ELM的分类性能,然后又对这两个单分类器分类识别的运行时间进行了比对;继而通过设置用户依赖模型和用户混合模型来对ELM、本文提出的AdaBoost和ELM相结合的语音情感分类模型分别进行实验对分类性能进行对比分析。实验结果表明,本文提出的分类模型取得了较好的实验效果。在CASIA汉语情感语料库上,ELM的分类性能不论是在分类正确率还是分类时间上都要要优于SVM,并且本文提出AdaBoost和ELM相结合的分类模型的实验效果较用单一的ELM分类效果有明显提高,正确率提高6～7%;继而在2017年多模态情感识别竞赛数据库(MEC 2017)和IEMOCAP语料库上分别进行验证实验,在多个数据库上验证本文所提出算法的有效性和鲁棒性。实验结果显示在MEC 2017上的分类正确率比baseline高出了 7.48%;在IEMOCAP上的分类结果为67.50%,比先前工作者提出的RNN-ELM模型的分类正确率提高了 3.61%。"
1204,基于知识图谱的教学资源推荐方法研究,"教育信息化的发展使学习者的学习方式从传统的课堂学习转变成在线学习。在教育大数据的发展下,教学资源呈现出资源海量、信息过载且质量良莠不齐的特征,学习者在这种环境下面临着“信息过载”和“知识迷航”的问题。个性化推荐系统是解决“信息过载”的一种有效方法。推荐系统根据学习者的历史行为挖掘学习者潜在的兴趣偏好,计算学习者与资源的相似度,向学习者推荐其可能感兴趣的教学资源。在目前的个性化教学资源推荐方法的研究中,研究者着重于学习者特征建模和资源属性建模,通过计算学习者与资源之间的相似度进行推荐。这类推荐算法更倾向于向学习者推荐与其偏好相似的资源,而没有考虑到教学资源之间的逻辑关系。学习者的学习过程有着循序渐进、知识由浅到深的特点,教学资源中包含的知识点之间有着丰富的逻辑关系,因此考虑资源包含的知识点间的关系来进行个性化资源推荐是非常有必要的。基于上述思考,本文构建了一个机器学习领域小范围知识图谱,并在此基础上提出了一种融合知识连接度和学习者兴趣的基于知识图谱的教学资源推荐算法。本文的主要工作如下:(1)使用Python语言编写网络爬虫爬取了豆瓣图书上标签为“机器学习”的所有书籍信息以及与其相关的交互行为数据作为本研究的数据集;(2)使用数据集中的中文目录文本数据构建机器学习领域小范围知识图谱。在知识图谱的构建过程中,我们首先使用词频分析和基于神经网络模型(BILSTM+CRF)结合人工筛选的方式完成了对知识面实体和知识点实体的实体识别工作。其次,根据目录文本的层级关系,采用基于模板的方式对实体进行了关系抽取。最后,我们使用neo4j图数据库将获取的实体与关系信息进行了存储,完成了知识图谱的构建。(3)在构建好的知识图谱的基础上,我们提出了一种融合学习者兴趣和知识连接度的协同过滤推荐算法。在该算法的模型设计中,详细定义了知识连接度和学习者兴趣并给出了详细的推荐流程。针对提出的推荐算法中存在的用户“冷启动”问题,我们给出了一种为初学者(新用户)推荐教学资源的推荐策略。(4)为了验证提出的推荐算法的有效性,我们采用离线实验对推荐算法进行测评并对实验结果进行了分析。实验结果表明,相比于传统的userCF和itemCF,本文提出的算法在准确率、召回率、Fl-score等指标上都有所提升。本文的创新点在于:(1)构建了机器学习领域小范围知识图谱。利用该知识图谱可以为学习者展示知识点间的关系以及相关学习路径,缓解“知识迷航”的问题;(2)提出了一个融合学习者兴趣和知识连接度的协同过滤推荐算法。该算法不仅考虑了学习者兴趣,更考虑了学习者的认知水平以及知识点间的逻辑关系,产生的推荐结果更加符合学习者的学习需求;(3)提出的推荐方法不受限于新资源的交互行为,在一定程度上可以缓解推荐系统中的资源“冷启动”问题。"
1205,神经网络中的隐私保护研究,"随着人工智能的不断发展,神经网络已经在人脸识别,医疗诊断等领域被广泛使用,越来越受人关注。神经网络的训练和预测都需要数据的支持,然而,数据总是不可避免的包含敏感、机密的信息,因此,在神经网络给我们的生活带来便利的同时,也带来了隐私泄露的隐患,如何利用神经网络同时又不会泄露隐私信息已经成为一个重要的研究领域。本论文针对几类典型的神经网络结构:感知器、卷积神经网络进行隐私保护的研究。感知器是一种简单的神经网络,它虽然结构简单,但是可以有效地处理复杂的二分类问题,要实现神经网络的隐私保护,首先要考虑的就是如何实现神经网络基本单元――感知器的隐私保护。针对感知器的训练,本文提出一个基于加同态加密的隐私保护训练协议,该协议可以保证数据提供者在提供训练数据给训练机构时训练数据不会泄露。针对感知器的预测,提出了一个云辅助的基于加同态加密的隐私保护预测协议,该协议可以有效保护预测过程中输入特征和模型参数的隐私同时借助云平台的强大计算和存储能力有效降低用户管理和处理数据的负担。最终,本文用真实数据集验证了本文感知器隐私保护协议的准确性和效率。卷积神经网络是一种擅长分析视觉图像,在图像和视频识别、图像分类和自然语言处理等方面有着广泛的应用的一种特殊神经网络,与其他图片分类算法相比,卷积神经网络不需要对图像进行复杂的预处理,因此卷积神经网络在实际中得到了更加广泛的应用。目前已经存在的卷积神经网络的隐私保护方案很多都采用全同态加密技术来实现,而且都忽略了对网络最后一层的输出的保护。本文提出了一个基于加同态加密的卷积神经网络隐私保护协议,本文的协议可以保护用户的隐私输入,服务器的模型参数,以及计算的中间值。最终,本文利用真实数据集验证了本文协议的正确性和可用性。"
1206,基于应用分类的安卓恶意应用检测模型,"安卓操作系统在社会智能化发展过程中扮演着重要角色,同时基于该系统的恶意攻击软件已对用户隐私和系统安全构成了严重威胁。360互联网安全中心2018年累计监测安卓移动端恶意软件感染量约为1.1亿人次;卡巴斯基实验室在2017年检测并截获总计5,730,916个安卓恶意应用安装包。为提高安卓系统的稳定性和安全性,维护移动应用市场的绿色健康发展,各大互联网安全公司及科研单位仍在不懈努力。权限管理机制在安卓安全模型中扮演重要角色,应用通过权限请求申请所需的系统软硬件及用户数据等资源来实现个性化功能。本文通过对安卓安全模型设计的分析和恶意应用检测课题研究近况的全面调研,提出了基于应用分类的安卓恶意应用检测模型,主要包含应用分类模块和基于类别的恶意性检测模块,通过两步走来检测未知应用恶意性。分类模块以K-means算法为核心,通过计算训练集内可信应用权限向量间相似度将可信应用聚为32个类并获取聚类模型,然后将恶意应用权限向量集输入该模型进行分类;检测模块,通过卡方检验来提取每个类中的敏感权限作为检测算法的输入特征,训练检测模型。实验数据包含13,588个恶意应用和13,382个可信应用,最终实验结果表明该检测模型的检测准确率可达94.02%。"
1207,回归学习问题中的隐私保护方案研究,"为了确保模型的精确度,传统机器学习算法需要收集大量的原始数据进行模型训练.一方面,人们享受着高精度模型给生活带来的便利,例如图像处理,文字识别等,另一方面,人们也面临着数据的隐私泄漏问题,引起了人们的广泛关注.如何保证在不泄露用户隐私的情况下安全地进行回归模型训练,或根据已有模型进行安全预测成为当前机器学习中亟需解决的问题.针对如何不泄露用户隐私的情况下进行安全回归模型训练的回归学习问题,本文提出了基于安全两方计算的隐私保护回归模型,该模型主要基于信息论意义下完备的加法秘密共享方案和安全两方计算协议.在这种秘密共享情形下,该模型通过使用一个辅助服务器,由两个非共谋半诚实的主计算服务器进行主要的回归学习的计算过程.全文的主要思路为:首先通过观察回归学习问题中的常规实现算法,给出对该算法进行隐私实现时所涉及基本运算的两方计算协议,例如秘密共享形式的加法和乘法运算等;其次,考虑到协议中不可避免会出现实数,给出此情形下安全实现两数比较的协议等;最后,结合以上协议给出回归学习问题中常规算法的隐私实现形式,并进行实验对比.实验表明,在该隐私保护模型下的隐私保护协议能安全地实现常规算法的所有步骤,给出一致的计算结果,且总体的方案耗时在可接受范围之内.同时实现了保护用户原始数据的隐私,也实现了保护模型的隐私,对研究其他机器学习算法的隐私实现具有一定的借鉴意义."
1208,面向不平衡电商评论文本的改进朴素贝叶斯分类模型研究,"文本挖掘是数据挖掘中的重要研究方向之一,本文选取较热门的电商评论数据情感分类作为应用场景。随着海量的订单数量每天产生巨大好评或差评数据,手动的人工分类会耗费大量的人力物力,若此时应用文本情感分类的方法,则会达到省时省力的效果。在文本分类领域中,朴素贝叶斯方法是常用的分类模型,有着高效且快速的特点。但针对电商商品的评论数据,其有着较严重的样本不平衡特点,即用户给予好评的样本数量远大于用户给予差评的样本数量,若不进行适当的处理,分类的结果会向多数类倾斜,少数类样本很难被识别处理,会严重影响分类模型的效果。本文的研究目的便是针对电商商品评论数据具有样本不平衡的特点,对朴素贝叶斯算法进行改进,能有效提高模型在不平衡样本下的分类准确率。为提高不平衡电商评论数据的分类成功率,本文主要从样本空间、模型算法、集成模型三个方面开展工作:(1)对于不平衡数据的样本空间,若不加以改造,那么分类的结果会较容易偏向类别较多的样本,本文则结合欠采样方法以及基于word2vec的词移距离进行判断,从多数类样本中采用欠采样方法选择出词移距离与待预测样本较近的若干个样本,从而构造出新的平衡训练样本。(2)在对平衡样本构造的前提下,会损失一定的样本,为了给分类模型提供更多样本中的信息,再进一步考虑赋予样本权重,因此,本文提出了基于WMD文本加权的多项式朴素贝叶斯模型。在(1)的基础上,根据所计算的词移距离对训练样本进行样本加权处理,并据此对传统的多项式朴素贝叶斯模型进行改进,使得模型能对样本信息进行充分地训练。(3)为了更好提高模型的预测能力,考虑模型组合的方法,在本文提出的改进朴素贝叶斯算法的基础上,进行模型的集成,反复迭代训练多个弱分类模型,对文本权重进行优化,最后形成一个强分类模型,相对于单个分类模型,经过集成后的模型具有更好的预测能力。"
1209,基于统计与机器学习的棋盘格角点检测算法研究,"棋盘格角点的自动检测是相机标定的关键步骤,并且广泛应用于曲面重建、视觉跟踪、姿态估计等任务。大部分棋盘格角点检测算法需要人工选择合适的阈值,以快速地排除错点。频繁的人工调整阈值将干扰棋盘格角点的自动检测,从而限制了棋盘格角点的使用范围。为了减少棋盘格角点检测中的人工干预,满足角点自动检测的实时性要求,本文结合统计学和机器学习算法,提出了一种分步式棋盘格角点检测算法。本论文的主要工作包括:(1)分析了棋盘格角点处圆环采样序列的频谱特性,定义了一种刻画圆环采样频谱特性的棋盘格角点响应函数,使得每个像素响应值能表征棋盘格角点的属性,提出了基于角点响应值空间分布特性粗选棋盘格角点的方法。(2)基于高斯分布假设,导出了反映图像噪声棋盘格角点响应值的累积分布函数,建立了基于该分布函数自动确定用于排除噪声点的阈值的方法,提出了基于超级像素的图像噪声估计方法。(3)分析了不同情况下圆环采样中心与采样序列灰度值差异的分布特点,结合棋盘格角点响应值,提出了一种棋盘格角点描述子,给出了利用该描述子实现线条中心点快速排除的方法。(4)通过图像角点检测实验,验证了提出的理论和方法的正确性,结果表明,本文提出的算法对不同的图像对比度、噪声级和透视畸变有较好的鲁棒性,并且可以高效地去掉大部分错点,实现至少99.2%的查全率和97.8%的查准率。"
1210,面向群体用户的情感趋势预测方法研究,"在线购物已成为最主流的消费方式之一,用户在电商平台发表的评论往往带有对商品的购买体验和情感观点。然而群体用户对商品评论的动态性导致情感趋势随时间发生变化,如何高效挖掘评论中潜在的情感观点,分析和预测群体用户对商品的真实情感倾向,从而辅助商家精准地定位用户需求,是促进电子商务发展的关键问题。现有情感趋势预测方法主要从单一用户角度获取情感趋势,难以深层次挖掘群体用户评论对商品的情感趋势变化,导致预测准确率低。本文从特征提取、情感分析、时序情感趋势预测三方面入手,提出一种面向群体用户的情感趋势预测方法。其主要研究工作包括以下几个方面:(1)为提高特征词提取精准度,针对传统TF-IDF算法存在的过度依赖词频计算特征词权重问题,提出一种基于多特征因素相融合的文本特征提取方法。首先,利用传统算法计算特征词权重;其次引入特征词位置和词性因子对TF-IDF算法权重进行重新分配和排序;最后融合三个结果计算更新特征词的权重。实验表明,优化后的TF-IDF算法的特征词提取精确度相对提高了1.6%。(2)为改善情感分类准确率较低问题,设计了一种基于多维情感特征向量的多层感知器(MLP)网络模型。首先,结合优化TF-IDF算法挖掘群体用户评论并获取多维情感特征;其次融合多层感知器(MLP)模型进行情感分析,以此获取群体用户情感倾向值;最后引入支持向量机(SVM)、决策树(DT)及朴素贝叶斯(NB)模型验证对比。实验表明所提出情感分类模型的准确率平均相对提高了4.9%,且F值提高了1.7%,能够为情感趋势预测阶段提供较好的基础依据。(3)在时序情感趋势预测过程,将上一阶段得到的群体用户情感倾向值与对应评论时间进行融合,构建群体用户时序情感倾向序列,并提出一种基于多层长短时记忆网络(ML-LSTM)模型的情感趋势预测方法。在大规模真实数据集上的实验效果表明,相比于现有的自回归(AR)模型、长短时记忆网络(LSTM)模型的平均MSE值分别降低了0.5%和0.02%,且ML-LSTM模型分别优于AR模型、LSTM模型的百分比达到了82.9%和13.9%,能够取得更加精准的预测结果。"
1211,面向移动设备的图像分类任务功耗优化研究,"近年来,深度学习在图像识别领域迅猛发展,针对不同应用需求的卷积神经网络(Convolutional Neural Network,CNN)层出不穷。随着移动系统性能的迅速提升,移动用户期望更低响应延迟的图像识别应用。而由于网络状态的不稳定性及网络带宽的限制,简单的将CNN模型部署在云端的计算模式无法保证移动用户体验期望,同时,受限于移动端有限的资源,移动设备也无法满足CNN模型对计算、存储及电量资源的需求。因此,亟须设计一种新的计算模式,使得基于卷积神经网络模型的图像分类任务能够满足用户对快速响应、低能耗及高准确率的期望。本文从CNN模型的能效和分类特点出发,对CNN模型在移动端的部署及图像分类任务的调度进行研究,主要工作如下:1.针对不稳定的网络状态环境导致深度学习模型推理延迟过高的问题,本文面向智能移动终端本地执行图像分类任务的场景,结合不同卷积神经网络模型的分类特点,提出了自适应CNN模型选择策略。该策略首先分析不同模型对图像的分类结果,输入贪心算法构建基于能效的图像分类模型序列,然后将预分类算法进行排列组合形成多种备选分类方案,最后为序列中的每个图像分类模型构建与之对应的预分类模型,并选择性能最优的预分类方案。该策略为不同的图像选择最适合的图像分类模型,实验结果表明,相比于单独使用Inception_v4,本文提出的自适应模型选择策略推理时间降低15.8%,能耗降低71%,准确率提升7.6%。2.针对在移动端本地执行图像分类任务的延迟高、能耗高问题,结合边缘计算的架构,提出基于边缘服务器的图像识别任务调度策略。首先根据图像在不同卷积神经网络模型和不同设备上的推理时间及能耗,分别在移动端和边缘服务器端部署了轻量级的模型和高准确率的模型。然后根据图像特征对图像识别任务进行调度。该策略将更适合应用于轻量级模型的简单图像分配给本地部署的模型执行推理,将更适合应用于高性能模型的复杂图像分配给边缘服务器端部署的模型执行推理。实验结果显示,相比于在智能移动端本地执行图像分类任务,基于边缘服务器的图像识别任务调度策略的分类准确率提升3.1%,推理时间降低91.6%,能耗降低了92.5%。"
1212,基于情感分析和特征过滤的主题提取方法研究,"近年来,互联网已经渗入到我们的日常生活中,互联网服务APP已然成为新时代的生活网络工具之一.人们进行选购商品时,经常翻看商品的评论来对这个商品作出购买判断,并且这些文本评论是消费者的直观感受,同时这些评论也提供了一个为平台了解客户的途径,快速挖掘文本评论的信息并且转化为生产力是亟待解决的问题.本文基于服务APP文本短评数据,探索适合短文本的主题挖掘方法.本文简单介绍了中文文本的预处理技术、文本特征的提取技术和不平衡数据处理技术,主要任务是探索快速且准确的文本情感分析的方法和精确提取主题的模型.并将情感分析和特征筛选融入到主题模型中,提出一种基于LDA模型的主题提取方法.本文的主要研究内容和工作如下:探索和选择适合短评数据的不平衡数据处理技术,用重抽样和欠采样技术进行处理并对比结果.从基于机器学习模型的情感分析和基于深度学习的情感分析两个角度展开,探索针对不平衡数据表现优异的情感分析模型.机器学习模型选用支持向量机和梯度提升决策树做实验,并用网格搜索和交叉验证调参.深度学习选用的是浅层网络fastText.用加权F1评估三个模型,实验证明,在处理不平衡数据方面fastText模型优于其他两个模型,并且指明了原因.在主题提取任务中,提出一种基于LDA模型针对短文本和不平衡数据的方法,先进行情感分析,将情感极性的标签加入主题提取模型中,再进行特征筛选,剔除公共属性特征,按类别进行短文本主题提取,效果较原模型显著,该方法具有实际应用价值."
1213,基于专家知识和深度学习的领域术语网络模型构建,"使用节点和节点关系的网络模型来表示知识,已经是研究领域中一种成熟的做法。另外如何通过机器对知识进行学习,这不仅是人工智能领域的长久研究课题,也是现实中专家的一种需求。本文使用基于德尔菲法的专家交互来获取专家知识,通过专家知识生成技术体系和技术清单,并在此基础上来检索文献数据,得到精准的文本数据集。抽取数据集中技术术语并构建其共现网络,使用表示学习模型Node2vec来训练共现网络得到术语的表征并进行进一步的显著度和相关性分析。本文研究发现,专家知识和数据分析后反馈的不断迭代能使我们得到更为精准详细的领域知识。同时基于网络模型的Node2vec表示学习模型也能忽略多余文本对实验的影响,得到的表征仅限于技术术语,使得分析更为针对和有效率。"
1214,基于语义分析的源码缺陷预测系统,"随着软件应用场景的不断扩大,软件的规模和复杂度也随之增大,在软件的开发和维护过程中,为了避免软件在生产环境中出现问题,需要对软件源码进行一定的测试,而软件测试随着规模的扩大,所需要投入的资源也呈爆炸式的增长。软件缺陷预测是软件测试中的一部分,依据历史数据来预测开发的软件源码是否存在缺陷,从而合理的分配测试资源。近年来,软件缺陷预测主要研究的是软件工程领域的特征,包括代码的结构和复杂度特征,将不同的软件工程特征进行选择和组合。而随着深度学习与自然语言处理领域的不断发展和体系完善,基于语义特征的软件缺陷预测成为现阶段研究的热点,本文将源码缺陷预测与自然语言处理领域的文本分类相类比,针对源码本身所蕴含的语义特征难以提取的关键问题,在分析现有语义特征提取模型的基础上,设计了基于卷积神经网络和长短期记忆网络的源码语义提取模型,该模型通过深度神经网络对源码文本进行特征抽象,获取源码语义特征;并提出采用Word Embedding技术对源码输入进行词向量映射,以此作为语义特征提取模型的基础,该技术能够对输入数据进行降维,并映射到低维的语义空间。实验和分析表明,针对相同的开源数据集,基于语义特征提取的预测模型在性能上优于基于传统特征领域的预测模型,验证了语义特征提取的有效性。"
1215,基于改进MTCNN模型的人脸检测与面部关键点定位,"随着计算机视觉领域的飞速发展,人脸识别技术成为人工智能的一大热点。而人脸识别系统是指通过分析比对人脸的视觉特征进行人员身份鉴别的技术。该技术可被用于诸多领域,例如公安侦破系统、门禁管理系统、上班打卡系统与视频监控系统等。人脸识别系统通常由图像获取、图像预处理、人脸检测、面部关键点定位与人脸识别五个部分组成。人脸检测与面部关键点定位的表现效果直接影响人脸识别的准确性与时效性。因此,本文主要对人脸检测与面部关键点定位进行研究。人脸检测是指根据算法与网络结构,判断输入的图像中是否存在人脸,并将人脸区域框定。而面部关键点定位,则是选用左右眼、鼻尖以及左右嘴角五个关键点对待检测的人脸图像进行定位。将检测出的人脸区域裁剪并缩放成人脸识别系统所适用的尺度以便后续人脸识别环节的进行。由于存在光线、遮挡、非正脸和图像像素过低等诸多因素的影响,给人脸检测与面部关键点定位的准确率带来困难与挑战。为增强人脸检测与面部关键点定位的准确性与鲁棒性,本论文以MTCNN模型为研究基础,对人脸检测与面部关键点定位进行了深入的研究。本文的主要研究内容包括三个部分:基于多尺度多模板图像金字塔数据预处理方法的MTCNN模型;基于脑平行交互机制的面部关键点定位方法的研究;将MTCNN模型与ERT模型结合,构建了新的组合人脸检测系统。论文的主要工作如下。1)针对MTCNN模型中单一模板多尺度图像金字塔预处理环节进行改进,将多模板多尺度的数据预处理引入MTCNN模型。从而使得网络模型可以适用于更多人脸尺度的情形,并且实现数据集扩充。实验结果表明,所提出的多模板多尺度图像金字塔数据预处理方法可以提高密集多人脸的检测精度。2)将脑平行交互机制的思想引入MTCNN,针对面部五个关键点定位的O-Net子网络提出了O-Net-1和O-Net-2的两个新网络。ONet-1在其平行交互的结构中让面部关键点定位的任务单独工作,从而提高网络对于该任务的针对性。而O-Net-2则仅针对面部关键点定位任务引入平行交互的结构,与原网络的二分类任务及回归框检测任务之间独立工作。实验结果表明基于脑平行交互机制的MTCNN模型能够提高面部关键点定位的准确率。3)提出了一种基于MTCNN模型与ERT模型的混合人脸检测模型,该模型是以ERT辅助MTCNN的检测模型。将MTCNN没有检测到的图像送入ERT模型进行二次检测,解决单个网络的漏检问题。根据实际需求制作了一个由摄像头采集的复杂环境下的人脸数据集。通过在该数据集上进行对比实验,证明了所提出的混合人脸检测模型的有效性。"
1216,面向互动展示的深度学习检测识别系统设计与实现,"随着科技的发展,融入科技元素的艺术形式越来越热门,将深度学习和计算机视觉技术融入之中,具有巨大研究潜力和应用价值。数字互动展示平台主要由目标检测识别系统和数字动画投影系统组成,其中目标检测识别系统是核心部分。本文针对复杂环境条件下互动展示平台目标物块实时识别定位问题,提出一种基于YOLO v2算法模型的快速识别定位方法,结合目标在样本图像中的尺寸差异,采用聚类算法提取更匹配样本目标对象尺寸的先验框尺度,设计并搭建了面向互动展示的深度学习检测识别系统。为保证目标样本图像的复杂性和多样性,采用数据增强扩充物块训练样本。最后通过试验分析验证系统性能,实现了端到端的目标物块检测识别。论文的主要工作包括:针对此次项目构建了特定项目数据集HUSTC605,数据集样本图像充分考虑了目标所处背景、光照强度、光照颜色等外部环境因素和拍摄角度因素,使用数据增广方法对数据集进行扩充,扩充时对数据样本随机进行镜像变换、高阶插值、增加Gaussian噪声、椒盐噪声和周期性噪声。基于YOLO v2模型设计了物块实时检测识别系统,发展了基于卷积神经网络的物块检测识别算法,并基于Qt的UI图形化界面设计了针对本文的实时检测识别系统软件用于测试系统的性能,软件功能界面具体包含界面显示控件、相机标定控件、参数设置控件等元素。分别在静态测试集和动态随机实时目标物块两个层次进行了系统检测识别性能验证,对处于若干个不同典型场景下的目标物块进行了测试研究。试验结果表明:在6个具有代表性的典型场景下,两个层次的检测识别精度结果均趋向于1;召回率均基本保持在0.95以上,单个目标具有较高的定位精度。总体上,检测识别系统检测识别性能优越,且具有很好的鲁棒性。"
1217,基于改进注意力机制的短文本情感分析研究,"随着社交媒体的快速发展,越来越多用户在互联网上发表言论、分享观点,这些用户数据无论是对消费者、企业或者政府部门都极具有商业价值和社会信息,因此大量研究者们着力于文本情感分析技术,进一步分析文本主观成分包括用户观点、情感倾向等。传统的情感分析主要集中于篇章级和句子级,且在一些数据集上取得了良好的结果,但是考虑到文本情感表达的实体或者对象,需要更细粒度的情感分析,本文提出了一种基于改进注意力机制的方面级情感分析算法,首先针对短文本内容简短,语句省略的现象,我们提出了一种基于词共现的文本特征提取方法,通过构建基于语义相似度权重的词共现矩阵提取文本的词共现特征;其次,我们提出Aspect-Attention记忆网络模型,通过双向LSTM学习表征文本的方面特征,并构建Aspect-Attention机制挖掘文本上下文语义与方面特征之间的潜在语义联系;最后引入词性特征,提出基于多特征融合的张量神经网络,通过构建张量神经网络挖掘文本不同特征,包括词性特征、文本上下文特征以及方面特征之间的语义联系,从而进一步表征文本上下文语义与方面特征之间的情感倾向。此外为了减少张量权重的冗余信息并减少权重参数,我们利用张量分解技术对张量权重进行降维,进行降维后的特征权重既可以表示多种特征之间潜在关联同时也控制了模型训练规模。本文的算法在SemEval-2016 Task5中文数据集进行对比实验,实验结果显示本文算法在方面级情感分类任务上较其他算法能够达到更高的分类准确率以及F1值等。"
1218,基于分布式优化的移动边缘计算任务调度和设备协同算法研究,"近年来,随着移动互联网与物联网技术的快速发展,计算密集型应用及时延敏感型应用应运而生,显然,在移动设备上运行这样的应用是不切实际的。在以往的研究中,用户将计算任务卸载到云端以满足设备的高计算需求。然而,基于云的解决方案导致了巨大额外带宽占用及无法预测的长时延。为了解决这一问题,移动边缘计算将服务器部署在网络边缘,提供近距离、低时延的服务。随着数据规模的增大,单个移动边缘服务器的计算方式会带来巨大的计算压力。为了解决这一问题,本文提出以协同的方式进行计算,一方面考虑当设备具有自私性时,如何鼓励设备的协作;另一方面当设备具有协作意愿后,怎样进行协同计算,如机器学习任务中存在扩展性及隐私等问题时,如何计算。针对以上挑战,本文以移动边缘服务器为中心,利用周边可用资源协同计算,进一步提升移动边缘计算系统的计算性能,使用分布式优化技术交替方向乘子法(Alternating Direction Method of Multipliers,ADMM)对问题进行求解。主要内容及创新点如下:一、针对单移动边缘服务器多边缘计算设备间的任务调度问题,本文提出一种分布式任务调度算法,移动边缘服务器通过召集近端可用资源,提高计算效率。现有研究中仅关注了团结协作的场景,本文进一步研究了边缘计算设备的自私性问题。在边缘计算设备具有理性思维的情况下,通常不会与移动边缘服务器进行协同计算,因此需要设计有效的激励机制鼓励边缘计算设备的协同。针对该问题,本文提出基于ADMM的斯坦克尔伯格博弈算法,通过对非凸问题进行转化,利用斯坦克尔伯格博弈理论,结合分布式ADMM优化技术,对任务调度问题进行求解。通过实验验证本文提出的算法的收敛性、稳定性与可扩展性。二、在单移动边缘服务器与多物联网设备协同计算的场景下,我们认为物联网设备具备共同执行任务的可能性。本文研究了机器学习中的回归问题。基于移动边缘服务器的集中式解决方案,可能会导致可扩展性、计算性能和隐私问题。为了应对这些挑战,本文提出基于ADMM的分布式设备协同算法,引入辅助变量将问题分解为多个子问题。由于子问题的不可导性与复杂性,分别针对子问题设计次微分演算法和改进的共轭梯度法进行求解。对典型数据集进行实验研究,结果表明我们的算法能够快速收敛到集中式方法的最优解。通过与传统集中式方法和独立方法对比,我们的算法表现出良好的扩展性能及效率。"
1219,基于深度学习的Webshell检测技术研究,"Webshell是一种脚本语言编写的黑客工具,是黑客攻击中非常关键的一个环节,一旦服务器被攻击者写入Webshell,就很可能导致服务器被黑客完全控制,从而导致挖矿、挂马、数据泄露、内网渗透等一系列严重后果。Webshell变形灵活,很容易逃避安全软件的查杀。深度学习类检测模型准确率虽然较传统检测算法高,但检测模型较为脆弱,很容易受到对抗样本攻击。本文主要针对深度学习Webshell检测模型的脆弱性问题,研究了模型脆弱的原因,在攻击和防护两个方面进行研究和实验验证。主要的研究成果有:(1)提出了一种利用词袋可控溢出污染数据集的新方法;通过利用词袋提取算法的一个安全隐患,产生可控的词袋溢出,可以在模型的训练阶段达到拒绝服务的攻击效果。(2)提出了一种快速生成对抗样本的方法;通过在反向语料库中随机搜索对抗词汇,并结合脚本语言程序语法,构造难以过滤的对抗特征,并将其注入Webshell,达到免杀深度学习检测模型的攻击效果。(3)提出了一种特征加强的Webshell检测模型。该模型通过融合机器特征和人工特征,整体上提高了检测模型的非线性程度和表达能力。实验使用的数据集为GitHub开源Webshell收集项目,经实验验证,该融合模型较原模型不仅准确率得到了进一步提高,而且可以防止很大程度上的对抗样本攻击、在叠加干扰噪声的数据集上依然能进行较好的学习。"
1220,隐藏服务内容分类研究,"随着网络用户对隐私保护要求的不断提高,匿名通信技术与隐藏服务机制(又名暗网)得到快速发展。然而隐藏服务强匿名性和难以追踪的特点为非法活动提供了庇护场所,非法服务层出不穷,给网络空间安全带来了严重威胁。因此,研究隐藏服务非法活动的分类,对防止和打击违法犯罪行为,具有重要意义。由于隐藏服务域名发布方式隐蔽,非法网站数量分布不均衡,且内容迁移更新频繁,大规模数据采集与标记具有一定难度,因此当前隐藏服务非法内容分类研究中存在数据集规模小、目标类别少、难以分类新型非法活动等难点。针对这些问题,本文以Tor隐藏服务为研究对象,提出了基于法律规制的隐藏服务非法活动分类方法,利用相关法律法规判定非法隐藏服务,结合TF-IDF特征权重计算和机器学习分类算法,实现了对隐藏服务非法网页的有效分类。本文主要工作与贡献如下:(1)在数据采集阶段,通过研究Tor隐藏服务发布与访问机制,设计了 Tor隐藏服务发现与收集系统,使用爬虫框架实现了从Tor隐藏服务目录类网站和明网搜索引擎关键字检索两种渠道发现和收集Tor隐藏服务域名的功能,构造了基于Tor隐藏服务的非法活动网页数据集,为后续分类研究提供测试数据。(2)提出基于法律规制的隐藏服务非法活动分类方法,使用法律文本作为隐藏服务非法活动的分类判定依据。该方法的研究重点是法律训练样本的提取与构造,针对从HeinOnline法学数据库中检索的目标类别适用法律,通过分析美国制定法和判例法的结构特征与行文规范,结合FindLaw术语库生成法律专用停用词表,过滤干扰信息。采用TF-IDF算法提取类别关键词,通过在本文采集的数据集上进行了小规模分类测试,初步证明该方法的可行性。(3)在方法实现阶段,提出了基于TF-IDF改进的特征权重算法。针对TF-IDF在网页文本分类中的局限,结合隐藏服务非法网页结构特点引入基于HTML标签的特征权重系数,提升筛选出特征词的类别区分度。将法律训练样本和非法隐藏服务测试样本分别构造为空间向量模型,使用8种机器学习分类算法进行训练与分类实验,其中贝叶斯分类器表现最好。实验结果表明,基于法律规制的分类方法使用TF-IDF特征权重计算和贝叶斯分类器达到了 93.5%的分类准确率,改进的ωTF-IDF算法比之提高了 2.6%的准确率,通过在DUTA数据集上与传统方法进行对比实验,本文方法使用小规模且易获取的法律训练集实现了与传统方法相当的分类精度。该方法不依赖于大规模隐藏服务训练模型,且对于还未泛滥的新型非法活动,该方法在掌握法律支撑材料的情况下,同样能够实现有效分类。"
1221,面向佯攻的虚实攻击链构造及检测方法的研究与实现,"近年来,持续进化的网络威胁环境带来了更为复杂的攻击场景。网络空间的攻击者不再像以往仅使用单一的攻击行为,而是在一个长期的过程中利用多种复杂的攻击相互配合来谋取非法利益,这类攻击模式被统称为多阶段攻击,其中攻击者的一系列攻击行为被合称为攻击链。本文的研究对象是一类特殊的多阶段攻击,在某些攻击阶段中的大部分攻击行为是作为佯攻起到吸引防御方注意或消耗其主要防守资源的目的,而作为攻击者真实攻击手段的剩余小部分主攻击在佯攻的掩护下将力图出其不意地达成攻击目的,这类多阶段攻击已成为严重威胁网络安全的重要因素之一。本文通过调研,发现现有多阶段攻击的检测方法并没有深入研究包含佯攻这类特殊攻击行为的攻击链,同时也缺乏检测该类攻击模式的专业数据集。面对这类特殊多阶段攻击亟需提出新的检测方法,达到检测此类攻击手段的目的。本文把对多阶段攻击中佯攻这类特殊攻击形式的研究实例化为对虚实攻击链的构造及检测。将佯攻定义为虚攻击,而在虚攻击掩护下达成真实目的的攻击定义为实攻击,通过将多阶段攻击检测方法与深度学习算法相结合来构造虚实攻击链,并实现对虚实攻击链的检测,以达到识别佯攻行为的目的。本文的主要创新点和贡献如下:(1)提出虚实攻击的概念,将多阶段攻击中佯攻这种特殊攻击形式具体实例化。利用基于属性相似度的模糊聚类方法构造佯攻行为所依托的基础攻击链。(2)提出基于CNN-HSVM的虚实原子攻击分类算法(Atomic Attack Classification,AAC),用其构建虚实原子攻击样本库,以解决缺乏研究佯攻攻击数据集的问题。(3)提出基于混合模型的虚实攻击链编码及检测算法(Coding and Detection Algorithm,CDA),用其将样本库中的虚实攻击事件同基础攻击链相结合构造虚实攻击链,最终对虚实攻击链建立检测模型。针对上述所提出的方法,本文使用加拿大网络安全研究院的CICIDS2017数据集来验证文中所提出的方法。在实验过程中,本文准确还原出多阶段攻击序列,并基于AAC算法构造出包含虚实攻击行为的攻击链,最终通过CDA方法建立了对包含佯攻行为的多阶段攻击检测模型,实验结果表明该模型的检测率达到80.7%,较好的实现本文的研究目标。"
1222,智慧协同网络中基于机器学习的DDoS攻击防御机制设计实现,"随互联网应用规模不断扩大,传统互联网的原始设计思想暴露出诸多严重弊端,难以满足未来网络“智慧”、“高效”和“安全”等重大迫切需求。以“两域”、“三层”和“三映射”体系为典型特征的智慧协同网络系统(Smart Identifier Network,SINET),突破并有效地解决了未来互联网体系面临的各项挑战。其作为一种处于发展过程中的网络体系,其网络安全是目前急需完善的重要课题。本文基于智慧协同网络组件协同机制设计并实现智慧协同网络中分布式拒绝服务攻击(Distributed Denialof Service,DDoS)防御机制,实现了对智慧协同网络中网络组件DDoS攻击检测及防御。本文具体工作如下:首先,分析现有互联网网络体系及网络安全的发展现状和需求,并概述国内外在网络体系及网络安全方面的研究现状;阐述智慧协同网络体系架构及服务机制,简述DDoS攻击过程及检测防御技术原理;进一步阐述在智慧协同网络体系架构下设计实现DDoS攻击防御机制的研究意义。其次,对智慧协同网络中DDoS攻击检测防御机制需求进行分析并设计总体方案;设计基于支持向量机的DDoS检测方案;阐述基于控制器调度的DDoS防御方案。再次,对智慧协同网络DDoS攻击防御整体机制进行实现。检测模块中实现了支持向量机的优化、确定了检测周期、提取了 DDoS数据流量特征和建立了源ID黑名单;实现防御模块中防御机制的触发、转发器转发队列的构建和转发器转发能力重分配。最后,对智慧协同网络DDoS攻击防御机制分步进行测试。对比本文优化前后和优化各部分对持向量机性能的影响;验证检测周期及特征值选取的合理性;对比支持向量机与决策树及神经网络基于本实验环境的性能;测试基于控制器调度的防御效果。最终证明本文设计实现的智慧协同网络DDoS攻击防御可有效防御智慧协同网络中DDoS攻击。本文实现了智慧协同网络中网络组件的DDoS攻击防御机制,对智慧协同网络中安全策略研究及部署提供了借鉴意义。"
1223,基于非平行支持向量机的多分类算法,"支持向量机是解决机器学习问题的一类重要算法,该算法集成了多项技术,自提出以来就受到了人们广泛关注,已经被应用到各种领域.由于支持向量机最初是用来解决二分类问题,而实际应用中遇到的许多问题是多分类问题,因此如何将二分类算法扩展到求解多分类问题,具有重要的研究意义.非平行超平面支持向量机对处理类间交叉的数据集和大规模数据集有优势,因此本文针对多分类问题,第三章在非平行超平面支持向量机多分类算法(NHCMC)的基础上提出第一种算法ε-非平行支持向量机多分类算法,简记为INHCMC.通过结合非平行支持向量机(NPSVM)的思想,将NHCMC中的二次损失函数改为ε-不敏感损失函数,半稀疏性改善了.论文给出的数值实验结果表明了 INHCMC是有效的.由于INHCMC对多分类问题采用的是一对余的思想,会造成数据集不均衡,因此很难选取合适的参数ε.第四章在INHCMC的基础上提出v-ε-非平行支持向量机多分类算法,简记为v-INHCMC,通过结合v-SVC和v-SVR的思想,将INHCMC原始模型中的参数ε和参数C2用有数值意义的参数v代替,化解了 INHCMC中参数ε的选取困难,并且v能够权衡模型中的两个目标(最大化间隔和最小化误差),以及有效的控制支持向量的个数,数值实验结果表明了v-INHCMC是有效的.交替方向法乘子法(ADMM)是一种用于解决可分凸规划问题的有效方法,尤其在解决大规模问题上具有优势,近年来被应用到机器学习的优化问题中.第五章我们采用交替方向乘子法的框架来求解INHCMC的原始问题,为了能够处理大规模数据集,本文用共轭梯度法近似求解子问题中矩阵的逆.数值实验结果说明了该算法是有效的."
1224,基于非平行支持向量机的顺序回归算法,"顺序回归机(简称OR)解决的是带有顺序的多类分类问题,它在众多领域有着广泛的应用,如信用等级、人脸识别、医疗研究和社会科学等.支持向量机(简称SVM)作为处理分类问题的一种有效算法,它在解决二分类问题上已经取得了显著的分类效果.因此如何将二分类算法扩展到顺序回归问题中,具有重要的研究意义.本文主要内容大致分为如下三个部分:第一部分是将v-非平行支持向量机(简称v-NPSVM)推广得到新的顺序回归机称为v-非平行支持向量顺序回归机(简称v-NPSVOR).相较于非平行支持向量顺序回归机(简称NPSVOR),该算法将其中的参数∈变为变量∈k,k∈{1,...,q},减少了选取参数的困难.第二部分是将稀疏线性非平行支持向量机(简称L1-NPSVM)推广得到新的顺序回归机称为L1-非平行支持向量顺序回归机(简称L1-NPSVOR).该算法是将NPSVOR中的目标函数添加了1/2bk2,不仅使得决策变量bk的解唯一而且对偶问题减少了等式约束;第三部分是将改进的孪生支持向量机(简称ITSVM)推广得到新的顺序回归机称为稳定非平行支持向量顺序回归机(简称SNPSVOR).该算法是将L1-NPSVOR中的第一个不等式约束改为等式约束,在一定程度上减少了数据集带有异常点所造成的影响.数值实验结果表明了以上三种算法的有效性."
1225,基于支持向量机的PU问题分类算法,"PU(Positive and Unlabeled)问题是一个定义在只包含少量正类样本点和大量未标签样本点的数据集上的分类问题,它是机器学习中半监督问题的一种特殊情况.在机器学习的很多应用(例如:文本分类,基因序列,图像识别等)中,获得大量的已标签样本需要耗费大量的时间和劳动力,因此研究PU问题具有重要意义.支持向量机(SVM)具有显著的理论与实践优势,在机器学习领域有着广泛的应用.利用支持向量机来解决PU问题的方法有Biased-SVM(B-SVM),One-Class SVMs等,其中B-SVM在已有的SVM模型基础上,将未标签的数据点全部看成负类点例,通过给予正类点一个较大的权重和负类点一个较小的权重来建立分类器进行分类,数值实验表明B-SVM的分类效果良好.非平行支持向量机(NPSVM)是支持向量机的延伸,它不仅具有支持向量机的优点,而且在处理类间交叉的数据集和规模较大的数据集时有很大的优势.在本文中,我们基于B-SVM方法和NPSVM,提出l1-NPSVM并将其应用到PU问题中,此方法具有一定的特征选择功能.通过将其转换成线性规划形式进行求解,使得求解过程简便高效.数值实验表明此算法分类效果较好.绝对值不等式SVM利用一个绝对值不等式来处理一般半监督问题中的未标签点,通过将未标签点合理分布于分类超平面两侧来建立分类器进行分类,此方法易实现且分类效果不错.在本文中,我们通过计算未标签点与已标签正类点之间的距离来选择部分未标签点作为负类点,将PU问题转换成普通的半监督问题,并利用绝对值不等式SVM对转换后的问题进行求解.数值实验表明此算法简单可行且分类效果较好."
1226,个人信贷领域的用户画像建模与逾期识别集成算法研究,"随着我国经济发展进入新常态,国内金融信贷行业发展迅速,许多金融信贷服务逐步推广到大众生活当中,个人信贷业务已经风生水起,加上互联网金融的不断发展,个人信用消费越来越普遍,信贷行业用户画像模型与逾期识别模型的建立已经是一种迫切需求。本文首先针对基础样本数据的变量类型提出了变量细分的想法,得到了变量细分的十一个维度,并在传统RFM价值评价模型基础上建立了以信贷用户消费能力、用户粘性和还贷意愿这三个维度的综合评价指标体系。基于变量细分维度与综合评价指标体系我们建立了用户画像模型,其中包括了用户细分画像与用户漏斗画像。对于用户细分画像,我们使用综合评价指标体系在消费能力、用户粘性、还贷意愿这三个维度细分了信贷领域的用户群,针对性的评价了每类用户群的价值并提出了相应的资源配置策略。对于用户漏斗画像,我们基于变量细分维度后得到的十一个维度使用用户漏斗算法,得到了高逾期占比用户群体并捕获了高逾期占比用户群的行为路径。在构建完用户画像模型后,我们着力于构建逾期识别集成算法模型。首先基于变量细分的思想与相关机器学习算法,完成了对基础样本数据的打分、降维,得到了新的两类样本数据,全量特征打分数据与细分维度打分数据,研究了不同样本数据对随机森林集成算法预测精度的影响。再基于两种不同样本、五种不同的集成算法,通过对测试集、交叉验证集、学习曲线与若干评价指标的评估选择了最优的Stacking集成算法,提供了精准、稳定、科学的逾期风险识别模型。本文构建用户画像模型是为了更好的服务于业务,构建集成算法模型是为了更好的服务于逾期风险识别精度。"
1227,极限学习机在分类问题中的应用与研究,"极限学习机(ELM)作为一种新的学习框架在模式识别和机器学习领域得到了广泛的应用。与传统的神经网络相比,ELM随机选取输入权重,通过最小二乘法无需任何迭代来确定输出权重。因此,极限学习机在分类任务中具有快速高效的特点。基于ELM算法的优势,我们对其进行了深入的研究。由于数据样本复杂度较高以及在监督学习中带标签数据有限的问题,限制了极限学习机的泛化性能。鉴于该问题具有重要意义,我们对此进行了研究,从以下两个方面对极限学习机进行改进:1)基于流形学习的思想,提出了基于局部信息保持极限学习机(localityinformation preserving extreme learning machine,LPKELM)。流形学习揭示了数据内在的几何结构信息,从流形学习的角度可以认为数据样本来自同一个边际分布,如果数据点在高维空间中离得很近,那么它们应该具有相似的属性,同属于一个类别。因此通过挖掘样本点间的几何结构能够为模式分类提供有效的信息。LPKELM将数据样本的几何结构信息和判别信息引入到ELM模型中,弥补了 ELM算法在监督学习中,学习不充分的问题。2)在上述LPKELM算法的基础上,提出了一种新的多映射核极限学习机(multiple-mapping kernel extreme learning machine framework,GKELM)。核函数的作用就是隐含着一个从低维空间到高维空间的映射,而这个映射可以把低维空间中线性不可分的两类点变成线性可分的。然而单一内核可能不足以表示所有数据情况,这将导致隐藏层输出矩阵的不适定问题,引起输出权重过拟合现象。因此核函数在极限学习机的分类中起到至关重要的作用。有效的核函数可以更好地获得数据的分布信息,避免数据冗余现象。因此,利用核函数的思想,将高光谱遥感数据映射到多层核函数中,充分利用了数据的空间分布信息,提高了分类性能。最后将两个算法应用到高光谱遥感图像数据集中进行实验,并与其他分类算法对比,从实验结果中可以看出所提算法有更高的分类准确率。"
1228,面向多标记分类的主动学习算法研究,"主动学习在机器学习、数据挖掘、模式识别等领域备受业内人士的关注,主要解决标记实例开销大的问题。主动学习方法首先使用少量已标记实例集学习分类器,然后根据实例选择算法从未标记数据中获取信息,最后由专家标注系统标记选取的实例并更新分类器。主动学习的核心问题是如何设计实例选择算法来选择质量和数量均佳的实例。目前主动学习的研究仍还集中在单标记分类问题上,多标记分类是数据分析中普遍存在的一个问题,多标记实例的标注通常比单标记实例的标注花费的时间更多、代价更高。在多标记分类问题中,如何更加精确地找出更适合分类的标记集合加入到属性空间中,这是提升多标记分类算法性能的关键。另外,已有的实例选择算法考虑噪声数据的情况较少,而且其选择策略比较单一。针对上述问题,本文从实例选择算法和多标记属性选择这两个方面展开了研究,本文贡献如下:(1)针对实例信息度量方式比较困难的问题,提出了一种基于不确定性采样的主动学习算法。首先,本文使用多个二分类的支持向量机分类器,将多标记实例的正负标记分离,正负标记值之间的距离称为分离裕度。实例选择算法将分类结果中分离裕度的值最小的实例视为不确定性高、信息丰富的实例。这里本文提出基于偏值项的分离裕度的主动学习算法,在选择实例时,使用偏置项作为衡量分离裕度的因素,选取分离裕度的值趋向于偏置项大小且非噪声的实例。其次,在此基础上,该算法使用标准差的方式度量实例的离散度情况,选取高离散度的实例。最后,通过多个多标记数据集上的实验结果证明了该算法的有效性。(2)针对分类器出现分类错误的情况下实例选择算法极有可能误选实例以及考虑标记间相关性的问题,提出了一种基于最大相关性的多标记主动学习算法。首先,使用实例与标记值之间的相关性来度量实例的不确定性,并将其与已有的最小置信度策略结合使用。其次,该算法采用改进的两层多标记模型,选择基分类器分类结果中高于阈值的标记值扩展属性空间。最后,将改进的两层多标记模型与实例选择算法综合使用,提升最终分类器的性能。同样,通过多个多标记数据集上的实验结果证明了该算法的有效性。"
1229,针对DQN在路径规划应用中的对抗性样本生成及预测研究,"近年来,深度强化学习在许多领域都取得了一定的成功并得到了广泛的应用。其应用是否具备承受攻击能力和强抗打击能力也随之成为近年来的关注热点。因此,在人工智能安全性的大背景下,本文挑选了深度强化学习中极具代表性及经典的深度Q网络(DQN)算法进行研究。同时将强化学习系统中的智能体自动寻路应用作为对抗应用场景,构建应用上贴近民用的无人驾驶和军事实战的具有代表性的AI强化学习系统,并针对DQN对对抗性样本的脆弱性,对其进行攻击。本文利用DQN算法实现智能体的自主寻路,寻路路径为最优最短路径,同时对寻路路径的规则及特点进行分析和评估。基于此,本文提出了基于白盒的对抗性样本生成算法(WAG)和基于WAG算法的对抗性样本预测模型(APM)两种方法。在对抗性样本生成的研究中,通过对影响DQN路径规划算法的两个的因素Q值和梯度值进行分析和总结,提出了基于白盒的对抗性样本生成算法(WAG)。该算法可以实现对所有可能对路径规划造成攻击的对抗性样本点的检测。这些对抗性样本会不同程度的干扰智能体寻路,使其通过自主寻路无法达到应有的最优最短路径并能够成功的降低它的训练效率。在对抗性样本的预测研究中,本文提出了对抗性样本预测模型(APM)。对通过WAG算法找到的所有疑似对抗性样本的特征进行分析,根据对抗性样本对路径的影响程度即寻路时长和寻路步长将对抗性样本分为两类,分别为普通攻击点和致命攻击点。然后,提取对抗性样本的Q值和梯度值特征,利用典型相关分析算法(CCA)实现特征之间的关联和融合。同时对对抗性样本建立标签,将对路径规划影响最大的点命名为“致命攻击点”,除该点外的点命名为“普通攻击点”。最后利用K近邻算法(KNN)实现对两种类型对抗性样本点的预测。为了证明WAG和APM两个方法的有效性,本文构建了一个仿真环境作为平台进行实验。首先制定了是否为对抗性样本的判定标准,然后通过大量的实验发现通过提出的WAG算法可以成功的找到对抗性样本,并且从多个角度对实验结果进行分析。最后,通过APM方法建立分类预测模型,通过实验证明该模型能较好的实现对两种类型的对抗性样本点的预测,且分类模型的准确率达到了94.8%。"
1230,基于信息熵的限制玻尔兹曼机稀疏化方法研究,"受限玻尔兹曼机(Restricted Boltzmann Machine,RBM)在机器学习领域应用广泛,是一种常用的的概率生成模型。由于其在特征提取方面的卓越性能被广泛应用于各种领域,其中,隐藏层神经单元的稀疏化技术是对RBM性能的重要改进。现有稀疏化方法中对于激活神经单元的阈值设定通常基于人为设定,使用全局的或固定的备用参数,并且与输入数据相互独立。然而输入数据通常具有不同的特征和概率密度分布,输入数据之间的差异也包含了大量的有用信息,将这些差异用于稀疏过程是本文的主要研究工作。本文在已有RBM模型稀疏化方法基础上提出了新的稀疏化方法,基于不同数据的特征分布的复杂程度不同,以此条件作为的RBM模型进行自适应稀疏化工作的条件,称为熵值基数限制玻尔兹曼机(EC-RBM)。通过确定EC-RBM模型的稀疏化条件,进而能够以此确定神经元的激活阈值,以激活阈值为限制条件保证神经元被激活的数量不会超过一定的数量,从而实现RBM网络模型的稀疏化表示。本文的主要工作有两方面内容:一方面是使用数据的信息熵作为条件实现了本文模型EC-RBM稀疏化工作的动态变化。在该模型中,使用基于数据信息熵的方法来计算不同类别输入数据的数据类熵,然后使用数据类信息熵来计算不同类输入数据所对应的激活阈值,从而动态地确定激活的隐藏神经单元的数量。这种稀疏化方法能够主动适应不同特征分布的输入数据。首先,分析并确定了不同类数据的分布特征确实存在差异,并且能够通过数据的信息熵来表示这种差异,这为我们之后的工作提供了基础。其次,寻找方法进行未知训练数据的概率估计,本文为了使结果误差更小,选取了Parzen窗非参数估计方法进行计算,然后通过计算得到的概率分布计算得到每一类数据的信息熵作为确定神经单元激活阈值的依据。与此同时,在实验过程中我们发现了在使用输入数据进行多种相关计算时,由于使用高维数据计算不同数据间的空间距离时通常会比低维数据计算时产生的误差更大,并且高维数据的数据量过大导致计算十分复杂费时以及产生很多冗余数据使算法效率不高。对此,我们改进了数据信息熵的计算方法,通过使用隐藏层数据而不是输入数据来进行多种相关计算,从而克服高纬度数据的“维数灾难”问题。另一方面,在具体RBM模型的稀疏化工作实现过程当中,我们引入自组织网络映射的优点,通过神经元之间的竞争机制更好地实现数据特征的稀疏化表示。这种工作模式能够促进我们的模型中的稀疏化工作,引入竞争机制可以使得稀疏化工作过程能够更好地提取特征从而提升实验结果的准确性。所以,我们在激活隐藏层神经单元的过程中,提出了不同的神经单元竞争方法。最后,在两个通用数据集上的实验证明了所提出的方法在分类准确性上具有优势。"
1231,基于标签依赖关系的多标签分类方法,"多标签学习广泛应用于文本分类、图像标注、视频语义注释、基因功能分析等问题。近年来,多标签学习日益受到学术界和工业界的关注,成为机器学习领域中的研究热点,并且取得了显著的进步。然而,多标签学习经常受到标签数量、标签之间依赖关系、标签缺失等影响,多标签学习仍然是一项极具挑战的研究。标签之间依赖关系是复杂且重要的因素,它的有效学习会丰富数据表示的内涵,对提升多标签分类性能产生重要作用。因此,多标签分类主要面临以下挑战:不同标签之间存在关联性,并且关联性存在较大差异;随着标签数量的增长,标签之间依赖关系变得复杂,并且面临时间和空间复杂度的挑战;以及标签依赖关系在标签缺失问题中的应用。本文针对上述问题提出了两种多标签分类模型,主要工作和贡献如下:提出了基于神经网络探究标签依赖全局关系的模型NN_AD_Omega。考虑到不同标签之间存在不同的相关性,本文构建了标签依赖全局关系矩阵来刻画标签之间的依赖关系。该矩阵关于主对角线对称,主对角线表示每个标签与自身的依赖关系,并且该依赖关系最强。NN_AD_Omega模型的优势在于在神经网络的顶层加入标签依赖全局关系矩阵,在输出层增强标签之间的知识共享。同时,标签之间依赖关系的学习通过充分挖掘数据内在本质特点得到,能够在出现样本部分标签缺失的情况时,弥补标签缺失所带来的误差,从而有效地提高预测标签信息的能力。在四个标准多标签数据集上的实验表明提出的算法能够探究标签之间的依赖关系和处理标签缺失问题,并且有效提升了多标签分类的性能。提出了基于监督主题模型探究标签依赖局部关系的模型BooMF_LLDA。随着标签数量的不断增长,构建标签依赖全局关系矩阵越来越庞大,矩阵更新的时间和空间复杂度越来越高。为了降低标签依赖关系矩阵的时间和空间复杂度,本文构建了标签依赖局部关系矩阵来刻画标签之间的依赖关系。该矩阵通过对数据-标签表示矩阵进行布尔矩阵分解得到,数据在隐标签空间的表示也可同时获得。该方法将数据-隐标签表示矩阵应用到监督主题模型中作为训练阶段隐主题分配的监督信息。监督主题模型为每个特征所分配的主题与该数据所拥有的隐标签一一对应。在两个标准多标签数据集上的实验表明提出的算法能够探究标签之间的依赖关系,并且有效提升了多标签分类的性能。"
1232,基于Φ-OTDR分布式光纤传感系统扰动信号的分类算法及实现,"随着科学技术的发展,光纤传感技术与机器学习算法也在不断地得到完善。其中基于相位敏感光时域反射仪(Phase-sensitive Optical Time Domain Reflectometer,Φ-OTDR)的分布式光纤传感系统由于设计结构简单、监测的距离较长、可实现多点定位等优点,在长距离机场安防、油气管道检测、涵洞隧道检测等环境中得到了广泛的应用。基于Φ-OTDR分布式光纤传感系统扰动事件的多分类逐渐成为了重要的研究方向,而本文就是基于AdaBoost(Adaptive Boosting)算法对五种扰动事件进行识别,完成的主要工作包括:(1)研究分析Φ-OTDR分布式光纤传感技术理论,对输出信号进行了简单的理论分析,提取五种情况(浇水、攀爬、敲击、碾压、无扰动)下的扰动信号。对采集到的样本信号进行数据归一化、数据分组、数据差分等预处理操作,可以消除原始数据之间的相互影响,为后续的特征提取提供便利;然后提取了扰动信号在时域方面的三十维特征值,为扰动信号的识别分类奠定了基础。(2)提出基于投票的扰动信号分类方法,并对其实现和验证。结果表明所提出的识别方法能够有效识别五种扰动事件,对五种扰动事件的召回率分别达到91.93%、98.20%、91.57%、90.83%、99.23%,平均识别召回率达到94.35%;五种模式的识别精确率分别为94.85%、87.54%、97.76%、95.83%、99.21%,平均识别精确率为95.04%。(3)提出基于二进制编码的扰动信号分类方法,对其实现和验证。结果表明该方法能够有效的对五种扰动事件进行区分,但相比于基于投票法的扰动事件识别方法,识别率有一定的下降,对五种扰动事件的召回率分别达到89.43%、97.70%、90.90%、88.30%、99.13%,平均识别召回率为93.09%;五种模式的识别精确率分别为93.28%、87.35%、96.23%、92.75%、99.64%,平均识别精确率为93.85%。此外,由于二分类器个数的减少,所以识别的时间相对于投票法有一定的下降。(4)提出基于二进制编码与二叉树的扰动信号分类方法,对其实现和验证。结果表明该方法能够有效的对五种扰动事件进行识别,而且相比于前两种识别方法,识别率有一定的提升,对五种扰动事件的召回率分别达到92.27%、97.83%、94.47%、90.33%、98.73%,平均识别召回率为94.73%,五种模式的识别精确率分别为92.95%、90.90%、97.05%、95.67%、99.76%,平均识别精确率为95.27%。该方法的识别召回率和精确率都较优于前两种识别方法,但是识别的时间却有一定的增加,100次试验的平均识别时间为0.2325s。"
1233,基于0-1损失的支持向量机分类器,"在大数据时代,无论是多媒体、图像学,还是网络通信、软件工程,以及目前十分火热的人工智能,都能找到机器学习技术的身影,尤其是在计算机视觉、自然语言处理等“计算机应用技术”领域.支持向量机作为一种机器学习技术,一直处于飞速的发展进程中,特别是在引进损失函数及软间隔的概念后所构造的软间隔支持向量机,一直是学者们研究的焦点,许多不同结构的损失函数相继被提出,同时一些快速有效的算法也随之被设计出来,为解决数据的分类问题提供了诸多帮助,值得我们深入探讨和仔细研究.本文从基于0-1损失的支持向量机模型出发,首先介绍本文需要的预备知识及本文的主要工作,然后简要介绍目前比较常见的五种软间隔支持向量机模型,展示相应损失函数的表达式与图像,分析每个模型相应的优缺点,并概述求解不同类型支持向量机模型的算法,给出相应的迭代框架.在此基础上与L0/1-SVM进行比较研究,分析该模型的一些理论性质,给出该模型有解的充分条件及模型的一阶最优性条件.同时设计出求解它的快速稳定的L0/1-ADMM算法,详细说明我们算法中每个子问题求解的过程及使用的技巧.最后与其他五种软间隔支持向量机模型在分类精度及效率上进行了对比.通过大量的数值实验证明,无论是在人工数据集还是真实数据集上,我们的模型及算法在分类精度和计算效率上都取得了很好的数值效果."
1234,分类器评价指标MCC、CEN和ACC的比较研究,"由于机器学习和模式识别在现实生活中的广泛应用,分类问题作为其核心环节一直深受广大科研学者的重视。对不同分类器的分类性能进行评价和比较,是分类器设计的最后阶段,也是数据挖掘过程中最关键的步骤之一。一个分类器的良好性能是决定该分类器能否应用于分类情景中的重要前提。因此,评价分类器性能的好坏在分类任务中至关重要。在分类器评价指标中,准确率ACC(Accuracy)作为经典的分类器评价指标,由于其符合逻辑的评价方式,简单易扩展的特性,被各行各业广泛地应用在二类和多类问题的分类评价上。马修斯相关系数MCC(Matthews Correlation Coeffic--ient)评价指标被广泛应用于生物信息学领域,最早用于解决二类不平衡数据集的分类评价问题,现己扩展到多类问题的评价上。混淆熵CEN(Confusion Entropy)是近年提出的直接定义在多类问题上的分类器评价指标,其充分考虑了样本的错误分类信息,展示了类别和样本分离的情况,对于分类结果具有强大的辨识度。这三个优秀的分类器评价指标,各自拥有各自的特点。本文针对MCC、CEN和ACC评价指标进行了深入的比较研究。首先,分别构造了 8个ACC相同和4个MCC相同的混淆矩阵,并计算了他们的CEN,发现这些CEN值是不同的。也就是说,当ACC和MCC对不同的分类结果无法评价时,CEN能对其进行区分;其次,以三类问题为例,分别对CEN与MCC、CEN与ACC、ACC与MCC做了常用评价2种方法优劣的一致性和判别性程度的比较实验,实验结果表明CEN相比较MCC、ACC评价指标均具有很高的一致性程度和一定的判别性程度。故CEN分类器评价指标对分类器性能的评价效果更优;最后,在UCI中12个基准数据集(包括8个多类数据集和4个二类数据集)和6种常见的分类器(包括2个二类分类器和4个多类分类器)获得的分类结果上对分类器评价指标CEN与MCC、ACC进行性能分析,进一步验证了 CEN具有更强的辨别性。本文通过全面地比较CEN、MCC和ACC对分类器性能的评价,得出分类器性能评价指标CEN更具有应用性。"
1235,集成学习算法在个人信用评估中的应用,"随着经济的发展,人们通过使用信用卡、蚂蚁借呗等新型产品进行提前消费以改变量入为出的传统消费观念。与此同时,形形色色的借贷方法开始流行,各类线上线下的资金借贷方式也变得越来越普遍。但从另一种角度来看,一种形势的盛行往往会引起一系列新问题的产生,当今时代信贷消费方式的流行也不例外。因而,由此所引发的客户违约问题严重影响了信贷行业的发展,进而阻碍了国家的经济发展。这一现象使得现有的信用评估体系面临着巨大的挑战,个人信用评估逐步成为信贷这一行业的研究热点,引入更有效的评估方法将更有助于经济的发展。申请贷款的客户的等级主要分为违约和不违约两种类别,可以将其看作一个分类问题进行研究。对该类问题的研究,主要是对申请贷款客户的个人经济条件、财产情况等个人属性以及历史信用记录建立分类模型,从而达到评估客户信用的目的。本文对国外某银行及国内某贷款机构所提供的金融信用数据集进行了系统的预处理,采用贝叶斯优化算法对模型进行参数优化,基于三种不同的模型对特征进行重要性分析。然后基于Bagging和Boosting两种集成学习的代表算法以及Stacking集成学习算法训练模型。其中Stacking集成分别以随机森林、支持向量机及LightGBM为初级学习器、对数几率回归为次级学习器构建评估模型。此外,本文还加入了对数几率回归、支持向量机、k近邻、决策树、神经网络等简单分类算法来进行比较。最后,使用Friedman及Nemenyi两种检验方法来比较这些模型,并绘制Friedman检验图进一步验证。基于上述模型使用10折交叉验证,验证结果表明Bagging和Boosting这两种集成学习算法训练的模型都起到了一定的性能提升作用,并且后者得到的效果更好,但使用Stacking集成模型的效果并不理想,未能有效地提升分类性能。整体来说,集成算法分类效果还是优于传统单一算法。最后,比较两种检验方法的结果可知,在置信度为95%的条件下认为部分算法的性能不同。"
1236,南昌市房价时空分布特征及驱动因素分析,"住房是人们生活中的必需品,关于住房价格问题的讨论多年来经久不衰,房价问题关乎民生的根本。随着中国经济的快速发展,如何平衡人民生活水平与日益增长的房价,已经成为了社会舆论非常重视的话题。房价在不同地区的异同、哪些因素造成了高房价以及房价在长期的变化趋势,这些问题成为了学界探讨的主要内容。研究房价的影响因素和房价变化的时空特征,既能在宏观上帮助相关部门以更加科学的视角制定和调整相关政策,更好地进行市场调控;也能从微观上揭示房价可能的变化规律和影响因素的驱动作用,有助于理解房地产市场。本研究根据南昌市2016年7月至2018年6月共24期的692个商品住宅均价,结合与楼盘相关的若干空间与属性特征,采用地理加权回归方法构建房价的回归模型,探究房价影响因素在空间上的分异。同时分别利用BP神经网络与随机森林算法拟合房价模型,计算每个特征的重要性,并作出房价空间分布格局的预测。进而利用时空立方体探究南昌市房价的时空分布特征以及影响因素的变化。本文的主要结论如下:(1)基于地理加权回归构建的房价模型显示,所有选取的因素均对房价有着一定影响:区位、自然景观、周边配套的便捷性等因素对房价有着比较明显的负向影响,而绿化率、物业费等因素对房价的影响是正向的。且不同的影响因素在空间分布上呈现出了一定的差异。(2)基于随机森林的房价预测模型相较于BP神经网络表现出更优效果,适合对新的房价数据集进行模拟预测。空间分布格局的预测结果表现出显著的空间分异特征,在赣江沿岸呈现高值聚集模式,而远离赣江的区域均为低值,同时房价拟合结果在老城区内误差相对较小,相对较大误差区域分布在一些新兴发展区域。(3)根据影响因素重要性预测结果,占地面积、容积率、楼栋总数等楼盘水平因素对房价的影响程度很小,特征重要性从大到小分别为楼盘与赣江的距离、所属区域、板块评级、地铁站可达性等。且空间特征变量的重要性超过78%,表明南昌市房价的空间分异主要由空间特征变量所解释。(4)南昌市的房价在时空尺度上有着非常明显的分异特征,沿江区域和中心城区以时空热点模式为主导分布,而城市外围区域主要表现为时空冷点模式。且时空热点区域的强度从未减弱,时空冷点区域有逐渐消失的趋势,南昌市的房价将进一步上涨。"
1237,几类财务危机预警模型比较研究,"近年来,在中国市场有大量企业挂牌上市的同时,也有越来越多的企业被迫破产清算。不断深化的全球化进程,严峻的经济形势,激烈的市场竞争,使得企业面临着越来越大的压力。而财务是企业的命脉,是企业赖以生存的根本与保障,财务出现危机意味着企业面临破产倒闭的风险,这不仅会对企业经营者造成损失,也会影响到投资者的利益,严重的甚至会对上下游企业造成一定影响。故而关注企业的财务状况,进行科学的财务预警是具有重大的现实意义的。本文选取了偿债能力、营运能力、盈利能力和成长能力4个方面共17个财务指标,以及绩效评价指标、诉讼仲裁指标和风险评价指标3个方面共5个非财务指标构建指标体系。基于沪深证券交易所A股制造业上市公司,将2018年被予以退市风险警示的43家企业作为*ST组,随机抽取等量的财务正常的企业作为Normal组,以7:3的比例划分训练组和测试组。对数据进行缺失值处理后,进行指标的显著性检验,剔除不显著的指标,再运用主成分分析法对数据进行降维,然后基于降维后的数据,分别建立SVM模型、Logistic模型、“串联”组合方式的SVM-Logistic组合模型和“并联”组合方式的SVM-Logistic组合模型,最后对这四种模型的预测结果进行比较分析。实证结果表明,就指标变量而言,利润因子对模型影响最大,这也符合企业追求利益最大化的目标,企业应多关注这方面的指标,及时发现问题并采取相应措施。就模型而言,组合模型的预测准确率明显高于单一模型,且稳定性良好。其中“并联”组合方式的SVM-Logistic组合模型较“串联”组合方式的SVM-Logistic组合模型分类准确率更高,分类效果更稳定。企业可以多关注组合模型在财务预警方面的应用,尝试不同模型按照多种组合方式进行组合,以期达到更好的预测效果。"
1238,在线虚假评论对消费者购买行为影响研究,"在线评论是消费者获取产品信息的重要来源,在消费者购买行为中发挥重要作用。然而,这种重要作用被别有用心的商家所利用,通过雇人撰写虚假评论的方式试图操纵在线评论,干扰消费者对产品的认识,误导消费者购买决策。在线虚假评论的存在严重影响了消费者的判断,极大降低了在线评论的可信度与参考价值。虽然在线虚假评论广泛存在于电子商务平台,已成为影响电子商务健康发展的严峻问题,消费者的购买行为也日益受到虚假评论的影响,但学术领域关于在线虚假评论与消费者购买行为的研究却相对缺乏。本文以在线虚假评论背景下的消费者购买行为为研究中心,重点关注当在线虚假评论为正面评论时,虚假评论对消费者购买行为的影响以及背后的影响机制。为解决本文的研究问题,本研究设计两个实验。实验一研究消费者能否识别在线虚假评论对消费者购买意愿的影响。研究表明,当消费者没有识别出虚假评论时,正面的虚假评论会显著提升消费者购买意愿。但当消费者识别出虚假评论时,正面的虚假评论会显著降低消费者购买意愿,并且此时在线虚假评论对购买意愿的降低程度大于消费者未识别出在线虚假评论时对购买意愿的提升程度。实验二研究影响消费者识别在线虚假评论的评论特征因素,以及虚假评论对消费者购买行为的影响机制,其中消费者对虚假评论的识别通过消费者对评论的信任程度来反映,另外对购买行为的影响从消费者购买意愿与消费者回避意愿两方面探讨。研究表明,消费者信任在虚假评论识别特征因素与消费者购买行为中发挥中介作用。消费者对评论者身份披露程度低的评论(vs评论者身份披露程度高评论)、过长或过短的评论(vs中等长度评论)、情感极端的评论(vs情感中性评论)表现出更低的信任程度,通过显著降低消费者对评论的信任程度,进而显著降低消费者对该产品的购买意愿,以及进一步引发消费者对该商家以及类似商家的回避意愿。本研究从消费者行为角度,深入研究在线虚假评论对消费者购买行为的影响,丰富了在线评论以及在线虚假评论领域的研究。研究结果对帮助消费者识别在线虚假评论从而避免受虚假评论的误导,引导在线商家正视采用虚假评论产生的不良后果,以及促进电子商务平台形成正当有序的竞争环境具有一定的实践指导意义。"
1239,基于领域情感分析的潜在客户识别方法研究,"潜在客户指能为企业在未来发展阶段带来盈利的一类群体,准确识别潜在客户可为企业精准营销,扩大产品市场占有率,提高核心竞争力等带来多方面帮助,是一项重要的研究内容。社交媒体环境下的用户生成内容,蕴含着丰富的情感信息,其中包括对于产品需求、品牌感知、购买意愿等内容的情感态度,研究表明用户的情感与购买意愿具有相关性,情感信息有助于企业发现潜在客户。但是,目前情感分析的主要工具情感词典无法很好的适应领域依赖性,无法及时覆盖社交媒体中的网络新词和准确识别未登录候选词的情感倾向,因此需要研究领域情感词典的构建方法。同时在识别潜在客户的过程中,由于用户生成内容文本不规范、情感随主题不断变化,且存在目标潜在客户群体所占比例偏低等数据不平衡问题,这些为潜在客户的识别带来困难。论文聚焦社交媒体下的汽车领域,构建了汽车领域的情感词典用于文本情感分析,同时将情感词典应用于不平衡数据集下的潜在客户识别任务中,设计联合领域情感主题的潜在客户识别方法,以发现具有潜在购车意向的用户。本文首先梳理了文本情感分析和潜在客户识别的研究现状,对情感词典的构建流程和文本分析中的特征选择、特征筛选和常用分类算法进行了介绍。其次,围绕情感分析最常用的工具情感词典,研究了情感词的情感极性判别规则。针对目前在构建情感词典的过程中使用单一识别算法存在的缺点,设计了一种改进的集成规则,提出了一种社交媒体环境下领域情感词典自动构建方法。接着,本文分析了用户生成内容中存在的情感主题信息,并将领域情感词典加入到联合情感主题模型中作为后验信息提取出情感主题特征,在此基础上进行潜在客户识别的特征工程研究并构造特征集合。另外,针对实际数据中存在的类别不平衡情况,设计了一种样本重抽样方法和一种针对不平衡数据的多样集成框架共同作用于数据倾斜下的潜在客户识别任务。最后,使用真实的社交媒体文本语料进行实验研究,验证本文所提方法。对比实验表明,本文提出的领域情感词典构建方法和联合领域情感主题的潜在客户识别方法在不同的对照组实验中均显示出良好的表现。本文在理论上对领域情感词典的构建、不平衡分类等内容进行了深入的研究,在实践中对企业发现潜在客户提供了解决方法,具有一定的理论意义和实践价值。"
1240,基于关联分析和判别分析的食品网购订单的研究,"现如今人类已经进入互联网、物联网时代,电子商务的快速发展给人们带来了便利,网上购物逐渐成为主流方式。从服装到基本食品的网购,人们享受到了更多的便利。越来越多的人选择美团网、饿了么网、百度糯米等进行网上订餐,大量的评论信息出现在人们视野里,人们通过这些评论信息作出购买决策,但是许多评论信息长而复杂,并不能一眼就能看出其情感趋向,用户通常综和多条评论的情感取向后作出购买决策。而需要定外卖或食品团购的用户大多数属于上班族,节约时间对于他们来说很重要,因为时间原因,用户不能够逐条的阅读评论,因此快速的将评论信息进行情感分类很有必要。本文通过利用网络爬虫技术,以食品网络团购的评论数据为例,采用基于机器学习的方法和基于语义的方法对其进行情感分类,创建食品网络团购甜品类专属评论情感词典。分类效果表明,在数据集不平衡的情况下基于语义的情感判别法稍优于机器学习方法;在数据平衡的情况下,基于机器学习的分类方法更优;在基于机器学习的方法中,随机森林判别法分类效果最优。另外,商品与商品之间存在着某种关联,为了解决大数据关联问题,本文选取饿了么网上外卖平台的某商家外卖订单数据进行关联分析,主要针对菜品与菜品之间的关联规则,从不同的角度挖掘其关联关系,建立菜品订购推荐系统,为某些无套餐商家提供菜品组合销售的依据,对于很多套餐商家而言,他们一般通过经验来定义套餐,而本文的定量关联分析也为这部分商家提供了意见,可以作为其套餐策略的补充。"
1241,关于酒店评论情感倾向的统计分析,"随着互联网+的逐渐普及,越来越多的商品采取线上的形式进行销售,不仅包括实物类商品,还有诸多服务类商品(酒店预订、在线打车、家政服务等)。消费者也不仅仅是商品信息的获取方,更多时候可以作为信息的输出方,对商品进行评价、描述、建议,海量的商品加上海量的数据,这也导致互联网的信息量呈指数型的增长。通过对这些文本信息进行分析,识别出潜在有价值的内容,了解这些信息的情感倾向――积极或是消极等,有助于挖掘出其中更有价值的内容,帮助商家获取新的市场机遇,给出消费者更多更好的消费意见,给人们带来生活上的便利。但在如此海量级别的信息数据下,想要了解用户对商品的评价情感,只靠人力去解读这些信息,工作量巨大,还存在许多主观意识和客观环境的影响。因此,为了更方便迅速的了解用户对商品评价的情感趋势,提取大数据下的有效信息,本文采取机器学习和深度学习等方法,针对收集的酒店评论数据集(包含覃建波老师的10000条和网络爬虫获取的5000条酒店评论数据集,积极语料和消极语料的比例为2:1)来进行情感分类分析,为消费者和商家带来对于商品信息更为直观的认识。本文最终通过一系列的模型训练,选择出效果较为理想的模型,能够将评论数据进行情感倾向预测,更为直接的分析出消费者积极或是消极的情感。"
1242,基于几种常见模型的P2P网贷借款人信用风险控制对比研究,"近些年来P2P网贷后凭借其操作方便快捷、投资门槛低等优势爆发式增长,网贷平台的数量及交易规模连年递增。在当下互联网金融的背景下,已然成为一种有代表性的投资模式。我国P2P网贷行业的高速普及和发展在便利居民借贷、提高小微企业发展和丰富我国多层次金融市场等方面发挥了积极作用。当然面临着机遇的同时也存在着信用风险、技术风险和法律风险等诸多风险,其中最关键的是信用风险。在P2P行业中信用风险即是借款人违约风险。为保证提高各网贷平台的核心竞争力,P2P网贷走向成熟发展方向,解决信用风险控制问题迫在眉睫。针对目前我国P2P网贷的发展背景和现状,本文基于市场监管环境强劲有力、法律死角无漏洞下度量借款人信用风险,主要研究工作如下:1.为合理有效地构建借款人信用风险评估模型,现针对我国不健全的征信体系,在传统信用风险评估指标基础上结合平台自身特点建立模型。主要包括借款人基本信息、工作信息、信用信息、资产信息和借款信息,并基于原始指标构造新的特征还清比例,验证该变量对模型拟合有着重要意义。2.结合我国P2P网贷平台的发展现状和特点并分析借款人信用风险和成因,构建新的评价组合模型RF-LR模型。基于RF-LR的信用评估模型不仅具有随机森林平衡误差的优点,还具有Logistic回归解决多重共线性问题的特点。3.与常用的风险控制模型进行对比分析。利用人人贷的真实数据通过各类评估指标的结果可表明:基于RF-LR模型的借款人信用风险评估模型比Logistic回归、随机森林、kNN算法等具有更高的分类准确率。4.对Logistic回归和随机森林进行特征贡献度分析,研究发现“信用信息”、“借款信息”和“职业信息”是评估借款人信用风险的关键指标,据此可优化信用风险管理框架。"
1243,基于Spark平台的互联网信贷风控研究,"随着我国经济的快速发展,市场经济的深化,社会融资的规模也在不断的增长,民间的经济活动也是越来越活跃,与此同时,信用卡、住房贷款、汽车贷款、消费贷款等个人信贷业务也在迅速增长。随着贷款的总量不断增大,用户的违约的次数也在不断攀升,甚至部分银行也出现了不良贷款率不断上升的情况。因此,对用户贷款违约风险进行研究,评估风险等级,做好风控,在现实生活中对于小额信贷企业预防互联网金融风险也是极其重要的。互联网金融的迅速发展给传统金融模式带来了严峻的挑战,特别是在风险控制体系。衍生出了不少金融诈骗,恶意骗贷,“薅羊毛”等,在这些互联网金融阶段过程中风险控制最核心的部分就是信用审核,尤其是无抵押的互联网借贷,借款人往往利用信息不对称,伪造相关证件骗贷,给金融机构带来了极大的风险。近年来,随着大数据和机器学习技术飞速发展。大数据技术如Hadoop，Spark,HBase,Hive等架构软件开始部署运用在各行各业。在金融领域,大数据风控这一理念也油然而生,大数据风控是指通过运用大数据构建模型的方法对借款人进行风险控制和风险提示。相对于传统的风控技术,多由各金融机构自己的信贷风控团队以人工审核的方式进行风险控制。这种审核模式存在的最大问题就是审核速度慢,从审核到放款通常需要一周以上的时间,这无法适应如今瞬息万变的金融模式。但是大数据技术的发展完美的解决了这个问题,通过对用户的信息数据的学习和训练,能够快速的评估该用户的信用等级,可借贷金额等相关数据。通过这种多维度、大量数据的智能处理,批量标准化的执行流程,更能贴合信息发展时代风控业务的发展要求。"
1244,基于随机森林的兴农卡农户用信预测模型及应用研究,"近些年,农户生产经营活动不断发生变化,越来越多的农户逐渐由原始的自给自足的生产经营模式转变成了承包大面积土地的专业种植养殖户或家庭加工小作坊。为了解决这些农户的资金困难,很多设立在农村的商业银行的小支行也逐渐由办理单一的存取款业务,发展到目前提供形式多样的贷款理财产品业务,“兴农卡”作为一种类似于信用卡的小额自助类贷款产品,主要服务于广大农户,为农户或农村集体种植,养殖等农村作业经营活动提供有效的资金保障。本文在分析研究“兴农卡”农户的历史存款统计信息,交易统计信息以及相关征信信息的基础上,构建基于随机森林的“兴农卡”农户用信预测模型,然后对“兴农卡”农户的特征数据通过提取,清洗及特征选择后,对农户用信预测模型进行验证分析,结果表明,在保证准确率的前提下,基于随机森林的“兴农卡”农户用信预测模型预测农户用信行为的时间效率最高,最后应用局部可解释性模型LIME对模型的预测结果从业务逻辑上作可视化解释,增强机器学习模型的可信度,给该银行的其他业务产品乃至银行业相关产品的农户用信行为预测提供借鉴,提高银行的收益,在银行农户关系维护与营销方面都具有重要意义。"
1245,基于迁移学习的工业过程故障诊断方法研究与实现,"工业设备的结构日益复杂,对设备安全性和可靠性的要求也越来越高,对设备的故障进行实时监测和分析就显得十分必要。现在许多企业依然使用纸质点检、人工分析的工作方式,对检修人员的专业知识也有很高的要求,更重要的是,这个过程很可能存在着由于人工疏忽而产生的误差,造成对设备故障的漏判、误判。因此工业故障智能诊断技术的研究具有十分重要的意义。本文针对故障诊断问题中存在的有标记训练样本数量不足的问题,以迁移学习方法为基础,提出了两种故障诊断方法。针对源域和目标域同构的情况,将对抗思想和迁移学习相结合,提出了双重对抗迁移学习方法(Adversarial-Adversarial Transfer Learning,AATL)。利用编码器对源域和目标域数据进行特征提取,然后用一个域分类器评价源域和目标域分布差异,找到二者之间潜在的分布差异,通过对抗地训练编码器和域分类器,使源域和目标域在特征空间内分布相近。为进一步减小源域目标域分布差异带来的损失,在目标函数中加入了最大均值差异。在网络中加入一个与主网络目标相反的辅助网络,通过拉开主网络和辅助网络之间的距离,提高了主网络的学习能力,避免了对抗过程中“模式崩溃问题”的发生。针对源域和目标域异构的情况,提出了基于栈式稀疏自编码的异构迁移学习算法(Domain adaptive based on Sparse Auto-Encoders,DSAEs)。利用两个不同的栈式自编码器分别对源域和目标域数据提取相同维度的特征,提出域间中心距离的概念来评价源、目标域特征分布差异,将其加入到编码器的目标函数中,交替地更新两个编码器的参数,最终使源域和目标域在特征空间内分布相同,最后利用源域特征训练出分类器,并将其应用到目标问题的诊断中。对提出的双重对抗迁移学习方法,先后在凯斯西储大学轴承故障诊断标准数据集和某钢厂采集的轧机颤振历史数据集上进行了实验。实验结果显示,AATL的诊断精度较其他迁移学习算法有明显的提高,而对比于经典的机器学习算法,优势更加明显。通过对比实验,证明了辅助网络的加入提高了模型的收敛速度。对提出的基于栈式稀疏自编码的异构迁移学习算法,在手写数据集、西储大学轴承故障诊断标准数据集以及轧机颤振历史数据集上进行了实验,实验结果表明,不同源域数据辅助训练的分类器对目标任务有不同的性能。在目标域内标记数据不足的情况下,该方法的性能优于传统的机器学习方法。"
1246,采用网络表示学习的多源社交媒体事件分类,"当今时代,互联网已成为人们的必备工具之一。越来越多的人通过社交媒体(如:微博、朋友圈等)分享自己身边所发生的事。因此,通过分析和挖掘社交媒体上用户发布的大量数据可以获取到许多有用的信息。本文通过分析不同源的社交媒体数据,来对当今世界正在发生事件进行分类。不同源数据存在着一个最大的问题,即数据的异构性。本文利用多源事件数据之间的关系构建一个网络拓扑图,随后使用合适的网络表示学习算法将事件关系形成的网络拓扑图的节点进行学习,从而学习到事件之间的特征。最后,将得到图中节点的向量表示,同时使用主流的机器学习方法对其进行分类。具体而言,网络拓扑图的构建是通过对多个源的社交媒体事件数据进行分析,提取事件之间通用的特征,然后使用这些特征对事件进行关系运算从而得到一个多源社交媒体事件联系的网络拓扑图。此外,网络表示学习的算法结合目前主流的网络拓扑图表示学习算法,即node2vec网络表示学习算法,SDNE网络表示学习算法以及HOPE网络表示学习算法。将这三个网络表示学习算法学习得到的向量作为基础向量,然后使用其进行组合得到一个优于单体模式的向量,最后使用stacking模型融合多个机器学习算法来对该向量进行分类。为了对本文提出的模型进行测评,我们收集了一个包含三种不同源的社交媒体数据集(Flickr-Wiki-YouTube事件数据集)并在上面进行实验。通过多个实验验证了本文提出的网络拓扑图表征学习方法、多向量组合的方式以及多模型stacking的方法的有效性。"
1247,生物医学本体支持的元数据异质性研究与标准化应用,"背景:数据已经成为生物医学发展的重要驱动力,实现数据到知识转化的一个关键环节在于增强数据的机器可理解性。通用数据元素(common data element,CDE)的使用是提高机器对元数据理解的重要手段。随着生物医学领域可共享的数据越来越多,纳入到通用数据元素库中的数据元素也在迅速增长,探讨如何提升通用数据元素的质量对于促进数据的整合和共享具有重要的意义。方法:一方面,本研究根据ISO/IEC 11179标准建立了具有语义支持的CDE表示模型,并在模型的基础上,构建了可共享的、可重用的和具有语义支持的通用数据元素库。在本部分研究中,首先根据《国民体质与健康数据库》初步确定了库中的数据条,通过复用caDSR中的CDE以及新建方式形成CDE数据集;然后基于模型实现了CDE的OWL表示,并且借助于语义网工具实现了 CDE的质量检查;最后利用图数据库来存储文件,并提供SPARQL复杂查询功能。另一方面,本研究进行了生物医学领域元数据之间异质性的研究,建立了元数据之间可兼容性自动化的预测模型。在本部分研究中,首先从国际上使用广泛的公共数据库NCI caDSR中,选取了与临床试验关联度较高的流行病调查的数据元素,根据构建的CDE表示模型提取了数据元素的必要组分,在NCIT(National Cancer Institute Thesaurus)的支持下利用基于本体的语义相似度计算方法计算出每两个关联数据元素对应必要组分之间的相似度值。最后,基于CDE组分之间的相似度值,利用支持向量机(support vector machine,SVM)对相关数据元素之间的兼容性进行了预测。结果:本研究构建了数据元素通用用用表示模型。此模型以ISO/IEC 11179元数据标准的核心组分为基础,规定了利用本体术语实现语义标准化的方式,定义了这些核心组分之间的关系,并为数据元素分配唯一标识符,以OWL格式表示。利用此模型实现了《国民体质与健康数据库》中的数据元素的图数据库存储和检索。在caDSR数据库元数据异质性研究中,结果显示元数据的概念层存在较大的异质性。即使在人工判别认为可以实现数据统一的数据元素间,在概念层的定义上也存在有明显异质性。通过SVM实现了数据元素是否可以整合进行了判断,模型对于可直接整合、人工干预后可整合和不可整合三组判断的总体准确率为81.67%。结论:本研究建立了符合FAIR准则的数据元素通用表示模型,并以此为基础围绕《国民体质与健康数据库》数据元素,建立了可参考的通用数据元素库,为解决数据异质性造成的数据整合和共享的问题提供了一个初步的可行方案。针对目前CDE数据库中数据元素异质性严重,本研究构建了 CDE可兼容性的预测模型,为用户使用现有的CDE提供了工具支持。通过本研究,将为提升元数据质量,进而提升数据质量提供技术和工具的支持。"
1248,致密气储层测井综合评价方法研究,"致密气约占我国天然气产量的30%,在我国能源结构中占据重要地位。与常规天然气储层相比,致密气储层通常具有低孔低渗、埋藏深度大、成岩强度高、岩性致密、孔隙结构复杂和非均质性强等特点,给储层综合评价带来了巨大挑战,利用相关测井数据,结合机器学习等智能算法,建立精细的测井解释模型,开展综合的测井评价技术攻关既具有理论研究意义,也具有迫切的实用价值。本文以鄂尔多斯大牛地气田下石盒子组、山西组、太原组储层为研究对象,开展了致密砂岩测井综合评价方法的研究。首先,基于研究区石油地质、岩石物理实验、常规测井数据等资料,开展了储层“四性”关系及测井响应特征研究,为寻找对致密气储层敏感的流体识别方法和构建测井解释模型做准备。其次,结合目的层测试结果基于测井响应机理开展了流体识别方法研究,建立了曲线重叠法、反算声波时差法、Pickkt图版法、正态分布法、孔隙度差值比值法、电阻率差值与比值法六种流体识别方法;通过精细的岩心归位后,考虑岩心分辨率与测井分辨率的差异,采用相适应的分辨率窗长对岩心数据进行等权平均,建立了各层段岩心测量孔隙度和声波、密度测井值的经验关系式,并形成了储层参数处理模块,挂接到了Forward.NET平台上,达到了规模化处理的需要。最后,本文分别基于BPNN、SVM、KNN单一学习器以及集成学习器实现了储层流体识别,对比了不同分类学习器之间的性能差异,基于机器学习方法有效解决了致密气储层流体识别的难题;分别基于BPNN、SVM、GPR单一学习器以及集成学习器实现了储层参数的定量预测,对比了不同回归学习器之间的性能差异,探索了致密气储层参数预测新方法。本论文建立了流体识别方法及测井解释模型,提高了气层识别精度及储层参数计算准确度,实现了致密气储层的综合评价。研究结果为致密气储层测井综合评价提供了新的角度,为进一步扩大勘探成果提供了技术支持。"
1249,基于地质语义模型和机器学习的成矿远景区预测,"地质矿产工作经过长期积累形成了数据量巨大的地质资料,数据作为一种资源也受到人们越来越多的关注。如何利用已有的地质矿产数据,合理运用新的技术方法获取矿产资源研究所需信息,是当今重要研究方向。本文主要研究了基于地质文本数据的信息提取及机器学习在成矿远景区预测中的应用。通过构建地质语义模型,实现对文本数据的信息提取,确定研究区矿产概况;基于该矿产概况,结合相应地质数据,通过随机森林算法,实现成矿远景区预测。本研究以甘肃西秦岭区域为例,完成成矿远景区预测,为进一步勘察分析提供了参考依据。主要包括以下几个方面:(1)地质语义模型构建:通过研究分析构建地质矿产基础词典,利用基于长短时记忆和条件随机场算法的LUIS构建了地质语义模型。(2)矿产特征提取:结合地质矿产文本数据及地质语义模型,通过文本数据预处理、分词处理、词频统计等获取相应的文本数据实义词,统计矿种及区域地质特征中控矿要素相关内容,确定矿产概况。(3)成矿远景区预测:根据矿产概况获取相关地质数据,通过随机森林机器学习算法,实现成矿远景区预测。(4)甘肃西秦岭地区成矿远景区预测:以甘肃省西秦岭地区为例,验证方法可行性并实现成矿远景区预测。研究表明,本文构建的地质语义模型能够实现对文本数据的地质矿产信息提取,以提取的概况信息为方向,结合已有地质资料通过随机森林算法可实现成矿远景区预测。通过甘肃省西秦岭地区成矿远景区预测案例应用,证明了本文提出方法的可行性,结果为进一步的矿产分析提供了数据参考。"
1250,安宁河冕宁至西昌段滑坡发育特征及危险性评价,"安宁河冕宁至西昌段地处青藏高原的东南缘,除安宁河谷平原外,其余部位地形切割强烈,峡谷纵横,地形起伏较大。由于复杂的地质条件及环境条件,区域内滑坡灾害频发,对人民的生命财产安全、基础设施建设及运营(如高速公路、电站、水库等)甚至是生态环境都造成了较大的影响。在对安宁河冕宁至西昌段区域地质环境条件的分析基础之上,详细分析了该区滑坡发育特征及其控制因素,引入信息熵法对研究区内415处单体滑坡进行了危险性评价,将单体滑坡的危险性评价结果应用到区域滑坡危险性评价之中,指出传统区域滑坡危险性评价方法的不足,并首次引入XGBoost机器学习的方法完成了区域滑坡危险性评价,主要获得以下几点认识:(1)依据遥感解译结合现场调查验证的方法,查明研究区内共发育415处滑坡,发育密度为1.76处/10km~2,安宁河两岸滑坡分布极为不均,左岸滑坡发育密度是右岸的3.11倍。不同坡向的斜坡中滑坡发育程度明显不同,其中朝向南东、南西、正南、正西四个方向的斜坡中滑坡较多,此外滑坡主要发育在坡度为15°~35°的斜坡之中,在地形起伏度为100~150m的区域内发育密度最大,大多数滑坡的剖面形态呈现凸形的特征。(2)地层岩性对滑坡发育具有明显的控制作用,从滑坡发育数量来看,研究区内64.34%的滑坡发育在在三叠系上统、侏罗系、震旦系下统地层中,由滑坡发育密度可知区内最易滑的为震旦系下统地层。滑坡在各坡体结构类型中的发育密度具有着明显的区分度,这说明坡体结构类型对滑坡分布有着控制作用,其中顺向斜坡、散体结构斜坡及斜向倾外斜坡中易发生滑坡。(3)区内滑坡发育受构造活动的影响极为强烈,从空间分布特征来看,区内具有两条明显的滑坡集中分布带,其中集中带A位于安宁河东支断裂带两侧,集中带B位于热水河红莫断层北西侧,两集中带内滑坡发育密度均为8.7处/10km~2左右,约为区域内滑坡发育密度的5倍。河流水系及道路工程活动对研究区内滑坡发育亦具有控制作用。(4)以洛乃格村3组滑坡、黑砂河右岸滑坡、依子阿木滑坡为例,对野外现场调查的滑坡进行了危险性定性评价;综合考虑影响滑坡危险性的因素,在系统性、独立性等原则的指导下,建立了单体滑坡的危险性评价指标体系,引入信息熵法为各指标进行了客观赋权,并计算了415处滑坡的危险性值H,依据等间距分级法将单体滑坡的危险性分为3级,分别为:低危险性(H≤0.333)、中危险性(0.3330.667)。对比信息熵法的滑坡危险性评价结果与野外现场调查的滑坡危险性定性评价结果较为一致,说明单体滑坡危险性评价结果比较可靠。(5)在单体滑坡危险性的评价基础之上,将单体滑坡的危险性评价结果应用到区域滑坡危险性评价之中,首次引入XGBoost机器学习法进行区域滑坡危险性评价,调整XGBoost模型中的学习率(learning_rate)、迭代步数(n_estimators)回归树的最大深度(max_depth)、最小样本权重和(min_child_weight)等参数,使得训练机器学习模型的预测准确率高达87.74%,并将训练结果应用至全区,评价结果具有较高的准确性。"
1251,机器学习支持下多源遥感数据的岩性分类研究,"随着遥感技术的快速发展,遥感探测频谱范围不断拓宽、分辨率不断提高,可利用的数据源也不断增多。由于不同岩性单元在不同类型的数据源上具有不同的显示特征,如何综合多源遥感数据各自的优势,结合人工智能领域算法和模型,将其应用于遥感岩性制图是一项重大的课题,至今仍然存在较多方面值得探索和研究。结合遥感和GIS技术,选取3种各具优势的多源遥感数据―GF-1卫星数据、Landsat-8 OLI卫星数据和Sentinel-1A雷达数据,在完成影像预处理、干扰信息弱化、多源数据协同的基础上,构建局部Lanczos双对角化极限学习机模型和支持向量机模型分别对贵州德江地区进行岩性分类研究。本次研究对其它多源遥感数据协同处理提供一定的技术参考,也为其它人工智能算法引入遥感图像分类领域具有一定借鉴作用。取得的主要研究成果如下:(1)采用“抑制-掩膜-强迫不变-直方图均衡化”植被信息抑制方法,对贵州德江地区Landsat-8 OLI数据处理试验得出该方法能显著抑制原始影像中的植被信息。证明该方法是一种不需要先验知识和野外实地光谱数据,适用于地形复杂、阴影较多、植被覆盖中等地区的通用光学遥感图像植被信息抑制方法。(2)将高分辨率数据的纹理信息、中分辨率数据的波谱信息以及雷达数据的立体结构信息依次完成像素协同和特征协同处理。结果表明:纹理主成分变换融合方法在消除冗余数据、浓缩方差信息的同时,完整保留各地物的图像空间结构信息;而Gram-Schmidt变换融合法具有较强的综合表现能力,使得融合后的影像光谱保真度很好,各类地物边界更为明显,区分度更大。(3)利用多源协同数据,再辅以有用特征信息―光谱和地形数据,构建LBD-ELM模型和SVM模型对研究区进行岩性分类。研究结果得出:LBD-ELM模型总体分类精度为88.12%,Kappa系数为0.8534;而被广泛使用的SVM模型的总体分类精度为86.58%,Kappa系数为0.8268;LBD-ELM模型分类结果得到的图斑完整性更好,地物错分漏分现象更少。因此,整体而言LBD-ELM模型能够更大程度地满足遥感岩性制图需求。"
1252,基于数据驱动的机器学习水体提取算法研究,"地表水是地球上最常见也是最重要的资源之一,由于环境变化等因素的影响,地表水也会在空间域和时间域上发生变化。水资源易受土地利用变化、气候变化、人为活动等因素的影响。地表水的变化可能会导致洪水、热带区域的干旱等灾害,会造成巨大的经济损失和伤害。因此,监测地表水的变化是十分必要的。青藏高原是世界上最高的平原,因其独特的地貌特性而被称为“世界之脊”,在全球气候变化中起着非常重要的作用。在本文中,将重点研究这一区域的水体信息。遥感可以为地表水调查提供免费、可靠的信息,已成为分析和分发水体数据的重要信息来源。许多基于遥感影像的水体提取算法已经被提出并得到了广泛的应用。为了得到精确的水体分布信息,本文进行了以下工作:(1)首先围绕水体提取这一主题,系统的查阅了国内外的一些相关文献。然后按照时间的先后顺序,对这些方法的原理和问题进行了总结。对Landsat-8影像来说,传统的方法所利用的光谱信息有限,并且缺乏对空间信息的建模,所以在复杂环境下分类效果很差。对Sentinel-2影像来说,不同波段间的分辨率不同,所以数据处理较为复杂。(2)为了充分利用Landsat-8影像的空间信息和光谱信息,本文提出一种基于随机的全连接条件随机场的水体提取算法。该模型使用支持矢量机对水体的光谱信息进行建模,使用水体指数信息对它们的空间相关性进行建模,实现了空间信息与光谱信息的融合。(3)为了更加高效和准确的提取Sentinel-2影像中的水体信息,本文提出了一种基于U-Net网络改进的分割网络。U-Net网络可以很好的对影像进行分割,可以得到精确的分类结果。改进的网络包含了图像上采样过程,不需要对原始影像进行超分重建处理,提高了Sentinel-2数据处理效率。研究结果表明随机的全连接条件随机场可以有效的去除异常地物的干扰,显著的提高分类精度。改进的U-Net网络可以有效的抵挡云层阴影的干扰,并且取得了较高的分类精度。"
1253,基于机器学习的SD气田储量和产量预测算法研究,"得益于计算机速度的高速发展和机器学习技术的突飞猛进,基于大数据的解决方案和预测模型已经在工业界得到了广泛的认可和应用。在当今自动化和人工智能的时代,尽管机器学习技术已经在石油工程的许多领域得到了广泛的应用,但是很少有研究着眼于海量的气井井口生产数据,多数是利用测井地质参数和压裂施工参数给出储量或者产能的分级预测,并且对于输入数据的种类和精度有着严格的要求,需要消耗大量人力物力。气田井口生产数据规模相当庞大,极其适合利用机器学习技术气田生产动态信息的深入挖掘和分析,但目前这两者的结合应用研究较少。本文将未得到有效利用的气田生产数据与机器学习方法结合起来,实现动态储量和未来产气量的自动化、准确计算。通过本文的研究,主要完成了以下的研究工作:1、基于Cullender&Smith法和计算机数值计算,实现了关井井口压力到井底静压的精确折算,提出通过绘制线性折算物质平衡曲线计算储量的方法,并建立了对非线性折算物质平衡曲线进行转化以及最优化的方法。2、利用机器学习和计算机编程技术,训练了折算物质平衡曲线的线性/非线性分类器,在此基础上建立了SD气田基于关井折算物质平衡曲线预测动态储量的全自动流程和方法,并且利用Python编程语言予以了实现。3、利用自回归移动平均模型研究了SD气田各气井的开井累产气量数据,证实了其作为时间序列具备一定自相关性和偏相关性。4、设计并实现了基于长短时记忆的深度循环神经网络,将其用于预测未来单井开井累产气量,该方法可实现准确预测。本文的结果表明,通过将循环神经网络与自回归移动平均模型结合,可高效率地确定神经网络的超参数窗口长度,实现参数的优选并提高预测精度。"
1254,基于视觉纹理及机器学习的木板识别研究,"随着图像处理、人工智能等技术的发展,智能制造已成为当前追逐的热点。如今人们的生活质量大幅提高,对家居舒适要求也越来越高,尤其是木质家具的外观要求更加多样性。为了满足家具定制的个性化选择,工厂需要根据木板表面特性进行等级分类,并利用同类木板进行加工制造,从而满足消费者需求。在这种局面下,传统的人工手段无法适应智能家居行业的飞速发展。有鉴于此,本文针对算力的不同,提出了三种基于图像的木板识别方法。在低算力条件下,本文针对实际木板纹理的特点,采用了基于灰度共生矩阵(Gray-Level Co-occurrence Matrix)的纹理特征提取方法,并利用该特征实现了基于马氏距离(Mahalanobis Distance)和支持向量机(Support Vector Machine)的木板识别;在高算力条件下,结合木板图像识别精度的实际需求,设计了一种高精度木板识别的卷积神经网络(Convolutional Neural Networks)。本文的主要研究工作如下:一、木板图像数据的采集及预处理:本文利用的木板图像是在家具工厂中通过扫描仪进行现场采集。为了提高木板图像的质量,对采集后的图像进行了平滑滤波去噪等预处理,并探讨了纹理参数阈值设置及木板纹理特征的提取方法。考虑到灰度共生矩阵对于图像的位置、亮度、颜色等具有较好的鲁棒性,且能有效地描述空间结构信息,本文基于灰度共生矩阵提取了四个纹理参数,用于木板纹理的描述和度量。二、低算力分类方法用于木板识别:分别阐述了基于马氏距离和和支持向量机的木板纹理识别的原理,为后续实验章节提供基础。实验结果表明,基于灰度共生矩阵所提取的四个纹理参数,支持向量机的识别效果要优于基于马氏距离的识别效果。三、高算力分类方法用于木板识别:为了进一步提升木板识别的准确率,本文还将卷积神经网络用于木板识别。在现有卷积神经网络的理论和方法的基础上,采用TensorFlow框架,设计并搭建了一种包含11个隐藏层的卷积神经网络。利用实际采集的数据构造了训练集和测试集,并对网络的参数进行了调优。实验结果显示,本文搭建的卷积神经网络可获得高达98.8%的识别正确率,并保证了较好的时效性,能满足实际应用的要求。本文因应不同算力情况下提出的基于马氏距离、支持向量机以及卷积神经网络的木板纹理自动识别方法,不但具有一定的理论价值,而且对智能家居制造厂商实现基于木板纹理的自动分类、识别,提高效率,节约成本,具有较重要的实用价值。"
1255,基于机器学习的高光谱图像恢复算法研究,"进入21世纪后,高光谱遥感技术在农业、环境、医疗、生物等各个领域得到了广泛的应用,特别是在农作物监测和资源环境监测方面,利用高光谱丰富的空间信息和光谱信息可以准确得到作物生长情况以及环境污染情况。然而,外界环境的影响和仪器自身设备的限制,获得高质量的高光谱图像并不是那么简单。其一,在高光谱图像采集过程中,噪声的存在阻碍了高光谱数据的后续应用,例如分类、解混、反演等。因此高光谱的去噪是不可缺少的一步。其二,由于高光谱采集需要苛刻的天气条件和昂贵的仪器,使得高光谱图像获取的时间长、成本贵,因此研究从简单的自然图像中恢复高光谱信息显得极其有必要和有意义。本论文基于以上两点,主要贡献有以下三点:1、结合高光谱图像高空间相关性和光谱相关性的性质,利用马氏距离建立了非局部空间域光谱的相似性权值,用来表示高光谱图像内非局部范围内的像素统计分布,将这种分布融合进PCA算法中,通过主成分的选择起到去噪的目的。2、为了适应当前高光谱图像数据量大,更新周期快等特点,利用生成对抗网络(GAN)对高光谱数据进行批量快速去噪,依靠生成器和判别器的对抗学习,不仅能够有效地抑制高光谱图像中的噪声,而且可以很好地保留图像的细节纹理信息。3、利用当前GAN强大的图像生成能力,利用频谱归一化生成对抗网络(SN-GAN)从RGB自然图像中恢复高光谱图像波谱信息,一定程度上解决了GAN网络的判别器不易收敛的问题。不仅可以快速方便得到高光谱数据,而且可以快速得到与RGB影像具有相同空间分辨力的高质量无噪声的高光谱图像,大大地提高了高光谱图像的应用范围。通过实验证明,非局部的空间域光谱域PCA算法不仅很好地抑制了大量噪声,而且很好地保留了图片中边界信息。同时发现,将当前深度学习算法应用到遥感领域特别是高光谱图像恢复上,不仅能够在节省人力物力的同时获得高质量的高光谱数据,而且能够使高光谱图像适用当前大数据时代的背景,真正让高光谱图像走向商用的道路。"
1256,面向起重机远程监控的NB-IoT系统设计,"起重机在当今工业生产中,起着至关重要的作用。随着物联网和人工智能的不断发展,本文将物联网技术与机器学习算法引入到起重机的远程监控中,建立起重机远程监控系统。其设计的目标能实时监测起重机的运行状态,并使用人工智能技术对起重机的金属结构进行安全预警。到目前为止,国内外的一些企业结合物联网技术对起重机的监控也做出了很多的努力。虽然对起重机实现了监控的目的,但由于使用的局域网监控,造成监控距离短,较少对起重机整体结构进行综合评估。本文把窄带物联网(Narrow Band Internet of Things,NB-IoT)技术引入到起重机的监控中,同时采用机器学习算法中的支持向量机对起重机整体结构的健康状况进行安全预警,实现了起重机的远程监控。本文的主要研究如下:(1)总体设计:对起重机远程监控系统的关键组成进行了详细的分析,然后分析了物联网的架构,以及每层件架构中要实现的功能;同时对NB-IoT的技术优势进行了讲解,分别介绍了起重机监控终端和起重机监控云平台的设计;最后对起重机远程监控系统的架构设计进行了设计。(2)采集终端的设计:对采集终端的硬件进行设计与选型;采用销轴式传感器来采集起重机的起重质量;采用无线应变传感器来采集起重机金属结构的应力;采用起重机液压油油温传感器对起重机的油温进行监测;采用风速传感器对风速进行监测;采用定位模块对起重机的位置进行监测;采用温湿度传感器对起重机所处环境的温湿度进行监测;然后选用NB-IoT技术作为物联网的通信方式,进行数据传输;最后对通信协议进行了编写,实现了采集数据的上传和下发。(3)结构安全预警的设计:为了能够对起重机金属机构安全进行预警设计,使用了机器学习中的支持向量机算法,并使用k近邻算法进行对比;从数据库中取出所需的数据,对起重机金属结构健康状况进行安全预警,从而避免安全事故的发生。(4)云平台的设计:选用阿里云物联网套件作为起重机远程监控系统的云平台,节省了企业自建服务器的成本,能够使管理人员随时登录云平台以查看监控终端节点的工作状态。并选用阿里云数据库对数据进行存储,设计了5个数据库表,为了实现对数据的快速操作,对数据库表采用相同的主键。最后对系统的数据传输与功耗进行了测试,经测试满足系统需求。"
1257,基于数据驱动TBM掘进载荷预测与参数分析,"全断面硬岩隧道掘进机(Tunnel Boring Machine,TBM)是一种系统化、智能化、工厂化的高效能隧洞开挖施工机械,适用于长距离隧洞的施工,可完成开挖掘进、岩渣运输、通风排尘、导向控制、支护衬砌、风水电及材料等供应等工序。其中掘进载荷的大小对TBM的结构设计、刀盘刀具寿命、施工成本的控制,掘进参数的选择有重要的指导意义,故在掘进过程中预测掘进载荷显得十分重要。现有的载荷预测有经验理论公式、刀具破岩理论、载荷等效建模方法,进行载荷模型的建立,以实现载荷预测。但忽略了TBM施工过程中现场所记录数据包含的价值信息,以及缺少基于数据分析建立掘进载荷模型的方法。故有必要挖掘施工数据包含的价值信息,并基于数据建立高精度的载荷预测模型。本文以单一的敞开式单对水平支撑TBM为研究对象,采用数据驱动方法建立掘进载荷预测模型,研究了不同建模区间的模型预测性能以及参与建模的参数敏感度,比较不同参数参与下的载荷预测模型精度,得到高精度载荷预测模型,并与实测结果对比验证模型预测的有效性,为降低模型输入参数的维度及提升载荷模型预测精度提供基础理论和建模思路。本文的主要研究如下:(1)利用代理模型技术和重要参数识别技术相结合,建立不同掘进段对应的载荷模型,对比不同模型对同一预测段的预测效果,确定最优模型;分析建立不同载荷预测模型的方法,通过增加建模段的样本数据,建立具有持续预测载荷能力和高精度的预测载荷模型,实现预测掘进载荷的目的。(2)多维度参数建立掘进载荷模型和参数重要性的分析研究。基于上述建模过程的分析,增加模型的输入维度和增加建模的数据样本;采用机器学习方法,建立适应多种地质类型的载荷预测模型,进一步,分析基于模型的参数重要性,通过设置参数重要性阈值,分析对应不同阈值下的载荷模型精度,识别参与建模参数中影响较大的参数,为后续模型的调整和提高建模效率提供参考。(3)基于kriging模型识别掘进载荷关键参数的研究。对数据样本的参数进行分析,得到影响掘进载荷对应的参数系数值,并将其转化为参数权重占比,实现对影响掘进载荷参数的识别。利用测试函数,采用Sobol灵敏度分析法得到测试函数输入参数的总灵敏度,同时对测试函数采用基于kriging模型参数系数分析方法得到对应的参数的权重占比,对比两者结果,验证方法的正确性。"
1258,面向智能家居的ZigBee-WiFi网关研制与应用,"随着科技的进步,智能家居逐渐成为人们研究的热点。家庭网关作为智能家居系统的核心,主要负责智能家居系统网络的搭建与维护、数据的传输与处理、电器设备的集中管控等。本文从智能家居、短距离无线通信等技术的发展特点出发,针对当前家庭网关的缺陷以及家庭内部网络的特点,研发了一款ZigBee与WiFi短距离无线通信技术融合且通用性强的智能家居网关,本文主要内容如下:首先,对嵌入式Linux、ZigBee组网、WiFi组网技术进行介绍,在需求分析的基础上确定基于ARM-Linux开发平台将ZigBee与WiFi组网技术结合的网关总体方案。进一步,对智能家居网关硬件部分进行整体设计,确定ARM9主控制器S3C2440A与ZigBee协调器CC2530组合的网关硬件主体结构,对智能家居系统下的温湿度、气体、新风机、照明、窗帘等无线终端节点进行硬件设计。同时,对网关整体软件进行设计,包括创建交叉编译链、Linux系统内核剪裁与移植、建立SQLite3数据库、搭建Qt交叉开发环境等,基于ARM-Linux平台进行多进程程序框架、共享内存与SQLite3数据库组合存储的软件设计,以及对ZigBee协调器与WiFi模块的软件设计、TCP服务器与客户端的应用层通信协议设计,并结合总体需求自主开发匹配的ARM-Linux端上位管理软件与PC-Windows端上位管理软件。另外,从机器学习与智能家居相结合的研究出发,基于本文搭建的实验平台提出基于随机森林与XGBoost机器学习算法的融合模型,通过公共数据集对融合模型进行家庭电器用电事件识别、家庭电器负荷状态预测,并且设计线下预测与线上管理结合的系统节能策略,在PC-Windows端上位软件中设计节能实验界面并在网关整体测试环节对节能策略进行仿真实验。最后,基于ZigBee-WiFi网关搭建整体测试环境,对ZigBee-WiFi网关进行数据采集、设备控制、节能仿真演示等功能测试,并分别对ZigBee、WiFi进行网络性能测试。测试结果表明,该网关稳定可靠,满足本文网关设计的综合需求。"
1259,基于SCADA数据的风机故障诊断算法研究,"随着人们对环境的日益重视和传统能源的紧缺,近年来新能源的发展越来越迅速。风能作为新能源之一,在我国的电力供给中十分重要。风力电厂一般位于环境条件较为恶劣的地区,再加上设备本身的特点运行及维护成本很高,为此需要有合适的故障检测方法来提早发现故障,以降低运维成本。目前,风力发电机组普遍配备监控和数据采集(Supervisory Control and Data Acquisition,SCADA)系统。通过应用机器学习方法,可以将为SCADA系统采集的大量数据用于状态监测和故障检测。本文首先介绍了风机基本组成和SCADA系统,并说明了一些风电机组的常见故障。然后介绍了机器学习技术在风电机组故障诊断中的应用,包括数据的预处理,特征提取,常用建模方法,模型的验证。之后对本文使用的完整故障预测流程进行了说明,并结合实验说明各个步骤的意义及效果,最后对风机的多个组件进行了测试,并应用于整个风场的到相关的统计数据。本文的主要创新点如下:建模上提出基于随机森林特征选择的深度神经网络(RF-DNN)。用随机森林算法挑选出合适的特征后进行模型训练,模型通过对比深度神经网络和支持向量机验证深度神经网络有效性。输入输出的数据虽然为五分钟平均的数据点,也可以看做信号,故在此机器学习流程上,引入信号处理方法对算法进行优化。输入方面利用小波分解信号进行降噪处理,输出方面利用自适应滤波器降低误报警率。应用这些方法,可以得到更精确的输出,大大降低误报警率。通过对实际的SCADA数据,对风电机组的多个部件进行了实验,验证了该方法的有效性,并应用于整个风场。"
1260,非侵入式负荷监测的负荷分解与分类网络拓扑分析研究,"非侵入式负荷监测的负荷监测方法指的是,能够利用安放于特殊位置的装置,完成对整个架构内的所有设备的识别和监测,获得的分解结果可不仅让用户直接了解各设备的用电行为,并能够在基于用电行为,为更多的服务和技术提供庞大的数据基础和支撑。现有的常用的用电设备分解方案主要通过采集的电气设备的电气数据转换成电气特征作为训练数据,同时也有包括使用频率和使用时长等非电气数据的结合,然后运用优化算法或者是机器学习的模型等进行进一步的负荷监测。但目前阶段存在的问题是并没有很好的分解方法能够高通过单一监测点精确地识别设备。现实生活中,单一的检测方法是暂时做不到识别所有设备,所以本文将从实际出发,从另一角度提出新的方案。针对以上问题,本文提出基于网络拓扑的非侵入式用电负荷分解方法。首先,用电设备的电气信息需要进行采集,利用数据生成的技术对多种复杂用电组合情况进行模拟,并产生充分的训练数据。其次,使用目前相对优秀的机器学习算法进行测试,以避免在他人研究中测试设备数量及种类的限制与本文提供设备的不同产生不一致的算法结果。第三,基于现实的使用环境,抽象出其电气网络拓扑,进而生成网络拓扑结构,用于实现和模拟现实场景,并在此场景内使用遗传算法进行优化求解。在一定条件下,从用户角度出发,实现全局负荷分解。最后,本文采用常用的REDD公开数据以及某工厂的真实电气数据和网络拓扑进行试验,并且从两种不同的评判标准出发,由于从用户角度出发,我们从准确率(ACC)、F1-measure、均方根误差中,选择精确率作为本文的主要指标。实验结果表明所提出的基于网络拓扑的非侵入式用电负荷分解方法可以有效地实现全局用电负荷的分解,并能在现实条件中更好的应用,所以具有较高的泛化性能。"
1261,俄罗斯与中国口蹄疫疫情的综合监测与预警,"口蹄疫(Foot-and-mouth disease,FMD)是一种高度传染的牲畜疾病,自然发病率和死亡率都很高,曾多次在世界范围内爆发流行,严重危害动物健康和农牧业生产。口蹄疫的已有报道多集中于病毒结构和检测方法,而疫情的爆发预测与风险评估常被忽略。鉴于此,本论文通过机器学习和风险评估法构建了俄罗斯口蹄疫的风险预警模型,从而预测俄罗斯口蹄疫的爆发并量化口蹄疫的风险;使用空间自相关、标准差椭圆等方法分析了俄罗斯、蒙古、中国口蹄疫爆发的聚集情况和传播特点,从而研究俄罗斯与其农畜产品贸易国之间口蹄疫爆发的相互影响。在此基础上,通过分析中国口蹄疫爆发分布的特点进一步研究俄罗斯口蹄疫疫情对中国疫情的影响。此外,以口蹄疫病毒VP1基因保守区序列为模板设计探针序列,构建了荧光探针-氧化石墨烯(Graphene Oxide,GO)检测法以加强海关口岸对于口蹄疫的早期检测,减少经济损失。本论文主要的研究内容及结论如下:1 俄罗斯口蹄疫疫情的爆发预测与风险评估根据2005~2014年俄罗斯口蹄疫实际爆发数和口蹄疫关键词谷歌趋势数的Pearson和Spearman相关性系数,采用Ranker变量筛选法结合62种分类器构建了俄罗斯口蹄疫的定性预测模型。结果显示变量数目为8和15构建的分类模型灵敏度、特异性和准确性都达到了60%以上。其中以Complement NaiveBayes为分类器构建的模型效果优于其他分类器,其灵敏度、特异性和准确率分别达到60.00%、72.00%和70.00%,表明该分类器构建的定性预测模型具有较好的预测能力,可应用于实际口蹄疫爆发的监测。在俄罗斯口蹄疫爆发定性预测模型的基础上,以俄罗斯监测区的活体牛为研究对象,通过五层风险路径(情景树)构建了口蹄疫疫情定量风险评估模型;以俄罗斯监测区口蹄疫防控措施为研究对象,通过疫病防御措施评分表构建了口蹄疫防控措施的半定量风险评估模型。经过10,000次蒙特卡罗模拟抽样后,定量风险评估模型输出结果显示俄罗斯监测区牛感染口蹄疫的概率为7.22×10~(-7)(p)。从俄罗斯监测区出口牛中至少一例感染口蹄疫概率为0.0316(q)。俄罗斯每年出口的39530~50576头牛中预计感染口蹄疫的数量为0.0325头(e),表明俄监测区出口的牛依然存在携带口蹄疫的风险。半定量模型计算结果显示,俄罗斯口蹄疫防御系统存在一定风险,风险概率为1.84×10~(-5)。基于联合国粮食及农业组织官网提供的2010~2018年中国、蒙古和俄罗斯口蹄疫的爆发数、爆发病例数以及爆发地理坐标,通过疫病流行性分析、空间自相关分析、热点分析以及标准差椭圆分析对中、蒙、俄三国口蹄疫的爆发进行时、空聚类分析以及传播特点的研究。结果显示9月为中、蒙、俄三国共同的口蹄疫爆发高峰月;三个国家口蹄疫爆发在空间上的聚集年份不一致,且热点分散,三国边境未出现显著的热点;此外,三国口蹄疫的传播方向为西北―东南传播,口蹄疫爆发的平均中心多位于中国,表明三个国家口蹄疫爆发虽然存在时间和空间上的集群模式,但相互之间并无显著的相关性且中国是三个国家中的口蹄疫爆发重疫区。2 中国口蹄疫疫情聚类分析与口蹄疫病毒的早期检测使用季节流行性分析,空间自相关分析等对2010~2018年中国口蹄疫的爆发进行了较为全面的时间、空间聚类分析并利用爆发区的标准差椭圆和平均中心移动轨迹判断疫病的整体传播趋势。结果显示中国口蹄疫疫情主要集中在每年的上半年,3月与5月是口蹄疫的高频爆发月;中国口蹄疫疫情在空间上存在显著的聚集分布,且西藏、宁夏等地是口蹄疫集中爆发的热点区域,中国边界线上基本不存在大范围的爆发热点,表明中国口蹄疫的爆发受本国内部如气候、温度等因素影响较多,受外部因素影响较少。此外,以口蹄疫病毒VP1基因保守区序列为靶标设计了探针序列,将靶标DNA修饰荧光基团后作为能量供体,氧化石墨烯作为能量受体,建立了口蹄疫的荧光探针-GO检测法。并将其与传统口蹄疫检测法SYBR Green Real-Time PCR进行比较以确定该方法的可行性。实验结果表明,与SYBR Green Real-Time PCR相比,荧光探针-GO检测法灵敏度更强(50 nM),步骤更简单,基本不存在假阳性,更适用于口岸口蹄疫病毒的快速检测。"
1262,人工智能神经网络诊断腰椎间盘突出及病理特点的应用研究,"【目的】本研究旨应用一种以人工智能(Artificial Intelligence,AI)为基础所设计的全自动计算机辅助诊断系统(Computer-aided Diagnosis,CAD),定位腰椎核磁共振(Magnetic Resonance Imaging,MRI)图像中的椎间盘去诊断腰椎间盘突出,并分析出腰椎间盘Pfirrmann退变等级及MSU突出程度分型。计算疾病诊断的阳性率,分型结果的准确度、灵敏度、特异度和交并比,及人机大战的最终结果。探究所设计程序的先进性及CAD系统的临床必要性,为人工智能诊断脊柱其他疾病提供基础,同时为提高临床工作效率提供新途径。【方法】本研究将217位腰椎间盘突出(Lumbar Disc Herniation,LDH)患者的MRI影像学资料,分成训练组与测验组,对所设计的CAD系统进行训练和验证,其中运用区域卷积神经网络Faster-R-CNN(Region Convolution Neural Network,RCNN)目标检测技术进行椎体定位,进而通过椎体定位和选取椎间盘。对选取区域使用二元神经网络分类器进行LDH的诊断。使用像素强度直方图(Histogram of Pixel Intensity,HPI),局部二进制模式(Local Binary Pattern,LBP)和金字塔式梯度方向直方图(Pyramid Histogram of Oriented Gradients,PHOG)三种图像特征的识别计算机算法,并在多层感知器分类器的基础上对椎间盘进行Pfirrmann分型。使用关键点检测神经网络来定位MSU定义中的标记点。使用U-Net网络结构进行计算,给予MSU分类。最后通过准确度、灵敏度、特异度和交并比(Intersection-over-Union,IoU)作为标准对CAD功能进行评价,最终进行人机大战,获取实验数据并进行统计学分析,确定人工智能辅助的必要性。【结果】研究中本课题组利用在天津医科大学总医院影像中心所获取患者的MRI影像学资料的部分数据,验证了本团队所设计的人工智能在腰椎间盘诊断方面的各项性能。在椎间盘的定位方面,准确率可达到95%;腰椎间盘突出诊断检测方面,准确率为95.83%,特异性97.52%,灵敏度94.12%;Pfirrmann分型方面,准确率为82%。在MSU分类方面,关键点检测的平均误差为3像素,而分割过程的交并比为90%。在人机大战中,人工智能在腰椎间盘突出的诊断,MSU的分型以及做出诊断的整体时间上表现出明显优势。【结论】本课题组提出了一个完全自动化的CAD系统,可以在放射科医师和临床医师的工作流程中起到很好的辅助作用。腰椎间盘突出的MSU分型,可协助医生在面对不同类型的患者时,做出更适合的治疗方案,对于1-A、1-B型和2-A型的患者中多采用保守治疗,在2-B和2-AB型中多采用手术治疗,在1-AB和C型的治疗选择上需要多方面分析。椎间盘退变的Pfirrmann分型,从理论上讲,Pfirrmann水平越高,手术就越困难,为临床医生提供警示作用,另外此分型应用于术前评估可以有助于退行性脊柱侧凸患者的外科决策。以临床应用为目的,CAD的机能有着很好的表现。经广泛验证后,本团队的CAD系统有望应用于临床中,并将解决社区医院或那些缺乏专业医师且医疗水平较低的偏远医院,无法对LDH给予准确诊断及合理治疗的问题。"
1263,甲状腺微小乳头状癌中央区淋巴结转移的2种预测模型,"研究背景和目的:甲状腺微小乳头状癌(papillary thyroid microcarcinoma,PTMC)是指直径≤1cm的甲状腺乳头状癌(papillary thyroid carcinoma,PTC)。全球各国过去几十年甲状腺癌发病率持续上升,其中新增甲状腺癌患者超过50%为微小乳头状癌,而死亡率仍然相当稳定。虽然PTMC恶性程度一般较低,经规范化治疗后预后良好,但其中央区淋巴结转移(Central compartment lymph node metastasis,CLNM)率并不低。2010年,甲状腺癌在一些欧洲国家以及美国是女性中第四大常见肿瘤类型;在韩国女性群体中甲状腺癌居所有恶性肿瘤的第1位;我国卫生部统计报告显示甲状腺癌上升至女性恶性肿瘤的第3位。Lin的一项基于707篇文献的系统综述认为颈部超声检查加上细针穿刺后的细胞学检查可以早期识别甲状腺癌,但目前尚不清楚基于人群有针对性的筛查能否降低死亡率或改善患者的健康结果,筛查导致惰性甲状腺癌的鉴定,以及这些过度诊断的治疗,可能会增加患者危害的风险。另外诊断性放射线的暴露以及肥胖等也可能是原因之一。与此同时,甲状腺微小乳头状癌手术率的增多,据预测研究,估计到2018年甲状腺癌将成为美国女性中最常见的癌症,这增加了近3,107,000,000美元经济负担,使得甲状腺癌作为一项日益严重的临床和公共卫生问题被广泛讨论,目前,从微小乳头状癌的诊断到治疗仍有较大争议。在网络应用日益普遍的今天,每天我们都会产生大量的数据,传统的数据分析体系已经日渐无力,很多新的数据分析的方法应运而生,它们不单高效,并且能和当今的信息技术相对接,决策树模型和列线图是大数据分析时代的两种产物,本文为探究这两种方法在甲状腺微小乳头状癌中央区淋巴结转移的危险因素中的应用。方法:选取2016年1月至2018年12月首次就诊于天津医科大学总医院普外科的PTMC患者为研究对象。纳入标准1)初次行甲状腺癌手术;2)术后病理证实为甲状腺微小乳头状癌;3)行甲状腺腺叶+峡部切除或全切加中央区淋巴结清除术;4)具有完整临床及病理资料。排除标准1)复发性甲状腺癌;2)偶发性甲状腺癌未行中央区淋巴结清扫。单因素分析用卡方检验、单因素Logistic回归分析,多因素分析采用非条件Logistic回归分析,P0.05)。Logistic多因素回归模型分析,结果显示女性(OR=0.37,95%CI=(0.21-0.65)P<0.05)、年龄0.8cm(OR=1.70,95%CI=(1.02-2.84)P<0.05)是影响CLNM的独立危险因素(P0.05)。由列线图展示所示:男性、年龄<0.05。在决策树模型中发现,性别、年龄30岁和49岁、多原发灶,肿瘤侵出甲状腺被膜可以协助甲状腺微小乳头状癌CLNM的判断。训练样本的灵敏度为75.4%,特异度为69.8%,准确率为71.26%,Kappa系数为0.379,(P0.05)。结论:1.在Logistic多因素回归分析、列线图、决策树预测模型中都发现男性、年龄年龄<45岁、肿瘤大小、多原发灶,肿瘤侵出甲状腺被膜和甲状腺微小乳头状癌的CLNM有着显著的相关。2.Logistic多因素回归分析、列线图、决策树预测模型这三种方法在术前预测甲状腺微小乳头状癌CLNM中各有优势和特点,Logistic多因素回归分析作为最传统的方式,方便理解;列线图模型将各种因素的作用大小可视化处理,能够使因素之间的作用大小一目了然;决策树预测模型提供了一种树形结构,对于因素的分割,临界点的选取很有意义。3.我们的研究没有分析长期随访期间的数据,如疾病复发和无病生存时间,因此,我们不能直接得出结论,评分系统可以预测预后。其次,这项研究是在横截面设计中进行的,而不是纵向观察。第三,单中心验证不够准确。评分系统需要多中心验证来检查其预测价值。需要进行更长时间的进一步调查。"
1264,基于机器学习和Wi-Fi信号的室内商铺定位研究,"随着移动智能设备的普及以及互联网技术的突飞猛进,现代的生活方式也发生了极大的改变。如今,人们可以不受时间地点的限制使用移动设备接入互联网,享受科技进步为我们带来的巨大的物质和精神上的财富。位置服务(Loation Based Service,LBS)是作为时下智能移动终端都必备的基本功能,许多软件的功能实现都依赖于能够准确的定位到目标用户所处的具体位置为前提,比如天气预报、附近旅游景点推荐、汽车导航、美团外卖等软件。因此,如何精准的定位到待测目标的位置,具有极大的商业价值和市场前景。定位服务根据应用场景的不同主要分为室外定位和室内定位。在室外定位领域,因为受周边环境以及其他干扰因素的影响较小,传统的定位技术已经可以满足普通的定位需求。室内环境相对复杂,直接将室外定位相关技术移植到室内定位领域,无法获得令人满意的定位结果。而由于人们工作、娱乐、生活主要集中在室内环境,伴随着近年来Wi-Fi技术的蓬勃发展,围绕Wi-Fi信号进行室内定位也成为近年来许多专家学者研究的热点。目前,线下实体店消费市场受到互联网线上购物的巨大冲击,大型购物商场为了保持竞争力需要充分开发线下消费的独特优势,比如体验式购物,以及个性化定制消费等促销模式。在复杂的商场室内环境中,只有能够精准的获得顾客所在具体位置,后续的附加服务才能顺利进行。本文借助多个商场内一段时间的消费记录以及到店顾客在商场内进行活动的相关信息,针对目前无线室内定位技术的瓶颈,通过数据挖掘手段和机器学习算法,量化顾客在大型商场内所在的具体店铺与商场后台服务器所采集的实时信息的关系,设计了一套室内商铺定位方案,通过将室内商铺定位问题转化为分类问题,并在单个分类模型的基础上提出修正框架,从而提高了室内商铺定位的准确率。本文主要的工作包括:(1)分析传统室内定位所采用的技术,选取室内商铺定位的基准方案。(2)综合考量目前室内定位技术形式单一、只是简单的使用一种定位方法的,没有考虑各种方法的应用场景和互补性的现状,以及无法充分利用顾客和商铺在后台服务器所记录的信息这一情况,并重点针对此问题进行新的商铺定位方法的设计。(3)根据不同数据类型完成原始数据前期的数据清洗和特征构建工作。设计相关实验,采用单个机器学习算法解决室内商铺定位预测,并与传统的k-NN指纹定位方法作比较。(4)从算法层面上入手,在完成单个分类模型训练的基础上,提出针对多分类模型的k-NN修正框架和针对二分类模型的Stacking融合过程,进一步提升室内商铺定位的准确性。"
1265,基于随机矩阵和高斯混合模型的频谱感知算法研究,"当前,随着无线接入设备数量的不断增加,频谱资源越来越紧张。然而很多授权频段大部分时间都处于空闲状态,没有被授权用户使用。认知无线电作为能够提高频谱利用率的重要技术获得了研究人员越来越多的关注。频谱感知是认知无线电技术实现应用的重要一步,频谱感知的目标是通过不断检测目标频带来判断频带与主用户的状态,检测出频谱空穴。为了准确实时的计算出频谱空穴,频谱感知成为了无线通信领域的一个研究热点。本文主要研究基于随机矩阵理论和基于高斯混合模型的频谱感知算法。频谱感知技术研究主要包括两个方面:一是单用户频谱感知;二是多用户合作频谱感知。首先总结了现有的几种频谱感知算法,介绍了以发射机感知作为基础的能量检测算法和匹配滤波检测算法。由单用户频谱感知技术的一些缺点,引出了多用户合作频谱感知中的集中式合作频谱检测技术,重点介绍了比较成熟的数据融合方式集中式硬融合方式,包括该方式的“与”准则,“或”准则和“K秩”准则。然后简要介绍了随机矩阵理论在频谱感知方法中的应用。最后为了改进传统的频谱感知模型引入了基于机器学习的频谱感知模型,并且介绍了基于机器学习的频谱感知流程。首先研究了随机矩阵理论在频谱感知中的应用,因为基于随机矩阵理论的频谱感知算法计算复杂度比较高,所以提出了最大特征值与平均特征值之差的频谱感知算法(MSE)和能量检测算法(ED)级联组合的频谱感知算法(ED-MSE)。在高信噪比下采用能量检测算法进行频谱感知,降低算法的计算复杂度;在低信噪比下采用MSE算法频谱感知。ED-MSE算法的频谱感知性能比单独使用能量检测算法或MSE算法要更强。然后研究了基于机器学习理论的频谱感知算法,因为基于随机矩阵理论的频谱感知算法的判决门限的推导比较复杂且存在不准确等问题,同时为了提高衰减信道下的频谱感知性能,所以提出了小波变换和高斯混合模型相结合的多天线协作频谱感知方法。该方法结合多次用户多天线技术提高分集度,减少路径衰减、阴影对频谱感知性能的影响,为了减少噪声对频谱感知性能的影响,使用小波变换对信号进行降噪。然后使用机器学习中的高斯混合聚类算法进行训练,得到频谱感知分类器,避免了复杂的判决门限推导。最后使用训练好的分类器进行频谱感知。在实验仿真部分,在Rayleigh衰减信道和Rician衰减信道下进行了仿真,对比了几种不同特征的性能,以及和k-means聚类算法进行了性能比较,结果表明了采用MSE特征的基于小波变换和高斯混合模型的多天线协作频谱感知方法具有更好的频谱感知性能。"
1266,基于机器学习的无线网络信号识别技术研究,"随着现代无线通信技术的发展与普及,无线网络设备数量与网络规模等都在急剧膨胀,特别是在ISM频段由于不需授权即可使用,其信道空间变得十分拥挤和繁忙,准确的识别无线信号能够帮助人们更加高效地使用无线信道。同时在电子对抗中,对无线网络信号的识别能够对敌方进行有效的监测,使己方取得优势。因此无线网络信号识别技术不论是在民用领域还是军用领域均具有非常大的意义。无线信号识别技术主要分为两种:一种是基于最大似然判别的识别算法;另一种是基于特征提取的识别算法。最大似然方法是利用概率论和假设检验理论为工具,将待识别信号与典型信号进行比对,以代价函数最小化为原则,结合适当的门限进行比较,形成判决准则。而特征提取是建立在对信号的分类特征提取的基础之上的,从早期的幅度、频率、相位等参数,到后来的谱相关特征,都是基于这种思想。近年来研究提出了很多使用机器学习、深度学习的方法进行信号识别,相对与传统方法取得很好的效果。本文结合传统的基于特征提取的信号识别方法,结合机器学习方法,从无线信号的特征分析到特征提取与融合,最后基于对目标信号进行识别与分类。论文的主要工作有以下几项:(1)本文研究了当前无线信号识别所用到的特征参数,将现有的特征参数进行了归纳,将这些有特征物理意义的特征参数定义为显性特征参数,由于对于不同的识别目标所采用的特征参数也会有差异,本文基于条件熵提出了对显性特征参数的提取与融合方法。(2)为达到更好的识别效果,本文利用一维卷积神经网络对无线网络信号进行了特征提取,此处提取到的特征参数只是为了对信号进行分类而不具有特定的物理意义,因此称作隐性特征参数。对于隐性特征参数的提取是基于无线信号的谱图,而非原始信号,这样不仅可以提取到信号的稳定特征而且能够一定程度上消除噪声的影响。(3)本文提出了基于支持向量机的无线信号识别模型,在前述特征提取与融合的基础上,将其构建成为联合特征并作为支持向量机的输入进行训练和测试,对分类器进行优化处理,得到有效的分类器实现对无线网络信号的识别与分类。"
1267,基于机器学习的3D打印机传动故障诊断研究,"3D打印技术具备个性化、复杂化和快速化等方面的优势逐步被应用于各个领域。3D打印机是3D打印技术发展的过程中重要的研究对象,但在智能故障诊断在3D打印机领域的研究还不够完善。本文针对Delta 3D打印机的传动系统故障,借助姿态传感器从数据驱动角度进行故障诊断以及故障程度评估的研究。在本研究中提出了在传动系统的末端,即动平台安装姿态传感器的故障信息采集的方法,再结合机器学习模型,从浅层学习到深度学习建立了Delta 3D打印机的故障识别模型和故障程度评估模型。本文开展的主要研究工作如下:(1)通过分析Delta 3D打印机的结构和工作原理得出常见的故障形式。以小样本和高精度为目标,提出基于支持向量机结合工业级姿态传感器的故障诊断方法。该方法在Delta 3D打印机的动平台上安装工业级姿态传感器进行故障数据采集,再使用故障数据建立LS-SVM故障识别模型,该模型的平均精度达到了94.44%。此外,还使用了相同的数据建立了BPNN故障识别模型,其结果显示BPNN模型的故障识别精度或稳定性都远低于LS-SVM模型。(2)从降低3D打印机的故障模式识别的成本出发,建立一种基于低成本姿态传感器的故障模式识别模型。为了解决低成本姿态传感器带来的低精度和高噪声等问题,采用了基于ESN结合特征提取的故障识别方法。用低成本姿态传感器采集故障数据后建立了ESN的3D打印机故障识别模型,该模型能够识别更多类型的故障且故障识别精度为97.17%。同时,使用低成本传感器的故障数据建立了SVM、LPPSVM和PCASVM故障识别模型,其识别精度较低。(3)在实现3D打印机的故障识别后,还研究了3D打印机的故障程度方法,该方法是一种基于SAE的深度学习方法。在故障程度评估中,通过使用低成本姿态传感器采集了两个案例(即关节轴承A和关节轴承B)的不同故障程度信息。对两个案例的故障数据归一化和提取时域统计学特征和时频域特征提取来降低数据维度减少SAE模型计算时间和提高模型精度。以SAE隐含层作为样本矩阵,通过计算正常样本矩阵分别和不同故障程度样本矩阵的矩阵相似度作为指标拟合出了案例1和案例2故障程度变化趋势曲线。"
1268,基于机器学习算法的数据分类应用研究,"当下随着互联网的迅速发展,网络产生的信息的数量在以前所未有的速度增长,如何更好的整合这些庞大的数据,解决信息混乱的问题,目前是信息产业方面重点研究的课题之一。随着机器学习算法的不断创新,特别是深度学习的快速发展和分布式计算的成熟,使得对数据的整合处理成为可能。在数据挖掘和机器学习领域中,研究如何对数据划分种类具有非常重要的意义,一方面可以更有效地管理数据信息,另一方面也为后续的检测、识别等研究奠定了非常坚实的基础。本文的主要研究内容是:针对文本数据,以朴素贝叶斯方法为基础,概述了中文文本分类的理论和步骤以及朴素贝叶斯分类器的理论思想。实验阶段,数据集选择搜狗全网新闻数据集中的10个类别作为训练集和测试集,进行分词和删除停用词处理,然后使用TF-IDF进行特征降维处理,使用朴素贝叶斯分类器进行新闻数据分类,同时引入多个评价指标对模型最终的分类结果进行测评。最终朴素贝叶斯分类器在准确率、召回率和F1值这3个评价指标上都达到了 97%,取得了良好的效果。针对图像数据,以卷积神经网络的典型模型VGG-16为基础,提出了一种改进的方法,然后检验改进模型的效果。首先搭建了基于Windows平台的TensorFlow-GPU试验环境。然后针对传统VGG-16网络计算效率低等问题,提出了一种改进的VGG-16网络,改进过的VGG-16网络去掉了一层全连接层,用均值池化代替了最后一个最大值池化,增加了顶层卷积层中卷积核的数量,更改了最后一层全连接层的神经元个数和softmax回归层的类别数。使用Fine-tuning的VGG-16模型对kaggle猫狗图像进行分类,相较于原VGG-16模型,loss值减小了约0.1,准确率达到了 94.52%,提高了 1.74%。随后在102_Category_Flower数据集上进行测试,同样的在准确率和loss值上面都有了提高,这表明了改进的VGG-16模型效果更优。"
1269,考虑并行计算和数据驱动的显式拓扑优化研究,"拓扑优化是一种富有创造全新的设计思想能力的基础性的系统方法。无论是工业生产,还是科学研究中,都不断涌现出各式各样富有挑战性的结构设计问题,对结构优化设计方法提出了更高效,更精确,更富有市场竞争力的急切需求。然而,基于像素点的传统拓扑优化方法具有几何边界不清晰,制造困难,设计变量数目大,计算资源耗费巨大等缺点。因此,利用先进的计算机科学技术,发展高效和精确的拓扑优化方法成为未来结构优化领域发展的趋势之一。理论要以与实践相结合为目的,先进的算法要和前沿的科学计算技术相结合。基于此,本研究论文将并行计算和数据驱动引入基于可移动变形组件法的拓扑优化框架,提出基于可移动变形组件框架的大规模拓扑优化并行算法和基于可移动变形组件框架的数据驱动的实时拓扑优化方法。具体研究内容分为以下两个方面:(1)基于可移动变形组件框架的并行算法研究。随着分析和优化大型工程模型的需求日益增加,利用高效的并行计算库PETSc(Portable,Extensible Toolkit for Scientific Computation)和C++线性代数模板库Eigen,通过面向对象的设计方法将拓扑优化抽象为若干设计对象,提出了基于可移动变形组件框架的大规模并行算法,通过数值算例验证了该方法提升大规模拓扑优化有限元分析效率,为解决三维大规模拓扑优化问题提供高效率的计算工具。(2)基于机器学习的实时可移动变形组件法研究。利用可移动变形组件法(MMC)显式边界的特点,本文将机器学习技术与可移动变形组件法(MMC)显式拓扑优化框架相结合,利用支持向量回归(SVR)和K-邻近(KNN)机器学习模型建立外载荷和结构最优设计变量之间的函数映射关系。值得指出的是,与现有基于像素点的拓扑优化方法相比不同在于本文所提出的方法不仅具有大幅度降低训练数据量(从GB量级到MB量级)和参数空间维度的优点,还能在结构设计中根据外荷载提供良好的工程直觉。若干数值算例表明所提出的方法以一种综合的方式在实现实时拓扑优化方面表现出巨大的潜力。"
1270,一种基于堆叠模型的钓鱼网站检测方法,"随着互联网的高速发展,上网冲浪、浏览网页成为人们日常生活中越来越重要的习惯。不法分子通过假冒知名网站的登录页面,诱骗用户进行登录操作,进而获取用户的隐私信息,这种行为被称为网络钓鱼攻击。近年来,网络钓鱼攻击的数量呈现出惊人的增长趋势,在攻击形式上出现了很多变化。网络钓鱼攻击具有欺骗性强、针对性高和时效性短等特点,这些特点使得没有接受过网络钓鱼知识科普的人很难人为的识别钓鱼网站。在钓鱼网站检测领域中,目前在工业界应用最为广泛的是黑白名单加规则的方法。但是,钓鱼网站一般存活时间很短,这使得维护一个数量庞大且具有时效性的黑白名单数据库成本很高;另外,人为设定的规则很容易被钓鱼者通过其他方法来绕开规则的检测。近年来,在学术界研究最广泛的方法是通过机器学习的方法来检测钓鱼网站。这类方法具有准确率高,鲁棒性强等优点。但是,要训练机器学习模型,需要大量的数据,目前来说,有关钓鱼网站的公开数据集非常稀少;另外,过于复杂的系统识别的速度比较慢,做不到实时检测。为了应对上述问题,本文提出了一种基于堆叠(stacking)模型的使用多源特征的钓鱼网站检测方法。该方法能实时检测钓鱼网站,并且能识别钓鱼网站的假冒目标。具体的研究工作如下:1、在数据集方面,本文收集了一个真实的数据集,包含了53103个网页的URL、HTML和页面截图的图片数据,命名为50K-IPD。2、在多源特征方面,主要使用网站的URL、HTML源码和浏览器渲染后的页面截图三种来源特征;其中,URL和HTML的特征都是轻量级的且不依赖任何第三方提供的服务,这使得开发实时的钓鱼网站检测系统成为可能。3、在模型方面,设计了一种堆叠模型,改模型结合了GBDT、XGBoost和LightGBM三种机器学习算法,且具有多层的结构,使得不同算法之间能够形成优势互补,提高钓鱼网站检测系统的性能。该模型在50K-IPD数据集上达到了准确率98.6%、漏报率1.28%和误报率1.54%的性能表现。在与其他机器学习算法以及与同行提出的方法对比中,该模型都达到了最优。实验证明,本文提出的方法在钓鱼网站检测方面是可行的。4、更进一步的,在识别出钓鱼网站后,本文提出了识别钓鱼网站的假冒对象的方法。本文收集了一个包含9013个网页的页面截图数据集,命名为9K-PCD。根据钓鱼网页所假冒的对象不同划分为不同的类,共113个类,每个类有不少于10个的样本。在方法上,本文使用了深度卷积神经网络(CNN)来训练分类模型,最终在识别假冒对象上达到了准确率92.31%和F_1值93.66%的性能表现。"
1271,基于机器学习的人脸表情识别系统,"在大数据和人工智能大发展的背景下,人脸识别已经得到了较好的进展,各种算法能够以较高的识别率识别出图像中的人脸。在理论基础研究上有了进步以后,人脸识别在各种场景都得到了一部分的应用。可是随着应用的深入,人脸识别显示出了一定的局限性,比如实际场景除了识别人脸外还希望得到受测人的某些更深入的信息,比如性别、大概年龄段或受测试时的表情等等。其中人脸表情识别技术领域有着广阔的使用场景和市场空间,包括人机交互、智能控制、公共安全、智慧医疗等产业。本文针对智慧医疗中人脸表情识别技术应用的需求,设计了一个人脸表情识别系统。该系统能对即时采集的图片进行检测,判断是否存在人脸,若图片有人脸则对脸部表情进行分类,实现人脸表情的识别功能。本文主要研究内容如下:1.非限定情况下的人脸检测主要介绍了在检测人脸算法中归一化的像素差异特征的原理及应用,通过AdaBoost算法来挑出最有区分度的特征并组成一个强分类器,实现非限定情况下的人脸检测功能。2.人脸表情识别的特征提取列举了各种基于静态图像的表情特征提取方法和基于动态图像的表情特征提取方法,然后对各种表情特征提取算法进行分析比对,从其中选择鲁棒性和准确率都更为突出的卷积神经网络算法作为本系统对人脸表情识别的特征提取算法。3.人脸表情识别算法研究及实现介绍了网络共享的表情数据库,根据本系统应用场景的分析制作表情数据库。通过使用卷积神经网络模型来提取人脸表情特征,对人脸表情进行分类识别同时保证低耗时和防止过拟合。4.人脸表情识别系统的实现、优化与测试实现了系统受检测端和监控端的各种功能,并联系应用实际分析了传统表情识别方法效率差得问题,通过本系统的卷积神经网络优化方案解决精度低、鲁棒性弱和耗时长的问题,能够适应智慧医疗实际应用场景的需求。在本论文最后总结了人脸表情识别系统的研究成果与其中的创新点,在讨论课题研究不足的基础上探讨了未来的发展方向。"
1272,基于机器学习优化用户音乐喜好个性化推荐的研究,"互联网信息的飞速发展和音频视频压缩等技术的出现,使得数以亿计的用户可以访问各式各样的资源。在信息爆炸的时代,内容提供商需要解决如何有效地向用户推送符合用户喜好信息的问题,推荐系统因此应运而生。推荐系统是一种信息过滤系统,通过从大量数据集中过滤多余信息的方法,利用算法精确定位用户的偏向喜好,向目标用户推荐其可能喜欢的新的相关内容。其中,推荐系统的一个重要应用就是音乐推荐系统。推送的结果好坏不仅决定了用户使用体验度,也是衡量一个音乐资源提供商实力的标准,并且也很大程度地推动了音乐文化的发展。现有的音乐推荐系统方法还过于单一,收集的大量用户行为数据的价值没有被充分挖掘利用,推荐效果还有待提升。另外每个音乐用户都有属于自己的私人歌单,歌单中的歌曲呈顺序排列,如何把这种上下文关系与推荐算法结合起来也是一个有待解决的问题。机器学习是一门近几年来研究的热点,在银行、保险、交通、生物、医学等领域有着十分广泛的应用。而将机器学习算法应用到音乐推荐领域可以充分地挖掘数据价值,更好地为用户提供服务,提升平台实力,推动音乐文化的发展。机器学习算法种类繁多,不同的算法在不同的数据集上的效果不相同,对不同的算法的优缺点进行对比分析,完善现有音乐推荐系统是非常重要的事情。本文结合目前国内外的研究成果,分类概述了目前几种主流的音乐推荐方法:基于内容和协同过滤推荐,以及两者的加权混合模型。本文对Spotify提供的音乐数据集进行研究,用Word2vec编码方式代替One-hot编码,建立了歌曲之间的上下文联系并解决了维度过高的问题,用XGBoost对特征权重进行选择,对特征进行分类,对比各种加权方法的优劣,通过协同过滤算法,XGBoost模型、LightGBM模型和基于Word2vec特征的组合模型对用户是否会在接下来30天内再次听目标歌曲进行预测,从衡量推荐准确度的评价指标AUC入手,对预测结果进行分析评价,对比评估本文提出的新的预测方法在用户是否会再次听歌问题上的预测性能。实验结果证明,基于Word2vec特征的组合模型预测方法预测准确度高,能够更好地利用类别信息,有效提高预测模型的鲁棒性以及弥补了机器学习技术在音乐推荐领域的应用不深的状况,这是一种非常适合用于音乐推荐相关问题的方法。"
1273,基于特征重要度的安卓软件安全性研究,"随着移动互联网逐渐发展,移动设备己成为人们生活中重要一部分,Android平台因为其开放性和多样化等特点得以迅速发展。但与此同时,Android用户也受到越来越多的恶意应用程序的威胁。不仅仅是恶意软件,即使是应用市场中的Android应用程序也可能存在窃取用户隐私的问题。目前,针对Android软件安全性的研究逐渐深入,但是很少考虑到不同类别应用程序特征不同的问题。例如:通讯社交类的应用软件通常需要申请READ CONTACTS权限以获得用户的社交关系,但是,如果新闻阅读类软件申请该了权限,则可能存在权限肿胀的问题。正常软件如果申请了额外的权限,则有可能造成用户的隐私泄露,而普通用户很难在海量应用程序中分辨每一种应用程序申请的各类权限是否正常。本文针对现有研究的不足,考虑到不同种类的应用程序具有不同的行为,其所需要申请的权限也有所差异的问题,采用机器学习的方法对Android应用程序进行安全性检测,主要研究工作如下。1.本文分别使用逻辑回归算法和随机森林算法对Android应用程序进行分类,并分别对两种算法中不同特征的重要度进行了分析。实验仿真得到了94.9%的恶意软件检测准确率和89.2%的多分类精度。2.结合逻辑回归算法和随机森林算法的特点,提出了一种线性模型构建方法,以提高恶意软件检测准确率。本文采用不同的方案进行线性模型构建,实验仿真得到了95.0%的恶意软件检测准确率和91.4%的多分类精度。3.基于本文构建的线性检测模型,本文提出一种Android软件安全性检测模型。该模型不仅仅检测应用程序是否为恶意软件,还通过分析待检测应用程序拥有的权限特征和该应用所属类别的特征重要度,检测应用程序是否存在异常权限申请的行为,进而达到良性软件权限越权检测的目的。最后,本文设计并实现了Android软件安全性检测系统。该系统运用本文构建的模型对用户上传的APK进行检测,检测结果反馈应用程序的具体分类和可能存在的隐私泄露行为。"
1274,基于机器学习的程序语义理解,"程序语义理解对程序分析、漏洞检测和恶意代码检测等工作至关重要,然而程序语义理解是一个繁琐耗时的过程,因此需要通过自动化方法来帮助人们完成。机器学习能够从大量代码中学习相关信息,成为了一个研究热点。在设计机器学习模型时,如果能够将关于源代码的先验知识融入到数据的表示中,模型将能更好地理解程序的语义。和代码文本相比,控制流自动机和抽象语法树能够更直观地反映程序语言的结构特性。本文分别以控制流自动机、抽象语法树和程序图作为代码的表示,并设计相关的机器学习模型,分别学习代码不同方面的信息,得到代码的多维向量表示。本文的主要工作概括如下:(1)将控制流自动机作为代码表示,基于Weisfeiler-Lehman Graph kernel模型和Doc2vec模型设计了一种机器模型来学习代码的控制流信息,经过训练模型得到代码的多维表示向量。为了验证该模型能否有效地学习到代码的控制流信息,基于代码表示向量构建一个代码分类器,并在源代码分类任务上与现有的模型进行对比。结果表明,控制流自动机包含的代码信息较少,模型仅能够学习到部分信息,未达到预期目标。(2)由于抽象语法树比控制流自动机包含更多代码细节信息,所以将抽象语法树作为代码表示,在前一个模型的基础上,设计了一种机器学习模型学习代码的语法信息。经过训练,模型可以得到抽象语法树中的不同节点和代码的多维表示向量。在基于代码向量的代码分类任务上,该模型获得了97.93%的准确度,相比前一个模型提高了13.19%,并且高于现有的模型,表明该模型能够有效地学习到代码的控制流信息。此外,聚类实验结果表明模型能识别代码中相似的token并能区分差异大的token。(3)为了进一步改进模型的学习能力,设计了一种将控制流自动机和抽象语法树相结合的程序图,并在程序图上构建代码机器学习模型,学习代码的语法信息和控制流信息。经过训练,模型得到代码的多维表示向量。在基于代码向量的代码分类任务上,该模型获得了98.94%的准确度,优于前一个模型。此外,在进行的相似代码检索实验中,该模型也获得了最高的准确度。最后,代码向量可视化实验结果表明,经过该模型得到的代码向量具有较好的可区分度。这表明程序图更利于模型学习代码信息。"
1275,基于机器学习的移动端情绪分析系统的设计与实现,"随着社会的不断发展与进步,人们的关注点逐渐从生理需要转变到了心理需要,越来越多的人关注自己的身心健康和精神状况。在这样的情况下,由于其市场的需要性以及计算机科学的迅速发展,情绪识别受到了人们的广泛关注,成为了当今社会的研究热点,在医疗健康、线上教育、远程交互等多个领域都具有十分广阔的应用前景和落地场景。目前的情绪识别技术主要分为四个方向:基于面部表情/语音、人体行为、生理信号、语言文本。普遍来讲,这些领域的情绪识别都需要用户主动地输入相关信息,用户参与度很高且并不便捷。与此同时,移动智能手机快速发展,普通的智能手机上也搭载了许多的传感器设备,能够在用户无参与式的情况下自动采集人及周围环境的相关信息。本文结合移动感知技术的优势以及情绪识别的相关机器学习算法,设计并且实现了一套基于安卓手机移动端的情绪识别框架流程方法,与传统的单一机器学习算法对比,准确率有显著的提高。首先,本文设计的情绪识别算法本质上是一种多分类器集成算法,通过将经典的机器学习分类器进行集成从而得到更优的结果。在将传感器信息经过数据预处理后,得到合理的特征向量,输入到多分类器集成情绪识别算法中进行预测。传统多分类器集成算法的主要问题在于如何选择基分类器以及采用何种组合策略。为了解决这些问题,本文的创新性和主要工作如下:在基分类器的构造上,采用多样性策略增加其多样互补性;在基分类器的选择上,利用轮廓系数与聚类算法相结合,以此确定待融合分类器的数量,并采用不一致度量方法评价其差异性;在组合策略上,借鉴贝叶斯思想,基于其先验概率和类条件概率动态自适应学习基分类器的权重。其次,本文基于上述算法,对安卓手机移动端上的情绪识别系统进行了设计与实现,包括需求分析,架构设计以及最终的具体实现细节。通过该系统可以得到算法的训练数据,并与用户进行交互,真正地让“根据移动设备数据对用户进行情绪识别”这一需求变为了现实。在论文的最后,对本文提出的情绪识别算法与设计的系统分别进行了测试与分析,展示测试结果,总结其优势与不足,并且为以后的研究方向及工作进行了展望。"
1276,基于Elasticsearch的房地产大数据分析系统,"随着我国信息化社会进入高级发展阶段,大数据时代下的中国互联网数据产生速度越来越快、越来越分散。我国房地产市场与互联网建设随着社会经济一同迎来了迅速发展,传统的房地产数据分析方法已经明显感觉力不从心,各式各样的地产公司与销售网站如雨后春笋一般随处可见,如58同城、赶集网等。面向大数据分析的房地产数据分析技术应运而生,它不但能有效的处理海量资源,并且能将其转化为结构化的数据进行分析,以便于从业者通过合理配置房产资源促进社会经济发展。但就国内对房地产大数据的研究而言,更偏向于理论性的把握与诠释,缺乏对该领域系统的研究与实践,急需进一步的落地。本文主要做了以下工作:(1)搭建了ELK房地产大数据系统平台,利用弹性搜索节点集群实现对全网数据以简单易懂的“倒排索引”的方式建立索引,相较于传统数据检索工具对大数据的处理力不从心,实现高效、稳定、快速的检索;利用日志存放器的自定义插件配置规范数据格式,配置字段过滤;通过可视化工具将检索数据以简单美观多元的可视化界面展示,使房地产分析数据的变化与趋势一目了然。(2)本文通过机器学习Xgboost算法提炼出了影响房地产价格重要影响因子。并通过俄罗斯房地产数据集完成对系统的测试,该数据集除了包含户型、楼层、装修、地点、朝向、环境等房屋固态因素,还包括俄罗斯宏观经济和金融部门的相关数据等影响房屋的动态因素。(3)为房地产大数据系统增加安全增强模块,提供安全保障,主要配置了数据加密功能、合法性授权功能、集群扩展功能,确保系统正常持续运转中的安全。"
1277,基于深度学习的网页分类技术研究,"随着计算机技术的迅猛发展,互联网因其包含的海量信息而越来越多的成为了人们获取信息的主要场所。也有了更多的人乐于在互联网上分享自己的知识,这导致了网页数量的爆炸式增长。据1月31日中国互联网络信息中心(CNNIC)在京发布的第41次《中国互联网络发展状况统计报告》显示,截止至2017年12月,我国网民数量已经达到了7.72亿,占人口总数的55.8%,超过全球平均水准4.1个百分点,超过亚洲平均水准9.1个百分点。种种现象表明,互联网已经成为当代人们生活中必不可少的组成部分。而伴随着互联网的飞速发展,网络内容得到了极大的丰富。如何将这些海量的信息进行一个合理的筛选,让人们能快速,有效的找到自己想要的资源成为了一个重要而且有意义的问题。为了应对这种问题,人们发明了搜索引擎,能准确地查找人们所需要的信息,但将所有网页放在同一集合查找显然不是明智之举。调查显示,人们在进行信息检索时往往会围绕着一个主题。如果能将网页按页面类型进行分类将有效的提高信息检索的效率。将网页快速、有效的进行分类还能很好的提高搜索引擎对人们发出的信息检索请求的响应速度。目前在工业上网页分类多半是采用人工策略或者传统机器学习的方法。得益于深度学习技术的高速发展,越来越多的难题得以被解决。2014年卷积神经网络被证实能运用于文本分类上,为本篇论文提供了灵感。本篇论文研究了国内外的分类策略,例如贝叶斯、决策树和支持向量机等。对卷积神经网络的搭建过程及运行原理进行了探究,对神经网络的标准化处理,损失函数及梯度下降法做出了足够的了解,并对现今主流的深度卷积神经网络进行了分析,例如:Le Net、Alex Net、VGG Net等。通过以上研究,本文提出了一个用深度学习方法对网页进行特征提取,再将神经网络的特征输入到分类器进行分类的方法,通过使用深度学习的方法搭建了网页特征提取模型,有效的提高了网页分类方法的效果,并通过和人工策略和传统机器学习的分类策略进行对比,证明了该方法的有效性和可行性。"
1278,基于URL和网页特征的钓鱼检测技术,"钓鱼网站,通过模仿一些合法网站,如银行等,欺诈互联网用户,非法获取其财产,并一直威胁着人们的网络空间安全。因此人们需要更有效的技术来防御钓鱼网站攻击。本文设计了基于URL的特征以及结合URL和网页特征的检测方法。网站URL特征可以大致分为三类;基础特征、字母频率特征、编辑距离,其中编辑距离特征提取策略为本文创新特征。实验证明,该特征可以有效提高模型准确率,最终分别在4000和40000条网址数据集上准确率为0.946和0.959。特别是使用Aho-Corasick算法进行URL特征自动提取,平均处理时间为14.1 ms/条。本文还提出了三类网页特征:网站内外链数目、前向链接和站内链接、是否包含登录窗口。通过对GBDT分类器模型进行参数调优,最终结合URL和网页特征,模型准确率为0.976,可以有效抵御网络钓鱼攻击。由于网页特征提取耗时较久,本文提出基于MongoDB+ES,对海量网站特征值进行预存储和查询。其同步特征值和查询平均时间为0.317 ms/条和17.914 ms/条,大大提升了检测效率。由于网页访问的不确定性,本文训练了基于URL特征的GBDT分类器A和基于全部特征的GBDT分类器B,包括单个网址和批量网址检测两种功能。"
1279,基于XGBoost的还款概率预测模型分析与优化,"还款概率预测是针对每一个借款人,综合其基本信息、交易信息等数据来分析还款风险,进而预测出借款人的还款概率。随着小额贷款行业的快速发展,客户量激增的同时,坏账率也显著增长,造成了大量的经济损失。而传统的催收方法并不能满足日益增长的逾期数据和复杂多变的业务场景,本文以小额贷款逾期数据为研究对象,以提高催收效率为目标,进行了还款概率预测模型的研究。当前常见的催收评分模型,例如违约概率模型、损失程度模型等等,应用了数据挖掘和统计学方法来分析催收数据,但是存在模型精度较低、无法处理大批量数据等缺陷。国内外主流的信用风险评估方法,多采用机器学习算法构建风险预测模型,同时利用特征工程提高模型精度,但是这些方法都依赖于用户征信信息,本文借鉴了这些数据处理和模型构建的技巧,将机器学习算法应用于逾期数据的还款风险分析的同时,提出了一种基于催收特征的数据集构建方法,并设计了一个基于衰减权重的还款概率预测模型,最终利用模型输出未标签样本的还款概率,具体如下:(1)基于催收特征的数据集构建方法:该方法不需要征信数据仅依赖于逾期客户的原始数据,首先进行高维数据的处理,经过数据项过滤,并基于word2vec提取词向量模型,构建关键词网络并可视化,以提取关键词,为数据项的筛选提供参考。然后设计了数据项特征转化规则,将定性、客户地址、日期、手机号码等非数值类型的数据转化为数值特征或特征编码。接着利用z-score方法完成数据的归一化。最后设计了标签提取算法用以生成数据集样本的标签,该算法可以通过调整阈值,产生不同的标签结果,以客观地反应客户的还款意愿。(2)基于衰减权重的还款概率预测模型:首先引入样本的衰减权重,该权重根据牛顿冷却定律的温度-时间衰减函数计算得出。然后对加入衰减权重并调整参数后的XGBoost模型进行训练,接着对训练好的模型进行特征重要性分析,最后执行特征选择来剔除无效冗余的特征,重复模型的训练,输出满足要求的模型。本文基于5个月的逾期客户数据构建了144561个样本的数据集,为验证所构建的数据集可用性,采用逻辑回归、GBDT、随机森林和XGBoost四种成熟的机器学习方法进行测试,实验证明,该数据集在各种方法下都表现出稳定的性能,AUC值都稍高于0.73;针对基于XGBoost并进行优化过的还款概率预测模型,设计了多组实验进行测试和分析,将带有衰减权重和默认权重下的还款概率预测模型的预测性能进行对比,在三组对比实验下,衰减权重比默认权重有着显著的优势,将对比实验3的测试集AUC值提高至0.7021;测试了特征提取时使用了均值编码处理产品特征,实验结果表明,只有训练集和测试集的产品特征的特征分布一致时,均值编码将AUC值提高至0.7036,而分布不一致时,独热编码较为稳定,高于均值编码的结果。"
1280,基于机器学习的物料采购进度监视方法,"在定制装备企业中,个性化定制带来的订单数量不确定性和订单交货期不断缩短的需求对企业生产管理提出了更高要求,在更短周期内以低成本高效率生产出个性化订单产品是装备制造企业的不懈追求。订单及其数量的不确定性会导致依据订单产品物料清单进行物料准备的进度不可控,使得后续物料采购进度管理和采购进度控制难度大,进而影响后续的生产、装配等环节,导致项目订单拖期。面向订单设计和装配的定制装备企业的生产特点是制造过程占比少,大多数零部件是采购或外协得到,核心环节是研发和装配。制约这类项目进度的最大因素就是研发下达订单时间和装配所需的采购、外协物料的到货进度。由于上游供应商的各方面能力和进度等不确定,使得项目所需物料不可避免的出现拖期,从而波及订单装配进度,导致整个项目拖期。针对物料到货进度拖期导致项目拖期的这个问题,本文将基于机器学习理论,研究物料采购进度预测方法,实现对项目所需物料的进度进行监视,具体内容如下:(1)针对物料采购进度预测问题,首先根据企业采购业务流程,分析了物料采购进度影响因素。接着,利用特征工程的方法,从原始数据属性出发,结合企业物料采购实际情况,提取并构造特征,利用特征选择方法降低特征子集空间。最后,选择多个不同监督式分类器,使用企业真实物料采购数据,进行计算实验。对比分析了特征工程对模型预测结果得影响,解决了物料采购进度预测问题。(2)在相同数据和特征的基础上,采用多种非监督式机器学习方法,对企业真实数据进行探索,寻找物料采购进度数据中的内在特点和知识,从不同角度分析物料采购进度预测的可能性。(3)开发了一套面向定制装备的物料采购进度跟催系统。通过将本文所研究的机器学习预测模型和方法嵌入该系统,实现了对企业物料采购数据的分析和执行进度的预测,可以支撑采购人员的跟催决策,可以嵌入进企业ERP系统。本文针对物料采购进度历史数据进度预测问题,采用机器学习的方法,从数据预处理、特征工程到模型训练和预测,进行了系统的研究和运用,为企业在实际采购进度管理过程中的决策提供一定地智能辅助。"
1281,基于Google Earth Engine的中国北方四大沙地灌木覆盖度估算,"我国北方地区曾是风沙危害、水土流失较为严重的区域。上世纪80年代,随着“三北”防护林、京津风沙源治理等多项大型林业生态恢复工程的开展,中国北方干旱、半干旱区植被覆盖情况发生了巨大的变化。地处北方农牧交错带的四大沙地生态环境极为脆弱,对气候变化的响应十分剧烈。灌木作为该区域的优势植被对于风沙固定、食品/木材供给起着极为重要的作用。掌握该区域的灌木覆盖情况对于植被生长状况评估及荒漠化监测意义重大,由于当前大尺度、中高分辨率干旱地区灌木覆盖度遥感产品缺失,使得提出一套适用于干旱区沙地灌木覆盖度估算方法迫在眉睫。鉴此,本研究基于Google Earth Engine(GEE)遥感云平台,以Landsat-8地表反射率产品为数据源,结合Collect Earth样本收集器和野外调查样点,选取地处中国北方农牧交错带的四大沙地为研究区,开展针对干旱区沙地灌木植被覆盖度的定量估算。首先,深入的解释了Collect Earth样本收集器的原理及采样方法,并通过GEE平台完成数据处理流程及相关遥感特征参数的提取。然后,结合本研究全面系统的介绍了分类回归树(CART)、随机森林(RF)、支持向量机(SVM)三种机器学习算法,并对比了三种算法的优缺点。最后,分别构建三种机器学习估算模型并对模型估算精度进行验证。研究结果表明:(1)Collect Earth作为一款用于土地监测的开源软件,通过联合多个高时空分辨率地图存档,并提出了“增强视觉解译法”以提升样本采集精度,该方法可帮助研究人员通过超高分辨率影像快速采集样本。在地表异质性较强、植被较为稀疏的干旱区沙地,Collect Earth样本收集器可以有效地获取地面灌木覆盖度样本数据集,可以将灌木与高大乔木与草本植被进行有效区分,为灌木覆盖度估算奠定了基础;(2)本文基于GEE平台分别构建三种机器学习模型,三种模型均展现了对于四大沙地灌木覆盖度的估算能力。其中SVM模型估测效果最好,估算精度(Estimated Accuracy,EA)达到66.8%,均方根误差(Root Mean Square Error,RMSE)为7.04%,模型确定系数(R2)高达0.93。但SVM模型的缺点也是明显的,在植被以中低覆盖为主的干旱区沙地,模型构造的超平面对高覆盖地区预测能力不足,出现了较为严重的低估。另外两个模型预测能力相对较差,估算精度均为54%左右,其中CART模型和RF模型估算均方根误差分别为9.86%和9.75%,确定系数均为0.72;(3)GEE平台存储了公开可用的全球尺度上近40年的遥感数据,其中包括Landsat、Sentinel、MODIS等国际主要卫星遥感平台数据及其他遥感产品,整个数据存储量达到BP级。通过平台提供的应用编程接口(API)可完成各种复杂的地图运算,通过即时分布式并行化计算,极大的提高了运算速率。在超级计算机上需要几天或几周完成的数据计算、分析,在GEE平台上仅需几小时便能完成,大大降低了数据计算成本,降低数据冗余度。是今后国家尺度、洲际尺度、全球尺度遥感研究中必不可少的平台基础;总体来说,本研究提出了一种大尺度、中高分辨率、适用于干旱地区沙地、可与高大乔木和低矮草本区分的灌木覆盖度遥感快速估算的方法,可以对当前缺失大尺度、中等分辨率干旱地区灌木覆盖度遥感产品的现状形成有效补充。"
1282,基于AdaBoost算法多因子选股模型的应用研究,"机器学习是一门最新发展起来的计算机技术,越来越多的学者开始探索如何将这门技术与股票市场的投资结合起来,以期求得高收益率。AdaBoost算法是机器学习的一种方法,该算法首先构建判断正确率略高于随机猜测的弱分类器,然后通过对数据样本反复学习,最终将弱分类器训练为判断错误率极低的强分类器。本文的目的在于通过结合机器学习算法(AdaBoost算法)和多因子量化选股方法构建基于AdaBoost算法的多因子选股模型,以实现高于基准收益的超额收益。为了构建该选股模型,必须首先筛选出构建该模型所必须的因子。本文选取了优矿量化因子库中的244个因子作为备选因子,并对因子进行了有效性的筛选和独立性检验,最终筛选出10个因子作为构建模型的“独立有效因子组合”。该模型以这10个因子为弱分类器,对股票的收益率进行反复学习,并根据股票收率的情况对股票进行标识,其中,股票收益率排名前30%的分类标识为1,股票收益率排名后30%的分类标识为-1。AdaBoost算法先给所有股票赋以相同的权重,随后根据弱分类器的分类情况更新组合中股票的权重,分类正确则降低权重,分类错误随之增加权重。弱分类器通过AdaBoost机器学习算法进行反复训练,最后将训练好的弱分类器组合在一起,构成一个分类正确率很高的强分类器。本文基于AdaBoost算法构建的多因子选股模型在回测过程中表现优异,年化收益率为25.5%,比以沪深300股为基准的基准收益率高22.4%。"
1283,基于机器学习的Pan-cancer基因通路以及染色质绝缘子调控元件研究,"随着DNA测序技术的发展,人们获得DNA序列和基因表达数据的手段越来越多,影响生物信息技术发展的瓶颈,是开发优质的数据挖掘算法从大量的生物序列数据中挖掘出有价值的信息。传统的序列数据分析通过对比,映射等,分析序列的突变以及在基因组中空间结构信息,对于表达数据,则是分析不同基因的差异表达,试图找出规律。然而,这些方法只能获取数据本身的属性,对隐藏的规律无法很好的挖掘和展现。近年来,机器学习在数据挖掘,个性化推荐,自然语言处理,图像识别等领域得到了广泛的运用,通过不同种类的监督方式,对特征加权,提取出高泛化程度的特征。在此之前,机器学习分析生物信息学数据主要是以问题为导向,解决数据的分类问题。但是机器学习算法和生物学意义之间一直无法相互联系,只能通过分类的评价指标来判断模型对生物数据的泛化性能,在本文中,设计了两组实验(TCGA基因表达数据预测泛癌症基因通路预测和绝缘子序列预测)对不同的生物数据进行数据挖掘,并通过生物学意义来验证算法对生物数据的泛化性能。癌症基因图谱(The Cancer Genome Atlas,TCGA)收集了 33种常见的癌症11000多个癌症患者的表达数据,变异数据,甲基化数据等。根据TCGA基因表达数据预测泛癌症基因通路,能够对癌症进行早期诊断,并发现基因表达和癌症通路激活之间的关系。绝缘子在调控基因表达中发挥重要的作用,绝缘子位于增强子与基因之间时,会阻断或减弱增强子对基因表达的激活作用,这样的元件在基因治疗中有重要的作用,能够防止基因毒性和基因突变,提高基因治疗的安全性,准确的预测并识别绝缘子元件模序可以降低验证成本,提升预测的准确性,两组实验的结果都具有重要的意义,本文的主要贡献有:1)提出一个泛癌症基因通路分析框架XBPCPA,利用机器学习XGBoost算法,对9000多个样本1.8亿多个特征点进行数据整合,挖掘分析了泛癌症基因表达对通路激活情况的影响。设计了阈值控制超参数v对正负样本的分类边界进行控制,解决数据中样本不平衡的问题,提升分类评估参数AUC和AUPR。对比实验表明,XBPCPA框架对癌症通路预测具有较高的泛化性能。2)提出了一个基于半监督深度学习算法ladder的生物绝缘子预测算法Ladder-Seq,解决了序列数据标签小样本情况下的生物数据深度学习训练问题,该模型使用卷积操作修改ladder,使其适用于DNA序列数据,通过模型设计,参数优化,具有较好的收敛性能。3)对生物数据分类任务相关的特征作用模式进行深入研究,提出具有生物意义权重相关联的权重调整策略,在基因通路预测实验中,用生成树的节点表示基因表达和基因通路激活之间的相关关系,将ladder第一层的卷积核权重矩阵表示绝缘子序列中的模序(motif)。在泛癌症通路预测实验中,找到了大量具有重要意义的基因表达,并被已经发表的论文所验证。相关研究对于泛癌症的早期诊断具有重要意义。"
1284,基于CNN的显微光学切片断层成像图像去噪方法研究,"在脑科学研究中,神经元解剖学结构至关重要。传统的生物医学成像系统,在获取神经元结构方面,无法在实现大范围的高分辨成像的同时满足构建精细的神经环路的研究需求。显微光学切片断层成像系统拥有提供全脑三维高分辨数据集的能力,进而解决了这一难题。然而,受到成像环境和成像传感器状态的影响,显微光学切片断层成像图像数据在鼠脑轮廓区域内不可避免的存在图像噪声。此外,受到样本包埋剂的影响,显微光学切片断层成像图像数据在鼠脑轮廓区域外同样存在噪声。图像噪声的存在会干扰微弱的神经纤维信号的识别,进而阻碍神经科学相关研究的进行。传统的图像去噪方法,对于显微光学切片断层成像图像数据而言,无法在实现高效的去除噪声的同时,保留微弱的有效信号。相较于只能提取预定义的低层次图像特征的传统方法,卷积神经网络作为一种有监督的学习方法,能直接从图像数据中自发地学习深层次的图像特征,也因此具有更强的图像特征提取能力并在图像处理中得到广泛的应用并取得了不错的效果。本文针对显微光学切片断层成像图像数据中存在的图像噪声,设计了一套图像去噪方法。根据噪声所处位置,显微光学切片断层成像图像数据中的噪声可以分为鼠脑轮廓区域之外的噪声和鼠脑轮廓区域之内的噪声。对于存在于鼠脑轮廓之内的噪声,使用U-Net模型,以实现对处于鼠脑轮廓之内的噪声的去除。所设计的U-Net模型使用残差单元,将神经网络对图像特征的学习变为对噪声特征的学习。对照数据集和训练数据集的制作方面,使用噪声模型叠加自然图像的方式人工合成图像,解决了去噪研究中无法获得无噪声对照图像生成的问题以及卷积神经网络模型的训练集生成问题。对于存在于鼠脑轮廓之外的噪声,设计了一个拥有局部图像特征提取能力的神经网络,实现对鼠脑轮廓的分割,以去除鼠脑轮廓之外的噪声。综上,本文设计了一套用于显微光学切片断层成像图像数据的图像去噪方法。所设计的方法能够在高效去除图像噪声的同时,保留图像数据中微弱的有效信号,相比较传统图像去噪方法具有更好的去噪结果和信号保留能力。该方法有望推广到其他类型的生物医学图像数据的相关应用之中。"
1285,RNA二级结构预测方法的研究,"在过去几年的研究中科学家们发现有许多DNA片段转录成RNA,但是这些非编码RNA不翻译成蛋白质,它们有着特定的结构。这些RNA能够行使一些特定的功能,例如催化反应,调节基因表达等。一般功能和结构相关,这也使得人们不断的深入研究RNA的结构。通常情况下可以通过实验测得的RNA结构,主要有两种方法,核磁共振和X射线晶体衍射。但是实验测量的方法样品制作较困难,而且代价比较高,费时费力。如果能够使用计算机模拟RNA的结构,能够节约很多的人力和物力,因此使用计算的方法得到RNA的结构是一个研究热点。随着大量的序列信息的增长以及计算机科学的发展使得使用理论预测变得更可靠。非编码RNA的功能通常和它的三级结构相关,要想得到RNA的三级结构,其中RNA的二级结构预测是一个很重要的环节。RNA二级结构预测主要包括两种方法,基于最小自由能和共进化信息,这两种方法各有优缺点。最近机器学习和深度学习在很多领域取得了很好的成果,例如AlphaGo战胜了人类的围棋选手,在图片处理,自然语言处理,蛋白质Contact预测,药物筛选,都又很好的表现。最近的AlphaFold在蛋白质结构预测领域也取得了不错的成绩。本文主要开展了下面几个工作,首先采用了神经网络的方法来预测残基的配对状态,然后将残基的配对状态信息作为限制条件去除直接耦合分析中的部分假阳,但是效果一般;之后使用全卷积神经网络分别训练了两个神经网路模型预测RNA的二级结构,并采用碱基扩展的方式对输出结果进行优化。在模型一中采用直接耦合分析的结果作为输入,相比于直接耦合分析精度有所提升;在模型二中采用多序列比对的统计结果作为输入,相比于模型一精度有所提高,并且大多数情况下好于其他流行的方法。"
1286,基于机器学习的心电信号识别分类算法研究及软件实现,"随着人们生活和工作压力的逐步加大,心血管疾病已经成为人类生命健康的一大威胁。心电图能够有效地反应心脏健康状况,是心血管疾病检测常规且有效的手段,在临床上具有重要价值,被广泛应用于心血管疾病诊断中。因此研究一套有效的心电信号识别分类算法具有重要意义。本文主要研究内容如下:首先采用带通滤波器对MIT-BIH数据库中的数据进行去噪处理,对预处理后的数据进行波群检测,对基于二进样条小波进行R波峰值点检测进行改进,加入自适应阈值检测极值对,减少R波的漏检、误检。提出斜率阈值平台搜索法检测QS波的峰值点及起始点,基于QRS波的检测信息采用斜率最值平台搜索法进行P、T波峰值及起始点检测,提高了波群检测准确率。根据波群检测信息计算特征值,计算了RR间期、QT间期等12种特征值。采用遗传算法对支持向量机的惩罚因子和核参数进行优化,基于特征值对5种心电信号进行分类,进行性能评估,结果表明采用遗传算法优化后的支持向量机识别分类性能更优,准确率得到提高。然后基于卷积神经网络对5种心电信号分类,分别设计一维卷积神经网络和二维卷积神经网络模型,对分类性能进行评估,结果表明卷积神经网络的性能优于遗传算法支持向量机的分类性能,二维卷积神经网络的分类性能优于一维卷积神经网络,且分类准确率得到提高。本文有从医院采集的全导联临床心电数据,设计卷积神经网络模型对临床数据的5种类型心电信号和6种形态进行识别分类,分类性能均良好,该算法较好的泛化能力,适用于实际数据分类。本文对8个导联分别进行识别分类,结果显示II导联数据性能最好,能更全面的反应心电信号信息,在无法获取全导联数据时可着重参考II导联数据。最后设计心电信号自动分析软件,选用Visual Studio 2013作为编译器,采用C#进行程序编写,实现了数据接收、数据解包、界面显示、识别分类和数据存储功能。采用MIT-BIH数据库的数据对所编写软件进行了测试,测试结果表明该软件能对心电信号完成自动识别分类,并能够显示异常类型及位置。"
1287,基于微博大数据与机器学习算法的旅游景点推荐方法研究,"旅游景点的精准推荐有利于提升用户出行的效率与旅游体验。然而,旅游特征因子的选择与推荐算法的不同都会影响景点推荐的准确性。针对现有旅游推荐研究中存在数据稀疏、旅游因子不足、推荐准确率不高等问题,本文利用微博数据的个性化表达、现势性强等特性以及机器学习的智能化预测作用,提出了基于微博数据与机器学习的景点推荐方法,实现了精准化、个性化的旅游景点推荐。论文的主要工作及成果体现在:(1)微博数据具有数据量大、语义丰富、表达用户真实思想、易获取等特点,可以缓解传统的利用旅游网站数据进行旅游推荐的数据稀疏性问题。因此,本文首先利用Python爬虫获取了与景点相关的新浪微博数据,并对获取的数据进行分类与清洗,以用于旅游景点的推荐研究。(2)其次,本文提取了丰富的旅游特征因子。典型的旅游推荐算法从景点、游客等方面选择旅游特征因子,未考虑游客到访目的地的通行时长、旅游季节等上下文信息,而它们可以从不同角度帮助了解用户的旅游偏好。本文从旅游景点角度利用核密度估计等方法提取了景点位置、景点票价、景点级别、主类、亚类、基本类型六个特征因子;从游客角度利用统计分析等方法提取了性别、年龄、年龄段、客源地四个特征因子;从上下文感知信息角度利用地理集中指数等方法提取了通行时长、季节、月份三个特征因子。基于此建立了丰富的旅游特征因子库,并将多元特征进行组合,为可靠预测提供支撑。(3)再次,针对协同过滤推荐算法的数据稀疏、冷启动问题,本文引入机器学习算法,并结合已提出的多特征旅游因子来构建动态的景点预测(随机森林偏好景点预测(Random Forest Preferred Attraction Prediction,RFPAP)和神经网络偏好景点预测(Neural Networks Preferred Attraction Prediction,NNPAP))模型。实验结果表明,RFPAP和NNPAP方法能够克服数据稀疏性问题,分别取得了89.61%和89.51%的准确率,且RFPAP方法优于NNPAP方法,具有更强的泛化能力。(4)然后,本文采用FP-Growth算法构建景点关联(FP景点关联(FP-Growth Attraction Association,FP-Growth AA))模型。利用该模型可以高效地挖掘微博数据中景点之间的关联规则。实验结果表明,通过挖掘游客选择的景点之间的关联关系,可为旅游出行决策提供有效信息。(5)最后,提出了一种融合RFPAP与FP-Growth AA模型的旅游景点推荐方法,不仅可以预测游客偏好景点,而且可以挖掘出与偏好景点关联性强的景点集,并依据置信度排序推荐给目标游客,有效提高了景点的个性化推荐精度,具有很强的泛化能力。"
1288,基于机器学习的海洋平台在线损伤识别研究,"海洋中蕴藏着丰富的资源,是人类能源供应的重要来源,海洋平台是海洋能源开发必不可少的基础设施。在复杂多变的海洋环境下,海洋平台结构可能会由于疲劳或腐蚀等因素发生损伤,这些损伤若不能被及时发现,会引发严重的后果。目前,海洋平台的损伤识别研究主要是基于环境荷载进行的,使用模态分析方法从响应数据中进行结构特征的识别与分析。近年来,传统机器学习与深度学习方法快速发展,若能将这些智能方法应用于该领域中,必将大大提高海洋平台损伤识别的效率和准确率,从而提升平台结构的安全性。针对海洋平台健康监测智能化的发展趋势,本文将传统机器学习以及深度学习与海洋平台的损伤识别研究紧密结合,主要体现在三个方面。其一,在结构特征提取后,采用无监督降维方法对结构特征进行降维,将数据从高维空间映射至低维空间,并进行数据分布的可视化分析;其二,分别采用基于密度、基于聚类和基于单分类的异常检测技术,通过检测海洋平台监测数据中的异常点来判断结构的损伤;其三,基于生成对抗网络,提出NLS-GAN非线性系统特征变化识别网络,将深度学习方法融入海洋平台损伤识别中。这些方法对正常工况下的监测数据进行学习,在得到诊断模型后,可对新数据的损伤情况进行评估。同时,针对结构长期监测过程中的在线识别,给出在线学习的解决方案,并提出在线边界增量学习方法。该方法使模型从实时监测数据中不断学习更新,且可在保证模型精度的前提下减少数据存储压力,提高学习效率。对于以上基于传统机器学习或深度学习的损伤识别方法,本文使用二阶非线性动力系统仿真实验验证了方法的有效性,在仿真系统参数改变后,这些方法可以从系统的输出响应中发现系统固有特征的变化。对于提出的在线边界增量学习方法,本文对多种在线方法进行了比较,最终证明该方法可以取得最好的在线学习效果。本文还将提出的方法应用于浮式生产储油卸油(FPSO)单点系泊结构实际监测数据的损伤识别中,识别结果与真实情况吻合。"
1289,基于纹理识别和深度卷积神经网络的高强钢材料显微组织识别,"随着汽车保有量的急剧增加,汽车工业对节能减排、减少环境污染的要求越来越高,高强钢的热冲压技术在汽车的结构件和安全件制造中的应用日益广泛。高强钢可以通过热冲压获得不同的组织定制零件的力学性能,可能得到的组织包括全部马氏体、铁素体/珠光体、马氏体/残余奥氏体、马氏体/贝氏体等。相关研究中,需要对材料显微组织进行识别,从而分析工艺过程,但该过程需要由专业人士完成,故存在效率低下、人员的主观性影响较大且专业人员数量有限等弊端。因此,需要研究材料显微组织的自动识别技术。针对上述高强钢热冲压获得四类组织的识别与分类问题,本文从纹理特征提取、机器学习方法分类和卷积神经网络等方向展开研究,提出了两种分类方法:(1)通过灰度共生矩阵提取显微图像的纹理特征,形成纹理特征向量,并对特征向量的表征效果进行了可视化。之后采用SVM、kNN、RF等机器学习方法在数据集上进行训练,得到分类模型,对比分析了各个模型的分类效果;(2)采用迁移学习的思想,对深度学习网络进行迁移与改进,构建了适用于显微组织识别的深度卷积神经网络模型,探究并确定了网络训练中的超参数,最后分析了深度网络模型对材料显微组织的识别效果,并与机器学习方法的效果做了比较。通过实验验证,本文提出的两种高强钢显微组织识别方法准确度较高,有良好的分类效果。主要结论如下:(1)基于GLCM的图像特征向量能够较好的表征高强钢显微组织图像的纹理特征,基本能够区分本文研究的四类显微组织;(2)基于GLCM特征向量的机器学习分类方法中,SVM的分类精度最高,达到95.50%;且SVM对于四类组织的识别率均在90%以上;(3)改进的深度卷积神经网络的图像识别模型中,参与训练的卷积层数越多,分类精度越低;当参与训练的卷积层数为0时,分类精度最高,为96.25%,超过GLCM+SVM方法。"
1290,覆盖件模具斜楔零件智能数控编程系统关键技术研究,"斜楔零件是汽车覆盖件冲压模具中的一种重要组成结构,主要采用数控加工的方式完成零件的加工。目前企业多以交互式图形编程方法编制斜楔零件的数控加工程序,该方法繁琐、易出错、效率低且过分依赖于人工经验,极大地影响了模具的制造加工效率,增加了模具交付周期及制造成本。因此,亟需研究开发一种更为高效和智能的数控编程系统。论文在深入分析了斜楔零件结构及数控工艺流程后,总结了斜楔零件的结构和数控工艺特点,提出了一种制造特征核心平面的概念。在此基础上,对现有各种智能数控编程关键技术进行了研究总结,针对目前智能数控编程系统在制造特征识别、加工边界抽取两类关键技术中存在的难题,提出了一种结合机器学习方法与二维图像处理技术的全新解决思路。针对制造特征识别问题,论文提出了两种制造特征识别算法:基于核心平面Brep关键信息的制造特征识别算法和基于卷积神经网络的制造特征识别算法,实验研究表明两种算法均在斜楔零件上取得了较高的识别准确率。其中第一种算法通过大量的推理规则识别制造特征,导致算法在通用性上存在着缺陷;为此,第二种算法通过引入机器学习理论成果,采用监督式学习方法学习获得制造特征识别能力,该算法在保持极高识别准确率的前提下在通用性上取得了较大的突破。针对加工边界抽取问题,论文针对两类制造特征加工边界形成特点,分别提出了一种基于核心平面面环的加工边界抽取算法以及基于二维图像骨架的加工边界抽取算法。第一种算法通过遍历制造特征核心平面的面环计算加工边界,主要应用于加工边界由制造特征组成面的边形成的情形;第二种算法将制造特征投影到二维平面,通过骨架提取算法获取单像素宽度的像素曲线,最后将像素曲线投影至三维空间得到加工边界,该算法主要应用于加工边界由制造特征中心线形成的情形。实验表明,两种算法在相互配合下可以有效提高加工边界的抽取效率及准确度。论文基于NX/OpenAPI及TensorFlow机器学习平台,在Siemens NX10.0上开发了一个智能数控编程系统。以企业典型的斜楔零件为测试案例,验证了该系统的可行性与可用性。"
1291,基于机器学习的冷轧机轧制过程建模研究,"在轧制过程当中,轧制力的初始设定决定了轧制规程的设置。并且影响着产品的质量与产量,轧制力准确的预报可以减少带材头尾长度。带材轧制过程具有多变量、非线性、强耦合的特征,如果利用传统的机理模型对轧制力进行推导预测,不仅适用面较窄,而且误差值较大,无法适应如今现场多规格产品、柔性化生产的要求。为了提高冷轧机的轧制力计算精度,从冷轧轧制基本理论出发,基于机器学习算法对轧制力进行统计建模。为了提高轧制力的预报精度,按照网络深度与学习方式建立了三种预测模型。针对传统机理模型假设过多与参数难以选取的缺陷,建立浅层机器学习模型。采用基于结构风险最小化的支持向量机模型对轧制力进行建模,考虑到支持向量机参数难以选取的问题,使用改进遗传算法对支持向量机的模型参数进行寻优处理。改进遗传算法中加入了精英策略与自适应遗传算子,以增加网络的收敛能力与局部搜索能力。浅层网络如支持向量机等模型,其表达能力受到了网络深度的限制无法有效完成对复杂函数的拟合。且在轧制生产过程当中,可提取大量轧制力相关数据。故为了满足轧制力大数据集下的预测,建立深度网络模型来预测轧制力。考虑深度网络存在梯度弥散等问题模型难以训练,本文将采取半监督方式训练深度网络模型。且为了提取更有效的模型特征,本文使用去噪自编码器完成模型无监督训练。为了使深度网络摆脱无监督学习加快网络训练,以符合轧制力对快速建模的要求,并进一步提高模型精度。建立一种新的深度网络结构,使用小批量梯度下降作为网络的基础学习方式,改善随机梯度下降与批量梯度下降存在的问题;使用Batch Normalization结构优化网络的前向传播,稳定每层网络的输入分布;利用Adam随机优化算法优化网络反向传播,在梯度更新中为不同参数提供自适应性学习率,完善梯度更新。且为了进一步解决网络的梯度弥散问题,选用Relu作为网络的激活函数。同时根据现场采集的数据,使用PYTHON语言进行仿真实验,得出的轧制力模型在精度与建模速度方面均由于常规浅层模型与半监督模型。"
1292,虚拟试衣型号推荐技术研究及应用,"近年来,随着体感交互技术的发展,基于Kinect的虚拟试衣系统为顾客在线选购衣物提供了一种新的选择方案。Kinect可以较为准确地测量出人体的骨骼模型,生成人体三维数据,以进一步的为用户推荐衣服型号,并利用可视化技术进行虚拟试装。然而,虚拟试衣技术近几年来表现得一直不愠不火,主要是因为其使用效果受到了技术瓶颈的制约,即无法准确地测量出人体尺寸。不同人的体型不同,不同厂家的制衣型号也不规范,传统的数据筛选与匹配手段为用户选择的衣服尺码总是难以尽如人意,无法提升用户体验与用户回购率。基于人体手工测量手段或者虚拟试衣系统方案,服装店积累了大量的用户体型信息和所购衣物信息,为进行用户购物信息挖掘提供了有效的数据支持。为了解决虚拟试衣合身度的问题,以提高顾客购买率,利用基于统计信息学的机器学习方法,从历史的用户体型信息和所购衣物信息中学习出试衣型号推荐模型,并且通过Kinect体感测量技术,实时获取真实用户的人体尺寸序列,来为其推荐合身的服装型号成为一种很有前景的选择。通过该策略,让消费者在购买服装时能够获得适合自己身材尺寸的服装尺码,增加消费者对网络购衣的满意度与信任感,从而增强消费者的购买行为。在本文中,结合了Kinect体感技术、机器学习技术和Unity3D增强现实开发技术,研究了一整套基于人工智能的虚拟试衣型号推荐技术方案及其应用,具体工作内容和创新如下:(1)基于Kinect体感测量技术,构建人体三维属性拟合函数,实时获取人体点云数据,并拟合出主要人体尺寸属性,减少传统手工人体三维测量的繁琐工作。(2)结合3ds Max人体三维数据库,本文使用多分类技术,训练了四种不同的机器学习算法,通过对比不同试衣型号推荐模型的性能指标,挑选出最优试衣型号推荐模型,代替了数据筛选与匹配的笨拙方案。(3)利用Unity3D增强现实开发工具,实现了试衣型号推荐模型所推荐尺寸的三维衣服模型与实时采集的二维人体影像的虚实融合效果,包括衣服贴合、手势换装等研究,为用户实时展示虚拟试衣是否合身。"
1293,基于机器学习的空气质量分析和预测方法研究,"随着社会经济的不断发展,人们的生活水平有了很大提高,但环境问题的日益严重,对人们的生活质量产生了很多负面影响。由于空气质量的影响因素复杂,且具有动态性、可变性和复杂性等特点,因此如何有效分析这些影响因素与空气质量的关联关系,进而研究空气质量的演变规律具有重要意义。在此背景下,本文提出了基于机器学习的空气质量建模分析方法,充分考虑了气象、环境等空气质量的相关因素,以此实现对空气质量演变趋势的准确分析。首先,分析影响空气质量的约束关系,从气象特征和环境特征两个维度进行分析,气象特征定义为本地气象因素(即温度、降雨量、湿度、压强、风速、风向),环境特征定义为域内因素(即目标区域历史污染物浓度)和域外因素(周边区域污染物浓度)。其次,采用定性和定量的方法将抽象的空气质量影响特征具体化。采用数值拟合的方法定性分析空气质量与气象特征、环境特征的相关性,采用皮尔逊相关系数定量分析气象因素间的耦合关系,并从中提取出空气质量预测所需的特征值。再次,提出基于机器学习的空气质量分析预测模型,在气象特征相关性分析的基础上提出贝叶斯网络的分析预测方法,在环境特征相关性分析的基础上提出随机森林的分析预测方法,最后基于上述分析结果建立空气质量的协同预测模型,实现对空气质量的准确预测。最后,对本文所提出模型的预测结果进行分析,并且通过图表对空气质量影响因素的具体关系进行了分析。对比实验结果表明本文所提出的模型考虑因素较为全面,在预测的精度上高于传统的单一预测模型。"
1294,基于模型预测控制和机器学习算法的空调优化控制方法,"空调的发明改善了室内环境、提升了人们的生活品质,同时也带来了能源的巨大消耗以及自然环境的恶化等问题,因此,空调的优化控制方法研究一直都是倍受关注的课题。针对空调的优化控制,一方面要采用更好的控制方法来提高空调的控制品质,另一方面还要提高空调的舒适度来满足不同用户的需求。针对变频空调的温度优化控制,本文首先采用理论建模以及基于空调采集数据的实验建模两种方法建立了变频空调温度控制系统模型,然后将模型预测控制算法应用于变频空调的温度优化控制。利用matlab simulink仿真工具对变频空调分别在夏季制冷和冬季制热两种工况下进行仿真测试,每种工况下分别进行标准模型、模型失配、抗干扰三种场景的仿真,并分别与传统的变频空调PID控制算法的效果进行了对比,对仿真结果进行了分析,验证了利用模型预测控制算法进行变频空调温度优化控制比传统的变频空调PID控制方法具有更好的控制效果。针对空调温度舒适度的优化控制,本文提出了一种利用机器学习算法并结合用户使用习惯数据分析的控制方法。首先设计了空调的整体控制方案,然后利用四种机器学习回归算法进行训练得到自动模式下的空调设定温度回归模型。在自动模式的基础上,在云服务器中的MySQL数据库中建立了用户使用习惯数据表,得到用户在特定的室内外环境下最喜欢的空调设定温度。最后对本空调控制方案进行了Web端的软件实现。该方法能够自动设定用户喜欢的空调温度,具有一定的创新性和实用价值。"
1295,基于高光谱成像技术的大米产地鉴别研究,"为了探讨基于高光谱图像技术快速、准确、稳定的大米产地确证方法,在吉林省不同水稻产区采集990个大米样本作为研究对象,利用高光谱成像系统获取400~1000nm波段范围的高光谱图像,提取10pixel×10pixel感兴趣区域内平均光谱反射信息作为样本数据。为了减少噪声等干扰信息的影响,采用标准正态变换(standard normal Z transformation,SNV)、卷积平滑(Savitzky-Golay,S-G)及多元散射校正(multiplicative scatter correction,MSC)三种光谱曲线预处理方法。利用多层感知机(Multi-Layer Perceptron,MLP)、在线序列极限学习机(Online Sequential Extreme Learning Machine,OS-ELM)、极限学习机(Extreme Learning Machine,ELM)三种非线性机器学习算法和偏最小二乘(Partial Least Squares Regression,PLS)算法,在对全波段的光谱数据进行自适应重加权(Competitive Adaptive Reweighted Sampling,CARS)、主成分分析(Principal Component Analysis,PCA)、多维尺度分析(Multdimensional Scaling,MDS)降维处理后的光谱数据基础上,分别建立产地确证模型,并从模型的分类准确率和训练时间进行比较和分析。研究结论如下:(1)基于全波段光谱数据建立的确证模型中,无论光谱曲线是否经过预处理,OS-ELM模型的准确率均高于ELM、MLP和PLS模型,预处理结果中MSC方法优于SNV与S-G方法,建立的MSC-OS-ELM模型的分类准确率(98.3%)最高,依次为MSC-ELM(89.6%)、MSC-MLP(88.4%)、MSC-PLS(79.5%);(2)经CARS降维处理后,共提取了15个特征波长,经MDS降维处理后,提取了13个特征波长,经PCA降维处理后,共提取了9个特征波长,将这些特征波长用于建立模型,对模型准确率分析可知,经MDS降维后的模型分类准确率最高,分类模型准确率依次为MDS-OS-ELM(97.4%)、MDS-ELM(88.5%)、MDS-MLP(87.1%)、MDS-PLS(78.3%)。四种模型的分类准确率相比较基于全波段高光谱数据建立的模型均有所下降,但输入变量减少了96.6%,在保证较高准确率的前提下,模型运行时间大幅减少。(3)模型训练效率的评估采取同等参数条件下,一次性输入500组数据和分5次输入累加到500组数据两种情况进行比较,第一种情况的训练时间依次为ELM(0.0301S)、OS-ELM(0.0303S)、MLP(246.5643S)、PLS(436.6958S),ELM与OS-ELM两者之间差距很小,均显著优于MLP和PLS模型。第二情况剔除了MLP与PLS模型,单独对比了ELM与OS-ELM模型的训练时间,发现ELM模型随着样本数据量的累加,训练时间呈线性趋势上升,而OS-ELM训练时间并无明显变化。因在产地确证应用中,实际情况通常是累次添加输入数据,故而OS-ELM算法更加适用于大米产地确证建模。研究结果表明,采用MDS降维方法能够有效提取大米特征光谱信息,高光谱成像技术结合OS-ELM算法对大米产地进行高效、准确、稳定的无损鉴别是可行的。"
1296,柔性多维度触觉感知装置设计与实验研究,"触觉感知是人与外界环境直接接触时的重要感知功能,也是智能机器人发展中的关键技术之一。针对柔性传感器的柔韧、延展和可自由弯曲甚至折叠的特性,以及触觉的多样性和复杂性等问题,本课题以触觉感知为研究对象,基于全柔性传感器的设计理论,以及柔性传感器的应用基础,通过对触感系统中柔软度、摩擦力、热传导等方面的针对性研究,建立触觉感知系统的基础理论模型。并通过建立的理论模型系统地从构型设计、仿真优化、制作工艺、样机研制与实验研究等多方面展开研究,为智能机器人发展在触觉感知方面提出了新的思路。首先,对不同物体触摸感知的不同进行系统分析,并提炼出几种触觉感知量。通过将提炼出的触觉感知量组成多维度的触觉感知系统,并根据各个触觉感知量的独特特点,理论分析与研究,最终提出触觉感知的测量方法。其次,构建多维度触觉感知装置的制造工艺体系,从成型模具的设计,软体材料的调配方法,软体材料的成型流程,到内含全柔性传感器的柔性基体的二次成型。保证了多维度触觉感知装置的制造效率、经济性、可靠性以及可重复性。最终实现了实验样机的研制。再次,完成了触觉采集系统的硬件设计。根据整个触觉感知系统的运行方式和采集原理,对控制系统进行整体的逻辑结构设计。基于建立的硬件实验系统,编写了对应的软件程序系统,采用上位机及下位机软件程序的形式。通过对比几种机器学习算法的特点,选择了一种简单有效的学习算法对触觉感知系统采集到的数据进行处理分类,完成特定场景下的应用。最后,对触觉感知系统进行实验研究。先对不同待测物分别进行柔度感、粗糙度感以及温感测试实验,然后对不同待测物做触觉感知的整体实验,通过对实验结果进行对比分析,完成了触觉感知系统的性能评估。"
1297,基于机器学习的型材滚弯成型回弹预测方法研究,"型材弯曲件在航空航天等领域应用广泛,具有零件种类多、成型复杂、精度要求高等特点。传统生产加工过程中常需要加工大量的模具,导致生产成本居高不下。滚弯装备由于采用滚弯工艺进行加工,无需专用模具,具有广泛的市场前景。由于滚弯成型受到材料性能参数、几何参数、结构参数、工艺参数等复杂因素耦合作用影响,加之目前对滚弯设备、滚弯工艺、成型控制等掌握不够,特别在变曲率滚弯件生产中,因其时序性、动态性出现成型件回弹难以解决等问题,因此关键核心技术急需突破。为此,本文对基于机器学习的型材回弹关键技术进行了深入研究,主要研究内容如下:首先,针对滚弯材料参数、设备参数和工艺参数对成型曲率的耦合作用和回弹影响进行了研究,并分析了滚弯成型的机理和曲率回弹约束条件,建立滚弯成型特征向量的表征方法,定性分析主要因素对成型回弹的相关性,在此基础上,结合成型原理对主要特征进行提取和归一化处理。其次,根据滚弯成型回弹关系和满足小样本分析的需要,采用机器学习方法,提出基于支持向量回归的定曲率回弹预测模型,分析和挖掘复杂因素影响下的定曲率和回弹的关联关系。并在模型中引入核函数,将滚弯回弹的高维特征问题映射到希尔伯特空间解析回弹关系。再次,针对变曲率成型过程的曲率随时间动态变化特点,在研究定曲率回弹关系的基础上,提出基于双向长短期记忆神经网络(BiLSTM)算法的变曲率回弹分析方法,通过神经元选择、遗忘及传递等过程循环迭代分析和优化拟合变曲率回弹关系。最后,基于三辊对称式滚弯机对6061铝合金型材滚弯回弹分析模型进行实验分析,通过实验数据分析建立不同曲率分布下的回弹解析关系,并针对不同输入曲率预测回弹量,验证所提出的基于机器学习的型材弯曲回弹预测方法有效性和可行性。"
1298,铁路工务作业远程监控系统应用技术研究,"随着我国铁路运营里程的不断增加,铁路线路的安全压力也越来越大,对线路的维护要求也越来越高,对现场施工人员的工作效率、安全性也提出了更高的要求。因此,利用现代通信和信息技术实现铁路运营、维修和管理的自动化与智能化是必然的发展趋势。然而,目前多数铁路工务段在作业防护时依然采用人工方式,由于作业人员的现场行为得不到实时的监控,安全事故时有发生。针对该问题,在分析了现有铁路工务作业安全防护系统的基础之上,提出了在工务作业监控系统中加入人员行为识别的设想,以探伤工的现场作业行为为研究对象,研究了作业人员的行为特点和人体行为识别方法,设计并实现了铁路工务作业远程监控系统并进行了测试。论文的主要工作包括以下几方面:首先,研究了基于穿戴式传感器的人体行为识别方法。主要包括:1)行为数据采集的方法;2)倾斜矫正、去噪、分割、标记的方法以及8类特征值的提取方法;3)kNN、C4.5决策树、随机森林和SVM四种识别算法。其次,对监控系统的需求进行了分析并进行了总体方案设计。分析了铁路工务人员现场作业的7种主要行为;分析了系统的功能需求和性能需求;将系统进行了结构划分;设计了系统的各个功能模块;对系统主要的3类实体进行了抽象描述,分析了各实体的输入输出数据流;对客户端软件的数据库进行了设计。再次,完成了监控系统的设计与实现。主要包括:行为数据预处理及特征提取的实现,分类器生成模型的基本原理分析、模型的训练和调用;服务器软件、人员行为监控装置和列车预警装置通信软件的设计与实现;Web客户端软件中管理员登录、用户管理、任务创建、历史查询、数据包解析与处理、GIS监控等模块的设计与实现。最后,对算法的性能和监控系统的功能做了测试。采集了8人的行为数据,并做了预处理和提取特征,经过Weka机器学习平台10折交叉验证后得到了四种算法的混淆矩阵,结果表明:四种算法的识别效果都较好,其中SVM识别率最高。以SVM作为行为识别的算法并进行了功能测试,测试结果达到了预期,表明该方案能满足对作业人员行为进行远程监控的需求,及时发现危险的存在,具有一定的工程应用价值。"
1299,基于学习的智能车车道保持与换道行为研究,"车道保持和换道是车辆驾驶中的两种常见驾驶行为。研究车道保持行为的根本目的是为了控制车辆的行驶方向,使车辆自动行驶在当前车道上,进而减轻驾驶员的操纵负担,提高驾驶安全性与舒适性。而研究换道行为的目的在于使车辆在具体驾驶场景中(特别是当车流量较大且出现频繁换道时)能够合理有序的做出换道决策和换道执行,从而舒缓交通流运行状态,提高道路通行能力,并在一定程度上缓解交通拥堵。智能车与传统汽车的不同之处在于其具有环境感知、规划与决策以及运动控制的功能,能够以一种智能的方式执行预期的驾驶行为。智能车的车道保持和换道行为的建模分析与研究,在自适应巡航控制、智能辅助驾驶和自动驾驶等领域有着广泛的应用价值。传统的车道保持模型和换道模型大多基于规则而设计,这存在两个问题。一方面驾驶场景往往比较复杂,传统模型很难将各种情形完全考虑在内。另一方面,传统的车道保持模型和换道模型并没有考虑到驾驶员的行为习惯,导致模型难以有效反映驾驶员的感知、决策和执行等一系列心理和生理活动的不一致性和不确定性。基于学习的车道保持和换道模型由于是数据驱动的,模型可以自我探索到潜藏在数据中的特征规律,进而利用提取的特征规律驱动车辆执行预期的驾驶行为。本文从数据驱动的角度出发,采用基于学习的方法,对智能车在高速公路上的车道保持与换道行为展开了研究。具体研究内容如下:第一,研究基于学习的车道保持。针对双车道的简单驾驶场景,设计一种基于端到端深度学习的车道保持模型,在人工采集的大批量数据样本上进行有效性评估,并采用可视化方法提高模型的可解释性。另外,在端到端深度学习基础上,采用数据聚集算法,设计一种基于模仿学习的车道保持模型。该模型利用与环境交互所产生专家示例样本辅助车辆完成车道保持任务。第二,研究基于学习的换道决策。针对包含多车和多车道的复杂驾驶场景,采用不同机器学习方法(支持向量机、多层感知器网络以及集成学习中的随机森林和梯度上升决策树)建立自主换道决策模型,并从准确率、精确率、召回率、F1度量、AUC以及Kappa系数六项检验指标上对模型的预测结果进行综合比较。第三,研究基于学习的换道执行。针对包含多车和双车道的驾驶场景,考虑车辆的整个换道执行过程满足时间依赖性,设计一种基于长短时记忆网络的换道执行模型,用于预测车辆换道执行时的运动轨迹,并与多层感知器网络的换道执行预测结果进行比较分析。"
1300,基于机器学习的建筑工程质量验收规范信息抽取研究,"建筑业和房地产业是信息密集型、知识密集型产业,如何高效地应用这些信息和知识成为一项重要的研究课题。建筑工程质量验收规范是指导施工和审查的重要依据。目前,建筑规范的应用方式为人工阅读和查找,基于建筑规范的质量自动审查系统也大多依赖于人工建立规则,因此自动抽取建筑规范中的约束成为减少人工、提高自动化水平的关键技术。本文以建筑工程质量验收规范作为研究对象,结合规范类文件的特点和信息抽取技术,提出了一个基于混合式机器学习的命名实体识别和信息抽取的方法,具体做出了如下工作:1.将建筑工程质量验收规范中的约束分为关系类约束和属性类约束,关系类约束是对两个工序之间的先后顺序关系和间隔时间做出规定,属性类约束是对材料或成品等对象的属性做出规定;2.运用基于Bi-LSTM-CRF的方法进行命名实体识别,取代了传统领域词典的方法,使得该模型在不同领域有更强的通用性;3.提出了一个基于LSTM-MLP的抽取模型。该模型弥补了基于规则的信息抽取对于专家制定规则的人工依赖问题,使得该模型有更高的自动化水平;4.对建筑工程质量验收规范进行信息抽取并结构化表示以后,提出了一种更加直观的展示形式方便学习和查询,为建筑工程中基于规范的验收工作提供便利,并可支持相关工程质量验收系统规则库的建立与更新。通过模型测试结果可知,本文提出的基于混合式机器学习的信息抽取模型效果较好,命名实体识别的F1值达到了88.5%,信息抽取的F1值达到了83.8%。作为工程规范类文件信息抽取的首次尝试,本研究具有减少人工依赖、通用性强等优点,有较高的参考价值,并值得做进一步研究。"
1301,基于机器学习的钢筋锈蚀无损检测数据的有效传感器融合,"钢筋混凝土的锈蚀是土木工程中主要的损伤机制之一,这种损伤会对混凝土结构的完整性造成影响并使其受力发生变化,导致建筑物存在很高的风险。目前,有多种无损检测(NDT)的方法可以检测锈蚀程度。但各种单一的检测方法和传感器通常不能获取足够的锈蚀特征信息,以至于很难判断钢筋锈蚀状况。因此,通过使用多种NDT方法综合检测同一个试件,可以获得更全面的钢筋锈蚀信息。然而,在对多传感器无损检测数据进行自动评估过程中,由于数据本身的复杂性高,传统算法计算效率及准确性低下。针对数据自动评估中多传感器数据的复杂性导致检测性能不高的问题,本研究基于多传感器钢筋混凝土锈蚀实验所得的无损检测数据,设计了基于机器学习(ML)算法的决策树算法(DT)、Bootstrapping模型和Boosting模型以加强对钢筋锈蚀的损坏程度的检测。算法从已标记的训练数据中学习最佳线性决策边界,以实现对数据的分类。并将其结果与基本的逻辑回归算法(LR)的结果进行量化、比较和分析。数据采集于钢筋混凝土锈蚀实验,该实验在各种环境因素都受控的条件下模拟加速混凝土构件的生命周期。基于多种检测方法获得钢筋锈蚀的特征信息,采用了探地雷达(GPR)测量钢筋反射的脉冲能量,并使用半电池电位法(HP)测量试件锈蚀电位,通过温纳法(WR)和微波湿度法(MW)分别进行锈蚀钢筋的电阻率和锈蚀湿度的测量。实现了利用多元数据综合评估多传感器融合方法。实验证明了与通过小型异构数据集训练出的具有复杂决策边界的DT算法相比,简单稳健的LR算法得到的分类效果更优,而通过DT可以得到各种检测方法在运算过程种的重要性。通过Boosting及Bootstrapping可以改善LR算法分类效果并实现数据的自动评估。其中Bootstrapping在实验数据中显示了更优的性能因为其不受数据复杂程度影响,并适用于小数据量的性能。"
1302,基于集成学习的居民建筑能耗预测及模型优化,"建筑节能是实现节能减排过程中中不可缺少的一步,建筑能耗的准确预测对于建筑节能优化以及建筑能源管理有良好的指导作用,通过数据驱动建立的能耗预测模型具备精度高、时间短等优势,在能源领域得到大量的推广。本文以采用供热站进行冬季供暖的某居民小区建筑为研究对象,采用各单一机器学习算法以及集成学习算法,根据数据采集系统采集到的数据、气象站中采集数据、小区总能耗等数据建立能耗预测模型,结合异常值处理、特征提取和网格搜索等措施提高能耗预测模型精度,最终得到的建筑能耗预测模型在具备较高的准确度的同时输入较少的特征变量,提高了模型的泛化能力。原始数据集中包含机组运行数据、气象站采集数据、时间数据以及能耗数据,采用散点图及箱线图进行异常值检测,采用中位数填充方法对异常值进行替换,通过比较处理后数据中各变量之间的最大信息系数判断各变量相关性,进而通过Bortua算法判断各变量重要性并选出最佳输入特征变量集。将经过特征提取的数据划分为训练集及测试集,利用多元线性回归算法、极限学习机算法、极限梯度下降算法与支持向量回归四种单一机器学习算法分别建立能耗预测模型,并通过十折交叉验证以及网络搜索的方法进行参数寻优。最后采用集成学习算法将四种单一机器学习模型综合在一起,提高预测精度,结果中测试集平均绝对误差下降4.36%~71.70%,均方根误差下降了3.80%~49.73%。鉴于居民建筑特性,新建历史能耗特征变量EWMA并加入到集成学习模型的输入变量集中,结果表明新的特征变量集能有效提升预测模型精度,与原始特征变量集相比,测试集平均绝对误差降低了10.36%,均方根误差降低了19.89%。"
1303,基于加权组合与核密度估计的电力负荷预测方法研究,"电力负荷预测是电力系统安全稳定运行的重要基础性工作,也是电网智能化建设过程中的一大研究热点。短期负荷预测可以为电力公司制定短期发电计划、机组启停、能源调度等任务提供重要参考依据。中期负荷预测对发电原材料采购、能源供应合同的签订具有重要借鉴意义。如今准确的负荷预测技术已成为保障电网正常稳定运行的关键性技术之一。通过对负荷预测领域前人研究进展的调研分析得知,基于统计建模的机器学习算法已成为该领域的主流方法。本文以新英格兰地区的整点负荷和气象数据为实验仿真数据,对该地区的负荷特征及其影响因素进行了详细分析,并以此为基础,建立了两个负荷预测模型:预测未来一周每个整点时刻用电量的组合预测模型和预测未来四年每个整点时刻用电量的区间预测模型。其一,考虑到短期负荷预测周期较短,且负荷数据间存在“近大远小”关系,因此,选取了时间跨度比较适中的训练样本,分别应用随机森林和BP网络对该地区的短期用电量进行预测。由于样本中工作日和休息日的数目存在较大差异,且随机森林选取样本采用的是自助采样(Bootstrap)方式,导致其对休息日的学习不充分,预测效果不佳;而BP神经网络则能通过重复训练,拟合出预测值和输入特征间的复杂关系。为了充分融合两种模型的优点,借助“误差平方倒数比”方法将两种模型的预测结果进行了加权组合,实验结果表明,组合模型的预测精度更高,误差极大值更小,且误差分布更均匀,组合模型在测试集上的平均绝对百分比误差为2.282%,只有4个样本点的百分比误差超过了6%,进一步验证了组合模型的稳定性更高。其二,基于长短期记忆网络,建立了预测未来四年每个整点时刻用电量的点预测模型,由于预测时间跨度较长,单纯的点预测值与实际值之间往往存在一定偏差,而区间预测结果则能提供更多不确定性参考信息。考虑到不同大小区间负荷值的误差分布存在一定差异性,因此,本文提出了一种基于核密度估计的分段误差统计方法,先按负荷值大小划分区间段,分别对每个区间段的误差进行统计分析,依次求得每个区间段的误差概率密度曲线,基于概率密度曲线求解误差在不同置信水平下的置信区间,并由此转化为负荷预测值的区间预测结果。分段区间预测模型在80%置信度下的区间覆盖率(FICP)达到了76.5%,实验结果验证了该区间预测模型的有效性。"
1304,健康问答社区主题识别和情感分析研究,"【目的】对健康问答社区进行主题识别,挖掘患者真实信息需求,找到患者关注的热点内容,对问题进行智能主题分类,促进精准信息服务和信息推送;对健康问答社区进行情感分析发现患者情感表达特点,帮助患者积极面对疾病。【方法】(1)编写scrapy爬虫代码在寻医问药网糖尿病频道抓取了共35000条提问数据,并将数据内容存储在mysql数据库中。(2)利用jieba中文分词工具、停用词表以及由国际疾病分类词表和中国2型糖尿病防治指南常用糖尿病药品目录构成的用户词典对初始文本进行分词和预处理,构成初始语料库。(3)从语料库中抽取1/5的数据进行预实验,构建预实验主题概率模型,从生成的主题中提炼出了33个主题内容,最终经过人工归并为10个主题大类。然后对全语料库进行训练,生成94个主题,采用归并算法结合人工标注的方式将这些主题归并到10个主题大类,依据主题分类结果进行主题分析。(4)从语料库中随机抽取8000条数据人工标注情感极性,利用word2vec模型进行特征提取,将转换后的数据集分别导入K近邻算法、朴素贝叶斯算法以及支持向量机进行训练,利用准确率、召回率和f1值评价生成的情感分类器,并对情感分类结果进行分析。(5)依据性别、年龄、主题和情感极性构建logistic回归模型,对情感极性的影响因素进行探索。【结果】(1)主题分类结果显示疾病预防和控制主题占18.7%,饮食占14.5%,就医指导占13.5%,合并症占12.5%,并发症占12.4%,疾病治疗与愈后占8.3%,疾病进展与危害占7.5%,用药指导占6.8%,病因与诊断占3.9%,遗传占2.0%。(2)情感分析时,发现支持向量机的分类效果较好。经支持向量机分类后的用户提问中积极文本占26%,中性文本占34%,消极文本占40%。(3)性别、年龄以及病因与诊断、饮食、并发症、合并症、疾病预防与控制、疾病治疗与愈后、用药指导、就医指导、遗传主题对情感极性的影响有统计学意义(p<0.05)。疾病进展与危害主题的影响无统计学意义。【讨论】(1)患者更愿意咨询疾病预防知识和饮食指导等科普性质内容,健康问答社区信息服务提供的治疗性建议相当有限。(2)患者网络就医咨询的情感需求很高,渴望得到情感支持。(3)性别、年龄、主题与情感极性之间存在关联性,需要进行进一步深入研究。"
1305,基于网络拓扑信息的疾病miRNA预测算法研究,"研究表明,疾病的产生与microRNAs(miRNA)调控异常有关,发现疾病相关的miRNA有助于研究疾病发病机制和治愈手段。然而,通过生物实验方式获取准确关联关系,花费大,周期长。因此,通过计算方式预测疾病-miRNA关系成为目前研究热点,并具有重要意义。在目前疾病-miRNA关系预测研究中,利用已知的疾病-miRNA关系构建生物网络,对未知连接中存在潜在连接的可能性进行计算,并按照可能性分数高低进行排序,从而向实验人员推荐分数较高的候选miRNAs。本文在生物网络基础上,结合网络内部拓扑信息,对疾病-miRNA预测算法进行研究,主要是以下三个工作:(1)构建了疾病-miRNA双层网络,并利用网络嵌入方法结合网络中权重信息和连接关系信息,从而提出了一种基于网络表示学习的疾病-miRNA预测算法。在预测结果分析和经典算法对比中,证实了方法的有效性和优越性。(2)针对网络表示学习的预测方法,从不同的角度提出了两点改进。通过加入基因节点改进网络结构,增加了网络拓扑信息以及利用DeepWalk算法改变网络编码方式,避免了搭建相似网络。通过结果分析和算法对比,证明了改进算法的有效性,并能极大提高预测效果。(3)为了利用网络拓扑信息,提出了一种基于机器学习模型的疾病-miRNA预测方法。该方法基于外部数据计算的相似矩阵和内部挖掘的拓扑向量矩阵两个方面构造特征,从而融合了外部生物信息和内部拓扑结构信息。实验结果显示算法能有效预测疾病-miRNA连接,而且明显优于对比方法。同时,疾病案例分析中推荐的前30个候选miRNAs基本都能得到数据库证实。"
1306,基于人体生理数据的血压预测分析方法研究,"血压病已经成为人类健康的主要威胁因素之一,准确持续地测量血压是实施血压疾病有效防治的前提。传统的基于袖带的血压测量依赖于专业的医护人员的操作,并且在测量过程中会对人体造成伤害,因此不适合于持续的血压测量。使用机器学习算法对人体生理数据建模分析,预测血压值是一个可行的持续测量血压的方式,但是传统的血压预测算法存在准确率低,训练时间长的缺点。本文提出两种方法来解决上述问题,主要内容如下:首先,本文介绍了血压测量方法研究现状和一些基于机器学习的血压预测方法,血压测量方法包括侵入式测量和非侵入式测量,血压预测方法包括聚类、分类和回归等,并分析了上述方法的优缺点和应用背景。其次,通过EIMO设备的传感器获取原始生理属性数据如PPG,ECG等,采用峰值检测的方法,从原始的生理属性数据中提取出与血压预测最相关特征如脉搏波传导时间,心率和血氧等。使用梯度提升树算法对特征属性数据建模,预测单人血压值。再次,通过CM400设备的传感器,采用类似的方法获得上述特征,并加入了身高体重等人体属性特征,通过分类回归树算法预测多人血压值。并通过加入剪枝、限制树的深度等正则化方法和交叉验证方法,提升梯度提升树和分类回归树的泛化能力,降低了过拟合的风险。最后,本文对上述提出的方法做了编程实现,以真实的血压数据和人体生理属性数据为基础的实例验证了本文研究方法的有效性。梯度提升树方法在准确率(±5)方面比目前传统的最小二乘法,岭回归,Lasso回归,ElasticNet,支持向量回归和最近邻算法更好,预测低压值的准确率超过了70%,预测高压值的准确率超过了64%。分类回归树算法的预测时间小于0.1s,并且预测的高压值和低压值准确率超过了90%,并且模型训练时间少于0.5s,有较高的时效性。本文也对研究方法提出了新的方向。"
1307,机器学习在人体血压预测和心律异常分类的应用研究,"血压和心电信号是临床检测中标志人体健康状况的两项重要指标。腕式血压测量和心电图观察是其常规的诊断方法,诊断过程依赖专业的医护人员,测量时间的可控性差,容易加剧医疗资源的紧张。为此,本文采用机器学习方法进行血压预测和心律异常分类,提出基于支持向量机的血压预测模型和基于自适应提升算法的心律异常分类模型,主要研究内容如下。首先,本文深入分析心电和脉搏波两项生理信号以及特征处理方法。心电和脉搏波信号作为人体重要的生理信号,均具有周期性和典型的波形特征;不同特征选择和提取方法从不同角度分析人体生理数据。其次,本文提出基于支持向量机回归算法的血压预测模型。根据数据的采样频率设计数据合理的拓展方式,并结合无监督和有监督两种特征选择方法分析各生理特征之间及与血压之间的相关性,进行特征选择和组合,采用非线性核函数的支持向量机学习各生理特征与血压之间的映射关系,实现准确地血压预测。再次,本文提出基于自适应提升算法的心律异常分类模型。按照医疗器械进步协会标准和非交叉方式,定义心律异常数据集。对心电信号进行滤波器处理和心电节拍分割后,从时域和变换域两个不同角度提取五种心电信号特征,采用分类树作为基分类器的自适应提升算法学习多种心律异常间的差异,实现准确地心律异常的多分类。最后,本文分别介绍血压预测模型和心律异常分类模型的具体的实验环境、评价指标,并分析实验结果,验证模型的有效性和准确率。"
1308,基于机器学习的镇静状态分类研究,"麻醉通过抑制中枢神经系统,达到意识消失的目的,监测麻醉的镇静深度对于判断术中的脑意识状态尤为重要。而脑电图能够反映麻醉中神经元的兴奋或抑制,进而反映大脑意识的兴奋或抑制的程度。因此,利用脑电信号,可以直接分析大脑镇静程度,并可作为一种术中监测手段,来反馈麻醉的镇静状态,调整手术中麻醉药物的用量。脑电双频指数作为当今比较权威的镇静状态监测指标,普遍用于术中麻醉深度的监测,但其计算方法及各个参数的组合关系不公开,且以它为指标的麻醉监护仪价格昂贵。而其他单一的指标,如熵、Nacrotrend、频谱能量等,通常无法满足对不同镇静深度的准确监测。对此,本文基于脑电信号,提出了镇静特征组合监测指标,以及图像特征的镇静状态识别。首先,针对单通道的麻醉脑电信号采取了多种去噪方法,去除了50Hz工频、基线漂移等噪声。在此基础上,我们提取了9个麻醉脑电信号的镇静监测指标,这些参数是应用于麻醉的常规特征参数,并且在很多文献中被证明与麻醉特征及年龄特征相关。其次,采用随机森林方法训练多棵分类树,对比多种机器学习分类算法,对清醒期、麻醉期、恢复期及爆发抑制期的测试样本实现了准确预测。进而提出了一种多个麻醉脑电特征组合监测镇静状态的特征指标,实现了成人和小孩在不同麻醉药物控制下,病人不同镇静状态的准确分类。采用粒子群优化算法优化的支持向量机回归方法,实现了对脑电双频指数相对准确的回归拟合。最后,基于来自成人和小孩在不同麻醉药物控制下的脑电信号,分析了脑电的频谱特征图和递归图在不同麻醉镇静状态下的差异。应用卷积神经网络的方法,搭建了具有多个卷积层和池化层的神经网络,对4种镇静状态的特征图片集进行了特征学习和镇静状态识别,分析了卷积神经网络在识别麻醉镇静状态方面的性能,验证了基于深度学习方法,将脑电频谱特征图像用于麻醉镇静深度识别的可行性。"
1309,静脉麻醉的闭环控制系统设计与研究,"麻醉的稳定实施是临床手术顺利进行的基础。随着对麻醉控制问题研究的逐步深入,如何实现精确的麻醉控制已经成为神经工程和临床的一个挑战性难题。在目前的临床手术中,对麻醉药物的控制方面仍主要依靠麻醉医生的经验,在麻醉监测指标和麻醉药物的控制之间缺少科学有效的控制方法,加之麻醉医生的工作时间较长,导致在麻醉的控制方面难免出现偏差。因此,如何实现麻醉药物的精确控制已经成为亟待解决的科学问题和现实需求。本研究的目标为建立一个静脉麻醉的闭环控制系统,从而实现手术过程中的麻醉自动控制。这样一方面能够减轻麻醉医生的工作压力,使其能够关注更重要的手术节点,另一方面能够提升麻醉控制精度,实现麻醉药物的个体化、精细化控制。本文的研究内容主要分为,静脉麻醉控制系统中监测指标的选取、麻醉控制过程中监测指标的回归预测、基于监测指标的控制器设计、静脉麻醉控制系统的实现。首先,通过对比分析熵指数、脑电双频指数及Narcotrend指数的算法复杂度、指标量化程度及时延等性能参数,选择脑电双频指数作为系统的监测指标。由于脑电双频谱指数在临床手术的过程中无法直接获取且其算法不公开,使得以其进行控制系统的设计时存在一定的困难。本文使用长短期记忆-前反馈神经网络模型,通过脑电信号数据实现了对脑电双频谱指数的回归预测,解决了指标算法不公开的问题,提升了指标的在系统中可应用性和可操作性。接着,根据临床麻醉手术的特点进行了控制器的设计。将麻醉的控制问题分为诱导期,维持期和恢复期。在对比分析模型预测控制器与蚁群优化PID控制器两种控制方式的性能指标后,选择使用蚁群优化PID控制器作为系统的控制器。最后,本文介绍了系统的软件设计与实现。"
1310,基于机器学习的大于胎龄儿的预测及分型,"大于胎龄儿是指出生体重在相同胎龄平均体重的第90百分位以上(约相当于平均体重的2个标准差以上)的婴儿。大于胎龄儿本身容易产生多种并发症,且产妇容易产生各类产伤。因此,建立大于胎龄儿预测模型对大于胎龄儿进行早期诊断及干预,具有重要意义。除此此外,大于胎龄儿分型的研究顺应精准医疗的理念,有助于提高大于胎龄儿诊治的效益。在医疗领域中,机器学习用于疾病预测、疾病分型等已有许多成功的案例,这为大于胎龄儿预测与分型模型的建立带来了启发。主要采用2010年到2013年之间收集到的新生胎儿数据记录作为样本,运用机器学习技术对大于胎龄儿疾病进行预测及分型。对大于胎龄儿预测及分型的研究主要分为数据处理、疾病预测、疾病分型三部分。第一步数据处理主要是为了解决由于样本信息收集的原始性与真实性带来的问题。这些问题包括样本特征类型复杂、标准不一致、数据缺失、信息重叠、数据不平衡、标签不明等。具体应用到了数据清洗、数据集成、数据规约、数据变换,以及专家知识、特征独立、低方差过滤等特征选择方法。第二步运用数据处理后的数据集构造大于胎龄儿分类器,采用稀疏逻辑回归模型获得分类结果及解释性强的相关特征,采用梯度提升树模型挖掘特征与分类结果的非线性关系,采用弱监督学习利用未标记与标记混淆的数据对大于胎龄儿分类器进行补充和泛化。第三步使用正样本、借助聚类方法,对大于胎龄儿进行分型。利用有监督方法得到的最优大于胎龄儿预测模型召回率为0.66,精准率为0.94,曲线下面积为0.89。使用未标记与标记混淆的数据弱监督学习后,分类器召回率为0.82,精确率为0.965,曲线下面积为0.89。发现双方体重指数、是否吸烟(被动吸烟)、有无生活工作压力、饮酒与大于胎龄儿发生与否相关,此外双方在最佳生育年龄、血红蛋白等指标正常时胎儿更不容易患病。分型得到两个大于胎龄儿亚型,一类与男女双方肌酐、女方血红蛋白、女方体重指数、叶酸服用情况等身体指标相关,另一类则与男女双方年龄、男女双方职业、男女双方教育程度等社会指标相关。利用大于胎龄儿预测领域的相关理论知识、真实数据,运用机器学习方法,得到效果良好预测分类器,发掘出与大于胎龄儿发生相关的特征,得到两类模糊亚型。这有利于帮助医生进行大于胎龄儿诊断,且模型具有一定的可解释性,实现了辅助临床的目标。"
1311,基于三维混合特征和机器学习的肺结节影像智能诊断方法,"随着空气污染日益严重,肺癌已成为威胁生命安全的疾病,早期发现病变对及时治疗有重大意义。传统影像诊断方法耗时巨大并容易产生误诊漏诊,因此基于机器学习的智能化肺结节诊断系统因运而生。计算机辅助诊断技术需要对大量测试数据进行分析和处理,导致目标区域精确分割难、模式分类精度低、肺结节诊断时间长等棘手问题。针对上述问题,本文提出了三种肺结节诊断方法,具体研究工作如下:(1)分析了肺结节智能诊断技术的当前研究现状;概述了肺结节的形态特征、病理形成原因及其主流诊断方法;介绍了肺结节CAD系统的一般诊断步骤;阐述了图像预处理、图像分割、特征提取和模式分类等基本原理。(2)基于混合特征和支持向量机的肺结节诊断方法:由于采集的序列CT图像含有噪声,考虑到肺结节与血管的灰度信息相似,将均值漂移聚类算法应用于图像预处理;利用自适应阈值、孔洞填充与滚球相结合的方式得到肺结节候选;提取了混合特征,采用LDA对高维特征进行选择;将构造的精简测试样本集送入训练好的SVM模型中进行结节检测。大量仿真实验结果表明:预处理后的图像更利于ROI分割,提出的结节检测方案有效地提高了分类精度。(3)基于几何活动轮廓和逻辑回归的肺结节自动诊断方法:针对各项异性扩散算法没有考虑到图像梯度的特性,选用复合扩散系数函数对图像进行预处理;采用基于几何活动轮廓的算法对预处理后的CT图像进行多目标分割;针对结节良恶性定性诊断问题,采用基于Kriging插值法重构三维结节并提取三维混合特征;将构造的样本集输入PSO-LR模型中进行良恶性诊断分类。大量仿真实验结果表明:该诊断方法在图像去噪、肺结节候选分割、诊断精度上均占明显优势。(4)基于自动图像分割和随机森林的肺结节诊断方法:基于各项异性扩散算法,提出了结合梯度信息的扩散系数函数;采用固定初始分割轮廓的分割方案回避了手动定义种子点的棘手问题;将构造的高维样本集输入随机森林模型中进行结节诊断。大量仿真实验结果表明:该诊断方法具有良好的泛化能力,肺结节分割准确且提高了肺结节诊断效率。综上,基于LIDC-IDRI公开数据库中的海量CT图像,结合图像处理和数据分析,论文提出了效果显著的肺结节智能诊断方法,减少了诊断时间开销和计算复杂度,极大地降低医学影像模式识别难度并提高了肺结节诊断效率。"
1312,基于专家辅助的英语作文自动评分系统设计与实现,"在综合考察学生的英语应用能力时,英语作文试题是极其要的一种题型,有助于全面地了解学生对英语的掌握情况,目前考试中即使引入无纸化阅卷,也无法解决人工评卷因主观因素带来的评分标准不一致问题,评卷过程的客观公正性难以得到充分地满足。基于机器自动评分有助于为评卷工作确立一个一致的评分标准,这个评分标准不再由主观的“人”来实施,而是由客观的机器来实施,确保评卷过程中评卷标准的全程一致性,但其在实际实现中存在训练集数据量大及可迁移性差的问题,很难达到实际需求。因此本课题将基于当前无纸化阅卷流程,将作文自动评分引入无纸化阅卷,提出一个适合实际需求的基于专家辅助英语作文自动评分方法。无纸化评卷过程中,针对获取的样卷所制定的评分标准不能满足实际需求的问题,给出了一种样卷候选集筛选方法,以此获得与试卷库同分布的样卷候选集,基于此可以得到满足评分实际需求的样卷集;结合实际需求,对现有作文自动评分方法进行对比分析,选择了一种合适的方法进行作文自动评分模型训练;基于提出的英语作文评分方法,设计并实现了英语作文自动评分系统。经过充分的实验论证,所提出的基于专家辅助的英语作文自动评分方法是可行的,所设计并实现的面向英语作文的机器自动评分系统是可用的。"
1313,GBR等六种回归模型研究数字货币的多因子套利,"数字货币是时下投资界的热点,然而巨大的波动风险给投资者出了难题。多因子模型用一组多维度因子揭示了收益率的变化,为计量资产提供了方案。本文以数字货币的代表比特币为研究对象,组合金融中多因子模型与机器学习中岭回归、随机森林、GBR等回归模型,预测比特币的未来收益,旨在实现数字货币市场的多因子套利。本文以2017年7月1日至2019年3月5日的OKCoin国际交易所的时频率数据为样本,首先对数据预处理,分析数据分布特点,发现收益率右偏呈尖顶分布,具有趋势效应。其次划分样本数据,以2017年7月1日至2018年12月5日数据为训练集,2018年12月6至2019年3月5日数据为测试集。训练集内构建多因子策略,基于移动平均线、布林线、动量、真实振幅等30个指标建立因子池,采用回归法,基于最大回撤、夏普率和IC值验证单因子的有效性,根据因子热力图消除冗余因子,确定8个有效因子后,分别训练GBR等六种模型,并学习模型最优参数。测试集内预测比特币未来三个月的收益率。最后统计年化收益率、最大回撤等指标评价策略的有效性。实验结果显示:六种回归模型回测业绩均超越比特币真实收益率,非线性结构下的CART树、Ada boost算法、随机森林和GBR下回测效果明显优于线性结构的Lasso回归和岭回归,其中随机森林下预测准确率最高。不考虑交易成本下,随机森林下三个月累计收益率为1.0915%,年化收益率为4.43%,最大回撤只有14%,夏普率为6.68,而比特币同期实际累计收益率为-0.0475%。"
1314,多跳无线传感器网络冲突识别机制研究,"基于IEEE 802.15.4的无线传感器网络中的隐藏终端效应可能导致严重网络冲突,从而使数据包传输出现错误。相较于路径损耗、多径衰落、阴影衰落和IEEE802.11干扰等因素造成的非冲突错误,隐藏终端引起的冲突错误会持续存在,因而其破坏性更大。准确识别由隐藏终端引起的冲突对保证传感器数据的正确传输至关重要。本文首先研究了隐藏终端导致冲突碰撞的机理以及对网络传输性能带来的影响。本文采用数值分析方法对完整的冲突及重传过程进行了仿真,通过搭建CSMA/CA通信模型,得到数据包在非时隙模式下的碰撞及重传概率,进而对影响网络性能的因素进行了研究。理论分析及仿真结果表明,数据包长度、发包率、隐藏节点比例等都会对网络性能造成影响,其中发包率对网络性能影响最大。随后通过高发包率实验对传输错误数据包的错误特性进行研究。在理论分析基础上,本文设计了多种典型场景下的传输实验,得到非冲突错误场景和冲突错误场景下的错误数据包,并定义误码率、错误比特位置分布和错误符号位置分布作为性能指标对错误特性进行统计分析。统计结果发现,冲突错误数据包的后部倾向于出现更高的出错概率,该特性能够明显区分出不同应用环境中冲突错误和非冲突错误。基于冲突错误包的这种特性,本文提出了基于冗余域插入方法的冲突识别机制,即CRM-ML。冲突识别机制在发送方数据包中插入已知比特组合的冗余域,通过互信息技术对冗余域的位置进行选择,然后通过机器学习方法对数据包中冗余域的信息进行分类,从而判断传输失败是否由隐藏冲突引起。实验结果表明CRM-ML机制在编码效率为94%时能达到90%以上的识别准确度。本文在所提出的CRM-ML机制基础上,进一步设计了一种面向混合MAC机制的切换机制,以实现发生持续冲突时MAC机制的自适应切换。将该切换机制应用于CSMA/CA与CDMA结合的混合协议中,证实了其有效性。本文提出的冲突识别机制可运行于无线传感器网络,在接收方对错误数据包直接进行分析,无需存储或收集更多的数据,具有简便、高效的特点;基于冲突识别的切换机制可为混合MAC协议提供有效的切换点,最大化网络通信性能。"
1315,基于机器学习的自动发音检错系统研究,"随着在线学习的兴起,计算机辅助语言学习也成为越来越多语言学习者的选择,作为计算机辅助语言学习的两大核心,发音错误检测和诊断反馈能够对学习者的发音问题进行错误分析并给出发音纠正建议,从而提高语言学习者发音水平和学习效率。相对于受到时空限制的课堂语言教学,计算机自动发音检错有着实时、便捷、高效等诸多优点。目前大多数发音检错的学术研究只注重了发音错误的检测,而忽略了反馈纠正的重要性,为了更加直观的对学习者给出发音纠正建议。本文针对学习者由于发音动作的不标准导致的音素级别发音错误类型进行了检错研究,结合机器学习算法对舌位升高(Rising)、降低(Lowing)、偏前(Fronting)、靠后(Backing)和音素拉长(Lengthing)、缩短(Shorting)六类错误进行分类检错实验。并利用互联网技术对实验中的发音检错模型进行Web系统集成设计开发了自动发音纠错系统。论文首先在评估了声学特征以及语音语料库后提出了基于MFCC-RF的发音分类检错模型。采用提取的39维梅尔倒谱系数(MFCC)声学特征作为随机森林(RF)分类器的输入来构建分类检错模型。通过实验结果分析构建的MFCC-RF发音检错模型在Raising、Lowing和Shorting三类错误类型上实现了较高的分类检错准确率。但是,由于发音错误类型样本数据并不是均衡分布,其中另外三种错误类型样本数据相对较少,因此基于MFCC-RF的发音分类检错模型只适用于Raising、Lowing和Shorting三类错误类型的检测,检错范围较小。深度学习近年来被证明非常适用于模式识别与复杂特征的提取。为了在基于MFCC-RF的发音分类检错模型的基础上扩大发音错误检测类型的范围,并进一步提高检错准确率。通过深层神经网络提取声学特征中所含有的深层隐藏信息作为机器学习分类算法的输入。提出基于DBN-SVM的发音分类检错模型,同时采用支持向量机的OneClass思想来解决样本数据不均衡问题。基于DBN-SVM的发音分类检错模型新增了对Fronting、Backing和Lengthing等三种错误类型的检测,完成全部六种发音错误类型的分类检错,并通过实验验证了模型的有效性。然后,论文结合互联网电子化教学方式的流行趋势,采用Java Spring框架结合网页相关技术对发音检错模型进行Web系统的初步设计与开发。实现了学习者自由、在线的进行发音纠错和提高的平台,为未来移动在线英语发音学习的发展奠定了一定的基础。最后对全文进行了总结与展望。阐述了本文自动发音检错系统构建中有待解决和完善的地方和下一步的工作方向。"
1316,基于机器学习的基站空调运维及用能调度管理平台的设计与实现,"通信基站的节能对电信行业具有十分重要的意义。即将到来的5G网络将有更多的流量负载,移动通信网络能耗的影响将更加严重。减少移动通信网络的能耗已经引起了人们的极大关注,在保证通信设备和通信设施正常运行的前提下,对基站空调进行节能分析是十分有必要的。本文以基站空调运维及用能调度平台为研究对象,通过对基站空调的用能模式进行分析,针对识别出的不同模式采用不同的控制策略;通过对基站站空调的能耗预测,提出用能调度方案。旨在构建一个基站空调运维及用能调度管理平台。本文首先分析了平台内基站空调数据的质量特点,根据数据的质量特点,利用机器学习的理论方法对数据进行预处理,提出了适用于基站空调数据的预处理体系。其意义在于为接下来的数据分析提供可靠的数据,并降低其复杂度。.其次,利用决策树、K-means、等方法对基站空调系统用能模式进行识别,并采用遗传算法优化K-means,进行对比分析,验证了算法的有效性。再次,提出了EMD-AGA-LSTM预测模型对基站空调进行短时间内的能耗预测。通过分析不同输入模式对预测模型的影响,找到最佳了输入模式;通过分析不同本征模态分量IMF重组方式对预测精度的影响,验证了模式分解对预测模型的有效性;通过对所提出的模型的组合方式进行比较,并与常用的预测模型进行比较,验证了本文所提出的空调能耗预测方法的有效性。最后,应用上述理论和方法,设计与实现基站空调运维及用能调度管理平台。"
1317,加密Wi-Fi环境下视频采集设备的流量识别技术研究,"如今Wi-Fi在人们的生活和工作中几乎无处不在,且基于802.11协议衍生出的加密技术为通信传输的安全性和可靠性提供了保障。但是现实中存在恶意用户利用隐藏的视频采集设备,通过加密Wi-Fi实时传输拍摄画面到外界的现象,这些设备在“无形”中传输他人私密信息或企业机构机密信息等,且由于通信加密,传输信息不易被正常用户和网络管理员察觉,从而导致重要信息的泄露。针对这一问题,本研究提出了一种解决方法,通过识别加密Wi-Fi网络中各通信设备的流量统计特征是否符合视频采集活动的流量统计特征,来判断这些设备是否为视频采集设备。本文在不破解加密的情况下,通过对加密Wi-Fi环境下视频采集活动与其他通信活动的流量统计特征进行分析研究,基于其特征差异,来利用支持向量机进行建模学习得到分类器,以识别出视频采集活动的流量。本研究首先通过统计加密Wi-Fi环境下视频采集活动流量和其他通信活动流量的相关特征,分析出视频采集活动流量在速率、帧长度、上下行方向的帧分布等方面,与其他通信活动的流量都存在明显的差异,并利用结合CFS的特征选择算法,从候选特征集中选出了用于流识别的最佳特征子集;接着设计并实现了基于SVM的视频采集设备流量识别优化方法,考虑到本研究的训练样本中存在异常样本的情况,将一种训练样本筛选算法运用在了本研究的识别方法中,由此得到的分类器在分类速率和分类效果上都得到了提升,且比基于其他几种机器学习方法得到的分类器的识别效果要好;最后为了能够判断加密Wi-Fi环境中的通信设备是否为视频采集设备,基于得到的流量识别分类器,设计并实现了一套视频采集设备流量识别系统,并在真实环境中验证了该系统确实可以快速准确地检测出视频采集设备。本研究得到的流量识别分类器,其准确率高达97.04%,且假正率只有3.43%左右;基于该分类器实现的系统,经测试其对视频采集设备的检出时间仅18秒左右。"
1318,基于机器学习的光谱识别与带内OSNR监测,"目前光纤通信系统正朝着超高速、超大容量、超长距离和动态可重构的方向发展。在这样的发展趋势下为了实现光网络的智能化管理,需要对各种速率和调制格式的光信号进行识别,并对其关键质量指标光信噪比(OSNR)进行监测。本文围绕基于机器学习的信号光谱识别技术和带内OSNR监测技术展开研究,其中信号光谱采用新型的基于受激布里渊散射的超高分辨率光谱仪进行测量。本文首先介绍了相关技术的研究背景和发展现状,然后提出了一种基于主成分分析和支持向量机的信号光谱识别方法,实现了九种常用信号的准确识别,具有对色散、偏振模色散、非线性效应以及级联滤波效应容限大的优点。在此基础上提出了一种新型的基于参考光谱法的带内OSNR监测方法,解决了以往同类方法无法实现动态光网络中光信号OSNR监测、对调制失真以及链路条件变化敏感的问题,具有精度高,对信号损伤容限大的优点。"
1319,基于机器学习的TFT-LCD质量预测方法研究,"随着人工智能技术不断发展、工业要求不断提高,各种机器学习、深度学习技术在工业领域内逐渐兴起。“德国工业4.0”、“中国制造2025”等口号的提出也再次加速了工业技术的发展。在TFT-LCD(薄膜晶体管液晶显示器)的质量检测过程中,原始采用抽样检测的方法对整个样本质量进行预估,但这种方式不全面且不具有时效性。随着工业大数据的迅速发展,工业产品质量要求的不断提高,这种简单的质量检测方式已经无法满足日益严格的工业质量要求,更好的工业智能预测技术亟待被发明创造。针对以上问题,论文对TFT-LCD质量预测数据进行分析。对标签的范围和数据集的特点进行分析;对数据预处理的方法以及选取有效数据的方式进行研究,对不同类型的数据进行encoder编码转换;针对该数据集样本少、纬度高的特点,对传统的降维方法进行研究,使用PCA方式对数据进行特征提取。在质量预测阶段,对传统机器学习算法的分类如有监督与无监督学习方法进行研究。通过文献查找与实验比对相结合的方法,对表现较好的预测算法如:随机森林、SVM算法进行深入研究。在此基础上,将随机森林在决策树上的运用思想应用于SVM算法中,设计了一种新的回归预测方法“RAN-SVM”算法,降低了单一SVM算法对数据的敏感性。最后将RAN-SVM算法与传统的随机森林算法进行结合,使用残差拟合的思想,将两类模型融合,并与传统算法中的决策树,KNN,线性回归等算法进行比较。RAN-SVM与随机森林进行融合之后的结果有效提高了整个样本的准确率和鲁棒性,利用该模型进行预测后的结果明显低于其它模型的均方误差值。新的研究算法在实验数据上的良好表现也为机器学习算法的发展提供了新的思考方向,为随机森林思想在传统算法上的应用拓展了空间。将这种算法运用于TFT-LCD的预测当中,可以更加快捷准确的得到产品的最终质量结果,而不是通过传统抽样调查的方式对产品进行最终的检验。使用新的预测技术可以基于预先知道的结果去做对应的决策和应变,对客户负责,对制造生产更加敏感,提升效率,提高产品质量,提高客户满意度。"
1320,基于统计方法与深度学习的Webshell检测模型研究与实现,"随着互联网的高速发展,新兴产业迅速崛起,Web系统广泛应用于社交和银行等重要业务。但是,Web系统容易遭受攻击,严重影响经济安全和社会稳定。恶意代码攻击是主要的Web攻击手段之一,因此,恶意代码的检测研究是当前信息安全领域的研究热点。Webshell是一种典型的恶意代码,它是一种基于Web服务器的后门程序,具有隐蔽性高、危害性大的特点。基于Webshell的典型攻击方式、逃逸手段和现有检测方法,本文提出一种综合统计方法和深度学习的Webshell检测模型,特征向量包括语法特征和语义特征。在统计方法中,以关键词、特殊函数、最长单词等为语法特征,以Webshell代码的操作码序列的词频作为语义特征。在深度学习时,使用词向量编码方式对Webshell代码的操作码序列进行编码,将序列中的每个操作码编码成固定维度的特征向量。统计方法选择随机森林算法进行检测,深度学习选择长短期记忆网络(lstm)算法进行训练。从github上收集正常PHP文件和Webshell共五千多个样本集,实验表明,将两种模型融合后,检测效果更佳。"
1321,基于机器学习的可学习哈希索引研究,"当今人们正处于高度信息化的时代,数据作为信息的载体记录着日常生活中的一切。在这种数据爆炸的时代背景下,如何高效地检索信息已然成为了数据科学及相关领域关注的热门话题。面对海量数据,对其进行高效、准确的查询并非易事,查询过程中很难同时满足高效率和高精度两方面的要求。哈希索引作为一种高效的信息检索方式被广泛应用于各类信息检索系统中,但是在大数据环境下,传统哈希索引的性能还是受到了严峻的挑战,为了能够保证检索效率,不得不牺牲一定的查询精度以换取更高的查询效率。另外,传统哈希索引方法在实现过程中利用了人为构造的空间映射,这也使得哈希函数在表达数据的内在相关性上存在局限性。近些年随着机器学习不断发展,机器学习方法逐渐涉足各个领域,这也为构建哈希索引提供了一种新思路,即利用机器学习模型来构建哈希索引,Google提出的可学习索引架构正是这一思路的产物。本文对前人利用机器学习构建哈希函数的工作进行了总结,在可学习索引架构的基础上提出了一种基于深度学习的局部敏感哈希的可学习哈希索引框架LLSHF,该框架包含四层,每一层都定义了具体的任务规则。相较于前人的工作,本文创新性的将机器学习构建哈希索引归纳成具体框架,该框架可根据具体需求构建具体的哈希编码模型。本文利用LLSHF实现了面向低维数据的哈希方法和面向图像检索的哈希方法:面向低维数据的哈希方法在框架中引入Hilbert曲线映射作为模型训练的目标,并对哈希方法是否满足广义LSH定义设计了实验方案;图像检索方法则利用迁移学习构建了端到端(End-to-End)的模型方案,可以直接将图片作为模型的输入,然后生成哈希编码。最后,通过实验验证了LLSHF框架下面向低维数据的哈希方法作为一种局部敏感哈希方法,完全满足广义LSH定义;而基于LLSHF的图像检索哈希编码模型同样具备优良的查询性能。"
1322,基于HOG特征和多分类器集成学习方法对行人检测的研究,"随着人工智能技术的繁荣和信息化大数据时代的到来,计算机视觉技术已经成为AI领域里不可或缺的一部分。与此同时行人检测技术作为当前计算机视觉技术中的重要内容,也受到了众多相关学者的关注。行人检测技术是通过判断图像中是否有行人存在,并把图像中出现的行人从背景中准确定位出来的一种图像分析技术。该技术在工程应用、学术研究和智能科技实践中都起到了关键作用,受到了相关领域人员的广泛关注。经过多年的发展,行人检测技术已经取得了一定的成就,也成为目标检测领域的研究热点。就目前而言,对行人检测的研究方法主要有两类,一类是基于运动检测的算法,这类方法首先利用背景建模算法把待检测目标中运动的前景提取出来,再通过分类算法对其进行分类,通过分类结果识别是否有行人存在。这种方法实现简单,速度快,但只能检测运动的目标且容易受到光照、阴影和天气环境的影响。另一类是基于机器学习的方法,人体无论在现实生活中还是图像视频中都具有自身的一些外观特征,而机器学习算法就善于从大量的样本数据集中自动学习人体的不同变化。因此,我们就可以通过合理的选择机器学习算法自动的学习样本中相关的人体特征建立人体模型。该类方法对不同样本的鲁棒性强,同时还可以通过人为的选择训练样本,挑选合理的分类器,来避免很多不利的条件。基于第二类方法的诸多优点,本文就借鉴第二类方法的思路,以Dalal提出的HOG特征作为人体特征的描述算子,针对传统的行人检测算法采用单一或单类的分类器,识别率较低,易造成误检漏检的问题,提出一种利用多分类器集成的集成学习方法对图像进行行人检测。首先利用梯度方向直方图(HOG)特征对训练样本集进行特征提取,得到训练不同分类器所需要的特征向量,然后利用提取出的特征分别训练出朴素贝叶斯(NB)、逻辑斯蒂回归(LR)和支持向量机(SVM)三个组件分类器,再利用加权投票的结合策略将三个组件分类器进行集成,形成一个强分类器,得到一个识别率更高、综合性能更好的行人检测方法。最后,使用本文方法与多种传统的检测方法在多个的行人检测数据集上进行了实验,验证了本文的方法具有更高的检测准确率,同时可以减少了误检和漏检的情况,总体而言,具有更好的检测效果,提高了行人检测识别效果的鲁棒性。"
1323,基于Bi-LSTM+CRF的医学影像报告结构化系统设计与实现,"随着医疗健康服务不断朝着智能化方向发展,机器学习在医疗领域的应用开始成为人工智能时代的研究热点之一。医学影像报告作为医疗文档的重要组成部分,是放射科医生对影像表现的描述与总结,蕴含大量对病灶的描述。从医学影像报告中提取这些重要信息,建立影像报告与影像图片间的关联,能够更好地服务于临床决策、数据挖掘等各类临床信息系统,从而减轻专业医师的工作量。目前医学影像报告大多以非结构化或半结构化的文本形式存储,计算机难以从这些不规则的文本数据中直接提取有价值的信息,从而无法利用机器学习算法进一步对数据进行挖掘分析。因此,如何从医学影像报告中自动、高效地提取所需信息,形成结构化的数据,并建立文本描述和影像病灶的关联,是目前智能医疗服务进程中的重要挑战之一。本文针对乳腺钼靶医学影像报告的结构化问题,利用机器学习模型Bi-LSTM+CRF来提取文本特征标签,并设计映射规则,用于实现结构化。本文的主要工作有:(1)解析影像报告及设计结构化模板。本文针对乳腺钼靶影像报告,结合国内外相关研究以及专业医师的指导,总结影像报告主要涵盖的内容及其结构,并设计结构化的报告模板。(2)设计影像报告文本特征标签。临床自由文本中存在术语和表述多样性的特点,本文针对报告中对病灶的描述,设计统一的文本特征标签,为机器学习模型提供输入。(3)采用机器学习模型实现标签提取。本文基于上海市某三甲医院提供的数据,采用Bi-LSTM+CRF模型进行迭代训练,模型最终达到了95%的准确率。(4)影像报告结构化系统的设计与实现。本文基于Django框架,将机器学习模型、结构化映射规则等功能模块进行封装,设计并实现了一个自动化的、可扩展的影像报告结构化系统。"
1324,图片多标签分类上的类别不平衡问题研究,"逻辑回归是多标签分类以及排名任务中最常用的损失形式,但逻辑回归下的Sigmoid交叉熵损失函数受类别不平衡的影响极其严重。这种不平衡主要来自两方面,一是单个类别正例样本与负例样本比例的不均衡,二是各个类别之间样本数量上的巨大差别。这篇文章首先指出了这两种不平衡能通过对分类器输入随机生成的噪声样本来量化,即使噪声样本不能提供任何有助于分类的信息,分类器对噪声样本给出的预测值在各个类之间仍然有显著且稳定的差异。这篇文章认为这些不依赖样本信息的预测差异反映了分类器的推断倾向,并足以作为在类别不平衡学习中校正分类器的依据。传统的类别不平衡学习主要面临两个问题,一是对类别不平衡影响最终预测的深层机制只有定性讨论,缺乏定量分析;二是没有度量模型受类别不平衡影响程度的定量指标。以上两点导致对类别不平衡问题的解决方案大多停留在启发式的加权策略上,缺乏系统的理论依据。这篇文章以图片多标签分类为基准任务,详细地讨论了多标签分类任务下类别不平衡问题的成因,揭示了类别不平衡与推断倾向之间的联系,并提出了用于定量测量推断倾向的噪声统计方案,并在此基础上提出两项Sigmoid交叉熵的改进方案,期望极值平移(ES)和噪声样本约束(NC),进而展示了如何通过降低推断倾向的影响来缓解类别不平衡问题。最后,在三个公开数据集Microsoft COCO,NUS-WIDE和DeepFashion上,通过对比试验和可视化论证了推断倾向与类别不平衡间的关系,以及两种改进方案的有效性。"
1325,基于位置密度与距离特征的差分隐私推理攻击研究,"随着信息技术的发展,各种各样基于位置的移动设备与服务广泛普及,使得包含了个人信息的移动数据呈爆炸式增长。一方面,这些移动数据可以用作商业研究,为用户提供更准确的服务;另一方面,原始的移动数据不仅包含大量个人属性,还可从中挖掘用户出行轨迹、社交关系,存在隐私泄露的风险。现有的隐私保护方法中差分隐私被广泛使用,但是对其进行推理攻击的研究却很少。通过对差分隐私进行推理攻击,发现其存在的隐私泄露场景,对未来差分隐私保护方法的完善具有现实意义。针对差分隐私存在的强独立性假设,以及经差分隐私处理后的数据依然能在一定扰动范围内保留用户的位置分布特征这两个问题,先给出扰动后的“真实数据”和“虚假数据”的定义。通过给定一个阈值,当扰动后位置到原始位置的距离在该阈值内,其大概率保留着原始轨迹的特征规律,则对应记录为真实数据,否则为虚假数据。基于这个概念设计了一个推理差分隐私的攻击场景,假设攻击者拥有部分真实数据作背景知识,并且利用背景知识来达到区分真假数据的目的。由此提出了一套针对差分隐私的推理攻击方法(DPIA-LDDF,Differential privacy inference attack based on location density and distance features),将每条扰动后的数据作为一个样本,从多记录中提取相关的位置密度与距离特征作为样本属性,根据数据的真实性为每个样本打上正负标签;将背景知识对应扰动后数据集的样本集作为训练集,一起训练出一个基于决策树的集成模型;将其余待推理的样本集输入该模型,可预测出每个样本的标签,即得到了每个样本对应的签到数据的真实性。设计并实现了该攻击方法,包括界定真假数据的阈值的指定算法,位置特征提取算法,基于决策树的集成算法。在多个数据集上进行实验,验证了DPIA-LDDF方法的有效性。"
1326,基于逆向工程及机器学习的Android应用漏洞检测技术研究,"由于移动互联网的快速发展,移动设备已经成为成为现如今人们生活各个方面的必需品,伴随着Android系统在市场份额中的占有率越来越高,截至到目前为止,Android系统的用户已经占据了市场份额的半壁江山,基于Android系统的应用程序已经成为了人们生活中不可或缺的一部分,从而吸引了一大批开发者来开发上线自己的应用程序。然而由于Android系统的安全机制不完善、开发人员安全意识淡薄等原因以及许多应用商店缺乏有效的漏洞检测措施等,导致许多Android应用程序的漏洞从开发到发布都没有得到修复与改进,这导致许多攻击者潜入空中,给用户和平台带来了许多损失。因此如何有效的检测出Android应用的漏洞成为了当今Android平台迫在眉睫的事情。目前针对Android应用漏洞的检测方式可以分为三种:静态漏洞检测,动态漏洞检测,混合漏洞检测。在近些年,Android应用漏洞检测领域得到了飞速的发展,但是现有的Android应用漏洞检测方法仍存在许多不足,如漏洞检测效率低下,检测不全面,精度不够高等。以动态加载漏洞为例提出了一种基于逆向工程与机器学习的Android漏洞检测方法。该方法使得漏洞检测效率更加全面有效。围绕该方法,完成了以下工作:(1)对Android的系统结构、应用结构及安全机制做了深入的研究。对现有比较成熟的Android应用漏洞的检测手段做了详细的介绍。(2)对于现有脱壳技术会造成数据丢失问题做了研究,提出了一种基于内存Dump的解决方案,Dump文件是内存镜像,存放程序运行时信息,结合Hook技术,可以获取程序运行时动态脱壳之后的dex文件。(3)针对从Android应用中提取到的原始特征集合比较庞大导致检测效率低下问题,改进了ReliefF特征筛选算法来对原始特征集合进行特征提取,从而提高漏洞检测效率。(4)由于一种类型的漏洞存在多种实现形式、不同的漏洞危险级别也不同,传统二分类算法与等代价多分类算法存在局限性,针对该问题设计了一种多标签代价敏感集成学习分类算法来对漏洞进行分类。(5)对构造的检测方案进行了实验,采用了覆盖率、汉明损失、子集精准率作为实验指标,在数据集上进行了实验,并与现有的检测方案进行了对比,验证了该方案的有效性。"
1327,基于生成式对抗网络的图像标注方法研究,"随着互联网技术的发展以及智能移动设备的快速普及,每天都会产生数以亿计的图像数据并且被各个用户上传到互联网,这些图像数据在大多杂乱无序的同时又包含着海量有用信息。为了对这些图像数据进行有效管理并高效利用其包含的有用信息,图像语义自动标注技术应运而生。目前,图像自动标注技术大多通过传统机器学习或者深度学习的方法构建标注模型实现对未知图像的自动标注。但是,这些标注方法大多都存在一个问题,即输出层的神经元(分类器)数目与数据集标注词汇量成比例,这将导致2个问题:1.模型实用性较差,当数据集词汇量较大时,过大的输出层数目将会急剧增加模型的设计和训练难度;2.模型结构稳定性差,模型结构会随词汇量变化而改变。针对上述问题,本文将生成式对抗网络与Word2vec词向量模型相结合,设计并实现了一种新的标注模型。首先,通过Word2vec模型将标注词汇映射为一个维数固定且可选择的多维词向量;其次,利用生成式对抗网络构建一个神经网络模型(GAN-W),使模型生成器的输出层神经元数目与多维词向量维数相等,生成器将生成与词向量同维度的向量,使模型输出层神经元数目与标注词汇量解绑;最后,对模型多次输出结果进行排序,通过排序结果来决定图像对应的最终标注。本文模型分别在Corel 5K和IAPRTC-12图像标注数据集上进行了实验:1.通过Word2vec模型输出向量维度对模型性能影响的实验证明了本文模型能够解决上述问题,模型的输出神经元数目可以在一个很大范围内自由选择。2.通过与其他模型的性能对比实验得出本文模型的准确率P和F1值均高于其它模型,同时召回率R仅次于CNN-MLSU模型,模型的标注性能具有较大的提升。3.通过模型的实际标注结果展示出了本文模型对每幅图像标注的标签数目自适应,更加符合实际标注情况。总而言之,本文模型在解决输出层神经元数目与数据集标注词汇量成比例问题的同时模型相较于其它标注模型标注在标注性能上有一定提高,在实际标注结果中同样具有优势。"
1328,基于特征选择和集成学习的入侵检测技术研究,"随着信息技术的迅猛发展,在给我们生活带来便利的同时也带来了许多的安全隐患。在大数据时代下,每人每天使用网络产生的海量数据经常被一些不法公司窃取用作商业用途,对于一个企业来说,重要数据就是使其发展延续的命脉,对于国家来说,重要信息泄露引起的危害是不可估量的。因此为了更好的维护信息安全,防止数据泄露,入侵检测技术应运而生。近年来人工智能一词不再陌生,机器学习也被应用到各个领域中,这其中就包括了网络安全领域。为进一步提高入侵检测算法的适用性和时效性,研究基于机器学习的入侵检测算法具有重大意义。该文围绕特征选择和集成学习两种机器学习算法对入侵检测技术进行研究,具体内容如下:首先,对两种入侵检测数据集分别进行分析处理。分析了KDD cup99数据集,针对其自身缺陷本文提出使用UNSW_NB15数据集,对比KDD cup99数据集而言,UNSW_NB15数据集更加真实的反应了现代网络环境。分别对以上两种数据集进行数值化、标准化和归一化的实验处理,得到可以直接用于入侵检测的数据。其次,设计并完成基于特征选择的入侵检测方法与实验。针对入侵检测数据集数据维度过高的问题,深入研究了特征选择的方法。使用主成分分析算法分别对以上两种数据集进行特征选择,保留主成分特征属性,去除数据影响较低的特征列。在入侵检测实验中使用了机器学习中典型的有监督算法:K-邻近分类算法和朴素贝叶斯算法,分别对两种数据集进行了分类实验。实验证明使用特征选择方法在一定程度上提高了检测率,极大地节约了计算时间。最后,设计并完成基于集成学习的入侵检测算法与实验,并在此基础上完善了入侵检测系统模型。在特征选择基础上加入了集成学习算法,对多个基分类器进行投票,根据投票结果决定分类结果。实验结果表明加入集成学习算法后,提高了入侵检测的准确率。系统模型的设计是在通用入侵检测模型基础上加入了特征选择和集成学习模块,提高了系统的综合性能。"
1329,基于机器学习算法的高速公路交通事件检测研究,"近年来,国家大力发展交通运输,高速公路产业发展迅猛,截至2018年底,我国的高速公路通车里程突破14万公里,里程规模位居世界第一。同时,随着交通网络的不断扩大和车辆的大规模增加,交通事故频繁发生,交通拥堵严重,损害了正常的交通秩序。及时准确的交通事件检测,能够有效缓解交通事件造成的交通拥堵,预防二次事故的发生,增加高速公路通行的安全性。交通事件自动检测(Automatic Incident Detection,AID)属于经典的二分类问题,可以将事件状态分为两种:正常运行和交通事件。现实场景中,交通事件数据一般远少于正常运行状态数据,因此,交通事件检测问题实质是不平衡分类问题。本文以基本的机器学习算法作为分类器,并结合不平衡数据集的处理算法,提出了几种交通事件检测模型。首先,将贝叶斯网络、逻辑回归、SVM、决策树、神经网络、AdaBoost、梯度提升树、随机森林分别作为分类器,并采用网格搜索方法进行参数优化,比较不同分类器的性能,筛选出综合性能更优的随机森林作为交通事件检测算法的分类器。其次,为了解决交通数据集的不平衡问题,提出基于合成少数过采样技术(Synthetic Minority Over-sampling Technique,SMOTE)的随机森林算法模型,使用少量样本来控制人工样本的生成和分布,以达到数据集均衡的目的,再通过随机森林分类器,实验获得相应的性能参数值,并与仅使用基本机器学习算法的模型进行对比分析。最后,考虑到SMOTE方法生成的样本存在重复项,从而容易导致模型过拟合的问题,于是引入数据清洗技术Tomek links和ENN(Edited Nearest Neighbor),可以清除重复样本。先使用SMOTE方法得到平衡数据集,再利用Tomek links或者ENN方法剔除平衡数据集中的噪声点,随后通过随机森林分类器,并与前面几种模型的检测性能进行对比分析。得出最终结论,基于SMOTE和Tomek links结合的随机森林算法事件检测模型的性能最优。本文的实验数据来源于京沪高速公路无锡检测点的真实数据库,实验算法以PyCharm软件为编程平台实验。实验结果表明,本文提出的基于SMOTE和Tomek links方法的随机森林交通事件检测模型能改善不平衡数据集的交通事件检测效果,提升事件检测效率,获得更佳的综合性能。"
1330,基于深度森林的交通标志识别算法研究,"近年来,随着经济与科技的快速发展,汽车在人们的日常生活中越来越普遍,为人们的出行带来了极大的便利。但是,不断增加的汽车保有量和愈加复杂的交通路网也带来了一系列交通拥堵和安全问题。对此,智能交通系统应运而生,自动驾驶系统作为其重要的组成部分得到了极大的发展。交通标志识别作为自动驾驶的关键技术之一,成为了机器视觉和模式识别领域的研究热点,引起了众多专家学者和相关科研机构的关注。然而,交通标志种类繁多并且自然场景中天气变化多端、光照强度不定、标志存在相似背景等复杂的交通环境都给交通标志识别带来了一系列挑战。本文在总结了大量国内外相关研究的基础上,利用深度森林及其相关知识重点进行了交通标志识别的算法研究。本文的交通标志识别研究工作分为交通标志检测和交通标志分类两个阶段,其主要工作包括:(1)在交通标志识别的基础预备方面,制作了国内的道路交通图像数据集结合公开的数据集构成了初始数据集,并通过直方图判断其光照情况,对光照情况较差的图像采用限制对比度的自适应均衡算法进行预处理。(2)在交通标志的检测阶段,提出了一种HOG特征和SVM的交通标志检测方法。该方法首先通过统计交通标志的颜色阈值后对其图像进行阈值分割,去除了大量干扰,然后利用最大稳定极值区域算法对连通区域进行检测,完成了交通标志感兴趣区域的粗提取,最后提取交通标志感兴趣区域的HOG特征,并结合SVM进行二分类以确定真正的交通标志区域。实验表明该方法在检测时间上具有极大的优势,同时实现了较高的准确率。(3)在交通标志的分类阶段,在研究了随机森林和深度森林算法的基础上,提出一种基于深度森林的交通标志分类方法。该方法利用多粒度扫描的方式把交通标志数据切分成多实例特征,并且通过深度级联森林对特征进行逐层表征学习。实验结果表明该算法在准确率和运算时间上均得到了较好的效果。"
1331,光声成像在骨质疏松诊断中的研究,"骨质疏松症(osteoporosis)是一种常见的全身性代谢性骨病,以单位体积内骨量减少及骨微结构改变为特征,多见于绝经后妇女和老年男性。骨质疏松的严重后果为发生骨质疏松性骨折,即在受到轻微创伤时或日常活动中即可发生的骨折。近年来,骨质疏松在我国的发病率逐年提升,已经成为了危害我国老年人健康的一大隐患,甚至发病人年龄有年轻化的趋势,因此寻找一些快速,有效的检验骨质疏松的方法成为了当务之急。本文主要是探究一些诊断骨质疏松的新型方法,包括传统的定性的频谱分析法和新型的定量的机器学习方法。近年来宽带超声频谱法(QUS)是一种新兴的检测骨质疏松的定性方法,主要通过斜率的变化趋势来确定骨质疏松的变化程度。我们首先通过数学推导来证明光声频谱法对骨质疏松检测的可行性,然后我们通过光声频谱的变化趋势和宽带超声频谱进行对比,来展示光声频谱法的确可以定性的检测骨质疏松的变化情况。仿真实验和实际实验都证明了两者具有相同的变化趋势,我们根据骨质疏松的腐蚀程度不同确定了光声频谱变化的趋势,再根据三组骨质情况差异的骨质信号光声频谱与超声频谱对比得出了结论。除了定性的方法,本文还研究了探测骨质疏松的定量方法。我们主要采用了k-means聚类,svm支持向量机,cnn卷积神经网络三种方法。对于前两种方法,我们提取了一些包括峰值,均值,频谱斜率等在内的十多个特征向量来作为参数进行训练,而cnn则是把信号当做一维图像对它进行分类,最终svm和cnn取得了分类的较好的效果。"
1332,基于顶端排序与深度模型的基本面量化方法,"在股票市场中,量化投资作为一种利用计算机程序替代人为主观判断的投资方式,可以避免投资者因情绪波动而做出非理性的投资决策。通过对上市公司财务报表、公开数据进行文本挖掘与抽取,量化投资策略可以实现对于上市公司的基本面的分析,并寻找盈利状况较好的优质公司进行资产配置。为进一步提升量化投资策略的效果,本文对基本面量化策略中的量化选股模型和公告文本信息抽取问题进行了研究,主要创新成果如下:1.本文提出了一种基于顶端排序模型的量化选股算法。以往量化选股算法基于分类模型,难以体现对多支股票之间优劣的比较。本文从优化排序的角度出发,提出大小窗口下的顶端排序模型,着重预测业绩最优的少数股票及其顺序,更加利于资产配置。该方法构建大窗口来跟进股价较长时期内涨跌模式的演进,利用小窗口实现股价短期内走势的捕获,以此实现准确的排序。该方法具有时间复杂度低、可解释性强的优点,且得到的因子线性权重也可以结合传统多因子策略进行选股。实证检验结果表明,本文方法显著优于对比方法,可以稳定获得超额收益。2.本文提出了一种基于深度模型的递进式公告信息抽取方法,通过及时准确地获取上市公司最新公开信息,来帮助量化算法快速准确地反映市场变化。该方法将文本信息抽取问题拆分为句-词两层结构并进行递进式分解。在语句层面,模型使用改进词向量的卷积神经网络模型,滚动更新词嵌入向量空间,实现数百条语句中少量关键语句的定位。在得到相关句后,再结合人工规则+TF-IDF+正则表达式实现对最终目标数据的抽取。本文以上市公司担保类公告作为切入点,实验结果表明,本文方法在公告抽取任务中,性能显著优于对比方法,因此可以有效帮助量化选股。"
1333,基于深度学习的专业领域术语识别系统设计与实现,"随着移动互联网技术与信息技术的高速发展,传统的纸质文献正在逐步被电子文献取代,这种进步在极大程度上减少了科研人员在获取文献资料时需要投入的时间与精力。专业领域术语识别是一项从特定专业领域的文本语料库中发现该领域专业词汇的任务,对电子文献的语义分析以及文本语料库的快速检索都具有重要意义。当前主流的专业领域术语识别过程主要依靠统计学和语言学的结合来完成术语的提取与识别过程,好的识别方法往往来源于几种简单的术语识别算法的结合。目前的术语识别技术主要依赖于传统的统计学方法,一些研究人员已经开始探究深度神经网络在术语识别过程中的应用,但尚未形成完整的可操作系统。因此,本文基于深度学习技术,设计并实现了一个可扩展、可灵活实施的专业领域术语识别系统。本文主要包括以下几方面工作:(1)基于N-gram模型对原始文本进行预处理,将完整的文章用特殊标识切分成细小的文字片段。(2)提出了一种基于注意力机制的双向长短期记忆神经网络模型提取文字片段中的术语,并引入条件随机场模型提升网络对长单词的识别准确率。(3)基于信息熵提出了一种术语可信度计算方法,提升系统对当前专业领域术语的识别准确率。(4)引入字向量模型和支持向量机(SVM)对提取出的术语自动分类。实验结果显示,本系统能够有效地从原始文本中自动提取专业领域术语,并依据原有术语库对提取结果进行分类,能够大幅度地减少构建术语库过程中的人工操作。"
1334,产品评论文本的情感分析方法研究,"随着互联网的普及和信息技术的飞速发展,海量的主观性评论出现在微博、淘宝、天猫等各种网站上,这些评论包含了发表者对评价对象的情感信息和主观观点,用户也习惯从各种评论中获取有价值的信息来辅助自己的决策。情感分析涉及到人工智能、自然语言处理以及机器学习等领域,是一门综合性研究学科。当前,对于文本情感分析研究者通常采用的研究方法是基于情感词典和基于机器学习的方法,但是传统的情感分析方法大都需要大量的人工工作,而且也不能得到很好的性能。本文所研究的情感分析是二分类(正面情感和负面情感)的,为了改善产品评论文本的情感分类效果,设置了多组对比试验来选择最优的分类模型,主要做了以下工作:(1)通过发掘新的情感词来扩展情感词典的方法,提高了情感词典的覆盖度。包括两个方法:基于近义词和规则模板进行情感词典拓展。实验把扩展前后的情感词典用于情感倾向性计算中,测试分类结果对比表明扩展以后的词典有效的改善了分类效果。(2)研究了基于机器学习的情感分析。在浅层学习中,采用改变传统的特征选择方法比如一元词组、二元词组等,而是将词向量作为特征输入,并融合情感信息和极性转移在里面,使生成的分类器获取了更深层次的语义信息,该特征表示方法避免了传统方法中用忽略语义、极性转移及特征维度高的问题。在深层学习中,考虑到长短时记忆网络的优势,选取了基于attention机制的双向LSTM模型作为深度学习分类模型。实验证明深层学习算法比浅层分类算法的情感分类效果更好。(3)研究了基于词向量技术的情感分析方法。把FastText模型和BERT模型分别用于情感分析研究中,FastText的和word2vec原理类似,BERT像是word2vec的一个加强版,他们的词级别或句子级别向量表示一样都是预训练得到的,word2vec的向量表示与上下文无关,BERT却是上下文有关的,这两个模型对比实验上结果表明,BERT在分类上表现的更好。(4)研究并实现了基于融合技术的情感分析方法。主要是基于Bagging算法对文本进行情感分类,使用多个弱分类器来共同决策分类的结果,同时,根据目前分类模型的发展情况,采用情感词典与基于attention机制的双向LSTM模型进行结合的方法作为Bagging算法的对比试验,实验结果表明,基于Bagging算法的情感分析的分类准确率比较高。"
1335,智能电能表故障集成分类方法研究,"随着电力行业智能化程度的提高,智能电能表由于在信息采集与存储、实时监测与控制、网络通信与信息交互等功能上的优势,覆盖率越来越广,逐步取代了传统的非智能电能表。同时,由于不断增加的功能和结构复杂性,智能电能表在实际的复杂工况下故障率也相应提高。为提高用电的安全性与经济性,可靠地识别并预测电能表故障具有重要意义。本文针对智能电能表的历史故障数据,运用统计原理和机器学习的方法,对电能表的属性展开分析并对电能表的故障分类与预测展开研究,主要工作如下:首先,详细分析了智能电能表故障数据的属性字段含义及其统计特性,分别从分类属性和数值属性角度进行分析,通过相关性对分类属性进行筛选,并将属性字段进行预处理,为后续特征工程和模型建立提供可靠基础。其次,对比分析了基于监督学习的多类别分类方法,根据数据集的编号属性为主的特点,比较了多种分类器在本文数据集的性能,并对性能结果进行分析。然后,针对智能电能表在决策树和k-近邻分类器的表现以及编号属性占比大的特性,设计了基于概率的分类属性特征提取方案。运用集成学习的思想,将多种相似性度量方法应用于k-近邻分类算法并进行集成,得到智能电能表故障分类的规则,改善了分类器的性能。最后,基于概率的分类特征提取方案,运用k-近邻分类器得到各属性的重要性权值,设计了基于特征加权的XGBoost分类方法,在提取出分类特征的可用信息的同时改变输入数据的权重,在XGBoost分类方法的性能上有所提升。"
1336,基于深度学习的医学影像变化检测算法研究,"现如今,科学技术飞速发展,物质水平大大提高,人们的生活节奏逐步加快。但也加快了癌症发病率的增长趋势。放射治疗作为肿瘤治疗的首选方法,对癌细胞拥有着较强的杀伤作用,但对正常组织影响不大。放疗常需要根据影像的特征来追踪评估疗效,所以放疗前后医学图像的变化检测技术就显得尤为关键了。深度学习近年来在各个领域大放异彩,在医学图像自动化处理方面更是发挥着重要的作用。与机器学习不同的是,深度学习利用深度神经网络模型来分析和研究数据,并通过特征提取和特征分类来提高效率,因此受到广大研究者的青睐。本文采用了基于特征提取和深度置信网络相结合的深度学习方法来进行医学图像的变化检测,能够检测不同时期的放疗前后的医学影像的变化,具有了良好的检测效果,通过检测结果能够记录病变区域的变化和发展趋势,从而为临床诊断提供更多参考依据。具体研究内容如下:(1)基于深度学习的变化检测方法需要建立DBN(深度置信网络)来训练数据,而DBN是由多个RBM(受限玻尔兹曼机)构成的,这就首先要对每个RBM进行预训练来来得到初始权重。由于训练神经网络需要进行样本的筛选和特征提取,本文提出一种基于模糊聚类的联合分类算法,并通过快速广义模糊C均值法(FGFCM)来缓解医学图像的伪影现象和部分容积效应,最后将提取的特征输入到深度置信网络中,利用反向BP算法调整参数,最后得到最终的医学影像变化检测模型。(2)本文提出采用SIFT特征提取和深度神经网络模型相结合的方法,SIFT特征可以较为全面地描述原图像的不变特征,这样有利于有效的区分变化部分和非变化部分。其次,进一步使用深度神经网络能够获取到原图像的深层次特征信息。因此,本文工作主要是尝试将这两方面的算法有效结合,利用SIFT特征的尺度不变性和平移不变性以及深度置信网络自身强大的特征提取能力,使深度置信网络来得到较好的训练效果。最后将改进的方法应用在医学影像上,来解决医学影像的变化检测问题。通过设置实验对多组真实的医学影像数据进行实验后证明,该方法在医学图像变化检测方面有着较好的效果。综上所述,本文研究的方法可以有效检测出放疗前后医学图像发生的变化,并为后续的医疗诊断提供理论基础,而且在一定程度上解决了医学图像中的伪影现象和部分容积效应。实验结果表明,该方法是有效的。"
1337,D2D网络中基于强化学习的路由选择与资源分配算法研究,"随着通信网络的发展,终端直连通信技术(Device-to-Devic,D2D)被广泛关注,它的应用将满足用户日益增长的流量需求。然而,D2D技术的引入使得蜂窝网络内部的干扰冲突加剧,用户难以满足服务质量(Quality-of-Service,QoS)的需求。一些传统算法基于网络“抓拍”信息可以计算得到各采样时刻的网络控制策略,却难以适应复杂多变、高度动态的网络环境。因此,本文着手于动态环境下的D2D网络中的通信问题进行了深入地研究,并结合正在兴起的机器学习技术,提出了更加智能化的解决方案。在本文中我们将分别研究“多跳D2D网络”与“D2D直连通信”两类D2D应用场景的通信问题,提出了在两种场景下基于强化学习的在线学习方法,从而解决多跳网络中的路由问题与D2D直连网络中的资源分配问题。而随着问题复杂程度的增加,强化学习算法也相应由浅入深。在路由问题中,因问题复杂程度较低,我们利用传统强化学习算法中的值迭代算法求解,而在资源分配问题中因问题规模变大,本文依次提出了基于深度Q学习(Deep Q-Learning,DQN)的资源分配算法和深度确定性策略梯度(Deep Deterministic Policy Gradient,DDPG)的资源分配算法分别解决了问题中状态空间连续与动作空间连续的问题,而这两种算法都是深度强化学习(Deep Reinforcement Learning,DRL)中的经典算法。在多跳D2D网络路由问题中,我们考虑了三类随网络动态变化的QoS指标,并利用值迭代算法求解,同时提出了分布式的强化学习算法解决了集中式算法学习周期过长的问题。仿真发现,在动态环境中,所提算法在性能与时间复杂度方面相较于传统算法有着更好的表现。在D2D资源分配问题中,我们考虑单信道与多信道两类资源复用场景,在用户移动构成的动态环境中,利用DRL算法智能体可以通过自身探索与环境反馈实现网络自学习、自优化的智能化控制。在单信道的资源复用场景,我们单独解决单信道上的D2D功率控制问题,而在多信道的资源复用场景,D2D的总发射功率可以以不均等的方式分配在各信道资源上,从而优化蜂窝网络整体的吞吐量。仿真发现DQN与DDPG两种算法均具备智能性,并在性能上优于传统算法。同时在仿真中我们发现DQN算法易出现“伪收敛”问题,因此本文又提出了“样本加权”的优化方法并有效的解决了该问题。"
1338,基于三轴加速度计的人体活动识别,"随着传感器技术的发展,传感器的体积越来越小,便携性越来越高,基于传感器的人体活动识别吸引了众多研究学者的关注。目前,人体活动识别主要通过机器学习方法和深度学习方法实现。高精度、高效率、特定的应用场景、多传感器的融合等因素是解决人体活动识别任务的重要目的,而传感器内部轴之间的隐藏关系却少有人关注。现阶段针对传感器内部轴之间的隐藏关系的研究方法大都依赖于人的领域知识,具有一定的局限性。为了解决该问题并探索隐藏关系对分类准确率的影响,本文提出了基于多通道数据融合的卷积神经网络方法以及基于单通道数据融合的卷积神经网络方法,对使用三轴加速度计的人体活动识别进行研究,本文的主要工作如下:(1)为了利用传感器内部轴之间的隐藏关系,本文提出利用数据融合的方法去完成包含传感器内部轴之间隐藏关系的融合数据的获取;之后,使用卷积神经网络进行特征提取及活动分类。由于原始传感器数据为1维数据,拥有多个通道,所以本文根据其数据格式提出了基于多通道数据融合的卷积神经网络方法。(2)考虑到1维卷积核只能捕获到时间的局部依赖性,2维卷积核与1维卷积核相比,不仅能捕获时间的局部依赖性,同时可以捕获空间的局部依赖性。在此基础上,本文提出了基于单通道数据融合的卷积神经网络方法。该方法将1维的传感器数据转换为2维的数据(数据中每一行均为融合数据),并将其输入到卷积神经网络中,以提高活动识别的准确率。针对传感器数据格式的不同,本文提出了多通道数据融合方法和单通道数据融合方法;在此基础上针对人体活动识别的研究,提出了基于多通道数据融合的卷积神经网络方法和基于单通道数据融合的卷积神经网络方法。(3)为了验证本文提出的基于三轴加速度计的人体活动识别方法,本文使用WISDM公开数据集进行实验。通过大量的实验分析,证明了两种数据融合方法的有效性。两种活动识别方法与卷积神经网络方法的对比实验,证明使用了数据融合的活动识别方法可以获得更高的分类准确率,且基于单通道数据融合的卷积神经网络方法具有更优的效果,其准确率达到了98.83%。本文提出的活动识别方法有效的解决了现阶段基于传感器的人体活动识别研究中存在的问题,且该方法更适用于解决三轴数据差异较大的活动识别问题。"
1339,基于主题的文本细粒度情感分析与应用,"基于主题的文本情感分析技术逐渐成为人们关注的热点,其主要任务是通过挖掘用户评论所蕴含的主题、以及对这些主题的情感偏好。本文中的情感倾向包含三级:满意、中立以及不满。区别于传统情感分析和方面级情感分析,“细粒度”体现为在一段评论中,以多个三元组作为结果呈现,并非一段文本只有一个情感;除此之外,主题词不再是“方面”级别,而是随机性更强的任意词语。本文基于真实的互联网商品评论数据,采用模型融合思想,提出了一套包含主题词与情感词抽取、主题词与情感匹配以及主题情感分析的算法框架,在交叉验证的条件下使用标准的F1-Score评判指标取得稳定且显著的效果。本文的主要工作如下三个方面:(1)主题词与情感词抽取方面,将双向长短时记忆网络联合条件随机场作为算法框架;受词嵌入思想的启发,提出主题词与情感词词典嵌入向量方法(Dict Embedding),使召回率以及精确率均取得显著提升。(2)主题词与情感词的匹配策略方面,提出分层匹配策略。分层匹配策略包括两个阶段:在R(Recall)阶段先对所有进行“粗选”,提高召回率;在P(Precision)阶段,为了提高精确率,再基于当前配对的相关信息使用深度神经网络进行“精选”,实验结果验证了策略的有效性。(3)情感分析方面,考虑到语境的差异性,不仅使用情感词作为特征,还引入上下文词向量等相关信息,提出一种新的联合情感分析算法框架对情感进行分类,并取得理想的实验效果。"
1340,基于卷积神经网络的分期购物用户逾期还款概率预测,"随着互联网金融行业的兴起与快速发展,分期购物模式,即消费者可以分多次付清钱款的消费模式被开发出来,并且越来越受到消费者的青睐。但同时互联网金融机构也面临资金风险问题。因此能否准确有效预测用户的还款行为,将有助于金融机构合理对用户信用风险进行评估,完成资金合理投放,从而最大限度的保证资金安全。目前,逾期还款概率预测主要使用的是传统机器学习方法,该方法需要对数据进行分析并建立特征工程,最后根据提取的特征建立预测模型,但是随着数据类型的增多和复杂度的提升,特征工程的建立变得更加困难,从而直接影响模型最终的预测效果。卷积神经网络是一种仿造生物的视觉机制构建的多层神经网络结构,在图像处理、语音识别等领域已经取得了成功的应用。卷积神经网络具有从数据中自动提取高维度特征并实现分类预测的功能,解决了复杂数据的特征提取问题,同样可以应用于逾期还款概率预测领域。因此本文引入卷积神经网络模型对用户逾期还款概率进行预测并与传统机器学习预测方法进行比较。本文主要的研究工作如下:(1)结合分期购物网站的用户数据,提出了基于改进的卷积神经网络的逾期还款概率预测模型,将用户数据分为基本信息数据和时序数据,分别构建子卷积神经网络对其进行特征提取,有效避免了大规模构建人工特征的问题,节约了人工和时间成本,最后建立了与传统机器学习模型的对比实验。实验结果表明,改进的卷积神经网络模型在省略特征工程的前提下,与传统机器学习中的XGBoost模型预测效果相当。(2)为了进一步提高预测准确度和解决卷积神经网络模型难以调整的问题,使用集成学习stacking方法将改进的卷积神经网络模型和XGBoost模型进行融合形成CNN-XGBoost模型,将卷积神经网络自动提取高维度特征的优点与XGBoost强大的分类预测能力相结合,建立模型并实现了对用户逾期还款概率的预测。通过与现有模型的实验对比,CNN-XGBoost模型取得了更好的预测效果。(3)以真实的分期购物网站用户数据为背景,设计并实现了分期购物用户逾期还款概率预测系统。"
1341,面向交通信息服务的对话生成方法研究,"城市交通发展带来了大量的交通路况查询、报警处理等信息服务需求,传统的人工服务已不能满足实际的应用需求,人机对话技术逐步应用于交通信息服务领域。在人机信息交互过程中意图识别和对话文本生成是人机对话系统的核心,但人机对话技术在交通信息服务领域的应用还存在以下问题:一是用户的对话内容口语性强,不能有效提取用户的对话意图;二是当用户对话内容无明显对话意图时,往往出现答非所问的情况。针对上述问题,本文将基于深度学习的文本分类技术和文本生成技术应用于人机对话系统,通过文本分类识别用户的对话意图,根据对话意图类别调整对话策略,并针对用户对话意图不明确的对话内容,采用基于深度学习的文本生成技术进行应答,提高了面向交通信息服务人机对话系统的用户体验和智能性,具有重要的研究意义。具体研究内容如下:(1)针对交通信息服务领域用户对话文本较短、口语性强的特点,采用融合卷积神经网络和长短记忆模型的方法,构建了基于双向长短记忆模型与卷积神经网络的用户意图识别模型。实验表明,该模型可以有效抽取用户对话文本的文本特征,提高用户意图识别的准确率。(2)针对交通信息服务领域某些应用场景语料相对较少且获取困难,无法满足深度学习模型训练需求的问题,本文将迁移学习应用于交通信息服务领域的意图识别,构建了基于迁移学习的用户意图识别方法。实验表明,在少量标注语料数据的情况下,该模型可以获得较为理想的用户意图识别效果。(3)构建了一种基于深度学习的对话生成模型。本文将深度学习应用于对话文本生成,构建基于BiGRU的Seq2Seq文本生成模型,并通过引入注意力机制(Attention)提高对话生成内容的质量,解决了对话内容意图不明确时,采用传统规则匹配方法生成对话回复文本,常常出现答非所问的问题。(4)搭建面向交通信息服务的人机对话实验平台。本文设计了面向交通信息服务人机对话系统的对话策略,将本文研究成果应用于人机对话实验平台,并通过实验对本文设计的面向交通信息服务的人机对话系统进行了验证分析。实验结果表明人机对话系统表现良好,可以满足实际应用要求。"
1342,基于突变的高效缺陷定位方法研究,"随着软件迭代的不断加速,软件的缺陷也随之变得越来越多、越来越复杂。为了保证软件的稳定运行,软件的开发者们需要不断地修复这些缺陷。在修复缺陷时,必须首先定位到缺陷的位置。然而随着缺陷的多样化,往往开发者要花费大量的时间首先理解软件的结构与缺陷的原理,才能够完成缺陷定位的工作。因此开发自动化的缺陷定位技术是非常有必要的。目前的一些研究工作已经提出了自动化的缺陷定位方法,其中比较知名的两类是基于程序频谱与基于突变的缺陷定位技术。这两类技术以带有缺陷的程序和测试用例作为输入,并输出一组排序过的代码位置代表程序中可能出错的地方。这两类技术在一些程序缺陷上取得了不错的效果,但同样也存在一些问题。首先,基于程序频谱的方法仅使用原测试中语句的覆盖信息作为语句可疑度的计算基础,因此无法区分相同执行模式语句。同时,基于突变的方法需要进行大量的程序突变和测试,这将带来很高的时间开销。在现有的两个工作MUSE和Metallaxis中,语句的可疑度仅与该语句上的程序变体相关,因此无法对不能进行突变的语句给出可疑度。为了解决以上问题,本文提出了一种基于突变的高效缺陷定位方法,主要包括以下几个部分:1.本文提出了一种高效的基于突变的缺陷定位方法,包含两个部分。首先,我们改进了变异测试的过程,通过使用动态程序切片结果进行突变以及收集变异测试执行信息;然后我们设计了新的可疑度计算方法,通过使用动态程序切片和变异测试执行信息,使得定位真实程序缺陷更加高效。2.我们设计并实现了方法对应的工具。通过使用胶水语言Python,结合突变工具PIT和程序动态切片工具JavaSlicer,我们针对Java语言实现了缺陷定位的原型工具。3.为了验证方法的有效性,我们在Defects4J数据库的262个真实程序案例上进行了分析。通过与7个其他的技术的对比表明,我们的方法在真实程序缺陷上能够取得更好的定位效果。"
1343,融合多源异构数据的推荐模型与系统,"在信息时代,数据是核心,海量数据带来的信息过载问题,使人们分析处理信息、找到自己喜爱的内容成为一件困难的事;而信息的生产者,也需要让自己的信息富有吸引力,从而获得流量,为平台创造收益。推荐系统作为一种信息过滤系统,极大地缓解了这一供需矛盾。推荐系统能够挖掘用户的行为模式,建模用户的兴趣,并预测用户对潜在信息的偏好程度,为用户提供服务。推荐系统的研究以信息过滤为起点,此后随着信息网络的发展,用户行为的变化和机器学习等计算机科学技术的兴起,发展出各种推荐模型和算法。以协同过滤推荐为代表的方法,成为学术研究热点,也是业界最为流行的框架。根据用户和物品之间的交互信息,如评分记录,学习两者之间的隐藏特征以及抽象的推荐模式,预测用户的喜好物品。实际应用中,用户和物品的相关交互数据十分稀疏,且对于新用户、新物品无法捕获有效特征,降低了推荐系统的性能。目前,数据稀疏及冷启动问题的一个重要的解决方案,就是融合相关的辅助数据,如用户社交网络信息、用户对相关物品的评论文本、用户标签数据和其他的用户反馈信息等。这些数据来源多样,且具有不同的结构,需要设计合理的机制,才能有效地融入推荐模型中,以提高最终推荐准度。本文针对上述问题,展开对融合多源异构数据的混合式推荐系统与模型的研究,主要工作有:1.提出了一种基于机器学习与规则方法的,融合多源异构数据的综合式推荐模型与系统。通过获取用户和待推荐物品相关的附属标签、主题文本、社交等数据,从中总结并应用推荐模式与规则,以调整协同过滤算法和基于内容的推荐方法的结果。在真实的代码社区板块帖推荐系统中,能生成更为准确的推荐结果,进而提升用户的满意度。2.提出了一种基于深度表示学习,融合了多源异构数据的多任务推荐系统框架,MultiCombine。借助深度学习技术,从用户、物品相关的辅助数据中,深入挖掘有效的特征信息。以用户为核心,构建多任务间共享的通用特征和任务相关的私有隐藏特征,使用户在多个领域任务中表现出的共性得以传递。相关实验证明,MultiCombine模型的融合机制,最终能够促进下游的推荐及其他任务性能的提升。深度表示学习与神经网络技术的相结合,构建用户画像,为这一多任务融合框架带来了可扩展性和可解释性,能灵活地适应多种任务需求。3.在上述融合多源异构数据的推荐算法和模型的基础上,设计并实现了个性化金融资讯推荐系统。针对现实的用户需求,改变了传统推荐系统中按照时间与浏览热度排序,为所有用户生成同样的推荐内容的弊端。根据用户的浏览历史记录及相关用户信息、标签、社会关系,为用户制定充分个性化的金融资讯推荐,增强了推荐的合理性。本文围绕多源异构数据在推荐系统中的融合方式,从规则方法到机器学习,尤其是深度学习技术,由浅入深地进行了应用与研究。在相关场景和数据集中进行实验与分析,证明了融合多源异构数据,可以显著提高推荐的性能,也是缓解推荐系统中数据稀疏以及冷启动问题的有效手段。"
1344,基于强化学习的多路径传输控制协议优化,"随着计算机网络和通讯技术的发展,通讯设备通常配备多个网卡接口,例如智能手机和便携式电脑都配置有WiFi和LIE等多个网卡。然而传统的单路径TCP连接只使用单个的网卡和链路进行传输,导致剩余的接口和链路资源空闲以及单路径传输的性能问题。为了实现多网卡多链路的同时传输,互联网工程任务组提出并标准化多路径传输控制协议(MPTCP),它将单一的TCP数据流划分为多个子流,在不同的链路传输。由于链路多样性,MPTCP 比单路径TCP更加可靠,并且能充分利用网络资源。然而在多链路网络,特别是异构网络中,每条链路在带宽、往返时延等服务质量指标上存在较大差异,使得MPTCP面临缓冲区膨胀、带宽利用率低、队头阻塞、吞吐量下降、应用延迟增大等性能问题。拥塞控制和数据包调度是MPTCP的基本机制,同时是MPTCP设计和实现的核心。因此,优化MPTCP的传输性能,需要考虑以下两个问题:(1)拥塞控制问题,即如何为每个子流设置合适的拥塞窗口。子流的拥塞窗口直接影响子流的吞吐量,对MPTCP的总吞吐量等服务质量指标有着重要影响。(2)数据包调度问题,即如何在各个子流间进行数据包调度。MPTCP数据包调度算法决定了子流之间的数据流量分配。一个优秀的MPTCP数据包调度算法能够适应复杂多变的网络环境,优化子流之间的流量分配,提高MPTCP的性能。针对上述问题,本文分析了传统启发式拥塞控制算法和数据包调度算法的缺陷:基于特定或简化的网络模型,采用固定的控制规则,在复杂多变的动态网络中,难以实现最优的拥塞控制和数据包调度。为了从根本上解决上述问题,本文提出并实现基于强化学习的MPTCP拥塞控制算法SmartCC和基于深度强化学习的MPTCP数据包调度算法ReLeS。SmartCC把拥塞控制过程建模为马尔可夫模型,使用强化学习技术,训练生成不同网络环境下的最优的拥塞控制规则。实验表明:SmartCC在总吞吐量、时延抖动等方面均优于现有MPTCP拥塞控制算法。ReLeS用人工深度神经网络表示MPTCP数据包调度策略,训练生成各种网络环境下的最优数据包调度策略。实验结果表明,对比现有启发式MPTCP数据包调度算法,ReLeS能自适应多种动态的网络环境,综合优化吞吐量、应用时延等指标,有效缓解队头阻塞和缓冲区膨胀等问题。"
1345,基于深度模型和谱方法的多因子选股策略研究,"量化投资有着纪律性、系统性和分散化投资等诸多优点,因此其越来越受到学术界和投资界的关注。近些年随着人工智能和深度学习技术的发展,学者与投资实践者把更多的机器学习算法应用到投资领域的各个方面并取得了不错的投资收益。与成熟的海外市场相比,量化投资在国内市场具有更广阔的发展空间和研究价值,本文基于国内市场上对数据挖掘和深度学习在量化选股和统计套利中的应用进行了研究,提出了基于深度模型和谱方法的组合选股模型。文章的主要工作分为如下三个部分:1.将深度学习算法应用到量化选股的问题中。本文用IRGAN(Information Retrieval in Generative Adversarial Networks)作为选股模型,然后设计了一个卷积网络结构并嵌套在IRGAN的生成器和判别器组件中,根据模型的输出得到选股结果。实验结果表明,本文方法在选择高收益率股票上的精度优于其他对比方法。2.将谱方法应用到统计套利选择价格曲线相似的股票组合的问题中。本文用动态时间规整距离替换欧氏距离作为股票的距离度量,通过谱聚类算法聚类产生相似股票组合。实验结果表明,在中低频时间尺度上,本文方法分析出的相似股票组合在价格曲线走势的相似程度上高于其他对比算法。3.提出基于深度模型和谱方法的组合选股模型。本文将深度模型选择出的股票作为核心股票集,用基于谱方法的相似股模型得到与核心股票的价格曲线走势相似的相似股票集,将核心股票集和相似股票集作为组合选股模型的选股结果。实验结果表明,本文提出的组合模型能够大幅提高模型选股的精度并且该模型的回测收益好于其他对比算法。"
1346,电商平台客户流失预警分析及应用研究,"电子商务相比较与以往传统的线下购物,其不受时间、地点限制,便捷的优势吸引越来越多人的选择。然而在如今电商平台百花齐放的市场环境下,平台间的竞争也日趋激烈。电商物流逐渐成为电商平台发展的瓶颈,物流配送问题等物流服务质量偏低逐渐成为客户最不满意的地方。电商平台客户,其行为不稳定性较大,流失率较高。而客户的稳定性与否直接和电商的销量预测息息相关,进而影响仓储的调配及其运输优化等等一系列涉及物流及企业成本方面的问题。而电商平台自身的物流服务质量,极有可能是造成客户流失的一个不可忽略的因素。因此探究客户流失原因,并针对影响其流失的因素进一步分析并提出对策,是电商平台亟待解决的一个问题,也是推动现代物流发展,提升物流服务质量的一个举措。本文首先论述了我国电商平台客户的特点、市场规模和发展前景,分析了可能影响电商平台客户流失的影响因素如物流服务质量等;进而探讨利用大数据进行预警模型的构建,并找出高效且准确度高的算法;然后以国内某知名H电商的大数据平台下的母婴事业部数据,利用数据挖掘技术和机器学习方法如随机森林、xgboost算法等,根据RFM模型,建立起影响客户流失因素的特征工程,进一步根据前面建立的特征维度进行预警模型的训练;最后是由训练的模型,得出影响客户行为的主要原因,并且发现未存在的因素,如缺货率与客户流失概率之间的关系,并据此提出挽留措施。结果表明模型具有较高的准确率,并且由模型得到了影响母婴市场电商平台客户流失的主要因素,如客户忠诚度、宝宝年龄、客户对物流的满意度等。最后根据模型结果提出了客户流失挽留建议,用于帮助电商企业制定个性化的客户挽留营销措施。本文的研究对电商平台及时发现高危流失客户,并进一步反思平台的不足之处,提升物流服务质量,及时采取措施修复,从而提高企业利润,扩大其电商市场份额有较高的意义和参考价值。"
1347,基于数据挖掘的交通信息预测机制研究,"智能交通系统(Intelligent Transportation System,ITS)是随着社会和交通的进步而发展起来的交通管理体系,其思想为将交通中所涉及到的人、车辆、道路以及交通的实时运行情况综合起来加以利用。智能出行作为其中关键的一部分,需要对交通信息进行预测,帮助人们在对未来短时交通状况有所了解的情况下有计划地出行。大数据相关技术的发展也为智能交通的稳步前进带来了良好的契机。本文的重点在于利用数据挖掘技术对未来短时交通信息的预测机制进行研究,以行程时间和出租车需求量的预测为代表突破口,实现对现有交通资源和车辆资源的有效利用。对于行程时间的预测,结合对数据的分析,将车辆的瞬时速度映射为路段速度,并将路段速度作为预测的关键特征。考虑到路段速度的缺失情况,在数据预处理部分,提出基于邻近相似度的缺失值填充算法并应用于路段速度的填充。通过K最近邻(K Nearest Neighbors,KNN)模型、人工神经网络(Artificial Neural Network,ANN)和梯度提升回归树(Gradient Boosting Regression Trees,GBRT)模型对特殊值填充等四种填充算法处理后的数据进行预测,验证了所提算法的有效性和准确性,也分析了不同预测模型在行程时间预测方面的优劣性。对于出租车需求量的预测,从时序和非时序两个角度进行分析。时序方面,以季节性差分自回归滑动平均模型(Seasonal Autoregressive Integrated Moving Average,SARIMA)作为基线,针对其纯线性的限制,提出混合的SARIMA-SVR模型,从SARIMA处理后的残差序列中挖掘出原始数据中的非线性成分,并对结果进行修正。非时序方面,首先通过基于密度的DBSCAN(Density Based Spatial C lustering of Applications with Noise)聚类算法挖掘出区域的热度分布模式,并将热度分布模式作为重要特征加入神经网络模型进行训练,得到适用于各种热度分布的区域预测模型。最终,通过集成学习算法将多模型进行融合,综合各自的优点,得到最终的高准确率的预测模型。对于不同种类的交通信息预测,都通过MAPE等指标对预测结果和预测模型进行分析。结果表明,本文中提出的算法、对于不同模型的改进措施相比于基本模型来说,在预测的准确度上都有较大的提升,这也使得对于交通信息的预测机制有了较大的改进。"
1348,面向大数据的电梯工况智能分析系统的设计与实现,"随着城市化进程的发展,电梯已经成为人们生活中必不可少的垂直交通工具。传统的电梯维保主要通过专业的人工定时维保,无法满足按需维保的需求,具有一定的延时性。并且,电梯种类各异,生产厂家各异,难以直接获得电梯运行信息如电梯运行层数等。随着物联网的发展,通过传感器可以采集各种数据。通过在电梯中安装传感器如加速度传感器等,可以采集电梯运行环境中的各种数据如加速度等,为实现基于大数据的电梯工况智能分析系统提供可能性。本文主要的研究内容为面向大数据的电梯工况智能分析系统的设计与实现。首先基于业务场景进行需求分析,提出功能性需求与非功能性需求。然后对电梯工况智能分析系统进行总体设计。电梯工况智能分析系统由数据存储层、数据监控层、算法分析层、数据应用层四部分构成。数据存储层用于数据存储与管理;数据监控层监控数据是否正常以及是否丢包与延时;算法分析层主要对电梯数据进行算法处理与分析;数据应用层接收算法分析层的处理数据进行前端页面展示。其中,电梯工况智能分析系统关键部分由算法分析层部分构成,即基于电梯传感器数据进行电梯数据的分析与机器学习模型的建立。算法分析层主要由两部分构成:1、基于电梯传感器采集的数据,建立多种电梯运行数据分析模型。通过数据预处理、特征选择、建立聚类模型、时序预测模型等,达到实时监控电梯运行的效果。对电梯历史运行状况进行汇总统计分析,对未来电梯运行状况进行一定的预测。2、基于电梯传感器采集的数据,建立电梯异常分类模型。通过数据预处理、特征抽取、特征选择步骤后,建立异常分类模型,达到对电梯运行是否异常的实时监控。为了达到快速实时监控电梯运行的异常与否,对异常分类模型中的梯度下降算法进行改进:结合随机梯度下降算法的在线性及拟牛顿算法快速收敛的优势,将拟牛顿算法owl-qn改为owl-qn在线学习算法。基于参数服务器的分布式框架,实现基于分布式的owl-qn在线学习算法。最后,本文对电梯智能工况分析系统进行完整的系统实现与测试,总结系统的不足与可改进之处。"
1349,基于k-means算法的WiFi用户行为分析系统设计与实现,"用户行为分析领域一直是研究的热点,例如研究校园里学生和老师的行为,了解校园里各场所的运转情况,能够为管理者的决策提供参考意见;研究商场里顾客的行为,有助于了解商场的客流量分布,可以给顾客提供个性化推荐,具有良好的商业价值。随着移动智能终端设备的普及,越来越多的用户会长期开启手机等终端设备的WIFI功能,利用WIFI探针能比较方便的采集到大量用户行为数据。由于利用WIFI探针采集到的数据集的数据量巨大,无法直接标注标签,标注成本很高,探索一种无监督算法来进行WIFI探针数据挖掘具有重要意义。本课题研究基于k-means算法的WIFI用户行为分析系统设计与实现。主要研究内容包含如下三点:(1)基于WIFI用户行为分析的业务场景,分析系统需求,对WIFI用户行为分析系统进行设计。整个系统分为数据接入模块、数据处理模块、数据应用模块等三个部分。其中,数据接入模块将WIFI探针数据同步到HDFS,实现大数据量访问,提高容错性。数据处理模块对原始WIFI探针数据进行预处理与特征工程,从多个角度进行数据挖掘。数据应用模块对用户行为分析结果进行直观呈现。(2)构建了 WIFI用户行为多维度分析数学模型。从用户、地点、时间不同层次对数据进行聚类模型的构建。按用户进行聚类,能够分析用户的行为习惯以及活跃度;按时间进行聚类,能够分析不同时间段用户的作息习惯・,按地点进行聚类,能够对各个地点的人流量分布进行宏观把控。(3)基于对WIFI大数据处理的快速实时处理的需求以及对传统k-means算法局限性的分析,对数据处理模块中使用的k-means算法进行多角度改进,使其可以快速实时处理WIFI探针数据。不仅通过实验证明改进算法的有效性,并且将其应用于WIFI用户行为分析系统中,具有一定的实际意义。"
1350,基于流量的WSN入侵检测方法研究,"随着大数据、云计算和物联网技术的快速发展,无线传感器网络(Wireless Sensor Network,WSN)作为一种新型的网络得到深入的研究和广泛的应用。由于WSN中传感器节点计算、存储和能量有限,常常部署在人员无法到达,条件恶劣等复杂环境中,所以WSN在安全方面面临着各种各样的挑战,必须使用有效的保护机制保障WSN安全。网络流量异常具有参数特征未知,流量产生突然等特点,WSN中一些典型攻击方法如Wormhole、Sinkholes、Hello Flooding和Jamming均导致网络流量偏离正常的流量,会短时间给WSN系统带来巨大的危害。因此,能准确、迅速的检测出网络流量异常,建立一个合适的基于流量的WSN入侵检测系统模型显得尤为重要。针对上述问题,论文主要利用基于信息增益比特征选择方法,集成学习、随机森林和深度森林等机器学习方法,对WSN入侵检测系统的关键技术进行了研究。主要研究工作如下:1.针对WSN入侵检测方法的待处理流量数据维度过高而导致入侵检测模型计算量大、以及对入侵攻击的检测性能偏弱等问题,利用集成学习算法原理,提出了一种基于信息增益比与Bagging算法的WSN入侵检测模型。该模型首先利用信息增益比方法对传感器节点流量数据进行特征选择;其次采用Bagging算法构建集成分类器训练多个C4.5决策树,通过10次迭代对集成分类器进行参数优化,并引入动态剪枝过程;最后对C4.5决策树的分类结果采用多数投票机制进行入侵行为的分类检测。实验结果表明,该模型与现有入侵检测方法相比,对入侵攻击行为具有很高的检测准确度,在保证99.4%检测率的同时,仍能保持较低的虚警率,并对入侵行为保持较高检测性能。2.针对现有的特征选择算法和分类算法在WSN入侵检测过程中检测性能表现不佳、检测实时性差、模型复杂度高等问题,提出了一种基于随机森林和深度森林算法的分布式WSN入侵检测模型。该模型首先对传感器节点流量数据进行预处理;然后将轻量级随机森林分类器部署到传感器节点和簇头节点,传感器节点和簇头节点合作对流量数据进行处理,并在基站上采用深度森林算法从大量流量数据中发现攻击行为;最后对WSN中入侵行为进行实时分类入侵检测。实验结果表明,该模型与现有的入侵检测模型相比,具有良好的检测性能,实时性较高,可避免模型过度拟合。"
1351,基于机器学习的新闻分类系统研究与实现,"随着互联网技术的发展和智能设备的高度普及,信息爆炸已经成为了一个越来越棘手的问题,各类文本信息呈爆炸式增长。新闻文本作为一种重要的数据承载形式有着重要的地位,如何在巨大的信息源中准确、快速的获取到有价值的信息成为人们的迫切需要,这也是工业界和学术界一直关注的热点问题。新闻文本分类系统的研究和实现不仅可以直接应用于广告、信息推荐等领域中,而且还可以为其他各类项目提供前置支持,是文本处理领域不可或缺的环节。比如,在广告领域,通过对各类新闻文本进行分类后,可以根据分类结果对广告主推荐相关分类领域的关键词以供广告主购买;对候选新闻进行过滤,进而提高推荐系统的准确率,以及在信息检索中依据类别信息制定不同的检索策略等。为了在海量的信息源中准确、快速的获取到有价值的信息,需要设计出一个分类系统对各类新闻文本进行分类,这也是新闻系统平台的价值所在。论文分析了文本分类技术的各个步骤和常用分类算法以后,以TextCNN和Lightgbm为基础算法来搭建最终分类模型,通过对计算效率、平台轻量级、分类性能的综合考量后,确定了以Python为开发语言,Flask轻量级框架作为平台框架,SQLite作为存储数据库的主要技术路线,通过python和Tensorf low完成了分类模型的搭建工作,并在此基础上搭建新闻分类平台系统,且测试阶段的测试结果表明了分类模型的性能符合预期效果。"
1352,智能机器外呼系统的设计与实现,"在互联网技术和人工智能的急速发展的环境下,各行业也得到快速发展。而在此过程中企业与客户的沟通必不可少,如产品推广、业务引导以及债务催收等。传统的企业与客户的沟通往往使用呼叫中心自动外呼,再转接给人工坐席完成外呼任务。这种以人工为主的客户沟通方式却伴随着外呼数量大、工作重复枯燥、通话效率底下以及话术不规范的问题。针对上述问题,在传统呼叫中心基础上构建了一个智能机器外呼系统,其中详细设计并实现了包含意图识别与智能问答功能的语义解析引擎,以及基于状态机的对话管理。引入人工智能的外呼系统,可以高效解决传统外呼过程中人工外呼成本高、效率低的问题,极具现实意义与商业价值。具体的研究内容包括:(1)基于文本分类技术的意图识别:首先调研了自然语言理解技术的国内外研究现状,总结其中使用的技术方案。针对智能外呼任务的实际特点,实现基于文本分类技术的意图识别。设计了基于字、词、拼音向量特征的深度学习意图识别模型,并结合规则模板的方法解决系统冷启动时数据量匮乏的问题。(2)基于深度匹配的智能问答:在实际场景中,用户问题往往无法穷举,且随着用户量的积累,问题集合也会不断扩大,因此确定意图类别数量的意图识别方法无法满足该场景。使用深度语义匹配模型,判断用户问题与标准常问问题的相似度,进而选择合适的答案反馈给用户。实验表明,该方案可以明显提升智能外呼系统的用户体验及实际效果。(3)智能机器外呼系统设计与实现:基于以上关键技术,设计与实现了一个完整的智能机器外呼系统。并在实际业务场景中验证了系统可以完成预定的外呼任务,且容易迁移到其他业务场景。"
1353,基于改进SVM算法的大规模中文网站分类系统实现,"随着互联网的发展,人们对于网站检索的需求日益增大。将网站进行分类可以极大地提升检索效率,研究中文网站的自动分类技术具有较高的实用价值。基于网页关键词词频的支持向量机SVM算法是解决高维特征向量分类问题的最好方案之一,需要设定的参数较少且具有出色的学习能力。目前SVM算法已经应用于各类网站分类工作,但因分类信息老旧,效率低下,更新速度慢等种种问题,无法完成对目前数百万的庞大的中文网站的大范围覆盖。针对上述问题,本课题对SVM机器学习模型进行了改进以解决大规模中文网站分类的问题,并基于上述方法实现针对百万规模数据集的国内中文网站的分类系统。本课题针对百万数据量下的网站分类准确率进行了相关探索,研究SVM算法相关参数对分类准确率的影响。针对传统SVM算法中存在的非均衡样本集对分类准确率产生影响的问题,本论文对算法模型进行调整,通过引入新的参数控制模型的超平面位置,将超平面向正类样本靠近,为负类样本留出更大的存在可能性空间,从而缓解非均衡样本集对分类准确率带来的影响。通过对照实验测试,改进的算法应用于非均衡样本集时,在一定的参数取值范围内对于负类样本的分类准确率有了较为明显的提高,从而提升了整体的分类效果。基于以上改进的SVM算法,本课题构建了大规模中文网站分类系统用以完成国内百万数量级规模的网站分类工作。系统包括数据采集、数据处理与存储、数据计算、数据分类、结果展示与查询这五大基本模块,完成了从网站信息爬取、信息存储、数据预处理到算法测试调优,再到算法应用及结果展示的一体化分类工作。系统模块经过测试,满足了应用需求,取得了不错的分类效果。"
1354,基于机器学习的软件缺陷预测方案研究,"随着网络科技的快速发展,用户对于软件的质量也提出了更高的要求。软件缺陷是影响软件质量的最大因素,软件缺陷的检测成为软件上线前的必经步骤。然而通常一个软件的体量非常巨大,如果要检查全部软件代码,花费的成本也是巨大的。软件缺陷预测的提出正是为了解决这一问题,将检测的人力物力更好的分配到可能有缺陷的地方,既可以提高效率又可以节省成本。本文针对基于机器学习的软件缺陷预测中对特征关联性考虑不足和无标签预测问题深入研究,从多个角度入手以提高预测的曲线下面积(Area Under Curve,AUC)指标,相比准确率指标更好的表达较少的有缺陷类的预测效果。论文主要成果有:首先,针对软件缺陷预测中分类的不平衡性,即与正常代码部分相比有缺陷的部分往往占少数,提出了新型的上采样方案。方案中增加了类内离散度信息与支持向量清洗策略,使得新样本分布更均匀。通过与多个上采样方案在多个软件缺陷预测中流行的机器学习方法上进行实验对比,证明了所提出的上采样方案取得了更高的AUC值。其次,从特征入手,根据每个特征对最终预测效果的影响程度对原有的特征进行筛选,提出一套特征筛选与预测为一体的方案。方案分别从正向增加特征与反向减少特征两个方面进行特征筛选,把噪声特征筛除的同时完成了特征的降维。实验结果表明,该方案与前人提出的特征降维预测方法对比,在AUC指标与时间复杂度上更优。最后,考虑到很多软件并没有多个版本的迭代,即没有标记好的数据,这就需要无监督学习来解决。本文提出了基于主要特征的自动标记方案,将分组后的特征映射到低维特征空间并使用聚类标记,最终在多个数据集上进行实验验证,结果表明该方案的AUC指标均有所提高。"
1355,基于安全多方计算的聚类算法统一框架的设计与实现,"聚类算法适用于诸多领域,但在涉及隐私数据的场景中,参与方处于对各自隐私数据安全性的考虑,导致应用困难。因此,研究如何在多方互相不可信环境下对各自的隐私数据应用聚类算法有重要意义。安全多方计算(Secure Multiparty Computation)是一种多方在互相不可信任的环境下进行共同计算,并在不泄露各自隐私的前提下获得最终结果的方法。因此安全多方计算比较适合用在隐私数据之间的聚类算法中。但是,聚类算法种类颇多,目前没有一个方便易用的框架来将基于安全多方计算的聚类算法部署到各个参与方的隐私数据集上。本文基于以上问题,改进了两种适用于聚类算法的安全多方计算基础算法;其次,利用基础算法来实现聚类算法中的相似度衡量;再之,根据安全多方计算中的网络通信的特点,本文引入了配置中心用于辅助连接,基于此给出安全多方计算的通信协议;最后,本文设计和实现了一个基于安全多方计算的聚类统一框架,实现隐私保护的聚类算法,可以方便的在各方的隐私数据集上进行部署。实验结果表明,该系统实现的聚类算法与普通聚类算法在聚类结果上保持了相同的准确度,进一步,本系统可以实现隐私保护的数据挖掘。"
1356,针对神经网络的图像对抗样本生成及应用研究,"深度神经网络在机器学习领域的许多任务中取得了巨大的成功,例如图像分类、语音识别、自然语言处理、医疗健康等。然而,近期有研究表明深度神经网络很容易受到对抗样本的攻击。对抗样本,即在数据集中通过故意添加细微的干扰所形成的输入样本,导致模型以高置信度给出一个错误的输出。在安全要求严格的应用中,如自动驾驶汽车、人脸识别、监视系统等,这种攻击严重阻碍了神经网络系统的部署。对抗样本的存在对人工智能安全造成了极大的威胁,这些威胁可能导致人工智能所驱动的识别系统出现混乱,形成漏判误判,甚至导致系统崩溃或被劫持。另一方面,对抗样本的存在也可以激发更多关于如何防御此类攻击的研究,从而获得更加鲁棒的可信赖的神经网络。近几年来,国内外研究团队在该领域的研究可分为针对神经网络的攻击和防御两方面。攻击即为研究如何构造或生成对抗样本的算法来欺骗神经网络,防御即为采取某些手段将对抗样本恢复为可被正确识别的输入数据或者训练不受对抗样本干扰的更加鲁棒的神经网络,保证人工智能系统的安全。研究对抗样本的生成算法和研究防御算法同样重要,探究攻击算法不仅可以促进更加有效的防御算法的产生,而且可以使研究者关注对抗样本的积极应用。攻击者仍应挖掘除神经网络本身脆弱性外的其他漏洞,发现其他可攻击点,多角度设计对抗样本,从而促进防御者对神经网络的修复,提高系统稳健性。此外,攻击者还应探究如何在苛刻环境中进行攻击,如无法得知网络内部结构参数的黑盒攻击或在获得信息量极少的情形下的攻击。本文对图像对抗样本展开了四个方面的研究,主要贡献如下:1.针对防御蒸馏网络的对抗样本生成算法:防御性蒸馏是现有的一种强有效的对抗样本防御方法,本文提出了一种针对防御性蒸馏网络的对抗样本生成算法――“∈邻域攻击”,通过巧妙地设计目标函数,在其中加人攻击者可调参数来限制图像中每个像素的扰动上限,既提高了算法可控性,又确保了生成的对抗样本中不出现对图像视觉质量有较大伤害的亮点。实验表明,该方法也可以大大提高对抗样本的计算速度。2.针对图像缩放的对抗样本生成算法:图像缩放是深度学习流程中将输入图像调整为模型所需尺寸的常用操作。已有的工作大多基于利用神网络本身的弱点,本文从不同视角出发,提出了一种新的对抗样本生成方法――“嵌入攻击”。通过此攻击,可以将一个尺寸较小的目标图像嵌入到一个大的原始图像中,以生成对抗样本,而无需访问查询目标网络模型。当把对抗样本调整为模型规定的输入大小时,它将完全恢复为嵌入的目标图像。本文针对三种常见的图像缩放方法分别设计了嵌入攻击算法,为了提高攻击的实用性,同时设计了一种能够适用于不同图像缩放方法的通用的嵌入攻击。此外,为改善生成的对抗样本的视觉质量,本文在嵌入攻击的基础上添加了图像预选、色彩转移等步骤,从而形成了一个完整的对抗样本生成框架。3.基于决策的对抗样本生成算法:深度神经网络在黑盒情形下也会受到攻击,攻击者通过多次访问查询模型,可以只依赖模型每次返回的最终决策标签来进行攻击,而无需依赖任何概率信息,此类攻击称为“基于决策的攻击”,它是黑盒攻击中最具有挑战性的一种。本文提出了一种新的基于决策的攻击算法――“qFool”,该算法可以仅通过少量的对目标模型的访问查询生成对抗样本。与之前的攻击相比,qFool可以在达到相同的对抗样本视觉质量的情况下大大减少对模型的查询次数。此外,本文还通过将对抗扰动约束在低频子空间来进一步改进算法,并成功攻击了商业图像识别系统,显示了qFool在现实场景应用中的有效性。4.基于对抗样本的图像内容保护算法:社交平台上的在线图片分享可能使用户在不经意间泄露隐私,如一些企业会利用深度神经网络检测这些上传的图像,并出于商业目的对用户进行偏好分析。为了在不影响人眼视觉质量的情况下躲避此类神经网络检测器的检测,本文提出了一种对抗样本生成算法――“隐身算法”,使自动检测器无法确定图像中物体的位置,达到保护图像内容的目的。实验表明,隐身算法与其他图像内容保护方法相比,躲避检测器的成功率高,处理后图像的视觉质量好。同时,算法中的用户可调参数“隐身衣厚度”可用于调节图像扰动强度,提高算法可控性。此外,本文发现此算法生成的对抗样本具有可转移性,即针对某个特定的网络模型生成的对抗样本也会影响其他模型。"
1357,基于摘要的论文分类与推荐模型的研究与实现,"科研工作者在日常科研活动中往往需要查阅大量的科技论文。所以,快速获取相关研究方向的科技论文成为了科研工作者的普遍需求。于是,对论文的分类和推荐便成为了一个亟待解决的问题。论文摘要是一类极具研究价值的短文本数据。因此,对摘要这类数据进行短文本处理,并基于摘要实现对论文的分类与推荐便具有了重要的意义。在现阶段,短文本处理问题主要采用卷积神经网络和循环神经网络等深度学习技术来解决。但是,这类方法的缺陷在于对短文本特征空间的挖掘不够充分。所以,本文对现有短文本处理方法进行了研究与改进,在此基础上完成了对基于摘要的论文分类与推荐模型的研究,并实现了科技论文推荐原型系统,主要内容如下.:(1)基于摘要的论文分类模型研究。本文针对现有短文本分类方法的不足,在卷积神经网络中加入了主题向量拼接算法,完成了文本主题信息的引入,从而提出了基于主题的卷积神经网络模型。并且,本文将该模型整合到论文分类模型中,使其解决了现有方法对文本特征空间挖掘不足的问题,取得了更好的分类准确率。(2)基于摘要的论文推荐模型研究。本文提出了基于论文类别的特征工程方法,把在论文分类模型中得到的分类结果以分类特征的形式加入到论文推荐模型中,解决了基于统计和语义的传统特征工程方法在特征提取的广度上具有局限性的问题,提出了具有更高准确率的基于摘要的论文推荐模型。(3)科技论文推荐原型系统的设计与实现。本文基于上述提出的论文分类与推荐模型,实现了一个具有高质量论文推荐功能的科技论文推荐原型系统,完成了对本文所研究的模型的实现和应用验证。综上所述,本文针对基于摘要的论文分类和推荐问题,分析了现有短文本分类与推荐模型的不足,提出了基于摘要的论文分类与推荐模型,设计并实现了科技论文推荐原型系统,并在系统中实现了上述模型。经模型验证实验和系统测试,本文研究的模型在准确率等各指标上要优于现有短文本分类与推荐模型,本文实现的系统可满足用户的功能和非功能需求。"
1358,代价敏感的多分类恶意网页识别系统研究与实现,"近年来,互联网的蓬勃发展为人们的日常生活创造了巨大的便利。但同时,便捷的网络服务也吸引了众多的攻击者们通过恶意软件、网络钓鱼、和垃圾邮件等方式进行非法牟利,这些网页被称为恶意网页。它们都在不知情用户进行访问时对客户端系统发起攻击,但这些不法活动的目的和手段各不相同,不同种网页的实际数量和误分类的代价也有很大差异。目前的研究主要是针对某一类恶意网页,实现恶意网页多分类的研究还相对较少,对于机器学习方法分类的研究中提取的特征也还有待完善。本文针对上述问题,提出了利用CSS特征和URL特征结合的有监督机器学习的分类方法,同时考虑数据不均衡和误分类代价不同的情况,提出了“误分类代价和”作为新的度量指标,对钓鱼网页、恶意软件下载网页和良性网页进行三分类研究。论文的主要成果有:首先提出了全新的CSS特征,并证明了这些特征在对恶意软件下载的恶意网页识别的有效性,通过组合和新增特征,本文对全部恶意软件下载网页识别准确率提升稳定至92%,对利用重定向的恶意软件下载网页的识别准确率最高可达到99%,时间性能也有所提高。其次推导出三分类误分类代价度量指标,考虑实际数据比例和误分类代价进行大量实验,证明新指标的合理性和本文分类方法的合理性。最后将本文理论分析和工程技术相结合,设计实现了一个针对钓鱼网页和恶意软件下载网页的多分类恶意网页识别系统,并测试了系统的准确性和稳定性。"
1359,基于最大似然估计的众包质量控制优化方法研究,"众包能够通过利用数十万网络中的工人(即人群)的智慧来解决计算机难以有效解决的问题,如实体解析、情感分析和图像识别问题。尤其在为机器学习和数据挖掘领域提供人类智能支持方面已经非常成功,它们通过在公共众包平台(如Amazon Mechanical Turk(AMT)、Crowdflower 和 Upwork)上发布标注任务来收集用于训练各种机器学习和数据挖掘系统的标记数据。由于众包中的工人可能具有不同水平的专业知识,未经培训的工人可能无法完成某些任务,甚至一些恶意的工人可能会故意给出错误的答案,众包可能会产生相对低质量的结果。因此,需要一些质量控制策略来保证众包任务结果的质量,即在收到工人的对于任务的回答后,对工人的质量建模,然后根据工人质量推测出任务的真实答案。现在已有的众包质量控制方法主要利用EM方法最大化似然值来估计工人的质量以及任务的真实答案。然而,基于EM的方法往往只是局部最优的解决方案,并且估计结果会受到初始值的影响。所以,本文提出了面向全局最优结果的众包质量控制优化方法来解决以上问题。本文主要针对于基于最大似然估计的众包质量控制优化问题进行了深入研究。首先,提出了基于最大似然估计的众包质量控制局部最优算法,利用EM方法最大化似然值对工人的质量以及任务的真实答案进行评估,分别提出了基于静态和动态工人模型的众包质量评估算法。其中静态工人模型是用概率值或者概率矩阵来表示工人的质量。动态工人模型中工人的质量受到任务难度的影响并且符合函数分布,动态工人模型能够更加详尽的体现工人的质量随影响因素的变化规律。在对工人质量建模后,利用EM方法最大化似然函数估计出工人模型的参数以及任务的真实答案。然后,本文在EM方法的局部最优结果的基础之上进行优化,提出了一个以似然最大为目标的众包质量控制近似全局最优算法。该优化算法由一个任务优势排序模型和一个迭代近邻搜索算法组成,通过进一步似然最大化来提高任务真实答案估计的准确性。任务优势排序模型可以帮助删减劣势的任务-答案组合,并且保留优势的任务-答案组合;迭代近邻搜索算法能够在一个邻域内找到具有最大似然值的任务-答案组合。本文提出的优化算法在最大化似然值的同时提供了工人的质量和任务的真实答案估计的准确性。最后,本文采用了模拟数据集和在AMT平台上收集的关于情感分析任务的真实数据集,通过大量的对比实验评估了本文提出的众包质量控制局部最优算法以及近似全局最优算法。实验结果表明,本文提出的方法能够得到更高质量的估计结果。另外,我们实现了一个众包APP作为实验平台,该实验平台能够管理和发布移动众包任务(例如商场打折信息标注任务)并收集移动众包数据,还可以通过该平台来应用众包质量控制相关算法。"
1360,基于机器学习方法的动态日内成交量比例预测的VWAP算法,"最近几十年,计算机技术和互联网技术的快速发展,带动了电子交易执行系统快速发展,这种电子交易执行系统称为算法交易。在金融市场中,算法交易是指投资者通过计算机下达交易命令的交易方式,这种交易方式由计算机算法来确定下达的交易命令的交易时机、价格、下单的数量等。本文研究的问题就是算法交易策略中使用最广泛的VWAP算法交易策略,VWAP算法交易策略的执行效果很大程度上取决于日内成交量比例的预测。因此本文的重点就在于研究日内成交量比例的预测方法。本文提出的日内成交量比例预测模型,使用了随机森林和前馈神经网络方法,模型的输入包括过去一段时间历史交易日的成交量和相同区间的成交量、过去几个区间的区间的成交量,输出为区间的成交量比例。本文使用的数据为中国金融期货交易所的沪深300股指期货主力连续合约的5分钟K线数据,在这个数据上验证本文提出的模型,相对于传统的滚动平均方法,前馈神经网络方法的均方误差提升了9.90%,证明本文提出的日内成交量比例预测模型的有效性。接下来本文使用沪深300股指期货主力连续合约的数据验证了成交量比例和收益率的相关关系。本文分别计算了成交量比例和收益率的皮尔森相关系数和斯皮尔曼相关系数,然后通过假设检验,计算P值,证明了成交量比例和收益率不仅具有显著的线性相关关系,还具有显著的非线性相关关系。继而本文将收益率和由收益率计算的波动率加入到本文提出的日内成交量比例预测模型中,相对于滚动平均方法,随机森林方法的均方误差提升了12.90%,在同时使用前馈神经网络方法时,加入收益率、波动率的日内成交量比例预测模型和未加入收益率、波动率的模型相比,均方误差的提升(相对于滚动平均方法)从9.90%提高到13.27%,证明了本文提出的使用收益率和波动率来预测成交量比例的有效性。最后本文计算了加入收益率和波动率的日内成交量比例预测模型的VWAP和传统的滚动平均的VWAP,和市场真实的VWAP进行对比。使用平均绝对百分误差作为评价标准,相对于传统的滚动平均方法,加入收益率和波动率的日内成交量比例预测模型的VWAP跟踪效果的平均绝对百分误差提升了38.36%,证明了本文提出的模型的VWAP跟踪效果更好。通过分析VWAP跟踪误差较大的交易日的实际情况,本文发现在该交易日的中间时段开始,成交价开始大幅下降,导致成交量激增,这个时候传统的滚动平均预测的成交量比例与实际情况相差较大,加入收益率和波动率的日内成交量比例预测模型预测的成交量比例能较好的拟合实际的成交量比例,因而相应的VWAP跟踪效果更好。同时本文使用了前馈神经网络方法来预测成交量比例,为以后将更加复杂的神经网络方法应用到这方面的研究打下了基础。"
1361,结合Relief算法基于神经网络与支持向量机的股价指数预测研究,"股票作为证券市场的重要组成部分,其价格的变动牵动着众多股市参与者的心。如果能够成功预测股价的走向对众多股市参与者来说意义重大,对于投机者来说可以通过预测股价的涨跌方向并在多次买卖中获取短期利润,对于投资者来说预测股价的涨跌方向可以更好的判断市场的情况并制定相应的投资策略,对于风险管理来说预测股价的走向更有利于及时从不合理的股价运动中发现市场风险并提前做出相应的管控和调整。因此寻找有效方法预测股票的价格或涨跌成为金融界的重点关注的问题。虽然股票价格的预测问题意义重大,但其在金融领域中却是一个异常复杂的问题,这是因为股票价格的运动是很复杂的,并且被诸如政治事件、公司政策、一般经济环境、投资期望、机构投资者的选择以及投资心理学等等多种因素影响。这些原因造成了股票价格的运动走向是一个非线性的、复杂的并且混乱的系统。在这样的情况下就意味着简单的模型是不能解决股价预测问题的,而是需要寻找更为复杂的模型或方法来解决这个问题。虽然股价预测的难度非常大,但到目前为止股价预测已经发展出了多种解决方法,其中所使用的方法大体上分为证券业所使用的基本方法、传统统计方法、机器学习方法和其他方法。本文将从BP神经网络在沪深300指数价格预测中的应用出发,并讨论不同机器学习模型、数据量的提高和Relief特征选择算法是否有利于提高模型预测准确率。为了实现上述目的,本文的主要工作分为三个部分,第一部分将BP、RBF神经网络和SVM(支持向量机)应用于沪深300指数日频数据的涨跌预测以对比不同模型的预测能力;第二部分将BP神经网络分别应用于沪深300指数的日频数据和分钟频数据的涨跌预测验证增大数据量是否会提高模型预测能力;第三部分将Relief算法应用于BP、RBF神经网络和SVM的沪深300指数日频数据的涨跌预测验证Relief特征选择是否会提高模型的预测能力。实证各部分结果如下:第一部分显示SVM的预测能力高于RBF神经网络,RBF高于BP神经网络;第二部分显示数据量的增大会提高BP神经网络的预测能力;第三部分显示Relief算法在SVM(多项式核函数)上会一定程度上提高预测能力。"
1362,深度森林在股指涨跌预测和投资策略中的应用,"近年来,在金融时间序列的预测问题中,股票价格指数涨跌预测是投资者和研究人员最具挑战性的金融时间序列预测问题之一。由于机器学习方法与金融时间序列的特点相契合且机器学习方法在分类和预测等问题上具有很强的性能,越来越多的机器学习方法应用在金融时间序列的预测问题上。本文首先简述了四种机器学习分类模型的理论知识。然后,以四种模型为基础构建股指涨跌预测模型,归纳总结前人的研究成果,选取了8个技术指标作为模型的输入特征,并应用了针对输入特征的离散化处理方式。将股指涨跌预测模型应用于沪深300指数上,对四个模型进行验证。通过对比分析四种机器学习算法针对不同预测频率的预测性能,充分验证了基于改进输入方式的深度森林模型在股指涨跌预测问题上的有效性,在日频和周频的股指涨跌预测中,该模型的准确率分别为59.78%和67.11%,AUC值分别为0.5514和0.6429,表现出十分显著的分类性能优势。最后,本文基于深度森林预测模型,构建了两个趋势择时策略,一种是基于指数基金的择时策略,另一种是基于沪深300成分股的股票组合的择时策略。两个择时策略在回测期间均具有良好的表现,在收益、风险和风险调整收益方面优于市场。本文提出的基于改进输入方式的深度森林模型在股指涨跌预测和投资策略构建上可以得到较理想的结果,具有实际的应用价值,能够为广大的机构投资者和散户提供借鉴和帮助。"
1363,一种结合图像质量评估和图像增强的指静脉识别方法,"Biometric recognition is the study of physiological and behavioral characteristic of person to overcome the problem of Information security.In today modern world,variety of biometric technology are employed,like fingerprints,face,iris or behavioral characteristics such as gait and signature,for automatic identification of an individuals.Among all biometric traits,finger vein recognition(FVR)technology is considered one of the new,reliable and superior biometric modality,which attract the attention of researcher around the globe with its unique advantages.Compared to other biometric technology,FVR system have many advantages,such as anti-counterfeiting,user-friendly,live detection of finger vein,required a small device to capture finger vein image,easy to carry the FVR system.However,image quality of finger vein influence the performance of FVR system.Finger vein image is acquire using NIR(near infra-red light)in illumination transaction method.Therefore,most of the finger vein images prone to non-uniform illumination,low contrast,noise,low brightness problem.These low quality images have a great influence on the performance of FVR systems.Therefore,how to effectively evaluate the quality of finger vein image and how to enhance the low quality finger vein image is still a key issue for FVR system.In this paper,a detail review about various steps is presented i.e.image acquisition,preprocessing,feature extraction and matchingMoreover,we list of the some novel finding after critical finding comparative analysis of the highlighted techniques i.e.traditional finger vein recognition method,Machine Learning and Deep Learning Finger vein identification methods.During performance analysis of various,we find that Image quality is also one of the factor that effect the performance of Finger vein recognition system.Finally,we present a novel method to enhance the quality of finger vein images and improve the performance of the FVR system.To deal with the image quality problem,a novel finger-vein image quality assessment method and an enhancement method are proposed.The proposed finger vein recognition Scheme is based on two folds:(i)Image Quality Assessment,and(ii)Image Enhancement.First,the quality of the image is assessed by the decision tree with r-smote technique,to classify the finger vein image into two classes,i.e.High Quality(HQ)and Low Quality(LQ)images.Second,a single scale retinex filter(SSR)with chromaticity preserved algorithm and Gaussian filter are proposed to enhance the low and high quality finger vein images.To evaluate and test the strength of proposed system,two parameters-namely accuracy and equal error rate(EER)for classifier and recognition performance respectively are employed on a dataset of 1052 Finger vein images.It was determined from experiment that proposed image assessment and enhancement method outperformed other enhancement and assessment scheme,by achieving low error rate of 0.0379.The achieved results show the strength of the proposed art is better than already developed methods in FVR domain.Results also conclude that proposed art would be perfect pre-processing tool for finger vein feature based algorithms."
1364,高速公路收费站车流量预测以及人力资源调度与优化,"实时准确的高速公路短时交通流预测是高速公路智能交通系统的核心内容和重要基础,而且有利于交通管理者实施动态交通诱导、保证交通控制与安全、实现先进的交通管理。由于短时车流量具有非线性、突变性、不确定性的特点,单一的预测模型难以适用,而基于集成学习的融合模型能够结合单个模型的优势,捕捉交通流的变化趋势,更加准确地预测出未来的车流量。本文基于Average和Stacking两种模型融合方法进行建模,研究比较各模型的预测效果,主要工作内容和结论如下:(1)对实验的交通流数据进行统计分析,处理数据集中的缺失值和异常值,并利用时间窗口平移的方法扩充了样本数据。根据处理后的数据,从时间、天气、道路三个方面构造特征。(2)建立XGBoost(Extreme Gradient Boosting tree)与LightGBM(Light Gradient Boosting Machine)两个基础模型预测高速公路收费站车流量。从时间、路线角度设计组合方案进行融合实验,通过mape指标选择合适的方案。(3)建立基于XGBoost、LightGBM、随机森林(Random Forest)以及支持向量机(Support Vector Machine,SVM)的两层Stacking框架模型预测高速公路收费站车流量。将XGBoost、LightGBM、随机森林三个基础模型放入Stacking框架中第一层,把SVM模型作为第二层融合模型。第一层交叉验证得到的预测的结果作为第二层SVM模型的输入。(4)根据预测的车流量建立高速公路收费站排队模型,预测未来各时段的收费员需求,从而实现收费员的动态最优配置。通过实验表明,本文提出Average和Stacking两种模型融合方法都比单一模型的预测准确性要高。而且在两种方法中,基于Stacking预测的框架虽然比较复杂,但在整体预测精度上比基于Average的方案要好。另外,本文的基于车流量预测的收费员动态配置对高速公路收费站人力资源优化具有重要的指导意义。"
1365,视频内容理解研究与应用,"随着互联网的广泛应用和现代信息处理技术的发展,视频数据呈现出爆炸式的增长趋势。由于视频数据具有结构复杂、内容丰富、非结构化等特点,人们对海量视频数据处理能力有限,其中潜在的信息没有被充分挖掘,因此需要采用更加智能化的技术对其进行处理。视频内容理解是智能化处理视频的主要手段,也是计算机视觉领域的一个研究热点和难点,涉及到的学科包括模式识别、图像处理、计算机视觉、人工智能等,在军用、民用及医学等方面有着重要意义,广泛的应用前景和潜在的经济价值。本文主要基于视频关键帧提取和目标检测实现视频内容理解,并通过视频内容理解在自动驾驶中的实际应用为例,阐述视频内容理解技术和应用。本文工作由以下五个部分组成:(1)针对视频数据非结构性、难以处理的特点,利用HSV直方图法将抽象复杂的高维数据转换为可以量化的低维数据,从而减少了数据量。(2)结合视频数据相邻帧具有相似度高的特性,将关键帧提取转换为聚类问题,分别设计了K-Means、凝聚层次聚类和密度峰值聚类算法来提取视频关键帧,并分析了它们的聚类效果,同时对比了压缩域关键帧提取算法和非压缩域关键帧提取算法的结果,最终得到了一种综合性能较好的视频关键帧提取算法。(3)为了保证聚类的质量,利用轮廓系数SC(Silhouette Coefficient)计算最佳聚类簇数,以确定初始的聚类中心和簇的数量。(4)为了提高目标检测模型的准确率,对数据集进行了剪枝,使得模型能够更好地适应特定应用场景,实验表明,改进后的模型在识别准确率上有所提升。(5)结合关键帧提取和目标检测算法构建了一套完整的视频理解实验流程,以自动驾驶系统为背景对实验数据进行了分析,展示了视频内容理解在自动驾驶中的实际应用。"
1366,基于LSTM的风机发电量预测研究,"随着全球经济的发展,能源消耗不断增加,而石油、煤、天然气等不可再生能源的蕴藏是有限的;同时随着化石燃料大规模的开采和消耗,带来了严重的环境问题。各国政府都对新能源的发展日益重视。风力发电在政策鼓励下发展迅速,但是风能本身的随机性给电网安全带来了威胁。电能是一种不可大规模存储的能源,电网必须保持大致的消纳平衡。电网本身的供需要求是平衡的,但风能的波动性是随机的,大规模接入电网对电网安全运行产生威胁。风电功率必须进行预测,以便电力调度。准确预测风电功率,可以有效缓解风电波动对电力系统安全运行的影响。随着风电平价上网的推进,对风电企业提出了更高的要求,为避免风电资源浪费,必须提供优质、可预测的电能,才能提高风能的竞争力。本文提出基于LSTM网络的滚动预测模型。对风电原始数据进行了预处理,对数据缺失进行了合理补偿以及科学删减,确保了数据的有效性;建立了LSTM网络,结合滚动预测方法对风电功率进行了预测研究。同时为进一步提高风电功率预测质量,提出了基于Bi-LSTM网络的风机发电量预测模型。本文的研究内容主要有以下几个方面:1.本文依托TensorFlow深度学习框架搭建了LSTM网络。将经过预处理的数据进行截取,对训练数据进行后端截取,对测试数据进行前端截取,制造时间差。模拟真实预测场景数据预测的时序顺序。然后对模型进行训练,最终利用训练完成的模型进行预测测试。2.针对风电功率预测的实际需求,结合滚动预测方法,构建了基于滚动方法的LSTM预测模型。风机发电量的变化主要依赖天气因素的变化,而不同风电厂的天气规律也各不相同,同一风电场在不同季节天气规律也各不相同。因此,难以利用一个固定参数的模型,针对任意风电场进行功率预测,而滚动预测的基本思想是不断利用获取的新数据,对网络参数进行优化,获取最新风电功率变化规律,有利于提高风电功率预测准确率,同时也提高了模型对不同风电厂的适应能力。3.为进一步提高风电功率预测准确率,研究了风电功率历史数据的内在特点。对当前时刻风电功率的预测不仅可以利用历史风电数据的变化规律,也可以结合考虑未来风电数据的变化规律。因此模型可以从两个时间方向对当前时刻风电功率进行预测。Bi-LSTM可以从两个反向的时间方向对当前数据进行预测,提出了基于Bi-LSTM的风电功率预测模型,实验结果表明,Bi-LSTM模型进一步提高了风电功率预测准确率。"
1367,基于阴道菌群构成变化的外阴阴道假丝酵母菌病复发风险预测模型构建,"研究背景外阴阴道假丝酵母菌病(Vulvovaginal candidiasis,VVC)是育龄期女性常见的下生殖道感染性疾病,与阴道菌群失调密切相关。VVC治疗后仍易复发甚至一年内复发4次或以上发展为复发性外阴阴道假丝酵母菌病(Recurrent vulvovaginal candidiasis,RVVC)。RVVC反复发作引起的临床症状及体征严重影响女性的身心健康、夫妻和谐与社会稳定,但目前其治疗仍是一难题。近年研究证实VVC患者阴道菌群构成呈多样化,RVVC相对单一;抗真菌治疗后,VVC患者阴道菌群结构的改变较RVVC显著,且后者菌群结构在疾病发作期和间歇期相似。亦有研究提示在VVC患者治疗后首次复发的阴道菌群较健康女性明显发生变化,随着复发次数增多其菌群结构则趋于稳定。本研究拟对VVC患者初次治疗后的阴道菌群状态与临床信息进行检测与分析,采用机器学习算法,构建VVC复发风险的预测模型,以期探讨和明确VVC复发的相关因素,为未来进行早期干预,预防其进展为RVVC打下理论基础。研究目的比较WC初治患者6个月内复发与未复发人群的阴道菌群差异,并基于VVC患者阴道菌群的构成,整合临床信息指标,尝试构建出VVC复发风险的预测模型。研究方法第一章2017年8月至2018年1月在云南省第一人民医院妇科门诊的首次诊断为VVC的患者,采集所有入组患者在初次治疗停药3天后复诊时的阴道分泌物。根据患者治疗后半年内的随访情况分为两组:复发组(即Yes)、未复发组(即No)。对样本进行处理后采用Illumina高通量测序技术对扩增的产物进行测序,再通过BIPES生物信息分析方法,比较两组间阴道菌群物种丰富度和结构差异。对多样性指数,应用SPSS20.0软件进行统计学处理,应用Wilcoxon Signed Ranks检验。P"
1368,基于差异基因共表达网络筛选阿尔兹海默症生物标志物,"阿尔兹海默病(Alzheimer's Disease,AD),是一种神经退行性疾病,会对患者部分脑区造成不可逆损伤,最终导致患者记忆及身体机能受损。随着全球老龄化程度加剧,AD患者数目将不容小视。此外,中国AD患者的疾病相关成本远高于癌症和心血管疾病,将会成为加剧社会负担的重要一环。截至目前为止,研究尚未得出AD明确的致病机理和有效的治疗方法,大部分研究得出的都是相关的假说,如淀粉样蛋白假说、炎症假说等。但已有研究证明,AD早期诊断具有重要的个人和社会效益,那么结合中国国情来说,筛选出能够用于诊断AD的血液生物标志物将会产生更大的作用。虽然已经存在少数生物标志物,如Aβ-42与Aβ-40比值、脑脊液(CSF)中tau蛋白的浓度及APP基因等具备较好的分类能力,但是目前并没有真正通过临床验证的AD生物标志物。本文使用不同脑区数据及时间序列数据,分别根据数据特征,采取不同方法构建差异基因共表达网络继而从网络中筛选出候选的生物标志物,并将候选生物标志物整合后使用血液数据进行初步验证,得到论文发现的AD生物标志物。全文主要研究内容如下:(1)对于不同脑区数据,本文采取整合六个脑区差异基因构建差异基因共表达网络的方法,得到差异基因共表达网络,通过对网络进行聚类,得到不同网络模块,后使用机器学习方法从网络模块中筛选出分类能力最好的模块,模块中含有的44个基因视为不同脑区生物标志物。最后,对模块进行功能富集分析发现其主要参与能量代谢、转化和功能失调修饰等生物学过程。(2)对于时间序列数据,本文采取基于基因共表达网络构建差异基因共表达网络的方法,筛选出差异基因共表达网络,由于网络内部已成模块,挑选网络中差异最显著100条边中的189个特异基因进行SVM(Support Vector Machine)时序多分类评价,得到时间序列生物标志物。经过功能富集分析,得到生物标志物主要参与细胞程序性死亡,转录和磷酸化等生物学过程。(3)整合不同脑区与时间序列生物标志物作为候选AD生物标志物,进行血液数据初步验证。采用SVM留一法对标志物分类能力进行评价,得到相应ROC(Receiver Operating Characteristic Curve)曲线及AUC(Area Under Curve)值。其中,不同脑区生物标志物对应AUC值为0.760,整合生物标志物对应的AUC值为0.920。鉴于上述两类基因整合后共232基因构成的生物标志物分类能力较好,可作为论文筛选出的AD生物标志物。"
1369,无线视频用户感知质量评价模型的研究,"如今,网络技术发展越来越迅速,用户接触到越来越多的无线视频服务,使得用户对观看无线视频体验质量的要求也越来越高。为了提升用户体验质量,评估及进一步优化无线视频业务的体验质量,对于保证用户观看视频业务的良好体验,具有重要意义,同时也是视频业务提供商和运营商关注的重点。本文以无线视频业务的用户体验质量(Quality of Experience,QoE)为研究重点,研究了无线视频业务的用户体验质量评估模型。首先,本文充分调研了无线视频服务用户体验质量的相关研究,给出了用户体验质量的定义,阐述了无线视频业务主观、客观和伪主观质量评估方法及其原理,详细介绍了无线视频业务无参考QoE评估模型,包括ITU-T G.1070模型、基于最近邻居算法评估模型、基于反向传播神经网络评估模型、基于圆形反向传播网络评估模型四种评估模型的原理。其次,针对无线视频业务用户体验质量的评估问题,提出了一种基于模糊层次分析法(Fuzzy Analytic Hierarchy Process,FAHP)的QoE评估模型。对影响无线视频业务QoE的终端参数、网络层、图像特性和内容特征等参数进行分析,确定了影响无线视频的QoE因素,分别为视频内容特征、网络层服务质量、终端质量及图像特性层。同时,确定了每个影响层面所对应的影响因素。然后,利用FAHP建立评价模型,并通过网络仿真和用户主观测评验证了各因素对无线视频业务QoE的影响及本文提出的评估模型的有效性。最后,针对无线视频业务客观无参考的用户体验质量的评估问题,提出了一种无参考质量评估模型:基于径向基函数神经网络((Radial Basis Function Neural Networks,RBFN)的改进模型。在此基础上,详细介绍了此评估模型所采用的算法及模型原理。通过仿真,将此模型和另外四种经典的无参考评估模型的评估结果分别对比研究,证明了本文提出的基于径向基函数神经网络的QoE评估模型具有最低的均方误差和最高的皮尔森相关系数,在评估准确度方面性能最优。"
1370,基于机器学习的Massive MIMO检测技术研究,"大规模多输入多输出(Massive Multiple-Input Multiple-Output,Massive MIMO)技术能够显著提升频谱效率,是5G的核心技术之一。由于Massive MIMO天线数目众多,检测计算复杂度显著增长,这对传统的检测算法提出了巨大的挑战。采用深度学习进行Massive MIMO信号检测,能够实现较高的计算并行度,是解决信号检测问题的一条重要技术途径。在现有的研究中,DetNet是一种采用深度学习进行信号检测的典型方法,具有较高的性能。在研究过程中,我们发现DetNet仍然有提升的空间。本文主要对DetNet网络进行了两方面的改进,(1)检测网络的简化;(2)扩展检测模型以适用于高阶调制。对网络的简化包括三个方面:网络输入简化、网络连接结构简化和网络损失函数简化。通过以上处理,网络的计算复杂度显著降低,同时检测性能也有改善。之后我们对改进后的网络扩展到高阶调制的Massive MIMO检测中。在这个场景中,我们将各调制符号映射为高维二进制向量,作为网络的检测输出,之后对向量进行线性加权,实现对高阶调制符号的解调。仿真结果表明,该检测方法适用于较多天线数目的场景,随着收发天线数的增多,检测的性能能够得到提升。"
1371,基于深度学习的数字信号调制识别研究,"调制识别技术是指在缺少先验知识的条件下,通过分析研究接收到的信号样本,来判断信号所采用的调制方式及其他参数的技术。调制识别技术作为一直以来通信领域中的一个研究热点,广泛应用于信号监测、频谱管理、电子对抗等多个军民用通信领域。目前,调制识别研究主要使用特征提取和模式分类结合的方法。随着人工智能技术的飞速发展,深度学习理论也越来越多的应用到调制识别领域。与传统的调制识别算法相比,基于深度学习的调制识别算法能从信号数据中自动地学习到更深层的特征表示,往往取得更好的识别效果。本文就深度学习技术在调制识别领域的应用做出了以下两部分研究。第一部分,研究了基于奇异值降噪和卷积神经网络的频率键控信号调制识别。首先,根据奇异熵理论对三种接收信号(2FSK、4FSK、8FSK)样本降噪处理;然后,计算降噪后信号样本的循环谱特征图;接着,对循环谱特征图做一定的变换处理;最后使用卷积神经网络进一步提取特征,并完成分类。在仿真分析中,对比了三种算法的识别率:本文提出算法、循环谱特征图与卷积神经网络结合的算法、循环谱切片向量和神经网络结合的算法。结果显示,本文提出的算法实现了更高的识别率,并且在信噪比-10dB条件下识别率接近100%。第二部分,研究了MIMO系统中基于自编码网络的数字信号调制识别。空分复用MIMO系统中复杂的信道环境给调制识别的研究带了很大的挑战。本文提出的算法首先提取五种调制信号(2PSK、4PSK、8PSK、16QAM、32QAM)的累积量特征;然后使用自编码网络处理信号累积量,得到新的低维非线性特征;然后用神经网络完成分类。在仿真分析中,对比了四种算法的识别率:本文提出算法、直接使用十二维累积量的算法、人工挑选三维累积量的算法、累积量经PCA降维处理的算法。结果表明,本文提出算法优于其他三种算法,在信噪比OdB的情况下识别率接近100%。"
1372,基于近似计算的GPU并行度提升方法,"随着机器学习、多媒体处理技术在新兴的自动驾驶、边缘计算等领域的广泛应用,应用程序对计算能力的需求越来越强烈。GPU的广泛普及极大地缓解了后摩尔定律时代应用程序日益增长的计算需求和发展缓慢的计算机硬件之间的冲突。为了减少上下文切换代价、隐藏内存延迟和提高程序并行度,GPU中的寄存器文件大小设计大大超过了CPU的寄存器文件。尽管GPU等异构平台的计算力在逐渐提高,但不断增长的大数据处理需求还是造成了一定程度的计算力短缺,比如很多深度学习框架的训练需要几天甚至几周的时间。此外,近年来GPU的寄存器管理策略没有发生较大变化,GPU寄存器资源的管理越来越成为程序的性能瓶颈。而机器学习、多媒体处理等应用本质上是大量的并行浮点数计算,对于这类应用,半精度浮点数计算的精度足以满足计算结果的精确度要求。近似计算利用这些应用的容错性,给进一步挖掘现有架构的性能潜力带来了机遇和挑战。本文探索了近似计算在GPU寄存器管理上的应用,设计了对于程序设计人员透明的选择性压缩寄存器的近似计算框架。通过分析GPU汇编文件的寄存器生命周期、分支调用关系,选择性的将两个32位寄存器合并到一个32位寄存器中,减少寄存器的使用量,提升程序的并行度。为了减少程序剖析的代价,本文在静态编译时对不同压缩方案添加了诸多限制,并通过分析不同方案的运行时间和精确度进行方案剪枝优化。本文在GPGPU-SIM模拟器上实现了设计的近似计算框架,实验结果表明,对于具有容错性且寄存器为性能瓶颈的应用,本文的算法相比于CUDA内置的maxrregcount/launch_bound方法,在同样平均提高14%并行度的情况下,获得了平均1.13倍的加速比,计算结果错误率平均为4.2%。"
1373,基于文本分析的在线图书评论质量研究,"随着大数据时代的到来,越来越多的人通过互联网分享自己的观点和想法,用户在线评论数量呈指数型爆发,评论的控制和利用成为当前网络平台面临的重要考验。一个有效的网络评论管理系统应当具备以下两方面的功能:帮助用户快速的从海量数据中得到有用信息和帮助平台合理有效的管理和利用用户评论。评论质量评估作为自然语言处理的一个分支,成为网络评论管理系统的重要组成部分。评论质量评估即寻找可衡量评论质量的指标,根据相应指标对评论质量进行量化,进而可以根据质量高低将评论进行过滤、排序等更多处理,识别出质量较高的评论,使得阅读评论的人能够在海量评论中快速获取有价值的信息。对非商业化图书交流平台进行评论质量评估,一方面,有助于识别出高质量评论,使读者更加快速高效地发现有价值的评论,协助其选择适合自己的、更优质的书籍。另一方面,能够改进图书门户网站的现有评论展示功能,改善网站的服务质量,提高用户体验度。本文面向非商业化图书平台的用户评论进行了质量评估研究。首先分析了非商业化图书平台的特点,结合中文表达方式的特殊性,构建了一套适用于该类型平台的WDC在线评论质量评价指标体系,然后以该指标为基础分析了使用支持向量机方法、逻辑回归方法进行分类的可行性。最终,以“豆瓣读书”网站上三种图书类型的评论数据进行了实证分析,分别利用支持向量机方法和逻辑回归方法建立了在线评论质量评价模型,从查准率、召回率、F值、准确率四个方面对模型的分类效果进行了分析,发现在这套评价体系下,支持向量机方法的分类效果比逻辑回归方法更显著。同时采用随机森林方法对各指标进行排序后得出结论:对于非商业化图书平台上的用户评论,评论的修饰词数对评论质量影响最大,其次是平均句长和字符数,而评分差异对评论质量的影响最小。本研究的创新之处在于:一、针对目前研究较少的非商业化平台构建了评论质量评价指标体系;二、在标注训练集评论质量时,采用了有用性投票和人工标注相结合的方式,且在标注时与以往文本长度越长,有用性越强的理论不同,适中数据才会被判别有用,这一改进丰富了有用性的定义。本文的研究成果丰富了非商业化平台在线评论质量评估的研究内容,为后续研究做出了一定铺垫。"
1374,基于深度强化学习的目标识别研究,"目标识别技术在计算机视觉领域有着十分重要的作用,是该领域的一个基础研究方向,其他计算机高级视觉处理和分析任务都依赖于目标识别技术为其提供基础性的图像信息数据。深度机器学习技术日渐创新,取得不断突破,特别是在数字图像处理领域,卷积神经网络模型所展现出的优秀的图像特征提取能力。虽然基于卷积神经网络模型的目标识别模型的相关领域研究发展迅速,但在实际推广应用中基于传统卷积神经网络的识别模型还存在一些不足。通过前阶段的学习研究发现传统卷积神经网络算法在实际应用过程中存在以下两个问题:第一,在卷积神经网络训练过程中,随着迭代次数的增加,后期的训练过程中,收敛性能和识别性能大幅度降低。第二,卷积神经网络在识别过程中时间复杂度过高引起的耗时过高。针对这两个方面的问题进行研究创新。本文就深度强化学习结合模型的研究主要分以下两个方面:(1)传统目标识别领域,在做图像特征分类时多是采用传统的卷积神经网络算法进行分类特征的自适应增强,但其存在一些不可避免的问题,即随着迭代次数的不断增加,收敛性能和识别性能大幅度降低,为此在这里提出了一种基于深度强化学习的目标识别方法方法。采用复域Contourlet变换方法对目标图像特征区域进行复域Contourlet分解,将分解结果输入到滤波器组中进行过滤处理,提取出目标图像子带系数矩阵,求取该系数矩阵的相关特征,并将这些特征的融合结果作为目标图像的特征向量。采取深度学习网络,使所选图像的特征向量参与模型训练过程,完成模型的训练。在实际实验过程中所提出的新的结合模型在相同迭代次数情况下体现出更强的识别性能,收敛性能也明显增强。(2)针对基于深度强化学习的识别模型在辐射源信号识别这一过程中,暴露出的时间复杂度过高这一问题进行研究。对传统降维的方式进行改进,通过多个隐藏层的使用,进而优化实现高维向低维编码。通过对低维编码的直接研究,研究结果更贴近原始数据本质,降噪自编码器拥有着较为优秀的非线性降维功能,利用这一特性对预先构建的传统卷积神经网络模型加以改进,降噪自编码器对冗余信息的去除,可以使我们更好的保留和识别数据主要特征,完成输入数据的高维向低维映射。对识别过程中暴露出的时间复杂度过高这一问题加以改善。"
1375,勒索软件追踪溯源技术研究,"勒索软件(Ransomware)是一类以加密数据、锁定设备为攻击方式,以勒索钱财为目的的恶意软件。如何应对勒索软件威胁,避免数据及财产遭受损失,已成为学术界和产业界的共同挑战。本文研究勒索软件发展历程与生命周期,从攻击目标、生命周期、安全威胁和攻击手段四个方面,介绍勒索软件机理。详细介绍勒索软件生命周期五个阶段的关键技术,并根据各阶段特性,理清现有的勒索软件对抗技术。目前,虽然已有众多勒索软件对抗系统,但传统的对抗方式在应对定向型勒索软件攻击时效率较低且对抗能力不足。所以,本文提出使用追踪溯源技术对抗勒索软件,通过威慑攻击者,达到遏制勒索软件传播的目的。根据勒索软件攻击与防御特性,本文提出勒索软件追踪溯源模型,在模型基础上设计并实现勒索软件辅助追踪溯源系统。首先,利用网络欺骗技术,诱导攻击者至欺骗环境。然后,通过监控模块收集攻击者遗留的可溯源线索。最后,结合机器学习及自然语言处理技术,设计实现了能够自动化提取和分析攻击者线索的可溯源信息分析子系统。本文邀请122名志愿者模拟勒索软件攻击环境,证明辅助追踪溯源系统诱导攻击者和收集可溯源信息的有效性,通过自动化分析勒索软件攻击者和制作者可溯源信息,信息收敛率可达98%。在真实的勒索软件样本分析溯源中,也证明了本文提出的方法在实际中也有辅助追踪溯源勒索软件制作者的能力。"
1376,基于RNN结构深度学习系统的白盒自动化测试方法的研究,"随着大数据时代的到来,以及计算硬件算力的快速发展,之前沉寂几十年的机器学习焕发了新的生命。深度学习(DL)是机器学习和人工智能研究的最新及最火趋势之一,深度学习不论在学术界还是工业界都是当今最流行的研究趋势。深度学习为计算机视觉(CV)和自然语言处理(NLP)还有语音以及医疗等方向带来了革命性的进步。新的深度学习技术正在不断诞生,超越最先进的机器学习甚至是现有的深度学习技术。随着深度学习的发展,应用深度神经网络的深度学习系统越来越多地部署在与许多与安全相关的关键领域,包括自动驾驶汽车、人脸识别或者预测金融市场涨跌行为,这类系统要求深度学习网络模型的安全性非常高。但令人遗憾的是,尽管深度神经网络系统的功能令人印象深刻,但由于训练数据偏差,过度拟合和模型不足等原因,对于一些极端样例(corner cases)中经常会做出意外或不正确的后果,自动驾驶汽车可能会发生严重车祸,人脸识别错误会发生重大财产及信息损失等等。因此,对于人身、财产、信息、网络安全都至关重要的深度学习系统必须像传统软件一样,必须经过系统地测试不同的极端案例,以检测和修复任何潜在的缺陷或事与愿违的行为,这就要求我们设计的深度神经网络系统的鲁棒性非常强。这个问题已经引起了学者的广泛关注,TianY等人提出了 DeepXplore,首个针对深度学习系统的自动化白盒测试框架。DeepXplore有效地在目前最先进的数个深度学习模型上发现了数千个不正确的极端案例行为(比如说自动驾驶汽车撞向护栏、恶意软件伪装成好软件)。该工作创新性地提出了神经元覆盖指标去查看在执行测试套件(test suite)期间被激活的神经元百分比,给我们提供了非常好的思路。同时该工作还有一些问题没有解决:可允许的约束不够灵活,所以得到的输入只能成为用于训练的输入,加上一些小的改动。另外,没有针对现阶段应用特别多的循环神经网络(RNN)做出测试。因为RNN网络独有的状态机制,RNN的输出与输入之间的关系比较复杂,我们对其进行了仔细的研究,分析出了其独特的求导机制,利用展开计算图,使用雅可比矩阵对每一个时刻的输入进行求导。Szegedy等人在有关敌对深度学习的研究中已经证明,神经网络很容易被欺骗,通过对现有图像添加微小干扰而精心制作的合成图像可以欺骗最先进的深度学习系统。Papernot等人成功生成递归神经网络(RNN)的敌对输入序列。验证了对抗样例的生成同样适用于RNN网络。根据这些已有的工作,我们在工作中提出了针对RNN应用的输入更加灵活的限制,让简单的修改和巨大的修改都成为可能。另外,我们同时在使用RNN的图像识别和自然语言处理的应用中分别做了测试,达到了不错的效果。我们将最后修改的原始输入加入到训练集中,继续训练深度学习系统,发现系统的准确性和鲁棒性均有提高。"
1377,云环境下移动智能终端入侵检测方法研究,"随着互联网技术的迅猛发展,以及云计算与移动智能终端技术的相互融合产生了移动云计算(Mobile Cloud Computing,MCC),并引起学术界和工业界的广泛关注。根据2016年思科IBSG数据显示,全球近85%的人口都在使用移动终端设备。然而,由于MCC具有分布式、用户访问量大和操作简便等特性,入侵者亦可在无管理员授权的情况下使用云计算和云存储等服务。针对移动云计算中的安全问题,许多研究学者采用防火墙技术和入侵检测系统(Intrusion Detection System,IDS)等网络信息安全技术来保障移动云计算安全。但现有研究依然存在较多的安全问题,如防火墙技术可扩展性和自适应性较差,IDS的检测精度低、误报率高以及数据属性冗余等问题。针对现有IDS存在的上述问题,论文采用基于分类和信息论的机器学习方法构建了入侵检测系统的入侵检测模型。论文采用的基于分类的机器学习方法和特征选择方法包括:支持向量机(Support Vector Machine,SVM),随机森林(Random Forest,RF),信息增益(Information Gain,IG)和用于进化特征选择的MapReduce(MapReduce for Evolutionary Feature Selection,MR-EFS)。主要研究工作如下:1.为了提高入侵检测分类的准确率并降低高误报率,采用支持向量机(SVM)和随机森林(RF)两种分类器对正常或恶意攻击进行了分类识别。2.实验采用KDD99和NSL-KDD等公共数据集,但这些公共数据集中仍存在冗余属性和重复无效数据记录的现象。为了处理数据属性冗余问题,论文采用了基于信息增益(IG)的特征选择和用于进化特征选择的MapReduce(MR-EFS)方法。在论文中,采用了基于IG的特征选择和MR-EFS方法来消除冗余和不相关的特征。实验结果表明,利用所提特征选择方法可有效地降低实验数据集的数据维度和计算复杂度。3.入侵检测系统作为一种实现网络安全的重要技术,广泛用于检测网络中的恶意访问和入侵攻击。结合上述问题,本研究将IDS技术引入到MCC中实现了入侵检测和攻击防护,并提出了两种基于移动智能终端的入侵检测方法。实验结果表明,提出的两种入侵检测方法对MCC中的恶意攻击具有很高的入侵检测精度和较低的误报率。"
1378,人工智能算法在电信运营商用户信用评级中的应用研究,"随着我国市场经济进入高质量发展阶段,信用体系的建设成为一种必然趋势。无论是机构、企业还是个人,信用在生产经营和日常生活中的作用愈发重要。如今互联网经济的不断发展,信用衍生品层出不穷,P2P、网络购物平台等互联网公司推出纷繁复杂的信用消费产品。但由于新兴平台尚处于扩大用户规模的初步阶段,信用风险成为公司发展的关键问题。而“互联网+”模式的兴起不仅使三大电信运营商之间的竞争白热化,且使一些互联网公司也加入到竞争行列。为了争取更多的用户资源,电信运营商不得不降低入网门槛,但该行为导致用户欠费转网现象频繁发生,也是公司造成亏损的重要原因。如此可见,信用风险问题的研究和解决迫在眉睫。近几年,人工智能技术在多个领域应用广泛,同时它也为大数据问题的研究提供了新的解决方案。电信运营商拥有天然的用户规模优势,其数据具有场景来源广、实时性强、真实可靠、覆盖的面广等特点,为人工智能算法在信用风险评级方面的问题解决提供了数据支持。因此,人工智能算法也为解决电信运营商用户信用评级的问题带来新方案。本文首先简单介绍了电信运营商用户信用评级问题的研究背景、研究意义、国内外研究现状、研究目的、创新点、研究方法和论文结构。其次,详细论述了人工智能算法的基本概念、模型的基本原理及其优缺点。接着,以江苏省某市的电信运营商用户的数据为例进行数据处理、变量筛选等工作,并分别采用逻辑回归模型、支持向量机模型、多层感知器模型、决策树模型、随机森林模型、XGBoost模型以及模型融合进行拟合,选择准确率、宏查准率、宏查全率、宏F1、ROC曲线和AUC值等指标对上述模型的拟合结果进行评价和对比。最后,依据实证研究的结果,对电信运营商用户信用评级问题进行总结和展望。通过对包含用户的身份特征、行为特征、消费能力、社交关系和信用历史等多维度的数据进行建模,对比模型实证结果得出:基于XGBoost和逻辑回归的Stacking模型融合在解决电信运营商用户的信用评级问题中比使用单一模型具有更好的效果。从测试集的表现来看,采用该模型融合不仅能够区分出一定比例的信用等级用户,并且还能避免过度将正常信用等级用户错分的情况。同时,该模型融合中包含交叉验证,可以有效防止模型过拟合,结果更具有一般性。因此,通过研究认为该模型融合可以有效辅助电信运营商及时预测和识别出不同信用等级的用户,减少公司的损失,并能够为不同信用等级的用户提供个性化的服务,提升用户的满意程度。"
1379,基于循环神经网络及百度指数预测A股市场波动率,"近年来随着人工智能上升为国家战略,人工智能技术在各领域的应用发展迅速,在金融领域股价变化趋势的预测一直是热点问题,能有效预测股价的走势也有着较大的经济与社会价值。目前人们在股价预测问题中应用人工智能技术时市场内的数据一般选用股票指标数据,构造多个因子,市场外的数据选用文本数据利用自然语言处理技术对股票时间序列进行分析预测。本文主要基于循环神经网络模型,将百度指数数据分析平台的数据视为市场外的投资者情绪,即环境变量,结合部分市场内数据,采用较有代表性的沪深300指数日波动率作为目标预测值进行预测。在本文的研究工作中理论部分主要介绍了传统机器学习方法和循环神经网络模型的相关理论基础,实证部分首先根据与沪深300指数波动率相关的市场内的数据和利用爬虫技术获取的百度指数数据基于嵌入法(Embedded)做特征选择,剔除部分市场外的无效信息,之后利用互信息(MI)度量选用最佳的观测窗口大小和标准化方案,接着在模型构建过程中利用Dropout技术有效防止了过拟合问题,并对模型参数进行调试优化,重新划分了训练集、验证集和测试集,最后与常用机器学习方法XGBoost算法的预测结果对比分析。本文最后的实证结果对比表明LSTM模型对沪深300指数波动率预测效果较理想,损失函数的最优解在合理范围,且循环神经网络LSTM模型预测效果稍微优于XGBoost模型预测结果,也就是说,机器学习算法在股价预测问题的表现具有一定的实用价值,为后续的研究工作拓展思路。"
1380,多生支持向量机及其优化方法研究,"孪生支持向量机是一种用以解决二分类问题的机器学习方法。然而在实际问题中,人们所面临的大多是多分类的情况。因而研究者们把孪生支持向量机扩展到多分类的情况下,形成了多种不同类型的多分类孪生支持向量机。多生支持向量机是一种最近被提出的新型多分类孪生支持向量机。多生支持向量机的判定准则是样本到超平面的最远距离,而不是孪生支持向量机的最近距离。与其他多分类孪生支持向量机相比,它具有计算复杂度低、分类速度快等优点。但是,多生支持向量机未能充分考虑样本特征的序列相关信息,并且它的损失函数不能体现样本类别之间的差异信息。同时,多生支持向量机需要凭借经验来选择参数,不能自动选择参数。本文从多生支持向量机入手,结合循环神经网络模型与Triplet损失函数来改进多生支持向量机算法,并且用优化算法来优化多生支持向量机的参数,从而从多个方面改进了多生支持向量机、提升了算法的性能。主要研究内容为:1.研究了基于循环神经网络的多生支持向量机。传统的多生支持向量机对数据集进行分类时,不考虑样本各维之间的相关序列信息。因而在面对序列相关的样本时,多生支持向量机的分类精度受到了一定的限制。针对这个问题,本文将多层感知器与长短期记忆网络引入到支持向量机当中,提出了三种新的多生支持向量机:基于多层感知器的多生支持向量机、基于长短期记忆网络的多生支持向量机和基于多层感知器和长短期记忆网络的多生支持向量机。在引入多层感知器和长短期记忆网络之后,这些算法可以充分地考虑样本的不同特征之间的序列相关信息,并在一定程度上起到降维的作用。最后,基于DGA域名检测数据集与UCI数据集的实验表明,本文提出的算法是有效的,可以极大地提高多生支持向量机的分类准确率。2.研究了基于Triplet损失的多生支持向量机。在面对不平衡数据的分类问题时,特别是各类样本数目相差很大时,采用Hinge损失函数的多生支持向量机常常存在采样不稳定的问题,使得其分类的精度受到影响。为了使多生支持向量机能够更好地解决不平衡数据的分类问题、进一步提升算法的分类性能,本文将Triplet损失函数应用到多生支持向量机算法当中,提出了基于Triplet损失的多生支持向量机。Triplet损失多生支持向量机通过设置Triplet损失函数中的阈值来控制正类样本和负类样本之间的距离,从而能够充分利用不同类样本之间的差异的信息,较好地处理不平衡数据的采样问题。基于UCI数据集的实验表明,该算法能有效解决不平衡数据集的分类问题,使算法的分类性能得到提高。3.研究了基于动态多群粒子群优化算法的Triplet损失多生支持向量机。传统的粒子群算法在单一的粒子群体中寻找最优值,在每轮迭代中不能动态改变权值。本文通过增加种群数目和动态改变权值系数的方法重新构造粒子群算法,提出了一种新的动态多群粒子群优化算法。与原始的粒子群算法相比,该方法对参数比较多的目标函数有较好的优化作用,可以在一定程度上减少局部极小值的影响,并能够快速找到最优值。本文提出的动态多群粒子群优化算法通过在每次迭代过程中改变各系数的方法防止最优适应度出现震荡,从而可以获得更加良好的收敛精度。随后,本文将该动态多群粒子群优化算法应用于Triplet损失多生支持向量机中,通过动态多群粒子群优化算法来搜寻Triplet损失多生支持向量机的最优参数,使得Triplet损失多生支持向量机的性能进一步提高。本文最后还通过实验测试了动态多群粒子群优化算法与基于动态多群粒子群优化算法的Triplet损失多生支持向量机的有效性。实验结果表明,本文提出的动态多群粒子群优化算法的寻优性能较传统PSO有较大提升。同时,基于UCI数据集的实验表明,本文提出的基于动态多群粒子群优化算法的Triplet损失多生支持向量机是有效的,相比于现有的算法,具有更高的分类精度。"
1381,基于机器学习方法的资产价格路径构造和资产配置的应用探究,"深度学习和强化学习是机器学习的两大类模型,被应用到社会的各个领域。在金融领域内,资产价格路径的模拟对某些路径依赖的期权定价来说意义重大,而资产配置则是近年来发展迅猛的新兴投资方式。本文基于深度学习中的生成对抗网络(GAN)模型和强化学习中的深度强化学习算法分别实现了构造标的资产价格路径的模拟和动态配置资产的资产配置策略。一方面,利用GAN变体构造新的混合模型(CWGAN-GP和ALI-CWGAN-GP)来对资产价格路径的分布进行拟合,并通过采样的方式构造样本路径,以此实现对资产价格路径的构造。通过在沪深300指数期货上的实证,结果表明了混合模型构造的路径无论是在采样速度上、路径收益率外在特征表现上还是在生成路径和真实路径的JS散度度量上都显著优于基于几何布朗运动和跳跃扩散模型的蒙特卡洛实现方法。另一方面,基于深度强化学习中的多种算法,分别训练智能体来动态给出两种资产的最优的配置方案,实证结果表明深度强化学习实现的资产配置,在收益上比基准策略(“买入持有”)和简单策略(布林通道)好很多,算法各有优缺点,适用的情景不同,投资风格也有所不同。此外,采用了上述CWGAN-GP模型生成了多条训练集路径作为强化学习学习的样本,将之运用到DQN、DDPG两种算法的训练上,得到了强于不加生成路径的结果。本文说明了构造的两种GAN混合模型可以作为一种构造资产价格路径的方式,且采样的价格路径质量不劣于蒙特卡洛采样的路径,这种构造价格路径的方法在金融领域的数据生成和资产价格路径构造上存在一定的理论和实际应用价值;而基于历史经验的学习从而得到自动配置资产的能力的深度强化学习算法对于资产配置的实现在实践上有很大指导意义。"
1382,基于XGBoost的基本面量化模型,"量化投资在国外市场经历过较长的发展时间,已经成为成一种较为成熟的投资方法和理念;但在中国证券市场上,量化投资概念引进的时间不长,但发展速度极快;与此同时,基本面投资在国内逐渐成为市场主流的投资理念,也标志着国内市场往更成熟和专业化的方向发展。在这样一个市场和观念不断变化的时代,基本面量化投资将有更深度的发展前景。本文主要参考2017年8月J.P.Morgan团队发表了文章“Value Strategi es based on Machine Learning”,文章提出了一种通过多维股票特征因子来预测公司市净率的统计建模方法。本文先对市净率在A股市场进行单因子有效检验,论证模型合理性,运用XGBoost算法预测下期市净率,再依据市净率建立“相对增长价值”指标。通过指标对沪深300成分股进行评价,做多高分组,做空低分组,最终等比例配权重构建投资组合。在样本外的年化收益率达到了 38%,高于同时期沪深300指数基准收益率。本文创新性的运用XGBoost+Lasso+SVM混合模型进行模型预测,改良后的模型策略与原策略相比有明显增强。本文结合事件驱动效应改进模型,构建事件驱动-基本面量化模型。业绩预告为上市公司公布市场的第一手信息,对股票价格有一定先行作用。本文先进行业绩预告正、负面事件实证,检验通过后依据事件定义剔除投资组合中具有负面事件的股票,改良后的投资组合与原策略相比收益率有小幅提高。最后本文对此类基于机器学习的价值选股进行展望,在进行实证分析后,提出尝试依据市盈率计算新的相对增长价值指标的设想。"
1383,基于有无监督学习的股价预测对比实证分析,"自股票作为一种投资工具被人们所熟知后,股票市场逐步渗透进大众的生活中,并且凭借其资产配置及价格再发现等功能,在国家经济中也发挥着举足轻重的作用。越来越多的人尝试从大量的、不完整的、模糊的股票历史数据中挖掘出隐藏的、有价值的信息,从而进行股票价格的预测,并进一步在股票市场中获得较为可观的收益。然而股票数据的波动非线性性和复杂性等特性可以反映出股价的预测并不像想象中那么简单。近年来,机器学习也是迅速崛起的一个分支,它在大众传媒中的应用范围和宣传力度决定了机器学习算法在不久的将来必然可以取得巨大的进步。同时机器学习算法也凭借其归纳计算能力在股票价格领域得到广泛的应用,各类学习算法根据训练数据中的输入和输出数据拟合出相应的参数,使得其训练出的模型达到误差最小化。然而机器学习领域中的回归算法种类多样,如何在不确定未来股价走势的情况下选取适用于股票数据且预测精度较高的模型则成为现阶段下人们需要考虑和解决的问题。本文所要解决的主要问题就是对比三种有监督学习算法:支持向量机、k-最近邻回归和决策树模型在股价预测方面的精确度,包括单一模型以及结合聚类方法的组合模型。本文在回顾各种股票预测方法,详细阐述有监督学习和无监督学习相关算法内容的基础上,利用单一的支持向量机、k-最近邻回归和决策树算法对上证综指和标准普尔500指数的历史数据进行训练和测试,比较不同参数设置下三种算法的预测精度、误差值和运行效率,结果显示支持向量机搭配高斯核函数和距离加权回归的k-最近邻算法的预测精度较优。之后将三种回归算法与聚类算法进行组合,先使用无监督学习中的主成分分析和k-均值聚类对原始数据进行降维处理,再分别使用选取高斯核函数的支持向量机、距离加权回归的k-最近邻回归以及决策树算法对降维数据进行训练和预测,横向比较各个组合模型的预测结果,实验充分证明基于主成分分析的支持向量机模型和基于k-均值聚类的k-最近邻回归模型在模型评价和预测准确度方面具有明显的优势；纵向比较,结果证明大部分组合模型的预测结果优于单一模型;比较同一种回归算法组合不同聚类算法的结果,可以看出支持向量机算法对于结合主成分分析或k-均值聚类并没有太大影响,基于k-均值聚类的k-最近邻回归模型的结果准确度优于基于主成分分析的k-最近邻回归模型,基于k-均值聚类的决策树模型相比基于主成分分析的决策树模型可以得到更为准确的结果。本文的创新点在于以下两个方面:(1)本文区别于以往学者的研究方向,将无监督学习算法中的聚类算法与回归算法相结合,并将组合算法用于预测股票价格,并在此基础上从不同方向比较预测结果;(2)本文选取较新的上证综指和标准普尔500指数数据,样本数据充足且不失新鲜度,相比单一股票更具代表性,得到的结论更具信服度。"
1384,基于量价关系的DTW-KNN股票趋势预测以及选股策略实证研究,"随着人工智能技术的发展,量化投资已成为欧美资本市场发展的热点与焦点,越来越多的公司将数据挖掘技术和机器学习算法应用于金融量化投资领域。利用机器学习方法进行股票价格和走势预测,以及利用股票未来趋势进行量化选股的研究是非常具有实际意义的,并具有良好的发展前景。本文主要基于机器学习中的K-近邻算法(KNN)来进行股票价格和股票指数的趋势预测,在分类算法的子进程――时间序列的相似性度量中应用动态时间弯曲(DTW),构建了DTW-KNN模型,并充分分析了量价关系,将换手率作为成交量的度量,构建了基于量价关系的改进模型。同时本文应用支持向量机模型作为本文构建模型的对比模型。本文将三种模型应用于中美股票市场,分别对上证50指数和标准普尔500指数进行了趋势预测。实证结果得到支持向量机模型和本文构建的DTW-KNN模型和基于量价关系的改进模型对股票指数趋势预测的准确率均能达到55%%以上,表明三种模型均是有效的,并且改进模型的预测性能明显优于DTW-KNN模型和支持向量机模型。本文基于DTW-KNN模型和改进模型在股票趋势预测的基础上结合我国股票市场的实际情况构建了量化选股策略。策略回测结果表明,基于DTW-KNN模型和基于量价关系的改进模型构建的选股策略在中国上证50指数成分股上表现均优于上证50指数的表现。策略的年化收益率分别达到16.8%和19.7%%,均能够获得超额收益。"
1385,微服务平台中服务划分和选择策略研究和应用,"随着云平台业务规模的扩展,传统的单体服务框架的复杂性越来越高,可维护性越来越差,因此微服务架构成为研究的热点。当前的云平台中服务复用率低,代码冗余率高成为平台的主要问题,另一方面,目前的服务选择策略未能综合考虑平台性能特征以及任务特征,导致服务的执行效率降低。为了提高平台中服务的复用率以及平台的执行效率,首先本文提出一种基于领域驱动设计思想的语义耦合的服务划分策略,该策略综合考虑了微服务平台中应用功能关联性大的特点以及微服务的划分原则,实现了高效的服务划分;其次本文提出一种细粒度的性能预测模型,该模型可以准确的预测每一个微服务的执行时间;然后,在性能预测模型的基础上,提出一种性能感知的服务路径选择策略,该策略通过初始化服务选择路径和动态的自适应更新得到最优的服务路径,提高了应用的执行效率;最后,通过实验验证了本文所提出的服务划分和服务选择方法,实验结果表明,本文设计的性能预测模型能够准确的预测服务执行时间,提出的方法能够有效提高平台服务的复用率,降低服务的执行时间,提高应用的执行效率。"
1386,基于DNA序列特征的必需基因判定研究,"近年来,伴随生物信息技术的迅猛发展,可用生物数据量正呈指数增长。从各公共生物数据库中可以获得大量、准确的生物数据信息,而如何准确、高效地对这些数据进行分析与挖掘,发掘其中蕴含的内在信息也成为研究热点。作为活体细胞所需的最小基因组,“必需基因”在维持生物体进行正常生命活动和繁殖过程中充当重要角色,该类基因的缺失将导致生物体死亡或丧失繁殖能力,后果严重。医学上,必需基因在生物体存活方面发挥着重要基础作用,已成为许多抗生素和抗癌化合物中的潜在靶点,被广泛应用于病原体和癌细胞的消除,在抗生素和疫苗研制中意义重大;合成生物学上,可以有针对性地选择目标细胞的最小基因组,合成活细胞“底盘”;进化生物学上,研究必需基因可以加深对生物进化过程的理解,通过对常见同类必需基因的研究,实现对物种的同源性分析。然而,目前常用的通过生物实验筛选必需基因的方法存在诸如成本高、耗时长、工作量大、适用范围小等缺点,为提高必需基因判定效率,适应生物“大数据”时代的需求,论文从信息科学学角度出发,对基于DNA序列特征的必需基因判定算法进行研究,提出了4种判别基因必需性的有效分类器。首先,对DNA 一级序列进行特征提取,其中包括三类共计10种特征提取方法,即基于核苷酸组成的k-mers与反义互补k-mers算法,基于自相关算法的DAC、DCC、DACC、TAC、TCC、TACC算法和基于伪核苷酸组成的PseDNC与PseKNC算法。然后,使用包括支持向量机(SVM)、决策树(DT)、随机森林(RF)、Adaboost、k-近邻算法(k-NN)、逻辑回归(LR)和朴素贝叶斯(NB)在内的共计7种机器学习算法对所提取的DNA序列特征进行分类,并通过以曲线线下面积(AUC)值为主的共7种分类器性能评价指标,即真正率(TP Rate)、假正率(FP Rate)、查准率(Precision)、F-评价值(F-Measure)、马修斯相关系数(MCC)和ROC曲线线下面积(AUC)对所得结果进行分析评价。通过对取得较优结果的特征提取方法进行集成处理,与效果较好的分类器结合起来,经过参数调节,最终得到4种目标分类器,分别为RF-4-RF、LR-3-LR、KmerDAC-RF与KmerDAC-LR分类器。为了证明论文所提出的分类器的有效性,论文使用了来自PEC通用数据库的大肠杆菌必需基因作为训练数据集,在对其进行的10折交叉验证中,RF-4-RF分类器选择的特征为k-mers、RevcKmer、DAC和PseDNC特征集合,其AUC值达到了0.830;LR-3-LR分类器选择的特征为DCC、DACC和TAC特征集合,其AUC值为0.834;KmerDAC-RF与KmerDAC-LR分类器选择了Ak-mers和DAC特征集合,其AUC值分别为0.827与0.799。与五种通用的参考分类器进行的以AUC值为主的各项综合指标进行比较,结果表明,论文所提出的分类器具有更好的预测性能,其判定必需基因准确、高效且稳定性好。论文提出的4种分类器是判定必需基因的有效分类器,在该领域中具有一定的应用潜力。"
1387,基于特征融合和语义分割的地形识别算法研究,"地形识别技术作为机器视觉领域重要的研究课题,被广泛应用于移动机器人的研究中,是实现移动机器人的自主定位与导航的关键性问题,地形识别可以帮助机器人理解周围环境,实现地形预判,以便于及时调整控制决策与路径规划。足式机器人相较于轮式机器人,虽然速度较慢、能耗较高,但具备极强的地形通过能力,在非结构化环境中适应性更强。相较于采用激光等传感器获取信息进行地形识别的方法,二维图像的获取更为方便,能够提供更为丰富的环境信息,结合机器学习算法,在移动机器人穿越未知、复杂环境时更具优势。主要工作如下:首先,论述了地形识别问题的应用背景与研究意义,总结分析现阶段关于地形识别的国内外研究现状与存在的问题。第二,针对现阶段地形识别方向公开图像数据集较少的问题,本文借助普通单目摄像头采集地形图像,建立了包含六类典型平坦地形图像的地形数据集。第三,研究了基于视觉图像的地形特征提取算法。针对平坦地形类别的分类问题,本文从传统机器学习的角度入手,主要在地形特征的选择上进行创新,基于视觉的低层特征可以有针对性地表示图像某一方面的特性,但也导致特征表达不够全面的问题,而深度特征则通过神经网络自主学习提取特征,特征语义更为丰富,两者存在语义表达上的互补关系,在地形识别研究中有效提高了分类性能。第四,解决了复杂场景中地形的分割及识别问题。实际情况下摄像头捕捉到的地形图像包含多种地形,需要同时完成地形的分割与识别问题,语义分割技术可以实现两者的结合,本文选用了当前流行的DeepLab分割网络,在输入图像中,结合低层特征图,完成复杂地形的分割与识别问题。该方法在改进后的Sift-flow数据集中取得了不错的分割效果。最后,总结本论文的所有工作,指出地形识别中仍未解决的问题并展望下一步的研究方向。"
1388,基于集成的扩展主题模型的情感分析研究,"随着互联网技术的高速发展,和各类应用软件在人们日常生活中的渗透,越来越多的用户习惯在互联网上发表对新闻、事件或产品的观点意见。对这些主观性非结构化文本进行情感分析,提取和分析文本中的情感倾向,对舆情监控、电子商务和信息预测等领域都有着重要作用。因此,对文本进行情感分析在理论和实践中都有重要的意义。本文主要进行了以下两个部分的工作:第一,使用TF-IDF加权的n-gram语言模型特征对LDA主题模型进行扩展。在基于词袋模型的LDA主题模型中,对文本中词序、上下文等语义信息有所忽略。使用TF-IDF加权的n-gram语言模型特征对主题模型进行扩展,在主题模型中增加部分语义信息,从而提高情感分析的效果。第二,在对LDA主题模型进行扩展的基础上,基于扩展模型的文本-主题概率分布划分子样本集,进行集成学习。考虑集成学习在提高模型效果和稳定性中的优势,结合扩展主题模型中各文本具有不同主题的特性,基于主题进行子训练集的采样,为集成学习中的各基分类器提供差异性。采用简单投票法进行决策融合,得到最终的情感分析结果。通过理论推导和实验结果分析表明,使用本文提出的基于集成的扩展主题模型方法进行情感分析,能够有效地提高情感分析的效果和稳定性,且在复杂度方面没有明显的增加。"
1389,基于深度神经网络的信息系统用户异常行为预测研究,"随着企业信息化水平的不断提升,企业核心业务越来越依赖于信息系统的可靠运行。对企业而言,任何信息系统用户所进行的异常操作,都可能会给企业带来不可估量的损失。因此,用户异常行为对企业造成的负面影响是一个无法忽视的问题,用户异常行为检测也成为当前学者的研究热点。在各种用户异常行为检测方法中,数据驱动方法可以适应数据的复杂变化,所以采用数据驱动的方法进行用户异常行为检测。由于存在多种多样的数据驱动方法,因此,如何选择一种高效准确的用户异常行为预测方法,成为了本文的研究问题之一。此外,目前企业中的异常检测软件大多针对系统的软硬件本身而开发,很少有专门检测用户行为的系统,而且用户异常行为的分析处理过程耗时较长,有较多步骤都可实施自动化操作。因此,亟需开发一个用于预测用户异常行为的系统,帮助企业提高数据处理效率,增加数据价值。为了解决这两个问题,本文以某船舶企业为例,采用特征工程的理论和方法,对信息系统日志数据进行了特征处理,并对相关分类模型与算法进行了详细的分析阐述和实验研究,并基于此设计了预测系统,最后提炼出了一个用户异常行为预测流程。本文主要研究和完成的工作如下:(1)日志数据的异常行为分类和特征工程构建。本文明确了异常行为的发生条件,将无监督的日志数据集转化为了有监督的用户异常行为数据集。然后运用特征匹配、构造、编码、缩放和降维的方法,对日志数据进行特征工程处理,得到了适用于深度神经网络模型的数据集和特征维度的重要性排序结果。(2)深度神经网络模型预测。本文首先构建并优化了DNN模型,其次采用特征去尾的方法迭代测试了不同特征维度数量下的模型性能,得到了相对较好的预测结果,然后对比了每个维度下的不同行为模式发生率,并可视化了对比结果,分析发生原因,制定降低用户异常发生率的策略,最后对比分析了深度神经网络模型与多重线性回归、支持向量机的预测结果,阐述了深度神经网络模型的优越性。以业务部门为例,深度神经网络的预测召回率达到77.4%,优于支持向量机的74.86%;预测精度达到84.56%,显著优于支持向量机的63.03%。(3)系统设计与预测流程提炼。结合相关理论方法和实际实验结果,本文基于此设计了一个预测系统,归纳了一个用户异常行为预测流程,并缩短了数据处理分析的时间,提高了预测的效率,让用户异常行为的分析变得更简单。"
1390,大数据技术在YJ银行反舞弊审计中的应用研究,"随着信息技术的不断发展,金融行业的数据储存已基本实现全数字化,为大数据技术的应用提供先天条件,金融行业进入了大数据时代,大数据技术在各家银行的客户精准营销、授信审批、智能投资等方面得到普遍应用。德勤、普华永道等会计师事务所的财务机器人、智能审计等,标志了大数据技术在审计方面的应用不断扩大。近年来各银行内部审计在大数据技术应用方面也不断探索,开发非现场审计系统,加大数据挖掘力度,“让数据说话”,提高审计工作质量和效率。目前,商业银行已成为我国金融体系的重要组成部分,商业银行数量不断增加,业务量不断增大,竞争也越来越激烈。近年来,银行业案件频发,银行市场乱象中员工舞弊案件成了危害金融业健康发展的元凶,是银行市场乱象的污染源,也是银行经营不稳定的祸根,涉及票据、信贷诈骗、柜面存款、违规担保等多个业务领域,特别是银行业务与非法集资、民间融资等外部风险相互交织,往往涉及金额巨大,部分银行员工道德行为引发内外勾结问题日益凸显,员工个人行为导致的风险日益成为银行不可忽视的隐患。金融创新及内部外环境的变化使舞弊手段越来越高明,违法违纪行为越来越隐蔽,对反舞弊审计工作提出了更严峻的考验。在这样的背景下,作者提出通过提高银行内审大数据技术应用水平,充分理解并把握“大数据”的内涵,通过收集海量的内外部数据,采用先进的技术加以挖掘与分析,发现舞弊事实,揭露案件风险,更好的发挥内审“查错防弊”职能。本文介绍了反舞弊审计的相关理论,大数据相关理论,可以应用于反舞弊审计的数据采集工具、数据挖掘技术、可视化技术和分析预测技术。以YJ银行为例,描述该银行反舞弊审计的工作概况,已经使用的大数据技术及已取得的成效,并总结大数据技术在建设银行反舞弊审计中的成功经验,将其与YJ银行的现状进行对比,研究YJ银行目前大数据技术应用于反舞弊审计工作中存在的困难和不足,发现存在审计数据采集不够全面;数据挖掘深度不够;数据可视化技术尚未应用;审计重发现舞弊,轻预防舞弊的问题,分析了问题产生的原因,并针对性地提出了大数据技术在YJ银行反舞弊审计中应用的改进策略,实际解决YJ银行内部审计工作中遇到的问题,如:挖掘并维护系统数据资源;提升数据挖掘力度和深度;加大可视化技术的应用和研究;建立舞弊预警、预测机制,推动YJ银行内部审计更好了提供审计服务,实现价值增值。在案例研究的过程中,作者认识到,由于我国国有企业在公司治理架构等方面存在的先天性缺陷,内部审计部门的独立性不够,组织内部对内部审计工作的重视程度不足,使内部审计工作实施和报告过程受到阻碍;信息系统之间“信息孤岛”现象严重,数据的缺乏和关联性不足;存在经营机构为了业务发展,纵容员工的情况等等。上述这些问题短期内难以根治,这些都导致了内部审计的目标难以实现,影响反舞弊审计工作的效果,内部审计的工作思路和方法还需要在实践中不断探索。此外,大数据技术在内部审计中应用的案例研究较少,因此可以借鉴的文献较少,本文提出的观点仅是作者在工作中的一些思考,还有很多不足之处。"
1391,基于神经网络的智能电视用户分类研究,"当前电视逐渐向网络化、智能化发展,传统的电视只能单纯的从广电服务中心接收信息,现在的电视更多的带有和互联网的交互功能,这样电视从单向的接受变成了双向的交互,如何充分的利用当前电视智能化网络化的特点是当前研究的新方向。现阶段电视用户分类数据严重缺失。而社交媒体分类数据相对容易获得,考虑到两者的弱关联,社交媒体数据可能对电视用户分类提供帮助。本研究课题为解决现有智能电视用户分类研究的不足,并且由于真实的用户分类信息采集困难,数据量过少且难以进行分类等相关问题。搭建神经网络并通过迁移学习方式解决。主要工作包含以下几个方面。1、根据实验室提供的某地区真实用户数据将用户进行分类。但是因为真实的用户分类数据量很少,为解决真实电视用户分类数据量过小的问题,尝试通过挖掘具有弱关联关系的大量“微博电视用户数据”作为训练数据。2、通过社交网络分析,挖掘用户和信息,提取用户特征和观看热点节目的关系。通过微博话题机制找到该话题下的用户,依次进行访问。抓取用户具体信息并存储在数据库中。3、通过神经网络的方法,建立用户观看热点节目和用户特征之间的模型。将微博数据分词后通过词典匹配用户的“相关爱好”,对用户进行相应分类,根据分类结果构建用户的训练数据,搭建多层神经网络进行训练。4、为解决“微博用户群体”和“真实电视用户群体”不完全重合问题,将上文中搭建好的用户模型,通过迁移学习的方法代入参数,用真实的电视用户分类数据进行训练。生成新的经过迁移学习后适用电视用户数据的模型用于预测真实的电视用户分类。5、利用前面通过迁移学习训练出来的模型对该地区智能电视用户进行用户画像,并对比微博数据和真实的电视用户分类数据,分析实验结果。实验结果表明,通过神经网络和迁移学习搭建的模型可以获得更接近真实用户分类分布的信息。"
1392,基于AdaBoost算法的路由泄漏检测技术研究与实现,"随着BGP网络协议的广泛应用,路由泄露作为常见的BGP异常,对网络稳定性造成巨大威胁。如何实现对路由泄露事件的有效检测,对维护网络环境稳定具有重要的意义。机器学习技术可以很好地用于路由泄露异常事件的检测。但是现有的机器学习检测算法在进行BGP异常检测时,缺乏针对路由泄露异常的特征研究,其检测结果只能反映出是否发生BGP异常,而不能进一步确定异常类型是否是路由泄露。这将会为解决异常问题造成不便。本课题基于以上问题,提出一种针对路由泄露异常的检测算法。该算法针对路由泄露异常事件,提出区别于其他类型异常事件的特征,同时引入AdaBoost算法改进现有的单分类器检测算法。该算法在真实数据的基础上进行算法实现,具有针对性强,检测准确率较高的特点。论文主要工作包括三个方面。首先,本课题对路由泄露的定义和BGP协议进行分析,挖掘出三个路由泄露的特征。同时加入一些常见的BGP异常事件的特征,将两者联合得到最终的特征集。其次,本课题在真实数据的基础上实现了相关特征的计算和有效性检测。最后,本课题设计并实现了基于AdaBoost算法的路由泄露检测算法。实验结果表明,与已有的算法相比较,本课题提出的基于AdaBoost算法的路由泄露检测算法能够提升算法的准确率,实现针对性的路由泄露异常检测。"
1393,近岸海域硝酸盐含量与化学需氧量预测分析方法,"目前,水体富营养化是困扰我国近岸海域生态环境最为突出的问题。富营养化是由于水体内的氮、磷等营养元素含量过高,使营养盐的输入输出失去平衡性,从而使水体生态系统的稳定性和功能性遭到破坏。水体富营养化严重影响着海域生态环境和海洋经济的可持续发展,因此,如何有效对近岸海域水体富营养化进行预测和预防已经成为国内外学者研究热点问题。根据水体富营养化评价方法,硝酸盐与化学需氧量是影响水体富营养化的关键指标,此两项因子的变化规律间接反映了富营养化现象的发生规律。因而,可通过对硝酸盐与化学需氧量的变化规律来预测水体富营养化现象。本文基于对威海市海洋与渔业监测减灾中心获取的近岸海域水质监测数据,采用渐进梯度回归树模型和时间序列分析方法对近岸海域硝酸盐和化学需氧量的含量进行建模分析,获取硝酸盐含量和化学需氧量的变化规律。本文的主要工作包括:(1)水质数据预处理。对原始监测数据采用异常值处理与缺失值插补方法进行预处理。其中,异常值处理基于拉以达法则,在满足正态分布的阈值范围内筛选出满足条件的水质监测数据,缺失值插补采用LIN插补算法,根据邻近日期间监测日期监测值间的相关性计算得到插补缺失值。(2)将海域功能区域划分纳入硝酸盐含量和化学需氧量的规律分析。该方法根据地理位置和海域功能等特征对整体水域进行划分,通过对划分后小流域分别建模进行预测分析,有效地提高了分析预测效果。(3)采用时间序列分析方法对化学需氧量进行预测分析。通过对获取的化学需氧量周期信号进行经验模态分解,获取多个子信号,分别对子信号进行自回归平均移动模型建模处理,组合预测结果得到完整预测结果。本文选择威海市2005年至2018年近岸海域的水质监测数据作为实验数据,实验验证了本文提出的机器学习模型在近岸海域内的规律分析的可行性与有效性。"
1394,心率变异性的多时间尺度分析及在心衰诊断中的应用,"随着心血管疾病的发病率逐年攀升和发病人群日益年轻化,我国心血管疾病患者人数已达到2.9亿,已经成为威胁人类健康和生命的“头号杀手”。心衰作为各种心血管疾病的严重和终末阶段,表现出高致病率、高致死率、高医疗支出和发病诱因繁杂的特点,是备受关注的心血管疾病之一。本文借助于数字信号处理技术、计算机技术和机器学习算法对生理信号进行分析,建立心衰的早期诊断模型,希望为心衰疾病的早期健康筛查提供依据,这将及时阻止心衰患者病情的恶化,极大减轻家庭和医疗机构的负担。本文以PhysioNet数据库中长时心电信号的心跳间隔时间序列为基础,首次结合多时间尺度分析和心率变异性(HRV)分析方法计算了九个HRV指标(时域:MEAN、SDNN、RMSSD,频域:LFn、HFn、Ratio-LH,非线性域:VAI、VLI、SampEn)在七个时间尺度(5分钟、10分钟、30分钟、1小时、2小时、5小时、10小时)下的结果,发现了多时间尺度拟合指标并用于心衰诊断模型的研究。主要研究内容和结果如下:1)HRV指标的差异性研究。比较同一时间尺度下的同一 HRV指标在心衰样本和正常样本中的差异,比较同一样本中的同一 HRV指标在不同时间尺度下的变化差异,比较同一 HRV指标在两组样本间的差异随时间尺度变化下的差异。利用t检验分析同一时间尺度下的同一 HRV指标在心衰样本和正常样本之间的统计显著性差异。结果表明:MEAN、RMSSD、LFn、HFn和VAI对时间尺度变化不敏感,而SDNN、Ratio-LH、VLI和SampEn对时间尺度变化表现出不同的敏感特性。对时间尺度不敏感的五个HRV指标在两组样本间的差异性p值对时间尺度也不敏感,而时间尺度分别对两组样本间的SDNN和VLI的差异性表现出放大效应,对SampEn在短时时间尺度上表现出缩放效应,在长时时间尺度上表现出放大效应。2)单时间尺度下的心衰诊断模型研究。以同一时间尺度下的九个HRV指标为特征向量,利用网格搜索算法来确定最优超参数,使用支持向量机机器学习算法来建立心衰诊断模型。同时使用十折交叉验证的方法来评估所建立的模型的分类效果。结果表明:2小时时间尺度下建立的心衰诊断模型性能最佳,其中灵敏度为86.67%、特异性为98.33%、准确率为94.44%,三项评估指标均优于其他时间尺度下的模型性能。这表明2小时时间尺度可能更适合于对心衰患者的诊断分析。3)多时间尺度下的心衰诊断模型研究。依据同一 HRV指标随时间尺度的变化差异情况,利用线性函数、指数函数和对数函数对HRV指标的变化趋势进行拟合,将拟合函数的系数作为新的非标准的HRV指标,同样使用支持向量机的机器学习分类算法来建立心衰诊断模型。结果表明:以多时间尺度下的非标准HRV指标所建立的心衰诊断模型性能均要优于单时间尺度下的最佳模型性能,其中使用三个组合的非标准HRV指标所建立的模型性能达到了 93.33%的灵敏度,98.33%的特异性和96.67%的准确率。该结果优于当前公开的绝大部分结果,这表明多时间尺度分析方法可以为心衰诊断提供更多有益的信息,为进一步将该方法应用到其他生理信号和其他疾病诊断分析上提供借鉴意义。"
1395,我国教育研究中的人工智能话语,"每一次重大的技术革新都会引发人们对教育变革的“想象”和“议论”。新近人工智能领域取得的突破,更是激起了公众依赖“新”技术改造“旧”教育的热情。这种热情也延伸到学术领域,形成了不少回应人工智能的教育研究文献。这些研究重点探讨了人工智能时代的教育革新、人工智能的教育应用以及关于人工智能的教育等议题。尽管也有针对这些研究的批判性反省,但是这些反省多是基于单一样本的分析或基于理论的批判,少有回归这些研究的文本本身,进行基于证据的整体描述和分析。有鉴于此,本研究主要立足当前我国的语境,描述和阐释教育领域人工智能研究的话语及其特征,进而反思它们存在的主要问题和深化的可能路径。本研究将作为研究成果表达形式的论文视为一种话语,同时内含着言说的主体、内容、方式等三个基本维度。与此相应,本研究重点选取了研究主体、研究主题和研究论据作为分析的框架。本研究采用的主要是内容分析法,以中国知网(CNKI)收录的期刊论文为基础,选取了623篇直接探讨人工智能与教育的期刊论文作为分析对象。根据研究目的和上述话语框架,又采取了不同的抽样策略,对这些论文进行了详细的编码和统计的处理。研究发现:(1)在研究主体方面,参与人工智能与教育议题的研究者分布广,但集中关注者和持续关注者少;他们集中分布在信息技术和教育技术领域,同专业、同单位的合作者多,但跨专业、跨单位的合作者较少。(2)在研究主题方面,与人工智能有关的教育主题集中在“教学”和“学习”上,而“个性化学习”、“智能教育”主题与“大数据”、“机器学习”等人工智能相关技术有明显的共现特征;从主题的类属上,多是变革性议题和应用性议题,主要与信息技术和教育技术领域的研究者有关,而少有基础性议题,主要是教育理论研究者新近发起的。(3)在研究论据方面,主要涉及政策、报告、事件、实例、数据等类型;其中“技术”论据最为常见,多被信息技术领域的研究者用于应用性议题的探讨,常与“政策”和“实例”论据组合用于变革性议题的讨论;而教育理论研究者采用“事件”和“实例”论据讨论基础性议题。基于上述发现,可以看到,该领域的研究主要存在以下问题:一是对人工智能改变教育的立场,尚需审慎的理论辩护;二是基于人工智能的教育变革趋势预测,缺少可靠的方法支撑;三是对于人工智能与教育的交互研究,缺乏充分的跨学科合作。针对这些问题,本研究提出,要真正推进人工智能与教育的相关研究,就需要理解人工智能时代的社会特征,反思人工智能的技术现实,挖掘人工智能与教育的双重内涵,促进跨学科的研究与合作。"
1396,基于机器学习的网络违规信息的分类系统,"随着互联网的蓬勃发展,违规信息也开始在网络中日益增加。鉴于机器学习领域的分类算法在垃圾邮件分类、真假评论识别等方面的成功应用,本文研究使用机器学习的方法,对聊天信息这种形式较多较杂,内容较多变的文本数据进行分析,从而对背后的聊天账号进行分类与识别,将结果分为正常账号和涉嫌违规账号两个类别。本文以某游戏公司的聊天软件在某段时间内的聊天记录作为数据,在进行分词、提取关键词、特征选择等数据预处理工作后,分出训练集和验证集,随后运用机器学习的算法对训练集进行学习、拟合,从而在验证集上进行效果的评价。其中,在分词阶段,本文主要使用Python中的jieba库,在删去停用词后得到全部的分词结果;在提取关键词阶段,本文主要使用了TF-IDF算法进行关键词特征提取的工作;在分类阶段,本文分别运用了决策树分类算法和随机森林集成学习算法,并对这两种分类算法的结果进行了比较。本文以真正例查全率、真反例查全率并结合G-means作为性能度量指标,研究发现,随机森林集成学习算法所得到的分类结果要优于决策树算法得到的分类结果,且在随机森林算法下,当关键词数量定为110时,真正例查全率达到了最高的0.857,而真反例查全率也同时达到了最高的0.963,分类效果良好。"
1397,智能空间下面向个性化服务的机器人任务感知与远程监控系统设计,"服务机器人是家庭智能空间中任务的主要执行体,服务机器人的服务质量代表着家庭智能空间的智能化水平。随着人们对个性化服务,特别是健康化服务的重视,现有机器人提供的普适服务已经难以满足不同用户的各类需求,人们希望机器人在提供智能化服务的基础上,可以根据不同的用户、不同的场景提供具有个性化和健康化的服务,真正成为人们智能化生活的好帮手。如何使服务机器人为不同的用户提供个性化与健康化的服务是服务机器人研究领域中亟待解决的问题。本文依托家庭智能空间环境,以智能空间中多源信息为源域数据,融合健康云专家知识库,设计了基于机器学习与专家系统的机器人个性化服务感知与健康修正策略,使服务机器人在利用家庭智能空间历史信息挖掘用户个性化需求的同时,也能够面向用户的身体状况,为用户提供一种集个性化和健康化于一体的服务。在此基础上,开发了cloudstack API和移动客户端APP,实现对智能空间的远程监控。主要的工作如下:(1)面向智能空间下采集数据的缺失问题,研究缺失数据的填充算法。针对缺失的历史数据,设计改进的聚类算法实现对数据的填充,并且通过实验进行比较和验证。针对缺失的实时数据,采用k近邻算法完成对数据的填充,为机器人服务的个性化感知提供前期的数据支持。(2)研究面向个性化服务的服务机器人任务感知问题。利用MySQL数据库管理系统对智能空间下采集的数据进行存储和固化,构建个性化服务推理模型,采用不同的机器学习算法进行服务推理。在此基础上,分析比较各种学习算法对机器人服务感知的效果,选择个性化服务推理方法,根据空间中实时数据完成对机器人个性化服务的感知。(3)研究面向健康化服务的服务机器人任务推理问题。借助健康云平台专家知识库和家用电器国家标准,搭建了健康专家系统。将用户的生理指标纳入到机器人服务的推理中,实现对机器人个性化服务的健康修正,从而满足用户对机器人服务健康化的需求。(4)基于论文的上述研究工作,搭建cloudstack云管理平台并添加机器人服务API,开发手机移动客户端APP,实现智能空间数据与机器人服务远程传输与监控功能,提高监控的可视化效果。"
1398,基于循环神经网络的机械设备健康状态预测方法,"随着工业信息化时代的来临,人们对生产制造效率的要求越来越高,如何避免因设备发生故障导致的停工停产成为亟待解决的难题。目前工厂和企业普遍采用根据经验定期维护生产设备的方式,而这无疑会增加企业在人工和运营方面的支出,造成资源的浪费。机械设备退化趋势建模和剩余使用寿命(Remaining Useful Life,RUL)估计技术是有效解决这一难题的关键。传统基于物理模型的方法随着机械设备内部结构的日趋复杂愈发难以实现,相比之下随着人工智能的飞速发展和数值计算能力的提高,以及传感器和存储技术的推陈出新,基于数据驱动的机械设备退化趋势建模和估计剩余使用寿命越来越得到重视。基于数据驱动的方法通常利用安装在机械设备上传感器实时传输的数据,对机械设备的退化过程建模,从而实现剩余使用寿命的预测。循环神经网络作为数据驱动方法的一种,通过模拟人脑的思考机制来学习到更高维的抽象特征,并能够保留时间序列中的长期记忆,非常适合于多传感器时间序列退化模型的构建,在工业领域有广阔的发展前景。首先介绍了基于数据驱动的方法是如何解决机械设备退化趋势建模以及剩余使用寿命预测问题。随后概述了工业数据集的数据预处理方法。最后详细说明了如何通过直接预测和间接预测的方法来对机械设备退化趋势建模。随后结合卷积神经网络与独立循环神经网络提出卷积独立循环神经网络模型(Convolutional Independently Recurrent Neural Network,CIndRNN),从传感器数据中抽取高维特征并将重构出的多变量时间序列学到设备退化信息,将其用于飞机涡轮发动机剩余使用寿命的预测,相较于其他机器学习有更高的准确性。接着利用长短时记忆网络(Long Short-Term Memory,LSTM)提出一种新的编解码方式对风机叶片结冰过程进行建模,利用重构误差建立起风机叶片的健康指数(Health Index,HI),有助于把握除冰的时机,延长风机的使用寿命。最后对上述两种方法进行总结,构建起比较完整的设备健康状态监测与剩余使用寿命预测的解决方案。同时也指出两种方法仍然存在的不足和进一步研究的方向。"
1399,基于复合算法的人脸超分辨率研究,"伴随着信息技术与互联网的不断发展,物联网已经成为数据时代的大趋势。图像作为在人们日常生活中传递信息最直接的传播媒介,在物物相连的信息化时代,更起到了不可替代的作用。虽然硬件平台已经达到较高水平,但是受环境和噪声等因素影响,在视频监控等公共安全领域的成像效果仍然无法实现对人脸的精确辨识,而超分辨率重建算法可从软件方面弥补硬件层面的缺陷。同时基于深度学习的超分辨率算法在解决图像重建问题上具有潜在优势,因此本文重点开展人脸超分辨率重建研究,主要工作如下:1)针对现有基于学习的超分辨算法复杂度高、训练时间长等问题,本文提出了改进的人脸超分辨卷积神经网络模型(SRCNN),通过改变卷积核尺寸和卷积核的数目、引入池化层,实现对SRCNN模型的卷积层数的加深,特征数量减少,达到缩短训练时间的目的同时保证重建效果。2)针对传统基于学习的图像超分辨率算法对于训练库中没有的特征不能得到恢复的问题,本文通过迭代反投影算法引入原图像的先验信息,提出了基于卷积神经网络与迭代反投影相结合的复合人脸超分辨重建算法(SRCNN-IBP),复合算法分为九个层面其中包括四个卷积层、两个池化层、两个下采样层和一个差分层。模型的前五层主要实现:补丁的提取与表达、非线性映射和重建;两个下采样层分别对原始图像和重建高分辨率图像进行了下采样;差分层对两个下采样层的结果进行做差作为先验指导;上采样层对差分结果进行重建;数据更新层对第五层的重建结果和上采样误差层进行迭代重建,直到差分层的结果小于设定阈值停止迭代输出重建结果。实验结果表明本文提出的算法在训练速度,重建效果方面都取得了良好的效果。"
1400,一种基于机器学习技术的日志记录语句级别推荐方法的研究,"日志记录语句由于具有捕获和记录系统运行时信息的能力,成为了软件系统遇到故障时分析问题原因的主要信息来源。另一方面,互联网领域日新月异的变化,带来了越来越多的用户以及丰富的功能需求,这导致软件系统质量和性能要求都日益提高。日志记录语句由于前述原因,吸引了越来越多实践者和研究者的关注。事实上,恰当地在软件代码中插入日志记录语句已成为开发人员日常工作中十分重要的一部分。一个日志记录语句会利用普通文本和可选的相关变量来记录系统关键的事件信息。在编写日志记录语句时,开发人员需要决策在哪里记录以及需要记录哪些内容。但是,仅仅考虑这两个方面是不足够的,现有的日志框架和工具都要求为每个日志记录语句分配一个用来描述记录信息详细程度的级别,它会影响最终保存下来的日志信息。如果一个日志记录语句被分配了不合适的级别,可能会导致本该记录的信息没有被储存下来,使得后续的日志分析等工作缺失了关键性信息。现有的研究中表明因为需要权衡内容足够的大量日志所带来的益处和所消耗的成本,开发人员在为一条日志记录语句分配级别时往往会花费较大的精力,他们往往只能依赖自己的开发经验和领域知识进行决策。为工业界提供日志记录语句级别分配的有效指导原则,已成为学术界一个紧急而重要的任务,因此本文提出了一种利用机器学习技术为开发人员进行日志级别推荐的方法。已有的相关研究中发现在为一条新添加的日志记录语句决定级别时,日志记录语句所在的包含代码块和文件所提供的信息发挥了最为重要的作用。所以本文把从包含代码块和文件中提取出的文本特征经过处理之后得到的数字文本特征以及数字特征和布尔特征作为算法模型的输入,便可以得到新添加的日志记录语句的合适级别预测。学习模型的训练数据来自具有良好日志实践、数据质量可靠的、涵盖多种产品类型、长时间运行的、GitHub上排名前一百的Java项目。本文不仅选取了三种传统的机器学习算法:决策树,支持向量机、logistic回归模型,还利用深度学习领域的卷积神经网络来构建预测模型。通过对GitHub上排名前100的Java项目中的日志记录语句级别进行特征学习,四种分类器模型的性能评估结果(AUC和BrierScore)都表现出色,在近似研究的数据集上也表现了更为优秀的性能。随机抽样数据的实验结果也证明了本文所提出方法具有较强的稳定性和广泛适用性。"
1401,基于联邦学习的空气质量监测系统设计与实现,"近年来,空气污染已成为影响人们健康的主要问题,而对空气质量的精准细粒度监测是进行空气污染防治的前提。但是,由于监测站点不足及其不完整的记录而造成的感知数据稀疏,正成为空气污染防治的主要挑战。为此,本文设计并实现了一种基于联邦学习的空气质量监测系统。与传统的数据集中训练不同,本文设计与实现的系统采用分布式模型训练方法,无需将训练数据上传至服务器,而是对各区域子端训练区域模型,提出了一种新型的区域联邦学习框架(FRL),从而提高分布式训练的模型质量。基于该框架,论文描述了整个FRL系统的设计过程,并基于Python语言和TensorFlow平台,搭建并实现了整个系统。最后,本文还将系统应用于北京PM2.5监控进行实验评估。实验结果表明,与常规分布式模型训练相比,FRL在RNN和CNN上分别提高了近5%和8%准确率,比起中心化训练模式在RNN和CNN上分别提高了近3倍和5倍的训练效率。"
1402,基于机器学习算法的股票收益率方向预测及分析,"时下建立在数理模型基础上的量化投资技术得到了广泛的应用,并给投资者带来了巨大的回报。当今人工智能和机器学习技术方兴未艾,在影像识别、搜索推荐等众多领域已取得傲人成就;相比时序分析,机器学习模型可以快速处理、分析海量数据,并往往具有较好的泛化能力。在本文中,尝试将相关机器学习算法应用于金融数据挖掘中,基于新近提出的极度梯度提升树XGBoost算法、以及主流的机器学习算法,提出了一套数据挖掘方法,对股票收益率的变化方向进行预测和分析。首先,考虑股市往往是不平稳的、低信噪比的复杂系统,通过小波分解以及阈值去噪对于数据的噪声进行过滤。通过小波的多尺度分析,将股价数据分解成不同频率的子序列,并对高频部分的数据降噪,以进一步提取数据中的有效信息。其次,引入多种机器学习模型,将股票收益率的变化方向转化为模式识别中的分类问题进行研究。极度梯度提升树XGBoost是一种新近提出的高效机器学习算法,本文基于该算法构建了一套量化研究模型,同时构建了包括随机森林、支持向量机SVM等多种前沿机器学习方法在内的模型进行对比研究。以沪深300中300支成分股2012-2017年的日频数据为样本,综合考虑了技术指标、基本面指标和舆情指标,并通过Boruta算法验证了所选指标的有效性。通过对去噪后的数据建模研究,发现XGBoost算法的准确率最高,三年的准确率近54.7%,且运行速度有大幅提升,在依靠概率取胜的量化投资中具有重要意义。进一步,根据模型预测的信号进行了回测交易,各算法构建的策略均可产生超额收益;同时基于XGBoost模型的输出构建了一个新的因子,设计了一种分层回测检验方法,发现各层策略之间具有显著差异,进一步验证了算法具有一定的识别能力。最后,机器学习存在黑箱特征,而已有研究中较少有对模型逻辑的研究和阐述,本文进一步尝试对模型的机理和选股逻辑进行了分析:定义了一种特征权重的度量方法,对XGBoost中各因子的权重进行了度量,研究发现能量潮、市盈率等指标相对重要;通过偏相依关系的计算,对于各指标与收益率的方向关系进行衡量,发现模型中市盈率、市净率整体与收益率变化方向呈现负向关系,ROE、周流入额等呈现正向关系。通过以上分析,一定程度上可以弥补机器学习中一直存在的“黑箱性”困扰,使得模型选股的策略逻辑更为清晰。"
1403,时序数据二分类问题的等距短shapelet转换算法,"时间序列数据在应用中无所不在,是一类非常特殊的高维数据,时序数据分类是时序数据分析中的最重要的任务。研究者对当前领域内的时序数据分类算法进行了全面客观的综合性实验,发现现有的时序数据分类算法中,存在两个比较明显的缺陷。其一是当前领域内的算法并没有关注算法对数据集的适应性,诚然没有算法能在所有数据集上跑出好结果,但是其应该给出其所适用的数据集的范围。其二是拥有最好分类性能的算法时间复杂度相当高,以至于难以投入实际应用。本文的工作内容旨在提出合适的算法改进上述两个当前领域内存在的缺陷。对于算法时间复杂度过高的问题,本文分析了作为领域内最佳算法之一的集成shapelet转换算法,从特征信息的选择,特征信息的评价,特征空间的构建以及特征空间中分类器的选择这四个方面进行优化,提出了基于等距短shapelet转换的时序数据二分类算法。对于该算法中的每一处创新和优化,我们都给出了相应的理论证明用以支撑之。而实验结果也显示我们的算法在保持最佳分类性能的同时,大幅降低了时间开销。对于算法对数据集的适应性问题,我们量化了数据集本身的一些和我们算法密切相关的特性,设计了适应性系数,通过数据集的适应性系数,我们可以有效判断给定数据集是否适合用我们的算法进行处理。相应的实验结果也证明了我们所设计的适应性系数的有效性。本文的主要贡献如下:・提出一个高效的新算法,在时序数据二分类问题上,能以极低的时间代价获得当前领域内己达到的最佳分类性能。・设计出了一个适应性系数,可以有效量化数据集的某种性质,并进一步可以借此判定给定数据集是否适合用我们提出的算法来处理。・对于一些时序数据分类算法中存在的普适性的优化策略,对其可行性给出了理论的证明。"
1404,基于机器学习的JavaScript恶意代码检测方案研究,"随着互联网的高速发展与浏览器性能的不断提升,各类新型Web应用与网站数量呈现明显的上升趋势。近年来,使用JavaScript编写的恶意代码层出不穷,高速发展的前端技术更带来了新的恶意代码攻击手段。如何准确识别各类JavaScript恶意代码对保证用户安全显得尤为重要。本文对基于机器学习的JavaScript恶意脚本检测方案进行了改进,通过实验验证了改进的JavaScript恶意脚本检测方案对JavaScript脚本及包含恶意脚本的HTML页面均可以进行高效准确的检测。具体成果有:1.提出了基于JavaScript代码特征及HTML与JavaScript交叉特征的恶意代码检测方案。该方案通过对AST抽象语法树及DOM树的分析,从JavaScript代码自身及与其交互的HTML两方面分别进行了特征提取,对传统的基于多特征的JavaScript代码检测方案进行了改进。经验证该检测方案具有更高的准确率和执行效率,可以对恶意代码进行有效的检测。2.提出了针对基于URL分割技术的JavaScript恶意代码的检测方案。该方案通过对let、const、复杂对象变量的检测扩展了变量声明的提取范围,基于二叉树结构改进了字典对象,并通过对模板字符串、join等复杂函数的检测扩展了变量拼接的检测范围。根据对比实验验证,改进后的方案对此类恶意代码具有更好的检测效果。3.对基于HTML5的新型JavaScript恶意代码提出了相应的恶意代码检测方案。该方案对使用localStorage等进行混淆的恶意代码进行了混淆特征提取,对使用ServiceWorker等执行恶意行为的代码进行了恶意特征提取。实验结果显示该检测方案能够对HTML5新型恶意代码进行有效检测。"
1405,基于深度学习的金融市场耦合关系建模,"现代学者很早以来就研究金融市场的预测方法,提出了各种时间序列模型,和各种统计模型,但是这些模型的预测效果往往不尽如人意。而金融危机的诞生和不同金融市场之间的相互影响让学界开始意识到对金融市场的预测十分困难和理解金融市场之间耦合关系的重要性。学界意识到金融市场是一个复杂的、变化的、非线性动态系统,不同国家之间的同质金融市场和非同质金融市场之间存在着复杂的耦合关系,但是这种耦合关系不仅不能直接从金融市场数据观测,而且非常难以通过模型反映。而近年来提出的深度学习模型,可以很好地拟合各种复杂的非线性函数,并且可以通过对简单特征的学习与提取得到高维度的复杂特征向量。基于深度学习,本文描述了三种不同类型的金融市场耦合关系:同质关系(不同国家之间同种金融市场之间的耦合关系)、非同质关系(不同金融市场之间的耦合关系)、自回归关系(过去时间节点的金融市场与当前时间节点的金融市场之间的耦合关系),并通过条件受限玻尔兹曼机模型和高斯条件受限玻尔兹曼机模型组成的深度学习网络对其进行建模,并基于训练结果对八个不同国家(美国、英国、德国、法国、日本、意大利、加拿大和中国)的多个不同金融市场(证券市场、外汇市场、货币市场)的价格指数构建数据集,来对价格指数的变化趋势进行预测。与传统的的金融时间序列模型、各种统计学习模型和不依靠耦合关系直接进行预测的深度学习模型相比,我们的模型取得了更有效的结果,预测的精确度更高。"
1406,基于机器学习的虚拟筛选效率对比研究,"药物设计是一个耗时且昂贵的过程,提高药物的筛选效率能够为药物设计提供早期的小分子筛选作用,具有重要科学价值。鉴于药物设计中的巨大搜索空间,随着人工智能技术的发展,机器学习已经成为预测小分子药物与靶向蛋白质之间亲和力的有效方法。然而,各种机器学习算法包括大量的参数和各种各样的模型,使得预测框架的选择非常困难。在这项工作中,本文探究了针对不同机器学习算法的参数优化来进行虚拟筛选,传统的机器学习算法以决策树为例,选择了XGBoost框架和LightGBM框架;深度学习算法则构建了多层感知器和卷积神经网络模型。在参数优化之后,对决策树算法和深度学习算法的RMSE值和R2值进行了比较与评估,对于本次实验所得到的结果是在虚拟筛选方面决策树比神经网络更有效。这是因为在具有约160000个样本的特定药物筛选问题的亲和力预测中,深度学习算法可能比决策树算法更容易过拟合。最后,可以得到先进的机器学习方法可以提取比传统的虚拟筛选方法更准确的蛋白质-小分子结合信息,提高药物设计的筛选效率可达200～1000倍。"
1407,大规模结构化数据特征抽取系统的设计与实现,"近年来,云计算、大数据、物联网、人工智能等领域取得了令人瞩目的进步,推动着传统行业信息化的高速发展,无论是个人、企业还是政府,其数据量和服务量都呈现出爆发式增长,这也带来了更多的机遇和挑战。如今,数据不仅规模庞大,维度更是迅猛增长、涉及的数据类型也日趋复杂,这导致数据内含信息的挖掘难度增加。为有效挖掘出海量数据中蕴含的信息,给搜索、推荐、预测等需求提供服务,首先就要引入当今数据科学中的一个关键课题――特征工程。特征工程是数据挖掘与建模中的关键一环,是指通过数据处理手段,将原始数据整合成可被模型使用的训练数据的过程,可以有效避免维度灾难、加快运行速度并降低程序运行的空间复杂度。特征工程主要包括三个部分:提取、选择和生成。特征提取与特征选择都是为了从原始特征中找出最有效的特征,以便后续的算法训练。特征生成则是通过整理或计算数据,衍生出新的特征。本文构筑了一个可以用来抽取大规模结构化数据的特征工程系统,该系统采用分布式架构实现,是机器学习平台的子系统,可通过Docker镜像和Kubernetes系统进行部署,主要面向公安系统,支持对千亿级别的样本和万亿级别的特征在百台服务器上并行运行。系统分布式地实现了三类特征工程方法,包括:特征提取,特征选择和特征生成。本文中所阐述的系统具有以下功能:1.可应对多种多样的结构化数据格式(tsv/csv/xml等);可处理多种数据类型(数值型、标签型、顺序型、字符型);提供字符离散化、连续值分箱等处理方法;2.通过分布式算法高效处理海量数据和特征,将特征与标签列映射成键值对向量,方便后续算法的计算;提供了用于压缩高维数据的特征降维方法,可辅助提取特征;3.提供可剔除数据集中冗余特征的特征选择方法;4.提供了数学操作和特征编码方法用于特征生成。目前,该系统已经部署在机器学习平台的产品内部,在某地公安局内部提供稳定服务,较好地实现了特征提取、特征选择和特征生成的功能。"
1408,基于机器学习的上市公司财务风险智能识别研究,"金融市场的风险无处不在,上市公司的运营受到方方面面因素的影响,因此对于上市公司财务风险的研究也有着重大的意义。传统的基于财务报表的研究方法例如五因子的Z-score模型等在财务风险预测领域有着重大意义,但仍有其局限性。一方面,传统的统计分析模型大多只采用了较少的财务指标。此外,对于文本信息传统模型大多没有能力进行分析。而随着大数据时代的到来,以上两方面的限制可以部分上得到解决。近年来随着计算机技术的不断发展,Fintech逐渐成为了金融领域的主要研究方向之一。机器学习,人工智能,深度神经网络逐渐被更多人认知和了解,其在图像识别,自动驾驶,自然语言处理等方面都给人们留下了深刻的印象,证明它存在着无限的潜力。深度学习的强大之处就在于它具有复杂的模型结构以及大量的参数,我们能以此对海量的历史数据进行充分的挖掘和学习。而金融领域就是一个充满数据的环境,出现财务风险的公司往往在危机爆发前就可以从其财务状况,运营状况,社会舆论等种种信息中找到线索。因此,如何构建一套基于机器学习的上市公司财务风险识别系统,对于大量的数据进行有效的挖掘和利用,从而实现对于上市公司的高效监管是―个值得深入研究的问题。本文对于上市公司的报表数据以及年报文本数据分别加以利用。对于上市公司的财务报表数据我们利用决策树,随机森林以及XGBoost模型进行挖掘并对比其分类效果。对于上市公司年报文本数据,本文经过清洗以后利用预训练词向量将文本数值化,构建基于深度神经网络的分类模型,并使用改进的损失函数对模型进行优化。最终将两个模型的结果进行综合,得到该公司存在财务风险概率的最终预测值。我们的实证结果显示随机森林以及XGBoost的综合模型均获得了较好的分类效果,而文本信息的加入也能够略微提高模型的分类效能。其中,XGBoost模型达到了最高的综合评分,而随机森林模型虽然综合评分略低于XGBoost,但取得了 82.53%的召回率,即在测试集中所有存在财务风险的公司有82.53%的公司均被模型成功识别。由于在金融市场中漏判一家存在风险的公司所带来的损失远超过将正常的公司误判,因此在这种情境下召回率比准确率更加重要,因此本文认为结果最优的模型是基于随机森林的模型。"
1409,机器学习模型在中国A股市场的应用,"金融市场在现代经济中扮演着重要的作用,一方面对政策制定者来说对金融市场的有效预测能使其更好的对宏观经济进行预判,进而制定相关政策引导经济健康运行,另一方面对金融市场的参与者来说,金融市场的预测对构建投资组合、进行风险管理尤为重要。但金融市场的复杂性导致传统的ARMA等模型预测结果往往不是很理想。而自上世纪九十年代以来,人工智能作为计算机科学的一个分支,其概念被不断提及,学术界、工商业,乃至社会大众无不对人工智能趋之若鹜。随着计算机性能的提高和算法的不断优化,人工智能的理论、方法和技术都得到了普遍的重视和提升。尤其在图像识别、语音识别、自动驾驶、机器翻译等领域,人工智能逐渐从幕后走向前台,并开始大展拳脚,在很多相关行业应用的范围也在不断扩大,这不禁让人联想到人工智能应用在金融市场的美好前景。本文将机器学习模型应用到中国A股市场上,主要使用支持向量机模型、人工神经网络模型、随机森林模型和三者的集成模型对中国A股股票未来三天涨跌的方向进行预测,并根据涨跌的概率选择最大的M只股票构建投资组合,建模包括获取数据、确立特征变量和目标变量、划分训练集和测试集、数据预处理、特征选择、模型参数调优、模型评价等过程。结果显示基于向量机模型、人工神经网络模型、随机森林模型三者的集成模型表现最优,其中M取值5时表现最好,夏普比率最大为1.35,年化复合收益率为44.69%,并且集成模型的表现显著优于沪深300指数和中证500指数。此外策略组合的行业分布也呈一定差异,并不是均衡分布,表明模型能在一定程度上捕捉A股行业轮动的信息,为量化研究、量化选股提供了新的思路。其他参考文献往往使用单一模型,或者在单一模型的基础之上又集成了其他用以特征选择的模型,本文创造性地将相关性很低、内在逻辑数理基础不同的支持向量机模型、人工神经网络模型、随机森林模型集成起来,结果表明集成之后的模型表现优于任何一个单一模型,体现了模型集成的优势。此外,本文也丰富了数据维度,在简单的技术指标之上,又加入了一些日频数据,包括估值数据、换手率数据、波动性数据、动量反转数据等,从而使数据维度更加多元,反映的信息更充分,进而提高模型预测的准确性和依此构建的投资组合的收益率等。这些都更符合金融市场非线性、非平稳的属性,在预测和构建投资策略时能够产生更好的应用效果。"
1410,使用机器学习方法预测不明原发灶的颈淋巴结转移癌的原发部位,"不明原发灶的颈淋巴结转移癌(Metastatic cervical carcinoma from unknown primary,MCCUP)是指在经充分的检查后仍没有任何原发肿瘤的证据的发生在颈淋巴结的转移性疾病,占所有头颈部肿瘤的1-4%。鳞状细胞癌是其主要病理类型,占75%～90%。确定MCCUP的原发部位目前仍是一项挑战,尽管根据头颈部淋巴的区域引流特征,提示MCCUP可能来源头颈部(口咽、喉、舌)或胸部(气管、支气管、肺、食管)。因此,开发一种新的有效的方法来确定MCCUP中的原发部位是非常迫切的。高通量和新一代测序技术的迅速发展使我们对癌症发生发展的分子机制的认识有了更深一步的认识。有高通量研究表明鳞状细胞癌(Squamous cell carcinoma,SCC)具有一定的共同组织学特征和分子标记。这使得鉴定病理类型以鳞状细胞癌为主的MCCUP的原发灶更困难。另一项高通量实验表明食管鳞状细胞癌(Esophageal squamous cell carcinoma,ESCC)与头颈部鳞状细胞癌(Head and neck squamous cell carcinoma,HNSCC)有着很强的相似性,而此两种鳞状细胞癌均为MCCUP的两个重要潜在的原发部位。因此在本研究中,我们通过研究一种新的方法来鉴别这两种鳞状细胞癌来辅助MCCUP的原发灶的诊断。我们从公共数据库下载了食管鳞状细胞癌和头颈部鳞状细胞癌的基因芯片数据集,使用R语言导入这些芯片数据并进行预处理后得到表达谱矩阵,行差异分析得到各个芯片的差异基因,再分别对食管鳞状细胞癌和头颈部鳞状细胞的芯片取交集作为这两种癌症各自的差异基因,然后对这两种鳞状细胞癌的差异基因进行集合运算得到它们的交集和差集(差集代表了这两种鳞状细胞癌的各自特有的差异基因,交集代表了它们的共同差异基因)。我们分别对这两种鳞状细胞癌的共同和各自特有的基因进行了 GO、KEGG通路和蛋白-蛋白相互作用网络(PPI)等分析,最后我们基于HNSCC与ESCC的各自特有差异基因,我们使用随机选择的方法提取特征进行特征选择,分别使用K近邻、随机森林、支持向量机等算法训练模型来预测和判断肿瘤组织类型。我们发现了这两种鳞状细胞癌的共同和各自特有的基因在GO、KEGG通路富集到功能和通路具有很多相同也有一些不同,蛋白-蛋白相互作用网络(PPI)分析亦是如此。基于三种机器学习算法建立的模型,我们使用一个独立的数据集进行验证发现由5个基因组成的支持向量机模型的准确率最高。通过本研究我们探索了食管鳞状细胞癌和头颈部鳞状细胞癌的差异基因不论是在相似度上,还是在所富集的GO功能、KEGG通路和PPI网络上都有诸多相似性同时也存在一些差异。由5个基因组成的支持向量机模型能有效的区分两种鳞状细胞癌,这可能有助于MCCUP患者的精确诊断。"
1411,基于深度语义特征的评论文本情感分析研究,"随着互联网的快速发展,各类网络评论日益激增,对这些评论文本进行情感方面的挖掘分析,能够为个人消费决策、商家营销策略规划、政府舆情检测等方面提供帮助。本文在总结现有情感分析相关研究和技术的基础上,利用深度学习技术挖掘出隐含在上下文信息的深度语义特征,以此来对评论文本进行情感分析研究,主要工作内容如下:(1)针对传统特征提取方法及词向量使用方面的不足,结合双向循环神经网络能更好表达上下文信息和卷积神经网络对于特征提取的优势,提出了一个联合双向循环神经网络和卷积神经网络(Bidirectional Recurrent Convolutional Neural Network,BR-CNN)的评论文本情感分析方法。首先利用PV-DM模型训练出蕴含丰富语义信息的词向量,接着利用BRNN学习得到词语的上下文信息向量,然后构造CNN模型进行深度语义特征提取。在公开数据集上经对比实验表明,BR-CNN模型具有较好的分类性能及良好的泛化能力,准确率达91.6%。(2)结合注意力机制(Attention Model,AM)能突出每个词的贡献程度和双向长短时记忆网络(Bidirectional Long-Short Term Memory,BLSTM)处理长距离依赖信息的优势,在BR-CNN模型的基础上,加入了AM,并将BRNN替换为性能更好的BLSTM模型,构建了一个新的网络模型AC-BLSTM。首先利用Glove模型训练出蕴含丰富语义信息的词向量,接着通过BLSTM对文本进行第一轮的深度特征挖掘,充分保留上下文语义信息,然后利用AM自动从存储的信息中找到最相关的部分,赋予最大的特征权重,最后利用CNN进行二次特征挖掘。在公开数据集上,将AC-BLSTM与BR-CNN进行对比研究,结果表明其准确率提高了2.3%,达93.9%。"
1412,基于机器学习的自闭症儿童行为分析研究,"自闭症是当今社会一个被广泛关注的问题,它目前被定义为一种脑部神经发育障碍所导致的疾病。近年,随着医疗的普及,自闭症的发现率逐年递增,但是从目前医学上的一些结论可以看出,自闭症病因复杂无法确定,且诊断繁琐困难。因此如何有效且快速地诊断身体发育未达到评估要求的儿童是否患有自闭症,是一个有难度也很有价值的问题。虽然儿童是否患有自闭症难以诊断,但是换个角度,如果能从自闭症儿童身上找到某些显著影响或者显著改善其自闭症症状的因素,那么不仅能找到有效改善自闭症儿童症状的治疗方案,还能给自闭症儿童的诊断带来更多的可用信息。本文的目的是使用机器学习去尝试分析自闭症儿童暴躁行为的主要原因和改善方法,即从自闭症儿童数据的所有特征中找出能影响自闭症暴躁行为的特征。然而只有那些基于输入特征值能正确判断暴躁行为输出特征值的模型,其模型的特征影响因子才会是有效的,因而本文在初步特征选择之后,需要进行机器学习,来进一步确定和判断选择特征。在进行机器学习步骤之前,还考察了数据的特殊情况,即医学统计分析上的两个常见问题:数据特征数p远大于样本数N;不平衡数据使学习模型产生归纳偏见和导致噪声影响增大。不平衡数据的问题采用机器学习的集成方法或是不需要数据平衡的模型解决,而特征数p远大于样本数N的问题通过特征选择减小P的值来解决。实验整体步骤:先采用均值替换的方法补全缺省值,保存数据的整体信息,保证数据相关性检验和模型拟合的可靠性。然后根据相关性的结果、随机森林模型和Adaboost模型初步拟合的特征重要性结果,进行特征选择。在实现样本数W大于特征数p后,再进行DEA方法的缺省值替换。接着选择k=5的交叉检验作为实验评估方法,选择错误率、精度和混淆矩阵及ROC曲线作为度量标准,进行随机森林模型、Adaboost模型、FCM模型的拟合。最后根据拟合结果确定最终的特征影响因子,即影响自闭症儿童暴躁行为的特征。本文对于FCM模型所做的主要工作有四点:在FCM模型之前增加了重新选择特征维度和DEA替换缺失值的部分;通过随机森林等模型验证重新选择特征的准确度和确定关联系数矩阵;采用机器学习的集成方法解决不平衡数据的问题;拟合之后根据拟合准确度去选择最终的较大影响的特征。"
1413,基于微服务的绩效归因平台的设计与实现,"历经二十几年的发展,基金已经成为一种大众熟知并逐渐接受的投资工具,较好的满足了社会大众及银行等机构投资者的财富管理需求。随着基金产品数量和种类的增多,在进行投资理财时,如何合理地评价一只基金业绩的好坏,如何评估基金经理真实的投资能力和对基金产品的管理能力,是基金公司和投资者们共同关注的焦点问题。绩效归因可以对这些问题作出科学的解释。国内的绩效归因理论研究起步较晚,研究基金业绩的第三方机构虽陆续出现,但因为数据采集真实性和覆盖性方面的欠缺,也仅是处于研究和试验阶段,且很难为基金公司提供个性化服务。早期公司外购的绩效归因系统也因技术老旧难以支撑业务需求快速频繁的变更。基于上述背景和公司实际发展需求,本文设计和实现了公司内部自用的绩效归因平台。平台根据功能需求划分为业绩管理、归因分析、交易日报、后台管理等核心模块。该平台采用微服务风格的Spring Cloud技术为基础进行开发,围绕业务构建微服务,增加了系统的灵活性,保证了业务创新和技术创新潮流下系统的可扩展性。前端界面主要基于Vue.js框架开发,MVVM模式解决了传统开发模式中业务逻辑代码和视图代码混杂在一起维护困难的问题。本平台将主流系统开发语言Java和强大的统计分析工具R进行了结合,采用ECharts开源库实现海量数据的直观展现,弥补了传统绩效归因平台在数据分析能力和可视化方面的不足。此外,本文研究了通过MLServer(微软机器学习服务器)调用R资源的方式,解决了单线程阻塞问题。目前,本文研究的基于微服务的绩效归因平台已经正式投入使用,并且凭借其高可用性、实用性、易操作性等优秀特性,为平台使用人员在业务工作上提供了良好的支持。"
1414,基于机器学习的光通信信号处理与检测的研究,"受益于机器学习的蓬勃发展,机器学习提供了强大的工具来处理诸如自然语言处理,数据挖掘,语音识别和图像识别等许多领域的问题,其典型特点是有自我学习和演进的能力,只要有新的数据,就可以通过调整结构和参数建立新的映射网络,进一步创造新的能力。信号均衡和光学光谱测量均为光通信中信号处理的重要问题,但是,应用机器学习来解决此方面的研究还较少。在光通信中,由于多径效应和信道所带来的噪声使得传输特性不理想,现存均衡技术需要训练序列所带来处理速度的降低,复杂的光通信系统应用要求均衡器的降低误码更加显著,处理高速率信号更加及时。而频谱图作为一个信号在频域下的常见表达方式,传达出另一个维度的光信息信息,传统的光学频谱分析技术被应用于频谱仪上,虽然实现了在光谱检测上达到更高的分辨率和更宽的波长范围,在功率检测上有更强的灵敏度和更大的动态范围,但这些方案是基于硬件实现的不同技术,无法在软件层面达到复杂度较低的应用。本论文主要针对光通信中的信号质量改善和性能参数监控,分别将机器学习应用于可见光通信均衡和频谱分析等方面进行了研究。将机器学习算法与均衡技术相结合,跟踪信道特性能力增强,做到均衡器的智能化学习与更新,另一部分主要工作为将机器学习引入到频谱分析之中,从频谱中做出对性能参数更准确的定性分析和更精确的定量分析。主要工作如下:第一,为了满足更高速率的需求,创造性的将机器学习中的非监督学习方法应用于波分复用和正交频分复用结合的WDM-DCO-OFDM可见光通信离线系统中,采用模糊C均值聚类方法对接收到的信号进行类别的软划分,得出聚类中心和各信号的隶属度,降低了计算复杂度,达到更好的均衡效果;再应用梯度下降算法对均衡器的权系数向量进行调整更新,得出均衡处理后的信号,达到不需要训练就能自动调节达到收敛的目的。系统在传输距离为14cm,传输速率达到1Gbps,误码率降为10-5数量级,达到不需要训练就能自动调节达到收敛的目的,减小了码间干扰,缩短了处理时间,大幅提高了信号传输的准确性,在非合作接受环境有很好的应用前景。第二,针对目前判决算法缺少智能学习的问题,将机器学习技术引入到光通信频谱分析中,提出了可以利用机器学习方法通过对离散数据进行特征提取来进行频谱的分析,先获取所需分析的频谱图训练数据集,然后选取四种典型的机器学习算法:人工神经网络、支持向量机(SVM)、决策树和K最近邻(KNN)等,将需要训练的数据输入到选取的机器学习算法中进行训练,然后对所需分析新的频谱数据输入到训练好的卷积神经网络模块进行特征提取和性能分析,其中支持向量机(SVM)算法的效果最好,对波长、信噪比和带宽的识别精度最高达到100%,识别时间也最短,分别为0.238s、0.338s和0.443s。第三,针对传统光学性能分析模块中一种算法只能识别一种参数,系统的复杂性高,适应度低的问题提出了一种新的方法,解决了离散数据维度过高或者不确定的而导致的模型结构不具备通用性的问题。提供一种通过自动检测提取特征达到自学习和演进,不断适应新场景、新需求的的卷积神经网络的深度学习的智能频谱图分析方法,当有新的识别目标时,可以根据数据和训练增加新的识别能力,并且由于输入的信息格式为图像,信息的维度确定,模型的结构也固定,兼具功能拓展和通用性于一身。"
1415,基于击键动力学的智能手机身份认证技术研究与实现,"智能手机在日常生活中被广泛使用,手机内存储了用户大量的社交、图片、语音、金融等等隐私信息。在手机失窃后,如果手机密码被破解进而导致隐私信息被获取,将会对用户的人身和财产安全造成威胁。因此,智能手机身份认证系统作为手机入侵检测的重要关卡需要不断被增强。考虑到手机身份认证的安全性和易用性,当今社会主要有三类身份认证方法。基于知识的身份认证如账号密码,容易被猜测或者破解。基于令牌的身份认证如电子密令,容易丢失而且携带成本高。基于生物生理特征的身份认证如指纹人脸,属于静态身份认证容易受到油脂分析或者图片伪造等攻击。因此,本文研究一种基于生物行为特征的动态身份认证方法,该方法既不会给用户带来记忆或携带上的负担,也难以被人仿造。本文在研究身份认证相关知识的基础上,对用户手机生物行为特征身份认证进行了深入的研究和分析。现有技术提取用户的生物行为特征,并对特征和类别的相关性进行计算,选取相关性强的特征进行分类,错误率相对较高。针对这个问题,本文分析了当前技术所采用的生物行为特征,定义了包括时间特征、加速度特征、压力特征、面积特征等在内的146维行为特征集合,并用差分进化算法对特征组合进行优化。结合差分进化特征优化算法和支持向量回归算法,本文得到最优等错误率约为0.12660%,在使用差分进化特征选择方法后,手机电池消耗降低约为31.25%。另外,现有方法大多针对用户某一身体姿态进行特征采集,而忽略真实使用场景中用户往往是多身体姿态使用手机的,造成模型的鲁棒性不强。本文对合法用户站、坐、躺、走等四种身体姿态进行数据采集,针对每个特征提取联合四分距范围,通过该范围构造对抗噪声样本,进而对模型进行鲁棒性测试和加强,最终在严格的实验环境和噪声环境下原方法等错误率增幅约为165.63%,本文方法增幅仅为37.05%。本文设计实现了基于击键动力学的智能手机身份认证系统。该系统包括有信息采集模块、准确率提升模块、鲁棒性测试与增强模块和身份认证测试模块。信息采集模块完成安卓应用开发采集数据;准确率提升模块完成差分进化加支持向量回归的模型构建;鲁棒性测试与增强模块完成对抗噪声样本构造和模型重训练增强;身份认证测试模块完成实际用户登入测试观察系统效果。实验结果表明,该系统能够在多种实用场景中对用户身份进行有效认证。"
1416,自然语言处理技术在项目文档管理中的应用研究,"随着IT技术的发展和大数据时代的到来,以往针对项目文档自动化管理的研究面对项目文档管理工作已经没办法系统的满足项目管理需求,特别是没办法解决文档内容中关键信息的处理问题。本文试图提出基于自然语言处理技术的方式来解决项目文档管理过程当中的当文档关键信息处理问题里,希望能够在理论上结合新的自然语言处理技术找到项目文档管理的新办法,在实践上提升项目文档管理的通用性、时效性、安全性和易用性。本文以项目文档管理为研究背景,以某金融证券公司为研究对象,基于自然处理技术,应用DG公司的自然语言处理技术软件,对项目文档关键信息提取进行研究。试图说明自然语言处理技术能够在项目文档管理当中发挥作用。论文首先介绍了该企业项目文档管理当中的现状和问题,然后介绍了如何将自然语言处理技术应用到项目文档管理当中,最后通过实验验证自然语言处理技术在项目文档管理过程中的实际效果。基于最终实验,发现基于自然语言处理技术处理文档,在准确率、召回率、F1值等重要指标上接近或超过人工。在时效性上可以大大提高。因此证明应用自然语言处理技术在项目文档管理当中,可以一方面保证准确性,另一方面提升项目文档处理的时效性。进而提升项目文档管理的通用性和易用性。与既有研究相比,本文的创新之处在提出使用自然语言处理技术的方式处理项目文档当中的关键信息处理问题。本文的理论贡献在于证明自然语言处理技术可以应用到项目文档处理当中,本文的实践意义在于可以加速企业内部文档管理,增加文档处理效率,减少文档处理成本。本文的研究不足在于研究范围还不足;研究方法仅仅采用了自然语言处理技术栈中的一部分;研究结论不一定适用所有的场景。今后的研究可以从这些方向继续进一步拓展。"
1417,混淆网页木马检测技术的研究与实现,"网络信息获取方式的多样性及普遍性使得脆弱的互联网终端成为不法攻击者通过网页木马静默攻击用户的主要途径。JavaScript语言不仅是构成互联网上活跃和动态Web内容的核心组件,同时也为大量进行偷渡式下载的网页木马提供了攻击和隐蔽自身的基础。由于这些攻击的混淆代码频繁而多变,给恶意代码检测的研究带来了困难,静态的检测方法在实践中被证明具有很大的漏报率,动态的行为检测方法的检测率受到恶意特征库的局限且开销大。本文深入分析与研究了混淆网页木马的技术与特点,然后提出了基于多字节码的恶意JavaScript检测模型,利用抽象语法树获取重构的代码,以此代码为基础提取多字节码特征,并利用高效的机器学习技术进行分类器模型的训练。最后设计与实现了基于多字节码的恶意代码检测系统,并验证了系统的有效性,进行系统展示与功能验证。论文的主要研究内容和成果如下:1.提出基于多字节码的网页木马特征提取方法。获取代码解析后的字节码表示,利用代码经过编译解析产生的语义泛化性,从中提取可以表征恶意JavaScript代码的多字节码特征。2.提出一个基于多字节码的混淆网页木马检测模型。首先将代码解析为抽象语法树,通过遍历树结构对语法树进行组织重构,使用转换后的语法树生成代码行为清晰的同语义代码。以经过重构的代码为分析基础,使用基于多字节码的特征提取技术,利用高效的机器学习技术进行分类器模型的训练。搭建测试环境,设计测试效果检测实验对提出的检测模型进行测试。3.设计与开发了基于多字节码的混淆网页木马检测系统,设计与实现系统各功能模块。该检测系统可利用离线训练得到的模型对网页数据进行网页木马检测。对模型的测试实验结果表明,基于多字节码的特征提取方法可以有效地提取出能够表征恶意代码的多字节码集合。模型结合了代码重构以及多字节码特征提取,能够自动化地获取有效的混淆网页木马特征。对系统进行的检测评估表明,本文提出的检测模型具有较好的泛化能力。"
1418,基于社交网络的用户人格分析研究与实现,"随着互联网的不断发展,各种互联网应用逐渐盛行。社交网络作为一个线上内容发布与交流平台,给人们的社会生活与交往方式带来了新的变化。由于人格与网络空间中的行为高度相关,人格分析的结果可以应用于商品推荐系统、个性化广告等场景中,因此获取网络用户的人格可以进一步促进相关应用的发展。传统的人格测量主要通过调查问卷的方式进行,但是这种方式不适合大规模用户的人格测量。用户在使用社交网络平台的过程中会产生大量的行为数据,通过社交网络用户的行为数据进行人格自动化预测,可以更高效地获取社交网络用户的人格特性。本文以Facebook为社交网络研究平台,分析Facebook用户的网络行为,并提取用户行为特征,建立社交网络用户人格分析模型,对Facebook用户人格进行分析,实验验证了模型的可行性。本文所做工作主要包括如下几点:(1)在用户行为特征选取方面,之前的研究大多仅考虑用户发布文本的统计词汇特征,忽略了用户发布的文本包含的内在意义以及用户心理特征与人格的关系,而相关研究表明,不同人格在语言习惯上会有一定的差异,各人格使用心理词汇的情况也不尽相同。因此,本课题对用户的属性及影响用户行为的因素进行深度分析,分清内外因的区别,针对性地提出文本风格特征和基于TF-IDF的心理词汇特征,构建多维度特征的人格分析模型。(2)在用户行为特征优化方面,引入二进制粒子群优化算法BPSO,并针对BPSO易陷入局部最优的问题进行自适应变异,将优化后的BPSO用于特征优化,选取最优的特征组合,减少了特征提取的工作量,提高了识别效率与准确性。(3)设计并实现了一个用户人格分析系统,该系统包括已知标签的离线数据库、特征提取模块、人格分析模型训练与测试模块、待分析用户数据收集与输入模块和社交网络用户人格分析模块。实验表明,该系统能有效地实现社交网络用户人格分析。"
1419,光纤安防系统中信号识别技术的研究,"随着人们近年来对自身人身和财产安全的重视,光纤振动传感周界报警系统作为安防系统的重要组成部分近年来被广泛应用于大型仓库、油气管道、大型水电设备等这些单纯靠人力和监控设备无法及时顾及的大型防区的安全防护。评价一个周界安防系统性能的主要指标在于能否正确并实时的识别信号类型。当前,基于模式识别的信号分类技术是对光纤振动传感信号进行分类的主流做法。目前的光纤振动传感周界安防系统主要存在以下问题:首先,作为一种专家系统,植入系统的先验知识就显得尤为重要,表现在此系统即为特征值提取的方法。当前多数光纤振动传感周界安防系统的特征提取以频率域和小波域特征提取为主,提取的内容主要包括一些频域的能量特性,未能充分挖掘光纤振动信号内在本质的特征,因此会出现对于某些突发信号识别准确率极低的状况;对所提取特征值的合理性没有进行理论性的判定,经常导致某些特征之间存在冗余。其次,作为分类系统,对于分类算法的选取也显得至关重要。此外,作为一个需要与用户交互并且需要适应不同环境的系统,系统参数应尽量做到在不同的环境条件下能够自动调整,而非每次在环境发生变化时都要进行长时间的人工调参。针对以上提到的三个主要问题,本系统主要工作内容如下:(1)基于光纤传感信号时间域的短时能量、短时过零率特征,设计了双门限法对信号进行初步过滤,滤除时域特征明显的信号。再通过快速傅里叶变换将信号变换至频域,通过频率截止点1对信号进行进一步筛选,滤除频域特征明显的信号。(2)语音信号为长时非平稳、不连续、短时平稳信号,这与光纤振动信号相似。借鉴语音信号处理的方法对信号在时域、频域、小波域进行处理,分析出不同的环境信号和入侵信号在各个域上的差别,进而提取信号各个域上的特征值作为分类算法的输入特征。并根据特征融合理论来分析特征提取的冗余性和合理性。(3)使用支持向量机(SVM)和概率神经网络(PNN)两类分类算法对信号进行分类,对比和分析两者在识别准确率上的优劣。(4)设计了基于Q学习的系统参数自调节策略,以减少对系统的人工手动调节,在使系统在识别准确率进一步提高的同时增强了自动化性能。"
1420,社交机器人检测技术研究及实现,"社交机器人是指一种能够在社交网络上接收指令并模仿正常人类用户行为的智能程序。随着计算机技术的飞速发展,社交网络已逐渐成为人们网络生活中重要的组成部分,拥有庞大的用户群体。因此,近年来在社交网络上出现了大量的社交机器人账号,它们在网络中伪装成正常用户,通过发布博文或与账号建立社交关系来达到影响舆论,广告推销,甚至进行社会工程学攻击的目的。社交机器人账号的出现对社交网络信息的真实性造成了极大的影响,也对社交网络用户的信息安全形成了极大的威胁。因此,对于社交网络中的机器人账号进行检测具有重要的现实意义。论文通过对社交机器人账号行为特点进行深入研究,提出了一种基于博文相似性的社交机器人检测方法,具体包括博文内容相似性、博文长度相似性、博文标点符号使用相似性以及停用词相似性四个部分。此外,针对现有的博文内容相似性检测方法未考虑到文本潜在语义的问题,本文引入了潜在语义分析模型对账号的博文内容相似性特征进行计算。通过一系列实验,证明了本文提出的基于博文相似性特征的检测算法的有效性,该方法在数据集上的准确率达到98.09%,优于Madhuri Dewangan论文中提出的方法。在此方法的基础上,本文对社交机器人账号检测系统进行了设计与实现。社交机器人检测系统主要包括离线数据库、特征提取模块、社交机器人检测模型训练模块、社交账号信息收集模块以及社交机器人检测模块。对模块的主要功能以及流程进行了详细的介绍。最后,通过对社交机器人检测系统进行测试,证明了系统功能的可用性及稳定性。结果显示,本系统能够对社交机器人账号进行有效的检测,可以帮助用户较为准确地识别社交机器人账号,从而为社交网络中的信息安全提供保障。"
1421,基于LSTM的商品期货高频数据趋势预测模型的研究,"量化投资为主动投资管理的一种新模式,其在欧美有五十余年的发展历史,在中国仅有十余年的发展历史。近几年伴随着机器学习与深度学习井喷式的发展,量化投资市场上基于机器学习与深度学习的量化模型的应用越来越多。本文分析了国内外量化投资市场上,机器学习与深度学习模型的相关研究与应用,发现其主要集中在股票市场,期货市场鲜有;因此,在介绍时间序列预测相关技术、剖析期货市场微观结构的基础上,选取2017年4月至7月,商品期货市场螺纹钢品种主力合约高频数据,选取相关特征作为输入,基于LSTM算法建立了趋势预测模型。实验结果与回测效果表明,该模型能够较好地预测螺纹钢品种期货短期内的涨跌趋势,证明了LSTM算法在期货高频数据上的适用性。"
1422,基于机器学习的放疗计划三维剂量分布预测研究,"肿瘤放射治疗是目前癌症治疗的主要手段之一,其关键目的是在确保靶区达到处方剂量的同时,尽可能的降低周围正常组织的剂量沉积。剂量学验证是当前临床放疗技术质量控制与质量审核的主要方式。但放疗计划的质量受限于计划设计人员的经验累积,计划质量的一致性难以保证。同时,临床计划多服从于统一的规范标准,不能为患者提供个体化的治疗计划。而研究表明,通过建模学习患者解剖结构对剂量沉积的影响,可以在计划设计之前预测新患者的剂量信息,为剂量学验证和质量控制提供标准,满足患者的个体化特异性需求,同时为放疗自动化提供基础。本文首先深入分析了现有的剂量学特征预测的方法,分别讨论了现有方法下对危及器官剂量学指征项预测,DVH预测,三维剂量分布预测等不同预测目标的实验思路并分析其优劣性。上述预测方法中,剂量学指征项和DVH为压缩的剂量学特征,包含的信息并不全面,不能满足某些肿瘤类型对三维剂量分布的临床需求,需要对信息包含更全面的三维剂量分布进行预测。因此,本文基于现有的通过神经网络对单个危及器官进行三维剂量预测的方法,结合机器学习中多任务学习方法,提出了一种单模多器官的三维剂量预测方法。该方法考虑危及器官之间的关系,并行构建多器官间几何解剖结构与三维剂量分布的关联模型。相较于对单个危及器官建立预测模型,该方法可以同时对多个危及器官建立预测模型。同时,针对单模多器官模型还需要进行人工特征提取从而可能造成重要信息丢失的缺陷,本文还提出了一种基于深度卷积网络的三维剂量分布预测模型。该模型基于U-net网络和densenet网络搭建而成,可以直接从患者的结构分布轮廓图中学习到几何结构分布与对应三维剂量分布的关系,从而预测整个照射范围内的剂量分布。为验证单模多器官剂量预测方法,实验收集了 15例鼻咽癌的MRT计划,并提取了危及器官体素与靶区,其他相关危及器官以及治疗计划间的相关信息,对脑干,左右腮腺,脊髓建立单模多器官的剂量预测模型。并与团队验证过的基于神经网络的单器官预测模型和进行比对分析。5例测试集的测试结果显示,多任务模型的预测精度更高,误差更小。其中脊髓、脑干、左右腮腺的平均体素相对处方剂量的百分平均误差分别为2.01%±0.0249、2.65%±0.0214、2.45%±0.0217和2.55%±0.0216。实验结果表明,相较于基于神经网络的单模单器官,多任务模型的预测结果精度更高。为了验证深度卷积网络预测方法,实验收集了37例IMRT鼻咽癌数据,搭建深度卷积网络模型,提取感兴趣区域轮廓结构图作为训练输入,训练剂量预测模型。5例测试集的测试结果显示,该模型预测误差小,DVH图和三维分布图的拟合程度高,所有体素点相对处方剂量的百分平均误差为2.36%±0.0214,其中脊髓、脑干、腮腺和靶区的平均误差分别为2.04%±0.0154、2.56%±0.0226、2.07%±0.0188和1.27%±0.10。综上所述,本文首先提出了一种基于多任务学习的单模多器官三维剂量预测模型,并在此基础上针对存在问题提出了基于深度卷积网络的三维剂量预测模型。实验结果证明两种模型预测精度都较高,且各有优劣。"
1423,基于机器学习的服务机器人云端故障诊断方法研究,"随着人工智能技术的发展,服务机器人逐步走进千家万户,为人们的生活提供了诸多便利。服务机器人工作在家庭环境中,其使用者包括老人和小孩,因此服务机器人的安全性至关重要。为提高服务机器人的安全性,本文设计了一种云端故障诊断系统,并对基于机器学习的故障方法进行研究。本文在综述机器人故障诊断技术的基础上,根据服务机器人运动控制系统故障分析,分别对云端故障诊断框架、云端故障诊断服务、故障特征选择、故障诊断模型进行设计与实现。在系统框架设计方面,对服务机器人运动控制系统进行设计以及故障分析,在此基础上设计了“云端-机器人”的系统框架。首先,机器人采集传感器数据,并通过WebSocket上传至云端,在云端对数据进行预处理;然后,基于集成树模型实现特征选择,将选择后的特征数据输入到故障诊断模型得出故障诊断结果;最后,将云端故障诊断结果通过云机交互接口反馈至机器人本体。在平台搭建方面,建立了故障诊断数据集,对云端数据库进行设计与实现;构建了四层故障诊断云服务架构,并采用Tornado框架对故障诊断云服务进行程序设计。在故障特征选择方面,首先,对数据进行标准化以及后向差分预处理;然后,研究了基于随机森林和梯度提升树算法的故障诊断以及故障特征选择;最后,提出了RF-GBDT故障特征选择算法,该算法融合了随机森林以及梯度提升树两者优势。实验表明,本文提出的RF-GBDT算法能够有效实现特征选择,故障诊断准确率有明显提高。在故障分类算法方面,针对传统故障诊断算法只关注当前状态数据的问题,提出了基于时间序列神经网络模型的故障诊断方法。首先,采用滑动窗口进行时间序列样本生成;然后,基于GRU神经网络提出一种改进的故障诊断混合模型,利用GRU神经网络提取时序特征,利用BP神经网络提取当前数据状态特征。多组对比实验结果表明,基于GRU神经网络的改进故障诊断模型具有更高的诊断精度;最后,在实际场景下进行系统测试,结果表明本文设计的云端故障诊断系统能够完成预期的故障诊断功能,可以有效提升机器人的安全性。"
1424,大数据及人工智能技术应用对在线劳动力市场的结构性影响研究,"随着信息技术的迅猛发展,作为“数字经济”代表的大数据和人工智能成为产业变革的核心驱动力和国际竞争新焦点。大数据及人工智能技术的广泛应用对我国劳动力就业市场将产生怎样的影响?这些影响呈现怎样的特征?这些问题开始引起学术界和企业界越来越多的关注。以往研究多聚焦于产业层面来分析新兴技术进步对劳动力市场的影响,较少站在企业视角定量分析。本文试图在既有研究基础上,拓展数据来源,应用新的数据分析方法,基于企业实际人才需求来定量分析新兴技术下在线劳动力市场的结构性变化趋势。本文通过采集在线招聘网站(智联招聘)21738条“大数据”和“人工智能”为关键词的招聘信息,以字段“岗位描述”做为文本数据,利用文本挖掘中的结构化主题模型自动识别归纳出10个主题。首先,分析两类技术在文本主题上表现出的软硬技能的异同;其次,进一步应用贝塔回归检验企业属性(行业、区域、所有制、规模)对不同主题显著性影响程度;最后,将不同类别企业招聘信息作为协变量验证其对主题偏向性影响。本文以企业需求侧为导向建立新兴技术对在线劳动力市场结构性影响框架图。研究发现:1)大数据和人工智能技术表现为典型技能偏好型技术进步,劳动要素投资大于资本要素投资;2)两类技术的“岗位描述”文本主题表现出软硬技能的差异,两类岗位对“硬”技能的要求大于“软”技能,表现出更偏爱“硬”人才;3)企业属性(行业、区域、所有制、规模)对文本主题表现出偏向效应;4)企业对人工智能岗位现阶段的人才需求偏向技术开发岗,而对大数据岗位现阶段的人才需求更为偏向行业应用。本文以企业端需求侧对大数据和人工智能招聘信息进行文本语义主题分析,定量揭示其对在线劳动力市场结构性影响。为企业和高校培养聚集新兴技术人才提供更多依据,共同推进大数据和人工智能等数字技术多行业融合,从而发挥更多价值。"
1425,弹幕与评论对网络视频流行度的影响差异研究,"网络视频行业发展迅猛,促进用户活跃与留存、提升点播量成为网络视频管理者的重要关注点。近年来,随着弹幕相关技术的突飞猛进与日趋成熟,其与评论一起,成为视频网站用户社交的重要形式。弹幕作为伴随时间轴展现的互动内容,与留言板式的评论在情感、感知有用性、互动性等方面各有特点,它们对于网络视频的流行度的影响情况也有所不同。本文从弹幕与评论对网络视频流行度的影响的角度出发研究两者的差异,主要内容与成果如下:第一,梳理弹幕与评论对网络视频流行度影响的国内外文献与研究脉络,同时构建弹幕与评论对网络视频流行度影响作用的研究模型。第二,收集案例视频网站数据,并对弹幕及评论文本进行情感倾向分析,得到文本的情感类别属性,为进一步的实证研究做准备。第三,通过实证研究探索弹幕与评论对网络视频流行度的影响。数据分析结果表明:(1)网络视频弹幕与评论的正向、中性、负向情感、感知有用性均对网络视频的流行度有着正向的影响。(2)弹幕的VIP用户数对弹幕正向、中性情感与点播量之间的关系的正向调节作用。而评论的VIP用户数对弹幕的三类情感与点播量之间的关系均有显著的正向调节作用(3)两者对点播量影响差异主要为:弹幕的中性情感发挥的效应更大,评论的正向情感发挥的效应更大;评论的感知有用性对流行度的影响程度更高;评论VIP用户数对情感对流行度的影响的调节程度较弹幕更大。第四,基于实证研究,总结弹幕与评论对网络视频流行度的影响及差异。针对网络视频及其他网络媒体应用的不同用户群,提出在管理角度、产品角度及营销角度的策略建议。"
1426,基于单细胞转录组测序数据深入挖掘脑胶质瘤细胞间相互作用,"脑胶质瘤是最常见的成人恶性脑癌,其以较差的临床预后与高度的分子异质性而著称。传统的研究是基于多细胞的转录测序技术,其只能获得细胞群体的平均特征,而忽略了肿瘤组织内部细胞之间的异质性。本文系统地研究了6341个来自脑胶质瘤的细胞的单细胞转录组数据,并通过数据降维等方法鉴定出了其中的癌细胞与浸润在免疫微环境的健康细胞。通过单细胞转录组数据和TCGA转录组数据结合分析不同类型细胞的配受体表达情况,鉴定出16对显著相关的癌细胞自分泌配受体信号分子。本文进一步分析发现了癌症干细胞与浸润的免疫细胞间的细胞间相互作用,并鉴定出66个配受体对,其中部分信号分子会显著影响脑胶质瘤患者的预后。之后,我们根据这66个配受体对的表达特征建立基于XGBoost算法的脑胶质瘤预后风险预测模型,可以通过这66个配受体对的表达情况精准预测出脑胶质瘤患者的预后风险。模型在独立验证集中也取得了良好的表现。总之,本文的研究不仅揭示了脑胶质瘤内细胞间重要的功能相互作用,而且为脑胶质瘤患者的预后提供了潜在的标志物。"
1427,视频监控图像的质量评估方法研究,"近年来,随着多媒体技术和计算机网络的不断发展,数字图像作为一种高效的信息载体得到了广泛的应用,视频监控系统也成为了人们日常生活中不可或缺的一部分。从视频监控系统中得到的终端图像在经过采样、压缩、传输等一系列处理流程后会受到不同类型和程度的降质影响,我们将之统称为图像失真。终端图像的质量好坏直接影响到人眼从中获取到视觉信息的准确度,因此对其进行质量评估意义重大。由于无损图像的获取难度较大,因此对视频监控图像的质量评估通常使用无参考方法。随着机器学习模型的发展,基于机器学习的无参考质量评估方法也取得了不错的效果,尤其是深度学习的兴起,使得这类算法的性能得到了极大提升。基于机器学习的质量评估方法有两个不同的优化方向,第一个是质量特征的构建和优化,根据不同的视觉模型寻找出更加贴近人类主观感受的视觉特征;第二个是机器学习模型的优化,即寻找更加合适的机器学习模型对图像质量进行建模。本文中,我们主要研究特征优化的部分,根据监控图像的失真特性,对相关的质量特征进行了分析和改进。由于监控图像容易受到多重失真的混合影响,且图像不同区域的失真类型和失真分布各有特点,本文在分析了多种经典的无参考质量评估方法后,以自然场景统计模型为基础提出了一种针对多重失真图像的评估方法。首先,本文对空域特征存在的问题进行了分析和改进,并引入了一个新的特征参数来提高其准确性。然后,基于图像分块处理的思路,本文引入了词袋模型来重构图像,一定程度上解决了不均匀失真给图像特征和质量带来的混淆。最后,我们通过支持向量机对图像的单词分布和质量分数之间的关系进行建模。考虑到图像底层特征和人类感知之间的语义鸿沟问题,本文在词袋模型的基础上又进一步引入了主题模型来反映图像的质量情况,解决了多重失真给图像空域特征造成的混淆问题。随后,针对视频监控图像的复杂性,本文又引入了视觉注意机制和信息熵来改进图像的特征构建和潜在语义分析过程,最终我们用支持向量机进行训练得到针对监控图像的质量评估模型。"
1428,基于机器学习的业务流程系统的预测,"流程挖掘技术是业务流程领域与数据挖掘技术的结合产物。目前流程挖掘的研究主要关注业务流程的预测方向。而业务流程的预测的主要关注点有:预测业务流程的下一时刻活动,预测业务流程中运行案例的未来路径,预测业务流程运行的剩余周期时间,预测业务流程执行结果以及预测业务流程执行结束后的性能。本文主要提出预测流程结果、预测流程下一时刻活动与时间、预测流程后续时刻事件活动与时间的预测方法并包装成预测模块,最后将预测模块应用到实际场景中,构建出业务流程监控与预测的原型系统。本文针对三个预测任务提出了两个预测模型。一个预测模型是用来预测流程结果的模型,本文提出了利用深度学习中序列处理网络LSTM算法模型去预测流程结果的方法,此方法旨在将流程结果的预测问题与自然语言处理方向相结合,提供一个新的解决思路。另一个预测模型则是用来预测事件活动与时间相关任务的模型,此预测模型将本文研究的预测流程下一时刻活动与时间、预测流程后续时刻事件活动与时间(即剩余周期时间)两个预测任务利用一个预测模型实现。本文提出了利用自然语言处理中的GRU网络结构、双向循环网络结构、Word2vec技术以及Attention机制进行预测的方法,此方法旨在多个自然语言处理中的新技术中找到适合业务流程预测任务的技术。在深入研究三个预测任务的预测方法之后,本文利用实现的预测方法构建出业务流程监控与预测的原型系统。此原型系统主要对正在执行的业务流程得到其运行状态的监控信息,并可以对其进行流程结果、活动与时间的预测,此系统旨在让使用者实时监控业务流程运行状态并通过预测其后续及时优化流程。"
1429,基于Hadoop的金融事件的分析与计算,"事件研究是金融行业的专有名词。事件研究通过检验企业股票价格在事件宣布前后的反应,来衡量事件发生(如企业合并、发布收益公告等)对企业估值的影响。目前事件研究的方法论比较成熟,但是并未走向实际应用。主要是由于以下原因:1.事件分析:目前的事件采集主要是人工采集,然而面对越来越多的上市公司,越来越多的公司公告,人工采集不能及时获得事件。本文基于Hadoop平台和NLP技术,在自动获取事件方面做了一些有意义的尝试。2.事件研究的分布式计算:目前事件研究多是对于一个企业某个事件做事件研究,然后将结果用于其他企业的同类事件的异常收益计算上。本文基于Hadoop平台的分布式计算能力,对于历史上同类事件综合计算其事件研究的结果。将这样的结果应用于未来发生事件的异常收益预计,具有更高的准确性。本文的主要工作内容包括:(1)简化对文本数据的管理。基于ETL工具Morphline实现了公告数据解析、导入到分布式全文索引服务器SolrCloud的整个数据加工过程。最终,索引和文件信息则是存放在分布式文件系统HDFS之上。(2)将传统的事件研究法的模型求解转换为多元线性回归问题,进而通过调用Spark MLlib组件,采用最小二乘法实现模型求解并完成显著性异常检验。(3)结合模式匹配实现基于词汇-语法分析的事件抽取。通过Spark对Solr上文本数据快速查询与并行处理。后续语法分析同时结合语法树与依存句法分析,来完成事件自动抽取部分的内容。(4)为了得到契合金融领域的人工标注语料,进而优化分词模型与实体识别模型,开发了采用前后端分离架构的辅助标注系统。"
1430,基于机器学习的安全异常发现系统的设计与实现,"随着信息技术的不断发展,计算机为人们带来便利的同时,来自外部的网络攻击以及内部的异常事件也层出不穷,给安全异常的发现和检测带来严峻的挑战。传统的异常检测技术基于规则库对异常事件进行拦截。这种硬编码的技术缺乏对不断出现的新型安全异常的适应性,需要通过定期更新规则库的方式对系统进行升级。针对上述问题,本文设计一个基于机器学习的安全异常发现系统。检测进出系统的网络流量数据,利用机器学习模型进行安全异常的发现。由于如目录穿越攻击等多种网络攻击直接体现在URL上。故本系统针对的主要场景是异常访问URL检测。在模型构建上,通过分析历史访问数据构建机器学习模型,采用TF-IDF提取并构建特征,并结合使用深度自编码器和K-means进行特征降维,显著提升了模型检测的精度和时间效率。在系统构建上,将检测系统拆分为多个微服务,微服务之间采用消息队列进行协同,降低了处理过程中的各个关键节点之间的耦合,使系统可以快速方便地扩展到其他异常检测场景。检测过程中产生的新数据可用于模型的迭代升级,使系统具有较好的适应性。此外,系统提供友好的人机交互界面,使用户可以方便地了解系统运行状况,参与异常判别过程。本文首先介绍了 TF-IDF、深度自编码器以及消息队列和微服务等相关技术,通过与现有的网络异常检测方法进行比较,提出了本文的检测系统。结合系统的目标定位进行需求分析,并给出了系统中各个服务的具体实现方案,包括基于消息队列的交互、模式缓存的构建、模式淘汰算法的设计等。接着,本文设计了基于机器学习的异常检测算法,重点阐述了特征提取过程和特征降维处理。最后,通过网络搜集到的真实访问数据对本系统进行测试。测试主要从模型检测效果和系统运行效率两个维度进行,验证了本文提出的检测系统的优势。"
1431,基于深度学习的用户行为过程预测方法研究与实现,"近年来,互联网的普及和快速发展大大改变了人们的生活方式,人们的很多行为都是通过互联网发生的,这些用户行为所产生的数据中蕴含着巨大的价值,同时,身处大数据时代,互联网信息过载问题不仅让服务提供者的运营成本大幅提升,而且让服务使用者常常无法高效的寻找到自己需要的信息,用户需要在网上频繁的进行信息筛选,用户想要获得不错的体验所付出的决策成本越来越高。而充分利用好用户行为数据可以很好的缓解这类问题,通过用户行为过程预测方法可以更加合理的辅助用户决策,提升用户体验。本文研究的用户行为过程预测方法通过预测用户的下一次行为或行为对象列表,为用户的下一次行为决策提供辅助参考。该方法的应用领域众多,如电子商务、娱乐行业、安全行业、在线教育等等,所使用的建模方法也很多,在该问题中,循环神经网络(RNNs)与传统机器学习方法相比有明显的优势。通过调研发现,以前的工作只是单纯的用循环神经网络建模用户的序列行为,并未充分考虑行为序列中的用户偏好与行为意向,另外,之前的工作并未探讨应对数据时效性问题的方法,而本文提出的方法可以解决这一些问题。具体来说,本文探索了一个带有注意力机制的双向门控循环单元(BiGRU)编码器,用以建模用户顺序行为,不仅能较好的解决长期依赖问题,同时能捕捉用户偏好。在预测阶段,本文提出的嵌入向量匹配方法能大大减少网络参数。另外,为了解决数据时效性问题,本文创新性的提出了时间迁移学习方法,不仅显著提高了预测效果而且大大减少了训练耗时。实验方面,本文主要使用了Recall和MRR两类评估指标,在不同领域的两组数据集RecSys2015和LastFM上的实验结果表明,本文提出的方法在用户行为过程预测问题上效果明显,并且相对于其他被广泛使用的方法有明显改进,尤其是运用时间迁移学习方法后,模型的预测效果大幅提升。"
1432,电子商务在线评论情感分类方法研究,"随着电子商务的迅速发展,各个电子商务平台都积累了海量的消费者在线评论数据,这些数据蕴藏着极高的商业价值,分析其内容对商家和消费者都具有重要意义,尤其是自动识别评论内容的褒贬性对其进行情感分类。然而在面对海量评论数据时,仅仅依靠人工处理已无法满足需要,这就使得评论文本内容自动分类技术变得十分重要。本研究将现有的文本分类技术运用到电子商务在线评论文本情感分类问题中,通过实验来对比各种分类方法在解决该问题上的优劣性。研究主要做了以下工作:首先利用网络爬虫技术采集真实的电子商务网站在线评论文本数据和评分数据,对数据做预处理后利用Word2vec工具建立词向量模型,以及建立针对电子商务在线评论文本分类任务的情感词典,并选择合适的特征提取方法进行特征提取,然后分别使用基于词典的分类方法,K近邻、决策树、朴素贝叶斯、支持向量机等基于机器学习的分类方法,以及卷积神经网络、长短期记忆模型等深度学习分类方法,对采集的在线客户评论文本数据进行分类,最后比较各种分类方法的准确率、召回率和F测度指标,从而对比分析各种分类方法的优缺点。实验结果表明,基于情感词典的方法从各指标上都明显不如其他方法,可见虽然该方法实施简单,但是分类效果却不尽人意,其对词典的质量具有非常大的依赖性。其次,基于机器学习的各方法之间分类效果差异比较大,决策树和K近邻方法表现不如朴素贝叶斯,支持向量机表现最好。而基于深度学习的两种方法属于三类方法中分类效果最好的一类,其中卷积神经网络是所有方法中表现最好的。另外,对于基于机器学习和深度学习的方法,词向量维度和特征选择方法对分类效果有很大的影响,本研究针对这两个因素设计不同实验进行对比,发现对于基于机器学习的方法用词向量均值做特征选择最佳,对于基于深度学习的方法用信息增益方法做特征选择最佳。"
1433,基于多个k值的DNA序列不对齐比对方法的研究,"随着下一代基因测序技术的发展,生物学领域产生了大量的数据,对这些生物数据的处理是一个急需解决的问题,同时也是计算机,数学等其他多个领域面临的一个重大挑战,生物信息学在这个背景下产生了。DNA序列之间的比对是生物信息学研究问题之一,并在很多方面有着重要的应用。序列比对旨在发现两条DNA序列之间的相似程度,进而揭示对应物种之间的联系。过去50年里,大量的序列比对方法被提出,目前主要的序列比对方法包括两大类:对齐的方法和不对齐的方法。对齐的方法,往往需要庞大的时间开销,对于两条序列的长度也有一定的要求,无法处理大规模的数据,在当前数据爆炸的环境下已经不适用。不对齐的方法通常是通过从序列中提取长度为k的短序列片段,并统计序列片段的一些统计特征来定义序列相似度。不对齐方法虽然能够快速的得到序列比对结果,但是也面临着两个急需解决的问题:因为这一类方法依赖参数k来提取序列特征,不同的k对于算法的性能影响很大,确定最优的k值往往需要进行大量的实验进行尝试,这给实际应用带来了困难;此外,这一类方法在解决相关问题的准确度上仍然需要进一步提高。本文为解决不对齐比对方法的两个问题,提出综合多个k值的思想。本文使用了两种加权方法用于区分不同k值提取特征的重要性,提高不对齐方法的精度;另外,本文也引入机器学习方法到序列比对领域,处理序列比对相关问题。基于综合多个k值的思想,本文首先对传统的不对齐的D_2类型方法上进行了改进,应用了两种不同的加权方案:最大离差法和遗传算法,对序列特征进行加权处理,提出了两种增强的不对齐比对方法。本文设计并实现了两个序列比对任务,实验结果表明,我们提出的方法在没有额外增加时间复杂度的情况下能高效准确地处理大规模的生物DNA序列,并且相较于以前的不对齐方法,我们的方法所获得实验准确率更高。此外,本文也提出一种用于序列比对的机器学习模型,仍然使用多个k值提取序列特征,对特征进行编码后,采用卷积神经网络对序列比对任务进行处理,相关实验结果表明,相较于以前的不对齐方法,使用卷积神经网络的比对模型准确率更高。"
1434,基于机器学习的电力系统暂态稳定性评估,"电力系统的安全稳定运行是现代社会稳定发展的重要基础和支撑。随着电力系统规模的不断扩大,各种新能源、新型负荷的接入、电力电子器件的广泛应用等都增加了电网运行的不确定性和复杂性,使其面临着严峻的考验。电力系统时常受到扰动,当发生各种短路、断线或开关无故障跳闸等大扰动时,需要研究系统的暂态稳定问题。随着计算机技术和人工智能的快速发展,大数据和机器学习方法越来越多的应用于电力系统领域。机器学习的观点认为系统的暂态稳定性与部分表示系统运行状态的特征量之间存在映射关系,通过建立模型对电网运行的历史数据进行离线训练,分析提取未知的函数关系,然后采集实时在线运行数据并不断更新模型的结构和参数,可以对电力系统的暂态稳定进行判别。本文依据机器学习观点和暂态稳定评估过程,主要研究了以下内容:(1)利用电力系统的仿真软件PSAT进行时域仿真,采集不同运行状态下的故障数据,并构造一组与暂态稳定性强相关且不随系统规模变化的故障特征量,编写系统故障特征量的程序处理得到用于电力系统暂态稳定评估的初始样本集。(2)针对电力系统暂态稳定判别评估方面,机器学习中的支持向量机算法被证明具有较好的性能,因此采用支持向量机算法进行快速判稳。并在此基础上构建了一种基于马氏距离的支持向量机模型,将马氏距离应用到核函数中并求解该模型,然后代入故障特征量的样本集进行训练,并对测试集进行预测,验证了所提模型的适用性。(3)机器学习作为浅层学习模型,其算法改进的效果有限,对数据特征的提取能力也有限,因此采用深度学习模型,对数据特征规律进行更加抽象的学习表示。在构建系统特征量数据的基础上,将堆叠自动编码器和支持向量机算法相结合,对样本集进行学习训练,并测试模型的准确性。考虑到堆叠自动编码器属于最基础的深度学习模型,进一步引入更为深层复杂的卷积神经网络作为电力系统暂态稳定评估的模型,并同时将支持向量机算法引进输出层的判别机制中,通过算例验证了所提的两种模型的有效性,提高了暂态稳定评估的性能。"
1435,基于蛋白口袋残基的打分函数和分子自动优化程序,"小分子的生物活性往往是早期药物发现最重要的指标之一,而大量生物活性实验是需要巨大的经济成本和时间成本的。因此通过计算机进行亲和力预测一直以来都是研究的热点。为了充分考虑配体与不同蛋白氨基酸残基的各种相互作用能的协同作用,这里我们发展了一种新的基于机器学习的打分函数(rbScore)。该打分函数通过分散配体和蛋白口袋的各种相互作用能到20种不同的氨基酸残基的主侧链上,共得到107个描述符,并利用随机森林的方式进行训练,得到预测模型。这里我们利用PDBbind数据集中的2017年refinedset和2013年core-set数据集分别进行训练和测试,测试结果的皮尔森相关系数(Rp)为0.79,标准差(SD)为1.50。此外,分子优化也是药物设计重要的过程之一。生物等排替换是药物化学中进行分子结构优化的常见方法,其在改善选择性、活性、ADMET以及规避化合物的专利范围均有广泛的应用。然而寻找合适的替换结构不是一件简单的事情,利用计算的方法可以为药物化学家寻找合适的生物等排替换结构提供帮助。基于蛋白结构生物等排替换的原理,我们开发了一个基于蛋白口袋局部环境的分子自动优化程序,该程序主要分为两部分内容。一方面,我们对大量的蛋白-配体复合物三维结构数据进行处理分析,生成片段-子口袋环境对,并构建特征指纹后存入数据库,以提供可查询的生物电子等排体。另一方面,我们提供了一个包括分子切割、子口袋指纹生成、指纹查询和相似性比对、片段连接等功能一体的自动化程序。通过程序的运行,可自动的对指定片段进行生物等排替换,得到可供参考的新分子。"
1436,基于数字病理图像的肺鳞癌基因变异和无病生存期预测研究,"近年来,肺癌已经成为了发病率最高、死亡率最高、增长速度最快的癌症。肺鳞癌作为肺癌常见的病理类型之一,具有独特的临床病理学和分子学特征,且与肺癌其它病理类型相比,肺鳞癌患者的生存期更短、死亡率更高。为降低患者死亡率,许多研究提出通过基因检测技术寻找癌症细胞特有的基因变异,并设计特异性药物来进行针对性治疗。然而,基因检测通常需要花费很长时间,可能使患者错失最佳治疗时机。基于数字病理图像预测肺鳞癌基因变异,将有助于患者基因变异信息的快速获取,从而辅助医生制定最佳的治疗方案。除基因变异外,数字病理图像作为临床诊断和治疗中的重要参考依据,还能够提供非常丰富的无病生存期相关信息。此外,现有研究显示多组学数据与肺鳞癌的无病生存期也存在着密切的关系。因此,有效融合数字病理图像和多组学数据进行肺鳞癌无病生存期的预测研究,可以为医生做出临床诊断等提供科学依据,并有助于改善患者的生活质量。本文主要完成以下几个方面的工作:(1)为实现基于数字病理图像的肺鳞癌基因变异预测研究,本文首先采用CellProfiler从每张数据病理图像中提取了细胞、细胞核及病理图像三个层面的特征,然后使用多种常见的机器学习算法分别对肺鳞癌中基因变异进行预测。多种性能指标的评估结果表明,预测算法对肺鳞癌基因变异取得了良好的预测效果。(2)为探索基于数字病理图像和多组学数据的肺鳞癌无病生存期预测研究,本文首先分别采用多种常见的机器学习算法进行预测,实验结果显示数字病理图像和多组学数据的结合能够提升预测性能。为更好地融合不同类型数据,本文提出了一种基于多核学习的肺鳞癌无病生存期预测方法LSCDFS-MKL,该方法首先针对不同类型数据分别构建多个核函数,并从中选择能够有效反映肺鳞癌数据集特性的核函数,随后通过对不同核函数进行加权平均得到最优核函数。实验结果表明,与现有预测方法相比,LSCDFS-MKL取得了更好的预测效果。最后,本文采用了独立验证集来进一步评估LSCDFS-MKL的泛化能力,实验结果显示LSCDFS-MKL取得了较高的预测准确率。"
1437,基于深度学习混合模型的商品垃圾评论识别研究,"随着互联网应用的不断发展,网络购物等线上消费行为已经逐渐成为社会中的一种潮流。线上电商平台每天都会产生海量评论数据,这些商品评论已经成为用户选择商品的主要依据。由于网络的开放性以及用户的言论自由,有些用户会给出一些垃圾评论,这些评论信息往往会影响用户体验,不仅不利于系统的维护与完善,也对信息资源造成了极大的浪费。为了解决上述问题并挖掘商品评论信息中蕴含的价值,本文综合利用数据爬虫、模型构建以及实验对比等手段进行研究,论文的主要工作如下:(1)对京东商城网站进行目标商品信息和评论爬取。本文基于Scrapy框架,根据网页的XPath路径对网页进行分析,通过多线程模型加快爬虫速度,利用改进网络爬虫策略获取更有价值的各类商品评论信息,最终将数据储存到MongoDB中,为后期训练分类模型做准备。(2)针对传统机器学习在处理评论文本分类时存在的不足,深度学习可以有效地解决了人工干预的问题,能够自动的获取数据中的结构特征,大大节约了人力和时间成本。因此,本文利用深度学习中CNN识别局部特征与LSTM利用文本序列的优势,并结合注意力机制,提出了一种基于注意力机制的CLSTM混合模型算法,最大化地提取上下文信息,更好的实现商品垃圾评论文本分类。(3)为了测试本文基于注意力机制的CLSTM混合模型分类器的分类性能,分别与传统的机器学习模型SVM和单一的深度学习模型LSTM进行了对比实验。本文选取了3组不同商品类型的数据集进行模型训练。在对比实验中,训练出来的混合模型结构分类器在3组数据中都比SVM和LSTM训练出来的准确率要高,分别是85.5%,84.8%,85.0%,从而进一步得证混合模型分类性能的优越性。"
1438,基于轨迹数据的船舶停留区域提取方法研究,"随着船舶自动识别系统的普遍应用,逐渐积累了大量的船舶轨迹数据,这些数据对海洋管理与服务具有重要的价值。其中,如何利用船舶轨迹数据挖掘分析得到船舶停留区域的信息是港口管理业务中的一个重要问题。港口中特定船舶停留区域(包括泊位与锚地)的分析与挖掘不仅可以为船舶安全停靠提供必要的基础信息,也可以为船舶港口的导航提供重要的信息来源,同时对港口的规划建设也提供了重要的决策支撑。然而,由于船舶轨迹数据具有数据量大,船舶轨迹数据相对于其他轨迹数据而言存在采集稀疏,轨迹漂移,时空跨度大的问题,同时船舶在港口的锚地和泊位也具有着不同的停留行为。为此,本文结合船舶轨迹数据的特点和港口停留区域的特征下,开展了基于船舶轨迹数据的港口停留区域提取方法研究,本论文的主要工作包括:1、结合船舶轨迹数据特点,定义了船舶轨迹停留段概念,并针对港口停留区域识别出现的船舶轨迹大数据的精度低、稀疏、漂移等问题,在对船舶轨迹数据进行去噪、插值等预处理操作基础上,提出了一种多约束条件下的船舶停留轨迹提取方法,设计了基于MapReduce的船舶停留轨迹提取算法。2、利用船舶轨迹在港口停留区域的抛锚行为和系泊行为特征的不同,提出了基于随机森林的机器学习分类模型,对船舶停留轨迹进行分类,分别得到锚地和泊位这两种不同的轨迹停留数据。3、基于分类得到的锚地和泊位的轨迹停留数据,分别设计了基于轨迹栅格化的锚地多边形提取模型以及基于聚类分析的泊位多边形提取模型,实现了泊位规则多边形数据信息和锚地不规则多边形数据信息的提取。此外,课题还基于真实的船舶轨迹数据集对上述研究内容进行了验证和评价,同时提取的多个港口的泊位和锚地信息也已经应用于相关单位的实际业务中。"
1439,基于边缘计算的电暖设备监控管理技术的研究与实现,"随着科技的发展,万物互联的时代已经离我们越来越近,在智能家居领域方面更是取得了突飞猛进的成就,但伴随着网络边缘设备数量的迅速增加,这些设备会产生海量的数据,以云计算为核心的大数据计算方式,已经不能满足快速增长的数据量的计算需求。因此,基于边缘计算模型的边缘式大数据处理方式逐渐得到重视。为了保证家居设备的平稳运行,需要对设备进行实时监控管理。传统的基于云的智能家居设备监控需要通过网络将传感数据传送到云端,受到网络传输的影响,不能保证家居设备监控的实时性。因此,本文提出了一种基于边缘计算的电暖设备监控管理技术,结合云和边缘节点对电暖设备进行监控,可以减少响应时间,提高数据的传输效率,实现实时监控管理。论文的主要工作包括:第一,本文通过对电暖设备监控管理需求进行分析,阐述了基于边缘计算的电暖设备监控管理系统的总体架构。架构主要分为三个模块:云端监控管理模块,边缘设备监控管理模块,用户移动端模块。边缘端负责接收电暖设备产生的传感数据并根据监控需求进行实时计算,计算结果发送到云端持久化存储;云端负责计算量较大、实时性要求不高的计算任务,并为边缘节点提供所需的外部数据源数据。从而基于边缘云协同监控,保证设备实时的监控管理。边缘端会向移动端实时返回监控信息,用户通过移动端及时了解设备监控情况。第二,本文通过对设备监控技术的分析研究,结合储热式电暖设备的实际应用需求,提出了基于边缘计算的电暖设备监控管理方法,分为电暖异常检测和用暖预测方法。电暖设备的异常检测是对实时的感知数据进行监控,对于出现的异常故障进行判断分析,提醒用户及时排除故障。电暖设备的用暖预测是根据用户在不同天气条件下的用暖喜好,搭建LSTM递归神经网络基准预测模型,对用户下一天用暖所需储热时长进行预测,实现合理的储热供暖规划,满足用户用暖需求的同时,达到减少能源损耗的效果。第三,设计和实现了电暖设备监控管理系统,包括边缘端的监控管理系统,提供了异常检测和用暖预测两部分功能;云端监控平台,提供Web界面可查看电暖设备的运行情况;以及移动端APP,提供对电暖设备的实时监控功能。最后进行实验验证,实验一比较了异常检测算法在两种计算方式下的响应时间,结果表明,以边缘云协同的方式响应时间更快;实验二是用暖预测精度的评估实验,结果表明,本文提出的电暖用暖预测方法可合理规划用户储热时长,相较于传统的BP神经网络,其对用户用暖数据预测更为精确,满足用户日需用暖的同时,可有效避免因储热过多而造成的能源消耗问题;实验三是用暖预测算法在云端和边缘端的训练时间的对比,结果表明,本文提出的在云端进行训练的时间更短,以边缘云协同的计算方式更优。"
1440,机器学习在心电数据分析中的研究和应用,"在全民健身广泛普及的今天,运动安全的话题也开始被人们普遍提及。无论是专业运动员还是普通群众,在运动后都需要对自身的身体状况有一个全面的了解,以确保不会出现运动过量导致的身体损伤。同样,监测身体状况能够为自己制定合适的训练计划,提高运动质量。在人体的各项生理指标中,心电指标是非常重要的一部分,由于心电数据异常容易导致猝死以及其他类型的心脏疾病,因此对心电数据的监测和异常类型分析就显得尤为重要。本文深入研究了心电信号异常类型检测技术及理论知识,并对异常检测过程中的相关步骤进行了优化,利用机器学习与信号分析相融合的方法实现对心电信号异常类型的自动检测。并将该算法集成于一个针对马拉松比赛中运动员身体状况监控及分析的管理系统。本文主要内容和创新点如下:1、本文采用小波分解法对信号进行去噪,由于噪声信号分布在不同的小波分解层中,因此本文采用组合阈值法对不同层小波系数进行去噪,提高去噪效果。2、对心电数据进行波形检测时,差分阈值法鲁棒性较低,容易受到噪声干扰,因此本文采用动态时间窗和动态阈值来改进差分阈值法,用以进行心拍分割,以降低错检率和漏检率。3、由于心电信号的频域特征难以表现其非线性特征,本文提出一种基于局部均值分解和样本熵相结合的方法用于提取心电信号的频域特征,并与时域特征结合组成样本的特征空间。4、本文采用支持向量机算法,基于上述特征空间对处理后的心电信号进行分类,并通过人工蜂群算法对支持向量机的参数进行迭代优化。最终将该算法集成入一套马拉松比赛管理系统中。"
1441,基于深度学习的音乐流派分类方法的研究,"随着互联网的高速发展,数字音乐呈现爆炸式增长。面对海量的音乐,如何快速准确的检索出用户想要的音乐变的越来越重要了。而音乐分类作为音乐信息检索的重要组成部分成为近年来的研究热点。传统的音乐分类方法主要是手动提取特征,然后使用机器学习方法进行分类,这种方法存在两个缺陷,一是手动提取特征很难保证特征的有效性和准确性;二是传统的机器学习分类方法在多分类问题上表现不佳,且无法进行大规模数据的训练。针对以上问题,本文提出了一种基于深度神经网络的音乐流派分类的方法,并研究了不同结构的深度神经网络对音乐流派分类的影响。本文的主要工作如下:(1)根据音乐信号具有时序的特性,提出了一种使用长短时记忆网络LSTM作为分类器的音乐流派分类方法。实验中,首先人工提取梅尔倒谱系数、频谱对比度、频谱质心三种描述音乐内容的特征,然后通过五组对比实验,找出较佳的特征组合。实验结果表明,当梅尔倒谱系数,频谱对比度,频谱质心三种特征进行组合时,长短时记忆网络在音乐流派分类上的准确率高于其他的特征组合。(2)根据卷积神经网络在图像处理上的优势,提出了一种利用声谱图作为输入数据,卷积神经网络作为分类器的音乐流派分类方法。由于声谱图是图像数据,包含了音乐的频率分布和声音幅度的变化,因此非常适合使用卷积神经网络。利用卷积神经网络能够自动学习抽象特征的能力,对音乐的局部特征进行组合,从而形成全局的表达。在实验中,首先使用音乐的声谱图数据训练了本文设计的卷积神经网络和基于VGG16的改进的网络,然后人工提取若干音乐特征作为训练数据,输入到支持向量机、随机森林、决策树、逻辑回归等分类模型中。最后将基于卷积神经网络的方法和传统的机器学习分类方法进行了对比。实验结果表明,在分类准确率上,基于卷积神经网络的方法要优于传统的机器学习分类方法。"
1442,基于机器学习的室内定位算法研究,"近年来,各个领域对室内定位的研究热度日渐高涨。室内定位服务主要应用在如机场,医院,商场等公共区域,通过移动端与服务器的交互获得自己所在的位置信息。因为信号的衰减程度和多径效应作用,一般的室外定位设施(例如GPS)在室内建筑中无法正常工作。近几年来WiFi迅速普及,使用WiFi进行室内定位操作不需要多余的硬件设施,成本低,灵活度高。基于WiFi的指纹室内定位算法是现阶段研究的热点之一,该定位方式主要是通过获取数个无线接入点传来的信号强度组成信号强度向量,收集室内的所有离线信号强度向量组成数据库;线上阶段通过实时收集的信号强度向量与离线数据库中向量的对比计算进行定位。该方法虽然简单有效但也存在着例如计算量大,定位精度不高等问题。本文的主要目的是对基于WiFi的室内定位机器学习算法的研究与改进。本文的结构大概有以下几部分:(1)论文首先对近年来室内定位的发展前景进行了简要的概括,并对国内外的研究现状进行了分析。(2)通过大量的文献调研与资料分析,介绍不同的室内定位方法。然后开始对各种室内定位方法进行分析,对基于各种平台的定位方法进行比较,如蓝牙定位,超宽带定位,WiFi定位等,并了解每种室内定位技术的优缺点。然后深入分析基于WiFi的指纹定位方法,对其中的各种机器学习算法进行比较,并选择主流的位置指纹法进行改进,对位置指纹法的KNN算法,贝叶斯算法等进行分析。(3)选择WiFi指纹定位中最常用的KNN算法,对该算法存在的计算效率低以及定位精度低这两个问题进行具体分析,并提出改进的方法。改进主要分为两类,一种方法是在KNN定位算法前添加聚类算法,并根据传统的聚类算法进行改进优化;另一种方法是在KNN定位算法得到定位坐标后与其它算法结合进一步进行优化。(4)为了证实算法的有效性进行实验仿真,对文中提到的改进算法进行对比分析。最后对全文进行归纳与总结。"
1443,图书虚假评论的识别方法研究,"当今网络迅猛发展,网上购物是人们消费的主要方式,在看不见实物的情况下,物品的评论成为了人们消费的主要依据。那么在图书阅读领域,书籍评论的真实性对于人们的选择以及商家营销策略的调整具有重要的意义。随着文本分析技术的发展,从海量的评论中识别虚假评论已经成为当前研究的热点问题。本文采集了豆瓣网的四万多本书和七百多万条真实评论作为数据集,然后针对两类算法进行虚假评论识别研究。第一类使用基于混合特征的监督算法识别虚假评论,分为基于全监督学习算法和基于半监督学习算法。首先,将豆瓣图书评论数据集进行预处理构建。再使用朴素贝叶斯分类算法进行全监督学习,识别豆瓣图书虚假评论。通过实验结果的对比分析,得出基于一元语法词汇特征混合深度句法特征的识别效果最优的结论。但是由于上述算法没有使用未标注的图书评论信息,所以接下来将在标注数据集的基础上使用未标注的评论文本。通过基于半监督学习的Co-training双视图算法,在评论文本特征的基础上使用评论者特征进行虚假评论的识别。第一个视图通过评论文本的相关特征来识别该评论文本是否是虚假评论,再使用全监督学习算法的最优实验结果进行特征建模;另一个视图使用评论文本者的相关特征识别虚假评论,若评论文本的撰写者是虚假评论撰写者,那这条评论是虚假评论的可能性较大。随后经过实验结果对比分析可知,在一元语法词汇特征混合深度句法特征的基础上使用半监督学习Co-training算法,能得到更好的识别效果。但是人工标注数据十分的耗时耗力,同时标注的数据集一般会有主观缺陷。通过分析上述算法和数据集,可以清楚的发现两种识别算法都使用了大量人工标注的数据集,同时对数据集信息的挖掘力度不够,算法识别效果没有达到预期,本文研究的第二类算法就是为了解决这些问题而提出的:使用豆瓣图书特征和自定义虚假评论词典的算法识别图书虚假评论,算法充分使用了评论文本信息、图书信息特征和权重比例过滤模型识别检测豆瓣图书虚假评论。通过对比分析三种实验结果可知,本文提出的融合豆瓣图书特征和自定义虚假评论词典的混合算法能更加有效的使用未标注的数据集,同时识别图书虚假评论的效果更好,算法可扩展性更强。"
1444,虚拟环境下的人体动作识别与交互技术研究,"三维虚拟环境的研究是计算机领域最热门研究之一,是图形、图像、人体运动捕获等技术的融合,并且虚拟现实技术也依赖虚拟环境,因此在学术、医疗、工业等领域都受到广泛关注。由于目前虚拟环境下的交互方式还不够智能并且智能的交互方式准确性也存在不足,因此本文从人体运动数据采集、人体动作特征提取、人体动作识别、虚拟环境下的交互技术等方面进行了研究。主要工作如下:针对目前人体运动数据仅存储关节点位置信息导致三维模型变形的问题,本文提出使用骨架中每个关节点相对父关节点角度偏移来表达人体运动的方法。为了验证该方法,本文使用OptiTrack运动捕获设备并结合相关数据预处理方法采集了三个人体运动数据库,并且实现了关节点偏移数据的预览。实验表明,此方法保存的人体动作数据可以有效的防止三维虚拟模型变形并且位置数据的误差在0.6毫米左右。在人体关节点偏移数据的基础上,本文提出该数据与关键帧结合的人体动作特征表示方法。在此方法中,本文将人体动作分为静特征态和动态特征,采用每个关节点相对父关节点角度偏移表示静态特征,使用关键帧来表达人体运动的动态特征。关键帧选取时,本文在帧消减算法的基础上进行了改进,加入了重建误差的二阶导数计算,从而可以自动的确定关键帧数量。实验表明此特征提取方法既减少了人体运动数据的数据量又可以全自动的提取人体运动特征。针对使用隐马尔可夫模型(HMM)对一类人体动作建模时隐状态数难以确定和识别准确率不足的问题,本文提出了基于关键帧的HMM动作识别方法。使用HMM进行动作识别时,针对观测状态离散化的大运算量和离散化存在误差的问题,本文使用高维高斯函数进行人体运动数据的拟合,完成了高斯混合的隐马尔可夫模型(GMM-HMM)动作识别方法。实验表明,关键帧数可以表示HMM的隐状态数,高维高斯函数拟合人体运动数据可以提高识别准确率。针对虚拟环境下交互技术单调的问题,本文研究了虚拟环境下的实时动作交互方法。为了在复杂场景中完成动作识别,本文在GMM-HMM的基础上结合了滑动窗口并设定阈值实现了人体动作的分割。在虚拟环境下的实时动作交互模块,本文将其分为离线训练和在线识别两个部分。最后,完成了舞台环境下的京剧动作交互系统。"
1445,基于深度学习的微博情感分析研究,"随着互联网的迅速发展,社交网络服务(SNS)呈现爆炸式增长,越来越多的人开始习惯于通过微博来表达他们的观点和情感。对微博平台上海量的文本进行情感分析与挖掘具有巨大的应用价值,近年来成为一个新的研究热点。传统的文本情感分析方法需要依靠纷繁复杂的特征工程,且难以适应微博文本简洁、多样、不断变化等特点。近年来,深度学习技术在自然语言处理领域取得了越来越广泛的应用,本文利用深度学习技术对现有的微博情感分析模型和方法进行优化改造,设计了两种深度学习模型:首先,考虑到微博句子中的每个单词对句子整体情感表达的重要程度不同,将注意力机制(Attention Mechanism)运用到基于双向门控循环单元(Bi-directional Gated Recurrent Unit,BGRU)的神经网络中,设计了一种 BGRU-Attention神经网络模型。BGRU能够有效捕获文本长相关性特征,注意力机制可以在模型合成高层情感特征时,给予重要单词更高的权重,而且有利于提高深度学习模型的可解释性。实验证明,BGRU-Attention模型在英文微博情感倾向性分析问题上,相较于传统的基于支持向量机的模型和其它深度学习模型有更好的效果。对Attention层进行可视化表明,模型选择了情感倾向性更强的单词给予了更高的权重。另外,本部分还组织了多组对比实验,探究预训练词向量的质量对BGRU-Attention模型效果的影响。然后,针对BGRU神经网络对细粒度情感分类效果有限的问题,结合基于双向门控循环单元的神经网络和卷积神经网络(Convolutional Neural Network,CNN),设计了一种BGRU-CNN神经网络模型。将BGRU和CNN的优点结合起来,利用CNN来强化局部重要特征的捕捉和提取,增强BGRU的健壮性。并采用层次结构分类方法进一步提高了模型在细粒度微博情感分类任务上的效果。在NLPCC2014中文微博情感分析数据集上进行实验,取得了比传统模型和方法更好的分类效果。通过一系列对比实验表明,利用深度学习技术可以有效提高微博情感分析的效果,并且本文设计的两种改进方法进一步提高了微博情感分析效果。"
1446,基于机器学习的金融风控模型和算法研究,"随着互联网技术的发展和应用的广泛普及,利用互联网进行金融理财已经成为一种新型的金融科技领域。然而,互联网金融给金融企业带来方便、快捷、汇报率高的同时,也带来了相当大的风险。主要表现在:信誉管理混乱、不良借贷和恶意欺骗等等。因此,利用网络运营商大数据对用户行为分析,避免上述风险发生是当务之急。本文针对上述需求,研究基于运营商大数据的用户行为分析算法,为金融企业提供金融风险控制机制。包括:运营商数据预处理、数据画像和标签刻画、用户行为预测等。其中,运营商采用联通网络平台作为基础平台,金融App作为数据采集对象;在用户行为预测算法中,实验采用贝叶斯网络作为预测模型,通过增加“风险”标签,构建风险预测概率图模型。对提出的算法进行了实验分析和工具原型实现。采用联通运营商大数据支撑平台,金融App上网日志作为采集对象,用Spark并行大数据处理系统作为分析数据环境。实验表明:不良用户行为预测成功率达到了比较满意的效果,开发的小工具在企业也已经得到应用。"
1447,基于收益评估的P2P网络借贷投资组合模型研究,"P2P网络借贷近年来因其新颖的模式以及迅猛的发展态势,吸引了众多的关注。对于投资者而言,P2P网络借贷中收益的可观性以及投资选择的多样性是吸引其投资的重要因素。由于投资者往往不具备鉴别借款项目的专业知识,也难以构建复杂的投资组合,借款项目的评估与投资策略的构建问题成为了众多研究者研究的重要问题。本文从满足投资者收益需求的角度出发,对借款项目进行收益评估,同时不局限于评估单一借款项目,而是通过构建基于收益评估的投资组合模型,帮助投资者获得更稳定的收益。本文首先从收益评估的角度入手,运用在预测问题方面表现优异的随机森林算法,以借款项目信息作为解释变量,借款项目收益作为被解释变量,构建回归模型,对借款项目的收益进行预测。随后在收益评估的基础上,结合Markowitz的现代投资组合理论,构建均值-方差模型,将投资金额分配问题转化为带约束的非线性优化问题。运用该模型,投资者能够基于自身对收益的需求,在选取收益能力强的借款项目的同时,确定投资资金在项目间的分配方案,从而获得满足其收益需求的较为稳定的投资组合。本文选取Lending Club平台的借款项目数据对模型进行实验验证,数据分析结果显示,相比于平台广泛采用的等级机制以及传统的多元回归方法,随机森林在预测借款项目收益方面效果较好。在投资组合构建方面,与基于等级机制的投资组合相比,基于收益评估的投资组合模型能够满足投资者的收益需求,尤其是中高水平的收益需求,同时使得投资者获得更加稳定的收益。不同于以往研究中着重于对借款项目进行信用风险评估,本文关注到P2P网络借贷中投资者所具有的收益需求,以收益评估为切入点进行借款项目评估研究。同时,本文不仅限于研究单一项目的评估方法,而是尝试研究构建投资组合的方法,为投资者提供更具体的项目选择以及资金分配方案。当前,P2P网络借贷平台正逐步尝试开发帮助投资者投标的工具,而本文构建的基于收益评估的投资组合模型对于平台而言具有一定的参考价值。"
1448,基于深度学习技术的EMS告警信息分析研究,"随着我国智能电网的发展,智能变电站的应用越来越广泛,变电站内二次设备的智能化水平和数量都有了很大提高,智能二次设备对电力系统安全稳定运行起到了重要作用,因此需要对二次设备进行更及时精准的检修与维护。智能变电站二次设备缺陷的发现主要靠能量管理系统(Energy Management System,EMS)中的设备自动产生的告警信号来确定,但告警信号数量巨大,且含有大量干扰与无用信号,对于运维人员发现真正代表有二次设备缺陷的告警信号造成了很大困难,亟需寻找一种智能高效的告警信息筛选分析方法来帮助运维人员准确找出二次设备缺陷告警信号。二次设备产生的海量告警信号为文本信息,近年来自然语言处理(Natural Language Processing,NLP)理论的兴起和深度学习(Deep Learning,DL)理论的发展使得对告警信息进行智能分析处理成为可能。本文在深入研究了 EMS告警信息特点的基础上,结合实际设备运维情况与告警信息历史数据,提出了基于深度学习技术的告警信息分析方法,主要包括人工经验筛选法与深度学习筛选法两个步骤,实现了对海量告警信号的智能准确筛选,并使用实际数据对本方法的可行性进行了验证。主要完成了以下工作:(1)介绍了本文的研究背景与意义,对EMS告警信息分析技术与深度学习自然语言处理技术的研究现状进行了详细介绍,总结了深度学习技术的先进性;(2)提出了高效的人工经验筛选法,介绍了原始告警信号的特点与产生机制,并对人工经验筛选法原理进行了详细介绍。人工经验筛选法包括字段划分、关键字选取和筛选方案,其中筛选方案根据告警信号类型的不同又分为关键字筛选法、日期时间对比法和频率统计法;(3)提出了基于长短期记忆网络(Long Short-Term Memory,LSTM)的深度学习筛选法,并对其原理作了详细介绍。介绍了深度学习筛选法的总体流程,重点介绍了深度学习技术原理,包括人工神经网络、循环神经网络与LSTM模型原理,最后对文本向量化技术进行了简要介绍;(4)使用实际告警信息数据进行实验,对本文提出的基于深度学习技术的EMS告警信息分析方法验证。使用Microsoft SQL Server数据库进行人工经验筛选法的处理,得到部分缺陷告警信号以及关键字筛选法得出的疑似缺陷告警信号。然后将人工经验筛选法处理结果作为深度学习筛选法的输入数据,进行合适的预处理与文本向量化,对LSTM分类器进行训练与验证,使用MATLAB软件反复实验寻找最佳参数,得出了筛选准确率。最后进行了与传统机器学习分类方法的对比与性能评价,证明了本文提出的方法综合分类准确率较高,漏选率、误选率均较低,建立的筛选系统可用于实际应用,实际具有可行性;(5)最后对论文全文进行了总结,并对后续研究进行了展望。"
1449,基于电网运维多源数据的线路保护通道及输电线路故障定位方法,"近年来,数据概念的迅速发展推动了各个行业和各个领域的技术创新。在电力行业,重点建设智能电网的整体发展态势对电网数据的梳理、整合及应用提出更高要求。面对当前电网对于安全稳定运行的需求,本文以输电线路的电能输送和信息通信这两个重要职能作为主要切入点,对于电网多个系统的静态数据以及历史运行数据等多源异构数据进行相关筛选、逐步抽取、统一建模和集中存储。在此基础上,运用与具体功能相匹配的数据算法进行数据挖掘,确定输电线路关于电能输送和信息通信的故障定位方法,实现对电网运行维护工作的关键有效指导。本文的基础工作重点是对于电网多个系统和多源异构数据的相关分析和集中整合。首先对于支撑电网正常运维的多个子系统进行主要功能分析,从中筛选出能够服务于目标应用的静态存储数据以及动态运行数据,并运用现代数据管理技术从电网多源数据库中抽取有效数据,重新搭建一个新的二次数据平台以实现有效数据的安全隔离和集中存储管理。根据具体业务需求,在二次数据平台中抽取相关有效数据,并设计统一数据模型对初始多源异构数据进行建模,在保证数据模型统一的前提下开发适用于电网运行维护需求的高级应用。高压电网保护通道异常告警近年来呈多发态势,直接影响高压电网主保护可靠运行,情况严重时可能造成保护拒动导致系统失稳。同时,随着无人值守及智能站、调控一体化的推进,传统以人工为主的保护通道运行维护模式存在工作效率低、多专业交互检查、异常定位复杂繁琐的问题。研究利用智能技术实现保护通道异常告警的自动辨识、故障定位对于现场的运行维护工作具有重要的指导意义,同时对于保障电网长期处于安全稳定运行状态具备十分明显的实用价值。针对电网中高压输电线路承载继电保护业务的光纤通信系统频发多通道同时告警事件导致故障定位困难的问题,基于电网运维历史数据,采用贝叶斯网络模型处理手段,提出了一种继电保护通信系统故障定位方法。以继电保护信息管理系统(后简称保护信息系统)和通信网管系统告警信息为触发条件,结合调度运行管理系统(OMS,Operation Management System)信息,首先识别故障区域以缩小故障定位范围,然后在故障区域内采用历史运维数据计算得到的先验概率,通过改进的贝叶斯算法进行故障概率计算,推断出故障原因,借助通信资源管控系统信息进行故障定位,同时提供基于通道异常的地线断线故障辅助决策。现代电网发生输电线路故障时,多种装置和系统均会提供关于故障定位结果的数据信息,例如行波测距装置、继电保护装置和故障录波装置等。上述3个信息源能够同时提供故障测距结果虽然能够保证故障处理时依据信息的可靠性,但测距结果的冗余和差异会对现场运行维护人员的工作造成一些困扰。除此之外,各装置和系统提供的故障定位结果均为确定的数值,而对于现场真正具有指导意义的是将最终结果精确定位到杆塔编号上。针对以上问题,以电网运行维护历史数据为样本,采用以神经网络为模型的机器学习方法进行模型训练,将接收到的故障测距结果输入训练成熟的可靠模型中,输出一个最终的故障测距值。根据生产管理系统(PMS,Production Management System)中关于架空输电线路杆塔配置信息,结合实时空间地理位置信息,对杆塔间档距和线路弧垂进行重新修正,对于故障测距数值进行物理层面的三维映射,最终得到具体到杆塔编号的故障定位结果。最后,本文对提出的架空输电线路准确定位方法进行了算例分析工作,以确保方法的可用性和准确度。"
1450,面向多源数据的谱学习算法研究,"在人类认识和改造世界的过程中,往往需要通过多源数据认知事物。与单源数据相比,多源数据蕴含了更加丰富的信息和知识,通过对多源数据的研究分析能够获取对事物更加全面客观的认知。面向多源数据的机器学习算法通过利用多源数据中的隐藏知识,可以有效提高算法的学习能力,然而传统机器学习方法一般面向单源数据建模,多源数据使传统机器学习方法面临新的挑战。本文针对多源数据学习的基本问题,研究面向多源数据的谱学习算法,主要工作包括:为了实现多源数据的融合学习,建立面向多源数据的融合学习模型。该模型通过结合全局谱嵌入融合和局部谱嵌入融合,能够更加全面地表示多源数据的内部结构。针对多源数据融合新模型,本文给出相应的优化求解算法。通过实验验证了算法的有效性,能够提高同构完备多源数据融合聚类的性能。为了降低多源数据融合学习模型的复杂度,提高算法学习效率,提出谱密度表示方法。首先通过谱方法获取各数据源的密度信息,形成多源数据的一致谱密度表示。通过各数据源谱密度表示的线性组合,获取最优谱密度表示。在此基础上,利用密度峰值聚类算法完成多源数据聚类任务。通过在多源数据集上的实验验证了算法具备多源学习的能力和较高效率,并且具备处理噪声数据的能力。为了解决非完备多源数据中存在数据缺失的问题,提出谱修复的方法。首先通过建立不同数据源之间的投影对各数据源进行填补,然后通过算子的谱性质对各数据源进行修复,从而获取各数据源真实完整的邻接矩阵。在获取各数据源真实完整的邻接矩阵基础上,建立多源数据的融合模型。通过在非完备多源数据集上的实验验证了算法能够解决多源数据中存在样本缺失的问题,实现非完备多源数据的融合学习。为了解决异构多源数据中存在关联缺失的问题,提出同时利用样本对应关系和特征对应关系构建各数据源之间的关联关系。传统多源学习中的关联关系主要体现为不同数据源之间样本的对应关系,但是当样本对应关系出现缺失时,传统多源学习方法无法建立学习模型。本文基于流形对齐的方法,联合两种对应关系,实现了异构多源数据的融合学习。通过在异构多源数据集上的实验表明算法与传统多源学习方法相比在出现样本对应关系缺失时性能更加良好和稳定。本文主要创新点包括:1.针对多源数据的融合学习问题,提出多源谱嵌入融合学习算法;2.针对多源数据的数据表示问题,提出多源谱密度表示学习算法和多源谱修复学习算法;3.针对多源数据中关联挖掘问题,提出多源谱关联学习算法;"
1451,基于认知机器学习的人脸表情识别研究,"随着人工智能技术的迅猛发展,机器已具有通过人脸图像,“理解”人类情感的能力。实现这种能力的方法就是基于机器学习的人脸表情识别,目前的主要应用有人机交互、安全安防、医疗健康等。人脸表情识别有7种基本类别,由愤怒(anger)、高兴(happiness)、悲伤(sadness)、惊讶(surprise)、厌恶(disgust)、恐惧(fear)和平静(neutrality)组成,因此人脸表情识别可用机器学习(分类器)来实现。在实际应用中,由于待识别的人脸表情图片可能包含复杂的背景,图片中人类的外貌、年龄、种族存在差异,不同表情类别之间的区分边界可能模糊不清,这些潜在的问题导致了表情识别准确率难以提高,在现实应用中表现出鲁棒性不足等缺陷。现有人脸表情识别方法的性能与人类的识别能力差距比较大,主要原因是模拟人类的认知能力不够。机器学习就是向人类学习,每次将人类的认知规律模型化,机器学习方法就取得了显著的原创性,因此论文的主要工作就是将认知规律用于机器学习,提出一些新的机器学习方法,并用于人脸表情识别。具体工作包括以下几个方面:(1)指出了现有机器学习方法面临的问题,分析了机器学习的惯性思维原理,进而提出了基于认知的机器学习框架,分析了框架中要解决的主要问题,为提出具体的新方法提供思路。(2)提出了一种新的复杂度感知分类算法(CPC),并应用于人脸表情识别中,该算法针对样本特征分布进行有区分度的学习显著提高了人脸表情识别的分类准确率。实验验证了复杂度感知分类算法的有效性和普适性。(3)提出了一种新的样本感知的个性化人脸表情识别方法,其采用贝叶斯学习方法从全局选择最优的分类器,然后用选择的分类器识别每个测试样本的情感类别。基于样本感知方法(SAP)从给定的基本分类器中选择最适合对给定的测试样本进行分类的分类器,这更符合人类的认知规律,具有个性化的分类能力。实验表明,SAP在情感识别方面的有效性明显优于任何基本分类器。(4)机器学习容易形成错觉惯性思维,但目前所有机器学习方法都没有考虑。本文提出一种基于逆向思维的机器学习方法,采用逆向思维克服错觉惯性思维,从而提高了机器学习方法的泛化能力,实验证明所提方法的有效性。所提方法是普适的,对任何机器学习方法都是适用的,特别适用于那些难分的数据集,如非平衡数据集,因为机器学习在那里很容易形成错觉惯性思维。"
1452,基于等离激元的光场调控与全息研究,"微纳光子学是近二十年来光学非常重要的一个研究领域。微纳光子学研究在波长、亚波长尺度下,光的传播衍化以及与物质的相互作用。对于光学器件微型化、集成化的发展至关重要。近年来基于表面等离激元和超构材料的研究,在光学传感与检测、光学成像、光信息传输与处理等都取得了许多成果。具有代表性的如超构透镜已经发展到实际器件产品,并且局部性能表现已可与成熟的商用物镜相比拟。本论文重点从空间光场与表面光场转换的角度,阐述了几种光场调控、成像与检测的方法和结果,具体内容包括:1、将全息方法引入等离激元波束调控,在金属表面成功实现了蜿蜒振荡的等离激元波束。该方法将等离激元波束看做是由一系列自身携带相位的像点组成。物光重现时,通过点阵横排格点数量调控波束振幅,通过点阵纵向位置调控相位,实现了质量很高的等离激元波束。该全息过程的物光和参考光都是表面波,很大程度地减小了成像系统的空间,符合光电子器件集成化、小型化的发展趋势。2、实现了以表面等离激元波做为参考光向空间辐射的复用全息成像。首先,以表面等离激元波传播路径做为复用通道,实现了四重复用全息成像。该复用方法理论上可实现18个不同路径的无串扰复用全息。然后,利用路径和偏振组合,通过调节入射光偏振和检测时的偏振可以实现四个没有任何串扰的成像态的转换。其次,将思路拓展到介质加载波导中不同模式场做为参考光进行复用成像的设计,成功实现了不同导波模式的复用全息。波导模式具有更小的传播损耗,因此更有利于在如增强现实和虚拟现实等成像设备上的应用。3、提出一种将空间轨道角动量波束耦合成等离激元波束,来检测模式的方法。通过对空间光耦合成表面光场的过程进行波矢分析,得到轨道角动量波束会被周期光栅结构耦合成两个分叉的等离激元波的现象。该分叉角度与拓扑荷数有一一对应的关系,因此通过测量分叉程度可以表征轨道角动量光的模式。由于测量过程无需对准,因此极大提高了检测器件的鲁棒性和准确性。另外使用了组合的光栅结构实现了对于轨道角动量波束拓扑荷数大小和正负号的完全测量。4、对超构透镜阵列的三维光场成像和基于机器学习算法实现透过散射介质成像做了初步探究。在实验上测量了消色差超构透镜阵列拍摄效果与商用微透镜阵列拍摄效果的对比,并用超构透镜阵列实现了三个景深位置处的物体拍摄和重聚焦成像的过程。另外利用基于人工神经网络的深度学习算法对通过散射介质成像做了初步尝试。包括深度学习在内的机器学习应用到光学领域,在大数据量的参数优化、复杂系统中的规律探求等方面都能发挥巨大的作用。"
1453,基于我国规范参数的土层液化可能性评价方法研究,"我国工程建设发展迅猛,建设韧性城乡也已成为我国防灾减灾设定的目标。液化问题作为防震减灾工作的重要一环,在我国工程建设和防灾减灾事业中有重要的工程价值。但是,我国现行规范中推荐的液化判别方法形成于40年前,方法拟合样本老旧、缺乏概率意义,已经难以满足当前工程需求。国外方法与我国地震动参数提供方式不接轨,与我国工程习惯不符,无法在国内应用。发展适于我国国情的液化可能性实用评价方法应是研究目标之一。从工程实用角度,完成土层液化可能性评价工作中,所需参数越少越好。仅采用最主要的参数和最简单的方式,在保证工程精度的条件下,完成土层液化可能性评价,应是研究工作追求的重要目标之一,同时成果也有助于提高对土层液化本质和影响因素的认识。随着机器学习技术的迅猛发展,以及液化调查样本的不断积累,使得采用最主要的参数和最简单的方式,实现土层液化可能性评价成为可能,但这方面的研究成果目前尚少。基于以上现状,本文的研究目标是为我国工程建设提供实用性的土层液化评价方法。其实用性主要体现在三点:一是判别指标选取与我国现有地震动参数匹配,并与我国现有工程习惯接轨;二是将现有规范确定性方法发展成概率方法;三是寻找最主要的参数和最简单的方式,完成土层液化可能性评价工作。基于以上研究目的,本文的研究主要有如下几个方面:1.基于现有国际上公开的震后调查数据,构建了液化土层实测剪切波速样本库与标贯样本库。以两个样本库作为数据来源,采用Logistic概率回归方法,分别建立了基于我国规范地震动参数的剪切波速和标贯两种液化概率计算方法。给出了指定概率水平下的临界值计算公式,为我国相关规范修订和工程使用提供了支持。2.基于机器学习,对液化影响参数重要性排序进行研究。在此基础上,分别建立了基于地震动峰值加速度a_(max)、剪切波速V_s和基于a_(max)、标贯N_m的液化可能性双参数分级准则。该准则构成简单,整体判别正确率达80%以上,为液化风险评估提供了十分简单的方法。3.在液化影响参数重要性排序研究的基础上,基于基尼指数,提出了土层液化判别标贯阈值法,即仅以饱和土层实测标贯值就可判别其是否液化的简化方法。在不同设计加速度区间,本文提出相应的标贯阈值,并对标贯阈值的可靠性进行检验。4.整理了同时具备剪切波速与标贯数据的双参数场地样本集,对双参数样本集中的典型场地进行了分析。将本文剪切波速和标贯液化判别方法及NCEER推荐的剪切波速和标贯液化判别方法进行对比,对以上方法的一致性进行了研究。"
1454,低维碳纳米材料力热性能的调控研究,"碳纳米材料以其独特的晶体结构,优异的各项性能以及在微纳机电系统等领域中巨大的应用前景,引起了人们广泛的关注。调控碳纳米材料的各项性能,扩大其应用范围,满足新的应用需求一直是碳纳米材料领域研究的热点。特别地,有效地调控碳纳米材料的力学性能和导热性能对于碳纳米材料在柔性电子器件、能源转换、防护结构和复合材料性能增强等方面的应用有着重要的意义。研究表明可以通过缺陷工程、官能化改性、填充等方式调控碳纳米材料的力学性能和导热性能。本文通过分子动力学方法和机器学习方法进一步对调控碳纳米材料的力热性能进行了研究,发现氧化作用、褶皱程度、富勒烯填充作用和纳米结构设计等因素对碳纳米材料的力热性能有着重要影响,主要内容如下:(1)研究了氧化作用对石墨烯泊松比的影响,揭示了去褶皱效应是导致石墨烯产生负泊松比现象的原因,为调控石墨烯的泊松比提供了新的策略。具体如下:我们计算了具有不同氧化浓度的石墨烯的泊松比,目的在于寻找泊松比与氧化浓度之间的关系。结果表明,石墨烯的泊松比随氧化浓度p∈[0,1.0]的增加而近似线性减小;当氧化浓度p=0.27时,石墨烯的泊松比由正转为负值;当石墨烯完全氧化即p=1.0时,泊松比达到最小值-0.567。氧化作用使石墨烯泊松比减小的原因是氧化作用产生的褶皱在拉伸过程中会被展平而在垂直于拉伸方向发生膨胀,即去褶皱效应。我们还研究了不同氧化浓度下温度对石墨烯泊松比的影响。(2)研究了褶皱程度对褶皱石墨烯稳定性的影响,揭示了临界褶皱程度与自吸附现象密切相关,为获得具有稳定性的褶皱石墨烯提供了理论参考。具体如下:我们模拟了石墨烯在静水压缩作用下和双轴压缩作用下的褶皱过程。结果表明,静水压缩作用下和双轴压缩作用下褶皱石墨烯的临界褶皱程度分别约为0.5和0.55,当褶皱程度高于临界褶皱程度时,去掉外力后,褶皱石墨烯不能回到初始的平面状态,即褶皱石墨烯具有稳定性。临界褶皱程度与自吸附现象密切相关,而自吸附现象会导致吸附能急剧下降。基于平衡弯曲能与吸附能竞争关系的解析模型给出的临界褶皱程度与分子动力学模拟的结果相吻合。(3)研究了富勒烯填充作用对碳纳米管热导率的影响,揭示了富勒烯与碳纳米管之间的相互作用是影响碳纳米管热导率的主要因素,为调控碳纳米管的热导率提供了新的手段。具体如下:我们计算了不同管径的碳纳米管在填充富勒烯后的热导率。结果表明,当n=8和9时,即碳纳米管管径较小时,富勒烯填充作用会显著降低碳纳米管(n,n)的热导率,这是因为碳纳米管和富勒烯之间强烈的相互作用会引起声子-声子散射的增加和声速的下降。与之相反,当n=10和11时,即碳纳米管管径较大时,富勒烯填充作用会轻微增加碳纳米管(n,n)的热导率,这是因为富勒烯与碳纳米管之间的相互作用较弱,填充在碳纳米内部的富勒烯不会引起明显的声子-声子散射的增加或声速的下降,相反,富勒烯提供了 一个额外的传热通道。我们的模拟工作可以帮助解释以往的理论研究结果和实验结果之间的差异。(4)运用机器学习方法反向设计了多孔石墨烯高热阻结构,揭示了卷积神经网络可以基于少量数据快速有效地提取使多孔石墨烯热阻增大的孔洞排布特征,为机器学习方法在纳米结构设计领域的应用及调控多孔石墨烯的热导率提供了新的思路。具体如下:我们测试了不同的卷积神经网络模型在预测多孔石墨烯热导率上的表现,结果表明一个具有三个卷积层和一个全连接层的卷积神经网络可以有效提取多孔石墨烯的特征,并对其热导率作出较为准确的预测(与分子动力学结果相比)。运用卷积神经网络模型搜索算法在小规模样本空间的体系上的反向设计结果表明:卷积神经网络基于少量数据即可找到多孔石墨烯热阻最大的结构。卷积神经网络模型在大规模样本空间的体系上的反向设计结果表明孔洞呈列状垂直于热流方向分散布置是增大石墨烯热阻的主要特征。我们关于氧化作用、褶皱程度、富勒烯填充作用和纳米结构设计等因素对碳纳米材料力热性能影响的研究结果,不仅为调控碳纳米材料的力热性能提供了新的策略,而且成功将卷积神经网络方法应用在多孔石墨烯的结构设计中,为孔洞纳米结构的研究提供了一个新的手段和思路。"
1455,基于深度学习的电力系统暂态稳定评估及风电功率预测方法研究,"电力系统暂态稳定评估和风电功率预测是保障电力系统安全性和提升电力系统经济性方面的两个重要问题。数十年来,业界对二者进行了持续研究,并取得了丰硕成果。当前,电力系统的新发展对暂态稳定评估和风电功率预测提出了更高要求,已有方法在适用范围、评估及预测的准确度和精确度等方面面临严峻挑战。深度学习的发展为二者的突破提供了新的可能,基于深度学习的电力系统暂态稳定评估和风电功率预测研究已经成为电力系统研究领域的前沿课题。本文对此进行了深入研究,主要工作及成果归纳如下:提出了一种基于深度置信网络的电力系统暂态稳定评估方法。该方法利用深层结构有效挖掘数据的隐藏模式,为暂态稳定评估提供知识基础。评估模型的训练不仅涉及利用标注数据的监督训练,而且还包括利用无标注数据的无监督训练,有助于模型泛化能力的提升。算例仿真结果表明,该方法具有评估准确率高、容错能力强、样本时域仿真耗时短等特点。提出了一种基于堆叠自动编码器的电力系统暂态稳定评估方法。该方法突破了传统的两阶段评估模式,对“特征提取”和“分类评估”进行了有机融合,实现端到端的暂态稳定评估。该方法摆脱了对人工提取特征的依赖,依靠深层网络自动从底层量测数据中提取特征,很大程度上保障了信息的完整性。此外,为减轻模型的过拟合,在模型的训练中加入稀疏性约束和Dropout技术。算例仿真结果表明,该评估方法能够直接面向相量测量单元(PMU)量测数据,评估准确率高,能较好地适应电力系统的暂态稳定评估需求。提出了一种基于深层稀疏去噪编码网络的电力系统暂态稳定评估方法。针对不同量测数据的不同物理本质,该方法提出了一种具有多分支结构的深层网络模型。借助不同稀疏去噪编码网络(分支)从各种量测量中分别提取特征,并在模型顶部进行融合,最终完成暂态稳定评估结果输出。算例仿真结果表明,该评估方法能够有效处理多种量测量的同时输入,评估准确率高,噪声环境下的鲁棒性好等优点。同时,与普通全连接网络相比,该模型结构更为简洁,计算复杂度较低,能够较好地适应较大规模电网的暂态稳定评估需求。提出了一种计及空间相关性的多位置风速预测方法。针对风速的空间相关性,利用可视化手段进行了直观分析,并建立了对多位置风速预测问题的一般性数学描述。立足时空序列的本质特点,提出“先提取空间特征,后建立时间联系”的两阶段建模策略,并构建了基于卷积神经网络的风速预测模型。该模型能够直接接收二维矩阵输入,在很大程度上避免了空间信息的损失。算例仿真结果表明,该方法能有效利用空间相关性提高风速预测精度,在总体平均性能和个体误差控制能力上均优于常规的机器学习类风速预测方法。提出了一种利用时空相关性的多位置多步风速预测方法。针对风速的时间相关性和空间相关性,利用采样交叉函数对二者从数学角度进行分析。将多位置多步风速预测问题建模为一个时空序列预测任务,并给出该问题的一般性数学描述。利用空间模型提取时空序列的空间特征,并利用时间模型建立各空间特征间的时间联系,最终达到时空信息联合学习的目的。算例仿真结果表明,该方法能通过空间模型和时间模型的相互协作,提高风速预测精度。并且,该模型规模不随时间长度序列变化,理论上能够利用任意长度的历史序列信息,具备良好的可扩展性。提出了一种基于多模态多任务学习的风电功率预测方法。对考虑多源异质信息的风电功率预测问题进行讨论,并给出了该问题的一般性数学描述。采用多模态学习策略促进输入变量间的信息共享,同时利用多种量测共同为风电预测服务;采用多任务学习策略整合多个时刻的风电功率预测任务,使模型具备风电序列预测能力。为有效确定模型超参数,采用正交试验开展模型选择,能显著缩小超参数寻优空间,节省计算资源。算例仿真结果表明,该方法能有效利用多种量测量提高风电功率预测精度。此外,以互信息为依据的输入变量选择指标能够为模型性能的进一步改善提供有利指引。"
1456,Research on Recommendation System for Healthcare Using Feature Extraction & Pattern Recognition,"In the era of health informatics,the growth of health information generated by health information systems and healthcare organizations demand expert and intelligent recommendation systems.It has become one of the most valuable tools as it reduces problems such as information overload while selecting and suggesting doctors,hospitals,medicine,diagnosis,etc.according to the patient's interests.Recommender systems are intelligent decision support software tools whose aim is to provide the most relevant information to a user by discovering patterns in a dataset They assist users to make decisions on a variety of items from different sources.Various techniques and approaches have been applied to design and implement such systems to generate credible recommendations to users.Traditionally,the most common techniques used by many existing recommendation systems are a collaborative approach,content-based approach,knowledge-based approach,and hybrid-based approach that combines two or more techniques in different ways.A multi-criteria recommendation is an extended technique used to predict unknown ratings and recommend exciting items to users based on ratings given to multiple attributes of items.This method has been used and proven by researchers in industries and academic institutions to provide more accurate predictions than the traditional techniques.There are several problems that need to remain in consider while working on a recommendation system.Accuracy improvement has been one of the issues yet to be solved by the recommender systems research community.Recently,multi-criteria recommender classifications that practice multiple criteria ratings to estimate overall rating have been receiving considerable attention within the recommender systems research domain.There is still a need to work on improving the recommendation system by using machine learning techniques.Weighted ranking model using collaborative and content-based approaches is helpful in improving the utilization of the recommendation model.The current study is focused on the implementation of the weighted ranking model using feature extraction based on several features of items.In this study,we propose a hybrid recommendation system framework that uses heterogeneous health data from different sources based on extracting the features an in-depth analysis of these features with their patterns.Our Health recommendation model is service oriented which gives output in a graphical timeline scrutinize and combine the drugs information with the medical test as well as with historical data of the patient.Besides that,for improving more quality of accuracy,we have used foreign health database for recommendation purpose.The novelty of our proposed algorithm is that it provides a recommendation for the hospital as well as doctors and patients both.We have implemented advanced data mining approaches with feature extraction which gives tremendous results towards health improvement,a decrease in chronic diseases,a decrease in mortality rate,etc.For the patient,it suggests a doctor,for the doctor it recommends treatment,and for management of the hospital,it suggests different ways to increase the efficiency of the hospital regarding turnover of the patients.Later we extended our model to different datasets based on feature extraction.To demonstrate the effectiveness of our proposed frameworks,several experiments were carried out.In the experiments,our proposed model was demonstrated on different datasets besides the health dataset.Different datasets of different types and categories are being used for the evaluation and validation of the proposed strategy based on features extraction.Features of all datasets were listed out in order to get the right recommendation of the results.The experimental results for each of the two proposed frameworks together with their corresponding single rating techniques are presented in this study.To analyze the performance of the approaches,we carried out a comparative analysis of their performance with the collaborative filtering technique and other multi-criteria recommendation methods.Through a comparison study with another single-and multi-criteria collaborative filtering methodologies,we demonstrated that using the proposed feature based multi-criteria learning method is an integral part of the multi-criteria recommendation process.In addition,the experimental results also show that using feature extraction to incorporate the multi-criteria rating information for predicting the overall rating has considerably improved the accuracy of the multi-criteria recommender system than using genetic algorithms.Furthermore,we explored other machine learning algorithms for the purpose of prediction of results and recommendation.We also compared the performance of different algorithms with our proposed algorithm and provide the results on different datasets."
1457,面向慢性病辅助诊断的多标签学习算法研究,"在医疗健康服务领域,数据分析技术常用于辅助医生进行疾病诊断。在诊断慢性病时,由于其成因复杂并有很大的概率可能引发相应的并发症,导致许多患者可能同时患有超过一个疾病,因此慢性病的辅助诊断模型需要为医生推荐多个可能的疾病,从而帮助医生发现患者更多潜在的疾病。由于多标签学习算法可以同时输出多个与预测样本相关的结果,所以多标签学习算法是一种非常适用于构建慢性病的疾病诊断模型的算法。但是,现有的多标签学习算法在医疗数据分析上还存在很多局限性。论文以提升慢性病的辅助诊断模型性能为目标,针对多标签学习算法在分析医疗数据中存在的几个关键问题进行了研究。主要工作如下:(1)针对医疗数据中的类别非均衡现象会导致多标签分类学习模型性能降低的问题,提出了一种融合多类集成分类的成对聚合多标签学习算法。对于每一个标签,该算法将多标签学习任务分成一个二元分类任务和多个多分类任务,然后训练一个二元分类器,以及利用一个基于正则化的多类集成分类算法来构建多类分类器,最后聚集二元分类器和多类分类器来预测样本的标签,以提升多标签算法处理非均衡数据的能力。在医疗数据集上实现该算法,并对比其他多个多标签算法的实验结果,验证了融合多类集成分类的成对聚合多标签学习算法在分析非均衡医疗数据上的优越性。(2)针对采用医疗数据的所有症状指标训练的多标签学习模型的准确度较低和训练效率较低的问题,提出了一种基于特征信息的多标签学习算法。该算法首先采用概率邻域图模型计算特征空间中实例的相关性,然后采用余弦相似性计算标签空间中标签的相关性。对于多标签数据,该算法不仅可以实现为每个标签选出标签特定特征的功能,而且还可以实现为样本预测一组相关的标签的功能。在医疗数据集上的实验结果表明该算法在提升慢性病的辅助诊断模型性能的效用。此外,本文还使用其他的公开数据集进行实验,验证了该算法的通用性和优越性。(3)为了分析多种疾病的相关性,提升多标签学习模型的准确性和高效性,提出了一种基于标签相关性的快速RAkEL算法。为了实现充分利用标签的相关性,该算法首先基于欧几里得相似度计算每个样本的k近邻,并为每个标签构建标签近邻标记矩阵和标签近邻缺失矩阵,然后分别根据标签近邻标记矩阵的相似度和标签近邻缺失矩阵的相似度来衡量标签的正相关性和负相关性,最后根据标签正相关性和负相关性来选择标签子集。选定标签子集后,对于每一个标签子集,首先采用回归模型把样本分为相关与不相关的两个类,接着用LP模型训练相关的样本,从而实现高效的多标签学习。通过在医疗数据集上进行实验,验证了提出的算法能够提高慢性病的辅助诊断模型的精度和效率。并且,在其他公开数据集上的实验结果表明该算法具有更优越的性能。"
1458,面向医学命名实体识别的深度学习方法研究,"医学命名实体识别在生物医学研究中起着重要作用,近年来围绕医学命名实体识别有大量的研究工作,目前的研究中存在3个问题需要解决。识别精度不够高,新的医学实体数量在快速增加,传统识别方法的精度不够高。计算效率较低,基于深度学习的识别方法在结构上无法实现高效的计算。多类别医学实体识别问题,欠缺识别多类别医学领域命名实体的方法。针对提高医学命名实体识别的精度的问题,提出基于语义的深度学习方法。提出基于字符的BiLSTM-CRF(CBLC)方法,通过字符级别的词嵌入方法捕获单词的内部结构信息。提出语义BiLSTM-CRF(SBLC)方法,使用大量包含语义信息的医学资源训练词嵌入,结合BiLSTM-CRF获取语义结构的上下文和标签之间的关系,结合Ab3P更有效识别缩写。结果表明,CBLC优于广泛使用的条件随机场和词典匹配等基线方法,SBLC方法优于DNorm和TaggerOne在内的先进方法。在语义的基础上,为了解决罕见医学实体识别以及实体标记不一致的问题,首先设计了一种基于Trie树的医学词典查找方法,然后提出两种融合词典注意力的深度学习方法。提出Dic-Att-BiLSTM-CRF(DABLC)方法,将词典匹配和文档级注意力机制结合到BiLSTM-CRF中,通过权重组合方式把词典和注意力方法进行组合。提出Dic-Att-BiGRU-CRF(DABGC)方法,使用词典匹配医学词典,同时结合双向GRU网络对词嵌入进行训练,输出包含上下文信息的隐状态,通过多头注意力机制解析词之间的结构。DABLC和DABGC方法可以有效地利用外部词典资源,解决罕见和复杂医学实体识别问题,进一步提升了深度学习方法的精度。为了提升深度学习方法的计算效率的问题,提出两种加速深度学习方法。提出Att-SGRU-CRF(ASC)方法,使用切片GRU网络,通过分组和分层的计算结构,有效提升方法的训练速度。并通过注意力机制解决标注不一致的问题,最后结合CRF计算出最优的标签序列。提出注意力迭代扩张卷积网络(AIDC),结合迭代扩张卷积网络(IDC)和多头注意力方法。AIDC将词嵌入输入到迭代扩张卷积网络中进行加速训练,结合多头注意力机制和条件随机场模型,计算出最终的输出标签。与现有的循环神经网络相比。ASC方法在速度上可以获取50倍以上的加速效果,同时获得较高的F1分数。AIDC 比BiLSTM快1.9倍,同时可以保持较高的识别精度。有效提升了深度学习方法的计算效率。为了解决多类别医学实体识别问题,提出基于文本分类和加权投票的方法Text Classification Weighted Voting(TCWV)。TCWV结合带秩约束的线性文本分类模型,通过较少量的训练文本,高效地对更大规模的文本进行分类。针对不同的命名实体类别,使用不同类别的医学文本作为词嵌入训练的输入。设计了权重投票算法,集成多个深度学习的模型。在疾病,化学和基因数据集上,TCWV均获得了最高F1分数,较好地实现了多类别医学命名实体识别。实验结果表明,本文提出的方法较好解决了当前面向医学NER领域,基于深度学习的方法存在的识别精度不够高,计算效率较低,多类别医学实体识别的问题。对促进医学信息学研究具有一定的积极作用。"
1459,政务营商环境研究,"2015年9月,中共中央国务院发布《关于构建开放型经济新体制的若干意见》,其中提出要“着力构建稳定、公平、透明、可预期的营商环境”。《中华人民共和国国民经济与社会发展第十三个五年规划纲要》将营商环境分为市场环境、政务环境、法律政策环境和人文环境等四个大类。其中,政务营商环境指的是制约企业达到其最高生产率的政府服务能力及水平的总和。2019年3月,国务院政府工作报告明确提出“激发市场主体活力、着力优化营商环境”是“促进经济平稳增长的关键所在”,因此将其列入2019年政府十项重点工作之一。政务营商环境的优化,有助于完善市场经济体制,促进政商关系规范化,降低企业制度性交易成本,提升地区经济发展质量,以及增强国家竞争力。更重要的是,政务营商环境的优化还能通过提高经济发展的质量和效益,建立起安全、高效益、高质量、可持续的财源体系,有力支撑财政的可持续发展。本文主要研究从企业需求的角度如何定义、分析、评价和优化政务营商环境。首先,从营商环境、政务营商环境问题的由来、发展及概念内涵外延的辨析入手,厘清了政务营商环境的内涵和特征,并通过文献的评述和理论的回顾与运用奠定了本文研究的理论基础。其次,基于现阶段政务营商环境相关研究存在着整体水平不佳、质量良莠不齐的情况,本文运用扎根理论的研究方法对“人民网・地方领导留言板”的留言数据进行了理论抽样,在达成理论饱和的基础上,通过三级编码形成了政务营商环境研究的分析框架。之后,运用有监督的机器学习方法,从“人民网・地方领导留言板”的全体留言数据中筛选出政务营商环境相关留言,并运用构建的分析框架对文本数据进行了分类和分析,最终对我国企业在政务营商环境方面存在的需求偏好形成了整体的认识。再次,基于政务营商环境评价指标体系对改进政府服务、提升政府效能所具有的价值导向和评价工具的意义,本文尝试着构建了政务营商环境的评价指标体系。之后,运用层次分析法对指标体系进行了赋权,并收集了国内地级以上城市的数据,据此来计算城市政务营商环境指数,并分析了中国城市政务营商环境的主要特点和我国地方政府在构建政务营商环境方面的主要问题。最后,在综合前述分析的基础上,以服务型政府理论为指导,提出了优化我国政务营商环境的对策建议,以期为我国改进和优化政务营商环境提供理论支撑和工具选择。通过上述研究,本文发现,企业对政务营商环境的主要诉求包括公平竞争的市场环境与稳定和谐的社会环境、充足的现金流与完善的产权保护、有效的政策落实、完备的基础设施与优质的生产要素、高效的行政审批服务等。但是,政府服务理念转变滞后、服务内容不清晰、服务能力不足、服务制度不健全、服务流程不合理、激励机制不完善等问题,导致企业的需求没有得到有效的满足。要想建立起需求识别有效、服务职能合理、服务能力良好、服务供给优质的政务营商环境,政府需要从服务理念、服务内容、服务设施、服务制度、服务流程、服务供给、评价标准、激励机制等八个方面提升政府服务效能,并运用合理科学的政务营商环境评价指标体系来评估和指导政务营商环境优化工作。本文运用经济学的视角与方法研究了一个公共政策问题,并将这个问题置于保障财政可持续发展的背景和逻辑中,即本文的研究视角和研究方法具有跨学科和综合性特点。此外,本文以政务营商环境为研究对象,系统分析了企业对政务营商环境的需求偏好,并在此基础上构建了政务营商环境评价指标体系、测算了中国城市政务营商环境指数、提出了优化政务营商环境的有效路径,这既有助于该领域理论研究的扩展和深化,也希望能够对政府营商环境建设的实际工作提供政策工具和理论指导。"
1460,微结构硅基光子学器件性能的研究,"集成电路(IC)由于量子尺寸和功耗问题越来越无法满足现代社会对高速数据处理和信息传输的要求。人们越来越关注到光子作为信息载体时的独特优势,希望可以利用光子延续摩尔定律的发展。在这样的时代背景下,硅基光子学得到了广泛的研究。而对硅基光子系统性能的提升成为了重要的课题。除了利用基于传统理论的设计和优化方法外,将其他领域的理论向光学领域和硅基光子系统进行推广以及结合近些年发展迅速的人工智能和逆向设计等新的技术手段都将为提升硅基光子系统的性能提供新的动力。本论文主要研究了提升硅基光子系统性能的新方法,主要创新点如下。引入了时空对称理论,提出了在自发PT对称性破缺的双模波导中,损耗介质对模式耦合损耗具有额外的增强作用。通过在双模SOI波导上设计有效折射率实部和虚部的微扰分布,构建了处于厄米相、破缺的PT对称相和纯吸收相的三种器件。通过数值计算和实验有效地验证了当系统处于破缺的PT对称相时,相比于纯吸收相将具有更高的对目标输出模式能量的损耗。在该方案中,损耗介质在常规的光吸收作用以外,还引入了从厄米相到破缺的PT对称相的相变,而后者强烈地阻止从输入模式到输出模式的能量耦合,可以有效地增强模式耦合损耗。实验结果显示,模式耦合损耗增强因子可以达到17dB,且具有较高的带宽。通过时空对称理论增强硅基SOI波导内模式耦合损耗的方案,可以为吸收型光强度调制器或光开光提供一种新型的设计思路,使得对于电控损耗介质的利用更加高效,提高调制深度或消光比。引入了人工神经网络算法,提出了使用卷积神经网络分析多模波导内模式能量分布的方案。该方案不依靠以往常用的空间模式排序技术,降低了器件层面的复杂度,并将此负担转移到了数据处理层面。针对片上常见的薄SOI多模波导和SOI重多模波导,分别设计了专用的卷积神经网络和普适的二维卷积神经网络,从而利用预处理后的远场光强图像预测模式能量分布。这些训练好的卷积神经网络的性能经验证能够达到较高水准。在SOI重多模波导中,该性能也没有下降。此外,训练好的卷积神经网络经验证对噪声具有较高的鲁棒性。这种利用卷积神经网络分析多模波导中的模式能量分布的新方法对于空分复用和结构光领域具有较高的潜在应用,并且可以拓展到多模光纤体系。引入了逆向设计理念,提出了利用粒子群优化(PSO)算法设计超小尺寸高性能的硅基模式转换器的方案。该方案将模式转换器耦合区域的单侧宽度变化和总长度参数化,并给予它们合理的取值范围形成解空间。以FDTD计算出的TE00模的平均前向透射率为适合度函数,不断更新在解空间搜索的粒子的速度和位置,从而逐渐逼近全局最优解。根据上述逆向设计的理念,得到了模式转换器的全局最优参数(或接近最优)并对其尺寸、插损、背向散射、模式转换率、模式纯度和加工误差容忍度等多个性能指标进行了分析。通过和前人结果进行比较,该模式转换器表现优异。"
1461,基于感兴趣区域率失真优化的视频压缩编码通信系统设计,"基于感兴趣区域模式的视频压缩编码近年来成为视频压缩、计算机视觉领域研究的热点课题。从广义上来讲,视频中的感兴趣区域指视频帧中引起人们注意的像素部分区域。它通常包括视频中运动的目标、色彩变化的区域。感兴趣区域视频编码的关键思想在于,对这部分区域以较小的量化步长进行压缩编码,以获得较高的编码精度。而对于非感兴趣区域部分,则采用较大的量化步长进行粗糙编码,以降低整体编码输出的比特。依据人体视觉系统的要求,感兴趣区域视频编码的目的是将特定的感兴趣区域在解码端得以清晰的呈现,而对于非感兴趣区域,人们的关注点并不在这部分,因此并没有必要完全保证这部分的编码质量。换句话说,在某种特定应用场景下,为尽可能减小编码速率,仅保留感兴趣区域部分的编码精度以达到不影响人们对视频内容理解的目的。本文设计了一套基于感兴趣区域率失真优化的视频编码通信系统,该系统包括感兴趣区域提取模块、感兴趣区域视频编码率失真模块与感兴趣区域视频流传输模块。设计这套系统的目的在于实现低比特视频流通信同时不影响对视频内容的理解。围绕这一系统展开,本文主要研究这三大模块中的三个核心技术:感兴趣区域提取技术、感兴趣区域视频编码的率失真优化技术、感兴趣区域视频流在无线网络环境下的传输技术。其中,感兴趣区域提取技术主要研究如何从视频帧数据中提取感兴趣区域,它主要指运动的区域以及一些特定的目标物体。这一部分区域作为视频帧的前景部分,而其它区域则作为背景部分。感兴趣区域视频编码的率失真优化技术主要解决视频编码中的速率和失真权衡的问题。即给定一组视频序列,使得速率受限制的约束条件下,该组序列的失真达到最小。在解决这一优化问题时,如何建立恰当准确的速率失真模型是其中的关键部分。速率失真模型可对感兴趣区域编码模式下的速率、失真进行数学描述。通过速率失真模型列出率失真优化问题的目标函数以及约束条件,并对其进行求解,得到视频组序列每帧的比特分配方案,进而设计速率控制策略。感兴趣区域视频流传输技术主要以异构无线网络为背景,通过对视频帧中编码单元的编码信息进行封装,组成网络层的传输单元并将这些传输单元分配到不同属性的无线信道进行传输。异构无线网络的传输的模式仍基于端到端的传输模式,然而终端具有多家乡接入属性。通常上讲,终端具有多元化网络接入单元接口,可同时接入不同属性的无线网络。感兴趣区域编码模式下的视频流传输力图保证包含感兴趣区域信息的传输单元能够具有较少的传输失真与解码失真。同时,视频流的传输需满足实时性要求。对于超过时延截止部分的视频流分组则会被丢弃以节约网络资源。此外,传输过程中引入信道差错控制编码技术,通过引入额外监督位降低误码率,并尽可能满足感兴趣区域部分信息得以完整的解码与重建。本文针对上述内容,对感兴趣区域视频编码的关键技术进行了深入详细的研究,主要内容包括:(1)研究了感兴趣区域提取技术。结合传统的数字图像处理理论以及当前流行的深度学习理论。本文分别提出了两种新的感兴趣区域提取检测方法:级联模型算法与基于文本主题模型的边界框修正算法。其中,级联检测算法四个级联步骤:全局运动补偿,运动块提取,多层像素分割和模型更新。前面两个步骤提取前景运动块并形成运动遮罩,后面两个步骤移除属于运动遮罩内背景的像素,并更新背景模型的颜色分布。另外,提出了基于块到像素的检测思路以实现检测灵活性。所提出的方法的另一个好处是它可以嵌入视频编解码器中以进行实时ROI检测和编码。实验结果表明,该方法在检测精度和时间消耗方面都实现了改进的性能。文本主题模型的边界框修正算法属于机器学习算法。它包含两个阶段:模型训练与验证。在训练阶段,它将检测目标图像的特征点信息转换成文本信息。在文档主题生成模型(Latent Dirichlet Allocation,LDA)的基础上,本文提出了一个具有单词共现先验的主题模型,其中图像特征之间的共现信息被充分利用。在验证阶段,本文提出了一种基于边界框(Anchor-box)的修正算法,该算法可以从一些传统算法中快速检测与预训练主题模型相对应的检测结果,并具有快速检测时间。对各种数据集的实验表明,所提出的方法可以在效率和计算成本方面提高检测性能。它对于颜色,光照,尺度等不同的物体也具有鲁棒性。有趣的是,所提出的方法可以与许多快速但有失准确性的感兴趣区域提取算法相结合,并增强了系统模型的灵活性。(2)研究了感兴趣区域视频压缩的率失真优化与速率控制技术。本文提出了一种基于DCT残差系数的混合分布与径向基函数神经网络的适合感兴趣区域编码模式下的速率失真模型。通过将编码单元分类为不同的深度、纹理特征来对其速率失真进行建模。在此之后,利用所提出的速率失真模型,列出率失真优化问题的目标函数以及约束条件,并根据凸优化理论对其进行求解。同时,设计针对感兴趣区域编码模式下的速率控制策略。通过实验验证,所提出的方法在解码重构的视觉质量,速率失真性能和比特率精度等方面取得了相应的改进。它针对感兴趣区域部分取得了较高的编码精度,同时保持编码缓冲器稳定输出,失真满足在可控范围内。(3)研究了感兴趣区域编码模式下视频流在无线异构网络环境下的传输技术。本文提出了一种基于感兴趣编码模式视频传输框架,该框架基于多家乡接入终端的异构无线网络环境。它包含感兴趣区域提取模块和帧分离器的模块,其中编码单元被分类封装到网络传输单元中。该框架还包括监视每个通信路径状态的信道监视器,并将反馈信号发送至视频流控制器来进行分组调度控制。本文提出了用于信道状态预测的深度学习方法。为了解决视频流分组传输问题,本文设计了适用于感兴趣区域编码模式下的视频流传输的速率失真模型,并制定传输调度策略。该策略传输延迟和失真之间寻求平衡点。它还保证具有ROI内容的数据包在具有足够带宽和低损耗的路径上进行传输。通过与其他传输方法的比较的模拟实验,验证了所提出的方案在视频传输质量,端到端延迟以及播放流畅度方面均取得了良好的效果。"
1462,面向细分领域的舆情情感分析关键技术研究,"客户对于服务的满意与否关系到服务提供商的效益,为了有效维护现有客户和开发新客户,服务提供商需要及时分析客户对于服务的反馈中所蕴含的情感信息以便快速采取措施应对,从而提升客户体验。随着信息产业、互联网以及移动互联网的飞速发展,客户对于服务的满意程度能够更加方便的通过网络平台进行反馈,互联网已经取代传统渠道成为主要的反馈载体,庞大的客户群体每时每刻都会产生海量的非结构化文本反馈,传统的依靠人工的反馈分析方式已经难以满足企业对于客户关系管理的需求;同时,企业服务涉及不同的主题,需要精确的将不同领域的反馈传达到相应的部门才能使反馈得到有效的处理。而每一个细分领域文本的情感具有领域特殊性,相同的语言表达在不同领域的情感倾向具有差异。因此,如何设计一种能够对海量非结构化客户反馈文本进行分类,同时进行舆情情感分析的方法,并利用该方法构建能够对细分领域非结构化文本的舆情情感信息进行快速自动分析并能够自动适应不同领域情感表达方式的系统,成为了企业客情关系维护亟需解决的问题。基于上述背景,为了高效的对非结构化客户反馈文本进行自动分析处理,本文针对生活服务网站中面向机票服务、酒店服务、餐饮服务等细分领域的舆情情感分析这一需求,对其中的文本细分领域分类、舆情情感分析等关键技术进行了深入研究,主要研究内容及成果如下:(1)提出了一种基于注意力机制与对抗训练的文本分类算法作为文本分析的重要任务,文本分类已经受到广泛研究,并涌现出了许多方法,例如隐藏狄利克雷分布(Latent Dirichlet Allocation,LDA)文档主体生成模型的文本分类方法、基于词袋(Bag-of-word)模型的文本分类方法与基于支持向量机(Support Vector Machine,SVM)的文本分类方法等。这些方法都是将词作为一个符号,记录文本中有无出现该符号以及该符号对某一主题(类别)的贡献程度,而忽略单词本身所代表的语义以及词语之间的顺序等关系。本文在循环神经网络(Recurrent Neural Network,RNN)的基础上通过引入注意力机制,使模型能够较好的保留文本词语之间的顺序关系与长距离依赖,同时自动提高关键词对于文本分类的权重,使分类器具有较好的效果。同时,利用对抗训练在模型训练的过程中产生词嵌入的扰动,使模型具有更高的泛化能力及鲁棒性。实验表明该方法具有优于基线方法的性能。(2)提出了一种融合分段卷积神经网络(Piecewise Convolutional Neural Network,PCNN)与生成对抗网络(Generative Adversarial Network,GAN)的情感分析算法文本情感分析作为目前网络环境下进行舆情监控、服务评价及满意度分析等领域最为重要的任务之一,需要对文本中客户的观点、喜好等情感加以判别。相比于传统自然语言处理分析工具,卷积神经网络(Convolutional Neural Network,CNN)作为深度学习中自动捕获句子特征的有效方法,可以从句子中学习与情感分析任务关联性最强的特征,提升情感分析模型的性能。然而原始的卷积神经网络模型忽略了对于文本情感分析十分重要的句子结构信息,而且很容易发生过拟合。针对上述的不足,本文采用分段池化的策略,使基于深度学习的卷积神经网络模型能够对句子结构进行建模,分段提取句子不同结构的主要特征来对文本的情感倾向进行分析,并且利用Dropout算法提升模型的泛化能力。同时,用户对于服务的反馈涉及到众多不同领域,每一个领域中的标注数据都较少,为了缓解数据的稀疏性,本文还利用生成对抗网络进行共同特征提取,使模型能够获取在不同领域的反馈中与情感相关的共同特征,增强模型在训练数据较少的情况下的泛化能力。在不同数据上的实验,证明了以上方法的有效性。(3)提出了一种基于门控单元的循环-卷积神经网络(Recurrent-Convolutional Neural Network,R-CNN)与卷积-循环神经网络(Convolutional-Recurrent Neural Network,C-RNN)的集成情感分析方法目前效果较好的情感分析算法都是基于统计学习的方法,这类方法性能的好坏取决于特征提取的质量,而良好的特征工程需要较高的专家经验且费时费力,可迁移性较差;神经网络的方法能够减少特征工程的依赖,RNN能够获得上下文信息但是有语义信息偏置问题;基于CNN的文本分析方法能够通过池化获得文本的重要特征但较难获得上下文信息,如本文提出的融合分段卷积神经网络与生成对抗网络的情感分析模型利用分段池化策略能够部分缓解CNN的不足,然而对于长距离依赖建模仍然较差。针对上述问题,本文提出了一种基于门控单元的R-CNN与C-RNN融合的情感分析方法,首先通过不同的方式组合RNN与CNN,缓解二者的不足,分别构建子分析网络R-CNN与C-RNN,最后通过门控单元自动融合两种网络,组成最终的分析模型。我们在不同的数据集上进行了充分实验,验证了方法的有效性。(4)提出了一种融合群稀疏与排他性稀疏正则项的情感分析模型压缩方法本文提出的融合PCNN与GAN的情感分析方法与基于门控单元的R-CNN与C-RNN集成情感分析方法,都使用了较大规模的卷积神经网络来保证模型的效果,导致模型的参数规模较大。而在实际运用中,标注数据较少,模型得不到较为充分的训练。同时,为了能够快速对出现的舆情进行分析,及时对客户的反馈进行应对,有效进行客情关系管理,情感分析系统需要具有较高的时效性。为了解决上述问题,本文提出在模型预训练过程中,利用群稀疏与排他性稀疏正则项对模型进行剪裁,首先利用稀疏正则项剪除权值较小的边,并去除连接稀疏的神经元节点,然后继续训练剪枝后的模型。我们在不同的数据集上进行了充分实验,验证了压缩方法的有效性,提升了网络在进行预测时的效率,同时保证模型的性能不会有较大的下降。(5)基于上述方法设计构建了客户满意度分析原型系统在上述研究的基础上,本文基于B/S架构,利用Spring-Boot框架设计实现了客户满意度分析原型系统。实现了数据预处理、垃圾信息过滤、细分领域划分及客户情感分析等核心功能,并进行了原型系统模拟测试,充分展示了本文所提出的方法的有效性、实用性。"
1463,中美上市公司年报话语质量对资本市场反应的影响对比研究,"近年来,我国企业赴美上市势头强劲,众多企业纷纷加速实施“走出去”战略。上市公司年报作为强制性披露文件,是企业和投资者之间信息沟通的重要工具,具有研究价值。会计金融研究以往主要关注财务数据披露状况,近年来企业年报文本研究成为一个新热点。本研究采用系统功能语法等语言学理论,结合有效市场假说等金融学理论,对比分析中美企业年报话语可读性、劝说性和情感倾向性,考察企业年报话语质量与资本市场反应之间的关系,具体回答三个问题:1)中美上市公司年报话语质量是否存在显著差异?2)上市公司年报话语质量是否影响资本市场反应?3)我国赴美上市企业如何提升信息披露质量和对外传播能力?本研究构建出一个企业年报话语质量影响资本市场反应的理论框架,包括可读性、劝说性和情感倾向性三个话语维度质量指标以及衡量资本市场反应的累计异常收益率指标。研究语料来自纽约证券交易所上市的全部52家中国企业2012-2016年20-F年报中的“经营与财务回顾与展望”部分,对比语料来自纽交所上市的135家美国企业2012-2016年10-K年报中的“管理层讨论与分析部分”,建立了由892份报告构成的企业年报话语语料库,总容量约为1800万词符。本研究采用语料库工具测量迷雾指数、词汇易读度、句法复杂度和连贯性等可读性特征;采用MDA(Multi-dimensional Analysis)多维分析法,借助MAT多维分析工具和因子分析法,并结合修辞结构理论进行定性讨论,考察并测量59种词汇-语法特征共现形式的劝说性交际功能;采用深度神经网络模型机器学习算法,对积极、消极和中性句子自动分类,测量样本语料情感倾向性;采用单因素多元方差分析和t检验等统计方法对比中美企业年报话语质量指标得分的差异;采用事件分析法和回归模型考察企业年报话语质量对资本市场反应的影响。本研究发现:第一,在可读性方面,中国企业年报话语的迷雾度显著低于美国企业(MD=-0.283,t=-3.790,p<0.05),说明企业年报话语的信息沟通功能和劝说功能的有效发挥,会引起资本市场的正向反应。从而表明,企业年报话语质量越高,资本市场反应越良好。本研究在理论和方法上具有以下创新和价值。理论上,将语言学、经济学、传播学、计算机科学等多学科理论相结合,构建起企业年报话语研究的综合理论框架;提出“企业年报话语质量”概念,构建企业年报话语质量评价理论模型;提出企业年报话语质量影响资本市场反应的理论假设,考察语言变量对资本市场反应的影响效应,拓展了以往仅关注财务数据影响效应的资本市场研究理论视角,实现了具有一定深度的跨学科融合。方法上,建立中美企业年报历时语料库,采用多种语料库方法和工具,定量与定性分析相结合,考察纽交所上市中美企业年报多维特征;采用人工智能技术,借助机器学习算法测量语篇的情感倾向;采用事件分析法,结合回归分析验证企业年报话语传播质量如何影响资本市场反应,具有一定的创新性。本研究的应用意义表现在,在企业信息披露研究中增加年报话语质量考察视角有助于完善企业信息披露质量评价指标体系,对提升我国在美上市企业对外传播能力和信息披露质量具有实际价值。此外,对商务英语教学也具有一定的应用意义。本研究今后可进一步扩大样本,增加评价指标,考察企业年报话语质量的影响因素,分行业考察企业年报话语质量对资本市场的影响效应,为我国企业“走出去”提供咨询意见和对策性建议。"
1464,金融科技对金融服务贸易自由化的影响研究,"随着1993年《服务贸易总协定》(GATS)开始为全球服务贸易治理提供规则框架以来,服务贸易重要性越来越受到国际社会认可。金融服务作为其中的重要组成部分,在全球经济运行中发挥着不可替代的作用。近年来,金融科技通过数字技术革新了金融服务的提供模式,改变了生产者、消费者和贸易商的交易行为,使金融服务供求愈加依赖于数据流动,对金融服务业和世界经济环境带来了一系列深刻变革。相对应地,也带来金融服务贸易规则的重大变化,最突出的新特征就是“数据策略性”。在以CETA为代表的双边和区域贸易协定中,金融对外开放范围更广泛,金融服务贸易规则更加新颖,进行中的TISA谈判同样在向高标准靠拢。在金融科技发展如此迅猛的背景下,有必要对其给金融服务贸易自由化的影响和效应作出研究,有必要对以跨境数据流动限制为主的新金融服务贸易规则作出分析,有必要应对金融服务部门的数字贸易规则挑战作出建议。本研究首先测度了金融科技发展水平和主要国家金融服务贸易自由化现状,说明金融服务贸易自由化水平的国别差距在加大,总体自由化水平表现出降低趋势。这主要是由于外资进入壁垒有所提高,尤其是对跨境数据流限制愈加严格。与此同时,在引力模型基础上得出发展中国家相对发达国家金融服务贸易成本显著偏高,且金融服务贸易竞争力偏低的现状。其次从金融服务贸易成本、金融服务市场特性、数字技术扩散以及金融科技的潜在风险4个维度出发,详细阐述金融科技对金融服务贸易自由化的影响机制。即通过区块链案例说明金融发展有助于降低微观企业金融交易成本,巩固金融服务贸易自由化的基础;通过人工智能案例说明金融科技推动中观金融产业差异化,引起金融市场由垄断向竞争转变,由此保障金融服务贸易自由化进程中的贸易收益;通过大数据案例说明金融科技引发新的数字经济范式,在未来5至10年,数字技术对宏观经济的渗透将进一步提升金融服务贸易自由化水平;同时还总结金融科技会带来数据泄露、网络风险等一系列高风险因素,通过MATLAB软件进行金融监管博弈仿真模拟说明有必要加强国际金融监管合作。总体而言,金融科技对金融服务贸易自由化有正负两方面影响,正向影响包括导致微观成本降低、中观竞争加剧、宏观创新扩散,正向影响引起跨境金融服务贸易规模扩大和自由化水平提高,致使主要国家金融服务贸易自由化水平“剪刀差”扩大;负向影响包括泡沫、数据泄漏和技术等潜在风险,会导致金融服务贸易自由化水平减弱,致使主要国家金融服务贸易自由化水平“剪刀差”缩小。最后,在实证部分,本研究以41个主要国家为样本,检验了金融科技对金融服务贸易自由化的影响效应。得出随着金融科技发展水平的提高,金融市场效率对金融服务贸易相对优势和金融服务贸易自由化之间的调节作用变得明显,金融市场效率对金融服务贸易相对优势和金融服务贸易自由化之间的调节作用变得明显放大的结论。即当一国金融科技发展至临界水平以上时,会导致该国对外开放金融市场的意愿变得更强烈;反之,在一国金融科技发展至低于这一临界水平时,封闭金融市场的意愿也会变得更强烈。说明在考虑了金融科技的影响下,金融市场效率对金融服务贸易相对优势和金融服务贸易自由化之间的调节作用变得明显。综合说明金融科技给金融服务贸易自由化水平带来正向效应,会导致金融服务贸易自由化水平“剪刀差”扩大。为迎接金融科技潮流,深化我国金融服务对外开放,提升我国金融服务业国际竞争力,本研究提出以下政策建议:一是协调好资本账户开放与金融服务贸易自由化之间的关系;二是利用监管科技革新监管体制并开展金融科技合作;三是在平等、互利、互惠原则上积极参与国际金融贸易规则制定等。"
1465,中国银行业系统性风险的测度和预警研究,"由2007年美国次贷危机引发的国际金融危机戳破了资本市场的泡沫,导致信贷规模大幅收缩,造成市场流动性不足。此次金融危机引起了世界各国对系统性风险的关注,系统性风险具有全局性、综合性和传染性特征,在金融危机期间迅速向全球扩散,不仅会导致金融体系的不稳定,还会阻碍经济的增长和损害社会福利等,对国际金融体系和全球实体经济都会产生巨大的负外部性效应。近年来,中国经济金融运行的国际、国内环境错综复杂。中国经济的发展呈现出短期与长期、内部与外部、周期性和结构性的矛盾和问题。这些挑战都可能会影响中国金融系统的稳定性。为避免中长期中国的经济再次陷入衰退的风险,警惕新一轮金融危机的发生,中国政府近年来多次召开经济金融工作会议,反复强调防范和化解系统性风险的重要性。党的十九大报告中也明确提出把防范化解重大风险作为中国目前三大攻坚战之首。由此可见,防范和化解系统性风险已成为当前中国经济金融工作的重点。长期以来,中国的银行业在金融体系中一直占据主导的地位,并且对中国经济金融的发展和稳定起着举足轻重的作用。为此,本文从中国特定的经济和金融市场环境出发,以中国的银行业为重点研究对象,采用定性分析和定量分析、理论分析和实证分析相结合的方法研究了系统性风险的测度、系统性风险的影响因素和系统性风险的预警等问题。本文的研究主要包括以下内容:第一,基于对数正态密度分布函数的广义Edgeworth级数展式,在CCA模型中,引入偏度和峰度项,提出拓展的CCA方法。然后,基于中国上市商业银行的数据,测度了银行业系统性风险。研究结果表明,引入高阶矩的CCA模型具有高度的灵敏性,能够准确地测度银行业系统性风险。第二,分别采用ΔCo VaR和MES方法测度中国上市商业银行的系统性风险贡献度。以中国上市商业银行为样本,基于商业银行的股票市场数据,测度银行的系统性风险贡献度。研究结果显示,首先,ΔCoVaR和MES模型测度银行的系统性风险贡献度比VaR模型测度的更准确,而MES模型测度结果除中国银行、平安银行、浦发银行、招商银行、南京银行、宁波银行的结果排序变化较大以外,其余银行的测度结果与ΔCoVaR接近。其次,整体来看,国有大型商业银行的系统性风险贡献度比股份制商业银行和城市商业银行的要高。第三,分别建立计量回归数据模型研究了中国银行业系统性风险的影响因素。首先,建立固定效应回归数据模型研究银行微观特征变量包括银行规模、杠杆率、银行总资产收益率、银行资产质量和银行股票波动率对银行业系统性风险的影响。实证结果表明,银行规模的扩大会显著地降低银行业系统性风险,而银行总资产收益率、不良贷款率和股票波动率的提高会显著地增加银行业系统性风险水平,杠杆率的提高虽然增加了银行业系统性风险,但是影响并不显著。其次,建立动态面板系统GMM数据模型研究表外业务与银行业系统性风险之间的关系。实证结果表明,整体而言,表外业务与银行业系统性风险呈负相关关系,也即商业银行增加表外业务能够显著降低银行业系统性风险水平。通过分组回归,国有商业银行增加表外业务能够显著降低对银行业系统性风险的贡献水平,而股份制商业银行或城市商业银行开展表外业务虽然会增加对银行业系统性风险的贡献度,在一定程度上对冲掉国有商业银行开展表外业务降低的系统性风险贡献水平,但是影响并不显著。因此,与商业银行不分组回归的实证结果相符。第四,采用计算机仿真模拟法和比较分析法,主要采用机器学习算法进行建模,对中国银行业系统性风险和金融体系的系统性风险进行预警研究。首先,基于支持向量机(SVM)方法构建中国银行业系统性风险预警模型,并将预警结果与BP神经网络模型和Logit回归结果进行对比,研究了中国银行业系统性风险预警问题。其次,采用SVM的改进算法,即最小二乘支持向量机(LSSVM),研究中国金融体系的系统性风险预警问题。将实验结果与SVM方法、BP神经网络方法和logit回归的结果进行对比。研究结果显示,LSSVM方法的预警正确率较高。第五,本文以国家政策为导向,提出构建货币政策和宏观审慎政策的“双支柱”调控框架,防范和化解系统性风险,维护经济金融体系的稳定。此外,本文还从完善防范系统性风险的制度措施、加强银行防控系统性风险的能力、建立科学有效的系统性风险预警机制、防范外部冲击的风险等方面提出了防范和化解系统性风险政策建议。"
1466,基于机器学习的缝洞识别及多波联合反演方法研究,"随着人工智能和机器学习的快速发展,机器学习已渗透到石油勘探开发的各个环节,对石油地球物理勘探产生了重要的影响,同时也带来了新机遇和新突破。石油地球物理勘探,尤其是测井和地震勘探,在研究过程中通常会遇到一系列的分类问题和回归问题。本文在调研总结石油地球物理勘探中的分类、回归问题的基础上,对分类问题中的裂缝和缝洞充填物识别,以及回归问题中的多波联合反演展开了研究,并分别提出了改进方法。针对裂缝和缝洞充填物识别,本文提出了一种基于最小二乘支持向量机的识别方法。结合FMI电成像测井图像和岩心观测资料,对裂缝和缝洞充填物进行分类;分析裂缝和缝洞充填物的测井响应特征,从众多的测井曲线中挑选出对裂缝和缝洞充填物敏感的测井曲线;由于利用单个测井曲线来识别的效果往往不佳,因此提取对裂缝和缝洞充填物更加敏感的组合参数;利用最小二乘支持向量机方法分别建立裂缝和缝洞充填物的识别模型,并通过粒子群算法对最小二乘支持向量机参数进行优化,以提高裂缝和缝洞充填物的识别精度。实际资料测试中,该方法的识别精度高于BP神经网络方法,识别结果与成像测井、岩心资料具有较好的一致性,说明该方法是可行的且具有一定的实用价值。针对多波联合反演,本文提出了一种基于改进贝叶斯推断和最小二乘支持向量机的非线性反演方法。该方法采用精确Zoeppritz方程进行PP波和PS波正演,避免近似公式在远炮检距和弹性参数纵向变化较大等情况下的误差;利用最小二乘支持向量机方法建立PP波、PS波反射振幅与弹性参数之间的最优非线性模型,以解决多波联合AVO反演的非线性问题;通过改进的贝叶斯推断对最小二乘支持向量机超参数的后验概率进行最大化,获得了最优的超参数,从而提高了多波联合反演的精度。模型试算表明,该方法的反演精度和抗噪能力优于常规方法;该方法的实际资料反演结果与实际测井曲线更加吻合,反演误差更小,表明该方法有着较强的适用性,利用该方法对研究区的实际多波地震资料进行反演是可行的。"
1467,基于非线性成矿动力系统的机器学习方法应用研究,"随着数字化进程的不断推进,地质科学迫切需要引入可以实现数据自动处理和分析的新技术与新方法,机器学习理论的发展为地质大数据中的复杂问题提供了新的求解途径。论文针对非线性成矿系统进行了动力过程的研究,验证了系统的动力学行为以及系统变量之间的非线性函数关系,并针对系统中的不同目标问题进行了机器学习模型的应用与探讨。论文主要研究成果如下:(1)以成矿元素为研究对象,运用相空间重构技术和关联维数,结合反应扩散方程对成矿元素的动力过程进行研究,研究表明:成矿元素的聚集与扩散过程具有混沌性态,其动力过程所形成的吸引子具有稳定的分形维数,系统的稳定性决定了相空间中吸引子的具体形态。(2)以涨落耗散定理为出发点,通过考察成矿系统内部的涨落,得到了系统对于能量的耗散程度,并结合实际钻孔中元素含量的分布特征,研究了成矿系统能量耗散对于元素含量分布的影响,结果显示:系统能量的耗散程度决定了成矿元素含量在空间中的分布高低。(3)利用DLA模型对不同约束条件下成矿流体的渗透过程进行模拟,结果显示:成矿流体的运移行迹在空间上具有自相似性,可以将其视为一种分形生长过程。(4)以结构化数据为基础,分别针对系统中的回归问题、岩性识别问题和特征提取问题探讨了不同机器学习模型的应用效果,结果显示:随机森林和SVM模型对于系统内部的非线性关系拟合效果较好;GBDT算法对于岩性识别问题具有较高的分类精度;经过熵函数的计算,随机森林模型选择的特征具有更高的分类能力;相比于PCA模型,基于RBF核函数和Sigmoid核函数的KPCA模型特征提取效果更好,并且实验样本在新生成的特征空间中线性可分;ISOMAP和LLE两种流形学习模型可以有效的学习高维空间中的变化,使得样本经过映射后在新特征空间中的分类边界明显;前馈神经网络模型则可以在求解目标问题的同时实现特征的自动提取,其隐含层的权重分布在一定程度上影响着特征学习的有效性。"
1468,顾及空间约束的多元地球化学异常识别自编码神经网络方法研究,"矿产资源是我国经济发展的重要支柱力量。目前,矿产资源供需之间的矛盾愈发尖锐,当务之急是实现地质找矿的重大突破,而这需要发展新的地质找矿技术。对矿产勘查实践来说,勘查地球化学方法具有十分重要的作用。故地球化学数据处理,以及与矿化作用有关的地球化学异常识别引起越来越多的关注。近年来,对于地球化学异常识别的研究取得了重要进展。机器学习方法由于其不依赖数据分布、不要求地质变量与预测值之间的线性相关关系、对非线性关系具有强大的刻画能力等优势,被应用于模拟复杂且未知的多元地球化学分布模型,以及提取与矿化作用有关的有意义特征。然而,目前机器学习在地球化学异常识别应用上仍有一些问题没有解决,这些问题牵制了机器学习方法在勘查地球化学领域的应用发展,限制了机器学习的异常识别能力。缺乏考虑地球化学数据空间特性及空间约束是目前机器学习在勘查地球化学领域应用的关键问题。这个问题得不到解决,会使得机器学习的数据处理优势得不到发挥,方法应用停留在表面而不深入,甚至影响到对找矿信息二次挖掘和利用。机器学习方法在地球化学异常识别的应用中,主要分为利用已知矿点作为标签数据的有监督异常识别以及无标签数据的无监督异常识别。由于有监督的学习方式缺乏考虑数据的内在结构,遗漏潜在的成矿信息,故本研究主要探讨无监督机器学习在地球化学异常识别应用中,自编码神经网络是无监督机器学习方法中最为重要的方法,如何融入地球化学数据的空间信息以提高自编码神经网络的地球化学异常识别能力。需要强调的是该研究主题与本专业测绘科学与技术具有一定的关联性,这是因为我们将地球化学空间分布图看作是地理景观数据,以测绘科学与技术中的地理信息数据分析及处理方法来解决地球化学异常识别的问题,从而将测绘科学技术与地球化学专业结合起来。本论文主要从两个方面着手研究顾及空间约束的无监督异常识别自编码神经网络方法,一是利用多元素之间的关系作为重构成份完成背景重构,另外一种是利用元素的空间信息作为重构成份完成背景重构。这两者皆是以大概率样本作为成分重构背景,从而达到背景与异常分离的效果。具体研究工作如下:(1)多元关系重构方法的主要问题是忽略了地球化学背景的空间异质性,导致对有价值的地球化学异常的识别无效。本文提出了一种多元地球化学异常识别的空间约束多自动编码器(Spatially Constrained Multi-Autoencoder Approach,SCMA)方法。该方法利用“因地制宜”思想去化解空间异质性带来的异常识别困难。其考虑了地球化学样本的化学相似性和空间连续性,通过多元聚类、空间滤波和空间融合等方法对不同背景的空间进行划分。利用多自编码器结构对每个子域的地球化学背景进行学习和重构,以减少自编码器神经网络中权值随机初始化的影响。然后计算异常分值作为观测到的地球化学特征与重建特征的差值。(2)地球化学背景的空间结构特征往往被忽略,如何有效提取元素的空间结构信息是关键问题。本文提出了一种多卷积自编码器(Multi-convolutional Autoencoder Approach,MCAE)方法来处理多元地球化学异常识别,该方法包括三个独特的步骤:(1)消除地球化学元素之间的相关性,避免有效背景信息被冗余数据稀释;(2)利用Global Moran’s I指数来明确元素背景空间结构的识别域,以保证模型有效提取元素背景空间结构信息;(3)利用多卷积自编码器非交互方式学习和重构背景空间结构特征,避免了学习过程中多元素相互干扰。最后根据观测地球化学数据与重建数据的差异计算异常值。(3)本文提出的方法皆应用于中国福建闽西南铁多金属成矿区,采用1:20万水系沉积物样品中Cu、Mn、Pb、Zn、Fe_2O_3元素对研究区进行多元异常识别。结果表明,SCMA和MCAE模型都在各方面都优于现有的几种方法,其识别的异常与该地区已知Fe矿床空间相关性较高,异常识别准确性得到有效提高。在具体工作之中,本文的创新点有两个:(1)揭示了准确划分空间域的关键因素,提出了基于空间约束多自编码器的多元地球化学识别方法。以往的自编码神经网络应用在地球化学异常识别上往往忽略了地球化学背景的空间异质性,导致对有价值的地球化学异常的识别无效。我们提出的基于空间约束多自编码器的多元异常识别方法,考虑到地球化学样品的化学相似性和空间连续性,创新性的提出了空间异质区域划分方式,其通过多变量聚类、空间滤波和空间融合,将区域划分为多个不相交子域,在空间上区分不同模式的地球化学背景。这样的空间划分方法可以较大提高地球化学背景重建和异常识别的质量。(2)揭示了确定背景识别域的关键因素,提出了基于多卷积自编码的多元地球化学异常识别方法。以往的自编码神经网络应用在地球化学异常识别上,没有考虑过空间结构作为背景重构成分来重构元素地球化学背景。我们提出的基于多卷积自编码神经网络的多元地球化学异常识别办法,其利用元素空间相似性指数来确定背景识别域,并以此设定移动卷积窗口尺寸,其避免了尺度设置不正确带来的结构提取不准确的问题。同时,在该方法中,利用ZCA白化算法来消除多元素之间携带的冗余信息,降低了多元背景融合难度。这些措施较大程度地提高了地球化学背景空间结构提取的能力,达到了提升多元异常识别的准确性的目的。总之,本文贡献是提出了一种灵活的、顾及空间信息的地球化学异常识别自编码神经网络框架,其包括的两种顾及空间约束的自编码神经网络方法。本文主要探讨了适合于自编码神经网络学习的空间域划分影响因素,以及确定地球化学元素背景识别域的关键因素。本研究工作不仅丰富了自编码神经网络方法在地球化学异常识别应用上的认识,同时为其他领域空间数据自编码神经网络应用提供了新的思路和方法。"
1469,基于功能磁共振成像的疼痛特异性脑神经活动研究,"【目的】大脑神经活动如何产生痛觉感知是神经科学领域尚未解决的一个难题。由于大量脑影像学研究显示疼痛刺激会激活一组特定的脑区,因此有研究将这些脑区命名为“疼痛矩阵”。然而,有文献证据表明“疼痛矩阵”的激活不是特异于疼痛感知,而是表征刺激的强度或突显性信息。因此,关于“疼痛矩阵”的神经活动是否反映疼痛特异性信息引起疼痛神经科学领域研究者各执己见、争论不休。这一争论的起因主要源于前人研究的几点局限性:第一,前人研究在比较痛觉刺激与非痛觉刺激所诱发的脑神经活动时,往往忽视了痛觉与非痛觉条件下刺激强度的匹配,从而导致无法确定两者所引起脑激活的差异究竟是源于感觉模态的差别还是刺激强度的差别;第二,受限于当时数据分析技术的局限性,前人研究大多采用传统单变量分析方法,对数据的信息挖掘能力有限;第三,前人研究大多从局部脑区(即空间小尺度)的角度孤立地考察单个脑区疼痛特异性神经活动,而忽视了大尺度下全局范围的神经活动空间分布模式。针对上述研究的局限性而且为了更深刻地理解疼痛在人脑中的特异性编码机制,本文运用功能磁共振成像(functional Magnetic Resonance Imaging,fMRI)技术并结合机器学习判别方法,进行了以下三部分研究。第一部分:在严格匹配痛觉和非痛觉刺激的感知强度的情况下,通过比较两者所诱发脑激活的差异来识别对痛觉信息处理具有偏向性的脑功能区。第二部分:利用先进的机器学习技术,通过多变量模式分析(Multivariate Pattern Analysis,MVPA)方法对fMRI数据进行更深度的信息挖掘,以寻找疼痛特异性的脑神经活动模式。第三部分:基于第二部分研究结果,即疼痛特异性神经活动可能具有分布式空间表达模式,由多个脑区的神经活动协同组成,本研究进一步系统性地考察了疼痛特异性神经活动模式的空间尺度。【材料与方法】第一部分:51名健康受试者接受功能磁共振扫描,同时接受痛觉和触觉刺激,并对每一个刺激的强度进行评分。通过挑选强度评分相同的痛觉和触觉刺激对两者的强度进行严格匹配,利用一般线性模型对刺激强度严格匹配的痛觉和触觉刺激所诱发的脑激活进行建模并对两者进行比较,从而识别两者激活有差异的脑区。第二部分:基于两套独立的痛觉及非痛觉刺激条件下采集的fMRI数据集,利用MVPA技术对强度严格匹配的痛觉及非痛觉刺激所诱发的“疼痛矩阵”内的脑神经活动的空间分布进行模式分类(即:痛觉vs.非痛觉),以识别疼痛特异性的脑神经活动分布模式。为进一步考察“疼痛矩阵”脑神经活动的分布模式与刺激强度或突显性之间的关系,本研究利用同样的方法进一步对高强度与低强度刺激(不区分刺激感觉模态)进行了模式分类(即:高强度vs.低强度)。为验证上述分析所建立的分类模型的可重复性和可泛化性,对每种模式分类任务,本研究不仅进行了同一数据集内的训练和测试,而且进行了独立数据集之间的训练和测试。第三部分:采用事件相关设计,采集了62例健康成年志愿者在接受痛觉和触觉刺激时的脑fMRI数据。通过不同的脑图谱模板对大脑进行不同精细程度的脑区划分,对单一脑区内的所有体素进行平均,从而构建出不同空间尺度下刺激诱发的fMRI信号。包括全脑体素水平的原始图像,本研究共构建了4种不同的空间尺度的图像数据:(1)尺度1:全脑体素水平;(2)尺度2:全脑划分为246个脑区;(3)尺度3:全脑划分为48个脑区;(4)尺度4:全脑划分为14个脑区。再针对每种空间尺度,利用MVPA技术对痛觉和触觉刺激所诱发的fMRI信号进行模式分类(痛觉vs.触觉),考察在哪种空间尺度下痛觉和触觉刺激所诱发的神经活动具有差异性空间分布模式。为明确考察脑区间的协同交互作用是否也包含疼痛特异性信息,我们还针对尺度2-4,进一步构建了全脑功能连接网络,利用MVPA技术对网络连接模式进行痛、触觉分类,考察在哪种空间尺度下存在痛、触觉差异性脑功能连接模式。此外,本研究还考察了全脑每个局部脑区体素水平是否存在痛、触觉差异性的神经活动分布模式。【结果】第一部分:(1)疼痛刺激激活的所有脑区也可被触觉刺激激活,反之亦然;(2)这些脑区的激活强度与刺激的感知强度呈正相关,而与刺激的感觉模态无关;(3)当严格匹配痛觉和触觉刺激的感知强度时,一些脑区在两种条件下的激活存在显著性差异:双侧丘脑、左侧辅助运动区、右侧额中回以及额下回眶部对疼痛刺激响应强于触觉刺激;而左侧中央后回、视觉皮质、右侧顶下小叶、左侧顶上小叶和右侧小脑对触觉刺激的响应强于疼痛刺激。第二部分:在匹配感知强度的情况下,利用MVPA技术能够识别痛觉与非痛觉刺激在“疼痛矩阵”内所诱发的差异性fMRI信号空间分布模式,并且这种差异性空间分布模式在同一数据集内的不同被试之间或独立数据集之间均具有一定的一致性。此外,本研究发现在忽略刺激感觉模态的情况下,利用MVPA技术也能够识别高强度与低强度刺激在“疼痛矩阵”内所诱发fMRI信号空间分布模式的差异。第三部分:在本研究构建的四个空间尺度下,不论在个体内还是个体间,结果均检测到痛、触觉差异性的脑神经活动空间分布模式。而对于脑功能连接网络,在尺度2和3检测到痛、触觉差异性的脑功能连接模式。当考察每个局部脑区时,结果发现虽然组水平上全脑很多脑区均在体素水平上存在痛、触觉差异性神经活动分布模式,但这些脑区的个体间差异较大。【结论】即便严格匹配了痛觉和非痛觉刺激的感知强度,一些脑区在处理痛觉和触觉信息时仍然表现出不同的偏好性,但这些脑区的神经活动并非特异性地仅处理某一种感觉模态的信息,其主要反应了感知到的刺激强度而与刺激模态的种类无关。相较于传统的单变量分析方法,机器学习技术可以更加敏感地识别疼痛特异性信息,进一步表明“疼痛矩阵”的神经活动在功能上具有异质性,它不仅编码着刺激感知强度的信息,而且也编码了疼痛特异性神经信息,此外,疼痛特异性神经活动在空间上具有分布式特点。利用机器学习技术对其空间尺度的系统性研究进一步证实疼痛在人脑内的特异性神经编码体现在从局部(小尺度)到全局(大尺度)的多个空间尺度,即:疼痛特异性神经编码信息不仅存在于某些局部脑区,而且分布于距离较远的多个不相邻脑区,由这些脑区神经活动的协同作用来特异性地编码疼痛感知,呈现“网络”式编码方式,这一编码方式存在较大的个体间差异,可能与疼痛感知的个体间差异有关。"
1470,高危型HPV感染状态与子宫颈癌相关危险因素和分子指标的关系及基于机器学习的子宫颈癌筛查效果多指标综合评价,"研究目标分析不同高危型别HPV单一和多重感染状态下子宫颈癌相关危险因素和分子指标的差异,探讨HPV感染状态与子宫颈癌及癌前病变的关系;基于机器学习的方法,利用上述指标构建子宫颈癌筛查综合模型,评价该模型用于子宫颈癌筛查的效果。材料与方法本研究采用以医院为基础的多中心横断面研究设计,2014年4月-2017年8月从7家研究中心入组参加子宫颈癌筛查的正常和轻度病变的妇女,以及医院门诊诊断为子宫颈癌和癌前病变的患者,进行子宫颈癌危险因素问卷调查,并取两份子宫颈脱落细胞标本。第一份标本用棉签拭子采集,用于HPV16/18E6癌蛋白检测;第二份标本用宫颈采样刷收集,放入ThinPrep细胞保存液中,分装后用于薄层液基细胞学检查、高危型HPV DNA检测和p16/Ki-67双染细胞学检查。筛查人群四种检测任意阳性召回进行阴道镜检查并取活检;门诊患者在治疗前取子宫颈标本用于以上四项检测。检测剩余的细胞保存液冻存于超低温冰箱。2016年7月-2017年9月,使用剩余保存液样本进行高危型HPVDNA分型检测、高危型HPVE6/E7mRNA和HPV16/18/45E6/E7mRNA检测。HPVDNA分型检测针对14种高危型HPV,可以单独报告HPV16、18、31、45、51和52共6种型别结果,其余8个型别分为3组(HPV33/58、HPV59/56/66、HPV35/39/68)进行报告。根据分型检测结果,将阳性样本的感染状态分为3组:1.明确单一感染组,包括HPV16、18、45、31、51和52单一通道检测阳性;2.可能单一感染组,包括HPV33/58、HPV59/56/66和HPV39/68/35单一通道检测阳性;3.多重感染组,两个及以上通道检测阳性。基于危险因素和分子检测结果,分析不同HPV感染状态下各分子指标的表达情况及其用于子宫颈癌筛查的效果,并通过逻辑回归、随机森林和支持向量机的方法构建子宫颈癌筛查综合模型。研究结果1.高危型HPV明确单一感染、可能单一感染和多重感染在正常/CIN1妇女中所占比例相当,分别为33.7%,35.4%和30.9%;而在CIN2/3患者中,明确单一感染(46.8%)和多重感染(37.2%)所占比例均有所上升,可能单一感染比例下降(16.1%);在SCC/ADC患者中,明确单一感染比例显著增加(70.3%),可能单一感染比例显著下降(5.4%),而多重感染占比略微下降(24.3%)。多重感染HPV E6/E7 mRNA总表达率(明确单一感染vs.可能单一感染vs.多重感染:87.0%vs.76.2%vs.92.5%,χ2=37.865,P=0.001)高于单一感染。多重感染妇女的细胞核p16单染、细胞浆p16单染、细胞核Ki-67单染、任意p16蛋白染色、任意Ki-67蛋白染色、以及p16/Ki-67双染的阳性率均略高于明确单一和可能单一感染,其中p16/Ki-67双染阳性率在不同感染状态之间的差异最为明显(明确单一感染vs.可能单一感染vs.多重感染:61.2%vs.38.7%vs.54.4%,χ2=56.669,P"
1471,面向电力大数据的用户用电行为挖掘方法,"随着智能电网的建设推进,逐步积累了大量的数据资源,而采集频度的增强、数据量的急剧增长、以及数据类型的多样化,对数据处理和价值挖掘也提出了更高要求。在电力大数据中,用户用电负荷数据占据了相当大的比重,它反映了用户真实的用电需求,值得对它进行深度挖掘,获取用户用电行为的重要知识,从而在配用电管理领域辅助实现决策支持。然而,用电负荷数据具有规模大、维度高、来源类型多、时效特征强、价值密度低等典型特征,且与大量社会、经济、环境、地理数据关联密切。因此,为了提高其应用质量和范围,就需要根据不同的数据特征和应用目的,研究开发高效的数据分析挖掘方法。本文针对用电负荷数据的数据特性,考虑需要实现的应用目的,分别从行为特征、行为关联和行为演化三方面,深入研究用户用电行为挖掘方法,取得如下成果:1.针对用电行为特征分析方法,首先提出一种基于小波变换的融合曲线聚类方法,以提高高维负荷曲线的聚类有效性,实现单用户典型用电负荷模式提取。该方法在利用小波变换进行降维的基础上,采用一种聚类融合子算法,用于融合并优化小波变换生成的两组特征数据的聚类结果。其次,在对大量用户提取负荷模式的基础上,构建一种基于负荷模式相似性的用户分类混合模型,获取明确的用户类别,并实现新用户分类。该模型使用类别特征识别算法,从负荷模式聚类的结果中识别出明确的用户分组和类别特征,并将无监督聚类问题继续扩展为有监督分类问题,利用类别特征作为标签,进行新用户分类。2.针对用电行为关联分析方法,提出一种具有最优结果选择机制的典型相关分析方法,用以分析两种或以上多变量数据间的相关性,研究多种因素对用电行为的影响。基于单用户的用电、用气和气候数据。该方法首先对多变量日负荷数据进行聚类,并依此将三种数据分组,然后按组分别对每日的用电、用气和气候数据进行典型相关分析,再使用基于预测逆过程的选择机制择取最优结果,最后将所有结果汇总并绘制成日典型相关性变化曲线,细粒度地展现一段时间内各因素两两间典型相关性以及各变量典型权重的变化。3.针对用电行为演化分析方法,提出一种具有概率策略的增量聚类方法,基于已有的负荷模式和新增用电负荷数据进行负荷模式更新,进而分析负荷模式的演进变化情况,并检测异常模式。该方法首先对新增日负荷数据聚类,以提取新负荷模式,然后在负荷模式融合阶段,逐一对新负荷模式判断其状态是新增还是融合,最后对融合后的负荷模式重新聚类修正。在负荷模式融合和修正期间,为保证结果最优,距离度量和聚类中心计算均采用概率策略。在一次增量聚类后更新重要参数,即能应对下一组新增负荷数据,实现持续的增量学习。通过对比分析连续更新的负荷模式,能清晰展现用户用电行为的演化过程,进而发现异常变化情况。上述三种方法和一种模型以用户用电负荷数据为中心,从数据的关联性和动态性考虑,形成多方位的数据挖掘方法体系,以技术手段支撑用户用电行为的深入挖掘,辅助决策支持系统,从而提高智能电网运行效率。"
1472,未来蜂窝网络中基于机器学习的资源管理技术研究,"下一代蜂窝无线网络需要支持超可靠,低延迟的通信,并且需要支持在高度动态的环境中实时智能地管理大量物联网设备。不仅如此,下一代蜂窝网络还需要具有智能化的管理功能,从而能够根据不同的网络与用户状态对蜂窝网络管理策略进行调整。这些要求只能通过在无线基础设施和终端用户设备上集成机器学习的方法来实现。因此,研究如何利用机器学习算法与人工智能技术对蜂窝通信网络实现自组织地、智能化地、实时地管理与控制具有较高的价值。机器学习算法在蜂窝通信网络中主要分为两大应用:一是对蜂窝网络环境进行识别并根据网络环境对网络资源与用户进行管理与调度,二是利用网络的已有数据对网络状态进行预测,从而优化网络性能。本文的研究内容主要包括如何利用机器学习算法对网络频谱资源与用户进行调度与管理,如何利用机器学习算法对网络状态与用户行为进行预测,以及如何优化机器学习算法使其适用于蜂窝无线网络环境。具体而言,本文首先介绍了新型网络的架构以及基于新型网络架构的无线蜂窝网络所存在的技术问题。然后详细介绍了如何利用机器学习算法对授权与非授权频谱资源管理、对缓存管理、对UAV的部署与规划以及对360°内容传输和缓存的管理。论文的具体研究内容及创新性工作如下:(1)研究授权与非授权频谱的分配以及上下行解耦的用户连接。本文提出了基于回声状态网络的资源管理与用户连接算法,从而实时地根据网络环境优化授权与非授权频谱资源分配与用户连接并且最大化用户吞吐量。(2)缓存管理的研究。本文提出了利用用户的行为信息决定缓存内容的算法,从而降低网络中前程与后程链路的负载并且优化用户有效容量。本文提出了基于回声状态网络的预测算法。所提出的算法能够对用户移动性与用户内容请求概率分布进行预测,从而确定基站与云端的基带处理单元缓存的内容。(3)研究无人机的部署与规划。本文提出了基于conceptor的状态回声网络的预测算法。该算法能够对用户行为进行分析与预测。根据预测的用户内容请求概率以及用户移动模式确定用户连接、无人机的最优部署位置、以及无人机的最优缓存内容,从而优化用户性能。(4)研究360°内容的传输与缓存。为了克服液态机无法保证具有循环记忆特性的缺点,本文提出了基于液态机与状态回声网络结合的机器学习算法。所提出的算法能够有效地管理360°内容与可视内容的传输与存储,从而最大化用户的传输可靠性。"
1473,基于机器学习的高Z物质宇宙线μ子成像方法研究,"宇宙线μ子成像技术是近年来发展起来的一种新型无损成像技术,它利用天然的宇宙射线作为射线源,避免了外加人工射线源对被检物及操作人员造成的辐照影响。此外,宇宙线μ子穿透本领强、对高原子序数(高Z)材料比较敏感,这些特点使得该技术在重核材料的无损成像上具有优势,在核安保、核废物测量以及条约核查等领域有着广阔的应用前景。该技术的研究重点和难点是成像算法,其中高Z物质快速识别算法是宇宙线μ子成像技术应用于安检领域的重要理论基础,如何实现快速高质量的图像重建也是需要特别关注的问题。然而,宇宙线μ子的通量有限,且各个μ子的能量和入射角存在明显差异,带来了重建图像噪声较大和数据不完备等问题,从而导致现有μ子成像算法大都耗时长、成像质量不高,难以满足现实应用需求。为此,本论文尝试将机器学习引入到μ子成像算法研究中以试图改善算法性能。机器学习技术在大数据分析、智能识别及归纳预判等方面具有很多优势,在人工智能等领域得到了非常广泛的应用。然而,目前关于机器学习在μ子成像算法研究方面的报道很少。为了提高高Z物质的识别效率及图像重建质量,本论文对基于机器学习的高Z物质宇宙线μ子成像方法中若干有代表性的基础问题进行了研究。在基于无图像模式的材料识别算法研究方面,本论文利用蒙特卡罗方法及宇宙线发生器CRY建立不同物质的μ子散射角数据集,利用有监督学习中的分类模型和灰色系统理论对数据集进行深入分析整理,设计二分类模型并建立用于结果判定的决策函数,构建了无动量信息的CMA及含动量信息的MCMA两种高Z物质快速识别算法。对算法的性能检测结果表明这两种算法效率高、鲁棒性好。其中CMA算法不需要对μ子动量信息进行测量,对系统要求低,更易实现。CMA对于高Z与中Z(或低Z)物质的区分效率较高,1分钟的检测时间内可以判定密封容器内的10 cm铀方块是否存在,但对于高Z物质之间的区分效率较低,区分10 cm铀方块和铅方块需要2个小时,适合用于高Z物质是否存在的快速判定;MCMA算法需要提供μ子动量信息,但对高Z物质的区分效率较高,4分钟的检测时间内就可以准确区分密封容器内的10 cm铀方块与铅方块。此外,该方法对μ子动量测量精度和探测器位置分辨率具有较好的容错能力,μ子动量测量误差在50%以内及探测器分辨率在3 mm以内并不会对算法效率造成明显影响,是CMA算法的一个有效补充。在基于图像模式的材料及边界识别算法研究方面,本论文首先是在基于散射图像分析的基础上加入无监督学习中的聚类方法,通过网格聚类的方法及密度聚类的方法不仅实现了不同原子序数材料的区分,而且还实现了图像噪声的去除以及边界的识别。在宇宙线μ子成像实验装置TUMUTY上获取了实测数据,对方法进行了验证,表明该方法可以提高图像重建质量以及对不同材料进行识别。其次针对经典μ子成像算法PoCA在竖直方向重建图像噪声大、边界模糊等问题提出了基于μ子透射图像信息分析的厚度测量方法,该方法对于厚度2 cm及以上铀平板的厚度测量相对误差不大于2%。对透射模式和散射模式成像图像质量进行了分析并提出了将两种物理信息相结合的图像重建方法,分析结果表明利用两种物理信息重建图像可以有效提升图像质量。最后,为了进一步提高高Z物质的识别效率,研究了利用μ子的散射特征及透射信息对不同原子序数的材料进行识别,结果表明综合利用两方面的物理信息可以有效提升材料识别能力。本论文紧密围绕宇宙线μ子成像技术的应用需求,对机器学习技术应用于高Z物质宇宙线μ子成像算法研究方面进行了探索,研究结果不仅为宇宙线μ子成像技术的应用提供了理论支撑,也拓展了μ子成像算法的研究思路。此外,本论文研究内容对人工智能与辐射成像技术的交叉融合研究也有一定的启示。"
1474,基于人工智能的磁共振图像重建和计算机辅助诊断的研究,"磁共振成像(Magnetic Resonance Imaging,MRI)是临床重要的检查手段,使用不同的脉冲序列,可以获得关于人体组织结构、功能、代谢等不同方面的信息。磁共振成像对比度信息丰富、分辨率高、可任意方向切片,并且没有辐射伤害,在临床诊断中发挥着重要作用。磁共振成像也是技术最为复杂的医学影像方法之一,在磁共振成像的数据采集、图像重建、图像后处理与图像分析等各个阶段都有大量的科学与技术问题需要研究。本文利用数据驱动与人工智能(Artificial Intelligence,AI)的方法,分别对磁共振图像重建、图像处理、图像分析等进行了系统的研究。本文主要做了如下工作:一、本文对磁共振成像图像重建中的若干问题进行研究。高分辨的磁共振图像需要较长的图像采集时间,这也是磁共振扫描成本较高的主要原因。利用采集部分k空间数据(欠采集)进行图像重建是缩短磁共振成像扫描时间的重要方法。本文首先对磁共振血管造影图像的重建进行了研究。我们利用磁共振血管的半高全宽不随分辨率变化这一先验知识,结合迭代算法,提出了约束数据外插(Constrained Data Exploration,CODE)算法。该算法可以利用采集的k空间低频数据,进行高分辨图像的重建。我们通过模拟数据和增强磁共振血管图像的实验,证明了与压缩感知(Compressed Sensing,CS)重建相比CODE图像更加锐利,对颈动脉的狭窄估计更为准确。我们还在传统字典学习(Dictionary Learning,DL)的基础上,提出了一种新的分割字典学习方法。该算法利用数据驱动的字典学习模型,根据脑部磁共振图像的组织对比度特点,可以从伪随机欠采的脑部图像数据中进行图像重建。通过模拟与真实数据的实验,证实了分割字典学习算法比传统字典学习能重建出更好的图像。二、本文以基于多参数磁共振图像的前列腺癌的计算机辅助诊断(ComputerAided Diagnosis,CAD)为目标,利用深度学习(Deep Learning)对腺体分割、病灶分类、癌灶检测等一系列问题进行了研究。高质量、多参数磁共振图像能够为疾病诊断提供更多信息的同时,也需要临床医生花费更多精力阅片。计算机辅助诊断系统对多参数磁共振图像进行分析处理,为医生的临床决策提供辅助,可以减轻医生劳动强度、提高工作效率、降低误诊率。为构建这样的系统,我们首先研究了前列腺腺体的分割问题。在目前流行的U-Net卷积神经网络(Convolutional Neural Network,CNN)的基础上,结合了前列腺的空间连续性设计了多层输入的分割网络,利用了多监督的网络输出,获得了良好的分割结果,尤其保证了前列腺的顶部和底部都取得了较好的分割结果。在此基础上,我们提出了多参数图像输入的TrumpetNet,对前列腺内部的区域进行癌灶检测,多中心验证结果表明该网络对于检测癌灶具有较高的敏感性,能够给临床医生以提示作用。最后在癌灶诊断方面,我们分别采用了影像组学(Radiomics)和深度学习两套模型,分别进行了临床显著性癌/非显著癌、癌/非癌的自动分类研究,探讨了不同序列和不同模型的组合对诊断结果的影响。我们提出一种新的增强预测方法,能够有效提高深度学习模型的预测能力。在上述研究的过程中,我们研发了两套软件。FeAture Explorer(FAE)软件用于影像组学研究,可自动探索影像组学研究各个算法步骤中不同方法的组合,发现最佳模型。该软件开源后已在多家医院获得应用。DeepOncoAnalysis软件则包括磁共振数据的读取、感兴趣区域标记、特征提取等功能,用于医生标记及数据准备;同时,该软件还集成了上述前列腺分割与检测模型,便于模型在医院科研中应用,并可用于医院反馈结果,精化模型。"
1475,基于数据驱动的中医精准诊疗模型研究,"数据驱动指以数据作为主导因素的决策支持方法,从广义的角度看,所有的行为都是数据驱动,从狭义的角度看,数据驱动的对立面是经验驱动,在经过数据采集、数据建模、数据分析三个过程后,杂乱的数据就可以转换为决策支持的结果。“精准医疗”体现的个体化医疗理念,与传统中医学因人、因地、因时制宜,辨证论治的思想是一脉相承的。因此,本研究提出的“精准”诊疗指将中医的精准性放到数据和数据的相关关系上解读,通过改进和引入机器学习等人工智能方法,对蕴藏中医知识资源丰富的经典文献和中医医案及相关数据信息进行特征提取和可视化梳理,实现对“病―证”的不同状态和阶段的精确分类,找到“症―病―证―治”的精准对应规律,进一步优化辨证论治的医疗过程,提高中医临床疗效,是中医诊疗客观化、规范化、信息化的交叉研究成果。目的:探索中医药多源异构数据融合处理方法,研究中医药文本数据由经验资料转换为客观资料的方法,设计基于文本特征处理的计算方法,实现对中医四诊资料的自动化处理,以量化的方式完成对中医四诊文本数据的辨证论治。以中医文本特征数据为主要研究对象,寻找中医疾病与中医证型间的相关关系,发现中医症状-疾病-证型-治法-方药间的规律和联系,构建以数据驱动思想为指导的中医精准诊疗模型。方法:(1)采集《中医内科学》教材中关于中医病、证的概念、定义、症状、治法和方药信息，采集《中医大辞典》中有关中医名词术语与症状体征要素,进行数据去重、归一化等预处理流程,结合科技部基础性工作专项的相应成果组建中医药多源异构数据集。(2)采用jieba分词工具对中医文本数据进行分词,实现文本数据从非结构化到文本向量的转变。(3)运用TF-IDF算法和TextRank算法分别提取文本向量中的关键词特征,并计算特征权重,运用Precision、Recall、F1评价方法对提取计算结果进行评估选择,山此实现对多源异构数据的融合处理。(4)运用数理分析方法提出一种中医诊疗特征相关性计算方法，并使用Visio Studio 2015+C#语言实现,以相关度表征精准性,能够结合疾病的症状特征、各个疾病对应各个证型的症状特征以及其特征权重,通过特征选择和加权计算的方式,量化辨病和辨证的过程,从而实现辨证论治的客观化,得出精准的辨证论治结果,实现中医精准诊疗实现。(5)采用中医病证结合诊疗模式思想,运用方法(3)将《中医内科学》中的疾病、证型概念和症状表现进行特征提取和权重计算,得到疾病-特征相关关系和疾病-证型-特征相关关系,结合疾病-证型-治法-方药联系分别构建中医辨病模型、中医辨证论治模型,最后结合中医诊疗特征相关性计算方法构建基于数据驱动的中医精准诊疗模型。(6)利用Cytospace软件将模型内容可视化并进行网络拓扑分析。结果:(1)数据采集阶段共获得中医病名69种,对应证型366个,相应治法366条,处方366条,概念名词及症状体征要素22989条,共计138336字,构建了中医药多源异构数据集。(2)使用来自中医诊疗数据集中的“病名”和“概念”两个字段的数据构建中医疾病文本数据集,涵盖了《中医内科学》教科书中69种中医疾病的名称和其相应的疾病定义、症状表现。对中医疾病文本数据集进行分词并使用TF-IDF算法进行特征提取和权重计算,共得到有效特征1271个,权重大于0.6的共241个;使用TextRank算法进行特征提取和权重计算,共得到有效特征862个,权重大于0.6的共534个。经过对两种算法模型结果评价,选用TextRank算法模型的结果作为构建中医辨病模型的数据。在完成疾病特征提取和权重计算后,通过特征将疾病有机地联系起来,用于探索病和病之间的关系,将TextRank算法模型计算的结果导入cytoscape软件中,以中医病名作为target结点,特征作为source结点,权重作为边,完成建立了感冒疾病特征网络、肺系疾病特征网络和全部疾病特征网络。(3)使用自中医诊疗数据集中的“病名”、“证型”、“症状”、“治法”、“方药”五个字段,涵盖了《中医内科学》教科书中69种中医疾病的名称、366个证型的全部概念、症状以及相应治法方药信息数据构建中医证型文本数据集,对中医证型文本数据分词并使用TF-1DF算法共得到有效特征6194个,权重大于0.6的共741个,使用TextRank算法共得到有效特征3490个,权重大于0.6的共2553个。在对两个模型结果进行评估后,虽然TextRank和TF-IDF在提取特征词上都具有较高的准确率,但TextRank对特征提取的数量远不如TF-IDF多,综合考虑到在后期精准模型计算中权重亦是主要影响因素,鉴于TextRank计算的权重较高,故构建辨证论治模型时选用TextRank提取的特征和权重作为模型基础数据。在完成证型相关特征提取和权重计算后,通过特征将各类疾病和各种整形有机联系起来,用于探索病和证之间的关系,将TextRank算法模型计算的结果导入cytoscape软件中,以中医证型作为target结点,特征作为source结点,权重作为边,分别建立感冒的证型特征网络、肺系疾病的证型特征网络、中医内科学全部证型特征网络以及疾病特征网络与证型特征网络的融合网络,最终得到“病-证-特征”的关联网络,能够从特征匹配和权重计算入手完成辨证论治的流程。(4)基于数据驱动的中医精准诊疗模型是在中医辨病模型和中医病证结合辨证论治模型的基础上,融合中医诊疗特征相关性算法而成。中医诊疗模型的精准性通过中医诊疗相关性算法中的相关度体现,就是将这种主观判断的过程使用量化的方式进行计算,使辨证论治过程由计算概率转变为计算相关性,最终将相关度作为精准性的评价参考。通过输入中医四诊资料,模型能够自动分析资料中相关的中医特征,通过中医辨病模型和辨证论治模型进行辨病和辨证,并通过相关性算法计算得到最终的辨证论治结果。经3种类型中医病案测试,分别达到完全正确、有所偏差、部分正确的辨证论治结果;经60例名中医医案样本测试,发现基于《中医内科学》教材数据构建的模型对近代中医医案诊断精准度为10%,对现代中医医案诊断精准度为60%,模型精准性符合预期,可以实现针对多源异构文本数据的辨证论治。(5)本研究在以下方面有所创新:a.通过建立中医专有词汇数据字典,引入jieba工具对中医文本数据进行中文分词,使用TF-IDF算法和TextRank算法提取分词结果中的中医关键词特征并计算特征权重,实现中医文本数据向量化。b.首次提出了一种基于中医文本特征和特征权重的中医诊疗特征相关性计算方法,通过计算向量化的文本特征数目和特征权重，可以获得特征集合与中医各个病、证之间的相关性,从而建立基于特征和权重的中医病-证相关关系。c.基于数据驱动的思想构建了动态开放的中医精准诊疗模型,以中医病证结合诊疗模式为基本结构,由辨病模型、辨证论治模型和相关性计算模块三个部分有机组成,对向量化的中医四诊资料先辨病再辨证,并通过计算四诊资料与病和证的相关性实现精准诊疗,最终输出四诊资料对应的中医病名、证型、治法和方药。结论:(1)中文分词是研究中医药大数据的一项重要方法和工具,中医的描述性语言可以通过中文义木分词的方式由句子变为词汇,从而让计算机更容易“理解”文本数据。(2)TF-IDF算法和TextRank算法能够提取中医文本数据中的特征关键词,并可以计算特征的权重,TF-IDF可以提取出更多的特征,但是权值的平均值较低,TextRank提取的特征数目没有TF-IDF多,但权值的平均值较高。(3)通过构建基于特征的中医辨病模型和辨证论治模型,发现中医各个疾病、各个证型之间都存在强弱不一的相关关系,通过计算其相关性可以将中医各个疾病、证型有机地联系起来,实现了中医诊疗的客观化表达,同时验证了中医“整体观念”思想。(4)本研究构建的中医辨病模型和中医辨证论治模型可以通过对中医四诊资料的特征匹配和权值计算的方式完成中医辨病和辨证论治过程,整个过程均可回溯,且每个流程均以量化的方式进行。(5)基于数据驱动思想设计的中医诊疗模型能够实现对中医药多源异构的处理,能够在有监督的条件下学习中医“理、法、方、药”知识,实现中医人工智能。该模型可以理解描述性中医四诊资料,并自动从中提取辨证论治过程中所需的文本资料,经过特征提取和相关性计算后,能够输出四诊资料的诊疗结果,为中医诊疗的客观化、规范化、信息化研究做出了一定贡献。"
1476,面向5G的光与无线融合接入网智能控制技术研究,"近年来,随着第五代移动通信(5G)技术的快速发展,接入网呈现出宽带化、多样化、融合化的趋势。此外,为了满足实时性5G业务的超低延时需求,边缘计算的概念应运而生。光与无线融合的云化接入网架构成为5G前传和回传网络的重要组网形式。同时,用户需求和应用场景的多样化对融合接入网的业务灵活承载和资源智能管控提出了新的需求,特别是超可靠低时延业务、物联网、工业控制网络等新兴业务,需要光和无线融合接入网提供更为优质的服务保障。因此,如何利用智能化管控技术合理有效调配资源,为5G的新兴业务提供更优化的网络服务,是光和无线融合接入网待解决的关键问题。此外,绿色低成本也是一个重要发展趋势,如何利用智能化的资源编排提升网络资源利用率,减少网络资源消耗也是需要光和无线融合接入网亟待解决的问题。因此,本论文围绕面向5G的光与无线融合接入网的智能控制技术展开研究。主要创新点如下:1)针对5G移动光前传网可扩展性差、资源管理僵化的问题,提出了一种光和无线一体化资源调度方案及相应的负载均衡的动态波长共享算法。仿真结果表明所提算法能够实现异构资源的联合调度和多业务的QoS保障,同时能提升多波长之间的负载均衡性能。2)针对5G网络中低时延和边缘计算的需求,提出了一种基于分层边缘云的移动光前传网络架构及相应的基于流量卸载的低时延保障方案,所提方案将时延敏感业务尽可能地本地化处理。仿真结果表明,所提方案时在高负载条件下能够实现80%的时延减少率,同时能减少时延抖动和前传带宽的占用率。3)针对5G网络超低时延业务需求,基于上述分层边缘云的移动光前传网络架构,提出了一种基于负载感知的动态流量迁移策略和资源编排方案,并搭建了基于OpenFlow的软件定义网络(SDN)移动光前传网络实验平台。实验结果表明:所提方案能够实现分层边缘云移动光前传网中边缘云、移动边缘计算以及光带宽资源的按需分配和动态编排,进而保障业务的低时延并提升网络资源利用率,该方案能够使时延性减少50%-80%,抖动减少50%-75%。在低负载条件下,前传带宽资源的占用最高能够减少38%。4)现有的“一刀切”网络架构不能为多业务场景提供灵活的可定制化的资源保障。针对现有5G移动光前传网的资源供应缺乏弹性且网络资源利用率低的问题,提出了一种基于分层边缘云的移动光前传网络切片方案,及相应的基于混合整数线性规划(MILP)的一体化网络资源管理算法。仿真结果表明,提出的方案和算法能够有效实现异构资源的灵活分配和编排,且能够灵活地满足不同切片间的QoS需求,对于超可靠低时延切片,其端到端时延能维持在2ms,此外,最高能使前传网络带宽资源释放21%。5)针对现有光传输网络缺乏智能决策能力并且资源供应不及时的问题,面向未来5G的城域汇聚网,提出了一种使用人工智能技术的负载感知网络切片方案,及相应的基于人工智能的流量预测算法,实验结果表明,流量预测算法具有较高的预测精度,同时网络切片方案能减少57%的阻塞率和18.2%的能耗。"
1477,基于深度学习的线粒体受药和病态细胞识别,"据观察线粒体疾病一般是由线粒体DNA或天然DNA的遗传或突变引起的,这些疾病会使线粒体中的蛋白质或RNA分子的原始功能受到影响。线粒体细胞疾病有可能干扰生物体的正常功能,甚至导致生物体死亡,因此,有必要对线粒体细胞疾病进行检测,找出预防措施。通过线粒体细胞显微图像可以检测出其细胞形态,综合分析这些图像可以用来检测患病细胞,进而对线粒体疾病的未来行为进行预测与分类。面对这一问题人眼难以准确分辨这些细胞图像中的细微差别,而人工智能可以在检测这些图像中隐藏的固有模式方面发挥重要作用,通过对显微镜图像数据智能化分析,可以提前识别疾病,从而为临床和疾病问题提供解决方案。鉴于正常和受影响的线粒体细胞具有不同的形态特征,疾病改变了线粒体细胞的形态,检测细胞形态的变化以及与此变化相关的时间具有重要的生物学意义。我们主要研究分析线粒体细胞的显微图像,主要研究成果和创新点如下:1提出了一种正常的和药物处理的细胞图像关联分析算法,简称为IC。实验结果表明,该方法具有较好的相关性。2.提出了一种基于卷积神经网络的正常和药物处理的细胞图像识别算法・通过实验验证了分类的准确性,并与传统的方法进行了比较。3.分析了正常细胞与疾病细胞的差异,提出了一种基于卷积神经网络的正常和疾病细胞的分类算法,并通过实验验证了该算法的有效性。4.分析了线粒体细胞动力学,提出了一种线粒体细胞器运动分类算法(MOMC)。细胞的行为可以通过组织形态发生来描述,包括组织的迁移、分裂或死亡,并受分子尺度的调节。从显微图像中自动检测细胞已成为细胞基础实验的一个重要步骤。我们设计了一种融合了K-Means、贝叶斯分类器和灰度阈值等方法的研究方案,对实时图像中的线粒体细胞形态变化进行分类。该方案包括以下步骤:首先将RGB图像转换成灰度图像,然后利用非锐化滤波器对图像进行调整,再应用0.65的全局阈值,得到一个候选细胞质的黑白晶体图像,并计算出细胞质特征,最后进行细胞质裁剪,结合200x200像素,寻找候选核。细胞受药物影响,包括药物的作用、粘度和药物治疗细胞的强度等,是进化生物学与精确医学领域的一项关键课题。由于受到药物影响的细胞数量非常大,始终困扰着该领域的研究。针对这一问题,本文设计了一个基于深度学习的框架DNCIC(Drug and normal cell image classification)可以准确预测正常线粒体和很少观察到的药物影响细胞。为了进行优化,我们使用共焦显微镜线粒体图像数据集对卷积神经网络进行训练,并用正常和受影响的细胞图像对算法进行了验证。我们训练的CNN模型对TPEF(双光子激发荧光探针)图像进行分类(正常细胞和受影响细胞),准确率可达到98%。本研究结果为药物影响细胞的诊断提供了依据。细胞分类是指从线粒体图像中检测正常和患病细胞。在生命体中,有些细胞可能属于不同的类别,使得难以对细胞进行准确分类。目前最先进的细胞分类方法是基于肿瘤细胞分类而发展起来的,并不适用于疾病细胞和正常细胞的分类。本文研究了两种被广泛用于分类和区分正常和疾病细胞方法的性能。数以百万计的正常细胞受到控制性生长,不受控制的生长可能与疾病的原因有关,但由于难以区分正常细胞和患病细胞,其临床应用仍然有限。现有研究仅限于系统地鉴定正常和患病的细胞。本文提出深度分类网络NDCC(Normal and diseased cell classification)用于收集病态和正常细胞的信息,以及准确的细胞分类和去除假阳性的验证网络。通过综合使用机器学习方法、逻辑回归(LR)、支持向屋机(SVM)和卷积神经网络(CNN).成功发现CNN对正常和患病细胞进行了更好的分类。利用正常细胞和患病细胞这两种类型的图像,我们训练了一种卷积神经网络,该网络能以98%的准确率识别患病细胞,并能发现正常细胞和患病细胞,进一步提高了人类患病细胞的临床应用。线粒体是高度动态的细胞器,能够在几秒钟内改变大小、形状和位置。线粒体细胞器运动是指找到分裂和融合的问题,并为细胞产生能量。为了解决线粒体细胞运动分类的问题,本文提出一种利用卷积神经网络进行线粒体运动分类的深度学习方法MOMC(Mitochondrial organelle movement classification)。该方法包含三个阶段:1)首先通过GoogLeNet提取局部特征描述,然后通过ResNet-50生成中间层特征,2)通过lnception-V3模型生成全局描述符特征,3)线粒体细胞器运动位置的最终分类。"
1478,基于MRI结构成像与静息态功能成像影像特征的机器学习法在AIDS患者中的应用研究,"第一部分AIDS患者认知障碍程度与感染严重程度的相关性研究目的:研究AIDS患者认知障碍程度与感染严重程度的相关性。材料和方法:按照纳入排除标准,收集20l7年09月至20l9年1月期间首诊于南宁市第四人民医院感染科未行抗病毒治疗的新发AIDS患者29例(16位男性,13位女性)、年龄和性别相匹配的正常人志愿者20例(12位男性,8位女性)作为研究对象。排除49例受试者中并发脑萎缩、蛛网膜囊肿、颅内感染、运动伪影过大无法配合的8例,最终纳入AIDS组27例(14位男性,13位女性,年龄范围22-63岁,平均年龄42.48±13.03岁);正常人志愿者中14例纳入对照组(8位男性,6位女性,年龄范围22-63岁,平均年龄39.0±13.02岁)。收集入选的27例患者的实验室检查指标(外周血CD4+T细胞计数及CD8+T细胞计数);采用简易智能量表(MMSE)和神经心理测评(NP)法对受试者进行评分和测试,根据评分和测试结果将AIDS患者进行认知障碍程度分组;AIDS患者组共有认知正常的22例,认知障碍5例(其中轻度认知障碍2例,中度认知障碍3例),而对照组简易智能量表测试均认知障碍正常。AIDS组神经心理测评UN组为9例,ANI及MND组为6例,HAD组为12例。用spss19.0统计软件,患者的感染程度(CD4+T细胞计数、CD4+T与CD8+T细胞计数比值)与认知分组(MMSE法、NP法)及临床量表进行相关性分析。分别以CD4+T细胞计数、CD4+T细胞计数与CD8+T细胞计数比值作为因变量与各项神经测量测评作为自变量进行多元回归分析。结果:(1)各AIDS组的字色干扰实验(Stroop C)完成时间与CD4+T细胞计数呈中度负相关关系(P=0.004,r=-0.535),各AIDS组的NP法得到的认知分组与CD4+T细胞计数呈中度负相关关系(p=0.02,r=-0.444)。(2)各AIDS组的字色干扰实验(Stroop C)完成时间与CD4+T细胞计数/CD8+T细胞计数呈中度负相关关系(P=0.034,r=-0.409)。各AIDS组的NP法得到认知分组与CD4+T细胞计数/CD8+T细胞计数呈中度负相关关系(P=0.005,r=-0.527)。(3)在CD4+T细胞计数的多元回归性分析中,分别是字色干扰实验(SC时间)和词汇流畅性实验(组词)进入回归方程。在CD4+T细胞计数与CD8+T细胞计数比值的多元回归分析中,字色干扰实验(SC时间)进入回归方程。结论:AIDS组认知障碍程度和病情的严重程度存在相关性;其中,字色干扰实验(SC时间)与感染严重程度有相关性。第二部分基于机器学习法在AIDS患者磁共振技术测量脑灰质体积的应用价值研究目的:运用基于机器学习方法的磁共振结构成像,探究灰质体积在评估HIV相关神经认知障碍中的诊断价值以及各脑区灰质体积与各临床指标相关性的分析研究。材料和方法:研究对象的纳入排除标准同第一部分。所有受试者均为右利手并签署磁共振检查知情同意书,采用GE Discovery MR 750w 3.0T磁共振扫描仪进行扫描。行常规轴位T1WI扫描、轴位T2WI扫描及矢状位T1加权(Sag3D T1WI-BRAVO)薄层扫描。图像预处理使用SPM12和DPARSF3.1两个软件,正式处理使用PRoNTo2.1.1机器学习工具包和DPARSF3.1以提取灰质体积值及图像数据分析。使用SPSS19.0统计软件分析90个大脑脑区灰质体积指标在HAND组和非HAND组的差异。使用SPSS19.0统计软件进行正常组和AIDS组差异最大前十位大脑区域灰质体积值与临床血液学、临床量表及认知评分、分组的相关性分析。结果:(1)AIDS患者与对照组脑灰质结果差异贡献最大的十个大脑区域,依次是右侧中央后回、左侧顶上回、右侧中央旁小叶、右侧补充运动区、左侧顶下缘角回、左侧颞横回、右侧顶下缘角回、右侧顶上回、右侧中央盖沟、左侧缘上回。(2)灰质体积指标分类效果评价的AUC值为0.73,准确率为70.73%,敏感度为85.19%、特异度为42.86%、正预测值为74.19%、负预测值为60.00%。(3)灰质体积指标对区别HAND组及非HAND组有意义。(4)前十位大脑区域的灰质体积指标与临床血液学、临床量表及认知评分、分组有不同程度的相关性。结论:机器学习法在基于磁共振的AIDS患者的脑灰质体积测量的分类有意义。AIDS患者组和对照组有差异的位于前十位的大脑区域主要集中在双侧额叶、双侧顶叶、左侧颞叶。灰质体积指标可以用于诊断HAND,磁共振结构成像的检查可以为临床诊断HAND提供客观的检查方法,磁共振结构成像的检查可以对治疗效果提供客观的评价指标,从而达到降低HAND发生和发展的目的。第三部分机器学习法在AIDS患者静息态功能磁共振成像中脑网络连接指标度中心度、对称体素同伦连接的应用价值研究目的:运用基于机器学习方法的磁共振静息态功能成像,探究DC值和VMHC值分别在评估HIV相关神经认知障碍中的诊断价值以及各脑区DC值和VMHC值分别与各临床指标相关性的分析研究。材料和方法:研究对象的纳入排除标准同第一部分。所有受试者均为右利手并签署磁共振检查知情同意书,采用GE Discovery MR 750w 3.0T磁共振扫描仪进行扫描。行常规轴位T1WI扫描、轴位T2WI扫描、静息态功能磁共振(rs-fMRI)扫描、矢状位T1加权(Sag3D T1WI-BRAVO)薄层扫描。图像处理方法同第二部分。统计处理同第二部分。结果:(1)DC指标在AIDS患者与对照组结果差异贡献最大的十个大脑区域依次是:右侧中央旁小叶、左侧中央旁小叶、右侧枕上回、右侧运动补充区、右侧楔叶、左侧楔叶、左侧顶上回、左侧楔前叶、左侧运动补充区、右侧中央后回。(2)VMHC指标在AIDS患者与对照组结果差异贡献最大的十个大脑区域依次是:左侧中央旁小叶、右侧中央旁小叶、右侧运动补充区、右侧楔前叶、左侧楔前叶、右侧顶下缘角回、左侧运动补充区、左侧尾状核、右侧中央后回、左侧颞横回。(3)DC、VMHC指标分类效果的评价如下:DC指标的AUC值为0.60,准确率为65.85%,敏感度为100%、特异度为0%、正预测值为65.85%、负预测值为0%。VMHC指标的AUC值为0.59,准确率为68.85%,敏感度为92.59%、特异度为14.29%、正预测值为67.57%、负预测值为50.00%。(4)DC指标对区别HAND组及非HAND组有意义,VMHC指标对区别HAND组及非HAND组无意义。(5)前十位大脑区域的DC值、VMHC值分别部分与临床血液学、临床量表及认知评分、分组有不同程度的相关性。结论:机器学习法得出DC指标较VMHC指标诊断效能更高,说明DC指标在AIDS患者中的应用更有意义。基于机器学习方法的静息态功能磁共振成像得到的DC值对于区分HAND和非HAND部分脑区有意义,而反应两侧大脑同步性的VMHC值在区别HAND和非HAND均无意义。这说明HIV相关认知障碍发生与部分脑网络连接节点有关系,而HIV相关认知障碍与两侧大脑同步性的致病调控机制关系不大。前十位脑区的DC值和VMHC值与临床指标(包括血液学、临床量表)和认知分组部分具有的相关性。机器学习法得到的DC值VMHC值能直观的反映认知功能障碍受损的区域和相应功能受损伤的程度,为患者改善临床抗病毒的治疗方案和增加神经认知障碍的干预措施,对降低HAND的发生和发展起到了一定的作用。"
1479,药物互作数据的挖掘与预测研究,"药物研发是一个漫长的过程,一种新药从研发到最终上市会耗费十几年的时间,而期间投入的成本甚至高达上亿美元。随着大数据时代的到来,与药物研发相关的数据呈爆炸式地增长,采用传统的实验手段处理这些数据已变得十分棘手。因此研究者们尝试使用计算的方法来辅助药物研发,解决药物研发中的各种问题。本论文重点围绕药物研发中药物相互作用的相关问题,挖掘潜在的数据关系并进行深入分析,构建相应的预测模型。主要开展基于传统机器学习算法构建蛋白质热点残基的预测模型,以及基于深度学习的算法分别构建药物-靶标相互作用的预测模型和QSAR药物活性筛选模型。药物研发的第一步是确定药物靶点。热点残基在蛋白质相互作用结合界面中起着关键性的作用,常作为潜在的药物靶点应用于药物设计领域中。但是采用实验的方法定位和识别热点残基非常耗时耗力,现已提出了许多基于序列或结构化表征的计算方法用于预测蛋白质热点残基。目前,绝大多数蛋白质的三维结构信息是未知的,这使仅从蛋白质的氨基酸序列中识别热点残基变得更加有意义。本文的研究工作旨在提出一种新的蛋白质序列特征编码方法,用于构建蛋白质热点残基的预测模型。该模型主要将氨基酸序列编码得到的理化特征与溶剂相对可及表面积结合起来,使用集成投票的方法得到最终结果。确定药物靶点后还需要寻找和验证药物与靶标蛋白之间潜在的相互作用关系。所谓的相互作用是指在生物体中靶标蛋白能够与其他小分子(如配体或药物)相结合,且引起生物体行为或功能的变化,产生治疗疾病的作用。本文提出了一个基于深度学习的预测模型,用于鉴定药物与靶标之间的相互作用。深度学习的网络模型有助于提取到更精细、更深层次的药物与靶标间的互作特征,从而进一步提升模型的预测性能。同时,由于药物与靶标互作的负样本数量众多,本文给出了一个较为合理的基于特征距离的负样本选择方法。该方法主要思想是计算每一个可能的负样本与整个正样本集之间的特征距离,若距离越大,则说明其与正样本之间的差距越大,那么该负样本的可靠性就越高。实验结果表明,预测模型在两种不同来源的数据上均表现出较优异的性能,可应用于识别药物-靶标相互作用的研究中。药物相互作用研究的最后一步是筛选出先导化合物。定量构效关系(QSAR)是一种基于配体的药物虚拟筛选方法,是准确识别新的先导化合物的有效方法之一。过去几十年中,在计算机技术的帮助下,QSAR的相关研究工作已取得丰硕成果。近年来,深度学习技术的兴起和大规模可访问化学数据库的出现,为深度学习在QSAR药物活性筛选方面提供了广阔的发展空间。因此,本文设计了一个基于深度学习端到端的预测模型来实现QSAR药物活性筛选,并使用两种训练方案对模型进行评估。该模型中编码-解码化学模型用于生成表征化学分子的中间特征;卷积神经网络结构则以中间特征作为输入向量对模型进行训练得到预测结果。两种训练方案均能证实模型的有效性。综上所述,本文旨在解决药物相互作用研究的相关问题,通过机器学习和深度学习算法,对相关数据进行挖掘和深入分析,寻找其中的潜在关系,构建泛化能力好、鲁棒性较强的预测模型。通过与其他模型比较,本文提出的预测模型均能产生较好的预测性能。因此,本文的研究内容可以为药物研发节约成本,缩短研发周期,同时也可作为药物研发中的辅助工具,为相关实验提供理论指导。"
1480,高压下材料结构和物性的第一性原理研究,"物质在高压下,其结构会发生明显的变化,结构的改变将会导致物质的物理、化学性质做相应改变。压力,作为一个强有力的工具,已被广泛应用于物理、化学、生物和地球物理等学科的研究中。过去很长的一段时间内,高压在研究地球内部结构和行星演化过程上扮演了重要的角色。研究表明:物质在压力下,其内部离子和电子会重新分布,这导致材料内原子之间相互作用的调整;随着压力的增加,许多材料将呈现出新颖的结构并表现出新的现象,例如,磁性转变、金属绝缘体转变、超导转变和弹性性质的转变等等,这些都引起了理论和实验研究者的广泛关注。本文针对材料在高压下的行为(包括结构和性质变化)转变进行研究,采用密度泛函理论(density functional theory,DFT)结合杂化泛函(hybrid functional)的方法研究了高压下铁方镁石中Fe的自旋转变,运用DFT和DFPT方法研究了高压下B掺杂石墨烷的超导转变,运用DFT + U方法研究高压下CeOCl的同构相变机理和电子结构特征;结合DFT和机器学习方法训练得到了适合于高温高压研究的C单质原子势。主要内容如下:1.高压下铁方镁石(Mg1-xFe,x)O中Fe2+自旋态转变压力的研究。我们研究了不同Fe浓度下含铁氧化镁中Fe自旋旋态转变压力,不同的泛函(PBE、PBE+U)所对应的自旋态转变压力具有较大的差别。例如在Fe的浓度为3.125 mol%时,PBE计算的自旋态转变压力为22 GPa,而PBE+U计算得到的自旋态转变压力高达68 GPa。同时PBE的计算结果显示Fe的中间自旋态在一定的压力范围内为基态,与实验结果相悖。为解决自旋态转变压力对泛函及其泛函参数的依赖问题,我们采用HSE杂化泛函方法研究了铁方镁石随着压力的物性变化。计算中采用同一套固定的参数,自洽得到了不同Fe浓度相对应的自旋态转变压力。我们的计算结果显示,Fe的自旋态转变压力整体上呈随着Fe浓度增加而增大的趋势,例如我们得到(Mg0.06875Fe003125)O和FeO的自旋态转变压力分别为56 GPa和127 GPa,与实验结果吻合。研究结果表明HSE能够在统一的参数框架下精确的描述金属氧化物的自旋态转变行为。2.高压下B掺杂石墨烷的超导电性的研究。我们对高压下稳定的石墨烷结构进行了 B的替位掺杂,基于密度泛函理论的第一性原理总能计算,进行了压力下的结构搜索和优化,得到了具有热力学稳定性的α-、β-和γ-相的B掺杂石墨烷,它们在压力下的相变序为phase-α→phase-β→phase-γ。相关声子谱计算发现phase-γ不具有动力学稳定性,因而在所研究的压力范围内B掺杂石墨烷的稳定相只有α-相和β-广相。对α-相和β-相的电子结构计算显示,该两相不论在常压还是高压下都具有良好的金属性,这也是判断他们是否具有超导电性的前提。在密度泛函微扰理论结合BCS超导理论框架下计算电子声子相互作用,结果发现随着压力增加,α-相和β-相的超导转变温度(Tc)都呈现增大的趋势。例如在10 GPa和100 GPa下,β-相的超导转变温度分别为39 K和77 K。我们的计算结果还表明B-C环对B掺杂石墨烷的超导有着重要的贡献。此外,我们还讨论了化学掺杂和均匀的空穴掺杂对B掺杂石墨烷体系超导的影响。结果表明均匀空穴掺杂会造成体系在倒空间Gamma点产生巨大的声子软化,有效增强了体系的电-声耦合,使得均匀电子空穴掺杂体系的超导转变温度(96 K)在常压下比化学掺杂体系的超导转变温度(45 K)高出1倍之多。3.CeOCl压缩行为和电子结构研究。基于第一性原理方法,我们计算了CeOCl晶体结构在压力下的压缩行为、状态方程及其电子结构。计算结果表明在压力作用下,CeOCl的体积和晶格常数会在3 GPa～6 GPa压力范围内发生不连续变化,但是晶体结构仍然保持为P4/nmm结构,与实验观测到的在压力6 GPa左右发生同构相变一致。为了解释同构相变的发生,我们对CeOCl进行了电荷分析,发现在压力作用下CeOCl会发生Ce电荷向C1和O的转移行为,表明同构相变是由CeOCl内电子结构相变引起的。从第一性原理计算的电子结构,我们发现CeOCl自旋向上和向下的能带分别呈现出间接和直接带隙的特征,其中自旋向上的间接带隙为3.14 eV,与实验结果3.05 eV接近。计算得到的能带结构能够很好地解释CeOCl具有较好的荧光特性。4.运用机器学习神经网络势方法研究碳在高温高压下的物性。人工神经网络原子势计算拥有比第一性原理方法更高的计算效率,以及比经验势更高的计算精度,机器学习拟合原子势能面构筑高精度的原子相互作用势在过去的十几年中已经得到了一定的发展。我们使用开源的原子能量网络程序包(aenet)结合分子动力学的方法研究材料在压力下的演化过程。运用第一性原理的方法我们计算了15855个不同密度下的碳单质结构的能量和力参数作为训练数据库,通过使用不同的训练方法对这些能量和力参数进行反复学习和测试,拟合得到适宜于计算高温高压条件下碳的人工神经网络原子势。最后通过比较运用该原子势与DFT计算得到的能量和晶格常数等,得到了具有很高的准确性和适用性的碳的神经网络原子势。"
1481,基于Himawari-8遥感数据的火点探测和自动化云检测的探索,"近几十年来,平均气温上升和昼夜温差变小等长期气候变暖趋势,造成世界各地森林火灾频发。森林火灾是突发性强、破坏性大、难以控制的自然灾害,会对生态系统和人类造成巨大的损失。精准、实时的获取火场信息对于减轻这种灾害的影响至关重要。遥感卫星由于具有成本低、实时性强、覆盖面积广的优势已经成为监测这种灾害的理想工具。在近四十年的时间里,科学家们基于不同的遥感卫星传感器,研制出了许多应用于森林火灾监测和探测的并且在世界各地得到很好验证的算法和火灾产品。然而,当前的火点探测算法存在没有考虑卫星数据的时空特性和火点探测算法中的云识别算法精度不高这两个缺点。本文的研究主题是针对火点探测算法中的两个不足,分别提出了不同的改进方法,目的是获取精度更高的火点探测算法。首先,针对火点探测算法中的第一个不足,当前用于探测的两个主要遥感数据资源具有明显的缺点:地球静止观测(Earth Observation,EO)卫星具有时间分辨率高但空间分辨率低的特点,而极轨卫星具有空间分辨率高但时间分辨率低的特点。因此,基于这两个系统中的现有森林火灾探测算法仅独立地利用时间或空间信息,目前鲜有结合时间和空间特征的方法来检测森林火灾。本文提出一个时空上下文算法(Spatio-Temporal Contextual Model,STCM),该算法充分利用了Himawari-8(海葵八号)地球静止卫星数据的的空间和时间维度。该算法一共分为以下几个部分:首先,提出一种改进的鲁棒拟合算法(Improved Robust Fitting Algorithm,IFRA)来模拟每个像元的长波和红外波段的昼夜温度周期(Diurnal Temperature Cycle,DTC)。其次,对于每个像元,使用卡尔曼滤波器来混合DTC以估计其真实的背景亮温(Brightness Temperature,BT)。随后,我们在使用MVC(NDVI的月合成最大值)阈值测试后利用Otsu方法测试火灾,以测试哪些区域有足够的燃料来支持此类火灾事件。最后,我们使用连续时间测试来校正火灾探测结果,并将其命名为STCM2。该算法应用于201 6年东亚和澳大利亚的4起火灾案例。结果表明:以MODIS Terra和Aqua传统的火点产品(MOD14和MYD14)作为标准验证数据,本文提出的算法有效地利用了多时相遥感数据的时空信息。此外,这种新的森林火灾探测算法比传统的上下文和时间算法具有更高的检测精度。其次,针对火点探测算法中的第二个不足,当前云识别算法的精度对于火点探测的精度影响非常大,但是在火点探测中的云识别算法都是基于人工经验的固定阈值法,这需要大量的先验知识,并且考虑到不同时间、不同地区的应用,设置的阈值往往比较保守,这些云识别算法不能够满足火点探测算法的高精度、高自动化、高鲁棒性的需求。因此本文探索了四种机器学习算法(SVM、kNN、Kmeans、BPNN)与基于人工阈值的动态阈值法和固定阈值法在云识别中的效果。本算法一共分为两个部分,首先选取六种算法中云识别精度最高的算法,随后将此算法带入到前文提出的STCM2火点探测算法中,比较并分析云识别算法的提高对于火点探测算法精度的影响。结果表明:以传统的MODIS云产品(MOD35/MYD35)作为标准验证数据,定性的目视解译和定量的精度评价表明显示四种机器学习的算法(SVM、kNN、Kmeans、BPNN)比基于人工阈值的动态阈值法和固定阈值法效果要好,平均总体精度要高16.74%,误检率要低50.21%。这是由于机器学习算法能够自主的学习云的特征,然而,固定阈值法和动态阈值法其应用的时空范围较大,阈值选择相对保守,所以云识别精度较低。同时,四种机器学习算法中BPNN由于其强大的自主学习特征的能力,表现最好。比表现最差的固定阈值法,总体分类精度高23%,误检率低74.5%。未来云识别算法的发展应该以多特征学习和深度学习两方面去考虑。最后,将六种算法中精度最高的BPNN云识别算法带入到先前的火点探测算法STCM2中,相比于先前的探测结果,漏分误差下降了4.30%,错分误差下降了14.7%,表明较高精度的云识别算法能够大幅度的减少火点识别算法中错误分类的像元,但是对于遗漏的火点像元数目减少较少。这些揭示了海葵传感器的在火点探测中自身的不足,未来可以考虑结合多种传感器优势,开发精度更高的火点探测算法。"
1482,基于机器学习的旋转机械故障诊断方法的研究,"旋转机械设备在冶金、航空、交通、化工、能源等行业广泛地得到应用,且机械结构也正在趋向大型化、重型化、复杂化、精密化、高速化等方向快速地发展。对它进行状态监测和故障诊断是保障现代化工业安全运行的重要手段。近年来,信号处理理论和机器学习理论得到了迅速的发展,为基于机械振动信号分析的故障特征提取及智能故障诊断提供了坚实的理论基础。本文的研究内容主要来源于国家自然科学基金项目“低速重载机械早期故障稀疏特征识别的研究”,并针对项目中的旋转机械设备的核心部件-轴承的早期故障特征提取及智能诊断进行了深入的研究。论文主要研究的内容如下:针对一般工况下的轴承的早期故障特征的提取问题,提出了基于自适应的互补集总经验模态分解(Complementary Ensemble Empirical Mode Decomposition,CEEMD)和完备的CEEMD方法对轴承早期故障引起的冲击信号进行检测,并提取故障的特征频率。通过深入地研究经验模态分解(Empirical Mode Decomposition,EMD)的3个固有缺陷:端点效应、拟合过/欠冲、模态混叠等问题以及它们产生的机理,在CEEMD的基础上嵌入基于最小二乘互相信息的网格搜索算法,对EMD分解过程中添加的白噪声的幅值进行自适应设定,从而抑制EMD的模态混叠问题。并在自适应CEEMD的基础上,继续提出了同伦-最小二乘支持向量双回归和保形分段三次样条插值算法分别用于抑制EMD的端点效应和拟合过/欠冲问题,构造一个完备的CEEMD方法。最后,对仿真及实测信号进行试验,实验结果验证了该方法对早期故障的微冲击信号的检测及特征频率提取方面都优于其他常用方法。针对大型的低速重载机械设备的早期故障特征的提取问题,提出了一种基于Teager能量算子和最优变分模态分解(Optimal Variational Mode Decomposition,OVMD)相结合的早期故障特征提取方法。由于大型的低速重载机械设备的早期故障中的冲击成份极其稀疏和微弱,无法直接地使用信号处理方法进行特征提取。使用Teager能量算子对采集的原始振动信号的故障冲击信号进行增强预处理,并使用变维的混沌鸽群优化算法(Variable Dimension Chaotic Pigeon-inspired Optimization,VDCPIO)构造最优的VMD方法,并使用该方法对增强后的故障振动信号进行重构并提取相应的包络谱。使用该方法对仿真信号和实测的故障信号进行试验和分析,其实验结果表明该方法可以有效地提取出表征故障特征频率的包络谱。针对旋转机械设备在变负荷工况下运行的轴承故障的类型及其对应的受损程度的诊断问题,提出了VMD和相关向量机(Relevance Vector Machine,RVM)相结合的诊断策略。通过引入量子混沌映射对果蝇优化算法(Fruit Fly Optimization Algorithm,FOA)进行改进,可以有效地提升标准果蝇优化算法的全局搜索能力和收敛速度。并使用改进的FOA搜索VMD关键参数的最优组合值[K,α],从而构建一个具有最佳性能的VMD方法。然后,使用最优的VMD提取变负荷工况下轴承的二维边际谱熵,将其作为RVM的学习样本。并采用两种不同的多分类的扩展策略对标准的RVM进行改进,一种是采用“嵌套一对一”的多分类策略来提升RVM的多分类性能,另一种是采用对“变分RVM”进行改进以提升标准RVM的多分类性能。最后,采集轴承在变负载工况下不同故障及不同受损程度的故障信号,并使用最优VMD提取它们的二维边际谱熵,其中,一部分边际谱熵作为改进的RVM的学习样本集,另一部分边际谱熵用于测试,其实验结果表明该方法可以有效地识别出不同的故障类型及其受损的程度。"
1483,基于机器学习的模块化多电平换流器开关器件故障诊断技术研究,"模块化多电平换流器(Modular Multilevel Converter,MMC)以其低谐波、可扩展性好、开关频率低、损耗低等优点,在柔性直流输电、电气传动、新能源并网、静止无功功率发生器(SVG)、有源电力滤波器(APF)、综合潮流控制器(UPFC)等领域得到推广和应用。随着MMC电压等级和容量的提升,桥臂串联的子模块数量已达上百甚至几百之巨。长时间的运行、环境影响、电磁应力的作用,不可避免引发子模块故障,严重影响到系统运行。国内外学者针对MMC系统的直流侧故障、交流侧故障等已有了系列研究,但对子模块故障的诊断与定位研究较少,已有的工作建立在每个子模块配置有传感器和独立诊断单元的前提下。每个子模块配置传感器和独立诊断单元,对于超高电平情况下增加了硬件成本,如何实现少传感器模式下MMC子模块故障诊断与定位,具有重要的理论意义和应用价值。本文在剖析了MMC的基本拓扑结构、工作原理、故障模式的基础上,重点分析了MMC子模块的几种故障形式,并且介绍了其故障后对MMC系统带来的影响。针对子模块开关器件的故障展开了重点研究,提出利用机器学习的方法对子模块开关器件的开路故障进行故障检测及定位。具体研究内容如下:(1)MMC系统无论是正常运行,还是有子模块发生开路故障,总会有三相环流存在于系统内部。而这种环流又无法通过一般的抑制策略实现完全消除,且同三相中的电流数据一样,在两种运行状态下具有明显的差异性。因此,将MMC系统的三相环流及电流信号作为故障特征信号,提出一种基于混合核支持张量机的故障诊断方法,在MATLAB/Simulink中建立MMC仿真模型,构建正常系统及单相子模块发生故障的系统进行仿真研究。根据仿真结果验证所提方法的正确性。(2)探究了在较高电平状态下,MMC子模块故障对三相交流电流带来的影响。经分析可知,不同桥臂间子模块的故障会对三相交流电流带来不同的变化,且电平数越高,单个子模块故障对交流电流带来的影响越微弱,其故障相电流输出变化与正常相相比越不明显。因此,需要更精确更灵敏的故障检测方法来进行故障诊断。将采集到的交流信号进行滤波处理后,进行包络均值的求取,将所得的信号作为最小二乘互信息谱聚类的训练集,得到分类标签。然后将训练样本输入到整体最小二乘支持向量机进行训练以获得决策函数,通过决策输出值可以判断故障相。在RT-LAB半实物仿真平台里对201电平MMC系统进行正常及单相子模块故障进行仿真研究,仿真结果验证分类的正确性和有效性。(3)针对MMC发生多相子模块故障的情形,仅仅利用电压电流的时域数据信息量太少,无法实现准确的故障检测。因此,首先利用快速傅里叶变换(Fast Fourier transform,FFT)将各相电压的时域信号转换成易于分析的频域信号,根据频域信号的变化特点,利用多分类相关向量机将所得的数据进行多相故障分类。建立MMC仿真平台,验证了该方法的有效性和正确性。(4)当子模块故障定位到具体桥臂后,需要对具体的子模块进行故障定位。常规的每个子模块都配有一个电压传感器,为避免使用大量的电压传感器,探索利用机器学习的方法直接利用各桥臂的电压变化定位到具体的桥臂。本文在分析桥臂电压数据变化的基础上,提出基于深度学习的方法,对正常及有子模块发生开路故障时的桥臂电压数据进行训练及测试,将故障定位到具体的子模块。"
1484,耕地数量与质量时空变化遥感监测研究,"耕地数量及质量是决定农业生产、农业资源利用及农业政策制定的重要基础信息。高精度的耕地空间分布、多层面的耕地利用格局及变化特征、动态的耕地质量状况及变化规律对农情监测、田间管理和粮食安全都有着重大的意义。遥感技术因其大范围、高时效的优势,已广泛应用于耕地分布制图、耕地利用格局分析及耕地质量时空变化监测的研究中,但在耕地制图方法选取、耕地利用格局指标体系构建及耕地质量指标动态变化获取上仍然存在一些问题与挑战。本研究以中国及湖北省为研究区,采用多源遥感数据、气象及地形数据、耕地及土壤样本数据、农业统计数据,围绕耕地数量及质量开展大区域时空变化遥感监测方法研究。在耕地数量研究的基础上深入进行耕地质量研究,并对两者之间的关系进行综合分析。本论文主要研究内容与结论如下:(1)多源遥感数据融合耕地制图。基于地理加权回归模型(GWR)和优化模糊一致性打分法(MFAS),采用七套地表覆盖遥感数据集进行中国区域的耕地融合制图。从训练样本数量、输入遥感数据集质量和地形地貌三方面设置不同情景组合,分析不同数据融合方法的优缺点和区域适宜性,提出融合算法选择策略并得到中国最优耕地分布图。研究结果表明,训练样本数量、输入耕地遥感数据集质量和地形地貌是决定多源遥感数据融合算法精度的三大主要影响因素。方法的选择取决于输入数据、景观地形和应用目的。训练样本数量大小是决定GWR融合精度是否高于MFAS融合精度的关键。MFAS方法对于输入耕地遥感数据集的质量和地形地貌变化更为敏感。从生产用于全球经济、生物物理和其他土地利用模型的全球或区域大尺度耕地分布图这一角度而言,MFAS是最优的选择。从生产高精度大尺度耕地比例图及分布图这一角度而言,GWR是最优的选择。(2)多层面耕地利用格局指标体系构建及时空变化分析。基于空间分辨率30米的GlobeLand30数据,计算耕地空间分布及变化、耕地面积及变化、耕地类型转移变化、耕地集约化程度及变化、耕地景观格局及变化等一系列指标。建立多层面高精度的中国耕地利用格局及变化指标体系,系统全面认识中国耕地及其变化情况。研究结果表明,2000-2010年,中国耕地面积减少且伴随着破碎化加重的趋势。现有的耕地保护政策并没有有效缓解这一问题。城市化为耕地流失且破碎的第一大原因,“退耕还林”为耕地流失的第二大原因。与耕地面积和破碎度上出现的消极状态相比,中国的耕地利用集约化程度有了积极而显著的提升。(3)基于机器学习的耕地质量时空变化遥感监测方法研究。选取土壤有机质(SOM)作为耕地质量指标的代表进行方法探索。利用时序MOD09A1数据、气象及地形数据,计算MODIS地表反射率和植被指数的年平均值和最大值、坡度、坡向和地形湿度指数。利用四种机器学习算法预测湖北省多年耕地SOM空间分布并分析其时空变化规律。实现耕地质量指标的动态遥感提取。并分析湖北省耕地数量及质量时空变化之间的关系。研究结果表明,MODIS数据的地表反射率和植被指数是SOM含量预测的关键因素。梯度提升回归树模型对于湖北省的耕地SOM含量空间分布预测效果最佳。湖北省耕地SOM含量“南高北低”,2000-2017年SOM含量总体呈现略微增长。鄂北大量SOM含量较低的土地在近18年间被开垦为耕地,而鄂东地区的优质耕地由于土地利用变化(如城市化)的影响而流失。"
1485,基于深度学习的药物重定位方法研究,"应用机器学习的药物设计早已是药物研究中的重要方法之一,而近年来随着深度学习在各个领域的成功应用,将与深度学习的相关框架应用在药物重定位是一个值得研究的问题。本论文中通过组合深度结构与药物有关的各种属性信息进行模式挖掘,期望找到在一些相关应用中的药物候选物的发现策略,从而能够在一定程度上加快药物重定位的研发速度。本文的具体内容包括以下四个方面:(1)根据药物与靶标活性信息、靶标蛋白特征信息以及药物分子结构信息进行活性小分子的推荐算法研究。在这一部分中,首先将基于项目的协同过滤推荐算法应用在活性小分子推荐中,然后利用AEuserbasedCF模型对推荐结果进行提升。在AEuserbasedCF模型中,首先将深度学习中的AE模型应用在靶标蛋白特征信息的降维中,然后把降维后的数据加入到基于用户的协同过滤推荐算法中,通过与之前没有加入降维信息的普通UserbasedCF对比发现其推荐精度有了显著提高;之后提出HybridSimCF模型重点解决推荐系统中的冷启动问题,具体是通过基于配体特征的方法进行改进,提取药物分子的2D结构信息并进行深度模型的降维处理,然后依据该数据计算药物小分子的相似度后,再进行活性小分子推荐。(2)根据药物与疾病的关系进行深度学习的算法研究。将药物与疾病分别映射为复杂网络中二部分网络的两个不同节点集合,由此将药物重定位问题转化为复杂网络的链接预测问题,然后应用受限波尔兹曼机(RBM)模型在该数据集上建模,与该领域中的其他算法比较AUC值发现RBM对于药物与疾病关系的潜在模式挖掘具有优势,在实验中仅是通过对于药物与疾病的二部分关系网络进行建模而不添加其他信息,其预测精度就要比其他算法有所提高,对于预测结果中的一些候选药物在相关数据库和文献中也得到应证,该实验结果说明药物与疾病的关系虽然是复杂网络,但有自身的分布特征,利用深度学习方法探索其内部特征是有实践意义的;之后再根据复杂网络中链路预测的主要指导思想,即“节点越相似,则越可能产生链接”,提取对于局部节点的特征描述数据并基于原有关系组成有标签的数据集,在该数据集上使用NN_RBM模型进行有监督学习,同时通过增加冲量的方法加快模型的训练过程,从而得到可预测链接的最优模型。(3)将药物、蛋白、副作用等相关属性加入药物与疾病的关系后进行推荐算法研究。考虑到药物的三种属性数据均有自身的分布模式与信息特征,因此在运用基于用户的协同过滤推荐算法之前,对药物信息进行有效的降维和特征提取。本文中通过两个深度框架Deep_Framework_1和Deep_Framework_2对药物属性信息进行提取,再通过与传统PCA方法对比发现两种不同的降维框架都可以在降维的同时更多地提取到原数据中潜在信息,其中Deep_Framework_2的模型表现更好。对于提取后的数据进行相似度计算后,与药物与疾病的评分矩阵一起进行基于用户的协同过滤的推荐,然后将实验计算的的数据集中所有药物Top20的推荐结果通过网页展示出来,以供研究者进行查询和进一步分析。(4)将基于多任务DBN模型应用在的药物重定位的预测中。药物重定位中的一个指导思想是:当药物被发现可以重定位某类疾病时,该药物的副作用越少则越有可能被选中进入下一步的实验。由于大部分药物在作用于人体时均会产生副作用,而有的药物副作用更有可能多达上百个,因此当为药物找到新适应症后,还需要对比药物的副作用情况。通过分析发现该任务非常适用于机器学习中的多任务学习方法解决,因此在将疾病和副作用分别进行分类整理后,应用MNN模型与MDBN模型分别进行学习预测,通过对任务分配不同权重后对比模型的计算结果发现,基于MDBN模型非常适用于药物重定位的任务,其在预测药物候选物时具有更好更稳定的效果。通过以上四个方面,本文将深度学习方法成功应用在药物重定位领域的候选药物推荐中。虽然药物发现是一个耗时费力的过程,然而通过本文的所有实验证明新兴的深度学习作为一个研究工具,对于药物重定位有很大的促进作用,对于提高药物重定位速度,降低研发成本等方面均有非常重要的实践意义。"
1486,基于网络测量的移动视频业务质量评估方法,"随着移动网络的发展,网络带宽的增加,视频的业务量已经在网络中占据了主导地位,并且仍然呈现出持续增长的趋势。因此,对于网络运营商来说评估网络中的视频业务质量对于保证视频业务的用户体验质量(Quality of Experience,QoE),管理和优化网络至关重要。网络运营商从网络侧评估视频业务质量主要面临着以下两方面的问题:(l)HTTP自适应流媒体(HTTP Adaptive Streaming,HAS)技术的应用导致无法直接使用网络服务质量(Quality of Service,QoS)参数对视频业务质量进行评估;(2)端到端加密技术的广泛应用导致深度包解析(Deep Packet Inspection,DPI)技术失效,网络运营商无法通过解析视频内容实现对视频业务质量的评估,甚至无法识别加密视频业务流。因此,在HAS技术和端到端加密技术广泛应用的背景下,我们从移动网络运营商的角度出发,围绕视频业务质量评估的关键问题展开,主要研究以下几个方面的内容:1)针对HAS视频业务流识别,本文提出了基于软动态时间规整的DWN模型,通过提取视频业务的流模式特征,首先结合传统的业务流统计特征从包含多种类别的业务流中识别视频类业务,然后根据流模式特征的差异性实现对不同类别,即采用不同传输技术的视频业务分类,从而完成HAS视频业务流的识别。DWN模型以网络层QoS参数的时间序列为输入提取业务流模式特征,能够有效地识别HAS视频业务流,并且广泛地适用于各种加密场景。2)针对非加密HAS视频业务质量评估,本文提出了基于播放器模型和机器学习的混合视频业务质量评估方法。首先采用机器学习算法对视频业务质量进行整体性评估,如视频是否存在卡顿等质量问题,然后针对存在卡顿的视频采用基于播放器模型的方法重构播放过程,评估视频的卡顿发生时间及卡顿时长,实现对视频业务质量的精细化评估。混合方法首先排除了大量不存在质量问题的视频,减少了需要重构播放过程的视频数量,在保证一定的准确率前提下降低了视频业务质量评估的复杂度,同时满足整体性和精细化视频业务质量评估的需求。3)针对加密HAS视频业务质量的整体性评估,本文提出了利用网络数据流构造协议独立特征量的视频业务质量评估方法,从网络QoS参数中估计HAS视频分段后,通过提取播放器缓冲区状态参数相关的特征量,并结合视频分段的统计特征,使用机器学习算法实现对加密HAS视频业务质量的整体性评估:估计初始缓冲时延,并回答关于卡顿评估的三个问题:视频是否发生卡顿;视频是否发生多次卡顿;视频卡顿时长占比是否超过播放时长的10%。基于协议独立特征量的方法充分考虑了HAS视频业务的自身特点,并结合了传统的基于播放器模型以及基于流统计特征方法的优点,以视频业务下载速率的时间序列为主要分析对象提取特征,充分保证了所提取特征的有效性和协议独立性。4)针对加密视频业务质量的精细化评估,本文提出了基于Attention机制的AHMM实现对视频业务质量的精细化评估。以视频下载速率的时间序列为观测序列,以视频的播放状态序列为隐状态序列,本文首先将视频的整个播放过程建模为隐马尔可夫模型,然后在传统隐马尔可夫模型的基础上引入并修改了Attention机制实现对转移概率的计算,解决转移概率的时间依赖性问题。AHMM模型是一个端到端模型,以视频下载速率时间序列为输入,通过维特比算法解码输出视频的播放状态序列,实现对视频业务质量的精细化评估。解码过程中通过控制维特比算法的译码深度,AHMM可应用于实时或准实时场景。本文以自主开发的数据采集平台为基础,从移动网络中采集的视频业务数据为支撑,围绕移动网络中视频业务质量评估的相关问题展开。通过上述四个研究内容,本文解决了视频业务质量评估过程中的加密HAS视频业务流识别,非加密和加密视频业务质量整体性和精细化评估问题,对运营商保证视频业务的用户体验,管理和优化网络具有重要意义。"
1487,基于深度学习的焊缝图像缺陷识别方法研究,"焊接作为一种基本的工件连接方法,其质量的好坏直接影响到结构的使用性能。随着工业的高速发展和竞争压力的增大,焊接的质量受到人们越来越多的关注。因此,对于X射线焊缝图像进行专业的解释和评定变得异常重要。人工评片由于受到多种主观因素的影响,而逐渐被人们淘汰。随着大数据时代的到来,数据的获取变得更加容易,从而使人工评片的工作强度变得更大。因此,关于自动识别X射线焊缝图像中的缺陷的研究受到了广泛的关注。目前缺陷的自动识别技术主要是依靠传统图像处理、手工特征提取和模式识别三大步骤。但是这里的手工特征设计依靠专业知识、经验,并且操作繁琐,人工干预的成分较多,难以达到真正的智能。另外,提取出的特征可能数量较多,通常还要进行特征的选择。最后经传统的模式识别方法进行分类。上述这些主要的步骤通常是独立进行的,很难进行联合的优化。近年来,随着计算机的飞速发展,基于计算机的视觉技术,如稀疏表示和深度学习为在光学图像上自动识别目标的研究打开了新的思路。尤其是深度学习在自然图像识别与分类上获得的巨大成功,促使人们尝试将其应用于工业检测中。但是,目前深度学习在X射线焊缝图像上的应用还比较少。本文以X射线焊缝图像为研究对象,对稀疏表示、深层表示学习算法进行了深入的研究,探究了它们在X射线图像上进行识别和分类的可行性,并提出了两种基于深度网络的端到端的识别模型进行了焊接缺陷的自动识别和分类。本文首先讲述了焊缝缺陷检测的研究背景以及研究意义,对本文所涉及图像识别的技术和机器学习的基础理论进行了介绍,并详细阐述了传统神经网络中的反向传播算法的理论,提出了其应用在深层网络时面临的困难。接着分析了深度学习兴起的契机及发展的三次浪潮。本文同时介绍了稀疏表示的理论,包括稀疏表示的求解方法、字典的学习算法和基于稀疏表示的分类。将基于稀疏表示求解的分类方法应用在焊接缺陷图像的分类中,并取得了较高的准确率,也证明了图像的稀疏表示在表达信息上的优势。接下来介绍了主成分分析算法和自编码器的理论,并阐述了它们学习低维特征的原理,以手写数字图像研究了它们提取特征和重构图像的能力。本文基于稀疏性表示的良好表达力,详细介绍了单层的稀疏自编码器的稀疏性的引入及其提取特征的能力,并讨论了在不同优化算法下的特征提取。接下来在单层表示学习的基础上,建立了深度的自编码网络,并研究了网络结构和参数对最终分类准确率的影响。将提出的深度网络与滑动窗口法结合,实现了整幅射线图像的缺陷识别。最后本文针对不平衡的分类问题,介绍了三种解决措施。提出了一种端到端的深度卷积网络对缺陷进行分类识别,并将提取的深度特征与手工特征比较,发现了深度特征的良好性能。另外,本文还探究了迁移学习在焊缝图像缺陷分类上的可行性,测试结果表明深度卷积网络具有强大的特征学习能力,可以应用在本文的研究对象上,并且所提出了网络拥有很高的分类准确率以及计算效率,拥有很大的实用价值。"
1488,代码克隆检测及克隆Bug发现研究,"在软件开发过程中,对代码进行复制、粘贴和修改是一种常见的行为。虽然代码复用可以提高软件开发效率,节省软件开发时间,但是其会导致大量相同或相似的代码产生,这一类的代码被叫作代码克隆。代码克隆不仅会造成软件系统中的冗余,导致软件维护问题,而且会对软件的质量产生影响,导致Bug的引人和繁衍。已有的代码克隆检测研究都是找相同或几乎相同的克隆代码,这样会导致克隆分析不全面和不深入,也会导致克隆Bug筛选不充分。本文围绕以下三方面问题,分别开展研究工作,主要内容和贡献包括:(1)Large-gap代码克隆检测算法研究当代码克隆中的差异较大时,我们称其为Large-gap(大差异)代码克隆。差异较大的代码克隆不仅可以更好地反映相似代码间的差异,体现代码功能的扩展(比如,修改和优化),而且可以使代码克隆分析更加全面和深入,帮助筛选和发现代码克隆相关的Bug。但是,Large-gap代码克隆的检测难度较高,已有的基于文本或词法的方法无法对其进行检测,而基于语法树或程序依赖图的方法也受制于大差异的影响。因此,针对这个问题,本文提出了一种全新的Large-gap代码克隆检测算法,并将其实现为代码克隆检测工具CCAligner,来高效地检测差异较大的代码克隆。与已有方法不同的是,我们考虑使用连续的代码片段,而不是单个的词法元素,来作为比对的基本单元。并且,我们进一步设计了一种带误配的索引技术,允许代码片段基于一定的误配进行匹配,来增强对差异代码克隆的检测能力,同时加快比对的速度和提升比对的精度。此外,配合使用非对称的相似度度量技术,我们的方法可以更好地度量差异较大的代码克隆的相似性。实验结果表明,CCAligner对差异较大的代码克隆的检测能力显著优于现有最流行的检测工具。对一般的代码克隆,CCAligner的表现也与最好的方法在时间、可扩展性、召回率和精确率上相当。(2)代码克隆度量分析软件系统中的代码克隆数量庞大,十分不利于软件维护者的理解和管理。需要对代码克隆进行进一步的度量和分析,来帮助和指导从大量的代码克隆中筛选较感兴趣的那些克隆。基于我们提出的最新的Large-gap代码克隆检测工具CCAligner,可以发现更多的Large-gap代码克隆,可进行更深入和全面的代码克隆分析。因此,本文基于CCAligner,进一步开展了代码克隆的度量分析研究。首先,通过与软件工业界交流并结合他们的实际需求,我们首次提出了代码克隆度量的三个指标:克隆强度、克隆频度和克隆距离,来反映克隆的程度和分布。克隆的程度过高,分布过于集中,都属于代码的坏味道(Bad Smell)。然后,我们设计了相应的算法来分析和度量每个指标,并将它们集成到我们的克隆检测工具CCAligner中,作为我们克隆度量分析的研究工具。接下来,基于该工具,我们开展了代码克隆分析的实证研究,来检验工具的效果和探索真实软件系统中代码克隆分布的情况。我们对不同软件、同一软件不同版本进行了实证研究分析,实验结果表明,不同的软件系统中,质量较高(发展时间长)的软件要在三个指标上明显好于其他软件。同时,同一软件随着版本的演进,三个指标表现出越来越好的趋势,意味着软件质量的不断提升。我们的克隆度量分析工具可以从代码克隆的角度,有效地对克隆分布和软件质量进行分析。(3)代码克隆相关Bug检测研究由于代码克隆会导致Bug的引入和繁衍,因此克隆Bug发现研究可以帮助发现软件系统中由克隆引发的问题。克隆Bug同样存在多种类型,大多数已有工作都是针对特定的Bug类型,人工设计和提取特征来进行检测。这些方法只能检测特定类型的Bug,无法检测未知的Bug类型。因此,针对这个问题,本文提出了一种基于深度学习的方法DeepCbd,来自动学习尽可能多的相关特征,同时应用差异克隆算法来提取差异部分代码作为差异信息输入。由于Bug可以体现在代码的语法和词法层面,我们相应地提取了代码的语法树和词法向量表示作为模型的输人。在模型设计上,我们使用了Tree-LSTM来对语法树进行处理,且基于词法向量表示,使用了注意力机制来增强学习的效果。此外,通过改造CCAligner,我们提取了差异代码部分的词法向量表示,将其与模型得到的特征向量进行拼接,来进一步增强检测的能力。实验结果表明,DeepCbd显著优于其他的基线机器学习和深度学习方法,识别准确率达到93.46%。与已有相关研究工作相比,DeepCbd可以识别出大多数已发现的克隆相关Bug类型,而且成功识别出了三种新的Bug类型。此外,交叉验证实验和泛化能力验证实验论证了DeepCbd具有很好的泛化能力和实用性。总体来讲,本文全部的工作可以分为两个方面:代码克隆检测研究和克隆Bug发现研究。在代码克隆检测研究中,我们又具体开展了Large-gap代码克隆检测算法研究和克隆度量分析。"
1489,针对深度学习模型的优化问题研究,中国科学技术大学 博士 2019 针对深度学习模型的优化问题研究 A Study of Optimization Problem for Deep Learning Model 郑书新 刘铁岩；俞能海 信息与通信工程 第1章 绪论 1 1.1 选题的背景和意义 1 1.2 国内外研究现状 4 1.3 研究内容和主要贡献 12
1490,基于贝叶斯方法的半监督学习算法研究,"随着互联网技术的快速发展,实际应用中存在着大量无标签样本和少量有标签样本。虽然有标签样本能够有效提升监督学习的性能,但是获取充足的有标签样本往往需要耗费大量的时间。在这种情况下,仅使用少量有标签样本的监督学习泛化能力不强,而完全基于无标签样本的无监督学习往往效果不佳。这些传统的机器学习范式不仅没有性能上的优势,还浪费了数据资源。因此,研究能够同时利用有标签样本和无标签样本的机器学习方法具有重要的意义。在有标签样本较少时,半监督学习能够利用大量无标签样本改进学习性能,近年来受到了广泛的关注。经过二十多年的研究,半监督学习己经成为一类重要的机器学习范式,并被成功应用到诸多领域。然而,半监督学习在无标签样本的有效使用、高效利用以及在特征选择中的有效性方面仍然存在一些有待解决的重要问题。本文对这些问题展开研究,主要贡献总结如下:(1)对无标签样本的有效使用进行研究,提出了基于稀疏贝叶斯的半监督学习框架以及基于该框架的半监督算法SBS2LEM和SBS2LVB。这两种算法具有良好的稀疏性,能够在训练过程中自动删除无关的无标签样本,从而更加有效地利用无标签样本。实验表明,SBS2LEM和SBS2LVB能够充分利用无标签样本提升性能。值得注意的是,即使无标签样本提供的有效信息较少,SBS2LEM和SBS2LVB也能取得比其他基于图的半监督算法更好的性能。(2)对大量无标签样本的高效利用进行研究,提出了基于稀疏贝叶斯的可扩展半监督学习算法SBS2LLP和ISBS2L。ISBS2L将SBS2LLP的二类边缘似然分解成与当前无标签样本相关和无关的两部分,从而量化了无标签样本对该边缘似然的贡献。训练过程中,ISBS2L使用增量策略,依次选择对边缘似然贡献最大的无标签样本,避免了直接使用所有的无标签样本。因此,ISBS2L具有更低的时间复杂度,能够处理大规模数据集。通过分析算法的鲁棒性和泛化误差边界,本文在理论上验证了所提算法的可靠性。实验表明,这两种算法在标准数据集上能够取得高度可比的性能;ISBS2L能够有效处理百万规模的数据,并具有良好的分类性能和可扩展性。(3)对半监督学习在特征选择中的有效性进行研究,提出了基于贝叶斯的联合半监督特征选择与分类算法JSFS。通过在无标签样本上关联自调整的权重参数,JSFS能够自动选择有用的无标签样本并删除不相关的无标签样本,避免了不加区分地使用无标签样本,增强了对无标签噪声样本的鲁棒性。此外,JSFS能够自适应地选择相关特征并利用所选特征训练分类器,打破了现有算法需要预先确定所选特征数量并借助额外的学习算法训练分类器的限制。实验表明,相比于目前最先进的半监督特征选择算法,JSFS对噪声具有更好的鲁棒性,并且能够有效处理高维数据。"
1491,基于本体的智能体情感识别与情感诱发研究,"智能体是一种能够感知周围环境,并能够自治运行以实现设计者和使用者目的的机器或软件系统。传统智能体能够模拟人类的心理状态,如信念、愿望和意图等,但没有考虑情感需求,在与它们的交互过程中,这些智能体给人的感觉是一台冰冷冷的机器。情感计算技术的引入使智能体具有了情感能力,情感智能体是使用情感计算技术使智能体具有识别人类情感、分析并模拟产生与人类相类似的情感的能力。情感智能体将会更可信、更准确、更有吸引力和更有效。情感智能是智能体和多智能体系统的一个重要研究方向。情感智能体已经具备一定的情感识别和情感表达的能力,但是,还有以下问题亟待解决。首先,多智能体之间如何达成对用户生理数据情感语义和智能体自身情感相关知识的一致信念?其次,当前研究主要集中在智能体对用户面部表情和语音的情感识别上。生理信号可以反映真实的脑功能活动。如何构建基于生理信号的便于智能体查询的情感识别模型是一个亟待解决的问题。最后,当前智能体可以实现面部表情、语音和姿态的情感表达,但是在什么时候、在什么条件下产生什么样的情感、是否产生了正确的情感(与人类类似)等问题尚未解决。基于上述问题,本文探讨了基于本体的情感智能体所涉及的若干关键技术和关键问题,包括情感多智能体系统(affective multi-agent systems)的知识库系统构建、基于用户生理信号的情感识别本体模型构建、智能体情感诱发形式化定义、验证及本体模型构建等。对这些问题的研究将为建立和谐的人机交互提供支持。本文主要贡献及创新有以下三点:1.提出了一个以分布式结构组织的情感智能体的顶层本体模型,模型由用户情感本体模型和智能体情感诱发本体模型组成。用户情感本体模型实现用户情感相关知识的建模,实现对用户的情感状态推理,从而实现多智能体对用户上下文信息和用户情感状态达成统一的理解;智能体情感诱发本体模型实现智能体低级反射性情感和高级认知评价情感诱发建模,从而智能体能够产生类似人类的情感。最后还探讨了该顶层模型在抑郁看护智能体上的应用。2.构建了一个用户情感本体模型,模型实现了一个对用户脑电和功能近红外光谱二个模态的生理数据及情感知识进行建模的本体模型EmotionO+,并利用机器学习算法―随机森林―构建情感推理规则,利用推理引擎将推理规则应用于本体知识模型,对其中建模的知识和数据以较高的准确率推理出用户的情感状态,该方法有效解决了脑电和功能近红外光谱二个模态生理数据和用户上下文信息的语义表示问题,使智能体能够理解用户生理数据的含义并推理出当前用户的情感状态,能够为情感多智能体系统提供一个用户情感知识共享平台。3.构建了智能体情感诱发本体模型,模型实现对情感智能体心理状态和情感诱发的建模。提出了一种对OCC(Ortony、Clore和Collins)认知评价理论的形式化定义及形式化验证的方法。首先,用OBDI(Observation-based Belief、Desire、Intention logic)逻辑中的信念、愿望和意图等概念,对OCC理论中描述诱发情感的认知评价过程给出了逻辑定义,根据此定义,构建高级认知情感诱发规则,应用于智能体情感诱发本体模型,以产生类似人类的情感。探索了如何应用符号模型检测技术来验证情感BDI多智能体模型的情感属性。提出了一种通过改进模型检测器MCKBDI(Model Checker for Knowledge,Belief,Desire,and Intention)来实现对情感诱发逻辑定义进行验证的新方法。实验结果显示,模型检测方法可以有效验证有限状态情感BDI多智能体系统产生的情感是否符合情感理论。综上所述,本文针对情感智能体和人机情感交互系统的发展需要,以情感计算为导向,对基于本体的多智能体系统中情感识别、情感诱发机制和关键技术进行了探索,提出了一个情感智能体的顶层本体模型;实现了基于脑电生理信号的情感识别与推理的用户情感本体模型;研究了OCC情感理论的逻辑形式化问题,提出了对所给出的形式化定义进行验证的一种新方法,并依此构建了智能体情感诱发本体模型。本研究丰富了情感智能体的理论基础,为建立一个和谐、自然并带有情感的智能体交互系统提供技术支持,有助于推动该方向的进一步发展和应用。"
1492,基于序列信息的蛋白质翻译后修饰位点预测方法研究,"随着人类基因组计划的完成和后基因组时代的到来,测序技术为生物学研究积累了大量的可挖掘数据。根据分子生物学中心法则,遗传信息保存在DNA中,但是真正行使生物学功能的是蛋白质。以mRNA为模板翻译出的前体蛋白是没有生物活性的,它需要经过一系列的加工过程才能成为具有生物功能的成熟蛋白。这种加工过程被称为翻译后修饰。翻译后修饰是蛋白质行使其正常生物学功能的基础。大量研究表明,发生在蛋白质赖氨酸残基上的Pupylation、泛素化和琥珀酰化修饰与许多疾病的发生存在密切相关性,阐明这些蛋白质翻译后修饰的过程和内在调控机理是揭示相关疾病发生机制并进行精准治疗的前提,而研究蛋白质翻译后修饰的关键起始步骤是找到可修饰蛋白及其作用位点。利用生物实验方法识别蛋白质翻译后修饰位点耗时长,经费投入大,而且翻译后修饰的酶促反应是一个极为耗时的过程,这严重制约了翻译后修饰位点识别研究的进展速度。随着生物信息学和计算生物学的发展,一些基于计算方法的蛋白质翻译后修饰位点识别技术被提出来,这些计算方法既能够高效而准确地识别蛋白质翻译后修饰位点,又能够进一步地对生物实验研究提供必要的线索。本文基于蛋白质序列信息对发生在赖氨酸残基上的翻译后修饰位点识别方法进行了深入研究,主要研究内容如下。(1)提出了一种新的蛋白质Pupylation位点识别方法EPuL。该识别方法的创新点体现在对初始可靠负样本集的构造,对于基于正例和无标记样本学习(Positive-Unlabled Learning,PU学习)过程,初始可靠负样本集的构造对算法整体性能至关重要。本文提出了一种基于分类器的初始可靠负样本集构造方法。初始可靠负样本集构造出来后,通过一个迭代过程对其进行扩充,最后构造出最终的可靠负样本集,并与正样本集构成最终的训练集,训练一个最终的支持向量机分类器来进行Pupylation位点识别。训练集上的交叉检验和独立样本集测试结果表明我们所提方法在预测性能上优于已有方法。另外,利用该算法从未注释位点的Pupylation蛋白质序列中识别出了一批潜在的Pupylation位点。特征分析结果表明本研究中使用的序列特征提取方法可以有效区分正样本和负样本。最后,根据此方法开发了一个用户友好的Web服务器提供免费的蛋白质Pupylation位点预测服务。(2)针对蛋白质泛素化位点识别问题开发了一种基于半监督学习与集成学习方法的预测算法。该算法首先选用伪氨基酸构成、蛋白质无序性打分、氨基酸理化性质、位置特异性得分矩阵、k-间隔氨基酸对构成、序列二进制编码和K近邻得分等7种方法对序列进行特征提取,对每一条序列构建8个独立的特征向量。位点识别算法首先利用改进的基于正例学习(Positive Sample only Learning,PSoL)算法根据8种特征向量从无标记样本集中逐步构建可靠负样本集,用于后续预测模型的训练。位点预测模型选用的是基于集成学习策略的随机森林算法。首先用每种单一特征分别训练一个随机森林模型,最后采用逻辑回归算法对8个随机森林模型的预测结果进行整合得到最终的预测结果。训练集上的10倍交叉检验和独立测试集的测试结果表明,本研究中提出的方法能够对物种特异的蛋白质泛素化位点和跨物种的综合性数据中的蛋白质泛素化位点进行有效识别,并且预测性能较现有泛素化位点预测算法得到了提高。最后,对算法进行特征分析,单一特征与组合特征比较结果证明组合特征预测较每种单一特征的预测效果都高,从而证明了特征组合的有效性。随机构建负样本集与本文构建的可靠负样本集上的比较结果证明了基于半监督学习的可靠负样本提取策略可以有效提高算法预测性能。(3)提出了一种用于蛋白质琥珀酰化位点预测的深度学习框架SucDeep。首先在k-间隔氨基酸对构成的基础上设计了一种新的序列特征提取方法。该方法用一个21×21维的矩阵来表示每一种氨基酸对在序列中出现的次数,每一个矩阵可以表示一种间隔的氨基酸对构成情况,然后把表示多种间隔的矩阵合并成在一起,构成一个与多通道图像类似的矩阵集合,作为待预测序列的一种特征。这种多通道特征矩阵是稀疏的整数矩阵,类似于计算机图像的表示方式,适用于深度学习模型。同时还采用位置特异性得分矩阵对序列进行特征提取,把每一条序列转换成一个20维的方阵。然后开发了一种基于间谍技术的半监督学习算法,用于从无标记样本中构建可靠负样本集。位点预测算法选用的是一种深度学习框架。该深度学习框架由两个多层卷积神经网络构成,每个子网络由3个卷积层,3个池化层和3个全连接层构成,并使用一个全连接层对两个子网络产生的特征进行拼接进行最终的预测。模型训练过程采用Bootstrapping策略,有效避免了训练集不平衡对算法性能的影响。最后构建了一个大规模的蛋白质琥珀酰化位点数据集对算法性能进行了测试,训练集上的5倍交叉检验结果和独立测试集的测试结果表明,我们所提出的算法较现有琥珀酰化预测算法在预测性能上有所提高。"
1493,基于机器学习的滑坡易发性区划与降雨诱发滑坡预报预警研究,"滑坡是由岩石、土体或碎屑堆积物构成的山坡体在重力的作用下,受到地表水和地下水或地震等的影响,沿软弱面(滑动面)发生整体向下滑落的过程。滑坡灾害可毁灭村镇、破坏交通,造成财产损失和人员伤亡,滑坡引发的次生灾害还会阻塞河道、引发洪水,甚至诱发形成泥石流灾害,造成更严重损失。我国山地环境广泛,尤其在西南地区,山地是主要的地貌形态,地质环境条件和水文气候条件复杂多变,是我国滑坡灾害最严重的地区,频繁发生的滑坡使得人们的生命和财产安全受到了极大的威胁。滑坡易发性区划是通过分析影响滑坡的内在因素和外在因素,评价潜在滑坡灾害的地理空间分布,为城市建设规划和滑坡灾害防治提供决策支持。我国的大部分滑坡是由降雨直接诱发或与降雨有关,降雨诱发滑坡的预报预警能够使有关部门及早制定防治措施,减少滑坡灾害的损失。本文以典型的西部山区县域DD重庆市奉节县为研究区域,开展基于机器学习的滑坡易发性区划与降雨诱发滑坡预报预警研究,具体研究内容和研究成果如下:(1)采集并处理了研究区2001~2016年发生的1520个滑坡数据以及地质构造、地形地貌、降雨、人类活动等数据,分析了研究区滑坡灾害的空间分布特征、成因机理及发育环境。(2)基于滑坡灾害成因机理的复杂性和诱发因素的多元化,选取地形地貌、地质条件、环境条件、人类工程活动以及诱发因子等5种影响因素的16个指标作为候选的评价指标,包括高程、坡度、坡向、坡位、微地貌、地面曲率、地形湿度指数、岩性、距离断层距离、倾坡类型、NDVI(归一化植被指数)、距离水系距离、土地利用类型、距离道路距离、距离房屋建筑距离和多年平均降雨量等,并对各因子与历史滑坡的相关性进行了统计分析。(3)选择逻辑回归、人工神经网络和随机森林三种机器学习方法进行滑坡易发性区划,为了能更有效地构建优化的机器学习模型,采用贝叶斯优化算法进行超参数优化,利用递归特征消除方法进行特征选择。测试结果表明利用贝叶斯优化算法的速度要比网格搜索的速度快40倍,且得到的优化模型精度要高于网格搜索。通过对不同方法的滑坡易发性区划结果进行比较分析,显示随机森林方法的结果更符合实际情况。最终得到研究区域滑坡易发性区划图与历史滑坡点的叠置结果,有65%的历史滑坡落在面积比不到20%的高易发区和较高易发区中。(4)结合研究区历史滑坡及对应的降雨数据,进行降雨与滑坡灾害相关性的数理统计分析,建立了奉节县滑坡灾害的前期有效降雨量计算模型。依据有效降雨量模型,对位于不同等级滑坡易发区的滑坡数据进行数据挖掘分析,提出了奉节县滑坡灾害不同预警等级的有效降雨量阈值。基于不同滑坡易发性区划的当日降雨量与历史滑坡关系的数据挖掘,提出了当日降雨对滑坡预警等级的标准。将易发性区划、有效降雨阈值和当量降雨调整标准结合,构建了奉节县滑坡灾害降雨时空联合预报预警模型。(5)开发了奉节县降雨诱发滑坡降预警预报系统,系统集成了奉节县滑坡灾害及影响因子数据,能进行滑坡易发性区划的机器学习建模、前期有效降雨和日降雨查询分析,以及时空耦合的降雨诱发滑坡的预报预警,并实现成果的可视化表达。(6)利用研究区2017年的滑坡案例进行了验证分析,根据5个滑坡案例的发生时间计算滑坡前10天有效降雨量,并结合当日降雨量,给出预报预警等级,结果表明5个典型案例的最终预警分析结果均为黄色~橙色预警,预警结果与现场实际情况总体吻合。"
1494,基于多源数据的贫困度与自然灾害相关性评估,"贫困是当今世界面临的严重社会问题,2015年全世界约有7亿人生活在极端贫困线以下,消除贫困成为世界各国努力的目标,联合国提出了包含消除世界各地一切形式贫困在内的可持续发展目标,我国也提出了“精准扶贫”的重要战略。在全球气候变化的背景下,自然灾害对贫困的消除构成巨大威胁。面对相同的自然灾害,贫困人群相对于其他人群表现出更高的社会脆弱性,更容易在自然灾害中遭受伤害,同时更难从灾害中恢复正常生活。近50年来,全球的自然灾害数量呈增加的趋势,贫困人群面对自然灾害的处境以及自然灾害对贫困人群的影响亟需得到更多的关注。开展区域贫困度与自然灾害评估及其相关性分析,对于深入理解贫困人群的生存现状、有针对性的开展扶贫和减贫计划、推进社会公平都具有重要意义。开展自然灾害与贫困的相关性分析,需要贫困度数据及自然灾害风险和灾情数据的支持。传统上对贫困度的评估主要依赖于统计和调查数据。然而统计数据多以行政区域为单位,无法反应行政区域内部的贫困度分布;入户调查数据则存在覆盖范围不全、更新频率慢等问题。很多极端贫困或处于战乱中的国家甚至常年缺少贫困相关的统计和调查数据。很多研究利用遥感、GIS数据或其它统计数据对贫困度进行估算以弥补贫困度数据的缺失。鉴于贫困成因和表现的复杂性,单一数据难以精确反应贫困,基于多源数据的贫困度估算则受限于特征数据的可获得性和计算成本。此外,不同国家和地区的贫困统计口径不一致,导致大多数研究侧重于单个国家或地区的贫困度估算,缺少大范围、跨国家的贫困度估算方法研究。因此,亟需提出一种可快速综合多源遥感和GIS数据的贫困度估算方法。由于贫困空间分布数据的缺失,目前对贫困人群在自然灾害中的暴露度以及贫困度与不同类型自然灾害的相关关系仍有待进一步研究。此外,尽管夜间灯光日数据已被证明可用于监测某些自然灾害的灾情,但在不同类型自然灾害灾情评估中的可用性和局限性上仍有待进一步总结和研究。同时,鲜有研究在某一自然灾害事件发生后,对区域受灾和恢复情况与贫困度的相关关系进行针对性的研究。针对以上问题,本研究提出了一种基于多源遥感和GIS数据及机器学习算法进行贫困度估算的方法,并探讨了该模型在单一国家、多个国家以及城市内部贫困度估算中的应用能力;从自然灾害危险性和灾情的角度分析了自然灾害与贫困的相关关系,并总结了NPP(National Polar-Orbiting Partnership)-VIIRS(Visible Infrared Imaging Radiometer Suite)夜间灯光日数据在灾害评估中的可用性和局限性。本文的主要研究内容和研究成果如下:(1)提出了一种基于多源数据和机器学习算法的贫困度估算方法。首先从夜间灯光数据、土地覆盖数据、高分辨率谷歌影像数据、可达性数据、数字高程模型(Digital Elevation Model,DEM)数据等多源数据中利用机器学习等算法提取了4类(社会经济特征、地表覆盖特征、地形特征以及可达性特征)与贫困度相关的特征。然后构建随机森林回归模型,以上述特征为自变量,以家庭组为单位的家庭财富指数WI(Wealth Index)调查数据为因变量,对单一国家(孟加拉国)、多个国家(南亚和东南亚地区)以及城市内部(印度维沙卡帕特南)的贫困度分别进行了估算。结果表明,模型在孟加拉国的贫困度估算精度(R~2)达到0.71,在南亚和东南亚地区的估算精度(R~2)为0.61,在维沙卡帕特南的估算精度(R~2)为0.63。与传统研究相比,本研究在兼顾估算可行性的同时,提高了估算模型的精度及其泛化能力。(2)从灾前风险评估的角度,评估了南亚和东南亚低收入和中低收入国家滑坡、地震、洪水、热带气旋四种自然灾害的危险性分布,并结合贫困分布数据,评估了贫困地区暴露于自然灾害的现状及贫困度与自然灾害危险性等级的相关关系。具体而言,首先分析了贫困区域暴露于自然灾害危险的现状,发现14.64%的贫困区域位于至少一种自然灾害的高危险范围内。通过梳理自然灾害高危险区域内的贫困空间分布现状,发现各个国家自然灾害高危险区域内的贫困区域面积普遍很高,但人口分布比较稀疏。通过分析不同自然灾害的危险性与贫困度之间的关系,发现各个国家在面对地震和滑坡等灾害时,其危险性等级普遍与贫困度之间呈正相关关系,即危险性越高的地方越贫穷,多数国家的洪水和热带气旋危险性与贫困度之间呈负相关关系,即危险性越高的地方越富裕,少数国家(印度)的洪水和热带气旋危险性与贫困度之间呈正相关关系。这与灾害本身的性质以及国家的防灾救灾能力有关。(3)从灾后灾情评估的角度,探索和总结了NPP-VIIRS夜间灯光日数据在自然灾害灾情评估中的应用,结合贫困分布数据分析了哈德哈德热带气旋过后,印度维沙卡帕特南市区的停电及恢复情况与贫困度的相关关系。首先构建了用于反映自然灾害发生前后夜间灯光亮度变化的指标PNL(Percent of Normal),通过分析6个典型的地震、洪水和热带气旋灾害事件发生前后NPP-VIIRS夜间灯光日数据的变化特征,进一步评估了其在自然灾害灾情评估中的可用性和局限性。结果表明,PNL可以在一定程度上反映尼泊尔地震后的房屋破坏情况(总体精度75.5%,Kappa系数0.31),但无法反映意大利地震后的房屋破坏情况;PNL可以精确估算玛利亚飓风造成波多黎各停电的百分比(R~2=0.94)和哈德哈德热带气旋造成维沙卡帕特南市区的停电百分比(估算的停电百分比与新闻报道相符);PNL可以反映榆林洪水造成的停电情况,但无法反映路易斯安纳洪水造成的停电情况。针对热带气旋过境后印度维沙卡帕特南停电及恢复的分析表明,相对贫困地区与相对富裕地区最初的停电比例相似,但相对贫困地区的供电恢复速度慢与相对富裕地区的供电恢复速度。"
1495,数据驱动的安卓恶意软件排查和安卓应用漏洞挖掘的研究,"大数据时代的典型展现是海量移动应用的普遍使用。随着移动设备的普及,人们越来越多地开始利用各种各样的移动应用来丰富日常生活。例如人们利用移动应用进行网上购物、网上支付、在线聊天、在线阅读等。搭载安卓系统的智能设备的市场占有率超过85%,加之安卓系统的开源性特点,致使该系统运行的安卓应用(App)成为攻击者的重要攻击目标。攻击者将攻击目标由PC端转移到移动端的趋势十分明显。移动应用安全领域最为关注的研究方向是:(1)基于安卓应用的主动恶意行为攻击,即攻击者利用各种恶意代码进行安卓应用攻击,以达到攻击者的非法目的。例如获取安卓用户的个人信息,推送恶意广告等;(2)安卓应用自身代码存在安全质量问题,即安卓应用中存在可以被攻击者利用的应用代码漏洞。其中,安卓用户最为关注的是个人敏感数据泄漏相关的漏洞。同时,安卓应用漏洞也会催生相关安卓恶意软件的发展。因此,上述这两方面的问题严重影响到了安卓应用生态系统的安全性。针对显著影响安卓应用生态系统安全性的上述两方面问题,本文研究的主要目标是通过安卓恶意软件排查和安卓应用漏洞挖掘以切实降低安卓应用生态系统的安全风险。由于安卓恶意软件的危害性,催生了许多针对安卓恶意软件排查的工作。相比较于基于签名匹配、恶意行为定义、数据流分析的安卓恶意软件排查方法,基于机器学习分类器的方法在安卓恶意软件排查领域能够取得更好的效果,并且对于变种恶意软件具有识别能力。但是,基于机器学习的方法具有以下问题:(1)现有数据集合过小,过时,且恶意种类不平衡。(2)特征集合都是基于权限声明和系统调用,语义和代表性不足。(3)时间和资源消耗过大。(4)基于理想环境下的安卓恶意软件识别,未考虑对抗性环境下的攻击场景(隐藏攻击和投毒攻击致使分类器失效)。另一方面,对于安卓应用漏洞的挖掘研究同样存在以下问题:(1)缺乏特定安卓类别(例如银行应用)的漏洞基准;(2)缺乏自动化敏感数据标签技术,致使漏洞挖掘结果存在大量的假阳性;(3)缺乏企业界对已发现漏洞的有效验证和反馈。为此,本文针对安卓恶意软件排查和安卓应用漏洞挖掘两个密切相关的研究方向,在以下几个方面进行了深入的研究:・首次利用大数据统计分析和信息增益相结合的分类器特征选取方法。选取最具代表性的、具有区分度的行为和语义特征集合。本文研究的数据集合来源于企业合作伙伴盘古公司的一手数据。基于该方法提出的基于机器学习和流式处理框架的安卓恶意软件排查系统Storm Droid成为该研究领域的基准之一。・首次提出多维度相似度过滤的自适应方法和两阶段迭代机制。以应对安卓恶意软件分类器在对抗性攻击环境下存在的高漏报率问题,并提出了对抗性安卓恶意软件排查系统Kuafu Det,该系统对于针对机器学习分类器的隐藏攻击和投毒攻击都具有明显的效果。该研究相关数据集合已经开源,并已经在全球60多家科研机构中得到推广和使用。・首次利用自动化敏感数据标签技术进行安卓应用数据泄漏的识别。通过该技术能够确定用户数据类型是否属于用户敏感数据,并结合数据流分析技术,完成了安卓应用敏感数据泄漏相关漏洞的挖掘系统AUSERA的实现。原型工具AUSERA已经开始进行企业化包装和推广。AUSERA共计发现了2157个应用漏洞。我们向60家银行企业进行了漏洞上报,共计21家银行进行了回复,确认了126个上报漏洞,其中52个上报漏洞已经得到修复,并与多家银行企业展开实质性合作,例如英国的HSCB,新加坡的OCBC和DBS。实验证明,通过对安卓恶意软件排查和安卓应用代码漏洞的挖掘,本文提出的方法能够有效且高效的降低安卓应用生态系统的安全风险,从而提高安卓应用生态系统的整体安全性。"
1496,源于RBM与ELM-AE的深度神经网络算法研究,"受限玻尔兹曼机是一种产生式网络,不仅能学习到数据的特征,并且能利用特征重构出数据。极速学习机-自动编码器也是一种对数据编码的网络,但其无需迭代。这两种模型都可以用于表征学习,从而被用来创建深度模型。以极速学习机-自动编码器与受限玻尔兹曼机为基础的深度神经网络算法研究已经取得了许多成果,但是还有很多问题值得进一步深入研究。本文主要从噪声数据分类、图像去噪、多视图数据分类、半监督学习以及多标签学习等方面的应用展开研究,具体研究内容如下:1.对基于干净数据与噪声数据的Point-wise Gated深度网络进行研究。传统的深度网络在处理带背景的数据时容易受到噪声的干扰,假设带背景的数据中与分类无关的部分影响深度网络的性能。因此,利用Point-wise Gated受限玻尔兹曼机使用特征选择策略提升深度网络在噪声图像的分类能力,当数据中出现干净数据与噪声数据,使用干净数据对Point-wise Gated受限玻尔兹曼机学习得到的与分类有关的数据二次去噪,接着堆叠深度模型对去噪后的数据分类。2.对鲁棒尖峰和平板深度玻尔兹曼机算法在图像去噪上的应用进行研究。传统的鲁棒高斯受限玻尔兹曼机只使用浅层的高斯受限玻尔兹曼机对图像建模。传统的深度玻尔兹曼机能很好的建模图像,但其只能处理二值数据,在其基础上设计了一种适用于实值数据的深度玻尔兹曼机网络。接着用该深度网络代替高斯受限玻尔兹曼机对鲁棒高斯受限玻尔兹曼机中干净图像进行建模,并用均匀场方法对模型学习到的去噪数据加工与处理,最终得到更为清晰的去噪图像。3.对面向多视图数据的受限玻尔兹曼机算法进行研究。受限玻尔兹曼机只适合处理单视图数据,在其基础上保证不同视图间隐藏层特征一致性,提出后验一致性受限玻尔兹曼机。但是,后验一致性受限玻尔兹曼机忽略了每个视图的独有特性,接着设计了后验一致性和领域适应受限玻尔兹曼机,其隐藏层包含不同视图间的一致性信息和每个视图的独有特性,最终提升多视图数据的分类性能。4.对多层极速学习机网络在半监督学习与多标签学习上的应用进行研究。多层极速学习机可以用无监督学习样本的特征,而传统的半监督学习或者多标签学习大多是浅层算法。可以将其与多层极速学习机的表征学习相结合提升算法的性能。结合半监督极速学习机设计了面向半监督学习的多层极速学习机网络,接着结合多标签径向基网络设计了面向多标签学习的多层极速学习机网络。"
1497,开放环境下的度量学习研究,"利用对象之间的相似性关系,度量学习为样本学到有效的特征表示,使得在该表示空间中,样本之间的距离度量能够精确反映样本之间的相似与不相似关系。有效的距离度量与表示空间极大地辅助了后续的多样化任务。在度量学习的研究中,传统的方法依赖于静态的、封闭的环境,需要无干扰、不变化的特征,大量的训练样本,且只能处理单一的对象语义。而实际应用场景比较复杂,是开放的,并存在“输入噪声多”、“训练样本少”、“特征变化快”、“语义表示广”等特点。本文从模型在开放环境下输入、输出层面上面临的挑战作为切入点,提出针对或利用度量学习特性的具体算法,从理论和应用等多个角度使得度量学习的研究能够契合开放的环境。本文的主要内容有:1.从理论上分析了度量学习的泛化能力,并提出策略以降低其样本复杂度。传统机器学习方法要求大量有标记的训练样本,而实际场景中,对于某些类别,考虑到样本搜集和标注的代价,只能获取极少量的有标记的样本。本文从目标函数性质以及度量重用两个角度进行泛化能力的理论分析,相对于以往的分析结果,提出如何能获得更快的泛化收敛率,即如何利用更少的样本得到同样的泛化误差。同时,本文通过大量实验进行验证,说明满足理论假设时,各因素对样本复杂度的影响与理论中给出的趋势一致。2.提出一种应用度量语义变换在小样本情况下应对特征变化的学习方法。除了仅有少量的训练样本,当在开放环境下处理新的任务时,模型也会面临特征空间变化的挑战。本文利用特征之间的关联性,提出构建特征的“元表示”空间,利用在该空间中学习的度量,将已有特征空间的分类器转换到新的特征空间上,以“重用”已有的训练好的异构分类器。提出的REFORM方法也降低了学习算法的样本和计算需求。值得一提的是,在REFORM方法重用分类器的过程中,没有历史训练数据的传输,而仅仅需要已有的模型,这也保护了不同阶段、不同任务之间数据的隐私性。3.提出能够灵活挖掘并自适应利用开放环境中复杂语义的多度量学习框架。图片、文本等对象在不同场景下往往存在丰富的语义。以往的度量学习方法只针对对象的单一语义进行建模,而忽略了语义的多样性。本文提出“语义度量”这一概念以及统一的框架UM2L,学习多个局部度量,不但能统一已有的方法、灵活挖掘出对象本身的不同语义,也能够提升后续众多实际问题的性能。针对度量数目的选择,本文也提出自适应的多度量学习框架LIFT,利用全局度量的辅助,动态地为不同的语义分配度量的数目。LIFT―方面防止模型过拟合、提升分类能力,一方面也降低了存储开销。4.提出一种利用分布扰动以适应输入特征和对象关系噪声的度量学习方法。开放动态的环境容易受到噪声的影响。一方面,输入的样本特征容易附带噪声,导致样本特征的描述不够精确;另一方面,对象之间的关联关系也会不准确,使后续相似性的学习更加困难。针对这一难点,本文首先对样本之间的距离做概率化分析,指出上述两种噪声都来源于样本特征的扰动。并提出一种基于“期望距离”的度量学习方法DRIFT。该方法在学习过程中动态地引入噪声,有效地增广数据,使模型有更好的泛化能力。利用DRIFT学到的距离度量更加鲁棒,能够更真实地反映对象之间的关系。"
1498,基于适配子组三重血清荧光高通量测定“一站式”肝癌诊断新技术的建立及其评价,"背景与目的:尽早诊断、准确分期和肝功能分级是提高肝癌疗效和改善预后的关键,但其完成需要完善的临床、实验室、影像学和病理资料,探索集肝癌诊断、分期和肝功能分级于一体的“一站式”诊断新技术有重要意义。前期我们筛选到365个肝癌血清适配子,创建了适配子三重血清荧光高通量测定技术,发现适配子三重血清荧光联合建模对肝癌有良好的诊断价值和一定的分期及肝功能分级价值,提示高通量检测一组诊断价值互补的适配子的三重血清荧光并建立诊断模型,可能实现肝癌“一站式”诊断。为此,本研究将优选前期筛选到的适配子构建适配子组,高通量检测适配子组三重血清荧光,创建肝癌“一站式”诊断新技术,并评价其诊断价值。方法:1、收集血清标本:收集2015～2018年间在南昌大学第一附属医院住院的治疗前的原发性肝癌、肝硬化、慢性肝炎患者的血清标本及其相关临床及实验室资料,并同期收集检查结果未见异常的健康体检者的血清标本。2、理论分析筛选代表性肝癌血清适配子:用RNA Structure 4.6软件分析前期筛到的365个肝癌血清适配子的二级结构。用Clustal X软件分析各适配子的序列同源性。选择二级结构各异、序列同源性低的适配子作为代表性适配子进行人工合成。3、混合血清分析优选高特异性肝癌血清适配子:采用前期建立的基于荧光定量PCR仪单管序贯检测适配子三重血清荧光法,在优化实验条件的基础上,分析各代表性适配子与肝癌混合血清结合的特异性,优选出对肝癌血清高特异性的候选适配子。4、单样本血清标本分析优选构建肝癌“一站式”诊断的适配子组:在优化检测条件的基础上,采用三重血清荧光法检测上述高特异性候选适配子与肝癌和对照血清标本作用后的荧光变化,优选出对肝癌“一站式”诊断价值大的适配子用于建立诊断模型,进入模型的各适配子即构成肝癌“一站式”诊断适配子组。5、评价适配子组对肝癌“一站式”诊断的价值:分别收集分类血清样本和随机连续血清样本,以上述优化的肝癌“一站式”诊断适配子组中的各适配子分别检测上述血清标本的三重血清荧光。以荧光指标为变量,分别建立Logistic回归(LR)、判别分析(DA)、支持向量机(SVM)、决策树(DT)和神经网络(ANN)的5种机器学习模型,获取模型对标本的肝癌诊断结果,通过ROC曲线分析评价适配子组对肝癌的定性诊断价值,计算适配子组对肝癌BCLC和TNM分期肝癌的分期准确率,以及对Child-Pugh肝功能分级的准确率。结果:1、代表性适配子的优选结果:Sructure 4.6软件对前期筛选到的365个肝癌血清适配子的二级结构分析显示适配子的二级结构丰富;Clustal X软件对适配子进行序列同源性分析,基于序列同源性分布365个适配子可划分为55个家族。根据相关相关文献中关于适配子序列同源性与二级结构对适配子与标靶结合的亲和力、特异性的规律,从365个适配子中优选26个代表性适配子。2、高特异性肝癌血清适配子的优选结果:根据26个代表性肝癌血清适配子检测40例肝癌混合血清与肝硬化血清的三重血清荧光的强度变化差异,Ap-HCS-9-109、、Ap-HCS-9-90、、Ap-HCS-9-120、、Ap-HCS-9-22、、Ap-HCS-9-110、Ap-HCS-9-23和Ap-ANHC-8-1-5共7个适配子的荧光增长差异均可达10%及以上。优选此7个适配子为候选高特异性肝癌血清适配子。3、构建肝癌“一站式”诊断价适配子组的优选结果:根据上述7个候选高特异性适配子对32例单个肝癌和肝硬化血清标本的三重血清荧光的检测结果,Ap-HCS-9-120、Ap-HCS-9-90和Ap-HCS-9-23 区分肝癌与肝硬化的AUROC大于0.75,联合分析AUROC达0.8以上;Ap-HCS-9-120预测BCLC和TNM分期的准确率高于55%,Ap-HCS-9-90预测TNM分期和Child-Pugh分级准确率分别达55%和75%。综合分析,优选上述3个适配子构建肝癌“一站式”肝癌诊断的适配子组。4、适配子组对肝癌“一站式”诊断的价值评价:以适配子组的各适配子分别检测112例分类血清样本和288例随机血清样本的三重血清荧光指标建立了 5种机器学习分类模型,对于区分肝癌和对照AUROC在0.767～0.992,在BCLC分期、TNM分期和Child-Pugh分级的准确率40～100%。其中,联合分析多数AUROC可达0.9以上,DT模型在各种条件下区分能力均表现稳定(AUROC均达0.9以上)分期分级准确率多数达90%以上。结论:1、对前期筛选到的365个肝癌血清适配子进行了二级结构分析和序列同源性分析,优选出序列同源性低和二级结构丰富的代表性适配子,理论上存在潜在的适合构建肝癌“一站式”诊断适配子组的候选适配子。2、在分别优化检测条件的基础上,先后采用混合血清和单样本血清逐步测定优选适配子的三重血清荧光强度,发现适配子Ap-HCS-9-120、Ap-HCS-9-90和Ap-HCS-9-23在肝癌的诊断、分期和肝功能分级有较好的价值,并以此3个适配子构建适配子组,发现可以有效进行肝癌“一站式”诊断。3、用上述适配子组测定了不同血清样本系列的三重血清荧光强度,通过5种机器学习方法建立起系列诊断模型,发现各模型,特别是决策树模型,在不同样本体系中均有良好且相似的诊断价值,优于AFP。表明基于的三重血清荧光法的适配子组对肝癌“一站式”诊断具有良好的效果。"
1499,基于序列前向选择策略的过滤算法研究,"随着大数据时代的到来,人类活动在不同领域产生了大量数据。这些庞大的数据信息为计算机科学家提供了丰富研究素材的同时,也带来了巨大的挑战。其中,高维数据中存在大量的噪音和冗余信息,这不仅不能为科学家们提供更多的信息,还会对真正有用的信息造成干扰。因此,特征选择技术应运而生。特征选择技术是机器学习和模式识别领域中重要的数据预处理手段。特征选择技术通过剔除数据中无关和冗余的特征,保留最具信息量的特征。利用特征选择算法选择出来的特征子集,可以提高数据质量,从而提高分类器的准确率。根据与分类器的关系,特征选择算法大致被划分为三类:过滤法(Filter),封装法(Wrapper)和嵌入法(Embedded)。过滤法由于它独立于分类器,执行速度快,易实现等特点而备受关注。另外,在搜索策略上,我们选择序列前向搜索策略。在测量特征与特征,以及特征与标签相关性时,我们利用信息论作为测量工具。传统的基于信息论的过滤式特征选择算法大致通过两方面手段选取最具信息量的特征子集:减小特征冗余;增大新的分类信息。本文围绕着两方面特征选择手段的缺陷,提出了两种不同的解决方法;另外针对两种手段同时忽略的问题,提出了一个补充项,并设计了一种新的特征选择算法;最后,本文还对两个新型特征选择算法进行了优化,并给出一种优化特征选择算法。具体而言,本文的主要贡献点和创新点如下:1.总结两类特征选择方法;结合类依赖特征冗余和类独立特征冗余,提出了一种混合特征选择方法Minimal Redundancy-Maximal New Classification Information(MR-MNCI)。这种混合特征选择方法分别与两类特征选择方法进行实验对比,实验结果证明MR-MNCI算法具有分类优势。另外,本文指出了该方法的不足以及未来的研究方向。2.通过分析增大新的分类信息的特征选择算法和信息论的基本概念,对特征相关性进行了重新解释,并提出了一种新的过滤式特征选择算法Compositionof Feature Relevancy(CFR)。另外,我们通过一系列等式变换,证明了CFR算法符合一种通项,并通过实验证明了CFR算法的分类优势。3.已存在的特征选择算法忽略了已选特征的动态变化。根据一个实例在信息论测量上的表现,本文提出了一个已选特征动态变化项,并且重新定义了特征相关性。通过结合新的特征相关项,已选特征动态变化项和特征冗余项。本文提出了一种极具竞争力的过滤式特征选择算法Dynamic Change of Selected Feature(DCSF),并在4种不同分类器和在没有特征选择的情况下进行了实验,DCSF算法取得了不错的分类表现。4.传统的特征选择算法不区分候选特征相关性和已选特征相关性,并且在分类过程中,一些依赖特征被误认为是冗余特征。针对以上问题,本文结合特征选择算法Joint Mutual Information Maximization(JMIM)对最小联合互信息的定义,以及Gene Selection via Dynamic Relevance(DRGS)算法对已选特征的权重赋值,将候选特征相关性和已选特征相关性进行区分,并且引进DRGS算法对已选特征的权重,提出了Dynamic Relevance and Joint Mutual Information Maximization(DRJMIM)算法。DRJMIM算法分别与JMIM和DRGS以及其它3个特征选择算法分别在一个具体实例和12个真实数据集上了进行了实验分析。实验结果证明,DRJMIM算法优于其它对比算法。本文致力于过滤式特征选择算法在序列前向选择策略上的研究。针对现有的过滤式特征选择算法存在的问题,提出了不同的解决方案并取得了良好的效果。这些研究可以为一些高维数据剔除无关和冗余特征,保留相关特征,从而提高数据质量。因此,具有重要的理论意义和应用价值。"
1500,水果及谷物制品品质可见/近红外光谱在线检测方法及系统开发研究,"我国是农产大国,目前仍存在着总量过剩与质量参差不齐等问题,尤其是水果和谷物行业。随着社会的发展,人们对水果和谷物及其制品的需求已经从数量转变为质量。因此,为了实现我国水果和谷物产品的多样化、优质化发展,必须重视和提高水果及谷物产后商品化处理技术,特别是能够实现快速无损、可进行在线的检测技术。研究水果和谷物及其制品内在品质的在线检测方法,开发相应的快速、无损、高精度的在线检测系统,对于提高水果及谷物的商品化,减少产后损失,增强我国水果和谷物参与国际市场竞争的能力具有重要意义。本研究是在近红外光谱检测技术的基础上,以草莓和面粉两种农产品为对象,研究了草莓品质及货架期的可见/近红外光谱在线检测方法,进一步开发了基于C++语言的面粉品质在线检测系统;研究了基于机器学习和深度学习的非线性建模方法,构建了具有较强泛化性的近红外光谱在线快速分析模型。主要研究内容与结果如下:(1)探析了草莓储藏过程中品质变化与近红外光谱之间的变化规律,建立了不同速度下(0.05、0.10和0.15m/s)草莓货架期的判别模型。结果表明采用原始光谱建立的LDA模型受到速度影响,且不具良好的预测能力;根据CARS算法提取的特征波长所建立的PLS-DA模型得到了最优的分类预测性能,且受到速度影响较小,三种速度下(未特别注明均是指从低到高的三种速度)的判别正确率均大于90%,分别为95.1%,97.4%和93.3%;(2)结合PLS算法,对在线获取的草莓光谱数据建立草莓SSC含量预测模型。经MSC、S-G平滑和二阶导数预处理的全波段光谱模型性最优,三种速度下RPD值分别从1.39,1.27和1.07提高到1.60,1.53和1.48,使得模型具备一定的预测能力,此外还降低了速度对模型精度的影响;经过CARS算法提取特征波长不仅简化了模型,提高了计算效率还增强了模型的稳健性,三种速度下的R_p~2分别为0.702,0.733和0.707;RMSEP分别为0.892,0.699和0.761°Brix;RPD值分别为1.80,1.96和1.87。(3)利用德国INSION公司的NIR 1.7/S微型光谱仪,与集成光源的漫反射积分球,结合在线平台设计了面粉品质在线检测系统。并采用C++语言对光谱仪进行二次开发,自主编写了一款适用于面粉在线检测的控制软件NIRspec。针对面粉水分含量在线预测分析,所有样品的水分含量预测绝对误差在3%以下,66%的样品预测误差在2%以下。实际值与预测值的决定系数R~2为0.883,均方根误差RMSE为0.206%。(4)针对传统线性PLS模型的局限性,分别构建了基于机器学习的BP-ANN、SVR面粉水分含量在线预测模型。并在此基础上,进一步探索了基于深度学习理论的CNN模型。通过试验,分别确定了三种模型的结构及最佳参数,并将结果与传统线性PLS模型结果进行对比,发现非线性模型的泛化能力更强,且SVR模型的预测精度及稳健性最佳,其R_p~2为0.887,RMSEP为0.277%。同时发现基于深度学习的CNN模型也具有较好的预测能力,其R_p~2为0.776,RMSEP为0.339%,表明该方法在近红外光谱分析中具有一定潜力。"
1501,基于机器学习的非侵入式电力负荷监测及用户行为研究,"节约能源是当今世界的一种重要社会意识。有效的能源管理办法可以帮助减少能源的损耗。智能电网的普及和智能家居的发展,有效地提高了电能的利用效率,促进了节能减排和可持续发展战略的实施,同时也保证了供电的安全和可靠性,帮助用户的生活更加智能和便捷。然而,由于传统的智能家电、智能插头等侵入式负荷监测系统在时间和投资上的花费巨大,更为经济有效的非侵入式电力负荷监测研究逐渐兴起。非侵入式电力负荷监测技术通过对总负荷的用电情况进行监测和分析,得到单个用电器的运行情况,硬件设施简单,而且便于安装、切除和维修,对于电力公司、政府部门、设备制造商等各个行业以及用户群体来说,都具有广泛的价值。本研究针对目前人们对非侵入式负荷监测的应用领域关注度不够的问题,提出了一种对家用配电箱中分支电路的功能进行识别,进而实现用户行为异常检测的新想法。基于该想法,本研究利用一款新型的非侵入式负荷监测装置Smart DB,对一个实验家庭进行电力数据的采集。并根据Smart DB可以同时监测家用配电箱中10条分支电路用电情况的特性,从用户日常活动的角度,将家用配电箱中的多条分支电路按功能划分为7个类别,然后对各条分支电路的功能进行识别。为了提高识别算法对不同家庭的泛化能力,本研究将实验数据与其他研究小组发布的几个公用数据集进行整合,并选用支持向量机、决策树、随机森林以及极值梯度提升四种分类算法分别对数据集进行训练和建模,最终验证了集成分类器对比于单分类器的性能优势。之后通过对比详细分析了随机森林与极值梯度提升两种集成的分类算法对每个类别的分类效果。在识别出各条分支电路功能的基础上,本研究选取了其中两条分支电路的实验数据,结合PCA降维、K-均值和孤立森林三种算法对实验家庭的饮食行为和洗澡行为分别进行了模式学习和异常检测。找出了该实验家庭中饮食行为和洗澡行为的规律性,并检测出这两种行为模式中出现的异常情况。为了验证该异常检测算法的实用性和适用性,将最终的异常检测结果与实验用户提供的活动记录日志进行了对比和分析。从而得出结论,该算法检测出的异常点在一定程度上能够提醒用户有关安全、健康或者利益等方面的问题,帮助用户提高生活质量。"
1502,基于随机森林算法的水体范围智能提取方法及应用研究,"随着经济和社会的不断发展,对水资源的需求越来越大,水资源短缺和水环境恶化的问题越来越突出。为了节约用水,合理利用水资源,保护水源地及其周边生态环境,各级政府部门逐渐加大对水资源的监测。水体范围提取作为遥感影像在水资源监控及分析中的第一步,而现有的处理大批量遥感数据的算法的智能化程度还不够高。近些年来,人工智能的发展为信息处理带来了全新的变化,其中机器学习作为人工智能的一个分支,通过使用算法解析数据、学习数据特征,对新数据做出决策和预测,这极大的帮助了大规模遥感影像的自动化处理。其中,随机森林算法作为机器学习中的一个重要分支,因其稳定性强、速度快、所需样本量小等优点在遥感影像分类研究中得到广泛的应用。本文主要以GF-1 WFV影像作为数据源,利用影像的4个波段和影像特征值作为随机森林算法的输入特征,利用随机森林算法挖掘特征组合信息,构建水体提取智能算法样本库,提升遥感影像水体范围的提取效果。本文的研究工作主要包括:(1)对目前的水体提取算法进行了总结,并介绍了随机森林算法的优点及其在遥感领域的应用。(2)基于GF-1 WFV影像构建基于随机森林方法的水体范围提取模型。采用GF-1WFV影像获取的地物特征,进行随机森林算法分类特征选择与分析,遴选出对分类结果影响较大的特征,最终获取固定的输入特征结构。其次根据确定的输入特征结构,对随机森林算法的参数进行优化,确定随机森林模型的决策树数量(ntree)和决策树内部节点随机选择特征的个数(mtry)。(3)构建算法样本库。当将从不同的训练样本获得的模型文件应用于分类时,其分类结果存在较大差异。因此在遥感影像中选取相应的样本时,利用地物的光谱特征、纹理特征等信息,充分考虑水体和背景信息的差异,分析影像中包含的地物类型及各类地物可能的存在形式,构建水体提取智能算法样本库。(4)基于前面章节的分析,利用选取的地物样本,设置随机森林算法参数决策树个数ntree=70,决策树内部节点随机选择特征个数mtry=6构建模型,获取模型文件。利用获得的分类模型文件,通过随机森林方法对北方地区重要饮用水水源地影像进行水体提取,获得高质量数据集。"
1503,基于Spark+技术的入侵检测研究,"随着计算机及互联网技术的快速发展,互联网已经成为人们日常生活中不可或缺的部分,由于互联网的开放性,共享性等特性,各种网络入侵行为日益频繁。而我国作为全球互联网使用大国,网络入侵等行为已经成为危害我国信息产业持续健康发展的重要阻碍因素。如何对入侵行为进行分析研究,从而保护个人隐私和商业机密,是信息安全领域目前亟需解决的问题。入侵检测技术作为防止网络攻击行为的有效途径,是目前国内外本研究领域的研究热点之一。部分研究者将Adaboost算法等机器学习算法应用于入侵检测领域。然而由于传统Adaboost异常检测算法训练模型耗时较长、样本权值调整时没有对分类样本权值调整范围进行明确划分,致使算法在异常检测时检测效率较低、检测准确率较低、误判率较高,不能有效应对未知攻击行为。鉴于此,本文结合Spark+CUDA平台提出了改进Adaboost算法的入侵检测系统。论文主要研究内容如下:第一,论文分析了入侵检测领域国内外研究现状及目前研究存在的问题,综述了入侵检测的攻击类型、入侵检测系统的分类方式,之后研究设计了基于Spark+ELK框架的web日志采集系统。第二,针对传统Adaboost异常检测算法样本权重调整没有设定调整幅度及阈值,致使异常检测准确率较低且容易产生噪声数据的问题,设计了改进的Adaboost算法。从样本点权重和弱分类器权重两个方面对算法进行改进。在样本点权重改进中引入样本点前t-1轮分类正确率T(i)的判断,在样本点迭代更新权重时结合正确率T(i)对分类错误的样本权重值增加及分类正确的样本权重值减少的幅度进行明确划分;弱分类器改进中根据弱分类器分类特定样本点的优势,在组合分类器时适当调整该弱分类器权重,通过样本点误判率参数控制,实现了组合分类器中弱分类器权重的优化。通过KDD CUP 99数据集实验证明,改进算法的异常检测准确率高于传统算法并且误报率低于传统算法。第三,为进一步提升改进算法的运行效率,本文基于Spark+CUDA架构对改进Adaboost算法的并行化展开研究。将改进Adaboost算法中的样本点权重值计算、样本点前N轮正确率T(i)与错判率F(i)计算、弱分类器权重计算等复杂计算交由GPU执行,同时利用Spark集群技术对数据集进行分块处理。最后通过KDD CUP 99数据集及自采集的web日志数据集实验表明,该方法有效提高了改进Adaboost算法的运行效率。"
1504,基于不平衡数据的XGBoost性能优化研究,"XGBoost算法自2016年面世以来由于优点众多已成为当前热门的机器学习算法。XGBoost自带参数较多会涉及到繁琐的参数优化问题,目前针对XGBoost参数优化大多用经验法或穷举法,但存在很多缺点。如经验法过于依赖人为经验,常常费时费力;网格搜索对所有的参数组合逐一尝试,耗费时间过大,在实际应用中常采用缩小步长的方法,但容易错过最优值;随机搜索在搜索范围中随机抽取样本点,准确性无法保证,结果存在偶然性。在不平衡数据中,以整体分类精度最大化为目标的传统分类技术,会出现分类面偏移的现象,导致分类结果无法达到预期。XGBoost虽然通过设置参数scale_pos_weight来改变训练时的少数类样本权重以此提高少数类分类精度,但在不平衡数据中往往可以训练的少数类样本数目较少,因此该方法效果有限。鉴于此,本文在相关理论的基础上,从XGBoost参数优化、不平衡数据中的分类性能优化这两方面进行研究。(1)针对XGBoost参数优化问题,由于参数优化时相当于黑盒操作,无法知道内部的函数结构和性质,提出一种基于贝叶斯优化的XGBoost参数优化策略。该策略将XGBoost参数组合作为目标函数的输入,XGBoost通过交叉验证得到的评价函数的均值作为目标函数的输出,不断添加新的样本来更新目标函数的后验分布,直到后验分布近似逼近真实的目标函数,从而得到最优的XGBoost参数组合。该策略由于会参照过往的参数值,对搜索距离没有限制,因此可以在较短的时间内获得较优的XGBoost参数。实验结果表明,该策略较网格搜索时间消耗大幅减少,较随机搜索能找到更优的参数组合,使得时间消耗和参数优化结果达到较好的平衡。(2)针对XGBoost不平衡数据分类问题,提出一种新的基于混合采样的XGBoost集成算法。该集成算法首先使用EasyEnsemble算法从多数类样本中随机抽取多个样本子集,并分别与少数类样本进行合并,然后通过Borderline-SMOTE2算法增添少数类样本,最终组成多个类别平衡的训练子集。XGBoost作为基分类器在每个训练子集上进行训练,使基分类器之间存在差异且单个性能达到最优,最后将所有满足条件的XGBoost基分类器集成为强分类器,从而提升在不平衡数据中的分类性能。实验结果表明,该集成算法较常见不平衡分类算法和原有单一XGBoost算法,分类性能得到较大提升。"
1505,中文微博情感分析技术研究,"随着互联网的高速发展,市面上涌现出了许多的优秀互联网应用,其中也包括微博这样具有社交性质的互联网应用。微博以其开放性、原创性、便捷性、草根性和背对脸等特点,在极短的时间内吸引了庞大的用户群体,成为了用户们最喜爱发声的“地区”之一。大数据时代的到来让人们逐渐发现了海量微博数据中存在的潜在价值,通过微博来了解用户们对当前话题所产生的情感,随即成为众多学者所追求的热点。微博情感分析主要是对微博的情感倾向进行判别,判别方法主要有基于机器学习的方法和基于情感词典的方法,这两种方法在文中均有所涉及。本文从扩充情感词典和改进情感分类方法两个方面进行了深入研究,主要工作内容如下:(1)通过制定数据降噪规则,扩充分词工具的用户自定义词库,去除停用词等步骤完成微博数据的预处理。利用投票机制和优先权机制对知网情感词典、台湾大学中文情感极性词典和大连理工大学中文情感词汇本体库进行整合,构建了基础情感词典。(2)在词典的扩充方面,本文在基于词向量的情感词典扩充方法中加入人工智能领域中常用的基于案例推理的思想,提出了C-word2vec模型。原始的word2vec模型在整个新情感词的识别过程中使用的基础情感词典是没有任何改变的,而C-word2vec模型会把新识别出的情感词加入基础情感词典,提高了情感词识别的召回率。(3)在规则的制定方面,本文综合考虑了否定词、程度副词和表情对微博情感分类的影响,制定了相应的情感打分规则。实验结果表明,考虑了规则的方法比没有考虑规则的方法准确率更高。(4)在基于机器学习情感分类方法的框架下,引入了情感词典和规则,提出了综合的情感分类方法。该方法让特征的提取不在局限于已经标注好的数据集,同时能够在提取到的特征中保留更多的词间语义。文本使用该方法在微博数据集上进行了验证,证明了其有效性和可行性。"
1506,基于注意力机制的文本生成式摘要方法研究,"伴随互联网和信息技术的飞速发展,互联网上的数据和文件呈爆炸式的增长,信息超载问题愈益严重。因此,如何从海量的数据中快速、准确获取有用信息变得重要。文本自动摘要技术是一种从文本文档、文章或博客等较大的文本集合中产生简洁而重要的信息的方法,已成为国内外的研究热点。的研究集中在抽取式摘要,从原文中抽取句子表示摘要,但不够精炼,表示效果差强人意。而生成式摘要是通过理解文本内容,从而生成新句子,与抽取式摘要相比,有着更为灵活的词汇组合和表达方式。基于此,本文将分析文本底层编码特征、文本词向量表示、注意力模型机制、等,从底层到模型结构全方位来展开对生成式摘要问题的研究。主要完成了以下工作:(1)采用了一种基于知识迁移融合多特征的文档词向量表示方法。词向量作为文本特征表示的基础工作,其表达的准确率直接影响各个上层模型结果的性能。用词嵌入技术训练词向量时,越多的文本数据训练出的词向量质量越高,所以本文用维基百科外部数据集,采用知识迁移的方法在任务训练集上进行增量训练,从而训练改善词向量质量。同时,在文本分类和摘要研究中,文本词的一些其它特征如词频逆文档频率等也被广泛使用,并取得不错的效果。为进一步提高文本中词表征质量,本文采用将词频逆文档频率、词性等特征和知识迁移后的词向量进行融合,产生新的词向量,并通过实验验证了本文采用的词向量表示方法的优越性。(2)采用一种基于注意力机制的指针覆盖文本摘要方法。在此方法中,采用两个双向长短时记忆网络(LSTM-RNN)捕获文档两个重要级别的信息,一个在单词级别,另一个在句子级别。然后,在这两个层面上引入注意力机制,让模型关注重点词。最后,解码阶段引入混合指针生成器网络,用生成概率和复制文本的概率叠加生成最后的摘要。本方法,消除了低频词的干扰,捕捉了句词结构,很好结合了利用原文本还是生成新的词的问题,提高了摘要生成的性能。(3)设计并实现了基于注意力机制的自动摘要原型系统。"
1507,基于遥感技术的水上油料和化学品的厚度预测研究,"本文主要研究了水体泄漏柴油、原油、苯乙烯的反射率光谱与其污染物厚度间的关系,对水上污染物厚度预测实验的可行性进行了分析研究,在此基础上主要是针对低空无人机(多光谱)和地物(高光谱)不同观测平台下获得的两种光谱数据,分别提取了不同污染物的厚度预测变量。然后,通过多元线性回归、偏最小二乘、支持向量机和随机森林四种预测模型分别建立了水上柴油、原油、苯乙烯泄漏的厚度估算研究,主要的实验结果如下:(1)利用无人机多光谱影像作为水上污染物厚度反演时,首先通过选取感兴趣区域,提取图像中实验范围内的多光谱数据,观察水上柴油、原油、苯乙烯的污染物光谱与其他周围环境的地物特征差异,并利用该差异对研究区域的图像进行了处理。然后,基于获取的四个波段通过波段组合公式进行了筛选,选定对柴油、原油、苯乙烯三种样品厚度相对较为敏感的波段以及波段组合,对建模样本中提取的11个光谱参数建立了MLR和RF预测模型。从模型预测效果可以看出,随机森林模型的整体预测精度要优于多元线性回归模型的反演效果。但总体利用无人机多光谱影像数据来预测水上污染物厚度变化,其模型预测精度并不是特别理想。(2)利用地面高光谱做水上污染物厚度反演时,柴油、原油、苯乙烯在12种光谱形式变换和19种特征参数与不同厚度的水上污染物的相关性分析研究中。柴油提取了9个预测变量、原油提取了8个预测变量、苯乙烯提取了9个预测变量参与厚度模型研究。3种污染物分别经过了多元线性回归、偏最小二乘回归、支持向量机和随机森林进行建模,由于样本量较少,在建模过程中主要通过“留一法”交叉验证的形式检验模型的预测能力。实验结果发现,通过以上四种模型预测研究得到的实测值与反演值之间的相关性相对较高,RMSE都比较理想,并且比较四种反演模型可以得出随机森林的决定系数较高,拟合效果最好。利用随机森林模型,柴油、原油、苯乙烯厚度预测值与实测值的相关系数分别达到0.9555、0.8756、0.9111,均方根误差则分别为14.76、20.82、24.64。"
1508,基于机器学习的A股量化价值投资研究,"价值投资理论由格雷厄姆提出,经过几十年的不断完善发展,已经成为了一套完整的投资体系。在当今的主流投资市场上,价值投资得到了广泛的应用。我国股市由于起步较晚,且初期充满着各种非理性投资和内幕交易,这使得价值投资毫无用武之地。但在近些年随着证监会的从严监管,市场环境不断好转,证券市场逐步走向规范,投资行为也日趋理性。在此情形下,价值投资在我国证券市场上将有着广阔的发挥空间。而根据我国股市的实际情况对价值投资理论进行实证研究也就具有十分深刻的现实意义。在此基础上,本文将尝试从理论和实证两个方面展开。本文主要针对三个问题进行研究。(1)如何从A股市场上3000多家上市公司中找出那些业绩优异、成长性好的具有投资价值的公司。(2)如何从那些具有投资价值的公司中找出被市场低估的公司,从而建立股票池。(3)如何对股票池中的股票权重进行配置,以满足不同投资风格的需要。针对以上问题本文运用理论分析和实证研究相结合的方法进行研究。首先在理论分析中阐述了传统价值投资理论及其他三种投资理论(增长投资理论、指数投资理论和组合投资理论),然后在传统投资的基础上融合了其他投资理论的优点并在实证部分进行了体现。在实证分析中,针对第一个问题,本文采用BP神经网络的方法对有完整数据的2630家上市公司进行筛选,筛选的标准基于2014年至2017年上市公司的基本面信息,最终筛选出656家具有投资价值的上市公司。针对第二个问题,本文采用支持向量机和BSM模型对筛选出的上市公司进行估值,找出那些被价值低估的股票,最终找出91家价值被低估的上市公司,并建立了股票池。针对第三个问题,本文采用五种不同风格的权重配置策略(价格加权法、市值加权法、等权重法、均值方差模型以及BL模型)对股票池中的股票进行权重配比,并对不同风格的权重配置策略进行了比较,最终得出了等权重法配置出的股票组合收益率最高,最后将这五种不同风格的权重配置策略所得到的收益率与沪深300指数的收益率进行对比,得出了通过基于机器学习的A股价值投资策略可以获得超额收益的结论。本文的特色在于在价值投资理论的基础上融合了其他投资理论的优点,并将机器学习的方法应用于价值投资理论的实际操作中,最终发现应用机器学习的价值投资策略在A股市场上可以获得超额收益。"
1509,基于特征融合与机器学习的RGB-D图像识别技术研究,"与传统的基于二维图像的识别相比,三维的图像识别由于其引入的深度信息,使得其具有更高的准确率和鲁棒性。这是因为三维的RGB-D图像不仅包含了二维图像的颜色、纹理信息,其中的深度图像还包含了目标的表面几何信息。随着Kinect、Xtion等三维体感设备的兴起,RGB-D图像的获取越来越便捷,RGB-D图像的识别技术也越来越成为机器视觉领域的研究热点。另一方面,近年来机器学习在图像识别领域取得了令人瞩目的成绩,特别是卷积神经网络,在大规模数据集的图像识别任务中取得了突破性的进展。基于机器学习算法的RGB-D图像识别成为了机器视觉中的热点问题。针对以往RGB-D图像的特征提取算法存在计算复杂、特征提取不充分以及特征信息冗余等问题,本文提出了一种RGB-D图像的彩色-深度局部Gist特征提取算法。首先将RGB图分解为R、G、B三个通道的图,分别提取三个通道图的局部Gist特征,同时提取深度图的局部Gist特征,通过按行融合的方式组成RGB-D图像的彩色-深度局部Gist特征。对彩色-深度局部Gist特征使用主成分分析法降维后,用K-means++算法聚类构建RGB-D图像的视觉词典,最后基于支持向量机分类器对RGB-D图像进行分类。实验结果表明本文的特征提取算法可以有效提高RGB-D图像分类的准确率。鉴于目前卷积神经网络在大规模图像数据集上的优异表现,本文提出一种改进的双流卷积神经网络的RGB-D图像识别算法。该算法设计了两个结构相同的卷积神经网络分别以RGB图与深度图的彩色映射作为输入,两个网络独立训练,再在全连接层进行网络的融合。针对融合的方式,本文设计了一种最优权值法,即根据两个网络的识别准确率赋予两个网络不同的融合系数。通过实验表明,改进的双流卷积网络识别准确率比单输入卷积网络的高,且采用最优权值法提高了双流卷积神经网络的RGB-D图像识别准确率。"
1510,基于异质集成学习的虚假评论检测研究,"由于网购接触不到商品,所以用户只能从电商平台上了解相关的产品信息,其中评论信息越来越被用户重视。许多商家发现好评能带来巨额回报,差评能让对手亏损甚至倒闭,所以“刷评”行为一直存在。为了防止卖家的恶性竞争、保证电商平台能够公平交易、保护消费者的权益不受侵犯,检测虚假评论一直是个研究热点。本文对虚假评论检测进行深入研究,主要工作分为以下几个方面:首先,针对Word2vec模型无法识别英语中的词对信息进行改进,提出了Bigram-Word2vec模型。该模型首先利用Bigram模型识别英语中的词对信息,在此基础上,对文本信息进行处理以后,再输入到Word2vec模型中训练相关的词向量。其次,由于词对取值个数的不同,Bigram-Word2vec模型训练出来的词向量的质量也不同。为了进一步优化Bigram-Word2vec模型,本文尝试了取多组值用于训练词向量,以寻找最优的词向量。再次,为了解决传统的虚假评论检测领域中使用单一的机器学习模型的问题,本文将异质集成学习领域中的相关知识应用到虚假评论检测领域中。在尝试将多个异质模型进行集成的过程中,针对异质集成学习中硬投票法遇到投票数相同及软投票法中权重如何设置的问题,提出了两种解决方式:二分类加权硬投票法和加权软投票法。最后,本文使用多种文本特征提取方法对亚马逊数据集进行特征提取,再结合多个模型对文本进行分类。为了对分类结果不理想的原因做出解释提出了“词重复率”的概念。同时也在该数据集上验证了本文提出的方法。"
1511,基于语料特征的文本分类算法研究,"互联网的快速发展使得文本信息大量增加,如何对有价值的文本信息进行精确分类是自然语言处理领域研究的热点之一。在进行文本分类时,由于传统方法容易忽略语料特征对分类效果的影响,因此考虑语料本身特征会对文本分类产生积极影响。该文采用有监督机器学习和深度学习分类算法,基于语料特征对文本分类进行了以下研究。首先,针对情感语料情感特征不明显问题,改进了词频逆文档(Term Frequency-Inverse Document Frequency,TF-IDF)特征权重算法。通过构建语料专用情感词典,匹配情感语料,实现了情感语料的特征增强和冗余信息去除,优化了用于情感语料分类的词频逆文档向量空间模型。实验结果证明,针对情感语料,该模型在多种分类器上提高了分类性能。其次,针对文本语料长度不平衡问题,基于卷积神经网络和长短期记忆网络分类模型,改进了模型处理语料数据的方法。在模型数据输入上,采用语句自循环方式对文本语料进行等长化处理,以达到调动全局神经单元提取特征的目的。实验结果表明,该方法加快了模型的收敛速度,提高了不等长语料分类的性能表现。最后,针对特定语料主题性强、上下文语义联系紧密的特点,设计了一种结合卷积神经网络和双向门控循环神经网络的分类模型。该模型采用自训练主题词向量,加强了词语的语义联系,结合卷积神经网络提取局部特征和双向门控循环神经网络捕捉特征前后联系的优势,对语料进行特征降维和上下文语义抽取。实验表明该模型降低了语料数据维度,节省了网络计算资源,提高了特定语料分类的准确率。"
1512,基于机器学习的运动目标检测与跟踪算法研究,"无人机由于体积小、成本低、灵活易操作等特点得到各领域的广泛关注,在应急救援、农业植保、军事侦察、地质勘探、环境监测、影视娱乐等行业应用领域需求旺盛。运动目标检测及跟踪是无人机航拍方面研究的基础内容之一,为实现无人机地跟踪拍摄,运动目标的检测及跟踪必不可少。本文采用随机森林(Random Forest,RF)和核相关滤波(Kernelized Correlation Filter,KCF)算法,围绕运动目标检测及跟踪这一课题,对运动目标的特征提取、边界检测、遮挡检测机制等算法进行了研究,最后将EBKCF(Edges Boxes with Kernelized Correlation Filter,EBKCF)算法移植到Manifold上,验证EBKCF算法的有效性。首先,由于结构随机森林(Structured Random Forest,SRF)的特征提取算法复杂,造成运动目标检测时间过长,本文提出了一种简单的梯度提取算法Simple-gradient。该算法减少了特征提取的复杂度,减少了算法提取时间,缩短了运动目标模型的训练时间以及运动目标边界检测时间;针对多棵决策树之间可能存在冗余,利用间隔减量均值计算SRF元分类器的相似性,剔除具有较高相似性且重要性低的决策树。其次,针对核相关滤波类运动目标跟踪算法,提出了一种遮挡检测机制Mean Peak-to Correlation Energy(MPCE)指标,以解决视野内遮挡导致的运动目标跟丢问题。根据遮挡检测因子与阈值的关系判断当前图像中是否存在遮挡,以提高算法在遮挡情况下的跟踪准确度;同时针对运动目标尺度变化导致的跟踪目标漂移现象,利用SRF算法检测运动目标边界,结合Edges Boxes算法更新运动目标尺度,对多个候选结果采用提案否决机制得到较准确的运动目标框。实验结果表示,对存在遮挡和尺度变化的情况,本文算法能准确跟踪运动目标。最后,为验证EBKCF算法有效,以Guidance视觉系统结合Manifold机载计算机,搭载大疆经纬Matrice100(M100)无人机飞行平台,移植EBKCF和KCF算法到Manifold中,根据当前实验条件分别设计尺度变化和遮挡检测实验过程,实现运动目标跟踪。通过KCF算法和EBKCF算法的对比实验表明,EBKCF算法能准确跟踪出现遮挡和尺度变化的运动目标。"
1513,基于软件度量的软件缓存区溢出漏洞预测方法研究,"在网络安全问题日益严峻的情况下,软件的缓存区溢出是软件漏洞中最常见和最严重的漏洞,缓存区溢出漏洞导致了一些信息窃取、资源被控、系统崩溃等危害。针对此研究问题本文提出了一种基于软件度量缓存区溢出漏洞预测的方法研究。本文中提出了基于决策树算法度量函数级别多类型的缓存区溢出漏洞预测方法,此外本文还针对数据不平衡现象提出基于随机森林算法度量函数级别的缓存区溢出漏洞预测方法。主要内容如下:首先,针对不同类型的软件缓存区溢出漏洞进行研究,采用软件度量方法对软件的源代码进行静态分析,分析了基于软件度量和机器学习分类算法相结合预测软件缓存区溢出漏洞的研究方法,并针对缓存区溢出漏洞的数据不平衡特征进行研究。其次,依据软件的源代码提取出相应的软件度量指标采取互信息方法进行特征选择,结合软件实际运行过程中函数之间的调用关系,利用数据提取的方法在不同类别的缓存区溢出漏洞数据中提取出基于函数级别的动态数据流的数据,在此基础上采取决策树算法提出了一种SVL缓存区溢出漏洞预测方法。再次,基于本文提出的SVL缓存区漏洞预测方法,针对软件中实际提取出的数据存在不平衡的现象,提出了在SVL缓存区漏洞预测方法的基础上,数据层面中采用基于遗传算法改进的SMOTE算法对不平衡数据集进行过采样处理,选取随机森林的集成算法针对软件缓存区漏洞进行预测。最后,在真实程序提取出C/C++数据集和Java数据集,并对基于决策树算法度量函数级别多类型的缓存区溢出漏洞预测方法进行了实验,在Java数据集中对基于随机森林算法度量函数级别的缓存区溢出漏洞预测方法进行了实验。"
1514,基于SVM的电商评论文本情感倾向性分析,"当今世界,电子商务平台飞速发展,海量的用户评论文本也由此产生。这些评论文本中包含了购买者对产品的情感倾向,如:“正向”、“负向”等。研究这些评论文本的情感倾向性,有助于平台管理者了解产品的优势和不足之处,便于日后的产品改进。同时,在获取到评论文本中的情感信息后,潜在的用户更容易做出正确的消费决策。而本文的研究方向是对电商平台的评论文本进行情感倾向性分析,在实验与研究过程中发现了模型构建的向量空间质量不够好,并且在长评论文本与短评论文本数据集上,SVM与MNB算法的表现刚好相反,因此由两个算法单独构建的模型并不具有一般适用性。为了解决这些问题,本文提出了两种改进方法:首先,将语料库及情感词典投入Word2vec模型中,构建两个词向量空间,并将两者进行特征组合;其次改进传统机器学习算法SVM,将其与MNB算法结合,构建分类器。本文的主要内容由以下几个部分组成:首先,本文介绍了文本情感倾向性分析目前的研究现状,对目前主流的文本情感倾向性分析方法做了简要概述,分析了已有的方法的现状及不足,并介绍了常用的文本向量化和文本情感分类的相关方法。其次,本文对Word2vec算法进行了深入研究,提出了基于Word2vec的特征优化算法。该算法加入了大型语料库及情感词典,将常用特征和特定特征进行组合,对特征进行了组合与优化。再次,本文对SVM与MNB算法进行了简要介绍,并且深入研究了两个算法在情感分类器上的各自的优点。在此基础上,将SVM算法与MNB算法进行融合,构建了SVM-MNB情感分类模型。最后,本文通过相关实验对改进的模型进行了验证,并与其它模型进行对比和分析。"
1515,面向多样性需求和服务资源匹配的推荐算法研究,"由于互联网规模和覆盖方面的快速增长导致信息过载的问题:过多的信息使得用户无法获得对自己有用的部分,信息的使用效率反而变低;同时使得商家无法让自己的产品有效展现在对它感兴趣的群体上。所以,如何提高推荐算法的精确性、推荐结果的多样性、增强推荐结果的可解释性以获得用户更多信任都是推荐系统研究的重点。本文首先提出了基于联合特征提升推荐系统多样性的方法。该方法利用MovieLens电影推荐数据集,针对现有二次优化算法不能主动提升推荐多样性的不足,提出了本文的改进方案,即对基于矩阵相似性求解联合特征的思想进行改进应用到推荐领域,通过求解出对不同品类都有促进作用的联合特征(标签),向用户推荐未涉足领域的可能感兴趣的产品,以此达到主动提升推荐多样性的效果,该方法在推荐过程中就考虑了推荐结果的多样性,避免了多数推荐方法只是二次优化带来的假设缺陷问题,且联合特征的发掘具有良好的可解释性,能够更加清晰地向用户解释推荐其他产品的原因,让用户更加信任该系统。本文接着提出了基于随机森林的需求偏好分析与服务资源推荐算法。此算法包含三个环节。在采样环节,为了提高模型的准确度和采样合理度,提出了基于组合原理的负样本采集算法;在属性分析环节,提出基于随机森林的用户偏好属性分析算法,实现了属性间深层关系的计算,且需求偏好分析环节具有良好的可解释性;最后在推荐环节,提出了基于显性评分的用户分群的算法,接着对用户已涉足领域进行推荐,使得推荐的结果结合用户自身兴趣和所在相似购买兴趣群体的兴趣,避免了超特化问题。"
1516,基于机器学习的个人数据平台推荐系统的研究与实现,"随着信息技术的发展,人们越来越多使用互联网获取新闻,购物,观看影片等。伴随网络中的数据量急速增大,推荐系统成为了解决信息过载的重要方法。与此同时,“个人数据管理平台”抓取了用户在各个平台上的信息,拥有海量数据,如何利用这些数据对用户精准推荐也恰好是推荐系统的研究领域。目前,最为广泛应用的推荐算法是协同过滤算法。然而,该算法也面临诸多问题,如相似度模型较为朴素、预测过程未考虑用户偏好模型以及当项目增加时,有潜在的性能问题。基于以上的问题,本文对相似度模型、用户偏好模型和拓展性问题进行了研究,提出了一种改进的协同过滤推荐算法,取得了如下的主要研究成果:(1)在相似度度量问题上,提出了一种新的度量模型。该模型受NLP领域中的词嵌入思想的启发,分别通过将项目的共现信息与项目的简介信息分别映射到低维的向量空间中,得到关于项目的两种向量表示方法。最后将两种表示结合起来,按权重计算相似度。在项目共现的嵌入中,提出了f-item2vec模型,该模型引入了项目评分因子,进而增大高分项目的相似度;针对项目简介信息,先分词,然后使用doc2vec的方法训练项目的向量。与现有相似度模型相比,本文提出的相似度模型不仅能捕捉到评分特征,还能捕捉共现特征和内容特征,得到的相似度结果更准确。(2)在预测评分中,引入了用户的偏好模型。本文提出了基于长短期兴趣的用户偏好模型。该模型将用户的偏好分为短期和长期两部分,分别计算短期兴趣和长期兴趣权重,最后融合生成偏好权重。在引入用户偏好模型后,当使用用户的历史数据预测当前评分时,与当前预测项目同类的项目所占的比重更大,预测结果效果也比传统方法更好。(3)提出了基于项目聚类的推荐方法解决潜在的性能问题。具体的,通过相似度模型得到项目向量后,运用聚类算法对项目进行聚类,并在预测评分时载入与待预测项目在统一聚类中的项目,在此聚类集合中找到最近邻并预测评分。该方法避免了在寻找最近邻居时读入全体项目数据,节省了时间和内存开销。"
1517,基于贝叶斯的网络入侵检测方法研究,"入侵检测是指监测网络数据信息,快速检测出入侵行为,避免入侵造成的危害。传统的入侵检测方法都集中在基于规则文件的入侵检测与基于数据挖掘的入侵检测。前者不能检测出新的攻击类型,后者大部分检测时间较长。首先,本文介绍了拒绝服务攻击、来自远程主机的未授权访问、来未授权的本地超级用户特权访问和端口扫描四种攻击类型。然后分析了每种攻击类型的特点,并对网络数据的特征属性进行了分析与定义。其次,针对基于数据挖掘的入侵检测方法,提出了在入侵检测中表现较好的梯度提升树(GBDT)模型,通过测试检测正确率达到92.63%,并重点分析了模型针对不同攻击类型的检测效果。然后总结了机器学习的入侵检测模型的缺陷,即虽然可以适应新的攻击类型但表现并不好,还有训练时间长和计算复杂度高的问题。再次,针对数据挖掘方法的检测时间长的问题,又提出了基于改进的主成分分析与高斯朴素贝叶斯相结合的入侵检测方法。对传统的主成分分析的前三个特征向量进行加权处理,以降低数据污染,然后再通过改进的主成分分析对数据降维,最后使用高斯朴素贝叶斯分类器检测出入侵行为,并用检测准确率、检测时间、查准率和召回率等指标对模型进行评价。实验结果表明相比于传统的贝叶斯方法,本文提出的方法将检测时间缩短了60%,缩短至0.5s,检测率提升至90.53%。最后通过交叉验证,方法的检测正确率的平均值在85%左右。最后,简要介绍了传统的基于规则文件的入侵检测方法,并与本文提出的两种机器学习入侵检测模型进行了对比,并对入侵检测的未来进行展望。"
1518,基于LSTM和小波变换的网络流量预测模型研究,"随着互联网的不断发展,网络业务种类日益繁多,网络业务总量持续增长。为了更合理地分配网络资源,更好地保障网络服务质量,一个准确有效的网络流量预测模型是必要的。然而,现代网络下的网络流量呈现出多种非线性特征。这使得传统的基于统计的流量模型不再适用于网络流量特征的描述,基于线性回归的方法也难以对非线性的网络流量做出精准的预测。近年来,机器学习方法的发展为网络流量预测问题提供了新的解决思路。本文在总结传统流量模型的基础上,对适用于网络流量预测的支持向量机和神经网络方法进行了研究和探讨,并结合混沌理论与小波分析理论提出了新型流量预测模型的构建方法。本文的主要工作与贡献如下:其一,提出了一种基于相空间重构的长短期记忆流量预测模型。该模型融合了混沌理论中的相空间重构方法,将流量序列还原到高维空间,并通过重构后的流量序列构建样本数据。设计了一种长短期记忆循环神经网络,以此学习流量序列的非线性特征,完成流量预测模型的构建。实验结果表明,相比基于BP神经网络和基于Elman神经网络的预测模型,基于长短期记忆神经网络的预测模型具有更高的预测精度。其二,提出了一种基于小波分解与重构的混合流量预测模型。该模型融合了小波分析理论中的离散小波分解与重构方法,将流量序列的趋势及波动特征分散到不同的分量序列中。依据支持向量机和神经网络方法对每一个分量序列构建了分量模型,设计了分量模型中的数据分割方法、模型训练方法与序列预测方法。通过比较预测误差选取了最优的分量模型,最后使用小波重构对各分量模型的预测结果进行了整合。实验结果表明,混合流量预测模型具有较高的预测精度,且分量模型择优的方法能够有效地提高分解重构模型的预测准确性。上述两个模型分别基于短期的网络流量与长期的网络流量构建。前者适用于具有突发性的短期流量,对实时的网络流量预测具有一定的借鉴意义;后者适用于具有周期性变化及波动特征的流量,对长期的网络流量预测具有一定的理论与应用价值。"
1519,机器学习在人力资源管理系统中的应用,"随着信息化管理的日益普及,信息化管理系统已经成为企业竞争和发展中必不可缺的重要工具。然而现代企业中的人力资源管理系统却面临着许多问题,例如手动录入数据量较大、数据格式混乱不统一以及无法有效地对海量数据进行管理和分析等问题。为了优化资源管理过程,减少业务工作量,提高办事效率,通过引入机器学习的方法来实现人力资源管理系统的功能,可以减少业务工作量,从而提高办事的效率和系统的性能。通过将机器学习技术应用到人力资源管理系统上,设计并实现了薪资预测模型和离职预测模型两种模型。其中薪资预测属于回归预测,它是通过利用简历的内容信息来预测应聘人员的录用薪资,模型是基于三层BP神经网络实现,采用了小批量梯度下降法作为收敛方向搜索算法,并利用结合了附加动量法和自适应学习速率法两种方法的混合算法Nadm来对模型进行优化,加快了模型训练的收敛速度以及提高了预测结果的准确率,最终预测模型的准确率可以达到77.3%;离职预测属于分类预测,模型是基于Logistic回归实现,采用了交叉熵函数作为目标函数,并利用牛顿迭代法和正则化来对模型进行了优化,加快了模型训练的收敛速度,最终预测模型的正确率可以达到73%。通过设计了一系列实验,将实现的两个预测模型与其他相关的机器学习算法进行了对比,验证了这两个预测模型的有效性,同时这两个预测模型在测试实验中准确率都比较高,说明了它们具有一定的实际应用参考价值,也进一步说明了机器学习在人力资源管理系统中的应用是具有相当大的发展潜力的。"
1520,基于KNN的分类方法及其应用研究,"机器学习技术在各个领域中得到了广泛应用,该领域中的KNN模型利用自身超强的实用性得到了很多学者的青睐。在将KNN应用到实际问题中时,为了得到更好的效果,需要对传统的KNN模型进行相关改进,本文针对KNN模型用于分类问题以及基于实际的应用场景即抽油机故障诊断问题,对传统KNN模型进行分析和改进,目的在于提高抽油机故障诊断的准确性。首先,针对故障分类要用到的示功图数据,对示功图的定义以及各种故障类别下的示功图的形状特点进行了详细说明。在此基础上将示功图看成由离散点构成的图形,然后直接从图形角度进行示功图特征提取,省去了转换成图像再进行特征提取的繁琐,在从图形角度进行特征提取上,观察到不同故障类型所对应的示功图相较于理论示功图不同区域的面积变化,提出了基于面积分割的示功图提取方法。其次,分析了传统距离度量方式下KNN的故障分类效果,并对KNN模型中距离度量方式进行了改进,最终得到了基于KNN的抽油机故障分类模型。最后,实验对比不同距离度量方式下的KNN模型的故障分类结果,通过机器学习领域在多分类问题中的常用衡量指标来验证改进的KNN模型在抽油机故障分类问题上的有效性和可行性。"
1521,基于神经网络模型的制造业上市公司财务危机预警研究,"伴随着人工智能的不断进步,机器学习引领的“金融科技”掀起一场新的浪潮,其应用遍及各个领域。与此同时,受外部金融危机和市场竞争的影响,企业面对的财务风险也不断增多,因此,寻找合适的财务预警模型一直是国内外学者研究的重点问题。不同行业的财务预警模型有不同的特点,本文以制造业上市公司为研究对象,制造业是国民经济的支柱,并且在A股市场中制造业上市公司占比重大。本文采用定性与定量相结合的方式。阅读了大量相关经典文献和书籍,总结了实践经验,从内外两个方面分析了上市公司财务危机形成的背景原因,梳理了财务危机预警的重要性和功能。在模型的构建方面,从财务因素和非财务因素归纳了影响财务危机的指标,选取2016年―2018年首次被特别处理的制造业ST公司,与之对应,按照1:1的比例选取资产规模与行业相近的非ST公司进行配对,共确定120家公司,其中训练样本100家,测试样本20家。运用多重共线性检验、KMO和Bartlett球形检验和因子分析检验后,筛选出了具有价值的六大预警指标。在此基础上,利用MATLAB中trainlm算法训练神经网络模型,最后检验测试样本得出模型的准确率达到80%,说明模型能够判断公司是否出现财务危机。最后针对制造业上市公司财务风险提出了五点建议:(1)建立透明和高效的内部控制制度,完善内控流程;(2)制定合理的借款计划和还款计划;(3)加强现金流管理,并使之与公司战略发展相融合;(4)增强上市公司盈利能力和成长能力;(5)提升上市公司市场价值,扩大销售市场的份额和资本市场的市值。"
1522,用户画像系统的研究与实现,"随着人工智能各式产品的诞生,用户的行为数据在广度、深度以及精度上都有很大的变化,数据成为一种重要的资源。用户数据在简单统计查询层面上的技术已经比较成熟,现在倾向于利用深度学习、机器学习等人工智能相关技术对数据进行深入理解和探索。用户画像是通过对用户数据深度挖掘,得到用户的标签。商家可以依据画像全面了解用户分布,提供个性化的服务,提升产品的用户体验,并且用户画像可以为一些决策提供事实支撑。所以众多商业智能系统中用户画像必不可少。相较于以往研究者和相关从业者基于简单查询统计的方法构建用户画像,本文依据企业实际业务需求,应用大数据机器学习模型完成人口属性标签的构建,创新性地将深度学习模型引入了用户兴趣标签的构建。本文首先采集用户的APP行为或文本数据,然后从数据仓库清洗原始数据、抽取训练样本,人口属性标签选取的量级是253万,其中性别标签的用户量级27万,学历标签量级226万,兴趣标签中负样本60931,正样本110388。然后在人口属性标签的分类预测中,用到了APP行为数据,对比了不同特征构建方法和LR、SVM模型分别对结果的影响,在兴趣标签的意图识别上,用到了文本数据,对比了目前NLP领域最流行的几种深度模型Bert、Transformer、Bi-LSTM+Attention和CNN的效果。最后结果表明,对于人口属性标签构建,特征使用app名称的索引值映射为0或1,样本采样比例设为1.0,模型选择逻辑回归+L2正则地效果最好,年龄预测的整体准确率可以达到85.2%,学历预测的整体准确率可以达到74.5%。对于兴趣标签的构建,经过预训练得到的Bert模型在下游分类任务中的确有很大优势,能准确的判断用户意图,兴趣标签预测的准确率达到99.0%。"
1523,面向科研人员评估的社交网络分析与研究,"如今,评价科研人员的标准的具体方式较少,如依照参与项目完成程度、发表论文的多少、考勤情况等这类重视结果的形式。但是这种过于单一的形式不能充分的反映出某一科研人员的实际工作能力和情况。在日常工作时,会产生大量有价值、可利用的工作信息,如邮箱来往信息、参加会议和活动、甚至出差产生的数据等都值得挖掘。光凭人自身的能力很难分析这些信息,但这些信息得到挖掘后是可以在一定程度上完善考核形式的。目前,社交网络技术大多应用在依托互联网的在线社交网络:分析新浪微博用户的关注和转发网络能够预测用户转发行为,研究Facebook上用户行为能够发现热点事件中的社会参与者及角色,对Twitter上的STEM教育社区进行研究能够分析用户特征并挖掘关键用户。然而,工作网络由于其活跃用户范围小、活跃度差、物理隔离等原因,社交网络技术几乎没在此领域得到关注。使用这种工作网络的科研人员在工作中通过工作邮箱、参加会议、出差等活动产生了大量数据,这些数据对业绩考核及人员管理有很大的应用价值。由于这些数据包含的信息繁复且含有大量冗余数据,其价值未能得到充分利用。本文通过对这些数据进行组织和重构,得到易于存储和使用的数据集,从而构建科研人员的工作社交网络,利用社交网络分析技术对其进行分析。本文首先通过数据清洗、抽取等手段对数据资源进行预处理,使存在于不同系统中的数据形成有效的关联,如工作中产生的邮件数据、参加会议产生的数据及出差活动产生的数据,最终得到三个数据集:邮件数据集,会议数据集和出差数据集。其次综合这些多源数据集,基于社交网络技术和力导布局算法,构建科研人员工作中的关系网络。最后借助社交网络分析方法,基于网络节点重要性估值方法,挖掘工作网络中的重要节点,找出工作社群中的社交达人、技术大牛,以及在工作中起到侨联作用的关键人。这些分析结果可用于考察不同部门、团队间的合作模式,优化部门、团队和工作安排。综合分析并研究实验结果,可以进一步有效分析人员在工作中的积极性和周期性,可作为传统业绩考核办法的补充和辅助。"
1524,基于磁共振成像技术的大脑老化预测模型的研究,"大脑在老化的过程中会不可避免地出现组织、结构以及功能衰退的现象,因此针对脑老化机制的研究,对脑老化有关疾病的早期预防、诊断和治疗有着重要的意义。基于大脑成像数据的年龄预测方法可以预测个体的年龄。通过比较预测年龄和真实年龄,可以捕捉出大脑结构和功能在脑老化过程中的偏差,根据偏差找到与脑老化有关的生物标记物,而这些生物标记物对临床疾病诊断有着重要的意义。因此,本文研究借助磁共振成像技术得到大脑图像,并探索实际年龄与根据大脑图像预测的年龄之间的差距。先前的年龄预测研究一般只依赖大脑的结构或者功能磁共振数据,在这里我们研究多模态数据融合,旨在提高模型的预测能力。主要研究内容包括以下几个方面:1.基于648例年龄19-88岁之间的健康被试,进行年龄预测研究。首先是提取特征,包括基于T1加权图像提取脑容积和皮层特征,基于弥散张量图像构建结构连接矩阵并提取矩阵的连接权值,基于静息态功能磁共振图像构建功能连接矩阵并提取矩阵的连接权值;其次是特征降维;最后将上述过程中得到的特征,构建不同模态的年龄预测模型。在预测模型的选择上,我们对比多个机器学习算法,最终得出基于贝叶斯岭回归以及脑容积特征空间的年龄预测模型,可以得到最优的预测结果。根据贝叶斯岭回归预测模型的结果,我们可以提出具有显著特征权重所对应的特征,作为我们所提出与年龄有关的生物标记物。本研究中发现在平均皮层厚度的特征空间中,与年龄显著有关的特征,基本集中在额叶、颞叶、脑岛等沟回。在平均皮层表面积的特征空间中,发现与年龄显著有关的特征,基本集中在颞叶,前后中央沟等多个区域。在功能连接网络的特征空间中,与年龄显著有关的特征,基本集中在颞-额叶和顶-额叶区域的连接。在结构连接网络的特征空间中,与年龄显著有关的特征,发现额叶内部有较多的连接,绝大部分颞叶区域集中在额-颞叶之间的连接,其它皮层脑区与皮下脑区之间也存在一些连接。这些区域的结构连接主要与记忆力和其它认知功能发生衰退有关。2.各个模态的数据不仅具有相似的共享信息,也具有自身模态特点的独特信息,因此将多个模态数据融合的年龄预测模型可能会得到更好的预测效果。将T1加权图像提取的脑容积以及皮层数据、弥散张量图像得到的结构连接矩阵和静息态磁共振成像数据得到的功能连接矩阵作为特征值,借助集成学习算法的Stacking作为整体架构的年龄预测模型,初级学习器使用贝叶斯岭回归,次级学习器使用线性回归作为预测算法并使用随机森林回归和Adaboost等算法作为对比。融合多个模态的数据发现,将功能与结构的数据融合能得到最低误差,平均绝对误差为5.53岁,皮尔逊相关值r为0.93,但是,单模态年龄预测最低的平均绝对误差为6.60岁。因此,多模态融合年龄预测要明显优于单个模态的年龄预测的最优结果。综上所述,本文通过将结构与功能磁共振数据融合,构建年龄预测模型,并且提取脑影像的显著特征作为与年龄有关的生物标记物,这些生物标记物可以为临床上的诊断提供一些参考。"
1525,基于标志层层位差识别地裂缝的方法分析,"西安地裂缝是世界上最著名的地质灾害之一,分布广泛、活动剧烈、致灾严重。在依据钻探数据查明地裂缝时,黄土梁-洼过渡区的标志层整体有一定的倾斜背景,影响标志层错断的判别。为了排除地层倾斜造成的影响与干扰,判别地裂缝标志层错断时更客观、合理,提高判别的准确度,减少误差,本文总结分析了地铁1~5号线地裂缝勘察资料中的含古土壤层的勘察场地剖面情况,整理出标志层层底高差?h以及对应的孔间距l的统计结果,分析了标志层层底高程与孔间层面倾斜的定量化特征,总结地裂缝标志层错断的判别方法。将两种方法应用到工程实例中,有较好的实用性与准确性。并且,基于大量的地裂缝勘察数据资料结合机器学习算法,建立机器学习分类器模型进行标志层错断的预测判别,为地裂缝的判别提供了大量的数据信息基础与数学基础。论文主要研究成果如下:(1)提出了标志层层底高程差函数,其在标志层错断处的特征为:地裂缝每一侧节点数不小于3时,标志层错断位于左、右高程差函数值变化量的最大值之间。(2)不同地貌单元古土壤层的倾斜背景值:平缓地层倾斜背景值为0.099,黄土梁―洼过渡区地层倾斜背景值为0.301。计算、分析了标志层孔间倾斜之差,得到了单个剖面中古土壤错断的孔间层面倾斜之差界限经验曲线。(3)将基于标志层层底高程差函数特征与孔间层面倾斜之差界限经验曲线判别标志层错断的两种方法应用于西安某场地勘察成果分析中,判别结果与实际情况一致。(4)选取孔间距、高程差函数值、孔间层面倾斜值、孔间层面倾斜值之差这4个因素作为标志层错断判别的指标,针对不同地貌类型古土壤层特征,运用逻辑回归方法与Kernel-SVM方法建立了四种机器学习分类器模型。(5)两个逻辑回归算法的准确率与AUC值均分别高于对应的Kernel-SVM分类器模型,总体上来说逻辑回归分类器模型的准确率高于Kernel-SVM分类器模型。(6)纵向对比两个逻辑回归算法分类器模型和两个Kernel-SVM分类器模型,结果表明平缓地层的两种分类器模型的准确率与AUC值均高于黄土梁洼过渡区倾斜地层分类器模型,平缓地层的标志层错断更容易判别。(7)将经过训练的两类机器学习分类器模型应用到工程实例中,结果表明逻辑回归分类器的预测结果更准确,性能更好。"
1526,基于历史日志的作业运行时间预测,"在高性能计算作业调度中,许多调度算法依赖于对作业运行时间的准确估计,尤其是以EASY为代表的回填算法,使用用户提供的作业运行时间往往会降低调度性能。为了提高超算平台资源的利用率,减少机器资源的空闲,需要开发一种准确的预测作业运行时间的算法。当前已有的运行时间预测算法分为代码分析和历史日志两大类。对代码进行性能建模需要获得用户提交程序的源代码和大量的编译知识,其可行性不如通过日志分析进行预测。通过日志分析进行作业运行时间预测有许多模型,本文把已有的基本方法分为卷积神经网络模型,统计学模型,基于聚类的预测算法和基于回归的预测算法。当前已有的预测算法存在预测精度不足,低估率高或只适应特定类型作业的问题。在已有模型的基础上,我们形成了一套完备的作业运行时间预测评价准则,并建立了自己的预测算法GA-Sim。GA-Sim把分类和基于实例的学习结合起来,并采用遗传算法训练模板参数。通过模板筛选有用的历史数据,使用SVR的给出运行时间预测。结合低估因子和正则因子,能够防止产生低估和过拟合的预测结果。这套预测算法还可以应用在分布式计算和工作流预测中,适应于提升具有各种作业信息特征的作业集群资源利用率。与已有的算法相比,GA-Sim在HPC2N04数据集上降低了 43%的平均绝对误差。本文主要的创新在于提出了一种新型的基于调度历史日志的超算作业运行时间预测算法,即GA-Sim算法。对预测算法进行了模型验证,给出了 GA-Sim和其他几种算法的预测结果,分析了 GA-Sim的低估率和平均绝对误差。与其他几种预测算法的性能比较实验结果证明我们的算法在几个方面都优于其他算法,能够较好的克服数据集的缺陷。根据这一结果,我们给出了选择预测算法的建议在调度环境上做了基本的验证。两种仿真环境下的调度结果显示,在已有数据集上使用本文算法的预测时间相对于使用用户给出的预测时间可以减少系统中至少40%的平均等待和39%的有界减速。因此,可以得出使用基于GA-Sim预测算法的估计时间比基于的用户估计更能提高调度的效率的结论。本文还把GA-Sim应用在分布式作业预测的算法,证明GA-Sim在并行计算的各个领域都具有潜在的价值。"
1527,基于机器学习的航空公司客户价值自动识别模型研究,"信息时代的来临使得航空公司营销焦点从产品中心转变为客户中心,客户关系的管理和维护成为航空公司的核心问题。本文建立的客户价值类型自动识别模型,能够帮助航空公司快速识别出客户的价值类型,然后针对不同价值类型的客户制定个性化的服务方案以及相应的营销策略,实现航空公司利润最大化目标。首先本文从航空公司的70866条会员客户的详细资料数据的40个特征指标中选取了14个典型特征指标来衡量航空公司的客户价值,以两年时间作为观测窗口的宽度得到了样本数据集,并对数据集进行数据的预处理,构造出了研究所需的属性变量指标,对异常值和缺失值进行了删除,将数据进行了标准化处理;然后本文运用主成分分析把众多指标转化为了5个综合指标,并通过因子载荷矩阵,总结出这5个主成分分别代表的含义是客户乘机消费水平、客户乘机积极性、客户在乘机外的消费积极性、客户办卡需求性以及客户消费类型;接着本文使用INCA指数确定了最佳聚类数目为4类,并使用K-means聚类对航空公司客户进行分群,通过每类客户群在5个主成分上的聚类中心总结出这4类客户群分别代表了优质客户群、潜力客户群、挽留客户群以及低价值客户群;接着本文将航空公司客户信息数据集打上类别标签作为训练集,通过十折交叉验证在七种最为常用的机器学习算法中选择出了最适合进行航空公司客户价值类型预测的BP神经网络算法;接着本文将数据集平均分为两份,将BP神经网络隐藏层的节点依次选取1到20并用第一份数据集进行训练,另一份数据集进行测试,通过观察测试集的误判率,最终选取了误判率最低的13个隐藏层节点数来建立BP神经网络预测模型;接着本文用数据集中90%的数据进行BP神经网络的训练集,并用剩下的10%的数据进行模型的评估,从99.88712%的准确率可以看出本文构建的BP神经网络预测模型效果十分显著;最后为了便于航空公司将上面建立的客户价值类型细分模型和客户价值类型预测模型运用到实际业务中去,本文建立了一个客户价值自动识别模型,当航空公司后续有新增客户详细信息时,以后续新增数据中最新的时间点作为结束时间,并以两年的时间段作为观测窗口的宽度,得到各个指标的观测值,输入到航空公司客户价值自动识别模型中去,模型就会自动返回新增客户的客户类型,以便航空公司就能够针对该客户类型提供个性化的服务和营销手段。"
1528,基于机器学习的网络影评分析,"每当新片上映之时,猫眼、豆瓣等电影交流平台上的用户影视评论将会呈现井喷的状态,这些评论数据对观众的购票方向是有指导意义的。但是同一部电影在猫眼和豆瓣上的口碑,有时候竟然会呈现完全相反的状况,《李茶的姑妈》这一影片就是如此。我们可以利用网络爬虫技术以及自然语言处理中的情感分析技术来估计出观众们的真情实感。其中,网络爬虫技术可以帮助我们抓取、汇集豆瓣、猫眼这两个平台上的影视评论,而中文情感分析这一人工智能领域的热门方向结合机器学习方法后,可以帮我们分析用户评论的情感倾向并预测用户的情感态度。本文主要实现了《李茶的姑妈》一片在豆瓣以及猫眼上的影视评论的情感分析系统。首先研究了情感分析中常用的机器学习方法:朴素贝叶斯、支持向量机,介绍了它们的基本原理、实现方法以及优缺点。并设计了爬虫模块,爬取了豆瓣、猫眼这两个平台上的上万条影视评论,并用程序清洗过滤掉了那些重复、含有信息量较少的评论。本文还专门建立了一个面向《李茶的姑妈》影评数据集的分析词典,大大地提高了分词准确性,减少了歧义词的出现。利用卡方统计量以及TF-IDF方法对影视评论进行了特征提取和特征表示。本文还对比了支持向量机、朴素贝叶斯这两种方法在数据集上的表现情况,最后得到最适合《李茶的姑妈》影视评论的分类器:朴素贝叶斯分类器。为了提高支持向量机分类器的精度,本文还详细地阐述了如何得到最优超参数的过程。此外,本文还利用简单抽样技术得到一个样本来代表总体,用得到的情感分析分类器估计出了《李茶的姑妈》这部影片的好评率,并分析了男女观众对该片的不同情感倾向,得出结论:《李茶的姑妈》这部影片不是一部值得专门买票去电影院观看的优秀影片,且相对于男性观众,女性观众对该片的好感度更高。"
1529,基于多元统计和机器学习的成绩分析及研究,"以学生的考试成绩作为选拔人才的主要方法,在我们的日常生活中早已屡见不鲜。从素质教育的学生时代到成人的职场生活,考试成绩一般都会是衡量我们能力的重要指标。尤其是在素质教育的中学时代,大到重要的升学考试,小至各种各样的随堂测试,这样海量的成绩数据充斥在学生和教师周围,但是对这些数据的使用,学校教师和学生有时为了方便仅限于一些简单的描述性统计分析,这不仅仅造成这种数据资源的浪费,而且对于教师管理学生不能够及时提供有效的、科学的、全面的、有针对性的建议。所以,能够找到一种适用范围广,有学习能力的数据分析的技术来对学生的成绩进行分析,透过数据表面,找出潜藏在繁冗数据中的关键的、有利的信息,变得十分必要。本文首先介绍了多元统计分析中聚类分析和因子分析的理论知识,重点介绍了对变量进行聚类的R型聚类,因子分析中主要介绍了主成分法的参数估计方法及方差最大的正交旋转。接着介绍了机器学习中的k近邻法分类与支持向量机分类两种分类方法的基本原理及思想。随后本文选取某具有代表性的学校的高一学生的几次综合成绩进行实例分析,通过R型聚类分析将原始的九个变量聚成三类,再运用因子综合评价模型进行因子分析,提取出了第一因子理科思维能力因子、第二因子语言思维能力、第三因子文科思维能力三个有效因子,发现此时提取的三个有效因子与聚类分析得到的三类完全符合,说明因子分析的结果比较有意义,随后再根据理科思维能力、语言思维能力、文科思维能力三个因子的因子得分情况对学生进行科学地归类,如第一因子理科思维能力因子得分最大则归为第一类,第二因子语言思维能力得分最大归为第二类,第三因子文科思维能力得分最大归为第三类。接着运用机器学习中的k近邻法和支持向量机分类对已经归为三类的样本进行拟合,根据十折交叉验证的误判率最小原则选择出支持向量机的ksvm函数分类为相对最优的分类器模型。今后可运用该支持向量机的ksvm函数对学生的成绩进行预测分类,该支持向量机的分类器模型为学生的成绩分析研究提供了一个科学的模型。"
1530,基于移动通讯数据的用户状态转换预测分析研究,"在计算机技术的推动下,移动通信技术与其相关服务业务正在逐步地与互联网技术、物联网技术相结合,从而促进了整个行业所产生数据的规模增长。通过用户通讯数据使用情况的大数据分析可以有效掌握用户的行为习惯,可为用户维系与精准营销提供高质量且可靠的参考依据。其中,如何准确地预测潜在的离网用户,并以此降低客户离网风险和提升客户维系工作效率,成为一类重要的研究课题。在现有相关研究的基础上,本文对移动通讯数据中用户的转态转换预测进行重点分析研究,主要包括以下三个方面:首先,本文以移动通讯数据中的用户状态转换识别作为分析切入点,根据状态转换时间点回溯转换前单位时间内的用户行为数据以形成样本集并进行特征提取,利用特征进行机器学习建模分阶段对不同的状态转换进行识别,并且对特征重要程度进行衡量以挖掘出影响状态转换的重点因素。实验结果表明,机器学习模型对用户的状态转换具有较好的识别效果。其次,为了解决过往研究中用户离网预测所存在的问题,本文提出以日作为时间粒度对用户所产数据进行时序化并将时序数据分析方法应用于其上,使用滑动窗口技术对用户数据进行实时采样分析,通过提前发掘出用户离网前的前序事件实现对用户离网倾向的提前预测。相应的预测实验使用了真实社会移动通讯用户的使用记录,并结合与传统月粒度统计项建模方法的对比,从理论上与实验结果中验证本文方法的时效性和预测能力。最后,本文基于以往工作对相似用户行为挖掘研究进行进一步深化,将用户静态数据与动态数据区分聚类再融合。在静态数据聚类中再将离散与连续特征进行区分,在动态数据中以窗口行为进行聚类,所有聚类工作均以客观衡量指标作为结果选取依据。"
1531,基于数据驱动的航空发动机气路性能参数预测研究,"航空发动机故障的诊断与监测是航空发动机相关研究的一个重要领域。及时地预防与诊断航空发动机故障,既可以降低整体维护费用,保持飞机平稳运行,又可以减少事故发生,有效地避免人力财力损失。航空发动机故障的诊断与监测关键在于对性能参数进行精确地实时预测。航空发动机的部件包括进气道,压气机,燃烧室,尾喷管等,各个部件环环相扣,组成了一个极其复杂的结构系统。一旦部分部件发生故障,将会导致整个系统无法正常工作。而航空发动机发生故障最主要的表现之一为压气机物理转速失调,所以对压气机物理转速的精确预测对于航空发动机故障诊断是至关重要的。传统的基于数学机理的预测模型具有很强的非线性与不确定性。随着科学技术的进步,航空发动机的内部结构越发复杂,建模精度越来越难以得到保证。自21世纪以来,在大数据的浪潮中,业界形成了采集-建模-决策的三位一体的数据驱动策略。在建模过程的研究中发现,机器学习建模算法可以在不知道系统内部结构的前提下,仅利用试验数据进行建模,可以有效地避免机理模型求解困难的问题。本文以中航工业沈阳发动机设计研究所提供的某型号涡扇发动机的台架试车数据为研究对象,采用三种基于试验数据的机器学习模型进行建模,对航空发动机气路部件中的压气机物理转速进行实时预测。模型确定过程中采用改进的自适应惯性更新权重粒子群算法对模型参数进行寻优。结果表明本文改进的粒子群算法克服了传统粒子群算法存在的自适应性差,收敛速度慢等问题。针对样本信息不完整的问题,本文采用基于稀疏自编码器的空间重构算法,使样本维数改变,并能够完整描述航空发动机工况,并使用滚动学习-预报技术建立模型输入向量。结果表明利用稀疏自编码器将低维样本的维数适当提升,能够提高模型预测的精确度。验证过程中,本文采用了三种目前流行的机器学习算法:随机森林、支持向量机和核极限学习机,并对三种算法进行了分析与推导。最终利用分组验证的方式对三种算法的回归精确度进行评估,结果表明:与支持向量机算法相比,随机森林算法增强了模型的泛化性,避免了过拟合;与核极限学习机算法相比,随机森林算法增加了样本数量,减少了样本维数,增强了模型对高维数据的学习能力,避免了欠拟合。"
1532,Human Action Recognition Based on Semi-Supervised Learning,"考虑到视频中人的动作速度不同,以及目前视频人的动作识别领域中主流方法不使用未知标签数据信息的现状,本文提出了一种基于半监督学习的多尺度人体行为识别算法框架。首先,本文在视频中提取了长度为L和2L的改进的密集轨道特征,并用hog、hof和mbh描述符描述这些轨迹。然后对不同尺度下的视频轨迹进行编码,得到相应的视频表示。在半监督学习下,不同尺度下的视频表示对应于不同的视图。最后,本文利用协同EM算法有效地利用未知标签的视频数据信息,提高模型的适应性和识别效率。本文在KTH和HMDB51两个标准动作数据集进行了大量的实验,验证了算法的有效性。实验结果表明,在HMDB51上,本文方法取得了可以和最新方法相比的方法。而在KTH数据集上本文的方法有一定的优势,取得了较好的识别效果。"
1533,Recommendation Algorithm Based on Blending Learning,"在当今世界,推荐系统对任何企业和用户都极为重要,它对企业收益的增加起着至关重要的作用。研究表明,通过简单地使用推荐系统算法,能让企业的收入增加30%。推荐系统是信息过滤系统,根据每一个用户对产品或项目的偏好进行用户定制。各大公司通过使用推荐系统来学习用户行为以了解市场需求,得到这些市场需求分析后,在大量用户中定位真实的产品受众再开展营销活动。因此,推荐系统既可以帮助各大企业做出明智的决策并节省时间成本和营销成本,也有助于企业进行广告投放等投资以增加收入。电子商务网站如淘宝,阿里巴巴和京东等企业通过简单地使用推荐系统增加交叉销售,其收入增加了35%。尽管推荐系统具有许多优点,但由于数据的性质,数据稀疏性以及其他因素(如可用的特征池)的影响,如何提高推荐系统的预测的准确性仍然是一个挑战。矩阵分解是最受欢迎的以及受到广泛研究的技术。矩阵分解使用的是不满足不等式属性的点积。许多研究提出了不同的技术来解决这个问题如度量分解。尽管度量分解改善了矩阵分解的结果,解决了点积的不等性问题,但是新的研究工作总是受到欢迎。因此,我们提出了一种称为混合的多模型集成学习技术。该技术包括两个步骤,首先,我们训练几个基本模型并获得电影的预测评分,然后使用线性回归将这些结果组合为第二层模型以获得电影的最终评分。使用均方根误差(RMSE)和平均误差(MAE)作为评判标准用于评估不同模型。我们的实验结果表明,新的混合方法优于其他使用的技术。我们使用SlopeOne,SVD,SVD++和Metric Factorization(MetF)等模型进行比较。我们在两个公开可用的数据集Film Trust和Movie Lens上进行实验并预测评分。通过在第一个实验中将三个不同的模型(即SlopeOne,MetricF和SVD)和第二个实验中的SlopeOne,MetricF和SVD++组合在一起来总结我们的结果,同时还在MovieLens数据集上重复这些相同的实验。结果表明我们的模型在两个数据集上的MAE和RMSE方面都表现出色。此外,研究工作包含了对推荐系统领域中使用的新旧技术的详细理解,以及在机器学习和人机交互的视角中,用于推荐系统领域的算法和用于结果评估的不同评估度量。"
1534,基于时序不均衡数据的在线交易欺诈检测研究,"由于近几年计算机处理能力的提升和数据科学的进步,推动了互联网的快速发展,以第三方支付服务为代表的在线交易模式已成为人们主流的消费方式之一,每时每刻来自互联网各个角落的人们通过这种基于网络的在线交易平台进行着成千上万的交易。而随着在线交易支付订单规模扩大和总交易金额的大幅度提升,各种类型的在线交易欺诈行为也越来越普遍。在线交易风险管理一直以来是业界十分关注的问题,而作为风险管理的重要组成部分,研究在线交易风险识别具有十分重要的现实意义。在线交易欺诈行为有发生频次低、造成危害大等特征,一般的反欺诈手段难以进行有效的识别并加以防范,随着机器学习与数据挖掘相关技术趋于成熟,将其应用于在线交易风险识别已成为近几年相关领域的研究趋势。在有关在线交易风险识别的研究中,其主要的难点有两个方面:首先是欺诈行为只占所有交易行为的很小一部分,数据类别分布存在高度的不均衡性,其不均衡比例甚至可达万分之一,而且部分欺诈类样本与正常样本的特征信息存在高度的相似性,使得普通的分类方法难以有效识别这类欺诈行为,因此需要利用不均衡数据分类的方法来对其进行有效的识别检测。其次,欺诈行为是具有时效性的,由于欺诈平台或者是欺诈团伙为了应对反欺诈措施会不断更改其作案方式,因此造成分类器无法适应新的特征规则,进而导致其无法对欺诈行为进行有效识别,即概念漂移现象。针对在线交易欺诈检测中的类别不均衡分布以及数据流概念漂移两个主要问题,本文在结合前人研究成果的基础上,提出了基于XGBoost和SMOTE技术的改进算法M-XGB-SMOTE,其核心思想是结合XGBoost算法较强的二分类能力和SMOTE泛化能力强的优点,以AUROC评估分数为指标从多轮重采样训练分类器中筛选分类器,并基于上述分类器构建集成分类结果的预测模型,以期提升模型预测的综合性能。在以上算法构建的基础上,提出了基于历史样本抽样递减规律的算法MS-XGB-SMOTE,以期利用历史样本随时间推移重要性递减的规律减少模型受到数据流概念漂移带来的负面影响。在基于交易风险识别数据集的实验环节中,与传统的分类算法比较中可以看出,M-XGB-SMOTE的AUC综合指标显著高于其他算法的结果;在与传统不均衡数据流分类算法的比较中可以看出,MS-XGBSMOTE算法的综合预测能力有明显提升。"
1535,基于机器学习的交通事故预测系统设计与实现,"随着社会的发展,交通设施愈加发达,人们的出行需求也不断提高,但是随之而来的交通安全问题也越来越多。传统的车辆事故预防措施包括被动安全系统与主动安全系统。近年来随着科技的进步,辅助驾驶等新一代的安全系统也慢慢登上了舞台,但是研究表明更加合理的安全系统必然是基于车联网技术与事故预测技术相结合的预防式安全系统,因为车联网技术解决了驾驶员视野受限的问题,使车辆与车辆可在非视距条件下进行通信。车联网技术结合事故预测能实时判断车辆是否处于危险状态,更好地保障乘客安全,减少潜在损失。一方面传统的事故预测往往将经典预测算法运用到一组少量数据上,得到的模型只能预测较小范围的交通事故;另一方面大部分事故预测模型受限于数据特征较少及未考虑到实际应用场景的问题,没有结合地区异质性,事故预测模型的预测精度较差。基于以上问题,本文做了以下研究:1.论文对已有的交通事故数据集进行了初步的数据处理,分别从人、车、道路、环境和其他因素五个方面分析并归纳了交通事故与影响因素之间的关系,证明了地区异质对事故的影响,为交通事故预测做铺垫工作。2.针对传统交通事故预测忽略地区异质性的问题,对原始数据和异质空间数据分别进行预处理和特征选择,分别运用逻辑斯谛回归和随机森林算法,训练得到相应的预测模型。结果表明,结合地区异质性后得到的预测模型相较于原始数据得到的预测模型具有更好的综合性能。3.利用SUMO、VEINS和OMNET++工具搭建车联网仿真平台,并在该环境下设计实现基于机器学习的交通事故预测系统。本系统能实时展示车辆运行界面与车辆通信界面,当分类器判定为危险状态时会对进行示警,避免潜在的交通事故。"
1536,面向六足机器人的地形识别与运动规划研究,"六足机器人是并联机器人的一种,具有多自由度,多肢体以及离散落足点,其运动方式灵活多变,稳定性强,具有良好的环境适应能力,应用前景广阔。本文对六足机器人的地形识别和运动规划方法进行研究,设计一种新型的六足机器人,主要研究了六足机器人机械结构和软硬件控制系统、正逆运动学,步态规划等内容,并提出了一种高效的地形图片特征提取和地形识别方法。六足机器人可通过采集到的地形环境图片,识别出其所处地形,并据此采取相应的运动控制策略,以完成指定的运动控制任务。本文首先介绍了课题的研究背景和研究意义,对国内外相关领域的研究现状进行了介绍和分析。同时基于仿生学原理,设计了六足机器人的机械结构,在机械本体上搭建了远程主机控制系统、机器人本体控制系统,机器人底层传感驱动系统三层控制结构的机器人硬件系统,并基于ROS机器人操作系统,采用分层模块化思想完成软件系统设计。接着,对六足机器人运动规划方法进行分析与设计。基于D-H表示法建立起六足机器人的正运动学模型,并采用几何法求解机器人的逆运动学模型。基于多足机器人步态设计的基本理论,设计了六足机器人的行走步态,包括用于直线行走的三角步态、四足步态、波浪步态以及旋转步态。然后,研究了六足机器人运动环境地形的图片特征提取和地形识别方法。通过采集和数据增广技术,建立起本课题研究所需的地形图片数据集Terrain6。基于迁移学习技术,采用MobileNet卷积神经网络,设计了一种地形图片特征提取方法,实现六足机器人地形图片的特征提取。通过提取的图片特征集,分别训练了支持向量机、朴素贝叶斯、随机森林这三个可实现机器人地形识别的分类模型。基于stacking融合方法,对训练好的三个单独进行融合,得到最终高精度的地形识别模型。六足机器人根据地形识别的结果,采取对应的控制策略进行运动。最后,对课题研究内容进行仿真分析和样机实验。基于ROS机器人操作系统,对本文设计的六足机器人系统进行仿真分析与验证,并在六足机器人的实体样机上进行实验。"
1537,量子力学辅助的机器学习算法对AIE效应的预测和理解,"传统有机发光材料在高浓度或聚集态下通常会发生荧光淬灭,因此在很多场合其应用受到限制。幸运的是,聚集诱导发光(AIE)效应为这个问题提供了一个革命性的解决方案。AIE材料因具有在溶液分散态发光效率低,聚集态发光效率高的独特发光特性,而在基础生命科学、医学、化学等领域展现出很好的应用前景。然而现在对新型AIE材料的研发主要还是基于繁琐的试错方法。因此建立在实验之前就能预测出荧光材料AIE活性的模型非常有意义。目前常见的AIE分子有很多不同类型,其中的三苯胺(TPA)衍生物因同时具有AIE活性和TICT活性而在生物医学成像及诊疗、化学传感、有机发光二极管等领域的应用被广泛研究。然而还有很多TPA衍生物都不具有AIE活性,而且目前也没有能够准确预测TPA衍生物的AIE活性的有效方法。本文以TPA衍生物为例,通过量子力学与机器学习的结合,建立了一种能够预测AIE活性的数学模型。考虑到量子力学能够计算出分子的理化参数,而机器学习具有从大样本量多维度数据中拟合出变量之间数学关系的能力。于是我们从文献中收集了61种TPA衍生物,并用DFT进行了结构优化,然后通过NBO分析计算了分子内电荷分布。再用支持向量机(SVM)分类算法来拟合电荷分布与AIE活性之间的关系,从而建立出能够预测TPA衍生物AIE活性的机器学习模型。经过优化,该SVM分类器的敏感性、特异性和准确率分别可以达到0.80、0.90和0.84,表明其对TPA衍生物的AIE活性具有很好的预测效果。本研究还类比偶极矩定义了一个能近似描述TPA核上电荷分布不对称性的物理量,并通过ROC曲线找出最优的阈值,从而建立出一个简单的AIE活性判别方程,其对AIE活性的分类效果跟SVM分类器完全一样。这些结果表明TPA核上足够大的偶极矩是激活TPA衍生物AIE活性的关键因素,这与TICT机理的解释一致。最后还通过所建立的机器学习模型预测出一个新型AIE分子,并用实验对其AIE活性进行了验证。这项工作为AIE的研究以及AIE材料的高通量筛选提供了新方法。"
1538,基于多源数据的公交通勤出行特征挖掘与分析,"随着城市化进程日益加剧,机动车数量激增,早晚高峰道路拥堵已成为困扰我国大中小城市交通出行的首要顽疾,严重降低了居民的幸福指数。通勤人群作为城市早晚高峰出行的主力军,深入挖掘和分析公交通勤出行的特征规律和时空特性,感知通勤出行环境特点,对提升公交通勤服务水平,诱导客流转移,缓解高峰拥堵具有重要意义。目前公交通勤出行研究多借助调查问卷数据,无法掌握真实的通勤出行特征与客流规律,而基于刷卡数据的通勤研究,通勤识别方法简单,提取结果不准确,特征分析不深入。为此本文以多源公交数据为数据基础,提出了两种新颖、高效、准确的通勤识别方法,对通勤出行特征和出行环境进行深入分析。具体研究内容如下:(1)多源公交数据处理层面,针对GPS报站数据缺失和IC卡刷卡系统与GPS系统时钟不一致等问题分别给出相应解决方法,然后利用数据融合技术,给出上车站点匹配、下车站点推断、换乘站点识别的具体步骤和方法,还原得到乘客公交出行轨迹的OTD数据,为之后通勤识别和特征分析打下基础。(2)基于机器学习算法通勤识别模型,首先进行特征工程,选择最佳识别特征并给出各属性特征值处理方法,然后据此制定调查问卷获取训练数据,选择与之最佳的机器学习算法,利用改进代的价敏感性GBDT(梯度提升决策树)算法训练分类模型,最后从真实刷卡数据中提取相应特征,代入模型完成通勤识别。(3)基于闭合出行链的通勤出行提取,首先给出闭合公交出行链的定义,构建基于OTD的出行拓扑图,然后进行深度优先的闭合环路搜索和相似性关联,从不完全、片段化出行轨迹信息中完成闭合出行链的提取,并从通勤出行时间和空间规律出发,制定筛选规则完成通勤提取。最后对两种通勤提取结果和方法优缺点进行综合对比分析。(4)通勤出行特征研究层面,首先基于提取的公交通勤结果,从出行链角度分析其特征规律,并对其出行时间和空间特性进行分析,然后针对出行主要考虑因素―通勤时间,建立通勤时间影响模型,对选取各因素影响程度进行分析,给出具体改善意见。论文以珠海市源公交数据为基础,利用Python、Mysql数据库、ArcGIS、Spss等工具,从真实刷卡数据中完成了公交通勤的精确提取和特征的多层次分析,为公交通勤出行的研究提供了新思路。"
1539,基于注意力机制的短时交通流速度预测模型研究,"智能交通系统(ITS)对解决现今的一系列交通问题有着重要作用,而短时交通流预测则是智能交通系统的核心内容,同时也是是交通信息服务、交通控制和交通诱导等系统的重要基础。深度学习算法能够使用多层神经网络或深层架构来捕捉数据的固有特征,而引入注意力机制对深度学习算法性能的提升效果已经在自然语言处理、图像识别等领域得到了验证。由于交通流的复杂随机性特征,准确的交通流特征识别并不是一项简单的任务,科学合理地运用深度学习算法对城市路网交通流进行更加精确的预测对于整个交通系统具有十分重要的意义。本文致力于使用深度学习算法对路网短时交通流速度预测进行研究,针对现有研究成果的不足提出了从预测精度和预测模型效率两个角度出发的具体方法,本文的研究内容包括:(1)为了提升用于预测的数据质量,分析了交通流数据的统计特性,进行了系统的数据预处理,给出了交通流数据缺失划分的定义,并根据定义的偶然性缺失和多发性缺失分别采用朴素贝叶斯和动态时间规整算法进行数据估计和填充。(2)阐述了选择循环神经网络(RNN)作为基础网络进行交通流预测的原因,针对其在实际应用中的梯度消失问题提出了长短期记忆网络(LSTM)对模型进行改进,并具体描述了模型框架、算法和训练过程。(3)为了进一步提升模型性能,将注意力机制引入LSTM-RNN预测模型,选择了适应于本文研究场景的基于注意力向量计算方式的变体,搭建了基于注意力机制的短时交通流速度预测模型,并具体描述了改进后的模型框架、神经网络结构和训练过程。(4)利用城市路网实际数据对搭建的模型进行验证。结果表明,在与不做缺失划分的稀疏数据填充模型的对比下,本文提出的混合模型具有更高的修复率和更低的估计偏差;在与RNN、CNN等深度学习算法的对比下,本文提出的预测模型能够提升预测精度和模型效率。"
1540,黄昏低照度条件下驾驶员心理负荷分析及建模,"根据交通事故数据统计,黄昏时段是一天中交通事故量频发的高峰时段。其原因主要在于照度的快速下降影响驾驶员对于周边交通环境的感知力,使得驾驶员心理负荷水平相应提高,且城市道路晚高峰时段复杂的路况也对驾驶员注意力和操控力提出更高要求,驾驶员容易出现反应迟钝、操作失误等危险驾驶行为。为此,开展黄昏低照度条件下驾驶员心理负荷研究,对保障城市道路行车安全、降低交通事故率具有重要理论和实践意义。本文综合应用交通工程学、人因工程理论、统计学和人工智能科学等多门学科知识,考虑“人-车-路-环境”各要素的相互作用关系,通过实车实验采集城市道路黄昏低照度条件下的驾驶员及车辆的多源数据,在分析驾驶员生理及行为特性的变化规律及相关作用的基础上,建立心理负荷表征指标集,构建黄昏低照度条件下的驾驶员心理负荷模型。首先,从驾驶员心理负荷的概念出发,分析黄昏低照度条件下驾驶员的生理及行为特性,从多个角度初步选取表征心理负荷的指标,设计城市道路黄昏低照度条件下的实车实验方案,在合理划分环境照度等级的基础上,采集驾驶员的生理及行为特性典型指标,并通过NASA-TLX任务量表获取主观心理负荷。其次,运用统计学方法分析环境照度和驾驶熟练度对于驾驶员生理及行为特性的影响规律及其变化特性,并尝试对环境照度与关键指标的关系进行趋势拟合及回归建模。结果表明:黄昏低照度条件下,随着环境照度的下降,驾驶员心理负荷水平提高,驾驶稳定性下降,且新手驾驶员与熟练驾驶员的表现具有显著差异。最后,基于相关性分析和主成分分析法建立心理负荷表征指标集,运用kNN、SVM、GBDT三种机器学习算法构建黄昏低照度条件下的驾驶员心理负荷模型,借助实测数据综合评判模型的识别效果和泛化能力,并通过逐个剔除指标评判指标集的有效性。结果表明:本文建立的心理负荷表征指标集具有一定代表性,基于GBDT算法构建的黄昏低照度条件下驾驶员心理负荷模型的识别效果最好,识别精度达92.25%。本文研究成果将指导驾驶员安全、科学、合理进行驾驶活动,并为城市道路交通主动安全管理及“智慧交通”背景下的车辆预警终端系统的设计提供依据。"
1541,手势识别及其在人机交互系统中的应用,"手势识别作为最自然的交互方式之一,在人机交互上有着很高的应用价值。基于单目RGB摄像头实现手势识别具有设备简单、成本低廉的优势,因而,增强单目RGB摄像头手势识别方法的鲁棒性和快速性,将其用于人机交互中,有着很好的前景。本文旨在研究在单目RGB摄像头下的手势检测方法、手势跟踪方法、动态手势识别方法和指尖点识别方法,并针对手势的特点,对相关方法做出改进,将其应用于人机交互系统中。本文工作主要分为以下四个方面:1)手势检测:首先分析常用的肤色建模方法、机器学习检测方法以及深度学习检测方法在手势检测中的特点和不足,然后结合手势在人机交互中的特点,提出了一种融合混合高斯肤色建模、贝叶斯校正和极限学习机的改进多尺度手势检测方法,最后在自建手势数据集GEST_SCUT上进行对比实验分析,验证改进检测方法的效果。2)手势跟踪:首先分析常用运动目标检测方法在运动手势检测的特点和局限,以及常用机器学习跟踪方法在手势跟踪中的特点和局限,然后通过设计置信度模型以及引入尺度滤波器,改进核相关滤波器方法,最后在自建手势数据集GEST_SCUT上进行对比实验,验证改进方法的效果。3)动态手势识别和指尖点识别:首先利用姿态卷积机生成手势的关节点,然后针对动态手势的特点,提取5个指尖点的余弦方向特征,并提出一种KNN-DW-DTW匹配方法对动态手势进行识别,接着在自建数据集GEST_SCUT上验证方法的有效性,最后分析基于凸包检测的指尖点识别方法,分析了该方法的特点与不足,提出了一种融合凸包检测、质心距离和曲率检测的改进方法。4)空中手写人机交互:首先对软件系统的功能需求以及程序框架进行介绍,然后根据软件每一个功能模块的需求分析,给出对应的设计方案,最后给出系统软件数据采集、数据标注和空中手写的运行结果。"
1542,基于深度学习的时间序列预测与分类方法,"时间序列是一种广泛存在于现实各领域之中的海量高维数据,在与时间序列有关的研究活动中,时间序列预测和时间序列分类是两个研究重点。传统时间序列预测方法仅仅从时间的维度对时间序列进行分析,忽略了外界影响因素对时间序列产生的影响。而传统时间序列分类方法过分依赖于序列间的相似性度量,忽略了时间序列本身的内在规律。本文利用深度学习方法解决传统时间序列预测和分类方法中存在的问题,主要研究内容如下:(1)概述时间序列预测与分类的研究现状,并重点分析了基于深度学习的时间序列预测与分类的研究现状。调研了深度学习相关的理论和方法,主要包括反向传播神经网络、卷积神经网络、循环神经网络、长短时记忆网络以及注意力机制。(2)针对时间序列预测模型DA-RNN(Dual-stage Attention based Recurrent Neural Network)无法对输入特征与被预测特征之间的相关性以及输入特征之间的相关性建模的问题,本文提出了一种DA-RNN的改进模型DAFDC-RNN(Dual-stage Attention and Full Dimension Convolution based Recurrent Neural Network)。DAFDC-RNN修正了DA-RNN的问题定义中与实际应用场景不符的部分,同时引入目标注意力机制学习输入特征与被预测特征之间的相关性,引入全维度卷积机制学习输入特征之间的相关性,引入时间注意力机制学习时间序列的长期时间依赖性。实验部分首先确定了模型的超参数,然后对模型的结构以及部件进行验证,最后通过对比实验证明本文提出的DAFDC-RNN模型在大特征量数据集上的预测效果要优于DA-RNN模型。(3)DenseNet是一种基于密集连接的神经网络模型,本文提出了一种基于DenseNet的时间序列分类模型。为了验证模型的分类性能,本文在UCR仓库共85个数据集上进行对比实验,同时使用数据可视化技术CAM对分类模型的决策过程进行解释。对比实验结果表明DenseNet的分类性能要好于前沿的时间序列分类模型,包括残差网络(ResNet)、全卷积神经网络(FCN)、多尺度卷积神经网络(MCNN)和多层感知器(MLP)。"
1543,面向高吞吐率计算的编程模型和运行框架系统,"处理大规模问题的常用技术手段包括高性能计算、高吞吐率计算和大数据处理技术等。由于高吞吐率计算存在计算时间长、使用计算资源多、多任务、容错性要求较高的特点,Hadoop等大数据计算框架和在高性能计算领域应用广泛的MPI都不完全适用于开发高吞吐率计算应用。为了降低高吞吐率计算应用的开发难度、提高开发效率,本文对已有的DCR编程模型和运行框架进行了改进,使其能够满足高吞吐率计算多任务、容错等方面的需求。借助本文的编程模型和运行框架,用户开发高吞吐率计算应用时,只需要实现编程模型中的分解、计算和规约过程,任务的执行、任务之间的计算资源分配、节点管理、负载均衡、容错等功能均由运行框架实现。本文首先介绍了改进后的编程模型,包括任务、任务模板和任务组的概念;任务组中任务依赖关系的描述;用于任务间通信的消息模型;任务间的计算资源分配原则。然后,本文介绍了运行框架的总体结构,包括调度节点和计算节点的总体结构、队列结构、线程结构以及两者之间的通信。随后,本文详细介绍了运行框架多任务机制的设计与实现,包括:任务模板的管理、任务的创建、任务的状态、任务的管理功能和任务管理器的实现、任务执行器的实现、消息机制的设计与实现。同时,本文还对任务执行过程、任务计算资源分配、负载均衡和容错等方面的实现进行了介绍。最后,本文在“神威太湖之光”、“天河二号A”以及GPU集群上对运行框架进行了多任务、消息通信和大规模集群支撑能力等多方面的测试,验证了运行框架能够满足高吞吐率计算的需要。"
1544,基于多任务学习的情感分析技术研究,"现有的情感分析方法主要分为基于情感词典的情感分析方法和基于机器学习的情感分析方法,而在基于机器学习的方法中,基于深度学习的方法最为流行。基于情感词典的方法十分依赖情感词典的质量及覆盖度,而基于深度学习的方法需要大量的标注数据集。在数据集较小时,基于深度学习的模型容易产生过拟合,多任务学习技术同时对多个任务进行训练,通过利用相关任务中的领域特有信息来提升模型的泛化能力,在一定程度上缓解了过拟合问题。本文对主流的多任务学习技术进行研究后发现以下几个问题:(1)现有多任务学习模型多使用基于LSTM的模型进行情感分析,并使用单层LSTM的最后一个隐藏状态作为文本的隐含特征,这一方法特征提取能力有限且存在有偏表示问题;(2)在文本包含多个情感词且语法结构复杂的情况下,现有方法无法准确识别出整个句子的情感倾向;(3)LSTM由于其循环特性,当前时间步的输入依赖于上个时间步的输出,其并行效率较低,很难完全发挥出GPU的性能;(4)现有多任务学习模型将特征空间分为私有和共享两部分,每个任务都拥有一个独立的私有空间,其内存消耗与任务数量呈线性关系,在任务数较多时十分耗费内存。针对以上问题,本文进行了以下几个方面的工作:(1)本文使用多种方法对ASP-MTL模型进行优化,并提出基于注意力机制的多任务情感分析模型AASP-MTL。这一模型拥有较强的特征表示能力,不仅可以解决LSTM中存在的有偏表示问题,还提供一种可视化分析方法,可以对模型进行更为直观的分析;(2)针对现存的第2个问题,本文将基于情感词典的方法结合到多任务情感分析模型中,利用基于情感词典的方法的优势来解决这此问题;(3)针对于LSTM并行效率差,且现有多任务模型耗费内存的问题,本文提出基于DT的多任务学习模型DT-MTL,此模型有着极高的并行效率和内存使用效率。本文在16个不同领域的情感分析数据集上进行实验,结果表明:在情感分析性能上,AASP-MTL的平均错误率要要低于ASP-MTL模型,DT-MTL模型的平均错误率低于ASP-MTL模型但略高于AASP-MTL模型;在模型并行性能上,DT-MTL模型要远高于AASP-MTL模型。在数据量较小时,使用AASP-MTL模型可以得到较高的情感分析性能,而在数据量较大时,使用并行效率更好的DT-MTL模型可以缩短训练时间。"
1545,ThunderSVM：一个高效并行支持向量机算法库,"支持向量机(SVM)是一种传统的监督学习算法,可以用于分类、回归和分布预测,被广泛应用于各种数据分析的实际问题。其中,LIBSVM是应用最为广泛的SVM算法包,它被许多机器学习框架作为底层的SVM算法实现。然而,在大而复杂的问题上,SVM的训练和预测的计算代价很高。LIBSVM针对早期的单核CPU进行了优化,只提供了有限的并行化支持,但随着数据量和问题规模急剧增加,LIBSVM的训练和预测速度往往不能够满足现实算法调试和应用的需求。于是,许多研究者开始研究如何使用高性能计算硬件(例如图形处理器GPU)来加速SVM。然而,并行化SVM还有如下挑战:(1)SVM的训练需要重复地随机访问整个数据集,这导致高代价的随机内存读写和重复的计算;(2)现有的SVM训练算法是针对单核计算机提出的,没有考虑如何充分利用多核甚至众核处理器,充分并行化SVM需要重新设计SVM的训练算法;(3)多分类SVM需要训练多个二分类SVM,同时训练这些二分类SVM需要的内存空间往往超过了现有的硬件资源。为了解决并行化SVM的挑战,本文设计并实现了一个高效的开源SVM软件工具包ThunderSVM,它充分利用了高性能的GPU和多核CPU资源,采用了工作集缓冲的SVM训练算法,减少了内存随机读写和重复计算,利用多分类SVM中的核函数共享和支持向量共享策略压缩了训练和预测过程中的内存。实验表明,ThunderSVM的速度一般比LIBSVM快两个数量级,比GPU基线版本快5倍,并且训练出的模型准确率与LIBSVM相同。ThunderSVM支持LIBSVM的所有功能,包括分类(SVC),回归(SVR)和单类别SVM,并且跟LIBSVM有着相同的命令行接口。ThunderSVM还支持多种语言的接口,包括Python、MATLAB和R。目前,ThunderSVM已在最大的开源代码托管网站上发布(地址 https://github.com/Xtra-Computing/ThunderSVM)。截至 2019 年 4 月,ThunderSVM已经吸引了 900多个星标和130多个克隆,得到了研究者的广泛欢迎。"
1546,基于特征选择的领域自适应方法研究,"领域自适应作为迁移学习的主要研究分支,能够帮助分类模型从源领域的数据中提取知识,并在有不同分布的目标领域中完成目标任务的预测。而当前随着互联网技术的发展,丰富的数据来源带来了海量的数据,这为传统机器学习模型带来了帮助,也造成了阻碍。这种阻碍主要是数据的多样化造成了数据领域之间分布不同,从而影响了机器学习模型的效果,而领域自适应方法的研究,正是为了普遍性地解决或减小这种阻碍。在以往的领域自适应方法中,研究者们往往通过特征降维或子空间学习的方式,学习一个或更多个特征映射函数来达到领域分布差异变小、特征有分类辨别性的目的。为了能够发挥以往研究中特征选择方法的优点,我们将特征选择作为手段并用到领域自适应的研究中,本文的主要工作包括以下几点:1)本文对领域自适应相关的理论背景和方法研究做了较为详细的梳理,阐明了领域自适应问题的本质,在此基础上回顾了关键的度量方法。同时对作为手段的特征选择研究进行了相关工作的梳理。2)针对过去相关方法不能兼顾特征分类辨别能力的问题,提出了TFS方法。该方法通过最小化一个包含领域分布差异度量、训练误差损失函数和l_0范数约束的目标函数,得到兼具可迁移性和分类辨别性的特征子集。3)在仅考虑边缘分布自适应的基础上考虑了条件分布的自适应,并为了提升模型目标的鲁棒性在两个分布度量之间添加了可学习的平衡因子,从而提出了了自适应平衡性分布的BTFS方法。4)提出了一个分布式优化算法框架,能够对所提出的模型进行有效的求解,即解一个带有l_0约束的混合整数规划问题。5)在多种真实的数据集上通过和基准方法对比、特征子集的可视化、迭代次数等方面展示了所提出方法的效果,并从负迁移性、目标有效性等角度分析论证了以特征选择为手段的领域自适应方法的鲁棒性和有效性。"
1547,城市轨道交通路网客流动态估计模型与系统,"网络化运营背景下,城市轨道交通呈现出路网规模庞大、客流量激增、突发事件影响传播快、客流特性及演化规律更复杂等特征,使得实时运营过程中的运营决策面临更大挑战。因此,亟需运用高效便捷的技术手段与方法,及时而准确地估计或者预测不同层面上的路网客流状态及其动态变化,作为定量决策的依据。面向这一目标,本文主要研究内容如下:(1)分析了实时运营过程中对客流状态分析的要求,明确了需要从如下三个层次进行研究:在客流OD层研究路网客流OD量的估计和预测,在路网客流分布层研究客流分布推演仿真模型并开发系统,在路网运营效果层研究突发事件影响的定量分析。(2)分析了实时运营过程中客流OD信息在不同情况下可知状态,提出了多层次递进的客流OD动态估计方法框架,构建了基于历史相似集的客流OD预测模型和基于LSTM的分时客流OD时序预测模型,并将二者有机结合。既挖掘了历史数据中蕴含的规律,又充分利用当日运营中的实际数据,提高预测准确性,能更好地符合实际情况。(3)在既有研究的基础上,构建了实时与超实时混合、仿真区域可变、适应正常与突发情况的客流分布推演仿真模型,设计开发了仿真系统。并为了面向突发情况的影响分析需要,研究了定量指标的设计与计算。(4)最后,以北京地铁为案例,利用前面构建的客流OD估计模型与仿真系统进行仿真实验。从不同层面对客流状态进行了分析,并对突发事件的影响进行了研究。"
1548,基于深度学习的脑电及功能磁共振信号的识别研究,"在生物医学领域,深度学习逐渐发展成为一个有效的分析工具。脑电(Electroencephalogram,EEG)以及磁共振(Magnetic Resonance Imaging,MRI)是生物医学领域中最常用的脑成像技术。本文利用深度学习方法,探讨基于脑电的运动想象(Motor Imagery,MI)分类和基于功能核磁共振(Functional Magnetic Resonance Imaging,fMRI)的注意力缺陷/多动障碍(Attention Deficit Hyperactivity Disorder,ADHD)分类问题,提出了跨被试和多中心的分类模型,突破了当前研究中的一些限制,为理解脑认知功能提供了新的视角。主要研究内容如下:1、在运动想象脑-机接口(Brain-Computer Interface,BCI)系统中,目前现有的方法使用单个被试的数据进行建模,给被试带来了沉重的训练负担,使得MI BCI系统应用和推广受到了极大的阻碍。因此,将现有被试的知识转移到新的被试可以有效地减轻被试的额外训练负担。本文介绍了一个合适且有效的深度学习框架,以实现基于跨被试迁移学习的MI BCI系统。考虑到多通道CSP(Common Spatial Pattern,CSP)时间序列可以表征运动想象任务中不同脑区的活动状态,我们提出一个基于局部通道的卷积神经网络,对不同的通道采取不同的编码方式,以突出不同脑区在MI任务中的特异性。随后将编码得到的特征连接起来并送入识别网络以执行最终的MI识别任务。我们使用传统机器学习算法作为基线模型并且在实验室数据集和BCI-IV竞赛数据集上进行验证。结果表明,在跨被试迁移学习的条件下,与传统方法相比,我们提出的模型可以提高基于MI分类的准确性,其中,在实验室数据集性能提升2-13%,在BCI-IV竞赛数据集上提升了2-15%。2、在fMRI数据的应用中,现有的工作大多是基于单个中心的数据,很少考虑到多中心数据的分类问题,这限制了fMRI数据的应用范围。本文针对ADHD疾病的分类问题,在先前工作的基础上,提出了针对fMRI数据的端到端的深度学习模型,从而实现多中心的ADHD分类系统。我们设计了适用于可变时间长度的深度特征提取网络以得到各个脑区的抽象特征。同时,发展了基于注意力机制的脑区融合重组模块来学习在任务过程中脑区的活动状态的相互作用。作为比较,探究了不同的脑区融合重组模块对分类性能的影响。模型在ADHD-200竞赛数据集上进行验证,与竞赛中基于单中心的结果进行了比较。结果表明,脑区融合重组模块可以带来有效的性能提升,其中基于注意力机制的模型可以取得最优的结果。此外,我们的多中心模型取得了比单中心模型更好的结果,具有较强的可行性。"
1549,基于生成式对抗网络的缺失数据填充与预测方法研究,"信息时代产生了海量的数据,这些数据中蕴含着许多有价值的信息,但也存在各种数据质量问题。由于在数据的获取、记录和保存的过程中,经常会发生部分数据缺失的现象,这些丢失了部分数据的不完备数据降低了数据的利用价值,所以它既给后续数据挖掘的过程带来了麻烦,同时也影响着数据用于进行指导决策的质量。因此如何有效处理不完备数据并且基于这些不完备数据进行高质量的决策研究有重要的现实意义。生成式对抗网络是近年来深度学习的热点研究方向,具有拟合高维数据分布的能力,因此本文采用该网络来学习缺失数据到完整数据分布的映射。本文主要对生成式对抗网络、高维度数据和高缺失率的不完备数据集的填充与预测方法进行了较深入的分析和研究,其主要工作和创新点如下:(1)研究了各种处理不完备数据的常用算法的适用条件和局限性。首先分析了不完备数据产生的原因、缺失机制和缺失模式,其次研究了大样本量下的数据缺失问题,然后分析了几种依托于深度学习技术的数据填充方法,最后分析发现大部分填充算法并未有效利用标签数据,也不能对大数量和高缺失率下的不完备数据集进行有效填充。基于此,本文提出了采用生成式对抗网络来解决以上问题的思想。(2)提出了一种缺失数据填充的生成式对抗网络MIGAN(Missing Data Imputation Generative Adversarial Nets)模型。MIGAN能对不完备数据集进行有效填充,同时协同训练的辅助预测网络使得填充结果与标签具有较好的关联性,本文在UCI的3个数据集和mnist数据集上进行了实验比对,实验表明MIGAN在不同维度和高缺失率的不完备数据集中和预测性能均好,尤其适用于高维度和高缺失率的不完备数据集的填充问题;另外从mnist数据集上的生成图片来看,MIGAN的生成结果具有较好的类别判别能力。(3)提出了一种半监督的缺失数据填充的生成式对抗网络semi-MIGAN(Semi-Supervised Missing Data Imputation Generative Adversarial Nets)模型来填充标签缺失的不完备数据集。本文在MIGAN的基础上进行了优化,提出的semi-MIGAN模型可解决不完备数据集存在标签缺失的特殊缺失问题,实验表明semi-MIGAN较其他方法具有更好的填充性能。"
1550,机器学习算法的认知探究,"文章首先对算法概念进行了词源学以及在不同层面上的说明与区分,阐明了算法与计算机等相关概念的关系并介绍了涉及算法的主要领域及其产生的影响。其次,分析了认知的结构基础,通过图灵测试与冯・诺依曼的支持,将人的认知功能与计算机处理信息的功能进行类比,证实了“机器思维”得以实现的现实基础。并论证了算法与认知可以同构的可能性基础。然后在人工智能不断取得进步的时代背景下,重点分析了作为当代人工智能的核心技术――机器学习算法的哲学意蕴。机器学习的思维模拟与创造是人类意识发展的新的里程碑,这给哲学家们提出了人的认知能力如何被认识、模拟和提高的新课题。然后分析了机器学习算法对人的认知过程的学习方式。结合机器学习算法,本文进一步解析了人的认知过程并通过机器学习算法对人的认知本质进行诠释,论述了认知的算法本质并引发了新的哲学思考。在说明了认知与机器学习算法之间存在某种相似性的同时,指出了这种相似性的有限性与发展空间。最后提出了三个有待探索的哲学问题。文中还探讨了机器学习算法的困境,如它不能实现对人的认知的完全模拟,这就给人脑“算法”(普适性和可塑性等)对于机器学习算法的可能性指导提供了新方法;同时,算法的精确性及发展着的机器学习算法尤其是目前很重要的认知计算正在克服人类认知存在的“谬误”,这反过来对人的认知研究也具有一定的启发。因此,我们要以哲学指导算法的创新研究,这样新的算法的提出也会积极地影响认知研究,使二者不断进行着“建构”和“互惠”。"
1551,基于电子病历分析处理的机器学习算法研究,"随着信息技术的发展,计算机技术越来越多地应用到了医疗领域,而在电子化医疗系统迅速普及的现状下,大量医疗相关的信息以电子病历的形式存储下来。电子病历蕴含着极大的医疗价值,如果运用机器学习等方法加以分析处理,将会有难以估计的价值,对未来的医学研究以及医疗发展也会产生深远的影响。论文对基于电子病历分析处理的机器学习算法进行研究,进行了一系列的任务与实验,主要工作包括:(1)基于结构化电子病历的分类算法:本实验研究多种机器学习分类算法在结构化电子病历数据集上的应用。(2)基于电子病历的嵌入方法:本实验主要探索电子病历的嵌入方法,包括句子嵌入以及文本嵌入。通过多种机器学习模型、网络结构对嵌入方法进行分析、实验与比较。(3)基于电子病历的命名实体识别:本实验主要对基于电子病历的命名实体识别任务进行相关研究,应用多个模型结构进行比较与分析。(4)基于电子病历的字向量训练:本实验探索一种基于电子病历的字向量训练方法,该训练方法基于多任务学习,并通过实验进行定量分析与研究。论文基于电子病历,研究了多种机器学习方法在多种任务中的应用,对部分模型做了一定程度的改进与创新,并通过系列实验进行验证、比较与分析。"
1552,基于高光谱的水稻品种鉴别系统设计与实现,"水稻品种的筛选和分类鉴别是农业育种过程中的关键环节,目前常用的水稻品种分类方法存在耗时费力,效率低等问题。基于此,本研究设计了基于高光谱的水稻品种鉴别系统,为水稻品种的批量化在线无损鉴别提供了一种新的检测技术。本文的主要工作内容如下:(1)使用设计的高光谱图像采集系统采集了6类共600个水稻品种样本。使用主成分分析法对数据的分类可行性进行了分析。在全波段下对从训练集样本感兴趣区域(ROI)内提取到的特征光谱数据建立分类模型,并比较了不同水稻品种分类模型的预测效果。结果证明使用梯度提升决策树分类模型对验证集样本的预测准确率最高,达到了95.68%。(2)使用多种预处理方法处理原始光谱数据,选出了多元散射校正作为最终的预处理方法。利用连续投影算法和特征重要性得分的方法选取了光谱数据的特征波长来降低数据维度,结果表明使用特征重要性得分方法提取的特征波长建模效果较好。最后对梯度提升决策树分类模型内部的主要参数进行了寻优,模型对60个外部测试集样本的分类准确率达到了95%。(3)以上述确定的算法为基础,设计了一套水稻品种鉴别系统。该系统的功能模块包括导入和删除测试样本功能模块、ROI和特征光谱提取功能模块、光谱预处理功能模块、全波段下测试品种功能模块、特征波段下测试品种功能模块以及投票决策结果显示功能模块。经过测试该系统具有较好的稳定性,极大的方便了用户的使用。"
1553,基于机器视觉的苹果品质分级技术的研发,"我国作为一个水果大国,每年产出水果的数量一直位居世界前列。水果销售前的一个很重要的环节便是水果分级处理。如果将采摘的水果进行分级处理,可以很好的提升水果的价值。但我国在水果自动分级领域不如国外先进水平。国内在水果分级方面采用的方式多为人工分级和机械分级,这两种分级方式存在着很多不足:分级效率偏低、容易造成水果损伤、分级标准不统一等。故本文选用我国水果产量第一的苹果作为分级目标,利用机器视觉技术对苹果颜色维度、大小维度及缺陷维度的分级检测算法进行研究,并对算法进行仿真及验证。本文首先建立了图像采集系统,并对苹果图像进行预处理操作,包括图像灰度化、图像降噪、图像分割及形态学处理等。然后进行苹果大小及颜色方面特征的提取工作,并完成相关分级数据的统计。在苹果颜色方面,将RGB彩色空间模型转换成HSI模型,通过计算苹果红色着色率的方法进行其表面颜色等级的划分;在苹果大小特征提取方面,采用最小外接圆法进行苹果直径的计算。接着利用外部特征及支持向量机对苹果缺陷进行识别,先是利用图像分割算法对图像进行阈值分割,利用闭运算、边缘提取及减运算获取苹果花萼、果梗或缺陷的外部轮廓,再进行孔洞填充和连通区域分离,最后对感兴趣区域进行分割。利用颜色特征、纹理特征和几何特征,提取13个特征值后,利用支持向量机进行识别,准确率最高为91.32%,实现苹果缺陷维度的分级。最后在苹果缺陷中引入卷积神经网络算法,设计8层卷积神经网络,利用苹果缺陷进行识别,准确率可达96.89%,与人工分级的结果差异小,符合分级要求,并利用全新样本集对SVM与CNN算法对比,CNN优于SVM算法,且CNN无需提取外部特征。"
1554,医疗数据可视化分析研究及其应用,"随着信息技术的兴起及其在医疗行业的广泛应用,医疗数据的数据量呈指数级增长,且存在异构高维等特点,这使得通过传统医疗数据可视化方法获取有效诊疗信息以探寻特定疾病的潜在规律,往往存在效率低下等问题,甚至难以进行。将机器学习方法融入医疗数据的分析处理,不仅能降低医疗数据的高维问题,也便于从中提取用于分析的主特征信息,可有效降低计算量,缩短时间复杂度,提高医疗数据分析的准确性。为此,本文将机器学习方法应用于医疗数据的可视化分析,提出了T-SNE-DBSCAN算法,用于医疗数据的相似度分析,构建了相应的可视化分析平台。针对医疗数据的高维问题,论文首先将机器学习方法用于医疗数据的特征值重要性测度分析。以MIMIC-III医疗数据库中的肺部肿瘤检测数据为基础,通过预处理,应用KNN算法、支持向量机算法和随机森林算法等典型机器学习方法,对该数据进行分类训练,从敏感性、特异性和检测准确性等方面构建了分类性能评价方法,从而得到最优算法用于计算特征值的重要程度值,作为实现数据降维处理的数据预处理方法。为医疗数据提供相似度分析工具,在特征值重要性计算处理基础之上,基于降维思想,论文随后给出了T-SNE-DBSCAN算法。在对MIMIC-III肺部肿瘤数据进行相似度分析的过程中,通过检测数据特征的重要程度实现数据的降维,通过对比分析得到相似度分析效果最好的机器学习方法,构建了T-SNE-DBSCAN相似度分析算法。实验表明相比于传统单一手段的机器学习算法,T-SNE-DBSCAN算法具有更好的判断准确率。在以上研究基础上,论文最后构建了一个通用的医疗数据可视化分析平台,通过多种数据可视化方法实现对医疗数据的分析处理,帮助医生对医疗大数据中潜在的规律及风险进行挖掘、呈现和预测,并进行相关的医学实验分析和科学研究。"
1555,基于财务数据的不同企业基本面预测系统的设计与实现,"近年来互联网+金融已成为财务预测的发展趋势,然而部分企业将自我披露的企业盈利预测夸大,投资者难以了解企业真实财务状况。因此,帮助投资者从历年财务数据中预测下一季度的数据,避免其被企业迷惑显得至关重要。基本面预测的重点是盈利预测,它能直接反映出公司当前运营状况。研究表明,我国盈利预测普遍按照具体行业进行,这导致收益较高的行业受到各界广泛的关注,而营业数值较小的行业得不到充分的关注,因此造成行业预测模型缺失。现有研究以单一行业为主,不同行业间的财务数据特征以及不同行业适用的财务数据模型是否存在差异性仍有待研究。本文针对这些问题进行了以下研究:首先,本文根据3000家不同上市公司的财务报表整合构建了61行业的财物数据,然后研究了不同行业间财务数据特征是否存在差异性。本文对构建后的财务数据进行特征统计及分析,然后判断是否存在各行业所特有的特征,并寻找这些特征与盈利之间的关联性,最后将关联度较高的特征作为后续模型选取的特征。其次,本论文研究了长短期记忆网络等七种机器学习方法并与三种归一化方法组合算法(Hybrid optimization简称H-op),它探究了在构建行业特征后不同行业是否应当采用不同的归一化和不同的机器学习算法,并将每个行业对应的最优预测方法进行展示。H-op针对不同的行业数据训练,按照金融业预测评价标准对预测方法进行比较,选择最优模型作为当前行业的预测模型。实验证明,本文提出的机器学习与多种归一化组合能得到当前最优解,预测准确率能达到96%以上。最后,本文采用上述研究结论实现了一个基于财务数据的不同企业基本面预测系统。利用H-op选取当前行业最优模型和相应的归一化方式预测此行业内不同公司下一季度的财务情况,并结合其它财务数据,对企业的风险和活力等作出判断评估,并将这些信息直观的展现出来。本文给出了各个模块的具体设计与实现,并对系统的功能和性能进行了相关测试,结果表明,本文实现的系统具有良好的预测与展示功能。"
1556,基于机器学习的JavaScript恶意代码检测技术研究,"JavaScript目前已经成为交互式网页和动态网页中广泛采用的技术,JavaScript恶意代码产生的攻击类型也变的多种多样,已经成为加密勒索病毒、脚本挖矿病毒、钓鱼网站、垃圾广告等攻击类型的载体。本文通过对大量JavaScript恶意代码的相关特征进行分析,并针对混淆恶意JavaScript代码进行特征提取与归类,从基于属性特征、基于重定向特征、基于可疑关键词特征、基于混淆特征、基于运行函数特征、基于词法分析特征和基于编译后操作码特征这七个方面进行研究,提出了一种反混淆算法并实现了基于机器学习的JavaScript恶意代码检测方法。主要研究内容如下:1.通过分析大量JavaScript恶意代码与良性代码,针对被混淆的代码,本文提出了一种基于行为分析的JavaScript脚本反混淆算法,该算法可以将部分被混淆的JavaScript代码转换至可读状态。2.运用特征工程相关方法,分析了JavaScript恶意代码的静态特征,对提取的特征应用熵值法计算权值,从中选出权值相关性较高的特征进行机器学习相关实验,实现了静态特征检测。3.深入研究JavaScript恶意代码在计算机中的攻击方式,实现了一种基于Ring3层的Inline Hook技术来实时监控JavaScript恶意代码的运行情况,实现了运行行为检测;通过对JavaScript恶意代码进行词法分析和编译后操作码的分析,提取特征进行机器学习相关实验,实现了动态特征检测。经过实验验证,本文所提出的检测技术针对恶意JavaScript代码的检测具有较好的检测效果,证明了模型的有效性、所选特征的可靠性。"
1557,基于卷积神经网络提取冬小麦空间分布信息的方法研究,"冬小麦是我国主要的粮食作物之一,精确地估算冬小麦的空间分布信息,对于产量估算、生产管理和粮食政策调整具有非常重要的作用。遥感图像解译是目前获取冬小麦空间分布信息的主要技术手段,具有覆盖面积广、探测周期短、获取信息丰富等优势。国产高分2号(GF-2)影像空间分辨率达到了1米,为及时、准确地获取冬小麦的空间分布信息提供了可靠的数据保障,利用卷积神经网络进行遥感图像解译从而获取冬小麦空间分布信息是目前研究者关注的热点问题,但是直接利用现有的卷积神经网络模型在高分2号影像上对冬小麦进行语义分割,分割精度并不是太高,主要原因是卷积神经网络的编码器和分类器存在一些缺陷:(1)编码器使用的模拟方式较为简单,不利于形成抽象的高层特征;(2)分类器在类别归属判断上仅仅利用了最大概率值这一信息,忽略了各概率之间差值大小对像素类别归属判断的影响。本文针对以上问题,选择山东省济南市的章丘区为研究区域,使用高分2号遥感影像和地面调查数据为数据源,建立了高精度冬小麦遥感影像分割模型(Winter Wheat Remote Sensing Segmentation Model,WWRSSM),获取了更精细的冬小麦空间分布信息。本文主要研究内容如下:1、本文选用比较经典的SegNet、DeepLab、RefineNet模型在高分2号遥感影像上提取冬小麦空间分布信息,对3个模型的提取结果进行统计,并分析了影响提取精度的主要因素,找到了模型的改进方向。2、高精度冬小麦遥感影像分割模型WWRSSM的设计与实现。针对SegNet、DeepLab、RefineNet模型提取冬小麦空间分布信息存在的问题,设计了由特征提取器、编码器、分类器组成的网络结构。使用RefineNet模型的卷积结构作为特征提取器用于提取冬小麦种植区域的像素的特征;选择拟合能力较强的深度置信网络(DBN)构建编码器,对特征提取器得到的特征向量进行编码,增加模型的非线性能力;分类器由SoftMax-Ex和最大后验概率(MAP)二级子分类器构成,SoftMax-Ex在SoftMax分类的基础上,利用概率差值计算置信度,对于置信度高的像素保留原分类结果,对于置信度低的像素则把类别概率向量输入到MAP子分类器。MAP层基于贝叶斯原理进一步判别置信度低的像素的类别。利用大量的数据样本对本模型进行训练,最终得到冬小麦分割结果。3、实验结果及对比分析。为了对WWRSSM模型进行验证,本文选择了SegNet、DeepLab和RefineNet以及分别与MAP耦合后的模型作为对比模型,采用相同的数据集进行训练及测试。由实验结果可知WWRSSM模型的提取精度为94.8%,高于6个对比模型的提取精度。最后总结了WWRSSM模型的优点及理论依据。本文构建的WWRSSM模型弥补了传统卷积神经网络提取冬小麦空间分布信息存在的不足,对于提高大范围冬小麦空间分布制图的精度和自动化水平具有重要的意义,也可以为农作物空间分布信息提取和面积统计提供一定的技术参考。"
1558,精神分裂症多维度信息管理系统的设计与实现,"精神分裂症是一种发病机制尚未完全阐明的重性精神疾病,其临床评价与诊断仍然高度依赖医生的临床经验,研究精神分裂症的诱病因素和神经病理机制具有重要的科学价值和临床意义。随着现代信息化技术的发展,对临床大数据进行回溯性研究及分析,是常用的方法之一。目前精神分裂症临床大数据的研究,缺乏良好的数据管理系统及工具,往往是个人或课题组的“小作坊”模式,存在着数据管理困难、数据分析不便等缺点,难以形成大规模的有效数据。本文针对精神分裂症临床大数据管理系统缺失的现状,设计并实现了一个针对精神分裂症临床大数据的多维度信息管理系统,对数据进行有效、可靠的管理及分析。本文从精神分裂症的四个研究问题出发,分析了临床试验及科学研究中需要存储的数据类型,包括基本信息、病例报告表数据、神经心理及认知功能测评、磁共振数据、脑电数据及肠道菌群数据等。通过系统的需求分析,包括数据管理部分、数据分析部分、系统管理部分的功能性需求及系统总体的非功能性需求,完成了系统的总体架构设计、功能模块划分、数据库表结构设计等。本系统采用B/S架构、前后端分离模式,基于Java语言开发了系统的后台应用服务器,基于Python语言开发了系统的计算服务程序。此外,详细设计及实现了系统的各个功能模块,并结合时序图阐明了各模块的软件运行流程。最后,采用本研究室试验采集的精神分裂症多维度数据进行了系统测试,验证本系统是否能够满足精神分裂症临床大数据管理的需求,使用本系统进行了机器学习自动分类模型的构建及测试,并对系统功能进行了详细的评价。本文设计的精神分裂症多维度信息管理系统相对于现有的工具,其特点在于:第一,能够管理及分析多种维度的精神分裂症临床试验及科学研究数据,操作简单方便;数据安全性和稳定性高,不易丢失;存储数据的格式统一,数据冗余度低,能够节省存储空间;系统为多种维度的数据提供了查询及检索功能,可以随时、随地查看并下载数据。第二,能够更加方便地进行数据分析,简化了数据统计及机器学习分析的流程,提高了研究效率。第三,系统为B/S架构的网页应用,扩展性好,容易进行多中心扩展,能够形成大规模的医学大数据,为精神分裂症研究提供强有力的研究工具。"
1559,因果推断中的GAN技术及应用,"近年来关于因果推断的研究在持续发展,并在自然科学、社会科学等领域得到充分实践。由于传统因果推断模型在现实应用中存在许多不足,如倾向得分匹配(PSM)模型是以大样本为基础的,在样本量较小的情况下,通过PSM也仍然会存在部分协变量不平衡的情况,因此PSM模型无法给出有效的因果推断。目前有部分机器学习领域的学者提出一些结合生成式对抗网络(GAN)的因果推断方法,以优化PSM模型的表现。本文在PSM基础上提出结合GAN的一个新模型――GPSM模型。模型核心在于:通过GAN学习原有数据集的分布,生成更多分布相似的样本,结合原有样本和生成样本进行倾向得分匹配,从而解决传统PSM模型在小样本情况下的局限性,控制选择性误差。GPSM模型主要由两个子模型组成:第一个子模型是基于GAN的样本生成模型。由两个神经网络组成,分别为生成器G和判别器D。通过生成器和判别器的相互对抗学习,生成新的模拟样本,从而拓展样本的数量。该子模型的输出与真实样本数据结合,作为第二个子模型的输入。第二个子模型是基于PSM的样本匹配模型。该模型通过Logistic回归计算各个样本的倾向得分,并利用倾向得分将处理组与对照组之间具有相同特征的样本进行匹配,即将处理组对象的反事实状态近似为匹配的对照组对象,并通过对比两者的目标结果差异来对处理的因果效应进行评估。本文最后以某肾病试验药的有效性证明为实验背景,对GPSM模型进行实证分析。利用本文提出的GPSM模型评估试验药对肾病治疗效果的影响,并对比GPSM模型与传统PSM模型的因果推断过程和结果。根据平均处理效应的估计量及假设检验结果,认为该试验药对于治疗有显著作用。实证表明GPSM模型的协变量平衡性、模型稳健性均优于传统PSM模型,并且随着引用的生成样本量越多,GPSM模型的综合表现越好。"
1560,基于特征权重计算方法的情感分析,"近年来,情感分析一直是自然语言处理研究者群体日益关注的主题。情感分析可以帮助公司和公共管理部门的人员更多地了解客户的意见,并帮助他们做出一些决定。在本文中,我们首先介绍了情感分析任务的背景,定义,以便读者更好地理解本文的研究目标以及论文的贡献。我们还介绍了最近的几种情感分析的方法,如概率算法(朴素贝叶斯),最近邻算法和变量算法,决策树或分类和矢量支持机器。然后介绍了构建情感分析系统的步骤,包括预处理,特征提取和性能评估。最后,我们更加关注由在线酒店评论组成的数据集,并应用监督机器学习方法Na?ve Bayes使用unigram特征和两种类型的信息(频率和TF-IDF)来实现文档的极性分类。如我们的实验结果所示,在准确性,精确度,召回率和F_score方面,我们的模型优于其他模型。"
1561,基于相似度的BP神经网络迁移学习算法,"传统的机器学习算法不仅要求有大量的带标签训练数据,还要求训练数据和测试数据满足同分布。但是在实际应用中,常常缺乏与测试数据同分布的带标签的训练数据,因此如何运用其他领域中不同分布的带标签的训练数据,辅助目标任务的完成是亟需解决的问题。迁移学习是解决这一问题的一种有效方法。而在大多数迁移学习中都要求源领域与目标领域之间存在一定的相似度,在迁移学习框架中利用相似度学习可以提高迁移的效果。BP神经网络算法是一种应用比较广泛的机器学习算法,其在带标签样本数据少的领域中分类准确率较低。针对上述问题,本文研究了基于相似度的BP神经网络迁移学习算法,其主要的研究工作如下:(1)提出了基于相似度的BP神经网络单源迁移学习算法(TL-BP)。该算法首先得到了源领域的最优权重参数并得到了源领域与目标领域之间的最优相似度;然后结合该相似度把源领域的最优权重参数信息迁移到目标领域中;最后构建了适用目标领域的BP神经网络模型。以BP神经网络算法以及TrAdaBoost算法作为对比算法,使用Letterrecognition数据集、Wine Quality数据集以及20Newsgroups数据集对算法进行了实证分析。实验结果表明,在大部分实验组合下,该算法的平均分类准确率和分类时间都有明显的优势,但是在个别实验组合中出现了“负迁移”问题。(2)针对TL-BP算法中出现的“负迁移”问题,提出了基于相似度的BP神经网络多源迁移学习算法(MTL-BP)。该算法是在TL-BP算法的基础上增加了源领域的个数,把各个源领域的最优权重参数信息结合对应的最优相似度迁移到目标领域中。为了验证算法的有效性,在Letter-recognition数据集以及20Newsgroups数据集上进行实验。最终实验结果表明,与MultiSourceTrAdaBoost算法相比,该算法无论是在分类时间上还是平均分类准确率上都有明显的优势;与TL-BP算法以及BP算法相比,该算法在分类时间接近的前提下有更高的平均分类准确率。综上表明了该算法的有效性以及避免了“负迁移”问题。"
1562,基于机器学习的声纹识别研发,"声音是人与人之间进行交流的信息载体,声音在人机交互中也起到了举足轻重的作用。声纹识别是语音识别中一个十分重要的方向,这种技术应用到人机交互中就会大大提高人机语音交互的安全性。作为一种生物认证识别方式,声纹识别还有很多重要的应用前景。近些年来,机器学习技术在自动语音识别领域取得了重大的突破,越来越多的机器学习方法尤其是深度学习方法被引入到声纹识别中,并取得了显著的成效。基于i-vector的声纹识别方法是目前与文本不相关声纹识别的基准方法。但这种方法面对短时语音时的识别率较低,也容易受到噪声干扰。本文利用机器学习的理论设计了基于时延神经网络的声纹识别方法,相比于基准方法,这种方法提高了声纹系统的识别率和稳定性,尤其是在短时声音的识别效果方面,应对噪声的鲁棒性也更强。为了进一步提高系统的识别效果,本文又设计了基于生成向量的声纹识别方法,这种方法将基于i-vector的声纹识别方法与基于时延神经网络的声纹识别方法进行了“融合”。此方法利用典型关联分析,将部分i-vector的信息融合到时延神经网络提取的特征向量中,使得生成向量更能表征说话者的身份特征。对三种声纹识别方法进行了实验验证,比如在VoxCeleb语音库下模型的识别效果上生成式特征向量模型的等错误率EER比传统的i-vector模型降低了3.1%。生成式特征向量模型比传统的i-vector声纹识别模型应对噪声的鲁棒性更强。本文还对设计的模型进行了实际的应用测试,验证了系统在应用的可行性。"
1563,基于迁移学习的运动想象脑电分类方法研究,"近十几年来,脑机接口(brain-computer interfaces,BCI)技术的研究引起了世界范围的关注,并且得到迅速的发展。它是一项交互技术,旨在识别用户的大脑意图并转化为一组特殊的指令以便控制现实世界设备。脑电图信号(electroencephalography,EEG)是BCI中应用最广泛的非侵入性成像技术之一,这种基于EEG的脑机接口系统可以替代受损神经并提供一种新的通信方式。脑机接口系统通常需要采集大量受试者有标签的训练数据来构建分类器模型,并且假设训练数据和测试数据在相同的特征空间中,服从相同的统计分布。然而,由于EEG信号具有非平稳特性,数据的分布可能不同。因为BCI系统主要应用于医疗康复领域,获取同一受试者大量数据往往难以实现,而不同受试者之间存在个体差异,无法直接利用其他受试者的数据。这些问题不仅影响到系统的性能,还限制了其应用范围。运动想象脑电信号是脑机接口系统中常用的控制信号,本文在传统运动想象脑电信号处理方法的基础上,将迁移学习的思想应用于运动想象脑电信号的分类,并提出了两种迁移学习算法以解决传统脑机接口系统的局限性。本文具体研究工作如下。本文在子空间对齐基础上提出样本加权方法,根据样本特征的相似度对源领域样本赋予不同的权重,生成加权源领域子空间与目标领域子空间对齐。考虑到脑电信号非线性的影响,提出了通过非线性映射将原数据转换到高维空间中再进行子空间对齐的方法,并推导了算法的可行性。最后设计两个实验,不同时期以及不同受试者的脑电数据迁移验证了算法的有效性。本文提出基于共同空间模式的迁移学习算法,结合了复合共同空间模式和自适应的方法,通过计算实验样本之间的相似度选择样本更新协方差矩阵,重新构建空域滤波器以提取用于分类的特征,从而提高分类器的性能。最后设计实验,在公开的脑电数据集中验证了算法的有效性。"
1564,基于车桥耦合振动响应大数据的损伤识别方法研究,"桥梁的结构健康监测已成为当今土木工程界研究的热点问题。桥梁结构由于各种因素会在运营期间发生不同程度的损伤,结合车辆过桥时引起的车桥耦合振动,会对车桥系统构成安全隐患。车桥耦合、损伤识别对桥梁的正常维护、安全运营和寿命评估意义重大。桥梁健康监测系统是实现桥梁结构在运营期间的数据监测、损伤识别、状态评估的一种重要手段。然而,目前对海量健康监测数据的数据处理以及数据挖掘方法仍存在不足,不能充分发挥它们的作用。如何利用监测数据对桥梁运营状态进行有效及时的评估是桥梁领域学者们关注的重点与难点问题,也是发挥海量监测数据作用的一个制约点。因此,本文利用符合实际车流状况的随机车流作为激励,提取桥梁载不同损伤工况下的响应信号,并利用机器学习进行结构损伤识别,提出一种结合桥梁响应统计特征的智能损伤识别方法,具体开展了以下工作:1)开发随机车流-桥梁耦合振动分析程序。基于元胞自动机-NaSch规则,结合实测车流数据,建立单车带随机车流模型,获得符合实际车流的车流数据;开发了基于Newmark-β法的车桥耦合振动分析程序;将二者结合,完成随机车流-桥梁耦合振动分析程序的开发。2)以随机车流-桥梁耦合下的桥梁响应为损伤识别输入量,结合多种机器学习方法,提出一种结合桥响应数据统计特征的损伤识别方法。获得不同损伤工况下车流-桥梁耦合振动作用下桥梁的响应时序,探讨损伤对测点响应的影响;根据桥梁测点响应统计特征,建立损伤识别样本库,引入随机森林、支持向量机、梯度提升决策时等机器学习方法进行损伤识别。"
1565,基于桥梁局部时变可靠度的人工智能损伤识别研究,"桥梁健康监测的基本内涵是通过对桥梁结构状况的监控与评估,为桥梁在特殊气候、交通条件下或运营状况异常严重时发出预警信号,为桥梁的维护维修和管理决策提供依据与指导。桥梁健康监测不只是传统桥梁检测加结构评估新技术,而且被赋予了结构监控与评估、设计验证和研究与发展三方面的意义。目前,国内外许多新建桥梁、大跨度桥梁都建有桥梁健康监测系统,实时监控桥梁的运营状态。然而一个尴尬的现象是,监测系统强大的数据采集能力记录了海量的监测数据,但由于对监测数据分析和挖掘的研究不够深入,使得海量健康监测数据得不到妥善处理和利用,反而限制了监测系统发挥其科学指导的作用。针对当前桥梁长期健康监测数据研究不够深入,海量监测数据得不到妥善处理和利用的问题,本文围绕长期健康监测数据应用开展了以下工作:(1)将长期健康监测温度数据应用于混凝土箱梁温度作用的统计研究,运用统计分析的方法,确定混凝土箱梁的温度场分布特点、温度梯度以及温差代表值,并与规范推荐值作比较。(2)将长期健康监测应变数据应用于桥梁局部时变可靠度分析的研究,完善和修正了基于长期健康监测数据的桥梁局部时变可靠度计算方法。使用聚类分析方法确定了肇庆西江大桥荷载效应统计时间段划分方法;使用假设检验方法确定了肇庆西江大桥测点应力数据统计分布类型;使用提出的局部时变可靠度分析方法计算了肇庆西江大桥某测点的局部时变可靠度指标,分析了该测点局部的可靠性和安全性。(3)以简支平面梁模型为研究对象,借助大型通用有限元软件ANSYS,通过在模型上施加实测温度数据的方法模拟桥梁长期运营状态,建立了局部时变可靠度指标数据库,确定了可靠度指标随损伤程度的变化规律,提出了一种以局部可靠度指标作为机器学习输入量的简支平面梁损伤识别方法。"
1566,基于CT影像组学对食管鳞状细胞癌病理分化程度的预测,"目的:探讨基于CT的影像组学对于预测食管鳞状细胞癌分化程度研究中的价值。方法:回顾性分析广东省人民医院从2008年1月到2016年8月,经手术切除、病理证实为食管鳞状细胞癌,临床资料齐全和术前行X线计算机体层成像(X-ray computed tomography,CT)增强扫描且获得完整图像的160例病例,随机分为训练组(103例)和验证组(57例),使用3D Slicer对病灶进行感兴趣区域(Interest of Region,ROI)逐层勾画;随后,使用Matlab软件对获得的图像进行特征提取;使用R软件进行特征筛选,构建影像组学标签。结合提取的影像组学标签和临床资料构建多变量Logistic回归模型,构建影像组学模型(radiomics predictive mode)并进行验证。利用受试者操作特征(receiver operator characteristic,ROC)曲线评价模型对术前预测食管鳞状细胞癌分化程度的效能进行评价。结果:影像组学标签是食道癌病理分化程度的独立预测因素。影像组学预测模型在训练样本中的预测效能AUC(area under curve)值是0.791,敏感度是81.6%,特异度是72.3%;在验证样本中,AUC值是0.757,敏感度是70.0%,特异度是73.0%。结论:利用CT图像提取出的影像组学特征所构建的影像组学模型,在术前预测食管癌分化程度方面有一定的预测效能。"
1567,基于机器学习的重度扩张型心肌病患者预后评估研究,"扩张型心肌病(dilated cardiomyopathy,DCM)是常见的心肌疾病之一,其心血管不良预后事件的发生率高居不下,尤其是重度DCM患者。其部分原因在于目前对重度DCM患者心血管不良预后事件的预测缺乏有效手段。为了解决该问题,研究者一般从以下两个主要思路进行深入探索:其一,寻找能更有效地提示重度DCM患者发生心血管不良预后事件的特征;其二,建立能有效预测患者发生终点事件的个体化风险预测模型。因此,本文的主要工作如下:一、基于45位重度DCM患者中位随访期为13个月(四分位数,7C17月)的数据,结合基于心血管磁共振(Cardiovascular magnetic resonance imaging,CMR)增强前T1mapping序列图像心肌区域所提取的影像组学特征与常规CMR影像特征,主要通过Lasso-Cox回归对特征进行筛选,并利用留一法交叉验证的方式,以各个关键时间点的时依受试者工作特征(time-dependent receiver operating characteristics,time-dependent ROC)曲线下面积作为性能度量,验证模型的预测效能。结果显示,T1 mapping序列所得的指标――细胞外容积分数(Extracellular volume fraction,ECV)的Lasso-Cox回归系数为1.038。另外,同样有7个影像组学特征的回归系数均不为0。结合ECV与这7个影像组学特征建立的Cox回归模型预测效能优于单独使用ECV所建立的模型。因此,我们得到如下结论:ECV与部分影像组学特征均对重度DCM患者终点事件的预测有重要作用;结合ECV与这部分影像组学特征有望更好地预测重度DCM患者心血管不良预后事件的发生。二、基于两家医院98位患者的常规临床特征与影像特征,通过机器学习方法建立对重度DCM患者一年内出现心血管不良预后事件的风险预测模型。本实验先对连续各项连续变量指标按照行业专家共识转化成离散变量指标,再经过Relief-F进行特征选择,最后使用朴素贝叶斯算法得到最优模型,其在十折交叉验证下的ROC曲线下面积达到0.920(置信区间:0.868C0.972)。其效果显著优于传统预测指标左心室射血分数(left ventricular ejection fraction,LVEF)的0.504(置信区间:0.354C0.654)和心衰患者风险评分系统MAGGIC Score的0.599(置信区间:0.469C0.729)(p<0.01)。因此,我们得到如下结论:通过机器学习方法得到的风险预测模型在预测重度DCM患者一年内出现终点事件的效能优越,有机会在未来临床工作中扮演重要角色。"
1568,基于心电信号的心律失常分类和身份识别研究,"心电信号是人体心脏电生理活动的反映,自从上世纪初心电图机问世以来,人们一直致力于通过心电图进行心脏疾病的研究。随着信息技术的发展,利用计算机结合人工智能技术进行心电信号的自动分析已经得到广泛应用。然而由于心电数据采集环境的限制以及医生诊断可能存在的错误,心电信号自动分类领域存在训练样本错误标记的问题,会使得心电分类成为弱监督学习,分类器会被严重破坏,分类准确率明显降低。本文针对这一问题提出了基于交叉验证的识别方法,对训练集中可能存在的错误标记样本进行识别,提升了分类性能,取得了满意的效果。另一方面,由于心电信号相对稳定且防伪造和窃取能力强,其应用也不再仅限于心脏疾病诊断,而扩展到身份识别等领域。尽管已有不少相关工作,但是运动心电身份识别还有待进一步研究,该鲁棒性问题限制了心电身份识别的实际应用。针对该问题,本文建立了运动心电数据库,对运动心电身份识别的可行性进行了探讨。第一章,介绍本文的研究背景和研究意义,回顾了心电自动分析和心电身份识别的发展现状。第二章首先详细介绍了心电信号的产生机理和波形特点,然后介绍了心电图机的导联系统和心电研究领域广泛使用的数据库。在第三章中梳理了心电信号处理的主要流程。在心电预处理中介绍了小波变换法和中值滤波法。在心电波形检测中介绍了动态阈值法,在心电特征提取中介绍了时域特征、形态特征和频域特征。最后在分类算法中介绍了支持向量机、决策树、线性判别分析、朴素贝叶斯和k近邻算法。第四章则讨论在心电自动分类中存在的错误标记训练样本问题。针对该问题,本文针对前人提出的基于遗传算法的错误标记样本识别方法存在的问题,提出了一种基于交叉验证的多种机器学习算法结合的方法,并在经过人工添加错误标记噪声的MIT-BIH心律失常数据库上进行实验。结果表明经过基于交叉验证的识别方法去除错误标记训练样本后,分类性能指标得到明显改善。其中,以总体分类准确率为代表,如果训练集中错误标记样本的比例在20%以下,那么总体分类准确率可以回升至与没有人工添加标记噪声时相当的水平。如果错误标记样本比例达到30%,则总体分类准确率可以回升到比无人工添加标记噪声时略低的水平。而如果错误标记样本比例达40%,则经过本文方法处理之后的总体分类准确率仍然远高于不进行错误标记样本去除的情况。在第五章中,针对运动状态改变对于心电身份识别造成的困难,利用本课题组采集的运动心电身份识别数据库探讨运动心电身份识别的可行性。本章首先介绍了运动心电身份识别数据库的详细信息,并分析得到运动心电身份识别的关键在于提取出运动前后保持相对稳定的特征。然后将当前心电身份识别领域比较成熟的特征提取和选择方法在运动心电身份识别数据库上进行实验。实验结果表明现有文献提出的心电身份识别方法在静止状态下取得了不错的效果,但是运动状态改变的情况还有待进一步研究。"
1569,基于深度学习的数字调制信号识别算法研究,"大容量、高速率的信息传输需求极大地推动了认知无线电领域的技术发展,其中,复杂电磁环境中信道均衡及通信调制类型识别技术,是该领域重要组成之一。传统的均衡处理主要是利用梯度下降法逼近信道特征,在时域或频域对信号进行逆卷积运算,以抑制信道干扰和畸变,改善系统响应;而传统的调制识别方法主要通过提取信号的专家特征,选择合适的分类器进行识别。近年来,许多先进的卷积神经网络架构及优化算法相继提出,深度学习在多个领域都取得了突破性的成果。基于卷积神经网络对原始输入的抽象特征学习能力,本文对其在信号去噪、信道均衡及调制识别等方面的应用进行了深入研究,其主要贡献如下:1)针对目前深度学习架构及其优化算法难以学习通信复基带信号结构性特征的现实,本文提出了一种多路并行复数卷积神经网络架构,以满足全数字通信信号复基带处理需求。该架构通过并行支路学习基带信号实部与虚部的结构化特征,在输出时按一定规则融合得到最终输出,实现了对复数值映射的拟合过程。2)针对传播信道引入的噪声干扰与畸变问题,综合讨论了去除加性噪声和信道均衡的传统方法,设计了一种基于多路并行卷积神经网络的端到端方法,可将两个问题统一解决。进一步地,为了验证方法的可行性及其性能,论文进行了仿真实验:利用MATLAB对调制信号进行信道损害及加噪处理;分别采用传统方法与本文方法对信号进行恢复处理;通过数字解调,计算对比输出误符号率。结果显示:本文所提出的方法较传统方法具备更强更全面的信号恢复能力。3)采用了一种“信号恢复预处理+调制识别”的方案,并在调制识别阶段采用了将多路并行架构与传统架构串联的方式构建卷积神经网络。论文讨论了卷积网络中卷积层输出的抽象特征,以及专家特征等两类类型特征对识别精度的影响,对比了常用机器学习模型在调制识别任务上的性能表现。实验结果表明抽象特征结合专家特征在集成学习模型分类中表现最好。4)为了验证本文所提出方案在真实环境中的可行性,本文采用NI-USRP2920作为通信信号收发装置,建立了真实通信环境实验平台,完成了算法测试与验证。结果显示,本文所提出的方案可以满足在真实环境下调制识别的需求。由于现实环境中存在着更多的干扰(例如收发时钟不同步),其识别率略低于仿真实验的结果。"
1570,机器人移动操作中的视觉认知技术研究,"随着人工智能时代的到来,机器人越来越广泛的应用于各行各业,在室内建筑工地场景下,机器人能够节省大量劳动力和大量时间。视觉能够为机器人提供大量信息,本文旨在模仿人类视觉认知机制,为机器人赋予目标检测及定位的视觉认知能力。传统基于双目视觉的深度相机对环境光照非常敏感,在光照较强和较暗的情况下双目视觉算法效果会急剧下降,同时在单调缺乏纹理、缺乏视觉特征的场景下,双目视觉算法还会出现特征匹配困难的情况。此外,基于飞行时间法的深度相机,由于技术不成熟,存在功耗较大、成本较高以及深度图像分辨率较低的问题。所以本文采用双目结构光相机来完成定位功能。近年来,深度学习在计算机视觉领域有了飞速发展,单任务的网络结构已经逐渐不再引人瞩目,取而代之的是集成、复杂的多任务网络模型,其中的代表就是实例分割模型。实例分割是一个比较综合的问题,它融合了目标检测、图像分割以及目标分类,并且检测性能也是领域中的佼佼者。因此,为了使机器人更好更快地识别物体并判断物体的位置,本文提出一种室内基于Mask R-CNN模型和双目结构光相机的目标检测和定位方法。本文的主要研究工作内容如下:1.研究并实现Mask R-CNN模型,同时对模型性能进行优化。具体方式是通过调整Mask R-CNN模型的训练方式,其一是忽略训练集中提供的目标框,改为采用自己生成目标框的方式,选择包含目标物体所有像素的最小框作为边界框;其二是采用梯度裁剪的方式,来防止梯度爆炸。从而使得Mask R-CNN模型效果得到提升,至此,使用Mask R-CNN模型完成了对图像精确的目标检测以及像素级分割。2.研究深度相机测距技术,并结合深度学习对测距效果进行提升。目前采用深度相机对物体进行测距的主流方式是对整个目标框中的每个像素的深度值求平均,但是目标框中并不是每个像素都属于目标物体,所以这种方式必然会带来误差。而本文通过Mask R-CNN模型对目标框中的物体进行像素级分割,可以过滤掉大部分不属于目标的像素,从而提升测距效果。至此,使用Mask R-CNN模型结合双目结构光相机完成了目标检测和定位功能。3.最后根据目标检测及定位结果,使用丹麦Ur公司下的Ur10机械臂来进行目标捕获实验,最终通过实验证明,本文提出的室内基于Mask R-CNN模型和双目结构光相机的目标检测和定位方法的有效性。"
1571,复杂场景中的3D目标表达与检测,"3D目标检测及位姿估计对于机器人,自动驾驶和增强现实等多种应用都有重要的研究意义。3D目标检测是指检测物体的三维位置和姿态,为机器人的智能操作提供必要的目标信息。然而,由于现实世界中对象的多样性,目标物体需要使用合理的表达结果才能满足检测算法的实时性和准确率要求。同时3D目标检测会受到场景杂乱以及遮挡的影响,这些都使得3D目标检测非常具有挑战性。本文主要研究工作如下:针对目前3D目标检测出现的不同关键点选取方案,我们设计了基于端到端回归预测网络的对比实验,比对了3D包围框(Bounding Box),FPS和本文提出的最小边界球关键点方案,为后续网络模型训练选择适合的目标表达方案。为了解决预测3D包围框在图像投影后形变导致位姿估计精度较差的问题,提出了一种基于预测框边长约束的网络ER-6DYOLO。本文基于3D包围框为立方体的先验信息,设计了针对预测框平行边的约束损失函数Edge restrain Loss,可以有效克服3D检测框特征点在图像投影后平行边长度差异的缺陷。通过为损失函数引入归一化处理,克服了预测框尺寸变化问题,并且加快网络收敛。本文通过在场景杂乱的LINEMOD公开数据集测试,平均3D距离指标(ADD)达到了60%,检测帧率达到每秒80帧。ER-6DYOLO在基于真实图片输入的算法中排名第一。针对遮挡场景中预测关键点向遮挡目标偏移的缺陷,本文提出了AttLoss损失函数,使负责预测同一目标的检测框尽可能密集地聚合在真实值周围,引导网络对未被遮挡部分特征的学习,在一定程度上解决了误检的问题。实验证明,通过引入AttLoss损失函数,在Occlusion数据集上相比SingleshotPose网络在二维投影指标(2D projection)提升了13.61%。基于小样本数据集且缺少位姿标签的研究工作,我们引入目标轮廓作为特权数据,设计了新的网络框架6DPose-PCNet。本文在网络中引入轮廓预测分支,通过上采样和底层特征融合,引导底层特征学习目标的边缘信息,为特征点检测提供更强的特征信息。我们轮廓预测分支轻量化的设计压缩了增加的网络参数,检测帧率每秒72帧,速度为当前最先进算法PVNet的3倍。实验证明,6DPose-PCNet在LINEMOD数据集上2D projection和ADD分别达到了93.97%和64.19%,相对ER-6DYOLO分别提升了2.86%和4.19%。"
1572,事件知识图谱平台设计及实现,"知识图谱是以实体作为顶点,实体间关联作为边,描述静态知识,但现实世界中知识是动态变化的,记叙文是记录动态知识的主要载体。针对记叙文的知识化抽取,本文设计并实现了一个事件知识图谱平台,能够将知识从非结构化文本形式转化成以事件为单元的图谱形式,描述现实世界中事物之间的关联。事件知识图谱平台由数据采集平台、图谱构建平台、并行计算平台及标注平台组成。数据采集平台负责从互联网中获取指定事件相关的新闻文本、追踪热点事件、自动更新数据。图谱构建平台将事件信息从文本形式转化为图谱形式。并行计算平台提供并行计算能力,承载图谱构建过程中的计算任务。标注平台为标注人员和行业专家提供规则制定和样本标注作业平台,确保平台能够适应不同的业务场景。平台的主要工作流程分为文本数据采集、元事件抽取及融合、事件知识图谱构建及可视化。首先通过数据采集平台获取事件相关文本,再利用自然语言处理技术分析文本,从中抽取元事件信息,然后对元事件信息进行整理和融合,最后将事件组织为图谱形式,完成事件知识图谱构建,实现将知识转化为以事件为核心的图谱形式。本文的研究成果包括以下四点:(1)针对数据采集时可能出现搜索不准确导致结果中出现无关文本的问题,提出一种基于篇章间关联的事件文本过滤算法,利用文本中的实体信息量化篇章间关联,再根据篇章间关联网络过滤噪声文本。(2)在事件融合过程中,针对由于中文表达灵活性导致的表达方式不一致问题,提出了事件元素格式化方案,消除由于表达方式不同所造成的影响。提出了基于事件相似性的元事件融合算法,去除重复事件,降低冗余。(3)在事件知识图谱构建时,定义了事件知识图谱层次结构,根据事件所在业务场景的事件范畴,将事件信息组织为结构化、层次化的图谱形式。(4)为了满足大规模事件知识图谱的存储和查询,设计并实现了一种事件知识图谱专用图数据库,能够将图谱保存在分布式环境中,并封装了相应的查询接口实现以事件为输入,以图谱为结果的查询,与并行计算平台相结合,为并行计算提供数据输入源和存储地址。最终,结合前端技术,实现图谱可视化,经过测试,本文实现的平台能够构建出事件知识图谱。"
1573,迁移学习在量化选股中的应用研究,"随着近年来机器学习、人工智能领域的快速发展,很多国内外学者尝试着将机器学习与量化投资相结合,试图通过数据挖掘的手段,比如SVM(支持向量机模型)、神经网络,集成学习等模型探索因子与股票收益之间的关系,进而建立多因子模型对股票未来收益进行预测。但上述算法在金融领域应用时存在两个主要问题:1.数据样本不足。虽然金融市场中存在着大量高低频数据可供研究,但是在模型训练过程中时真正有效的样本数据是非常有限的,如何高效利用有限数据构建出泛化误差较小的机器学习模型是值得研究的。2.金融市场是不断变化的,分别处于不同时间节点的训练样本和测试样本往往很难保持同分布,因此会导致机器学习模型的延伸性比较差。本文尝试引入迁移学习的思想与多因子选股模型相结合来处理上述问题,在TrAdaboost算法的基础上进行补充,通过构造辅助训练样本集和源训练样本集,从前者中学习知识并提取部分与源训练样本集分布相似的股票样本与源训练样本集一起重组为迁移学习量化选股模型的训练样本,从而规避常规机器学习模型中需要假设训练样本和测试样本相同分布的问题。本文设计了一个包含因子筛选和数据降维的因子库建立体系,同时给出了完整的迁移学习量化选股模型框架,通过2013年至2018年底的真实市场交易数据对该模型进行实证分析,将其结果与未使用迁移学习思想的Adaboost多因子选股模型进行对比,证明了本文研究的迁移学习多因子选股模型的有效性,在参数相同的条件下,合理设计辅助训练样本集和源训练样本集的采样方式可以提升传统机器学习模型的绩效。"
1574,基于大量因子的GBDT-SVM多层次选股模型研究,"在量化投资领域中,多因子选股模型凭借稳定性高、资金容纳量大等优势被A股市场的广大专业投资者接受和使用。但近年来,模型的同质化愈发严重,A股市场风格频繁变化,基于多因子模型的投资难以获取稳定的可观收益。当前,在人工智能方法广泛应用和计算机运算能力飞速发展的背景下,梳理多因子选股模型在应用中存在的问题,将大数据样本下的机器学习算法与多因子模型相结合,可以为优化多因子投资模型提供一种手段。为了提高多因子模型对股票超额收益的获取能力,本文使用机器学习技术,对多因子模型中因子选取进行优化,并对因子权重作动态调整,故提出了基于大量因子的GBDT-SVM多层次选股模型。本模型在经典多因子模型的基础上,先使用梯度提升决策树算法对经典选股因子构建特征组合;再将特征组合作为新的一批因子,使用支持向量机算法构建选股模型。之后,使用中国A股市场数据进行实证研究,并与经典多因子模型和机器学习改进模型进行比较。研究结果表明,GBDT-SVM多层次选股模型具有更高的股票分类准确性,在模拟交易测试中也表现出了良好的盈利能力。本文的研究成果主要包括两个方面。一方面,本文构建了大量基于高频交易数据的特殊经典因子,也验证了这些因子的有效性,为新的多因子模型的研究提供了一些更有效的初始经典因子。另一方面,本文提出的GBDT-SVM多层次选股模型,在理论上为多因子模型的优化提出了新的方案,并可应用于实际投资的策略研究中。"
1575,印刷体数学公式识别算法应用研究与系统研发,"随着人工智能技术和互联网的渗透,在线教育发展迅猛。在高等数学在线教育中,大量数学公式存在于教学文档和作业题目中。数学公式结构复杂,识别难度大,其识别效果还不理想。本文通过研究印刷体数学公式识别技术,将其应用于微积分学习平台。首先,本文通过分析印刷体数学公式特点,重构数学字符标准库。该标准库充分考虑了印刷体数学公式的表现形式,以及数学公式字号大小、粗细体、正斜体、各种字体类型等差异性,涵盖数字、字母、数学符号等115个字符类别,共计字符样本21850个。其次,通过数值实验的方式,比较分析并验证OCR识别法、模板匹配法、ML方法等字符识别方法,最终选择支持向量机(Support Vector Machines,SVM)算法进行公式识别,效果最佳。此外,进一步提取字符特征,提升公式识别精度,实验结果显示识别精度约97.7%,识别结果良好。然后,基于字符的位置特征,并结合公式分布特点,采用数学公式结构分析方法,实现数学公式识别。在数学公式识别算法研究的基础上,用Python+PyQt5+Pycharm开发了一套印刷体数学公式识别系统。该系统能实现常规数学公式的识别,以及完成常规的数学公式图片处理工作。最后,通过设计微积分学习平台,该平台可通过用户行为数据分析,结合推荐算法,基于学生提问的题目,实现智能推荐解题思路、学习方法等,提升平台用户体验度和用户学习效率。通过精准的公式识别算法,能实现教师学生的高效协同,教学工作的个性化和去中心化。"
1576,利用机器学习改进列生成算法求解多集装箱装载问题,"将各种尺寸数量的箱子全部装载到不同尺寸的集装箱中,并使得总运输成本最小的问题叫做成本最小化的多箱型多集装箱装载问题(MCLCMP)。包括多集装箱装载问题(MCLP)在内的许多组合优化问题都可以被描述为集合覆盖模型。由于其复杂性,决策过程往往分为两个阶段:第一阶段忽略子决策细节,粗略估计全局决策;第二阶段考虑所有细节,生成完整的方案。此类问题通常使用列生成(CG)技术进行求解,CG的有效性在很大程度上取决于定价子问题的解决效率。我们的CG策略是:1.对定价子问题进行松弛变换;2.训练机器学习模型以预测松弛变换与其真实解决方案之间的差异;3.根据预测将松弛变换转化为真实解决方案。每个企业的产品规格不同、运营数据具有独特性,而机器学习可以挖掘数据背后的信息,因此本文通过机器学习从累积的历史运营数据中提取有价值的信息,来提高CG对MCLP的有效性。为第一阶段的全局决策分配更多时间,使它能够更快速地锁定高质量的解空间,最终提高优化算法的整体性能。同时改进后的优化算法在应用于具体企业时能达到更高的效能,这是传统的优化算法无法做到的。"
1577,异构网络多尺度嵌入算法研究,"网络嵌入(图嵌入)算法的目标是把给定图结构中的节点映射到一个低维向量空间中,这些低维向量可以反映节点在图中的上下文信息。节点向量可作为传统机器学习算法的输入,使传统机器学习算法可以应用在图分析任务上。网络嵌入算法在推荐系统、用户画像等领域中有着广泛的应用。现有的网络嵌入算法大多只能利用节点周边的短距离局部上下文信息,而忽略了远距离全局结构和网络本身的层次结构信息,严重影响了在大规模复杂网络结构下的节点嵌入向量的效果。另一方面,现有的异构网络嵌入算法只能对静态的网络进行建模,在动态变化的网络结构上运行效率很低,难以直接应用于现实场景。针对上述问题,本文提出一种多层次异构网络动态嵌入算法。首先本文采用蚁群行走的方式探测网络中的层次结构,构造出图金字塔,得到每一层图结构的嵌入向量后,使用降维的方式把多层次特征融合到最终的节点嵌入向量中。同时本文还提出一种基于异构连接扩增的动态网络嵌入算法,先对异构网络中的静态子网进行连接扩增以减弱网络的稀疏性,再对动态子网中的节点进行增量式嵌入,使算法在动态网络上能取得较高的运行效率,提升算法在实际场景中的实用性。本文通过在公开图数据集上的大量实验,证明了上述算法在实际图分析任务中的优越性。此外,为了验证动态异构网络的增量式嵌入算法在实际场景中的应用效果,本文还构造了一个学者论文关联任务的应用场景,采集了相应的大规模异构网络数据集,并在实验结果中与现有的学术搜索引擎系统进行了对比,结果表明该算法可以取得不亚于商业系统所取得的效果。"
1578,光学扫描全息中的超分辨率成像,"光学扫描全息是一种单点扫描的特殊数字全息技术,它通过二维扫描将三维物体图像保存为二维图像。光学扫描全息技术作为一种特殊的数字全息技术,其具有传统数字全息技术的特点的同时也具有其不一样的地方。与其他数字全息技术相比,光学扫描全息具有分辨率高、时效性好的特点。然而,值得注意的是光学扫描全息的重建过程与其他数字全息技术一样面临着重重挑战,其中,光学扫描全息超分辨率成像中就存在自聚焦、重建、去噪等问题,本文通过采用时间反演技术、数字图像处理技术、深度学习技术解决自聚焦、重建、去噪问题。本文着重从理论分析、计算机仿真和实验验证等方面验证算法的可行性和优劣。有关光学扫描全息超分辨率成像的研究,本文主要从以下几个方面探讨:(1)从菲涅尔衍射原理、光瞳的光学传递函数出发推导光学扫描全息数学模型,分析了光学扫描全息重建面临的自聚焦和重建算法问题。同时,本文阐述了随机加密光学扫描全息技术中的去噪问题。(2)介绍基于时间反演多空间分解(TR-MUSIC)算法在光学扫描全息中的基本原理。通过MATLAB仿真实现光学扫描全息中单点定位,分析了多点定位面临的问题,并给出了一种去卷积的方法实现多点定位。通过MATLAB仿真实现基于TR-MUSIC的轴向定位,并分析了其分辨率、噪声、运算复杂度等特性。(3)介绍连通域算法的基本原理,MATLAB仿真实现了基于连通域算法的自聚焦与重建。然后,介绍凸优化重建与高次放大结合去噪的基本原理,并通过MATLAB仿真实现。(4)介绍神经网络的基本原理,提出了一种U型网络去除离焦噪声的算法,通过仿真实现了简单图像和复杂图像的去噪。然后,提出了一种深度学习结合二分法实现自聚焦的算法,并通过仿真实现。本文通过TR-MUSIC提高了光学扫描全息超分辨率成像中自聚焦问题的分辨率,通过深度学习结合二分法解决了深度学习自聚焦中泛化力低的问题,通过凸优化重建和深度学习的方法解决了现有去噪算法去噪效率低、不适用复杂物体的问题,同时,本文提出了一种利用连通域实现自聚焦和重建的方法,得到了无离焦噪声的重建图。"
1579,基于OpenCV的前方车辆识别与车距检测系统的设计与研究,"随着“互联网+”的时代的兴起,越来越多的企业开始注重将自己的产品与互联网信息技术相结合,对已有产品进行升级,并结合已有产品特性打造出新兴产品,智能网联汽车就是传统汽车产业在“互联网+”时代下的一个产物。对本车前方车辆的识别及距离检测是智能网联汽车研发和应用过程中必不可少的一个内容,是其发展的一个重要技术基础。本文研究设计了一种基于OpenCV的前方车辆识别及测距系统。该系统以配置好OpenCV的Visual Studio 2015作为程序开发环境,在载入摄像头采集的视频图像后,首先完成对视频图像的预处理,再导入训练好的车辆分类器来对视频图像中的车辆进行识别,然后结合车距检测算法,计算出本车与识别出的前方目标车辆之间的距离,并将识别结果和车距检测结果显示在屏幕上。最后实现系统的Android移植,通过Android客户端与云服务器的通讯将检测出的车距实时地传送给云服务器。本文完成了对训练车辆分类器所需正负样本的采集,研究设计了可以一次性对所有样本进行灰度化、归一化等预处理的算法流程;调用OpenCV机器学习相关函数完成了基于Haar特征的Adaboost级联分类器的训练与检测;搭建了车距的计算模型;研究设计了利用车辆分类器实现对摄像头采集的视频图像实时进行车辆识别并测距的算法流程,其中包括完成打开摄像头,读入视频图像,对视频图像的预处理,导入分类器识别,对识别到的前方车辆进行距离检测,将识别效果和距离计算结果显示出来等一系列编程;最后还实现了系统的Android移植,设计了能将Android端系统检测的车距发送到云服务器的数据通讯算法流程。为了验证本系统的最终效果,本文分别对该系统和移植到Android的系统进行了实车实验来进行功能验证,结果表明该系统和移植到Android的系统都有较好的车辆识别及车距检测效果,且Android端系统的通讯功能也能很好的实现。"
1580,睡眠分期算法研究,"睡眠分期是睡眠监护和睡眠研究过程中至关重要的一环。人工睡眠分期结果一致率低下,且是一个耗时耗力的繁琐过程,而基于睡眠电生理信号的自动睡眠分期能进行批量数据处理并得到一致的分期结果。相较于睡眠研究,便携式睡眠监护场景中要求在较少信号电极情况下得到较好的睡眠分期结果,以满足便携性和舒适性。本文基于生物医学信号研究资源网站PhysioNet(www.physionet.org)的SleepEDFx睡眠信号数据集训练了三个睡眠分期机器学习模型,提出的具有睡眠时期转换时间依赖性的睡眠分期模型能得到最好的分期性能。论文研究内容如下:1、依据睡眠专家知识提取了单通道睡眠脑电信号的时域特征、时频特征、非线性特征和复杂度特征,得到11维睡眠特征空间,并在此特征空间上训练了一个睡眠分期支持向量机模型,获得了74.49%分期准确率和61.99%的F1分数。2、通过对30秒睡眠时期判定时间的低尺度分解,训练了一个复合三层卷积层的卷积神经网络自动特征提取睡眠分期模型。本文利用设计好的卷积神经网络比较了不同睡眠信号组合对模型分期性能的影响,结果表明,由睡眠脑电、眼电和下颌肌电构成的组合信号训练的模型性能最佳,分期准确率为79.14%,F1分数为70.13%。另外,使用单通道脑电训练得到的睡眠分期卷积神经网络模型性能(准确率:76.53%,F1分数:66.34%)优于睡眠分期支持向量机模型,表明本文构建的卷积神经网络学习表示的特征是有效且与美国睡眠医学学会的睡眠评分手册描述的特征一致。3、利用睡眠分期卷积神经网络提取的特征向量,本文结合长短期记忆循环神经网络引入睡眠时期转换的时间依赖性,构建了具有时间依赖性的自动睡眠分期模型。使用脑电、眼电和下颌肌电训练的具有时间依赖性的睡眠分期模型获得了最好的泛化性能(分期准确率:85.56%,F1分数:77.61%),使用单通道脑电训练的具有时间依赖性的睡眠分期模型的准确率和F1分数分别为84.59%和75.09%,均达到了人工睡眠分期标准。基于单通道脑电的具有时间依赖性的睡眠分期模型能很好地应用于便携式睡眠监护场景。"
1581,基于HHT和机器学习的非平稳信号分析,"随着科学技术的发展,非平稳信号分析已成为许多工程领域的重要组成部分。时频分析方法是用于非平稳信号分析的常用方法。希尔伯特-黄变换(Hilbert-Huang Transform,HHT)作为一种全新的自适应的非平稳和非线性信号分析方法,相比于传统的时频分析方法拥有更加锐利的时频分辨率。HHT包含了两个关键部分:经验模态分解(Empirical Mode Decomposition,EMD)和希尔伯特谱分析(Hilbert Spectrum Analysis,HSA)。EMD能够自适应地将非平稳信号分解为有限数目的内部模态函数(Intrinsic Mode Functions,IMF),对IMF进行希尔伯特变换(Hilbert Transform,HT)就可以得到非平稳信号的时频分布。由于缺乏坚实的数学基础,EMD的实现仍然是经验性的,这导致HHT方法仍然存在一些问题,进而严重影响了其分析结果。本文主要对HHT中的端点效应和模态混叠问题进行研究,利用HHT及其改进方法对一类非平稳通信信号进行了分析。本文的主要研究内容如下:首先,利用HHT以及几种传统的时频分析方法对常见的非平稳信号进行了时频分析,结果表明HHT方法对于非平稳信号分析具有更加优异的时频分析性能。其次,针对HHT中存在的端点效应问题,阐明了端点效应的存在原因,总结了现有解决方法。重点介绍了极值镜像延拓法、基于支持向量回归的波形延拓法和基于极限学习机的波形延拓法。提出了一种基于极限学习机与极值镜像的延拓方法,综合正交性系数、相似系数以及模型训练时间等评价指标来看,该方法能够有效的抑制端点效应问题。再次,针对HHT中的模态混叠问题,阐明了模态混叠的产生原因,总结了现有解决方法。重点介绍了自适应噪声完备总体经验模态分解(Complete Ensemble Empirical Mode Decomposition With Adaptive Noise,CEEMDAN)、频移法以及掩膜信号法这三种解决模态混叠的方法;提出了一个掩膜信号法的实施原则,该实施原则能够指导研究人员更好的利用掩膜信号法。最后,利用HHT及其改进方法对一类非平稳通信信号进行了分析。结果表明,在无高斯白噪声的条件下,利用HHT方法能够准确的分析出信号中的时频特征;在有高斯白噪声条件下,HHT方法的分析性能减弱,采用CEEMDAN和HSA作为HHT的改进方法能对非平稳通信信号的频率信息进行有效的提取。"
1582,基于容器的负载预测模型与能耗优化调度策略研究,"随着近年来容器技术的不断发展,继IaaS、PaaS、SaaS之后,在云计算领域又出现了容器即服务(Container as a Service,CaaS)的运作模式。CaaS不仅更细化了资源划分的粒度,同时还进一步扩大了云计算的规模,但这也导致了云数据中心的能耗问题日益严重。容器负载与其产生的能耗之间有着密切联系,因此可以根据容器的负载状态来进行资源的动态配置和调度,从而优化系统的整体能耗。但由于云环境中容器负载状态变化频繁,从监控软件获得的负载值可能存在很大的滞后性,因此需要借助数学模型来预测容器的负载状态。除此之外,由于容器规模大,调度过程不仅涉及到容器本身还涉及到虚拟机,因此CaaS模式下的节能调度问题会更加复杂。综上,如何准确预测容器负载并能依据预测结果对容器进行有效资源配置和调度是当下亟待解决的问题。在这样的研究背景下,本文所做的主要工作有:(1)本文调研了在负载预测领域广泛使用的单值预测模型,并分析指出此类模型存在误差敏感、鲁棒性差等缺点,不利于资源配置和调度决策。为此,本文在传统区间预测模型的基础上,提出了一种基于趋势感知的区间预测模型(简称SAC-GPSO-SVM)。该模型通过频谱特征和自相关系数分析来对不同趋势的负载进行分类(SAC),并结合SVM方法进行针对性的预测。为了提升预测效果,模型还引入了带梯度信息的粒子群算法(GPSO)来优化SVM中的超参数。在公开数据集上的实验结果表明,SAC-GPSOSVM能在提升预测区间对真值覆盖率的同时有效窄化区间宽度。(2)为保证服务质量且有效降低云数据中心能耗,本文提出了基于动态伸缩的容器调度策略(简称DSCS)。该策略首先会根据容器伸缩规则以及SAC-GPSO-SVM模型对容器负载的预测结果,有针对性地增加或减少容器副本,尽可能以最小容器数量保证服务正常运行。接着,通过策略中基于负载相关性分析的容器选择算法(MCor-ML)和主机选择算法(CorHS),来有效地放置新增容器,并以最小代价实现过载/欠载主机上容器的迁移/合并过程。最后,策略会根据系统状态,销毁没有容器运行的虚拟机并使闲置主机进入休眠,从而减少资源浪费、降低能耗。在扩展了容器仿真功能的CloudSim平台上的实验结果表明:与其他策略相比,在保证云服务质量的同时(SLA违反率小于5%),DSCS能达到更优的节能效果(节能效果提升7.41%)。"
1583,基于重采样的代价敏感学习在网络贷款用户分类中的应用,"网络贷款数据集具有申请量大而获批少的特征,是典型的不平衡数据集。利用机器学习方法,预先筛选出可能给予贷款的用户,可大大减少后续人工审核的工作量,加快贷款用户的响应速度,具有较好的应用价值。对不平衡数据集的研究集中在数据层面和算法层面,本文在数据层面对随机平衡采样算法进行改进,在算法层面提出改进的代价敏感决策树算法,最后对算法层面和数据层面的改进算法进行融合,提出以最小误分类总代价为目标的新算法,并将提出的方法用于贷款用户分类研究中,论文的主要工作和贡献如下:1.不平衡数据集的重采样算法:本文在随机平衡采样算法的基础上,提出改进的随机平衡采样算法,该算法先根据样本点的位置,将所有样本点分为三类:安全点、边界点和噪声点,之后移除噪声点和边界点中的多数类样本,这样不同类样本间的分类边界更清晰,并针对不同类型的样本采用不同的采样方式;再同时对多数类样本进行欠采样、少数类样本进行过采样,使样本集中各类别样本数目基本一致。在网络贷款分类中,与随机平衡采样算法相比,该算法提高了少数类样本的分类准确率。2.不平衡数据集的代价敏感学习算法:本文在代价敏感决策树敏感函数的计算中加入类分布,以减弱正负类样本数量差异过大对误分类总代价的影响,构建改进的代价敏感决策树。依此作为基分类器,训练得到多个模型,每个模型对原始数据集进行预测,以期望误分类总代价最小为准则对原始数据集进行重标记,对重标记的数据集进行训练,得到新模型,同时将新模型与分类准确率较高的基分类器进行集成,得到最终的分类器。在网络贷款分类中,与代价敏感决策树算法相比,该算法可以提高整体的分类正确率,具有更强的泛化能力。3.对不平衡数据集的研究大多是纯重采样或者纯代价敏感学习,本文基于类别不平衡和误分代价不等往往同时发生的事实,尝试将重构数据集和代价敏感学习相融合,先采用重采样方法降低数据集的不平衡程度,再采用代价敏感学习算法构建模型。在网络贷款分类中,与纯代价敏感学习算法相比,该算法的分类正确率得到了提升。"
1584,三维人体模型及其强化学习训练,"在虚拟现实的应用中,往往对真实性和沉浸感有着非常高的要求,用户在希望虚拟场景中的模型质量、场景外观、物理仿真等尽可能地接近现实场景的同时,也希望交互对象的行为和决策具有较高的真实性和合理性。本文结合人体建模技术和强化学习技术设计了一个虚拟乒乓球角色,使之与用户在HTC VIVE平台上进行乒乓球对打交互。对于一个虚拟乒乓球交互系统而言,沉浸感和真实性主要体现在两方面:其一,虚拟场景的真实程度,即乒乓球场、球桌、球拍等实物以及虚拟角色的几何建模、物理仿真与全局渲染要尽可能地逼真;其次,虚拟角色的自我感知和自主决策能力,在这里体现为以合理的姿势与策略回击从用户方打过来的乒乓球。本文将着重从虚拟角色个性化建模及其行为决策的智能化来提高虚拟现实应用的沉浸感。在建模方面,实现了一个由刚性配准、特征点引导变形和稠密配准三部分组成的三维人体扫描数据拟合系统。在特征点引导变形阶段,实现了变形图变形和SMPL参数化模型拟合变形两种方案。后者让我们能够利用SMPL参数化模型来表达个性化三维人体数据,从而为乒乓求交互系统利用逆向运动学技术驱动个性化虚拟角色生成击球动作打下基础。乒乓球、球场、球拍等虚拟场景则采用Unity 3D进行几何建模与物理仿真。在虚拟角色的自主决策方面,我们利用强化学习方法对球拍的击球策略进行训练,使之能产生一个有效的击球轨迹,然后以球拍位置对虚拟球员的右手腕关节进行约束,利用逆向运动学与强化学习相结合的人体姿态估计算法解算出球拍击球时虚拟球手的击球动作,从而得到一个能用合理姿态进行击球的虚拟球手。由于场景外观真实感强、虚拟球手击球动作有一定的智能性,使得所构建的虚拟乒乓球交互系统有较好的沉浸感。针对所提出的方法和策略,我们都进行了较详细的实验验证与分析。结果表明,本文提出的人体建模方法能忠实地还原扫描模型的几何细节,而本文设计的虚拟乒乓球员,则能准确地完成击球任务。"
1585,基于端对端方法的任务型对话系统设计与实现,"随着人工智能的发展,人机对话系统成为了学术研究的热点。广泛应用于任务型对话系统的方法是基于模块化的思想,将系统划分为自然语言理解、对话管理以及自然语言生成三个子模块。这种分而治之的方式保证了每个子任务独立建模,简单易于实现,但同时也存在三个问题:一是模块之间的依赖性强,数据的更新会带动所有模块进行调整以保证系统的全局优化;二是每个模块的训练需要大量独立的标签数据;三是子模块的设计跟特定领域相关,导致模型的领域移植性差。近年来,大量研究尝试使用基于端到端的对话框架来解决上述问题,然而现有的端到端模型多集中于非面向任务的对话系统,缺少对自然语言理解的建模及领域知识的应用。针对上述问题,本论文设计与实现了一个基于端对端方法的任务型对话系统。具体来说,本文的主要研究内容包括:(1)在自然语言理解的意图识别任务上,分别介绍了基于CNN、RNN以及两者混合的意图识别模型,其中重点提出了一种带有自注意力机制(self attention)的RNN模型。最后,实验结果对比表明带有加性自注意力的BiLSTM模型表现效果最好。(2)在自然语言理解的槽位填充任务上,分别介绍了基于统计机器学习、基于神经网络以及基于两者相结合的序列标注模型,重点阐述了利用神经网络提取输入文本的状态特征后通过CRF获取全局最优槽位标签序列的过程。最后,实验结果对比表明基于BiLSTM_CRF的模型表现效果最好。(3)提出了一种基于端对端的任务型对话系统架构,包括文本的特征表示、命名实体识别和状态跟踪、基于RNN的对话策略网络、对话动作模板和领域知识库等模块。在此基础上提出了两种不同的方式引入对自然语言理解的建模:第一种方式通过引入(1)和(2)中的意图识别和槽位填充模型,将预训练的自然语言理解模块加入到文本的特征表示中;第二种方式通过对自然语言理解和对话管理进行联合建模,充分探索了多任务之间的共享知识。实验结果表明上述两种模型的表现均优于前人工作中已发表的端到端模型。"
1586,基于种子生长及边界约束的弱监督图像语义分割算法研究,"人工智能越来越贴近人们的日常生活,图像语义分割作为计算机视觉的基础任务,被广泛应用于自动驾驶、机器人视觉感知、服装分类及地质分析等领域。传统深度学习下图像语义分割多采用全监督模式,而逐像素标记训练数据的成本十分高昂,因而研究者们将目光转向了被认为更具有潜在应用价值的弱监督图像语义分割算法研究。现有弱监督图像语义分割算法中,以基于种子生长及边界约束原则的分割思路较为直观,故本文以此为基准,对SEC(seed expand and constraint)模型的各个阶段做出优化工作如下。(1)提出在SEC模型的种子生长过程中引入多种先验约束包括抑制约束、前景约束及背景约束,构建MPCSEC(multiple priori constraint SEC)模型,以改善目标物体种子生长过度或种子生长不足的问题,使种子的扩张更为合理。(2)提出增加图像预处理层,通过图像自适应对比度增强、图像仿射变换的预处理操作,优化训练数据的质量和数量,使得模型的学习聚焦于目标物体的显性区分特征,同时丰富模型对数据学习的角度,以改善SEC模型初始种子提取存在的间断、稀疏问题。(3)将(1)和(2)的优化工作整合,构建更为强大的MSOSEC(multiple stage optimization SEC)模型,实现对SEC的进一步整体优化。(4)对MSOSEC模型进行裁剪及微调处理,获得更为精简且高效的弱监督图像语义分割模型,满足算法未来落地于移动化、实时化应用的需求。此外,本文通过实验验证了各项优化工作的有效性,实验结果显示基于本文最终整合优化的MSOSEC模型,语义分割的准确率相较现有SEC模型提升3.8%。而裁剪优化处理后,MSOSEC模型的整体精度损失为0.3%,同时参数量下降16.5%,单张图片的平均分割时长减少25%。本文算法基于图像级类标签,实现了图像的语义分割,且宏观层面上分割的结果表现也更为清晰、规整。"
1587,基于语义权重和注意力的实体关系抽取研究,"实体关系抽取是信息抽取的一个子任务,能够判别给定文本中实体对之间存在的关系,在自然语言处理领域有着非常重要的地位。完全依赖人工建立实体关系抽取语料费时费力,而利用远程监督可以便捷地建立大型的语料,但是远程监督无法避免的标注错误带来了严重的数据噪声。为了解决这一问题,很多方法应运而生,其中表现最突出的就是基于多示例学习的注意力网络模型。但是目前的大多数方法将所有的实体关系独立看待,无法利用实体关系的内部联系,以及实体关系定义中丰富的语义信息,严重限制了模型的整体性能,特别是对其中缺乏训练数据的长尾实体关系的抽取性能。本文针对当前注意力机制在远程监督实体关系抽取任务的应用中,包级别的注意力计算中的查询向量中缺乏实体关系的层级结构信息与语义信息,导致模型无法学习到合理的注意力权重的问题,提出了实体关系注意力网络(Entity Relation Attention Networks,ERAN)模型。ERAN模型使用双向GRU(Gated Recurrent Unit,GRU)编码实体关系定义生成实体关系的上下文表示,使用自定义的点积注意力机制计算注意力分数,能够充分利用GRU编码得到的所有隐藏状态,从而使得模型能够合理地分配注意力权重。此外,为了强化模型描述实体与文本上下文的相互关系的能力,ERAN模型还将依存树中实体词和单词之间最短路径的长度定义为语义距离,以此为基础使用语义权重对模型的输入向量进行加权处理,生成与实体关系更相关的输入向量,帮助模型减小与实体关系无关的噪声文本片段的影响,进一步提升模型的实体关系抽取效果。实验结果表明,ERAN模型在广为使用的纽约时报远程监督实体关系抽取数据集上取得了当前最好的抽取效果,而且ERAN模型的注意力机制显著提升了模型对长尾实体关系的抽取效果。使用PR曲线的面积AUC(Area Under Curve,AUC)作为评价指标,ERAN模型的AUC达到了0.460,相比NLP-progress中记录的最佳模型RESIDE的AUC值0.416提高了0.044,相比同样采用实体关系定义作为外部监督的PCNN+HATT模型的AUC值0.423提高了0.037。"
1588,基于不平衡约束及联合损失的深度聚类研究,"在大数据时代,聚类方法作为机器学习与数据挖掘中最重要的方法之一,已经在各行各业都广泛应用。其中,半监督聚类通过增加少量的辅助监督信息,既只需要付出少量的人工成本,同时又可以获得相对高质量的聚类效果。因此,对半监督聚类的研究能够帮助各个行业在海量多维数据中快速分析数据,具有重要的应用价值和学术价值。半监督聚类的监督信息主要分为类标签和成对约束信息。本文以基于成对约束信息的半监督聚类作为研究的重点,提出了联合损失的深度聚类模型。本文的主要工作包括:1.本文提出一种联合重构损失、成对约束损失和聚类损失的深度聚类网络。该深度聚类网络采用深度自编码器网络的重构损失,确保网络的隐藏层可以学习样本的数据特征;通过构建成对约束损失,使得隐藏向量可以体现样本相似性,即相同类别的样本距离更近,不同类别的样本聚类更远;通过引入聚类损失,使得神经网络进一步学习到样本之间的相似性,从而实现良好的聚类效果。在多个实验上表明,本文提出的聚类模型具有更好的效果。2.本文提出一种基于动态代价敏感的成对约束损失。针对成对约束标签中存在类别不平衡的情况,本文采用动态学习的放大少数类样本权重的代价敏感法。本文提出的动态代价敏感的成对约束损失构建的隐藏向量更加体现样本相似性,实验表明其具有更好的聚类效果。"
1589,提升小类准确度的代价敏感局部泛化误差模型研究,"不平衡数据集主要是可以分为类间的不平衡和类内不平衡。类间不平衡指的是不同类别之间的样本数目差别较大;类内不平衡是指在某一个类别的内部,不同部分的数据分布成不同的簇(Cluster),不同的簇之间样本数目差距较大的情况。因为大多数的传统的机器学习方法默认使用的数据样本相互之间是平等的,并且假设其数据量是相对平衡的,所以数据集不平衡问题的最根本难点是样本的不平衡性往往会显著地影响大多数机器学习方法的性能和学习的结果。当学习不平衡数据集的时候,特别是当数据量非常小,在处理类间不平衡的同时,也可能有类内的不平衡的情况发生,在这样的情况下,传统的机器学习方法可能难以通过简单的学习泛化到未知的样本空间上。在二类问题中,具体的表现是分类器趋向于将样本数目较少(小类)的样本判定成样本数目较多(大类)的样本。本文提出通过一种通过最小化基于代价敏感的局部泛化误差模型(c-LGEM,costsensitive Localized Generalization Error Model)的目标函数的方法来优化神经网络的训练,在保留代价敏感方法在效率上的优势的同时,提升分类器对小类样本的泛化能力。更详细地说,代价敏感局部泛化误差模型被用于最小化小类的样本的泛化误差,但是同时对大类样本仅最小化其训练误差来提升分类器对于小类样本分类的准确率。除此之外,在计算小类样本的代价敏感局部泛化误差之前,使用k-NN先行判断哪些样本点出现在边界上,并通过近邻样本中大类样本的个数用于确定在代价敏感局部泛化误差模型中生成的模拟点的数目,以此为根据优化代价敏感局部泛化误差的计算过程。实验结果囊括了10个UCI数据集和包括本文研究的方法在内的5种方法,并使用G-mean(geometric mean)以及AUC对c-LGEM从整体上进行比较。同时记录了小类样本分类的准确率用于说明本文研究的方法在提升小类样本的准确度上的优势。更进一步探讨了本文研究的代价敏感局部泛化误差模型的作用。"
1590,面向高维数据的自适应半监督聚类集成方法的研究,"随着互联网的飞速发展,数据的维度和数量呈爆炸式增长,高维数据的聚类分析问题显得愈发重要。传统的聚类分析方法不能有效地对高维数据聚类,因此研究者提出半监督聚类集成的方法来解决此类问题。半监督聚类集成将半监督学习和集成学习应用在聚类分析任务中,能够显著地提升高维数据聚类结果的准确性、稳定性和鲁棒性。然而,当前的半监督聚类集成方法存在一些缺点,例如:1)没有专门设计有效的方法处理高维数据问题;2)不能充分地利用先验知识,尤其是成对约束信息;3)在聚类集成生成过程中,随机性太强,没有采用自适应的方法来优化生成过程;4)在聚类集成一致性函数过程中,考虑了所有的聚类成员的结果,即使有些聚类成员的结果质量很差。为解决这些缺点,本文提出了一种双重自适应的半监督聚类集成方法(DASSCE)。DASSCE主要贡献有:1)提出了一种基于bagging约束的子空间生成方法,该方法使用bagging约束产生一组约束子集,并使用不同的约束子集指导子空间生成。2)设计了一种自适应的约束聚类集成选择方法,该方法能够有效地移除聚类结果中的冗余和噪音划分结果。3)采取自适应的子空间集合优化方法,从而获得了更好的聚类效果。为评测DASSCE的有效性,本文采用来自不同领域的、不同特点的、公开的高维数据集并设计了详尽的实验。实验结果表明:在高维数据聚类问题上,由于采取了本文提出的三个创新点,DASSCE获得了比其他半监督聚类方法更好的聚类效果。"
1591,企业级赛事管理系统的研究与实现,"为了加大精神文明建设,各个领域不同类型的赛事相继举办。调研发现,多数赛事的举办是在线下进行,信息采集和赛事举办过程耗时费力,赛事资讯反馈不及时。现有的赛事管理系统,大多数是针对某个特定领域来设计的,很少有竞赛管理系统能管理多种类型的赛事,而且很少有赛事管理系统为赛事评分过程提供评分辅助。基于上述缘由,本文对各类赛事流程进行研究,分析赛事举办过程存在的共性,设计并实现了一个赛事管理系统,该系统能管理多种类型的赛事。该系统的文件存储采用第三方云平台存储解决方案,将系统文件存储到企业级云存储平台。该系统从用户权限作用范围,将用户角色划分为系统范围角色、大赛范围角色。对于赛事评分过程,设计辅助评分模块。对程序题辅助评分进行研究,现有程序题辅助评分的静态分析方法,大多数需要程序参考答案来支撑,参考答案的选取对评分结果有很大的影响。出于这个原因,本文将机器学习方法应用于程序题辅助评分模块,以消除使用相似度比对的静态分析方法对程序参考答案的依赖。采用机器学习进行程序题辅助评分,有历史评分数据的程序题采用分类算法实现,没有历史评分数据的程序题采用聚类算法实现,类别对应程序题的评分等级。关键问题在于将程序表示为特征向量后能表示原程序的词法和语义特性。将程序开发过程分析的结果作为特征提取的依据,提取程序基本特性、控制特性和表达式特性,利用TF-IDF和向量空间模型技术对获取的程序特性进行向量化处理。使用不同的程序特征向量去训练SVM模型和kNN模型,再对训练好的模型进行测试。实验结果表明,在kNN模型中,加入表达式特性的程序题特征向量,比没有加入此特性的特征向量的测试精度高,且整体精度高于SVM模型,平均精度达到86.0%。经本文测试和2个单位的部署来看,其中一个单位连续两届赛事使用本文的赛事管理系统,本文设计实现的赛事管理系统在赛事管理过程中起到一定作用。"
1592,基于异构信息网络和细粒度特征的学者消歧方法研究,"学术资源共享使得研究者们对公开学术资源的依赖日臻紧密。但资源信息中重名现象的普遍性以及因文化差异导致的记录方式的不一致性,使得数据库中存在大量同名学者。姓名歧义问题已成为学术资源检索的一大阻碍。现有的学者姓名消歧解决方案中存在以下问题:1)有效信息利用不充分。在表示学习中因未充分考虑期刊等特征,以及作者与期刊等关系类型而导致表示模型单一,不足以全面刻画待消歧实体;2)同构算法不能有效表示异构特征。文献的引用、著作等关系以及发表期刊、摘要等属性之间存在差异,现有同构算法不能准确提取文献的异构特征;3)容错能力差。许多模型没有考虑特征缺失的情况,在现实场景中难以直接应用。针对这些问题,本文基于异构信息网络和细粒度特征提出一系列学者姓名消歧方法,包括:(1)融合多类特征关系的学者消歧算法(MFRAD)。在学者消歧算法常用的著作和合作关系基础上,引入引用关系、所属单位、文献摘要等信息;构建多个异构信息网络,将多种结构信息和文本信息相融合以全面提取文献特征;并设计可扩展的基于成对约束的损失函数表征网络信息,使得模型具备对不同数据集的适配性。(2)本文提出一种异构关系感知的网络表示模型(HRANE),解决单一模型的局限性。本文分析了文献特征对姓名消歧的影响程度以及关系类型的差异性,分别构建不同强度的异构关系网络,共同约束文献特征的学习,以减小因强特征缺失而生成的不完备网络对消歧效果的影响。(3)本文提出一种结合异构关系感知和特征增强的网络表示模型(HRFENE),更有效地利用弱特征。HRFENE保留合作、引用和著作等强特征网络和期刊等较强特征网络,将弱特征和较强特征作为强特征网络中的节点属性,迭代学习网络结构信息和节点属性信息以更好的表征待消歧实体。并对该模型的复杂度进行了分析。(4)在公开数据集上验证本文网络表示模型的有效性。实验表明本文的HRFENE模型与对比模型中的最优的模型相比,在Aminer和DBLP数据集上,综合评价指标(Macro-F1)值分别提升了19.27%和10.96%,对单个姓名的消歧结果最高提升了38.71%。基于上述模型,本文还构建了一套半自动化学者姓名消歧框架,通过对聚类算法和人工反馈环节进行优化,能高效准确地进行学者姓名消歧。"
1593,Paraxle：一种面向大数据和科学计算的高性能领域特定语言,"在大数据时代,面向大数据、科学计算、人工智能的算法和应用不仅需要强大的计算机算力作为基础,还需要高效且易于使用的编程模型作为硬件资源与编程者交互的媒介。目前,面向大数据和科学计算等领域的编程框架往往较为复杂,对于不具备计算机专业知识的使用者是难以上手的,不利于交叉学科的持续蓬勃发展。领域特定语言是专注于特定应用领域的计算机编程语言,具有语法简洁、表达性强等特点。Axle是面向科学计算的领域特定语言,提供了大数据、科学计算的一系列基本功能。基于大数据时代对更优编程模型的内在需求,本文提出在Axle的基础上进一步扩展其功能,研究面向大数据和科学计算领域的高性能领域特定语言――Paraxle。Paraxle对Axle进行了多方面的扩展。针对Axle中部分可并行化的功能,Paraxle实现了这些功能的并行化,提高了执行效率。由于Axle仅提供了少数大数据方面的算法,Paraxle在回归、分类、聚类等方面进行了扩充,增加了多个算法的实现。Axle不具备异构计算的功能,然而在大数据时代,异构并行计算有着重要作用,基于此Paraxle将OpenCL与Axle相结合,实现了面向异构计算的线性代数、模拟等功能,同时将上述实现封装成易于使用的编程接口,使得不具备OpenCL背景知识的用户也能轻易获取到异构计算带来的加速。此外,Paraxle基于Akka实现了部分算法的并行化,同时为基于Akka的集群计算提供了方便的编程接口。本文基于Paraxle实现了高斯过程回归算法并且与高斯过程回归的伪代码进行对比,充分反映了Paraxle编程的简洁性和直观性。本文的实验从可用性和性能两方面对Paraxle进行了仔细深入的测试与分析,实验结果表明Paraxle对Axle的扩展达到了预期效果。相比于Axle,Paraxle具备了异构计算的功能,并且具备在更多大数据场景中应用的潜力。此外,由于Paraxle是基于Scala的嵌入式领域特定语言,Paraxle强大的类型系统为今后的进一步扩展优化提供了广阔的空间。"
1594,基于深度神经网络的中文情感分析研究,"21世纪以来,伴随着互联网技术的发展,特别是移动互联网的飞速发展,各类网络应用快速普及,人们越来越受益于网络所带来的便捷服务。互联网用户数爆发式增长,微信、QQ、推特、微博等社交媒体用户数数以亿计。数据显示,新浪微博2018年月活用户量已经达到4.62亿人次。人们通过微博、微信朋友圈等发表自己的心情,以及对于各类事件的观点、看法等,这些数据信息能够很直观的反映出社会舆论情况。文本情感分析,即对文本数据所表达的情感观点(喜、怒、哀、乐、积极、消极等)进行发掘。有效的利用网络上的大量用户观点信息,通过情感分析方法,发掘用户对特定问题或产品所表达的主观情感和所持有的观点,具有重大的研究意义。本文拟基于深度神经网络技术,通过分析中文的特点,基于卷积神经网络和循环神经网络模型等提出了有效的中文情感分析方法。具体的,本文主要取得了如下研究成果:1)针对中文网络评论文本的情感极性分析问题,本文提出了基于词嵌入的双向长短时记忆循环网络的情感分类模型textEBRNN,该模型首先通过词嵌入技术训练大量中文语料,进行中文文本的词向量表征,然后通过双向长短时记忆网络进行进一步情感特征提取,最后通过分类网络建立二分类模型进行情感分类。通过对比实验分析,相对于支持向量机等传统的机器学习方法以及textCNN和单向长短时记忆网络等模型,该方法取得了更高的分类准确率,证明了该方法的有效性。2)针对中文网络评论文本的情感极性分析问题,本文进一步提出了带注意力机制的双向长短时记忆网络模型,该模型在原有网络模型的基础上,充分考虑了序列中各特征的权重分布,进一步提升了模型的准确率,证明了此模型的有效性。3)针对中文微博的情绪分析问题,设计实现了使用卷积神经网络与双向长短时记忆网络结合的深度情绪多分类融合模型以及带注意力机制的融合模型,融合模型通过对比长短时记忆网络模型和卷积神经网络模型以及双向长短时记忆网络模型,取得了更好的多分类效果,以此证明了两种网络的融合模型在中文微博情绪多分类问题上的有效性。4)本论文进行了神经语言模型预训练词向量的研究,并在实验中对比了多组预训练词向量与非预训练词向量的网络模型,证明了神经语言模型提取浅层文本特征的有效性,在文本分析问题中神经语言模型能够较好的提取浅层文本特征。"
1595,基于深度学习理论的中文文本分类技术研究,"文本分类是信息挖掘的关键技术之一,在新闻分类、情感类别分析和舆情监督中都有广泛的应用。传统的基于词袋模型和向量空间模型的文本表示方法存在特征提取能力不足和特征信息损失大的问题,而在面对较复杂的文本结构以及多分类、数据不均衡等问题时,这些基于传统的统计学习和机器学习的分类算法的分类性能和模型泛化能力都将受到限制。本文主要在文本的表示方法和深度学习模型两方面研究中文文本的分类技术,将中文文本表示方法和优秀的深度学习算法相结合,在文本分类任务中实现理想的分类效果。本文的研究工作包含以下几个方面:1.基于字符级卷积神经网络的中文文本分类研究。针对中文文本中的多分类问题,提出一种基于字符级文本表示和卷积神经网络的分类方法。首先基于该任务构建了规模达到575000的汉字字符数据集及其对应的三种拼音格式数据集。对于汉字字符数据集,以汉字字符和标点符号构建字符字典;对于三种拼音格式的数据集,以拼音字母、数字以及标点符号分别构建字符字典。然后基于四种字符字典,分别建立相应的字符级文本表示作为模型的输入。最后在汉字字符及其对应的三种拼音格式数据集上进行模型的训练测试。实验结果表明,模型在汉字字符数据集上的性能要优于其对应的拼音格式数据集。此外,在相同数据集上将本文构造的模型与前人使用的模型进行了实验对比,结果显示合适的字符字典和卷积神经网络超参数在中文文本分类任务中起着重要作用。2.基于注意力机制和双向独立循环神经网络的中文情感类别分析。针对作为文本分类领域细分方向的情感分析需要提取丰富的语义特征的问题,提出一种基于词向量、注意力机制和双向独立循环神经网络的分类方法。首先对原始的中文文本去除标点符号和特殊符号,利用分词工具进行中文分词,采用Skip-Gram模型和维基中文语料库对分词后的文本进行词向量训练。然后将文本中各词用其对应的词向量表示,把代表各文本的词向量序列作为双向独立循环神经网络的输入,提取文本的语义特征。最后引入注意力机制,对那些能重点表现情感的词赋予更高的权重,使最终形成的表示文本的特征向量既包含语义信息又包含各关键词的权重信息。在相同的数据集上,将本文设计的模型和LSTM、双向LSTM、GRU以及深度IndRNN进行对实验对比,结果表明本文所设计的模型相比于其它模型在情感类别分析任务中获得了更高的准确率和F1值,说明能多层堆叠IndRNN和具有注意力机制的模型能够提取更加全面而丰富的语义信息,使模型获得更优秀的性能。3.最后结合字符级卷积神经网络和具有注意力机制的双向独立循环神经网络模型,设计了一个混合文本分类系统。"
1596,面向领域的实体识别与关系抽取设计与实现,"随着互联网的不断发展,网络数据的激增,互联网中的数据包含的信息也开始爆炸式的增长。如何快捷准确的从海量数据中抽取知识,并将提取的知识应用到各个领域成为当下研究的热点。目前对于英文隐含关系的抽取和实体识别有很多研究成果,但中文的研究却十分欠缺。为此,本文针对中文研究设计了命名实体识别和关系抽取的模型。传统基于特征的方法较为成熟,且提升空间有限,为了进一步提升模型的自动化和性能,本文着重研究了基于统计机器学习和基于深度学习的命名实体识别模型和关系抽取模型。本文模型以先进的词向量技术作为基础,以传统机器学习和深度学习的理论为指导,分析、训练、比较了模型的表现效果。本文主要工作包括如下几个方面:1.传统层叠马尔可夫的命名实体识别需要人工总结实体领域命名实体的构成规律。本文结合词向量技术,让模型学习命名实体的构成规律,增加算法的自动化程度,减少算法对先验知识的依赖,使该算法有更为通用的使用场景,提高其跨领域的使用。2.在关系抽取任务中,结合多种的词向量、深度学习理论构建模型。使用transformer,解决一词多义问题。并使用绝对位置嵌入和相对位置嵌入解决网络对语序信息的捕捉。3.构建了文本分析处理系统,系统集成多种自然语言处理相关模型。系统以低耦合强内聚等软件设计方法为依据,结合54种算法、存储和读取处理的模块。实现的文本的读取,预处理,信息抽取,抽取知识存储以及知识的查询与展示功能。"
1597,基于半监督学习的目标识别技术研究,"应用层协议识别技术作为网络监控的基本技术,一直以来在网络管理、安全监控、用户体验改善等领域发挥着巨大的作用,但目前也面临着许多问题。首先,加密协议的日渐增多,导致传统基于端口和应用层载荷分析的方法已不再适用;其次,应用层协议种类数量增长迅速,基于载荷分析的方法需要不断更新特征库,特征库容量的迅猛增长给特征匹配算法的时效性带来了严峻挑战。将机器学习方法引入到应用层协议识别中可以大大提高识别系统效能。本文基于半监督学习方法研究应用层协议识别,主要研究内容和成果如下:(1)通过对生成式方法、半监督支持向量机(Semi-Supervision Support Vector Machine,S3VM)和图半监督算法等进行分析,相较于这些半监督学习算法,TriTraining和Co-Forest利用了集成学习的思想,避免了诸如模型假设、损失函数非凸等问题,算法实现更为简单有效。本文将Tri-Training和Co-Forest这两种基于分歧的半监督学习算法应用于应用层协议识别中,实验表明相较于Tri-Training,CoForest具有更高的协议分类准确率。(2)特征选择是协议识别中的重要模块,本文在分析Relief和包裹式特征选择算法优缺点的基础上,提出了基于Relief统计量的包裹式特征选择算法,该算法结合了Relief算法高效率和包裹式算法高准确率的优点。实验表明,在本文构造的实验数据集上,相比于Relief特征选择算法,本文提出的方法对协议识别的准确率平均提高了约1%。(3)针对网络流数据不平衡的问题,对基于Relief统计量的包裹式特征选择算法做了进一步改进,提出了基于加权Relief统计量的包裹式特征选择算法,该算法主要通过对Relief统计量的加权处理和对特征子集评价函数的更改来实现。实验证明,相较于基于Relief统计量的包裹式特征选择算法,该算法选择出的特征子集更有利于网络流中少数类的识别,如P2P、DATABASE和MULTIMEDIA等,它们的查全率得到了不同程度的提高,同时多数类应用层协议如WWW、MAIL对应的查准率也得到了不同程度的提高。"
1598,基于集成学习与半监督学习的网络入侵检测方法的研究,"作为保护网络安全的一项重要组成部分,网络入侵检测系统长期以来受到较高的重视。近年来,随着人工智能的普及,许多基于机器学习的技术被应用于网络入侵检测系统,并依赖于数据构建检测模型。这种数据驱动的方法虽然能够大幅度地减少人工识别的代价,却也存在着一些的问题。首先是原始数据质量参差不齐,网络入侵检测运用的数据大部分是网络流量数据,而流量数据的数量是巨大的,其中会存在着大量冗余及噪声数据,而数据特征中也存在着部分不必要的内容,这些部分极大地影响了检测模型的精度。其次,在构建检测模型时,由于流量数据中缺乏攻击行为,数据分布会严重不平衡,造成训练模型对攻击行为缺乏认知,泛化能力较弱,检测性能低下等问题。再次,大部分基于机器学习的检测模型采用了无监督学习或者有监督学习的方法构建模型,仅仅采用无监督学习方法,由于缺乏标签数据的引导,会造成模型的性能较差,准确率低,误报率高等问题。而仅仅采用有监督学习的方法,检测模型会依赖于标签数据,使其缺乏对新型攻击的认知,并且当标签数据匮乏时,会严重影响有监督学习方法的性能。针对于上述提出的问题,本文首先提出一种针对流量数据的处理办法,该数据处理方法中运用了PCA算法进行数据压缩,采用聚类算法进行数据采样,从而改善了流量数据冗余的状况,去除噪声数据,加速后续模型的训练。其次,本文提出了一种基于宽度学习的集成模型――BLET(Broaden Learning-based Ensemble Tree),采用了带权重决策树作为基分类器,解决数据不平衡问题,并通过宽度学习方法进行集成,提高模型的泛化能力。之后,本文进一步提出了一种半监督学习式的学习算法――FSSLT(Fuzziness-based Semi-Supervised Learning Tree),解决由于单纯采用有监督学习或无监督学习带来的检测缺陷,以及标签数据稀少的问题。最后,通过实验进行综合对比,提出的算法能够带来良好的检测效果,并且能够优于当前较新的入侵检测技术。"
1599,基于特征分析的互联网消费金融风控研究,"2013年底,党的十八届三中全会将“发展普惠金融”确立为国家战略。随后2015底发布推进普惠金融发展规划,而互联网消费金融作为普惠金融的先锋,发展迅猛,其中持牌类消费金融公司、P2P借贷公司、以及电商平台的电商金融占据了消费金融领域的一大半市场。一方面,互联网消费金融打破了传统银行的壁垒,使得借贷者能够在线上直接实现融资,这种创新型金融模式给我国金融改革带来新的机遇,为我国的经济转型、消费升级注入了新的活力。而另一方面,互联网消费金融的负面新闻频频出现,其风控能力备受质疑,因此如何做好风控、形成健康的盈利模式将是互联网消费金融面临的首要问题。分析我国互联网消费金融的发展现状,互联网消费金融产品主要分为三种经营模式:第一,信息资金服务中介;第二,传统消费金融的互联网化;第三,基于电商平台开展金融业务。在互联网消费金融迅猛发展的趋势下,主要面临三类风险:信用风险、技术风险和监管风险。其中欺诈类风险作为信用风险的主要表现形式,是互联网消费金融风控能力的主要指标,因此互联网消费金融反欺诈能力的提升刻不容缓。本文借鉴国内外的研究成果,结合统计学和机器学习等学科知识,以大数据为依托,提出了一套较为合理互联网消费金融的反欺诈模型。该模型主要由统计分析、模型验证、和人工验证三大部分组成,其中统计验证是采用统计方法收集、整理和分析原始数据;模型验证是使用机器学习算法,建立反欺诈模型,验证出有欺诈可能性的用户;人工验证是前两个模块的补充,再次审核可能存在欺诈的用户。基于反欺诈系统的模型框架,本文收集互联网消费金融的行业的实际数据,并以此进行建模与分析。原始数据集中包含用户的消费信息、社交信息和信用信息(异常类型和正常类型)。基于大数据统计分析,发现用户的消费、社交与用户的信用类型正相关,而用户的社交关系对用户的信用评价有明显影响。抽取部分训练集数据分别建立神经网络模型、支持向量机模型和随机森林模型,使用测试集数据进行验证,模型评估表明神经网络的预测效果最理想。最后,总结互联网消费金融反欺诈系统的研究成果,阐述研究中的不足之处,并且对建设互联网消费金融反欺诈系统给出合理的意见。"
1600,基于LSTM模型的深度学习与迁移学习在预测外汇汇率中的应用研究,"正确的分析和预测汇率对制定相关经济金融政策,企业规避外汇风险来说一直都是具有非常重要的意义的。外汇汇率市场作为一个非线性变化的动态市场,汇率的波动变化有着非常显著的非线性和历史依赖的特征。神经网络模型其具有处理非线性特征系统的优势被广泛应用于外汇预测中并被证明比以往的时间序列预测具有更高的精度。但传统的神经网络模型却忽略了序列内部的先后时序关系,后来有学者提出具有记忆持久化功能的递归神经网络(RNN)来解决时序依赖的问题,但RNN在实践中常有梯度消失、难以训练的问题。因此后来人们提出基于门控制长短期记忆单元神经网络即LSTM神经网络(Long Short-Term Memory),这种神经网络独特的“门式”控制和记忆单元结构使得其在金融时间序列中被证明比传统RNN具有更高的预测精度。目前将深度学习LSTM神经网络应用于汇率预测方面的研究相对来说比较少,主要还是集中在股指、期货数据上。对于此本文采用LSTM模型来对不同时间跨度的外汇汇率时间序列进行预测。一方面,本文在六种货币对的每分钟汇率收盘价数据的基础上,利用LSTM神经网络对不同时间跨度的短期汇率序列进行预测并对比几种常用的传统预测模型(BP神经网络,支持向量回归)结果表明:深度LSTM模型的汇率预测模型的预测误差要优于这两个传统预测模型。另一方面,在外汇汇率更长时间跨度预测上,对于神经网络在时间间隔增大时预测误差会变大这样一个问题,本文在LSTM模型预测的基础上探究采用迁移学习的方法来提升汇率的变长时间跨度下预测性能,利用三种货币对的日度汇率序列进行时间迁移和货币对迁移两方面不同时间粒度下的汇率预测实证并与LSTM模型直接预测比较,实证结果表明:1、基于时间粒度迁移和货币对迁移的LSTM模型具有更低的预测误差;2、在对澳元兑美元和人民币兑美元汇率的预测中,货币对迁移对LSTM模型预测性能的提升比时间粒度迁移更大。另外本文以时间跨度为3天的人民币汇率为例,通过EEMD(集合经验模态分解)方法,将迁移LSTM和LSTM模型预测结果序列进行分解并与真实序列分解的分量序列进行对比,发现迁移学习之所以能够有效提升LSTM模型对更长时跨度汇率预测的性能,是因为迁移学习在对低时间跨度汇率序列进行预训练的过程中,模型能够更加充分地学习汇率波动的长期变化和趋势特征,因而在对长时间跨度汇率序列的预测中迁移学习LSTM模型能具有更高的精度。"
1601,基于宽深度模型的广告点击率预估方法,"随着互联网技术发展的日新月异,传统广告行业正在向新兴的互联网市场转移,与互联网企业营收息息相关的广告点击率相关研究成为了各个互联网企业最为热衷的领域,同时也是学术研究在工业界落地的重要应用场景。面向海量的用户行为数据,如何根据用户行为数据向用户推荐更符合用户需求的广告显得尤为必要。本文着眼于实际的应用场景,利用了用户信息、广告信息和用户历史行为信息,从宽度、深度这两个模型切入,提出了基于宽深度模型的广告点击率预估算法,本文称之为RD-FM算法,从而能更好地对针对不同用户的喜好进行广告推送,提升广告点击率。本文的主要工作包括以下几个方面:(1)调研了有关广告点击率相关国内外研究现状,并分析了它们的优势和存在的缺陷。(2)广告点击率数据预处理:本文分析了点击率预估原始数据存在的问题,提出了一套完整的点击率预估流程,包括对采集到的用户属性、广告信息、用户历史行为的数据清洗、数据采样、数据规约和数据转换。(3)基于宽深度模型的广告点击率预估算法:本文依据谷歌提出的宽深度模型模型,结合Deep-FM算法及广告点击率预估数据集的时序特点,设计了RD-FM算法。该算法分为基于因子分解机模型的宽度层、融合时序特征的深度层以及两者共享的Embedding层和输出层等部分。(4)本文对比多个算法,对算法的有效性进行实验。本文提出的RD-FM算法在AUC、RMSE两个评价指标上与传统的点击率预估算法进行了对比,实验结果表明本文算法相比传统点击率预估算法在AUC和RMSE等指标上具有更好的表现,说明该算法充分发挥了因子分解机模型和时序深度模型的优势。"
1602,基于机器学习的DDoS实时网络入侵检测系统关键技术的研究,"随着计算机技术的快速发展,尤其是云计算与大数据、人工智能时代的来临,分布式拒绝服务(Distributed Denial of Service,DDoS)攻击已经成为网络空间安全领域最具威胁的因素之一。同时,伴随着工业物联网的兴起,越来越庞大的僵尸网络使得DDoS攻击的危害性越来越大,因此DDoS攻击检测始终是网络安全领域的研究重点。尽管前人已经提出了诸多方法,然而随着技术的不断发展和业务场景的变化,很多针对DoS或者DDoS攻击的传统检测方法和防御手段已经过时。目前,针对DDoS攻击的检测,如何提高检测的效率和准确率,实现分布式检测和协同防御变得越来越重要。因此,本文利用机器学习与大数据分析等相关理论方法和技术,根据DDoS攻击流量的特点对网络流量中多维度的属性特征进行提取、分析,实现对互联网中大流量的DDoS攻击进行实时、高效、准确的检测。针对DDoS攻击检测的需求,本文提出一种针对DDoS攻击流量的集成学习分布式检测框架(Ensemble Learning Distributed Detection Framework,ELDDF)。该框架采用分布式的流量采集存储技术,实时的数据清洗技术以及基于集成学习的攻击检测方法,能够满足DDoS攻击检测的实时性、准确性等需求。在提出的ELDDF上,木文结合当前比较流行的大数据框架,构建了基于大数据的DDoS攻击检测系统。检测系统使用Gopacket、Libpcap等工具构建分布式流量采集传感器对流量进行实时采集,使用Spark Streaming构建实时流量特征提取模块,根据TCP/IP网络编程模型和DDoS攻击流量的特点对采集的数据包进行多维度的特征提取,同时基于Spark构建DDoS攻击检测模型并实现分布式随机森林检测算法,能够满足大数据的网络流量的实时检测。"
1603,基于机器学习的煎炸油品质近红外检测方法研究,"煎炸油在经过多次煎炸后,不仅会影响煎炸食品的口感,同时也会降低煎炸油的品质。随着煎炸次数增多,油里的有害物质不断增多,进而导致煎炸油的品质严重下降。所以本研究提出在标准实验操作下,采用近红外光谱(NIRS)技术结合机器学习方法来检测煎炸油品质。将煎炸油品质折算到标准实验操作下的煎炸次数,从机器学习的分类和回归两种不同角度分析,分别建立随机森林(RF)和偏最小二乘(PLS)模型。首先,本文设计了标准煎炸实验操作,过程是以大豆油作为煎炸油,冷冻薯条作为煎炸物质,共进行十次煎炸操作。每次煎炸操作在不添加新油的情况下,将大豆油反复煎炸15次,并得到15次不同煎炸次数的光谱数据。其次,使用一阶导(D1)、二阶导(D2)、标准正态变量变换(SNV)和多元散射校正(MSC)等方法对这些光谱数据进行预处理,并且根据分类和回归的结果来选择最佳的预处理方法。同时,根据分析的角度不同,采取不同的特征波长选择方法。随机森林模型采用相关系数方法选择特征波长,偏最小二乘模型则采用向前间隔偏最小二乘(FiPLS)、向后间隔偏最小二乘(BiPLS)和遗传算法(GA)来选择特征波长。最后,经过分析发现随机森林模型采用D1和相关系数相结合方法处理光谱后,得到的模型准确率最高,训练集准确率(TRA)为100%,测试集准确率(TEA)为93.33%,袋外数据(OOB)误差率为0.04148。而对于偏最小二乘模型,采用SNV、FiPLS和GA相结合的方法来处理光谱数据时,模型的效果最好,决定系数(R~2)为0.9994,预测均方根误差(RMSEP)为0.1060和相对分析误差(RPD)为40.7021。研究结果表明,本文所采用的两种不同类型的建模方法都能够快速、准确的鉴别煎炸油的品质,同时也为煎炸油品质的检测提供了便捷高效的方法。"
1604,基于威胁情报的APT检测技术研究,"高级持续性威胁已成为网络空间安全对抗的主要形势,传统的网络防护技术效率无法满足需求。基于威胁情报的检测以其快速高效成为当前防范APT攻击的一种技术手段,也成为当前研究的热点问题。本文基于数据分析及机器学习方法对威胁情报数据进行挖掘和分类,从中发现恶意软件攻击特征,对当前高级持续性威胁的防护效率提升具有重要意义。本文主要工作如下:1.针对多源威胁情报采集,设计实现了三种方法,分别是:基于网络爬虫的可抵抗现有典型反爬策略的方法、基于邮件订阅解析的方法以及基于开源情报共享的方法;2.基于TextRank和FastText算法实现了针对威胁情报的自动化标注。所提出方法通过TextRank算法对威胁情报样本进行关键词提取并去除停用词,接着输入到FastText算法中,构建分类模型,通过实验和调参训练威胁情报分类模型,最后利用该模型实现对威胁情报的自动化标注;3.基于关键词关联方法对威胁情报进行关联分析,挖掘一则威胁情报从产生到消亡的生命周期,确定该情报在不同发展阶段的状态和形式,从而能够更加全面地理解威胁情报;4.基于威胁情报中提取到的35934条恶意域名,利用机器学习算法提取恶意域名特征,采用集成分类器训练恶意域名识别模型并进行检测。结果表明本文所设计的方法能够有效区分恶意域名和正常域名。最后,对本文工作进行了总结并给出了未来研究方向。"
1605,基于隐马尔科夫模型及反向传播神经网络的音效素材分类,"随着多媒体技术发展和计算机运算效率提高,多媒体信息数据呈现快速增长的趋势。目前在国内广播电影电视行业的音效剪辑仅依靠人工听辨音效素材,由于素材声源混杂,且具有丰富语义及听觉特性,要从海量的音效素材中找到目标文件耗时且低效,因此迫切需要一个音效素材自动分类系统。本研究首次在广播电影电视行业内部应用机器学习方法对音效素材的自动分类进行探索,通过对音效素材提取特征参数建立标准数据集,采用不同的算法对于数据集学习训练并建立了基于反向传播神经网络的音效分类原型系统。研究核心为音频数据的相似度匹配算法以及音频数据的标注处理。主要工作及研究成果如下:1、实验对4074个音频文件分别提取了短时能量、短时平均过零率以及梅尔频率倒谱系数及其差分这三类特征参数,根据不同类型算法建立了相应标准数据样本集。2、分别构建隐马尔科夫模型和反向传播神经网络模型对样本进行训练识别得到分类准确率并分别测试模型的性能;对两种算法及相关研究从算法结构、训练时间和识别率进行扩展讨论。结果表明:对于含有复杂声音来源且有较多易混淆元素的音效素材进行分类,反向传播神经网络训练方法更易实现效果,平均识别率接近90%左右。3、建立基于反向传播神经网络的音效分类原型系统,以便于今后音频工作者使用。"
1606,基于网络结构的多组学数据融合关联分析,"现代社会快速发展的同时也带给人们巨大的精神压力。随着医学的进步,精神类疾病逐渐被人们所重视。其中,精神分裂症作为具有遗传性的一种精神类疾病,因其病因不明,临床表现复杂而受到研究者们的关注。随着机器学习和基因测序等相关技术的大热,众多研究者将重点转移到机器学习的相关方法和生物医学中的组学数据相结合,进而得到研究者们所需的信息。本文采用的基于网络结构的多组学数据融合关联分析算法对fMRI数据(functional Magnetic Resonance Imaging,功能性磁共振成像)、SNP(Single Nucleotide Polymorphism,单核苷酸多态性)、DNA-methy(DNA methylation,DNA甲基化)这三类组学数据进行计算分析。首先,在对数据标准化等预处理之后,我们构建网络结构模型对样本数据进行一个结构的建模,针对每一类数据都建立相应的相似性矩阵,然后利用以交叉扩散过程为核心算法对样本对进行加强强相关,减弱弱相关的操作,将每一类数据融合成最终的统一数据矩阵,从这个统一矩阵元素中选择出强相关的样本对,进而对其进行具体关联的分析,最终根据对应的SNP位点、fRMI体素信息等找到潜在的精神分裂症的生物标识物和其相关例如潜在发病脑区等信息。相比于其他使用线性融合等的方法,本文采取的是非线性信息融合的方法,对先验信息要求低,并且不需要对每一类数据做权重的分配。通过模拟数据集和真实数据集的验证,在相同的参数条件下,三类组学数据的大部分融合样本相似度比两类组学数据相应的融合样本相似度高,并且在寻找相关疾病的潜在发病生物标识物时,三类组学数据最终分析结果比两类组学数据分析结果多,侧面论证第三类组学数据的加入对数据的融合有一定的补充和完善,从而在医学上分析相关疾病提供一定的帮助。"
1607,基于Spark的STL-SVR短期电力能耗预测算法研究,"随着节能减排的不断推进,对电力能耗准确预测的需求变得日益迫切,同时,物联网技术的不断发展,使得电力能耗数据采集规模不断扩大,在海量的数据基础上进行预测,单机环境势必会遇到计算资源不足的瓶颈,如何快速处理这些海量数据进行预测同时达到电力能耗预测准确性的要求已成为近年来的热点研究方向。基于此,本文建立了一种STL-SVR电力能耗预测模型,并通过Spark分布式处理平台实现此模型对大规模数据的快速处理。本文的主要工作如下:(1)引入STL(Seasonal and Trend decomposition using Loess)时间序列分解结合支持向量回归SVR(Support Vector Regression)建立STL-SVR电力能耗预测模型。针对单一模型无法实现准确的电力能耗预测的问题,通过引入STL时间序列分解,将电力能耗数据分解为趋势项、周期项与余项,并分别根据每项的特点采用支持向量回归算法预测或其他方式进行处理之后整合得到总体模型,实现了电力能耗数据的准确预测。(2)引入模拟退火算法优化SVR的参数选择。针对使用网格搜索进行SVR算法的参数优化缓慢的问题,通过引入模拟退火算法这一适用于大型组合优化问题的算法实现SVR的参数优化,大大加快了SVR算法的参数优化效率。(3)STL-SVR电力能耗预测模型的并行化。针对海量数据下单机环境遭遇计算资源不足,算法运行缓慢的问题,引入了Spark分布式处理平台,在Spark上实现了包括数据预处理、特征工程处理和SVR算法的并行化,建立了基于Spark的STL-SVR电力能耗预测模型。在保证预测精度的同时,缩减了海量数据下模型的训练时间。本文基于提出的STL-SVR预测模型进行了三组实验,分别是回归森林、SVR、STL-RF模型与STL-SVR模型的对预测比实验,使用模拟退火算法与网格搜索进行SVR参数优化的对比实验与单机环境与Spark环境下STL-SVR模型的对比实验。实验结果表明,基于Spark的STL-SVR预测模型相比单机环境下的传统算法更具竞争力,在预测精度与参数优化效率上有了明显提升,在海量数据下也能同样保持较高的运行效率。"
1608,基于大规模MIMO实测信道数据的机器学习研究,"随着大规模MIMO的逐渐成熟,这项可大幅提升通信速率的物理层技术已进入5G移动通信标准,在5G商用中很快将得到广泛部署和运用。大规模MIMO是通过大量增加基站端天线及射频链路数达到很高空间解析度的一项关键性技术。大规模MIMO通信系统的波束赋形依赖于准确的信道状态信息Channel State Information(CSI),在时分双工模式下,基站需要实时估计上行的信道状态信息。在此系统中,由于基站端的天线数量和用户数比传统MIMO系统多一到两个数量级,基站端估计获得的CSI将是大量的数据,再加上正交频分复用Orthogonal Frequency Division Multiplexing(OFDM)的子载波数量以及信道在时间维度上的变化和采样数,大规模MIMO系统中的信道状态信息数据可视为5G无线通信中的“大数据(Big Data)”。这些CSI数据通常在基带处理(Baseband Processing)后便直接丢弃,然而这些数据包含了基站和用户所在小区的信道环境信息,具有一定的潜在利用价值。本文设想将信道状态信息存储下来进行数据分析、挖掘(Data Mining),使用机器学习技术来发现信道状态信息大数据内部的结构和关联,以期辅助大规模MIMO通信、降低大规模MIMO系统复杂度或形成基于大规模MIMO系统的新型应用。本文的研究工作基于大规模MIMO实测信道数据,实验环境为郊区(Suburban)户外环境中的无线信道,基站端采用128根天线的圆柱状天线阵列,用户端采用单根垂直极化天线,信号中心载频为2.6GHz,带宽50MHz,基站与用户之间有视距传播路径。在对信道数据的分析中,不仅使用了矩阵的形式,且将数据变换为张量的形式进行分析。研究采用了经典的主成分分析(PCA)和针对张量的多线性主成分分析(MPCA),以及特征向量非正交的稀疏字典学习法,对大规模MIMO信道数据的稀疏性进行量化的分析。然后,将预处理后的数据采用神经网络进行地理位置上的分类与识别。本文提出了将大规模MIMO信道数据作为物理层大数据的思路。在已知大规模MIMO信道具有稀疏特性后,对实测信道数据进行了量化的稀疏性分析,并且采用张量的形式和方法,保留了不同维度之间潜在的相关性。在对数据进行初步分析后,我们发现基于信道数据的地理位置分类与识别可以达到80%以上的准确性,尤其是利用仅含信道增益的数据进行分类、识别,不仅大大降低了运算复杂度而且准确性也有明显改善,达到90%以上。"
1609,认知商务的商业模式分析,"认知技术和人工智能等新一代数字技术的快速发展与广泛渗透,正在驱动商业和经济的数字化转型变革。在新的数字化转型变革背景下,认知商务(Cognitive Commerce)正在成为商业变革和电子商务生态体系演化创新的前沿,在对技术、管理、商业和社会等诸多层面或领域提出了许多新课题和挑战的同时,也为电子商务的转型升级提供了重要发展机遇。以认知商务这一新的方向为选题,研究探讨它的基本概念、系统运作框架和商业模式的价值活动,对提高认知商务的理解和认知,进一步丰富电子商务研究,推动认知商务发展具有重要意义。首先,本文梳理总结了认知商务理论研究和实践发展现状,梳理了认知科学、认知心理学、认知技术、商业模式等相关的认知商务理论基础,确定了研究的主要内容和技术路线。其次,针对认知商务理论基础薄弱的现状,对认知商务的基本概念进行了系统分析阐述,包括认知商务定义、产生背景(社会、技术两个角度)、产生动因(需求拉动、供给推动两个角度)、产生基础(科学、技术、社会三个角度)四大部分;并在认知技术和认知商务应用发展的基础上,提出了认知商务的运作原理和运作框架。第三,在分析提出认知商务的产业链结构的基础上,从价值主张、价值创造、价值获取的角度构建了一种基于价值视角的认知商务商业模式的概念框架,并进一步构建了e~3-value价值分析模型,对商业模式进行初步的仿真运算和定量分析,论证了商业模式的可行性;第四,以医疗行业的癌症治疗为例,构建了基于认知商务的癌症治疗的业务流程和e~3-value价值模型,对其价值进行了进一步评估分析。最后,阐述了本文认知商务的研究结论和局限性,并指出了未来可进一步深入研究的问题和方向。认知商务是电子商务演化发展的一种重要方向或趋势。本文研究明确了认知商务的基本概念,提出了认知商务的运作体系框架,构建了一种基于价值视角的认知商务商业模式的分析模型。本文研究工作为电子商务发展提供了一种新的研究视角,同时为商务管理的新数字化转型提供了有价值的参考和借鉴。"
1610,基于多层混合深度神经网络的电商商品短期需求量预测方法研究,"在电商供应链管理中,商品的短期需求量预测是电商供应链中一项关键的任务,准确的商品需求量预测不仅可以帮助企业制定合理的补货计划和库存决策以降低企业的库存成本,同时也能提升供应链运行效率、满足消费者体验。然而,由于电商环境下商品交易具有动态性、间歇性以及影响因素复杂等特点,故电商商品的短期需求量预测问题成为该领域的难点和重点。在此背景下,本文首先对国内外学者在商品需求量预测方面的研究进行了学习,系统分析了电商商品需求量预测模型及内容方面有待解决的问题。其次,对电商商品短期需求量相关概念、特征等内容进行界定与说明,并对电商商品短期需求量预测相关内容及预测方法理论进行了研究,为后续预测建模做基础支撑;另外,通过对预测方法的对比研究,结合电商商品短期需求量相关特征及影响因素,基于前人的研究成果,构建了能够同时对特征集进行学习与抽取、模拟时间序列趋势以及需求概率分布的多层混合深度神经网络(AR-MDN)模型;再者,利用探索性数据分析以及特征工程方法理论对收集到的电商商品历史交易数据进行了预处理,构造了预测模型所需的原始特征集群;最后,利用构造的电商商品特征集群数据对多层混合深度神经网络模型的预测效果进行验证,并与ARIMA模型和MLP-LSTM模型的预测结果进行了对比分析。通过对电商商品短期需求量进行预测,结果表明基于AR-MDN模型的电商商品短期需求量预测值与真实值拟合效果良好,预测误差稳定,模型具有一定的有效性;因本文的特征集考虑了衍生特征,故比较了有无衍生特征对AR-MDN模型预测效果的影响,发现衍生特征在提升模型的准确性方面有一定的作用。其次,与两个对比模型的预测结果相比,AR-MDN模型在电商商品短期需求量预测方面具有更低的均方根误差(RMSE)和平均绝对百分比误差(MAPE),且AR-MDN模型在区域分仓中的预测结果优于其他两个模型,说明AR-MDN模型在电商商品短期需求量预测方面具有更好的精确性和鲁棒性。"
1611,视觉导引移动机器人标识符识别与路径跟踪系统研究与设计,"在工业4.0和中国制造2025政策的推动下,国内外高校和企业逐渐加大对机器人的研究力度。随着计算机和传感器等软硬件性能的提升,移动机器人的功能逐步趋向全方位化和全自动化。视觉导航技术作为引导机器人工作的“眼睛”一直是机器人导引研究的热点,其关键核心为路径识别技术。提高移动机器人的路径识别技术水平和路径跟踪控制技术水平有利于机器人实现更高精度的运动,为移动机器人跟踪更复杂的工作路线以及完成更高难度系数的任务建立基础。本文以视觉导引移动机器人作为研究对象,设计并搭建出视觉导引移动机器人系统。建立相机标定模型并对相机进行标定,完成失真图像的矫正过程。对导航带图像和标识符图像的预处理算法进行研究,包括灰度化、滤波、分割、形态学增强、边缘检测和感兴趣区域选取等,提出轮廓边缘扫描法提取边缘线,并通过最小二乘法拟合中心线;使用改进后的Hu矩算法提取标识符特征,并用机器学习算法进行标识符识别。建立视觉导引移动机器人的运动学模型,分析两驱动轮位置偏差和角度偏差与控制电压之间的数学关系,获得路径跟踪控制系统方程。基于模糊控制方法,对运动学模型设计出一种模糊控制器,并与经典PID控制器进行比较。本文对视觉导引移动机器人进行测试,验证视觉图像处理算法精度和实时性以及路径跟踪控制器的纠偏性能。测试结果表明:(1)与传统算法相比,本文提出的轮廓边缘扫描法结合最小二乘法拟合中心线耗时22ms,改进后的Hu矩算法处理时间为2.49ms,比原Hu算法的4.81ms短,且精度更高。改进的算法性能满足视觉导引移动机器人系统的实时性要求和精度要求。(2)本文基于模糊原理设计的路径跟踪控制器可以准确快速地跟踪直线型、圆弧型和混合型线路,可以用于不同速度移动的机器人系统,角度偏差控制在±4°,位置偏差控制在±6mm。表明控制器的控制性能好,鲁棒性强,具有较高的实际工程应用价值。"
1612,基于迁移学习的脑磁图解码研究,"脑机接口是在人类大脑与电子设备之间建立的一种不依赖于外围神经和肌肉组织的直接的通讯和控制通道。它让人类通过脑信号同外界环境交流成为可能,让人类不需要语言或者动作而可以直接通过大脑来表达想法或操纵设备。脑磁图正迅速成为不可或缺的非侵入式脑成像技术。通过使用专业的仪器,脑磁图可以检测大脑中神经元群发出的微弱磁性活动,并且只有脑磁图可以精确定位并记录这些信号比地球磁场小约十亿倍的毫秒级现象。传统的脑磁图解码算法过分依赖于训练样本的数量,以及训练样本与测试样本在相同特征空间中分布的一致性。实际应用过程中,很难满足以上条件,因此限制了不同受试者之间的训练数据或训练模型的可迁移性。本文针对上述问题,将迁移学习的思想应用于跨受试者的脑磁图解码中。通过回顾在脑解码中取得令人满意的结果的迁移学习技术,本文提出了三种跨受试者的脑磁图解码方法,具体研究内容如下:本文根据黎曼流形上的点与切空间中切向量的对应关系,在切空间中找到不同受试者脑磁图样本协方差阵特征之间相同的特征子空间进行映射,实现了基于黎曼流形学习的跨受试者脑磁图解码。本文将每个受试者视为一项任务,假设每个受试者的学习模型具有相同的结构,通过共享模型参数之间的先验分布信息,在基于贝叶斯的多任务学习框架的基础上,提出了改进的多任务学习框架。在黎曼流形学习和改进的多任务学习框架的基础上,本文提出一种联合算法,通过结合黎曼流形学习的特征提取和多任务学习框架的分类过程,实现基于特征-模型的迁移,进一步提高了跨受试者的脑磁图解码的性能。本文实验采用16个受试者在目标视觉刺激检测任务中的脑磁图数据集,验证了以上三种算法的有效性。"
1613,聚合物共混挤出混合质量的超声在线监测系统开发及应用研究,"共混挤出是工业中最常用的塑料改性手段,而保证改性塑料的混合质量是企业提高生产效益和可持续发展的必要要求。目前共混加工产品的质量检测依赖于对产品随机抽样的离线测试结果,耗时费力、反馈滞后,且不能完全保证整批产品的质量一致性和稳定性。对连续生产的共混挤出过程进行实时监测与控制是一个突出的技术难点,成为制约改性塑料精益化生产的瓶颈。为此,本文开发了基于超声波测量技术的质量在线监测系统,提出针对聚合物混合质量生产合格判定的质量评估方案。本文设计并开发了模块化测量硬件和上位机交互软件,系统硬件由熔体测量模头及电气控制装置、超声波发射接收装置、可调测量间隙超声导波装置三部分组成。模块化设计能使系统连接到不同类型的挤出加工设备,测量间隙可调式设计能使超声测量适用于声衰减差异巨大的多种聚合物共混体系。上位机交互软件采用Labview编写,以生产者-消费者模式构建软件框架,使用Python编写数据处理模型,最终实现加工设备信息获取、超声信号采集与处理、测量参数设置、界面显示与交互及共混产品质量实时评估等功能。对开发的超声在线监测系统进行可靠性测试,测试结果表明:(1)该系统在260℃,10 MPa工艺范围内正常工作,并能保证良好的信号传输性能;(2)该系统的超声导波装置调距误差不超过0.1 mm,不同距离下熔体声速测量偏差不超过1%;(3)该系统经过累计600多小时的使用与测试,未出现明显故障。本文从是否明确超声信号与聚合物共混产品的材料性质的表征关系出发,分别提出了基于声特征参数过程统计和基于声信号数据模型分类的两套质量评估方案。以聚丙烯基碳酸钙填充复合材料合格检测作为应用研究目标,使用生产厂家提供的该复合材料的合格品与不合格品,设计了声特征参数对比实验、标准样品数据采集实验及共混加工过程模拟实验,对实验结果进行分析并验证质量评估方案的可行性。实验结果表明:(1)在合格样品与不合格样品不同比例混合实验中,超声熔体回波幅值及其傅里叶变换幅频谱与合格样品质量占比的相关性较高,线性模型决定系数达0.96,因此能将这两种参数作为统计过程分析的工艺特征参数。使用标准合格样品的超声信号计算特征参数并进行正态性检验,计算了??~?控制图与?~?控制图的控制参数,两种控制图能准确找出共混过程模拟实验中随机出现的不合格样品,与实验设计的样品序号一致;(2)两类标准样品采集的超声回波信号在PCA降维与K-means聚类后,类别标签重现率为84.4%,表现出较强的信号可分性,随即建立了基于时域特征的SVM模型和基于小波包分解系数矩阵的CNN模型,两个模型在验证集上分类准确率分别达到96.35%和99.58%,在测试集上分类准确率为96.69%与99.17%,在模型分类的基础上通过批次计数图能定位到不合格的样品批次,与实验设计的样品序号一致;(3)声参数过程统计法需要进行基于控制变量的试验设计以寻找特征参数,并对合格样品进行范围标定;声信号模型分类法需要不同质量等级的样品进行数据建模与参数调优。在影响产品质量的材料性质与超声信号的表征关系较为简单时,前一方案实施简单,有一定的可解释性且抗干扰能力强;反之,在工艺配方复杂、质量影响因素尚不可知的情况下,后一方案可操作性和准确性更高。两种质量评估方案在聚丙烯基碳酸钙填充复合材料的加工合格品检测中表现良好,初步验证了超声质量在线监测系统的工程应用可行性。本文研究成果可以发展为一种新型的聚合物共混挤出加工产品的在线质量监测标准,促进企业生产效益的提高。"
1614,基于数据驱动的注塑机液压故障智能诊断系统研究与设计,"随着我国工业互联网布局的逐步完善以及智能制造战略的稳步落实,在工业设备运行状态监测与健康管理的领域中,故障智能诊断技术逐渐成为各类工业设备智能化应用的研究重点。注塑机作为高分子材料加工的主要设备,使用的量大面广,但目前仍普遍采用事后维修的方式,特别是当设备内部液压系统出现故障时,因故障隐蔽性强,给排查、维修工作带来巨大难度的同时也严重影响了生产效率,急需提升注塑机的智能化水平;现有的故障诊断专家系统能够在一定程度上提高诊断维修的效率,但是该种诊断技术的实现依赖于专家主观经验,且不具备自更新功能,故障诊断准确率偏低。针对上述问题,本文设计了基于数据驱动的注塑机液压故障智能诊断系统,通过非破坏性的人为操作模拟出实际注射过程中的液压缸内泄漏状态,获得故障数据样本,使用数据挖掘算法完成故障特征提取以及诊断模型训练,并结合互联网技术实现远程的故障智能诊断。本文的研究工作包含了以下几个方面:(1)分析和调研了注塑机故障诊断需求与历史故障维修记录,以数据驱动的诊断系统组织架构为基础,确定了系统的软件模式与结构设计。(2)将故障诊断对象设定为出现频次高的注射油缸内泄漏故障,并搭建了故障模拟实验平台,成功采集了注塑机在正常、轻微泄漏、一般泄漏、严重泄漏共四种状态下的数据样本。(3)提出了结合注塑机工艺特点的方法,对注射阶段与保压阶段进行了差异化的故障特征提取,其中注射阶段利用探索性分析法提取出4个特征变量,保压阶段运用时域统计与小波包变换能量法提取出5个特征变量。(4)采取了XGBoost算法对所提取的故障特征数据进行小样本数据训练,并利用PSO算法完成超参数的寻优,最终诊断模型在测试集上的准确率达到88.9%。利用Java Web技术与Python脚本所开发的注塑机液压故障智能诊断系统,能够实现数据上传、数据可视化、特征提取、远程故障智能诊断、诊断模型自更新等多种功能;在12组现场模拟状态的数据上,系统故障识别率为100%且各类响应时间平稳,说明系统运行稳定可靠。"
1615,高危作业交叉风险评估与控制模型及应用研究,"动火作业、高处作业、受限空间等作业过程中重大事故时有发生,造成严重的人员伤亡和财产损失。到目前为止,在同一区域内多种作业的风险因素相互影响产生的交叉风险仍然缺乏系统性的分析和研究。分析高危作业过程风险因素交叉影响机理,全面、系统地管控高危作业风险具有紧迫性和现实意义。以企业生产过程中存在的高危作业为研究对象,运用统计分析方法和贝叶斯软件,分析了高危作业风险因素间的交叉影响,构建了基于贝叶斯网络(Bayesian Network,BN)的高危作业交叉风险评估模型,在此基础上针对交叉作业情况建立了基于风险交叉熵(Risk Cross Entropy,RCE)的高危作业交叉风险控制模型,并应用于某烟囱防腐施工工程。研究内容如下:(1)构建高危作业交叉风险评估指标体系。根据高危作业的特点,结合历史事故案例及现场调研,总结出人、物、环、管4个方面15个风险因素指标。对15个风险因素指标开展问卷调查并对结果进行统计分析,确定了3级风险状态,获得了各风险因素指标的风险状态统计数据。(2)建立基于BN的高危作业交叉风险评估模型。借助贝叶斯软件,通过机器学习结合专家知识方法,得到了风险因素间的交叉影响关系,并进一步确定了BN的结构与参数,构建了基于BN的高危作业交叉风险评估模型;通过评估某经济区内高危作业的风险情况,得出8个容易导致事故发生的高敏感度因素。(3)建立基于BN-RCE的高危作业交叉风险控制模型。根据相对熵理论,结合作业调度、交叉作业关系及BN模型风险评估结果,建立了基于BN-RCE的高危作业交叉风险控制模型;提出了用于描述交叉关系的“交叉度”概念,研究了交叉度及交叉作业风险的计算方法。(4)模型应用研究。结合某纸业有限公司烟囱防腐施工工程,对BN-RCE模型进行了验证与应用。运用数学软件编写了算法程序,增强了模型在应对复杂实际问题时的易用性。从BN节点敏感度及交叉度控制方法的角度提出了22项安全改进措施。采取改进措施后交叉作业系统RCE值下降幅度达52.1%,该烟囱防腐施工工程交叉作业整体风险大幅降低,模型具有较好的实用价值。"
1616,基于结构响应向量与机器学习的损伤识别方法研究,"工程结构的健康状态与人民的生命财产安全息息相关,对结构进行高效精准的损伤识别具有重要的社会意义。然而现今的损伤识别方法存在很多局限性,这一方面是因为结构本身的多样性与环境的复杂性,导致难以建立精确的有限元模型;另一方面是因为测量仪器的精度有限,导致测量数据存在误差并且不够完整,进而影响到损伤识别的效果。因此研究新的结构损伤识别方法并将该方法运用在实际桥梁中有着重要意义。结构响应向量(Structural Response Vector,SRV)可以同时包含结构的静态响应与动态响应,更加利于反映结构的健康状态。机器学习方法可以有效避免人工复杂的计算,直接有效地挖掘输入量的信息,可以在大数据的基础上得到更加可靠的损伤识别结果。但是目前基于结构动静态响应的研究不够深入,动态响应部分受噪声影响较大,此外机器学习的方法依旧缺少实桥模型的验证。因此本文基于SRV与机器学习,完成了以下工作:以珠江黄埔大桥北汊桥为背景,建立斜拉桥有限元模型,通过斜拉索弹性模量损失模拟桥梁损伤,得到斜拉桥在斜拉索单损伤以及多损伤情况下的动静态响应。本文研究结果表明,可以通过主梁竖向位移来判断发生损伤的斜拉索的位置和估计损伤程度,也可以通过固有频率增量的极值点所属阶次,判断损伤发生的位置。这为构建对损伤敏感的SRV分量提供了理论依据。提出一种基于SRV与机器学习的简支梁损伤识别方法,该方法以2阶固有频率与5个节点的竖向位移组成SRV,对简支钢梁模型进行损伤定位与定量化研究,得到了良好的识别效果与计算效率。为了解决基于SRV与支持向量机的损伤识别抗噪性较差的问题,本文引入主成分分析(Principal Component Analysis,简称PCA),对SRV中的动态分量进行降噪处理,保障了所提出的损伤识别方法的抗噪性。该方法有效解决了相平面法数据信息过度压缩、对结构响应类型不够敏感的问题。为了验证基于SRV与机器学习的损伤识别方法在实际工程中的可行性,也为了模拟结构实际的损伤形式,本文基于斜拉桥模型,进行了斜拉桥单损伤与多损伤的识别研究。该方法在斜拉桥单损伤识别方面拥有较高的识别准确率与一定的抵抗干扰的能力。在斜拉桥多损伤识别方面对所提方法进行了调整,在SRV的基础上,结合神经网络的多输出特性对斜拉桥进行损伤定位与定量化研究,得到了可观的结果。相比较传统的损伤识别方法,本文提出的方法既避免了复杂的计算,又能在所需响应信息更加精练的基础上得到很好的识别效果,更加具有工程实用性。"
1617,基于深度学习的鼻咽癌患者MR影像病灶分割和预后方法研究,"鼻咽癌(nasopharyngeal carcinoma,NPC)是人体鼻咽部最常见的恶性肿瘤,患者MR图像的病灶检测和淋巴结准确定位,是进行诊断、制定治疗方案与预后的重要基础。研究对象来自中山大学肿瘤防治中心,总共收集647名鼻咽癌患者临床信息与T1W、T2W、T1C等三种序列头颈部结构MR图像,由富有经验的医生勾画的肿瘤与淋巴结轮廓作为金标准,对被试按照3:1的比例划分为训练集与独立测试集。根据多序列MR图像的特点,分别构建多序列2D-ResUNet和多序列多维融合(Multi-sequence and multi-dimensional fusion,MSMDF)模型,对肿瘤区域与淋巴结进行分割。利用分割模型的结果,提取图像特征,并与TN分期、颅神经侵犯、EBV-DNA拷贝数、治疗前EBV含量、VCAIgA、EAIgA等临床指标相融合,构建分类预测模型,对术后是否转移与复发进行评估预测。实验结果表明,多序列2D-ResUNet对肿瘤与淋巴结的测试Dice值分别为0.786、0.808,豪斯多夫距离(Hausdorff distance,HD)分别为6.09mm、5.72mm,面积差占比(percentage of area difference,PAD)分别为19.1%、17.7%;而MSMDF模型对肿瘤与淋巴结的测试Dice值分别为0.801、0.830,HD分别为5.97mm、5.43mm,PAD分别为18.0%、15.6%。转移评估模型中,单独采用临床指标、单独采用图像特征、图像特征结合临床指标三种方法AUC值分别为0.733,0.791,0.840,F1值分别为0.458,0.622,0.727;评估模型中,以上三种方法AUC值分别为0.727,0.802,0.849,F1值分别为0.432,0.571,0.686。本研究利用NPC患者的多序列MR影像,建立基于多序列影像的深度学习模型,通过实验证明,该模型可准确有效地检测肿瘤区域与淋巴结,将分割结果与其它临床指标相融合,实现NPC术后转移与复发的评估预测。研究方法与结果对NPC患者的诊断、治疗与预后等具有重要的临床应用价值。"
1618,基于多特征融合与连续特征缩放的WiFi室内定位算法研究,"随着社会现代化的推进,智能手机已经普及人们的生活,基于位置的服务(Location Based Services,简称LBS)也越来越影响着我们,人们对于基于位置的服务的要求也越来越高。室内定位作为基于位置的服务中的一个重要技术,近年来受到了越来越多的关注。室内环境的复杂性导致了室外的定位方法如全球定位系统(Global Positioning System,简称GPS)等现有方式无法在室内实现良好的定位效果。并且,由于WiFi大量的在大型超市、医院、机场等场合的大量覆盖,利用WiFi信号实现室内定位成为了人们实现高效、经济、简单的室内定位的一种选择。然而,如何利用WiFi实现更加精确定位,如何应对多种场景下的不同需求,是一个亟待解决的问题。本文主要从以下两个方面展开工作:针对室内定位的粗定位(分类)问题,为了改善传统室内定位分类算法仅使用WiFi强度指纹作为特征的单一指纹方法,提升室内环境粗定位的分类精度,本文利用WiFi通信获得的WiFi指纹强度信息和一同获得的其他信息特征进行多特征融合,提出了基于集成学习模型(XGBoost与LightGBM)和多特征融合的定位系统。我们把所提出的定位系统应用在真实的场景中,实验表明,多特征融合的方法相较于传统单一仅使用WiFi指纹特征的方法能够提升定位的精确度,所引入的集成模型(XGBoost与LightGBM)相比传统的随机森林模型能够实现更好的定位效果,同时我们对于系统适用的场景也做了进一步的探讨。针对室内定位精定位(坐标定位)问题,本文就已有的基于特征缩放的方法k近邻(Feature Scaling based k-nearest neighbor,简称FS-kNN)算法中出现的“边界模糊”问题,提出了一种改进的使用连续特征缩放模型和异常点剔除的算法,简称CFS-kNN(Continuous Feature Scaling based k-nearest neighbor)。CFS-kNN不同于FS-kNN需要将整个RSSI(Received Signal Strength Indicator)信号空间划分间隔,从而避免了相邻区间上的权重选择问题,同时结合异常点剔除这一流程,进一步提高了定位的准确性。通过实际场景下的实验表明,所提出的算法在实验的几种算法中实现了最高的精度。最后,通过实验验证了算法在新环境下的稳定性。"
1619,基于微服务架构的装备智能维护技术研究与实现,"近年来,随着军队信息化战略的不断推进,部队信息化水平有了显著的提高。但是在装备维护领域上,数据依然采用人工录入等传统手段,使得数据来源低效且不具备活力和主动生成的能力。同时,部队装备随着国防事业的不断发展,装备在种类和数量上都有了成倍的增长,依然采用传统的装备登记,通过人工经验来做装备维护,效率低效,已经不能满足正常的使用要求。针对现有问题,本文对基于微服务架构的智能化装备维护技术进行了相应研究。提出了采用微服务组件、分域虚拟化技术、终端射频识别技术等,实现装备数据全链路的监控管理的方案,并提出了典型软件部署以及使用模式。设计了装备维护各阶段的典型微服务组件,并针对现有检索和维护方案提出了基于机器学习的推荐算法,大大提高了普通维护人员对装备维护的实用性和快捷性,保证了装备维护的快速和高效性。本文的主要工作有:(1)分析了国内外现有信息系统架构的特点以及装备维护方面的现状和不足,提出了基于微服务的整体解决方案。(2)在研究了相关技术与调研需求的基础上,提出了基于云平台以及应用商店的微服务发布架构,设计了相关总体架构、应用逻辑架构以及接口设计。(3)提出了装备维护方案的智能检索与推荐方案,对分词器进行了相关词典扩展和训练,提出了基于词向量计算的最大相似度推荐方案。(4)针对典型功能实现进行了相关功能测试和部署测试,结果表明本文提出的基于微服务的装备智能维护系统,部署灵活,各组件可按需进行调度和安装,大大提高了装备维护信息化管理水平和智能化水平。"
1620,基于HMM时间序列分析的列车轴承健康监测的研究,"近些年来,随着我国高铁的迅猛发展,高速铁路网的规模不断扩张,如何保障铁路车辆的安全成为极具挑战性的问题。走行部轴承作为影响列车运行安全的最关键部件,监测其健康状态一直是铁路车辆运行维护部门研究的重点。目前,如何评估轴承的健康状态仍是亟待研究的问题,本文基于全寿命周期的轴承监测数据,重点研究一种轴承健康状态的评估方法,为轴承健康监测标准的建立提供技术依据,也为铁路车辆的可靠性研究提供技术支撑。本文根据列车运行时轴承相关监测数据的时间序列属性和无标签性,选择将既能对时间序列中状态的相关性建模、又能以无监督的方式训练的隐马尔可夫模型(Hidden Markov Model,HMM)作为研究重点,并针对HMM的隐状态数必须预先设定的不足,将HMM的非参数版本,无限隐马尔可夫模型(infinite HMM,iHMM),引入到轴承的健康监测中。该模型利用分层狄利克雷过程(Hierarchical DP,HDP)的分层共享原理及良好的聚类属性推断隐状态数目,弥补了HMM的不足。同时本文对iHMM的缺陷及状态划分的质量进行优化,建立了有效模型,并将轴承全寿命周期的健康状态分为四个劣化等级,实现了对轴承健康状态的监测。具体研究有如下几点:(1)针对iHMM的收敛状况对其超参数较为敏感的缺陷,本文利用贝叶斯优化和Mann-Kendall准则调节其超参数;同时考虑到传统iHMM模型的拓扑结构不适用于轴承健康状态的退化过程,本文将其各状态遍历的拓扑改造成自左至右的模式,以贴合轴承健康监测的需要,将改进后的模型命名为LR-iHMM。(2)实际的轴承劣化数据存在两个时间尺度的动态变化,单层模型存在状态表达能力不足、状态划分过于直接的问题。因此,本文将LR-iHMM模型的结构拓展至两层,对单层模型的隐状态进行宏观划分,以宏观状态模拟轴承的健康状态,提高模型对轴承数据的建模能力;同时根据同一健康状态下其数据特征具备一定相似性的原理,将数据分布相似的微观状态归并为一个宏观状态,在无监督的条件下进一步提高模型进行健康状态划分的质量,形成了Doubly LR-iHMM模型。(3)构建了基于Doubly LR-iHMM的轴承健康监测模型,本文通过实际的轴承数据进行验证,结果表明,与单层模型相比,Doubly LR-iHMM能够更好地拟合轴承性能退化数据,健康状态的划分结果也更加合理。本文根据实验结果,以四个劣化等级定义轴承全寿命周期的健康状态,实现对轴承的健康监测。"
1621,脑机接口中基于黎曼几何的机器学习方法研究,"脑机接口通过供额外的信号通路,实现大脑直接控制外部设备,在残疾人功能辅助与康复等方面有着广阔的应用前景。在运动想象脑机接口中,受试者通过想象部分肢体的运动产生多种模式的脑电信号,系统分析受试者的脑电解析控制指令,实现对外部设备的控制,其中的核心技术是对运动想象脑电信号的解码。然而,脑电信号的低信噪比、非平稳性以及个体差异性是运动想象脑机接口从实验室走向商业应用的巨大障碍。因此,寻求高效的解码算法、降低训练成本是该领域长期的研究热点。近年来,有学者出使用黎曼几何的工具对运动想象脑电信号的协方差矩阵进行建模和分析,取得了良好的效果,为解码脑电信号供了新工具。在实际应用中,黎曼几何方法常常面临维度灾难的问题,往往需要设计降维算法。本文基于黎曼几何工具,出了一种新的解码运动想象脑电信号的算法,利用流形学习的等距映射降维算法对局部黎曼切空间投影的结果进行降维,然后使用局部线性嵌入算法获取全局坐标。该算法改善了直接使用黎曼切空间进行投影带来的边缘样本分布扭曲的问题,并实现了降维操作,在国际脑机接口竞赛数据上表现优异。同时,针对运动想象脑电信号非平稳性和个体差异大导致模型难以训练的问题,本文结合黎曼几何与降维方法,设计了一种新的迁移学习算法应用于运动想象脑机接口系统。该方法利用黎曼切空间投影法分别将不同受试者的样本集投影到相似的特征空间上,并拉直成向量,然后对所有样本使用多尺度放缩算法进行降维,并在低维欧氏空间上使用成熟的线性分类器进行训练和分类。实验证实,该算法在国际脑机接口竞赛数据集的表现优于现有黎曼几何方法。最后本文根据运动想象脑电信号在黎曼流形上的分布讨论了信号的非平稳性和个体差异特性对结果的影响。"
1622,虚拟现实视觉诱发态下基于前额脑电及眼动的情绪分类研究,"情绪是人类最重要的特征之一,对情绪分类进行深入研究,有助于推进人机交互的智能发展,同时为精神病患者心理障碍的诊治提供了可能。虚拟现实(VR)凭借立体、逼真的环境,让用户享受到身临其境的直观感觉,是较优的情绪诱发元。同时,在情绪分类研究方面,脑电与眼动等生理信号凭借其真实、客观被更多的应用。因此,本文将针对虚拟现实视觉诱发态下基于前额脑电及眼动的情绪分类展开深入研究。据调研,目前相关研究存在以下问题:1)虚拟现实视觉诱发态下带有情绪标签的生理信号库近乎空白,不利于后期算法的研究;2)在基于脑电的情绪分类研究方面,较之传统方法,仅基于前额二导联脑电信号的情绪分类算法研究十分缺乏,给操作与应用带来极大不便;同时,由于VR的特殊性,采集的脑电信号因头部运动与设备电流等引入大量噪声,而基于VR诱发的脑电去噪算法存在空缺;3)眼动位置数据与情绪关联关系存在极大的不确定性。基于以上问题,本文主要进行了如下工作:1)创建了符合国际标准的含有36张三种情绪的VR图片库,搭建了包含3个场景的自动交互型VR视觉诱发实验环境,通过24个受试者参与实验,创建了带有情绪标签的脑电、眼动数据集;2)在基于前额脑电的情绪分类任务中,基于DEAP数据库,借助梯度下降树(GBDT)模型,提出了基于前额二导联脑电时空频域特征融合情绪分类算法,获得平均75.18%的二分类识别率,不输于传统32导联方法,且减少了需处理信号通道数量,降低了特征提取计算;基于VR视觉诱发脑电数据集,提出了2种基于去噪自编码器(DAE)的脑电迁移学习去噪算法,极大地去除了头部运动与VR设备所带来的噪声,借助DAE+GBDT融合算法模型,获得76.88%的平均识别率,验证了分类算法的有效性、普适性;3)在眼动信号分析中,基于循环神经网络(RNN)模型初步探寻了眼动位置信号与情绪的关系,发现了个体差异性,指明了可深入研究方向。本文所做工作,为虚拟现实诱发态下带情绪标签生理信号库的创建打下坚实基础,为基于VR诱发的脑电信号去噪处理提供了可实施方案,为基于前额二导联脑电的情绪分类研究提供了有力参考,有助于可穿戴式情绪检测设备的发展。同时,在基于眼动数据的情绪分类研究上进行了一次积极有益的探索。"
1623,基于深度学习与脑电信号的情绪倾向分析,"人类的情绪包括人们针对外界或自身刺激产生的心理反应以及伴随着这种心理反应的生理反应,其在人际交往和决策过程中往往起着非常重要的作用。而基于计算机的自动情绪识别由于具有天然的客观性以及基于大数据所获得的强大的泛化能力,对构建更加智能的人机交互、疾病诊断、心理辅导等系统具有重大意义。本文聚焦当前火热和前沿的深度学习技术,主要研究基于脑电(EEG)信号的情绪分类以及情绪激活机制的问题。论文针对现有研究模型泛化性能较差、情绪激活机制不明且无心理学理论支撑等问题,进行了情绪分类和情绪激活机制这两个方面的工作。与传统研究只注重于情绪分类准确率不同,本文在利用深度学习等技术提升识别准确率的同时,创新性的对情绪激活机制进行了研究,并将结果与心理学理论和实践结果相互印证,使本文的结论得到了心理学方面强有力的支撑,为基于脑电的情绪倾向分析提供了一种全新的思路。本文的主要工作和创新点包括:1.提出了一种基于深度学习的情绪识别算法。该方法通过提取脑电信号的相关特征来降低输入数据的信息冗余,选择少量特征代替高维度的脑电信号输入到深度网络中,利用深度学习技术自动提取判别力更强的高阶特征,再基于这种高阶特征进行情绪分类。同时,针对传统方法实验设置不合理的问题,采用了更为合理的实验设置方式,提升了算法的泛化性能。最终,针对情绪正负向二分类任务在DEAP数据集上取得了87.27%的准确率,证实了本文所提出的方法的有效性。2.针对传统研究只关注情绪识别准确率而对情绪激活机制缺乏研究的问题,提出了一种基于机器学习的情绪激活机制研究方法。该方法在保证情绪分类结果在合理范围内的前提下,利用分类结果创新性的构建情绪激活曲线,从直观上反应了情绪的激活过程。在获取到激活曲线后,将其与心理学相关理论与实践相互印证,为本文所得到的结论提供了强有力的支撑。本文的两项工作分别覆盖了情绪倾向分析的实际应用和理论研究这两个方面,在情绪分类精度超越传统研究的同时,本文基于脑电信号对情绪激活机制展开研究,同时与心理学相结合,为基于脑电信号的情绪倾向分析提供了一种新的思路。"
1624,医学疾病表型实体及其关系抽取方法研究,"随着信息和数字化技术的应用,医学领域形成了大量的数字化知识和数据,但截至目前,大部分的医学知识和数据仍以非结构化的文本为主要表达形式,如临床电子病历,中医古籍(如黄帝内经,伤寒杂病论,本草纲目等)和现代医学文献等。从这些大规模文本信息中提取结构化信息是进行深入医学分析和利用的前提,是目前医学数据挖掘的主要瓶颈之一。本文结合表型实体及其关系的抽取问题,分别对临床病历,中医古籍和PubMed题录文献进行人工规范化标注,构建信息抽取标准数据集,然后进行表型命名实体识别及不同实体间关系抽取方法的研究。主要研究工作包括以下三个方面:第一,首先构建10426个现病史症状表型实体识别标准数据集,并且分别应用条件随机场(CRF)和结构化支持向量机(SSVM)进行实体抽取,重点比较分析了传统特征、基于深度表示的字词特征学习方法(Word2Vec和Node2Vec)的性能差异。实验分析发现,基于传统特征的CRF方法的F1值为0.83,而基于Word2Vec词向量的CRF和SSVM方法F1值分别达到了 0.9798和0.9908;同时基于Node2Vec字向量的F1值分别达到0.8879和0.9413,词向量的F1值分别达到了 0.9752和0.9788。可见,基于深度表示学习的方法性能优于传统特征的命名实体识别算法,基本达到了实用程度(F1值>0.95),且SSVM在性能上优于CRF方法。同时,由于不需要进行分词处理,基于Node2Vec深度字特征表示的SSVM也达到了很好的性能。第二,以英文题录文献中的表型实体关系抽取为目标,构建了源自PubMed中包含4种关系的标准数据集(8991条样本记录),再分别基于词特征和句子特征,采用经典卷积神经网络(CNN)和多卷积核CNN(CNNs)进行关系抽取研究。实验发现,融合词特征和句子特征的CNN的F1值达到0.7494,而CNNs方法F1值为0.8039。相比纯基于词特征的CNN(F1值0.7031)分别提高了 4.63%和5.45%。第三,构建包含10种关系类型的古籍标准数据集(共81908条样本数据),再分别采用BiGRU算法结合Attention机制和BiLSTM算法进行关系抽取研究。实验结果发现,BiGRU+Attention算法的F1值达到0.9486,而BiLSTM算法在WF特征和WF+PF特征上的F1值分别为0.9017和0.9232。可见,BiGRU算法的性能要优于BiLSTM算法的性能。"
1625,基于编码器―解码器结构的眼底图像中视网膜血管分割的方法研究,"眼底图像是糖尿病性视网膜病和高血压性视网膜病等不同视网膜疾病的有用诊断工具之一。眼底图像中视网膜血管的分割结果能够辅助医生诊断潜在患者的病情,帮助医生大大减轻工作量,对医生的临床分析具有重要意义。由于视网膜血管的独特性,如何更高效地实现视网膜的血管分割仍是一个研究难点。最近,卷积神经网络(CNN)被广泛应用,并且在医学图像分割中表现出很好的性能。本文基于卷积编码器-解码器结构,构建了两种不同的卷积神经网络,来提高分割结果,并在可公开访问用于血管提取的数字视网膜图像(DRIVE)的数据集上进行了评估分析。本文主要的研究工作如下:首先,本文在卷积编码器-解码器结构上添加了两种跳过连接,其中,长跳过连接将编码过程的特征图连接到相应层次的解码器,使得上采样过程能够同时获得高层语义信息和浅层细节信息;短跳过连接在不增加网络计算复杂度的基础上,使网络通过学习残差映射来得到更好的收敛效果。实验结果表明,添加了跳过连接的模型能得到更好的分割性能。其次,为了充分利用网络在编码过程中学习到的特征,在跳过连接的分割模型的基础上提出了多路径融合的整合方式,来对分割结果进行微调。分别对不同层次学习到的特征图进行上采样,然后将不同路径的结果进行整合,来实现端到端的分割。通过实验对比,多路径聚合的分割模型提升了分割结果的精确度和AUC的值。最后,为了降低无用特征和解码过程中噪声的影响,提出了基于Attention机制的分割模型。通过在编码器和解码器中添加不同的空间软注意力,对特征图赋予一定的权值系数进行参数的调整,使得特征图中的重要信息得到更多的重视,而抑制不重要的信息。实验结果表明,在提升分割性能的同时,模型对血管像素的敏感度也得到了有效的提升。"
1626,基于深度学习的声学场景分类与声音事件检测,"声学场景分类(Acoustic Scenes Classification,ASC)和声音事件检测(Sound Event Detection,SED)是多媒体分析与检索、音频监控、智能辅助驾驶等应用领域的关键技术,也是目前音频信号处理领域的研究热点之一。本文以复杂音频作为分析对象,探讨基于深度学习的声学场景分类和声音事件检测方法。本文主要工作及创新点如下:(1)提出了基于音频特征增强的声学场景分类方法。本文主要探讨音频特征增强(Audio Feature Augmentation,AFA)对声学场景分类性能的影响。具体包括:对两个通道音频数据的特征进行求均值和求差运算,得到两个通道特征的相同点和差异点;对音频数据均值的频谱做谐波冲击源分离(Harmonic Percussive Source Separation,HPSS),得到增强的音频特征。采用实验数据库DCASE2016和DCASE2017进行评测,基于音频特征增强的声学场景分类方法获得的准确率分别为85.8%和69.9%,均优于没有做数据增强的方法。此外,与其它声学场景分类方法相比,本文方法性能更优。(2)提出基于深度特征融合的道路异常声音事件检测方法。首先,采用深度自编码网络(Deep Autoencoder Network,DAN)将梅尔频率倒谱系数(Mel Frequency Cepstral Coefficient,MFCC),Bark滤波器组(Bark Filter Bank,BFB)和Gabor滤波器组(Gabor Filter Bank,GFB)三种浅层特征变换为深度特征,然后将上述深度特征的组合再次采用深度自编码网络进行变换得到融合的深度特征,最后将融合的深度特征输入长短时记忆网络(Long Short Term Memory Network,LSTMN)进行判决。实验结果表明,融合的深度特征在没有添加噪声时所得到的异常声音事件检测准确率为92.15%,F值为91.32%,高于其他单一特征所得到的结果;在添加噪声后,当信噪比分别为20 dB、10 dB、0 dB、-10dB时,融合的深度特征的性能明显优于其他特征,具有较强的抗噪性。综上所述,本文提出基于音频特征增强的声学场景分类方法和基于深度特征融合的道路异常声音事件检测方法。从多个侧面实验分析本文提出方法的性能,在多种实验条件下进行对比,验证本文方法的可靠性和有效性。"
1627,基于机器学习的MTC网络接入策略和资源分配,"当今世界对于互联网的需求是全天候的高速的无处不在的网络连接,旨在实现一个完全移动和互联的互联网社会。这种对于互联网的需求催生了物联网(Internet of things,IoT)的概念。机器类型通信(Machine-Type Communication,MTC)作为物联网的推动者,允许智能对象在没有人为干预的情况下实现相互通信。随着第五代移动通信系统(5th-generation,5G)时代的到来,物联网的进一步发展,高速增长的设备对无线接入网络的接入能力造成了极大的考验。因此,针对当前新兴的机器类型通信网络,如何有效接入大规模机器类型通信设备(MachineType Communication Device,MTCD),是一直以来亟待研究解决的热点问题。近来,随着机器学习(Machine Learning,ML)技术的更新发展,机器学习开始应用于很多移动互联网的场景等。机器学习是计算机系统使用的统计模型,无需使用特殊的指令有效执行特定任务,而是依靠模式和推理来代替。机器学习通过观察环境和自我探索,来获取新的知识从而不断改善自身性能。本文结合机器学习的思想,对于MTC网络中接入能力不足以及资源分配问题进行了研究,提出了不同MTC场景下有效的接入策略和资源分配方案,主要成果概括如下:根据MTCD的上行链路占优,小数据为多的特点,提出了基于自组织映射神经网络聚类算法的MTC接入策略。通过利用聚类算法,MTCD自组织自发地训练得到合适的数据聚合点,从而减少和基站直接交互的设备数量,有效避免了大规模MTCD接入基站造成的拥塞问题。另外,聚类算法保存了映射关系,让MTC网络环境对于新加入的MTCD包容性很高。考虑到随机接入过程中前导码是相互正交的,将接入问题简化为竞争同一前导码的竞争接入问题。利用退避机制,设置MTCD的双队列模型,将访问请求的排队模型抽象为马尔可夫决策过程。从而利用马尔科夫决策过程的动态规划算法来求解该竞争接入问题。由仿真结果可以得到,算法有效提升MTC网络的接入能力,降低网络碰撞概率,减少了接入时延。针对MTC网络存在多种业务需求的MTCD的情况,利用深度强化学习算法得到高效资源分配方案。对于大规模MTCD资源分配问题,利用传统Q学习解决该问题会出现状态动作对过大,Q值表占用内存爆炸的问题,因此利用深度神经网络和Q学习相结合,获得相对最优的资源分配方案。相对于传统的资源分配方案,基于深度强化学习的资源分配方案在保障MTCD不同的服务质量需求的同时,最大化网络吞吐量,降低接入时延。本文通过分析MTC通信的特点,利用机器学习的方法,针对性的设计接入策略和资源分配方案,来提升网络的接入能力,为MTC网络接入问题的求解提供了新的思路。"
1628,古籍文档图像智能标注系统的设计与实现,"中华文化源远流长,古籍文档作为中华文化的重要载体,对其进行数字化处理成为传承中华传统文化的有效途径,同时促进对古籍资源的保护和再利用。海量的古籍文档不可能依赖于人工录入的方式实现数字化,随着计算机视觉技术的发展,借助计算机视觉技术完成古籍文档的数字化成为可能,如实现古籍文档图像中文本的检测与识别。在大数据时代,大量的数据资源和计算资源推动了深度学习的发展,深度学习在计算机视觉领域取得了显著的进步,但相对于传统的机器学习方法,深度学习需要大量的数据,中文古籍文档数据集的匮乏限制了基于深度学习的算法研究,构建适用于进行大规模数据标注的系统成为迫切的需求。考虑到标注工作中完全由人工进行标注需要耗费大量的人力物力,可使用机器学习方法对数据进行预处理,以减少人工标注的工作量。根据以上分析,本文的主要工作总结如下:1)利用了垂直投影方法对原始数据进行列切分和字符切分,在单字字符数据集的基础上,利用了篇幅级文本标注信息训练模型,基于原型学习的卷积神经网络相比基于Softmax的卷积神经网络模型具有更高的精度和更好的泛化性。利用训练的模型对数据进行预处理,借助预处理的结果辅助人工标注,从而提高标注工作效率。2)根据古籍文档图像标注任务需求,设计并实现了基于阿里云平台的古籍文档图像智能标注系统,为大规模的数据标注和数据管理提供有效的工具,通过服务层封装API提供接口服务,同时可集成相关的算法服务,为古籍文档数字化提供了一个极具实用价值的原型系统。3)构建并公开了一个中文古籍文档数据集,包含1000张高丽藏大藏经和1000张多个版本的古籍大藏经数据,完成字符级别的位置信息和文本信息标注。基于该数据集研究了用于中文古籍文档图像文本检测与识别的方法,并开发相关的应用算法服务API,集成到标注系统,提供中文古籍文档图像文本检测与识别的应用服务。"
1629,基于深度神经网络的点击率预估模型,"大数据时代,我们生活中的方方面面都出现了信息过载的问题。用户从大量的信息中寻找对自己感兴趣的信息也随之变得困难;而对于信息生产者而言,让自己生产的信息在众多信息中脱颖而出也变得越来越难。推荐系统就是在这样的前提下产生的。推荐系统的主要目的是把合适的信息推荐给合适的人。对于用户而言,推荐系统能将用户感兴趣的内容推送给用户。对于商家而言,推荐系统可以给用户提供个性化服务,提高收入。在推荐系统中,点击率预估是非常重要的一个环节,判断一个商品是否进行推荐需要根据点击率预估的点击率来进行。论文主要研究基于深度神经网络的点击率预估模型的问题,聚焦当前火热和前沿的深度学习技术。论文针对当前存在的深度点击率预估模型,从低维特征的表达和组合特征的表达为切入点,对当前存在的深度点击率预估模型在低维特征表达与组合特征表达这两个层面做了改进工作,主要进行了将FFM中“域”思想引入深度点击率预估模型和将注意力机制引入深度点击率预估模型的两方面工作。本文的主要工作和创新点包括:1.提出了一种基于FFM深度神经网络的点击率预估模型。该方法的主要思想是通过将FFM模型中“域”的思想引入到深度点击率预估模型中,通过“域”的思想对低维输入特征进行多个维度的表达,使得模型可以更好地发现每个特征下包含的规律,最后利用深度神经网络技术进行点击率预估。相关工作已整理发表专利。2.提出了一种基于注意力机制的深度神经网络的点击率预估模型。该方法的主要思想是通过把在图像和自然语言处理领域取得良好效果的注意力机制引入到深度点击率预估模型中。通过注意力机制可以更好的表达特征与特征之间的交互关系,从而使得模型可以更好的表达特征之间存在的规律,最终实现模型性能的提升。本文的两项工作分别从低维特征表达层面和组合特征表达层面对现有的深度点击率预估模型做了改进,使得模型在参数相同的情况下获得了性能的提升。因此,本文方法具有广泛的应用前景。"
1630,用户个性化图像美感评估及表征研究,"图像美感评估,也就是可计算图像美学,指的是利用计算机,模拟人的视觉认知与心理认知,对给定的图像做出美学意义上的评估分数。近年来,随着以深度学习为代表的一系列方法的发展,建立通用的图像美感评估模型取得了长足的进步。然而,图像美感评估是一个十分主观的任务,不同的受众有不同的认知。因此,一个通用的美感评估模型并不适用于所有的用户。个性化的图像美感研究,尤为重要。个性化图像美感研究,指的是在可计算的图像美感研究中,单独地去考虑每一个用户,对用户的图像审美偏好进行学习。这项研究,主要面临着以下的这些挑战。首先,用户个性化美感的公开数据集较少。这是因为用户个性化信息收集较为困难,并且每个用户能提供的带有个性化美感信息的图像不够丰富。其次,用户个性化美感往往是抽象、没有明确规则的,这跟通用美感研究的挑战性是一致的。上述的客观原因制约了这个领域的发展,导致相关研究进展缓慢,可参考的文献资料等相对匮乏。本文主要针对个性化的图像美感研究中的两个问题,进行了研究。(1)用户美感评估,研究的是怎么才能更好地为不同的用户,构建符合他们审美偏好的图像美感分数评估模型;(2)用户美感表征,研究的是怎样才能更好地根据用户喜欢的多张图像,构建起有效的用户表征向量,用于用户识别、用户推荐等的任务。虽然研究者们在这几个方向都做出了很多富有意义的开创性工作,但是现有的研究工作依然存在着若干问题:1、对于用户美感评估,现有的方法借助残差模型的思想,结合了图像美学属性或者是真实用户的在线反馈进行用户个性化的图像美感评估模型的快速构建。这种方法没有解决用户数据量过少的问题,从用户数据中提取的信息有限。2、对于用户美感表征,现有的方法利用生成式的Counting Grid模型,借由所构建起来的图像数据内部结构对用户的图像美感偏好进行表示。这种表征方法会将用户表示为一个稀疏的结构,降低了用户个性偏好表征的信息密度,建模效率不够高;针对以上提出的问题,本文主要以个性化的图像美感作为研究对象,对相关问题进行了深入研究,研究内容包括基于元学习模型的用户美感评估与基于生成式Counting Grid模型的用户美感表征。本文主要取得了如下的创新成果:1、对于用户美感评估,首次将元学习的思想引入到用户个性化美感建模,将求解用户个性化美感评估模型这一个任务看成是元学习的测试过程,利用元学习这一方法解决用户数据量过小的问题,并针对实际的情况创新性地提出了一个基于混合策略以及元正则的元学习策略,以提升模型的泛化性能。本文提出的方法,给出的用户个性化图像美感评分预测,与用户的真实评分更吻合。2、对于用户美感表征,针对一个生成式模型的用户图像美感偏好建模方法,提出了一种网格空间集聚的改进,将原本较为稀疏的、不利于进行数值计算的用户表征,转变为更稠密的、信息量更大的表征形式,同时针对实际情况中的数据不平衡问题进行了改进。本文提出的方法,在用户识别、相似用户距离等的实验中都取得了更好的结果。"
1631,单幅图像去雾算法研究,"随着环境的恶化,雾霾天气越来越常见。在雾霾天气下获取图像时,物体的反射光在传播到传感器的途中,部分光会被空气中的悬浮粒子吸收和散射,同时混入部分大气光的散射光,导致成像后的图像往往会出现对比度降低、饱和度下降和色调偏移等退化现象。这些退化现象会严重影响计算机视觉系统效用的发挥,因此,图像去雾已经成为了图像处理领域的一个重要研究方向。本文分别基于暗通道先验理论与深度学习的方法对单幅图像去雾算法展开研究,有效提高了算法的运行效率与效果。主要工作如下:(1)提出结合暗通道先验的单幅图像快速去雾算法。首先建立场景深度模型并使用该模型估计雾霾图像的透射率,再基于暗通道先验和透射率的局部一致性特性得到粗透射率。然后利用图像融合方法,将基于场景深度模型估计得到的透射率与粗透射率融合,修正粗透射率图像中天空区域的透射率。最后使用导向滤波细化的透射率复原图像,同时利用色调调整函数提高复原图像亮度。实验结果表明,该算法运行效率较高,并且有效提高了复原图像的清晰度、对比度。(2)提出结合卷积神经网络与动态环境光的图像去雾算法。首先构建包含配对的真实雾霾图像与透射率图像的图像库,然后对其进行随机块采样,得到配对的雾霾图像块与透射率图像块作为训练集,训练透射率估计网络,再使用训练好的网络估计雾霾图像的透射率。同时考虑到图像成像光照不均的问题,使用动态环境光替代全局大气光,最后使用平滑滤波后的透射率与动态环境光复原图像。实验结果表明,该算法不仅可以有效复原图像,而且显著提高了复原图像的亮度、饱和度。(3)提出基于循环生成对抗网络的端到端图像去雾算法。在构造训练集时,先构建包含配对的清晰图像与深度图像的图像库,再对其进行采样、亮度调整操作,得到配对的合成雾霾图像块与清晰图像块作为训练集,训练所设计的网络。最后,使用该网络中的去雾网络对雾霾图像进行端到端的图像去雾。此外,算法中设计了深度加权损失以减小图像块中的天空区域对网络训练造成的影响。实验结果表明,该算法具有较好的图像去雾效果,复原结果亮度高、清晰度高,且具有丰富的纹理细节信息。"
1632,卷积神经网络在密度泛函结构预测计算中的应用研究,"随着现今新能源材料应用的增长,密度泛函计算等大规模材料计算也迎来新的挑战。卷积神经网络是一种前馈人工神经网络,不仅使用了较少的预处理,而且在特性设计中具有独立于先验知识和人工工作等特性,现已经成为众多科学领域研究的热点之一。本文基于卷积神经网络和密度泛函计算,开展材料晶体结构的预测分析。卷积神经网络的模型可以通过动态自动训练,不需手工装配训练数据集,所以无需对晶体结构预测算法进行重大调整,即可开展基于密度泛函计算的晶体结构预测。而且卷积神经网络可以与密度泛函计算相互验证结合,提高物质计算时结构预测的效率和准确性。为了跟进新能源材料的不断发展和机器学习算法的广泛应用,本论文探索将机器学习预测方法与密度泛函计算的预处理相结合,开展材料结构计算分析与晶体结构预测应用。基于密度泛函理论研究了面向材料晶体结构预测的卷积神经网络相关算法分析,进行了对应软件的模拟测试应用。首先结合材料计算技术新近进展概述密度泛函相关理论,讨论将机器学习引入材料晶体结构预测。接着基于TensorFlow软件环境搭建卷积神经网络,通过结构预测训练给出相应网络模型分析。并对钠元素的13种不同ID的晶体结构进行预测实验,为相关材料的计算模拟提供晶体结构预处理支持。"
1633,基于卷积神经网络的肝脏CT影像及纹理信息分类问题研究,"卷积神经网络在医学影像上已有广泛应用,然而在肝脏分类问题的研究上还有许多进一步研究的问题,比如针对肝脏数据源建立新的CNN模型以及针对肝脏纹理信息采用CNN进行分类实验等.本文主要针对肝脏CT影像数据和肝脏纹理信息进行分类实验,肝脏数据类别包括肝癌,肝囊肿,肝血管瘤,肝正常四类,由于数据中不同类别的样本数量差距较大,肝癌数据占比接近50%,因此设计了二分类和四分类实验.针对图像数据,本文主要采用VGG-16,Inception-V3,ResNet网络进行分类实验.在二分类实验中,网络参数采用随机初始和迁移学习两种方法,结果表明采用迁移学习准确率较高,但在四分类实验中,迁移学习不能够解决样本比例失衡问题,因此设计了新的卷积网络模型IRNet,能比之前的模型更好的适应样本失衡问题.在肝脏纹理信息的分类实验上,采用机器学习中的SVM,XGBoost和CNN进行对比实验,实验结果表明,CNN在二分类和四分类的分类性能明显优于机器学习模型,且在四分类实验中CNN模型能够适应样本不均衡的情况."
1634,基于机器学习的目标跟踪技术研究,"随着科学技术的发展,机器视觉已成为人类感知世界和获得重要信息的主要途径,目标跟踪是机器视觉的一个重要研究方向,被广泛应用于智能视频监控、医药影像复核、人机交互、全天气候侦察和军事应用等领域。在实际跟踪过程中,因为应用环境的复杂性、特殊性和被跟踪目标的类型多样性,出现了目标检测与跟踪算法鲁棒性差、难以长时间跟踪、稳定性差、实时性差、跟踪准确度低等问题。针对上述问题,本文对基于机器学习的目标跟踪技术展开了研究,主要研究内容如下:(1)一种基于Camshift与Kalman滤波的跟踪算法。针对Meanshift跟踪效果差、跟踪框无自适应性的问题,研究了Camshift与Kalman滤波结合的跟踪算法。为验证该算法对颜色的抗干扰性,对短视频进行了跟踪和分析。实验表明:Camshift与Kalman滤波结合后的算法跟踪效果较好,不受背景颜色干扰,未出现跟踪失效现象。(2)研究了TLD跟踪算法的理论知识、基本原理与算法特点,并通过实验分析算法的优缺点。在本文的模板匹配实验过程中,比较正负样本与耗时之间的关系时发现原TLD跟踪算法耗时较长。但对目标行人被遮挡的跟踪中,当目标发生尺度、形状变化和部分被遮挡且遮挡时间短时,TLD算法的跟踪性能高。(3)对原TLD算法进行优化。针对原TLD算法计算量大,当有相似目标出现、目标物被遮挡严重时,跟踪精确度低、效果差的问题,本文提出了优化算法――用Camshift算法代替原TLD算法跟踪器中的光流法。通过对行人的跟踪实验对比,发现优化的TLD算法,未发生迟滞现象,可以实现对遮挡较多、运动速度慢的运动目标准确跟踪。(4)结合Camshift与Kalman滤波的TLD跟踪算法。在对目标进行长时跟踪中,针对遮挡、运动速度快、相似目标物影响、光照变化等问题,本文采用结合Camshift与Kalman滤波的TLD跟踪算法。通过对David视频跟踪进行实验,发现本文算法成功率比原TLD算法高,跟踪效果好;视频帧中心位置误差最小,集中在20像素以内,在本文实验过程中跟踪的实时性与快速性好。为了验证本文算法的跟踪鲁棒性和实时性,本文以运动员的跟踪进行实验验证。实验结果表明:本文算法重叠度稳定,对运行速度比较快、相似目标物干扰、尺度变化严重、发生遮挡的目标跟踪鲁棒性强;中心偏移距离较低,说明本文算法跟踪效果好、实时性好。"
1635,复杂环境下全卷积神经网络在桥梁裂缝检测中的应用研究,"混凝土桥梁耐久性差、服务寿命短及全寿命经济性指标低等问题已成为普遍难题,因此,对在役桥梁结构性能评估的研究十分紧迫并具有现实意义。混凝土桥梁结构的初期损伤与破坏,首先都是在梁体结构中出现可见裂缝,而裂缝的出现及不断扩展将直接影响桥梁的整体性能。因此,对混凝土桥梁进行健康评估首先从裂缝的检测入手。本文以混凝土桥梁裂缝为研究对象,提出基于全卷积神经网络的混凝土表面裂缝识别方法,自动提取和计算混凝土裂缝的长度及宽度物理值,为在役桥梁结构安全和稳定性评估提供精确可靠的数据支持。(1)本文首先从混凝土桥梁结构裂缝的危害、成因和分类方法入手,对裂缝的物理特性进行分类研究,利用机器学习和深度学习中的经典算法对混凝土表面裂缝进行识别和分割。同时,设计复杂环境下混凝土桥梁底部裂缝图像采集系统,对采集的裂缝图像进行人工准确标记,为深度学习网络模型的训练准备数据集。(2)采用随机结构森林和卷积神经网络(CNN)经典机器学习算法进行裂缝检测。为了验证裂缝预测准确性,将裂缝识别结果与人工标记裂缝进行比较,并从识别精度和识别速度上分析比较传统算法的优缺点。在裂缝图像上寻找最优的检测算法。(3)以随机结构森林和卷积网络为研究模型的基础,对裂缝识别结果进行分析评价,提出一种全卷积神经网络(FCN)的裂缝识别算法作为本文研究模型。首先,通过输入复杂环境下多种类型的裂缝图像对FCN模型进行训练及超参数优化,针对不同特征的裂缝图像在像素级上进行语义识别和分割。然后,运用宽度为单像素的裂缝骨架来表示预测的裂缝分段,定量测量裂缝的形态特征,为实际评价提供量化指标,如裂缝拓扑、裂缝长度、最大宽度和平均宽度等。通过训练好的网络模型进行仿真实验,并与上述传统的机器学习算法对比,验证全卷积神经网络的混凝土桥梁裂缝识别方法的精度和效率。由于FCN模型改进了经典的VGG19卷积网络模型,使裂缝预测精度提高到了像素级,可以接受任意大小的裂缝输入图像,避免了使用图像分割块而带来的重复存储和计算卷积的问题,解决了输入裂缝图像尺寸问题和训练模型时间等问题,因此本文提出的FCN检测模型针对混凝土裂缝目标更加高效。"
1636,基于机器学习的信道译码算法研究,"通信系统中的信道编码系统通过对原始信息进行随机化并加入冗余信息的方式来增加信息传递的可靠性。过去的信道码译码算法多是通过纯粹的数学公式推导得出。由于如今人类掌握的数学工具的匮乏与计算机算力的限制,传统的信道译码算法往往需要对模型进行简化,对计算进行近似,这样处理的好处是在可接受的计算复杂度下完成译码,但同时也损失了准确度。当下机器学习算法在多种领域都有了可实用的表现,译码问题本质上可以看作是一个二分类问题来进行研究,其任务为将接受到的被信道污染的数据通过一个分类函数映射到0、1两个值上。本文研究内容为使用机器学习的方法对这个分类函数进行拟合,研究对象为5G通信中控制信道采用的polar码与4G通信中采用的turbo码。本文主要包括以下三点的创新:第一,针对现有polar码的SCL译码算法为串行译码算法,并行性较差的缺点,结合神经网络在层内可实现全并行的特点,本文提出一种针对polar码的全新的卷积神经网络译码器,该译码器利用polar编码时相异或的比特相关性更强的特性设计卷积核,使用七层神经网络可以获得与现有译码器相当的性能,但计算复杂度相比前人提出的全连接神经网络更低,且具有更强的泛化能力和更低的训练复杂度,能使用全连接神经网络千分之一的训练数据量获得与之相当的结果。第二,基于现有BP译码算法,结合循环神经网络,在BP迭代中引入隐藏参数权重,提出加权BP译码算法。本文提出的加权BP译码算法可以在10次迭代时达到传统BP译码50次迭代的性能水平,大大降低了多次迭代对BP译码算法造成的译码延迟。第三,结合BCJR译码算法中分量译码的思路,提出用两个相同结构的卷积神经网络拟合两个子译码器。分析turbo码中卷积编码器的编码过程,并据此设计卷积神经网络的卷积核。对比不同卷积核和卷积通道数对译码器性能的影响。"
1637,高效的贝叶斯推理电路设计及应用,"随着计算机技术与人工智能领域的不断发展,人们已经开始在各行各业中引入机器来取代人做出各种判决。而由于庞大的计算量与复杂的模型制约,人们也更愿意依赖计算机去完成规律的把握、因果关系的学习、甚至决策的判决。而对于学习推理问题中的不确定性,人们常将其转换成概率图模型求解。对于具有因果关系的不确定性问题推理的往往采用贝叶斯推理的方式进行求解。传统方法中对贝叶斯推理中求解概率问题的解析解仍然具有很高的计算复杂度,因此人们常通过随机采样的方式获得计算复杂度低的近似解。然而,采用传统处理器结构实现的采样模块仍具有较高的复杂度,因此本文设计实现了高性能、低复杂度的随机采样门电路来实现贝叶斯推理。首先,本文介绍了贝叶斯定理,随后推导了MC采样方法,包括逆采样方法、拒绝采样方法、重要采样方法等,然后也详细推导了MCMC方法,包括Metropolis采样法、Metropolis-Hasting采样法和Gibbs采样法,也在推导经典采样方法的同时也说明了各种方法的局限性,为后文的贝叶斯推理电路设计提供了理论基础。为了构建具有贝叶斯推理能力的系统,本文设计实现了随机采样门电路,并对每个采样门的结构详细进行了分析:对于设计的二元采样门电路可以在每个时钟周期完成一次采样,而即使是最复杂的标准化多项采样门可以在平均k个时钟周期完成一次采样。随后通过利用概率分布条件独立性的特点提出了并行采样和随机有限状态机的设计思想,从系统层面优化采样流程,使得系统的效率得以提升。随后本文介绍了基于MCMC方法的MIMO检测器,将设计的随机采样门电路应用于MIMO系统中,通过从概率分布中进行采样实现了MCMC-MIMO检测器的功能,在性能较全精度MCMC-MIMO检测器至多低1dB的基础上,随机采样门电路能以低消耗、高效率地完成逐比特及逐符号的MCMC-MIMO检测器功能。最后,本文将设计的随机采样门电路以软件仿真和FPGA实现的方式进行分析,给出了采样门电路的资源消耗。并通过RTL代码对Rain模型和Ising模型进行实现,完成了贝叶斯推理的功能。讨论了随机熵源和量化精度对随机采样门电路的影响:误差会随着熵源性能的提升得到改善,并且量化精度远低于传统全精度的程度时就已经能较精确的对分布进行估计,在量化位宽为5比特时估计得到的误差最高仅为0.026,而量化位宽为12比特时采样估计得到的误差最高仅为0.0017。基于随机采样门电路的大型系统能以更低的开销更高的效率执行。"
1638,深度神经网络硬件加速研究,"随着半导体工艺的不断进步,机器学习领域研究的深入,神经网络成为了近年来实现人工智能的重要机器学习算法之一。神经网络尤其是深度神经网络因其结构的复杂带来的计算复杂度的上升,使得单纯用中央处理器顺序串行执行耗时越来越长。这样不仅给网络的训练带来问题,也给对于实时性有一定要求的网络计算任务带来了问题。因此人们提出了各种各样硬件加速的方式。其中一种比较常见的硬件加速方式是取代了过去数字信号处理器而出现的现场可编程门阵列(Fieled Programmable Gate Array,FPGA)。FPGA以其比较好的并行性和灵活性以及开发成本相对较低等特性受到高校等研究机构的青睐,甚至在一些应用场景直接用于商用产品的开发。目前,大多数FPGA的加速主要针对复杂指令集计算机,即CPU以X86或AMD64为主的计算机,并通过PCIe接口与CPU交换数据和控制信息。并且目前大多数FPGA仅仅加速已经完成训练的神经网络,而不会加速网络的训练过程。为了达到最佳的加速性能,通常FPGA加速会针对特定的神经网络进行优化,使得神经网络的FPGA加速的通用性变差。本文提出一种基于ZYNQ的FPGA加速结构。它以ZYNQ内部自带的ARM(Advanced RISC Machine)作为主要计算核心,ZYNQ自带的FPGA作为神经网络的硬件加速部分,兼顾结构中软硬件的通用性和可扩展性,实现嵌入式神经网络的计算加速。本文提出的结构中,将神经网络中的全连接的矩阵乘法运算以及卷积运算放到FPGA上进行,而ARM负责流程控制,池化和激活函数的运算。本文结构在尽量满足通用性的前提下加速神经网络,因此本文结构中FPGA的互联采用标准的AXI系列协议,并且通过互联模块连接逻辑与处理器。本文中详细描述了关键的软件函数流程以及硬件加速电路的结构。并且在实现了整个结构后,通过LeNet-5手写数字识别网络对加速架构进行测试。在10000张MNIST图像的测试下,识别率在92%,使用FPGA加速前后效果不是特别明显,一张图片的处理时间仅仅减少了1%。"
1639,基于深度对抗学习和域迁移的空中手写识别研究,"近年来,随着硬件设备的高速发展和可穿戴、移动设备的广泛普及,空中手写(Air-Writing)逐渐受到国内外研究学者和工业界的广泛关注。空中手写,指的是在空中书写有意义的字符和字符串,转化为用户指令的人机交互方式。与一般体感手势相比,空中手写的表意更加丰富,与以鼠标、键盘和触摸屏为代表的传统交互方式相比,空中手写更加贴近人类的书写习惯。在空中手写的众多实现中,基于惯性传感器的空中手写凭借更高的自由度、更低的设备成本和更高的环境噪声抗性,在智能家居、医疗保健等领域有着广泛的应用前景。然而,惯性传感器信号的弱可读性和训练样本的稀缺限制了相关算法的研究和发展。基于以上观点与现状,本文针对基于惯性传感器的空中手写识别开展了研究,主要的贡献和工作包括:1.提出一种基于长短时记忆的识别模型和一种基于卷积网络的识别模型。卷积模型用条状卷积核适配传感器数据,用全卷积结构和均值池化层实现任意长度样本输入。在与传统模型的对比实验中,本文的两个模型在三个受限条件不同的空中手写数据集上均获得了更好的识别性能;2.针对数据可读性差的问题,本文提供了空中手写可视化的新思路,提出两种空中手写域迁移方法,包括基于全注意力机制的序列到序列有监督域迁移模型,和基于自编码隐空间对抗学习的无监督域迁移模型,实现了加速度角速度信号与空间轨迹的双向迁移;3.针对空中手写样本稀缺问题,本文提出一种基于特征图位置编码和深度对抗学习的样本增强方法,生成类别和长度可控的、具有可靠质量和一定多样性的样本,样本以伪标签半监督训练的形式提升了模型的分类性能。"
1640,基于情感词典的中文微博情感分析与话题倾向性判定研究,"微博具有用户多、消息数量大、更新快等特性,已成为人们获取信息、发表舆论的重要途径。针对微博的情感分析能够获取用户对特定话题的观点,从而挖掘微博背后隐藏的价值。对微博用户发布的内容进行情感分析,最大程度还原用户真实情感,将有助于政府控制社会舆论走向,有助于用户优化自身的购买决策,有助于企业有针对性地进行自我改进,提升市场竞争力。近年来,网络中不断涌现的网络流行语给中文微博情感分析带来了挑战:首先,微博中大量的网络流行语表达了用户态度分明的情感,而现有的情感词典大多并不包含网络流行语;其次,现有的分词工具不能正确识别网络流行语,从而降低了微博分句、分词的准确度;最后,网络流行语具有时效性,其时效性随着热度的增强或减弱,因此需要实时对网络流行语词典中的网络流行语进行添加和删除。综上所述,构建可实时更新的网络流行语词典是微博情感分析的关键。此外,现有的中文情感词典大多是将情感词汇简单地分为正向和负向,然后运用相应的语义规则获取中文文本的情感极性。但是,人们对于事物的情感态度往往不是简单纯粹的,而是复杂多样的。微博用户对于特定话题的情感态度不能只停留在好与坏的层面,而应尽可能对情感类别细分,才能真实地还原人类的情感。因此,传统的正向、负向二分类情感分析方法已不适用于句式多样、词汇多样的微博情感分析了。针对以上两个问题,本文探索了实时获取和更新网络流行语的机制,并提出了一种构建细粒度情感词典的方法。基于以上两点工作,实现了微博文本情感的细粒度分析和微博话题的倾向性判定,主要研究内容如下:(1)网络流行语词典的构建:选择百度、搜狗输入法提供的网络新词作为构建网络流行语词典的候选词库,通过微博语料对候选词进行筛选获取网络流行语,并使用基于拉普拉斯平滑改进的SO-PMI判定其情感极性。将已构建的网络流行语词典与其他词典资源合并整理后,最终组成了包含网络流行语词典的微博领域情感词典。(2)基于微博领域词典的微博情感分析:首先根据已构建的微博领域情感词典计算微博句子的情感极性,然后引入中文问号、句号以及含语气网络流行语的对微博句子的情感极性进行修饰,最后引入微博句子的位置系数获取整条微博的情感极性。(3)微博话题倾向性的细粒度情感分析:通过基于《知网》语义的词语相似度计算方法将情感词典中的词语分为7类,并根据相似度的值为情感词语定义1-9的情感强度,与大连理工大学情感词典合并后构成了细粒度情感词典,最后实现了微博话题的细粒度情感分析。实验结果表明,本文所构建的网络流行语词典有效提高了分句、分词的准确度,也提高了微博情感分析的准确性。基于《知网》语义相似度计算方法所构建的细粒度情感词典可以实现对微博话题倾向的判定。"
1641,基于特征融合的时间序列预测方法研究与实现,"时间序列预测通过对事物历史数据的分析来预测未来一段时间的发展趋势,广泛应用于气象、农业等各个领域。由于时间序列数据具有数据量大、非线性、影响因素众多的特点,使得时间序列预测成为了研究难点。时间序列预测方法主要有传统的时间序列预测方法和基于机器学习的时间序列预测方法。其中传统的时间序列预测方法主要是基于统计学理论,建模技术单一,预测精度不高。基于机器学习的时间序列预测方法不仅提高了预测的精度,而且泛化能力强。虽然目前有许多基于机器学习的时间序列预测方面的研究,但是仍有一些需要解决的问题,特征提取就是其中之一。目前在特征提取方面主要有两个问题:一是特征提取方式。特征提取的方式主要是人工,该方式具有一定的主观性和不完备性;二是有效特征的选择。特征的质量直接影响了建模的水平,特征数目较多时如何选取出有效特征,这也是机器学习的研究热点之一。本文针对这两个问题,提出了一种将人工特征和基于深度学习生成的隐性特征相融合,并将融合后的特征集植入集成学习算法进行预测的方法。该方法使用改进的卷积神经网络自动提取隐性特征,然后将隐性特征与人工特征融合形成总特征集,最后利用随机森林从中选取有效特征后植入LightGBM算法中进行有监督的训练。基于所提出方法,本文使用两种时间序列数据进行验证,分别建立了汽车上牌量预测和农产品价格预测,与其它预测方法的对比结果显示该方法预测准确度更高,表明了该方法的可行性和有效性。"
1642,面向大规模GPS轨迹数据的并行化地图匹配方法研究,"轨迹数据挖掘是当前智能交通领域的一个研究热点,其中路径导航、交通出行行为分析等研究需要含有路段信息的轨迹数据。而出租车车载GPS装置采集到的GPS轨迹数据中无车辆所属路段信息,且轨迹点的经纬度坐标有误差。地图匹配算法可以在路网数据中匹配到轨迹点所属的路段,从而对该轨迹点的经纬度坐标进行校正。因此,地图匹配方法研究是轨迹数据挖掘中一项必要的基础研究内容。传统的面向GPS轨迹数据的地图匹配方法通常主要考虑匹配结果的准确度,而忽视了匹配效率。而随着机动车数量的快速增长,轨迹数据呈现出爆炸式增长的趋势。在此情况下,传统地图匹配方法匹配效率低下,大规模轨迹数据的地图匹配效率问题亟待解决。因此,本文提出一种面向大规模GPS轨迹数据的并行化地图匹配方法。本文的主要研究内容如下:(1)大部分地图匹配算法根据当前轨迹点在各路段的投影距离是否小于预设的距离阈值来判断该路段是否属于当前候选路段集合,在面对大规模轨迹数据集和大范围路网时,上述候选路段集合选取方法比较低效。提出一种基于GeoHash编码的分布式网格地图索引方法,该方法能够有效提升候选路段集合选取的效率。(2)面对海量的车辆轨迹数据,传统的地图匹配算法的计算效率已经无法满足相关研究工作的需要。为改善这一问题,提出了一种并行化地图匹配方法。并提出了一种基于时间标签的分区策略,有效改善了并行地图匹配中的数据倾斜问题。实验结果表明,所提方法在保证较高准确度的条件下,匹配吞吐率可达到8.54万条/秒。相对于文献中提出的一种基于Hadoop的并行化地图匹配算法,其运算速度提高了约33倍。(3)研究内容2所提的并行化地图匹配算法不能解决实时轨迹数据流的地图匹配问题,基于Structured Streaming计算模型,进一步提出了一种面向大规模轨迹数据的在线式地图匹配方法,在保证具有一定实时性的条件下,实现了地图匹配的流式处理。(4)提出了一种基于集成学习的出租车乘客候车路段推荐方法。首先,统计一定时间间隔内西安市各个路段上空载出租车的分布数量;然后,利用集成学习方法对西安市各路段未来一个时隙内空载出租车的数量进行预测;最后,根据预测结果为即将出行的乘客推荐最佳候车路段。"
1643,基于深度学习的空气质量预测模型分析研究,"近年来,随着我国经济的快速发展以及城市化进程的快速推进,空气污染问题愈发的严重。空气污染不仅严重影响人们的日常生活和身心健康,同时对社会的可持续发展也带来了巨大的阻碍,已经引起了社会各界的高度重视。因此,对空气质量进行精确的评价与预测具有重要的现实意义和社会价值。随着大数据和人工智能技术的兴起,传统的空气质量预测方法已经不能满足对大数据进行智能化处理的需求,许多学者开始基于大数据,利用智能化的方法对空气质量进行评价与预测。深度学习是人工智能技术的重要分支,具有强大的特征提取和数据拟合能力,在图像识别和分类预测等方面具有广泛的应用。鉴于此,本文将深度学习引入到空气质量预测中,用西安市2013年11月至2019年2月的空气质量监测数据构建训练样本库,以深度信念网络(DBN)和自动编码器(AE)为基础,构建了DBN、DBN-ELM和DAE-BP三个基于深度学习的空气质量预测模型。主要研究内容如下:(1)通过对国内外相关文献的调研,选取CO、NO_2、SO_2、O_3、PM_(2.5)、PM_(10)六种污染物作为空气质量预测模型的评价因子,空气质量指数(AQI)作为模型的目标变量。(2)对本文原始试验数据集进行清洗和填充等预处理操作,构建空气质量预测模型训练样本库。(3)针对传统的回归模型和浅层机器学习算法在空气质量预测中的不足,本文利用深度信念网络强大的特征提取能力,构建了一种基于深度信念网络(DBN)的空气质量预测模型,试验结果表明,本文构建的模型相比传统的预测算法有着更好的预测效果,验证了深度信念网络在空气质量预测上的有效性,为空气质量的预测研究提供了新的思路。(4)针对传统的深度信念网络(DBN)在特征提取与参数训练存在的不足,将交叉熵稀疏惩罚因子机制引入到DBN的特征提取过程中,将DBN与ELM算法进行结合,提出了一种基于DBN-ELM算法的空气质量预测模型。试验结果表明,本文构建的方法相比传统的深度信念网络与传统的浅层机器学习预测算法有着更好的预测效果。(5)将深度自动编码器(DAE)和BP神经网络相结合,构建了一种基于DAE-BP算法的空气质量预测模型。首先将多个自编器(AE)堆叠在一起构建深层特征提取器(DAE)逐层的对空气质量数据集进行特征提取;然后将提取的特征输入到BP神经网络,用自编码器网络的权值来初始化BP神经网络;最后通过BP神经网络的反向传播算法对模型进行参数的调节和优化,实现空气质量的准确的预测。试验结果表明,DAE-BP模型相比与传统的浅层机器学习预测算法有着更好的分类预测效果,证明了深度自编码器模型在空气质量预测中的有效性。本文构建的DBN、DAE-BP、DBN-ELM三个基于深度学习的空气质量评价预测模型,为空气质量预测提供了新的思路,为空气污染的治理和人们日常生活的指导提供了新的理论依据和预测方法。"
1644,基于机器学习方法的高光谱数据分类对比研究,"当今世界,机器学习相关技术的应用领域正在迅速扩大,数据处理与信息分析的技术也发生了翻天覆地的变化,影像数据的分类效果也因此能够得到显著的提高。以往的高光谱或多光谱图像分类与识别,往往只关注像元光谱维上的特性,其特征统计也只在光谱上进行展开。由于自然界的复杂性、混合像元问题的存在,仅靠像元的光谱特性是不够的。在高光谱遥感图像监督分类过程中加入空间特征信息,可有效提高分类结果的速度与精度。本研究将两种空间信息的提取方法与极限学习机(ELM)和支持向量机(SVM)结合,对两种机器学习分类方法加入空间特征信息前后的分类结果进行时间与精度的综合评价与比较分析。本文选取了经典的ROSIS传感器的意大利帕维亚大学以及Hyperion传感器的博茨瓦纳奥卡瓦纳三角洲的高光谱遥感数据作为试验数据;同时,为了试验机器学习方法在地质找矿当中的应用前景,还选取了美国内华达赤铜矿AVIRIS高光谱遥感数据进行试验。经影像预处理、训练样本选取、光谱特征分析,分别运用两种分类方法对数据集进行分类实验;之后将光谱特征与空间特征结合对数据进行分类试验。本文主要的研究内容和结论有以下这些方面:(1)利用支持向量机(SVM)与极限学习机(ELM)两个分类方法,对采集于两种不同传感器、具有不同地表覆盖类型的高光谱数据集进行实验,对数据进行光谱特征分析,并与分类结果进行对比,证实了不同类别之间的光谱曲线特征相似度较高,将会增大数据集的分类难度,并对类别的分类精度结果产生不良影响。(2)基于梯度图像的直接分水岭算法容易导致图像的过分割,产生这一现象的原因主要是由于输入的图像存在过多的极小区域而产生许多小的集水盆地,从而导致分割后的图像无法把图像里有意义的区域体现出来。所以应当把分割结果的相似区域实施合并。(3)运用多数投票法将光谱和空间分类结果进行合并,其结果中很多离散点被指定为邻域值,提高了分类精度。另一个效果是类别间的边界平滑了,解决了分类精度差异常出现在这些边界点上的问题。(4)运用混淆矩阵方法对实验结果进行对比分析,可以看出,将基于光谱特征的分类结果与空间特征相结合,可以有效提高两种算法的分类精度。同时在分类时间、精度方面,对于两个研究区,极限学习机(ELM)均优于支持向量机(SVM)。"
1645,低空空域无人机入侵检测研究,"近年来,随着低空空域的逐渐开放,无人机逐渐从军用领域逐渐扩展到民用领域,在带来便利的同时,也导致了“黑飞”、“滥飞”事件的频发,严重危害公共安全和个人隐私。因此,对低空空域无人机入侵检测的研究在反恐、治安管控、安全生产方面具有重要意义。本文对基于视觉的无人机检测技术进行了较为深入的研究,提出了一种基于天空区域的无人机检测方法,并按摄像机的运动状态分为静态场景的无人机检测和动态场景的无人机检测。本文的研究内容包括:1.静态场景的无人机检测:静态场景下常用帧间差分法、光流法、背景差分法等对运动目标进行检测。本文先根据天空区域的灰度平坦、面积大、亮度高等特点,采用基于边缘检测的图像分割算法和行列扫描法对图像进行分割,得到天空区域的最小外接矩形;之后通过运动目标检测算法对矩形框内的天空区域进行无人机检测。基于系统的可行性考虑,本文采用Simulink搭建仿真系统进行实验验证,结果显示本文方法可有效提高无人机检测的精确率,解决地面运动目标带来的误检问题。2.动态场景的目标检测:动态场景目标检测方法有背景补偿、机器学习、深度学习等。为了实现无人机的智能监控,本文首先构建了基于全卷积网络的天空区域分割网络,实现了天空区域像素级别的分割;然后构建了基于FastBox的无人机检测网络,实现了无人机的准确检测。实验结果表明,基于深度学习的天空区域分割网络和无人机检测网络能够准确地实现对天空区域的分割和无人机的检测,并且满足实时性需求。最后,开展了天空区域和无人机检测网络的融合研究,通过共享卷积提取特征,并在深度特征图后连接天空区域和无人机检测网络,最终在一个模型中,实现天空区域和无人机的同时检测。"
1646,优化卷积神经网络模型在隧道探地雷达实测数据分类中的研究及应用,"随着我国高速公路建设的加快,施工中隧道地质超前预报是施工安全保障的重要手段之一,其中探地雷达(Ground Penetrating Radar,GPR)图像的判读是隧道地质超前预报中的关键步骤,如何提高探地雷达图像判读准确率一直是该领域的研究热点。本文结合卷积神经网络在图像识别中的优势,研究并实现高效的隧道GPR图像分类模型,并对卷积神经网络模型压缩做了相关研究。在实际工程中,隧道GPR图像存在复杂多变,难以识别等问题,所以传统的机器学习方法很难有效提高对GPR图像的识别准确率。因此,本文采用迁移学习和数据扩增的技术改进了典型VGG-16(Visual Geometry Group-16)网络模型,旨在使用较少的标记样本充分训练卷积神经网络,以有效提高模型对隧道GPR图像的识别准确率。并在此基础上进一步研究发现,基于迁移学习改进的VGG-16网络模型存在模型体积庞大、预测时间久等问题,不利于将该网络模型部署在嵌入式设备中。因此,本文在研究相关模型压缩技术后,采用通道剪枝和权值量化的方式对改进的VGG-16网络模型进行优化。首先,迁移学习阶段使用VisTex纹理数据库作为源域数据,在Caffe平台、GPU加速计算下对VGG-16网络模型进行预训练,接着再使用6000多幅实测隧道GPR图像对网络模型进行微调。然后,模型优化阶段使用基于泰勒展开的通道剪枝和权均值得三值量化方法对改进的VGG-16网络模型进行优化。实验结果表明:基于迁移学习改进的VGG-16网络模型识别准率高达97.54%,经过优化后VGG-16网络模型体积压缩近77.35%,预测时间缩短3.6倍,而识别准确率仅下降1.73%,并且优化后网络模型可以获得较好的鲁棒性。"
1647,基于海量出租车轨迹数据的学习与预测,"随着我国城镇化进程的不断加快,城市常住人口与流动人口逐年增长,出行交通需求与日俱增,然而城镇路网建设周期较长,交通供需矛盾日益突出。与此同时,随着智能交通系统(Intelligent Transportation Systems,ITS)的广泛部署,多种感知设备实时测量行人、车辆和路网数据,尤其是便携式GPS设备的普及,给交通管理和居民出行带来诸多便利。海量的GPS轨迹数据蕴含丰富的时空信息,为分析城市主干道拥堵问题,研究居民出行规律和合理规划出行提供了数据保障。本文采用机器学习中的聚类分析和深度神经网络的最新研究成果,充分学习和挖掘轨迹数据的深层非线性特征,主要从以下三个方面展开研究:第一:研究城市主干道拥堵问题。首先,利用热点聚类方法判别城市拥堵热点区域,实验结果表明西安二环是最为拥堵的路段。其次,从城市车辆增长和私家车尾号限行政策两个方面,分析二环道路拥堵的时空分布特征,为判别交通拥堵提供新的视角。第二:研究居民出行的出租车需求问题。首先,利用西安市出租车GPS轨迹数据,并结合节假日,天气条件和空气质量等外部数据,采用基于卷积神经网络(Convolutional Neural Network,CNN)和长短期记忆网络(Long Short-Term Memory,LSTM)的模型以及残差网络(Resnet)的混合深度学习模型(CNN-LSTM-ResNet,CLR),预测居民出行的出租车服务需求。混合模型首先使用CNN提取城市范围的交通流量的空间特征,其次引入残差单元加深网络层数,然后利用LSTM提取GPS数据的临近性、周期性和趋势性,最后通过权重融合以上三个分量,再与外部数据进一步融合,从而预测城市特定区域的出租车需求量。与传统的预测模型比较,实验结果表明混合模型有更高的预测精度,因此该研究结果可用于交通管理部门平衡供需。第三:研究在已知出发终点(Origin Destination,OD)位置,和相应出发时间,预测出租车乘客出行所需时间。首先,针对网格方法不能区分多层立交桥区域不同高度道路的交通流问题,本文提出一种基于交通分析小区和路网嵌套的OD流细粒度表示方法,将OD流的表达细化到路网级别。然后,验证了居民的出行时间与出行频次呈正相关,并设计了一种混合深度网络的模型(convLSTM-Conv2DTranpose-SeparableConv-2D,CLTS)来预测城市范围出租车乘客的出行时间。模型先采用convLSTM模型学习OD流的时空特征,然后针对细粒度OD流的稀疏性问题,使用转置卷积网络(Conv2DTranspose)捕获数据的稀疏特征。最后,使用可分离卷积网络(SeparableConv-2D)逐点卷积出行时间OD矩阵和出行次数OD矩阵的空间位置关系。本章采用西安市出租车数据进行分析,实验表明与传统预测模型和现有的深度学习模型相比,该模型具有更小的均方根误差(Root Mean Squared Error,RMSE)和平均绝对误差(Mean Absolute Error,MAE)。"
1648,川东平行岭谷区土壤养分数字化制图研究,"耕地质量评价涉及国计民生,影响甚广。《耕地质量调查监测与评价办法》中要求每5年定期发布耕地质量等级信息,以保证全面和及时地了解耕地质量状况及其变化情况。土壤养分作为耕地质量评价中重要的一环,准确高效地预测土壤养分的空间分布,不仅可以为耕地质量评价提供基础数据,也可以为土壤养分空间分布预测提供理论参考。以位于川东平行岭谷区中心的重庆市长寿区作为研究区域,综合考虑植被因子(归一化差异植被指数)、气候因子(年降水量、年均温)、地形因子(高程、相对坡度位置、沟谷深度、地形湿度指数、垂直到沟谷距离)、成土母质四类环境变量,评价空间插值方法(普通克里格、反距离权重)、机器学习方法(分类回归树、随机森林)和混合地统计学方法(随机森林残差克里格)预测研究区内十种土壤养分(土壤pH值、土壤有机质、碱解氮、有效磷、速效钾含量,各5162个样点;土壤有效硫、有效铜、有效铁、有效锌、有效硼含量,各316个样点)空间分布精度,并使用随机森林分析影响研究区土壤养分空间变异的主要因素。最后选择预测精度最优的模型对研究区土壤养分的空间分布进行制图。主要研究结论如下:(1)研究区土壤pH值(5.90±0.86)总体上呈酸性,土壤有效磷(20.38±11.68 mg/kg)、有效硫(49.39±61.65 mg/kg)、有效铜(2.18±1.28 mg/kg)、有效铁(98.62±69.45 mg/kg)和有效锌(1.60±0.91 mg/kg)含量处于丰富水平,土壤有机质(17.46±5.89 g/kg)、碱解氮(59.57±15.76 mg/kg)和速效钾(69.49±21.59mg/kg)含量处于中等水平,土壤有效硼(0.31±0.21 mg/kg)含量处于较缺水平。土壤养分变异系数在14.58%-124.83%之间。除土壤有效硫含量为强烈变异外,其余均为中等程度变异。(2)土壤pH值、土壤有机质、碱解氮、有效磷、速效钾、有效硫、有效铜、有效铁、有效硼含量在不同类型成土母质中存在显著差异(P<0.01),相关系数分别为-0.17、-0.57、-0.25。土壤有机质含量与土壤有效硫、有效铜、有效铁、有效锌、有效硼含量均呈极显著正相关关系(P<0.01),相关系数分别为0.47、0.67、0.36、0.26、0.43。(4)研究区土壤养分在空间上存在中等或强烈空间自相关性。土壤pH值和土壤有效硼含量的块金效应分别为27%和50%,属于中等程度空间自相关;土壤有机质、碱解氮、有效磷、速效钾、有效硫、有效铜、有效铁和有效锌含量的块金效应均小于25%,属于强烈空间自相关。(5)运用随机森林计算环境变量在土壤养分预测模型中的相对重要性。结果表明,对预测土壤养分空间分布最重要的三个环境变量依次为:土壤pH值受成土母质、年均温和沟谷深度影响最大;土壤有机质含量受年均温、高程和沟谷深度影响最大;土壤碱解氮含量受年均温、沟谷深度和植被指数影响最大;土壤有效磷含量受沟谷深度、年降水量和年均温影响最大;土壤速效钾含量受年均温、沟谷深度和植被指数影响最大;土壤有效硫含量受土壤有机质含量、土壤pH值和植被指数影响最大;土壤有效铜含量受土壤有机质含量、植被指数和年均温影响最大;土壤有效铁含量受土壤pH值、土壤有机质含量和沟谷深度影响最大;土壤有效锌含量受土壤pH值、土壤有机质含量和地形湿度指数影响最大;土壤有效硼含量受土壤有机质含量、沟谷深度和植被指数影响最大。由此可见,对于土壤pH值、土壤有机质、碱解氮、有效磷、速效钾含量,年均温和沟谷深度表现出普遍的重要性;对于土壤有效硫、有效铜、有效铁、有效锌和有效硼含量,土壤pH值和土壤有机质含量表现出普遍的重要性。(6)使用五种模型分别对十种土壤养分的空间分布进行预测并比较其精度,结果表明,不同土壤养分的最优预测模型存在差异。其中,土壤pH值、土壤有效磷、速效钾含量的最优预测模型为反距离权重,其决定系数分别为0.87、0.61和0.81;土壤有机质、碱解氮含量的最优预测模型为普通克里格,其决定系数分别为0.80和0.69;土壤有效硫、有效铁和有效锌含量的最优预测模型为随机森林,其决定系数分别为0.18、0.63、0.38;土壤有效铜含量的最优预测模型为分类回归树,其决定系数为0.34;土壤有效硼含量的最优预测模型为随机森林残差克里格,其决定系数为0.25。由此可见,对于样点数量较多的土壤养分,空间插值方法的预测精度更高;对于样点数量较少的土壤养分,机器学习方法和混合地统计学方法的预测精度更高。"
1649,基于深度学习的心律失常分类研究及应用,"心电图是医生用于进行心脏疾病诊断和治疗的重要依据,而判读心电图通常依赖于医生的主观意见和经验。随着患者的增多,医生们每天要诊断的心电图的数量是巨大的,这非常容易造成疾病的误诊,同时依靠人工识别心电图往往缺乏实时性,有可能会耽误患者治疗的最佳时机。因此,将基于深度学习的心电信号自动分析识别技术应用到心脏疾病科学研究中,在减轻医生的工作量的同时能够提升诊断的准确程度,这在临床应用中将会对心脏病的诊断和治疗产生巨大的价值。本文采用麻省理工学院的心律失常数据库(MIT-BIH数据库)进行信号预处理和自动分类研究。先用小波变换对心电信号进行尺度分解,并选取合适的阈值和阈值函数对心电信号中三种主要噪声(基线漂移、肌电干扰和工频干扰)进行去噪。再将去噪之后的心电信号以R波为轴,分别向前向后共取256个点,获取一个心拍样本,对获取的心拍样本进行Wigner时频变换,将一维信号转变为二维图像。最后采用LeNet-5和VGGNet-16两种卷积神经网络模型对图像进行识别分类,并且对模型分别进行改进,在经典的LeNet-5的基础上增加一层卷积层和池化层,并分别增加三个卷积层上的卷积核个数为32、64和128,并选取合适尺寸的卷积核;为了模型能够从数据中提取更加抽象、有辨识度的特征,在VGGNet-16基础上,在卷积层模块5上增加一层卷积层,并增加卷积层模块5上卷积核个数为700,进行实验对比。本文选取七类共16246幅心拍时频图作为数据集,最终得到原始的LeNet-5模型的分类准确率为63.75%,改进后的LeNet-5模型的分类准确率为92.48%,VGGNet-16网络模型对数据的分类准确率为97.43%,比改进的LeNet-5模型识别率高出5个左右的百分点,VGGNet-16改进1模型的分类准确率为97.9%,VGG-16改进2模型的分类准确率为98.9%。最后给测试集数据加不同强度的高斯白噪声,结果表明信号的信噪比越低,识别准确率越低,当信噪比为25-17dB时,改进后的LeNet-5模型准确率变化不大,当信噪比小于17dB后,准确率开始快速下降,最终为62.79%;VGGNet-16模型和改进后的VGGNet-16模型在25-13dB时,准确率下降很缓慢,而当信号信噪比小于13dB后准确率快速下降,最终分别为70.95%和75.26%。"
1650,基于双鉴别器的条件生成对抗网络图像去模糊方法研究,"图像在拍摄过程中可能受到多种因素影响导致模糊不清,而图像的清晰度是人们评价图像的重要前提,因此图像去模糊也是一个重要的研究课题。传统图像去模糊方法首要任务是图像模糊核的估计,但因自然图像模糊类型很多,对模糊核的估计造成很大困难,影响去模糊效果。因此本文采用端到端的思想,利用双鉴别器的条件生成对抗网络来提升模糊图像的清晰度。主要研究工作总结如下:(1)原始生成对抗网络的结构由一个生成器和一个鉴别器构成。生成器捕捉真实数据样本的潜在分布,并生成新的数据样本,以欺骗鉴别器为目的;鉴别器是一个二分类器,通过分析图像中的各个像素,鉴别所输入图像来自真实数据的样本分布还是来自生成器生成的数据样本分布。(2)本文以原始生成对抗网络的思想为基础,采用双鉴别器的设计,生成器与两个鉴别器的网络结构分别构建,并给予两个鉴别器不同的损失计算方法,因此两个鉴别器具有不同的优化目标。第一个鉴别器更侧重于真实的数据样本分布,若样本来自真实分布则给与该鉴别器较高的“奖励”,第二个鉴别器更侧重于生成器生成的数据样本分布,若样本来自生成的分布则给与该鉴别器较高的“奖励”。在网络学习的过程中,两个鉴别器同时与生成器做对抗训练,生成器所生成的数据样本要同时欺骗两个鉴别器,对于其生成的样本质量要求更高。该方法在改善图像清晰度的同时,也可一定程度上提升网络模型的泛化性能。(3)网络模型构建完成后,将对其进行训练,在训练的过程中根据具体情况适时调整相关参数、网络结构以及优化器类型,然后重新训练,以达到改进训练效果的目的。(4)模型训练收敛后对其去模糊效果进行测试,并与类似方法的去模糊效果做了对比分析。测试时除了对测试集中数据样本的测试,还加入了对实际拍摄图像以及网络搜索图像的测试。测试结果表明,本文方法与类似方法的去模糊效果相比,无论从客观评价法中PSNR及SSIM的测试数据还是从主观层面来看,本文所用方法的效果相对来说都更好,证实了本文所用方法的可行性。"
1651,基于机器学习的共享单车需求量预测模型研究,"自行车一直是城市交通中的一种重要工具,随着移动互联网时代的蓬勃发展,共享单车在城市交通出行中开始盛行,它在方便人们出行的同时也促进了共享经济的发展。但是不合理的投放对单车资源、厂家的经济利益以及城市市容都会造成很大的影响。本文通过对共享单车使用量的数据进行分析,设计了共享单车需求量的组合预测模型,通过预测单车的需求量指导单车的合理投放。主要的工作包括:对原始数据进行数据预处理并进行可视化分析,初步获得影响单车使用量的影响因素。在此基础上,通过向后移除法筛选特征,并结合可视化分析结论确定了最终构建模型所需要的实验数据。对传统预测算法进行了研究,重点研究了梯度提升(GBDT)算法、随机森林算法和BP神经网络算法,并使用之前确定的实验数据进行了单项预测模型的实践,实验结果表明,同一特征在GBDT预测模型和随机森林预测模型中其重要性是不同的,气温对单车需求量的影响最大,三个单项预测模型的R方值相近,预测准确度都有很大的提升空间。在此基础上,将三个单项预测模型进行组合设计了两种组合预测模型,一种是以预测误差绝对值之和达到最小的线性组合预测模型,另一种是以BP神经网络进行组合的非线性组合预测模型,对模型进行试验发现,两种组合预测模型准确度较单项预测模型都有提高,但非线性组合预测模型的预测效果更好,主要因为线性组合中的线性关系在某种程度上限制了组合模型的优化程度,组合模型中单项预测模型之间的关系具有一定的复杂性,不只是线性关系,而BP神经网络在满足线性关系的同时能够挖掘到其非线性的信息,使得模型的效果更好,其R方值较线性组合预测模型提高了0.02。因此,将以BP神经网络进行组合的非线性组合预测模型作为最终的共享单车需求量预测模型。"
1652,基于协同生成对抗网络的人脸补全与置换,"生成对抗网络是在2014年由谷歌大脑研究员Ian Goodfellow等人首先提出的基于博弈论思想的模型,它在机器学习领域得到了众多研究者的关注。在计算机视觉领域,生成对抗网络对于缺失区域的图像补全有着广泛的应用前景。通过分析基于生成对抗网络的现有研究成果,同时查阅图像修复及人脸置换等传统实现方法,本文利用搭建改进的生成对抗网络,采用卷积神经网络构建生成器与判别器,结合相关的图像处理工具,先后完成人脸补全和人脸置换两大任务。通过大量科学系统的实验,同时结合客观性的评价指标及具有代表性的调查方法,证实了搭建网络在处理以上任务中的良好性能。受到深度卷积生成对抗网络的启发,本文先后开创性地搭建了改进的深度卷积生成对抗网络、改进的基于Wasserstein距离的生成对抗网络,分别进行了人脸补全的实验,比较了两种模型在不同训练迭代次数下的人脸补全性能。同时,针对补全还原度不够高的问题,提出了协同生成对抗网络,利用两个生成器分别就图像的整体轮廓和局部区域生成真实样本,通过有逻辑性的大量实验,证明该网络在人脸补全上的表现比前两种改进的模型在性能上提升了至少30%。另外,还创造性地提出了基于交叉熵和像素均方差相结合的损失函数,使得协同生成对抗网络在处理大面积遮挡的人脸补全问题时性能提升了至少50%。本文最后还通过卷积层间的参数共享机制,创造性地提出利用协同生成对抗网络实现了人脸置换,证实了该模型在人脸置换中的有效性和合理性。"
1653,基于机器视觉技术的智慧城市人流量统计系统设计与实现,"随着机器视觉技术不断的发展,监控摄像头的覆盖范围越来越广泛,对于智慧城市公共场所的人流密度进行实时统计与跟踪也得到了广泛的研究和应用。也可以对特色景点和公园等人流密度较大的公共区域进行人数统计,可以准确的掌握当前区域的游客数量,有利于避免踩踏及偷窃等多种不良事件发生,同时也可以合理的减少游客排队等候的时间和环节公共设施的使用压力。基于机器视觉的智慧城市人流量的统计能够更好的服务群众、减少安全隐患、增加管理效率。本文对于基于机器视觉的人数统计系统设计主要分为三大部分:基于混合高斯背景建模的运动行人目标的检测及提取、基于深度学习的人头目标检测以及基于改进卡尔曼滤波的多目标跟踪。通过对行人人头目标的检测与跟踪,实时的统计行人的进出入数量。首先,使用了混合高斯背景建模的方法对监测环境背景进行建模,实现了对于监测环境中所有的静态目标和有规律运动的非行人目标进行分析,统一建模;之后,比较了三种运动目标的检测方法的优缺点,并选取了背景差分法检测提取所有包含行人的运动目标区域;最后,采用了形态学图像滤波算法对检测到的运动区域进行了进一步的处理,剔除和缩小了提取出的运动目标区域,减少了人头目标检测的工作量,降低了对伪行人目标的误检率。然后,采用了基于深度学习特征提取实现行人头部检测。为了更好的检测到运动行人的人头,监控摄像头必须采用中置放置的方式。本文采用真实视频制作了人头检测数据集,并提了结合训练模型进行数据标注的方法。本文还对基于深度学习的目标检测算法Faster-RCNN、RFCN、SSD算法进行测试比较,最终选取ResNet101+RFCN网络结构作为本文的人头检测算法。最后,提出了结合卡尔曼滤波和Mean Shift算法的方法,对监测场景的行人进行了运动跟踪计数。将卡尔曼滤波的结果作为Mean Shift算法的初始输入值,对运动目标进行跟踪,有效的减少了因为短时间的遮挡或者干扰造成的跟踪目标丢失现象,提高了跟踪效率。在计数方法中,在监控环境中设置虚拟线框,并且根据行人通过虚拟线框时,执行计数,并且根据通过虚拟线框边线的先后顺序判断方向。"
1654,基于Spark的线缆制造大数据平台研究与实现,"工业4.0时代,全球生产制造行业飞速发展,生产制造过程产生的数据也一直呈现指数级别的增长。企业也在逐渐重视对这些数据的利用。而如何高效的利用工业大数据促进企业生产制造的网络化和智能化,是目前制造企业面临的挑战之一。本文就是为更好利用生产制造中的大数据,进行的线缆大数据平台的设计、搭建与应用研究。通过分布式系统架构Hadoop、大数据处理框架Spark搭建大数据平台以及改进的K-Means聚类算法,设计实现了大数据平台数据处理方案。本文所做的工作主要有以下几点。(1)大数据平台技术的研究与大数据平台的搭建。本文通过深入研究Hadoop和Spark技术在大数据平台上运用的优缺点,设计基于Spark on Yarn模式的线缆行业大数据处理平台SCP(Spark on Yarn Cable Big Data Platform),该平台具有稳定、高可靠、快速,维护成本低,资源利用率高等优点。并通过Flume集成Kafka搭建了可扩展、容错、快速、稳定的数据收集系统。(2)大数据处理技术研究,K-Means算法的研究和改进。研究了Spark核心组成技术Spark Streaming,并完成了数据的清洗规整。同时讨论了Spark的另一核心组成技术Spark MLlib,并就其支持的聚类算法进行了深度的剖析。分析了K-Means算法的实现原理,利用聚类算法易受离群值干扰和难确定K值等缺点,以及善于处理高斯分布型数据的优点,使用特征缩放、检测删除离群值、最优聚类中心、降维等方法进行了算法的优化与改进。(3)基于线缆行业大数据平台SCP实现数据采集、数据处理和数据分析。首先通过数据采集系统,采集原始生产数据,然后将数据输出到大数据平台通过Spark Streaming完成数据清洗处理,最后通过基于MLlib的K-Means算法,对清洗后的数据进行分析挖据,发掘数据之间的聚类和关联关系。为企业生产设备参数调整与主动维护提供指导,同时也为后续深入研究提供了参考。通过本文的研究发现,利用Spark和Hadoop搭建的工业大数据平台,可以快速稳定的实现海量数据的分析处理。通过Spark众多的接口可以轻松的扩展大数据平台的处理能力,丰富了大数据平台的应用场景。"
1655,基于深度注意力网络的人脸表情识别,"表情作为一种传递情绪状态和意图的非语言信号,在人际交流、人机交互、安全驾驶和在线教育等领域发挥着不可磨灭的作用。高效准确地识别人脸表情是一项充满挑战且意义非凡的任务。近些年已有诸多国内外学者和科研机构对其进行深入的研究,人脸表情识别也成为计算机视觉领域的热门课题。人脸表情识别是指计算机模拟人的思维和认知方式将提取的人脸表情特征进行分类,进而分析和理解人的情感状态。当前的人脸表情识别算法一般分为基于静态图片的人脸表情识别和基于动态视频序列的人脸表情识别,本文主要侧重于静态图片中的人脸表情识别。深度学习作为机器学习的一个分支,相较于传统机器学习算法需要人工设计和提取特征,深度学习能够以监督或非监督的形式自适应地学习多层次的判别性和鲁棒性较好的描述子。近年来它在目标检测、图像分类、图像检索、语义分割等计算机视觉任务中成绩斐然,各种性能优良的深度学习模型层出不穷。凭借卓越的表现深度学习征服了众多研究人员,成为人工智能领域热门的研究方法。本文利用深度学习技术开展对静态图片中人脸表情识别的相关研究。对深度学习理论和当前备受关注且性能优良的深度学习模型进行了充分研究和持续总结之后,本文对现有的模型进行了改进。在继承传统模型的诸多优点的基础上,融合注意力机制提升模型的鲁棒性和准确性。本文的主要工作分为以下几个部分1、为了尽量减少卷积神经网络池化层丢失部分信息的影响,本文提出一种轻量化的多尺度注意力卷积神经网络。该模型能够融合多个尺度卷积操作学习到的视觉特征,这些特征能够有效地传递到高层,使更高层可以同时整合和抽象不同尺度的特征。通过深度学习层次化连接的特性学习高度抽象化的语义特征,利用可判别性和鲁棒性较高的语义特征提升人脸表情识别的准确性。2、由于人脸不同区域的视觉信息对于人脸表情识别的作用各不相同,而传统的深度学习方法忽视了该问题,无差别地对待整个人脸区域,从整张人脸图像中提取固定维度的全局特征。为了有效利用人脸的局部特征,本文提出多通道卷积神经网络,该网络能够自适应地从完整的人脸表情图像和人脸部件(Facial Components)(例如:眼睛、嘴巴、鼻子等)图片中学习判别性优良的全局特征和局部特征。3、为了避免冗余信息和噪声信息对表情识别的影响,本文将注意力机制融入到深度卷积神经网络中,通过模型的迭代优化自适应地捕获不同人脸表情所涉及的不同显著性区域。这些显著性区域所包含的视觉信息能够被赋予不同的权重,从而有效的整合成判别性和鲁棒性较好的深度特征。4、当前的深度学习模型中一般采用SoftMax分类损失作为监督信号(Supervision Signal)来训练模型和优化参数,而SoftMax分类损失无法满足同时增大类内相似度和减小类间相似度的要求,本文通过设计新的损失函数-Regularized Center Loss、Improved Triplet Loss-和SoftMax分类损失联合使用作为模型训练的目标函数,使得类内聚合、类间分散,极大地提升了深度卷积神经网络学习到的特征的可判别性,从而较大幅度提升表情识别的效果。为了验证所提出的方法的有效性,本文在CK+和Oulu-CASIA等人脸表情数据库上进行对比实验,实验表明本文所提出的方法能显著提高人脸表情识别的准确度。"
1656,基于特征工程的协同过滤算法研究,"协同过滤算法是目前应用最广泛、最成功的推荐算法之一,通过分析用户或项目特征计算相似度,生成最近邻集合,最后预测对未知项目的评分生成推荐结果。用户或项目特征在协同过滤算法中是至关重要的,其区分度和稀疏性会直接影响算法的预测准确度。无论是传统协同过滤算法还是改进的协同过滤算法,二者都是将评分数据作为用户或项目的特征,因此就有两个方面的问题需要进一步探索和优化:(1)用户或项目特征的区分度不高。评分数据在很大程度上受到用户个性化偏好、行为习惯等不可度量因素的影响,对于不同的用户来说,相同评分会代表不同偏好,而不同评分却可能代表相同的偏好。因此,将评分数据作为用户或项目特征就会存在特征区分度不高的问题。为了得到区分度更高的特征,研究者们会使用不同的方法,例如:基于内容的方法引入各种用户或项目特征、引入人口统计特征或结合自然语言处理技术等。(2)用户或项目特征具有高稀疏性。随着互联网用户规模的急速扩大和电子商务的普及,用户评分的项目通常只占全部项目的很少一部分,评分数据极度稀疏。此时,将评分数据作为用户或项目特征就会存在特征稀疏度高的问题。为了缓解稀疏性问题带来的影响,研究者们创新出了多种控制填补技术、降维技术和对稀疏性不敏感的相似度计算方法等。本文从特征工程的角度出发,针对由于特征区分度不高和稀疏性所导致预测准确度降低的问题,从如下两方面展开研究:(1)针对用户特征区分度低的问题,提出融合归因理论特征的协同过滤算法(AF-CF,Collaborative filtering based on attribution features)。归因理论属于社会心理学的范畴,通过分析一致性、区别性、一贯性、正负偏好等区分度很高的用户特征能很好的对用户行为进行归因分析,即推理用户行为的原因。因此,AF-CF算法为了得到区分度高的特征,使用统计方法提取归因理论中的三种特征:一致性、区别性、正负偏好。将用户评分行为归因于用户偏好,线性处理这三种特征得到用户项目偏好。计算偏好相似度与评分相似度,为兼顾两种相似度的优点,对相似度进行融合,最后进行评分预测。为了验证工作的有效性,文中首先对相似度融合参数进行调优,得到最优的参数:??(28)(28)、6.01.0。然后,在最优的融合参数下,与传统协同过滤算法的预测准确度进行对比,以MAE为评价指标,其值下降了1.5%左右,即算法的预测准确度提升了1.5%。最后,与最新的三种最新的协同过滤改进算法进行对比,算法的MAE值下降了4%-5%。(2)为了降低稀疏性对协同过滤算法预测准确度的影响,同时兼顾提取具有高区分度的特征,提出基于标注映射的协同过滤算法(LM-CF,Collaborative filtering based on label and map)。标注映射是文中提出的一种特征提取方法,标注是为了生成原始数据的类别信息,映射是将原始数据按照标注转换成为新特征。根据标注的方法不同,文中对原始评分数据分别采用聚类标注映射和自标注映射方法,提取出数据维度低和区分度高的新特征。不同于已有的特征提取方法,标注映射提取的是由集合所组成的新特征。以新特征为数据,进行基于项目的评分预测,其中相似度计算使用线性Jaccard方法,通过对特征的细粒度划分,能更好的计算项目相似度。在通用数据集Movie lens、Yahoo!R4、Film Trust上进行实验,以MAE为评估标准,验证工作的有效性。首先,分析聚类标注和自标注的各自适用性,聚类标注适用于大数据集,对数据格式没有要求,自标注适用于小数据集,对数据格式有严格要求。最后,通过与四个最新算法的MAE值对比,证明工作(2)要优于对比算法,MAE值下降了2%-12%。"
1657,基于机器学习的软件缺陷预测方法研究,"随着信息时的到来,软件成了人们生产与生活中不可或缺的存在。在软件需求迅猛上升的情况下,软件开发的规模和复杂度不断增大。由于软件工程师的开发能力不一定能够完美满足软件开发的需求,因此不可避免的产生软件缺陷。暗藏的软件缺陷可能会对人们的生产和生活造成难以估量的损失,这些让人难以承受的后果让人们开始关注软件质量的重要性。软件测试可以有效地探测出软件产品中隐藏的缺陷,但是由于软件项目时间和人力成本以及功能的复杂性等方面的影响,软件测试工程师不能考虑到软件模块所有方面,无法对软件模块完全覆盖测试。而软件缺陷预测技术结合机器学习等热门技术,利用软件产品的历史度量数据构建预测模型,进而预测软件中存在缺陷的模块,该技术对软件测试技术进行了卓有成效的补充。本论文主要从机器学习角度剖析软件缺陷预测的特点,并针对当前实际应用中软件缺陷预测研究存在的问题提出了对应的解决方法。主要包含问题如下:(1)缺陷数据集中存在部分冗余或者不相关的特征,这些特征严重影响缺陷预测模型的性能;(2)软件缺陷数据中存在的类不平衡以及数据集未完全进行类标记,现实情况中,软件缺陷数据的正负样例数目比例相差较大,并且不是所有的数据都存在类标记,因此传统的监督学习不能满足预测模型构建的需要;(3)新项目缺少足够的历史缺陷数据来训练预测模型,因此无法使用独立同分布的训练集和测试集进行缺陷预测模型的构建和验证;(4)未来传统的单机模型已经不能满足大模软件缺陷数据的存储和计算的需要。具体针对措施如下:(1)针对缺陷数据集中存在部分冗余或者不相关的特征的问题,本文提出一种基于相关度和冗余度的稳定特征选择方法(RRSFS)。RRSFS在K重交叉检验下通对特征与特征之间冗余度与特征与类之间的相关度进行两阶段多算法融合选取最优子集,RRSFS算法不仅降低了建模过程中数据运算的成本,还加强了特征选择算法的稳定性。(2)针对软件缺陷数据中存在的类不平衡以及数据集未完全进行类标记等问题,本文提出了一种基于采样与集成的半监督软件缺陷预测方法(SISDP)。SISDP首先通过采取类别平衡的样本构建稳健的KNN打标模型,来对一批未标记的数据进行打标,再通过迭代形式,将新标记的数据加入原有数据集进行下一次打标模型构建,迭代到数据标记完毕。对打标完毕的数据集,最后用混合采样算法获取训练集,并对多分类算法构成的集成分类模型进行分类训练。SISDP不仅减少了少数类对打标过程的干扰,而且提升了缺陷预测模型的泛化能力。(3)针对新项目缺少足够的历史缺陷数据来训练预测模型问题,本文主要提出了基于卷积神经网络的迁移学习算法(CNNTL)进行缺陷预测,该方法将迁移学习过程分为A、B两类任务,首先提升A任务中源项目数据集的特征维度,并将其输入到多次卷积网络之中进行初步训练,将训练A任务源项目数据集得到的卷积层权重参数,应用到B任务目标项目数据集的卷积层训练中,从而实现了迁移学习。CNNTL算法不仅特征迁移能力强,并且有不错的预测性能。(4)针对大规模软件缺陷数据的存储和计算这类问题,本文提出了基于神经网络的分布式缺陷预测算法(NNDDP)。该方法基于集成了Kerberos的Hadoop集群进行研究,将需要处理的缺陷数据集存储在分布式文件系统HDFS上,再对数据进行预处理得到训练集和测试集,通过将数据划分并分配到多台服务器上进行同步并行训练,最终由参数服务器进行局部参数汇总,训练出一个全局的缺陷预测模型。NNDDP算法不仅能够处理大规模数据集,而且拥有不俗的预测性能。为了探究本文提出算法的可行性,本文对每个算法都进行了相应的对比实验。同时为了探究本文提出算法的稳定性,本文在不同数据集上进行了多批次实验。实验结果表明本文所提算法对软件缺陷预测数据集的处理拥有较优的性能。本文的所有研究旨在为软件质量保障提供新的理论基础,为软件缺陷预测技术探索新的研究方向。"
1658,基于Hadoop的网络异常流量分布式检测研究,"随着计算机科学和网络技术的高速发展,互联网的开放性和共享性等优点越来越明显,网络信息技术被运用到诸多领域,应用范围遍及世界每个角落的政治、经济、金融、教育和军事等领域。由于计算机及网络的脆弱性、网络协议的缺陷和隐藏的安全漏洞,给网络安全带来极大威胁。网络流量数据和网络日志蕴含着丰富的有价值信息,在用户行为分析、上网行为管理、入侵检测和网络管理等许多领域具有非常高的价值,最初的网络数据处理方式是使用单台计算机对数据进行计算分析,单台处理设备在CPU、I/O与存储方面的性能受到硬件当时硬件发展水平的限制且没有扩展性。面对当今高速发展的高性能硬件设备,导致系统产生数据量和网络中传输的流量呈现几何级数级别增加,传统检测方法无法满足大规模数据分析对时间和效率的要求,在实际应用中对数据分析的处理时间要求越来越高,具备高吞吐和低时延的并行计算成为了数据处理的重要指标,分布式异常检测的研究成为异常检测研究领域的新风向标。针对网络安全形势日趋严峻和海量网络数据快速增长的背景下,本文设计并实现基于云计算的分布式异常网络流量检测的实验,通过云计算对大规模数据的存储和计算能力,解决入侵检测、网络流量分析及日志数据的采集、存储和分析面临的主要瓶颈问题,运用Hadoop的MapReduce分布式并行计算模型,能够高效和可靠地并行处理大规模数据集。本文有关网络异常流量分布式检测的主要研究内容如下:(1)分布式异常检测平台架构研究通过需求分析完成分布式入侵检测平台架构设计,整体架构分为网络采集、分布式存储和异常检测分析三个层次,按照需求完成网络数据采集、数据存储和数据异常检测的实验环境的搭建,通过训练样本训练建立异常检测模型,使用历史特征形成特征异常检测特征库,可以提高异常检测系统的数据处理能力,提高检测效率和检测准确率,可以扩展系统的学习能力挖掘分析更深层次的信息。(2)网络数据采集和网络日志收集研究采用Flume从多源前端服务器中采集日志和告警信息等网络日志数据存储到HDFS分布式文件系统中,使用Sniffer技术采集网络流量并对网络流量进行特征提取,采集端运用WinPcap与LibPcap采集网络数据,实现会话连接重构方式提取网络流量并存储特征值,将KDD99格式特征数据传送到分析处理系统的HDFS文件系统中,对入侵告警信息进行相关性融合分析。(3)数据分析算法研究将模糊C-均值聚类算法、词汇分割分类算法和统计学方法应用到采集的网络流量和网络日志数据,验证算法的可行性和检验分析结果的准确率。通过预处理网络数据和使用基于网络流量相关性的模糊C-均值聚类算法完成聚类分析,提出网络流量相关性四关键要素和基于权值的目标函数计算方法,从训练样本数据获取聚类簇中心值和聚类类型,使用异常方差统计的方法,检测分布式拒绝服务攻击行为,并构建历史特征库满足对未来数据快速分析的需求。(4)基于分布式的网络异常检测研究将机器学习算法和MapReduce分布式计算模型结合在Hadoop平台上进行并行化处理,将存储在HDFS分布式文件系统中网络采集数据、日志和告警信息,采用MapReduce和Flume等分布式计算技术完成分布式异常检测实验、融合告警信息,通过聚类算法和分类算法深入挖掘数据中的异常信息和异常网络流量,对分布式异常检测的时间效率、准确率、漏报率和误报率进行了分析。综上所述,本论文构建的网络异常流量分析实验有效地解决了网络数据的采集、存储与异常分析等问题,融合了Hadoop与数据挖掘各自的优势,充分发挥了Hadoop分布式计算框架的高扩展性和高吞吐性等特性,利用数据挖掘算法深入检测网络事件中的异常信息,形成一整套比较完整且准确度较高的采集、存储、分析和特征建立过程。"
1659,多标记与偏标记学习算法研究,"机器学习的目的是基于训练数据进行模型学习,从而利用学习到的模型对未知样本进行预测。对于分类问题而言,传统的监督学习将现实世界中的一个样本对象视为一个“示例&标记”对,其中示例就是用来描述样本的特征,标记即该示例所对应的类别标签。传统单标记学习假设每个样本对应单一的...、明确的...类别标记,即训练样本集中的每个示例仅与一个类别标记相关联。但现实应用中的很多机器学习场景并不符合上述的两个假设:(1)一个样本对象有可能会对应多种语义信息,即一个示例对应多个标记;(2)训练集中的样本可能不具有明确的类别标记。基于这两个问题,多标记学习以及偏标记学习这两种学习范式近些年来受到越来越多研究人员的关注。多标记学习与单标记学习的区别在于样本在标记空间的多义性,即每个样本示例可以与一个或者多个类表标签相关联。近年来,多标记学习得到越来越多研究者的关注,大量的多标记学习方法被提出,但由于多标记学习在标记空间的复杂性,现有方法很难再各项评价指标上都能够达到很好的效果,为了更好地处理多标记分类问题,本文提出了两种多标记学习算法。首先针对多标记学习中不同样本之间的差异性,我们提出了一种基于局部自适应6)近邻的多标记学习算法,该算法考虑到数据集不同区域的样本之间差异,使得在运用6)近邻算法解决多标记问题时能够获得更准确的结果。另外针对多标记任务上的标记之间的差异性,我们提出了一种基于标记重要性分析的多标记学习方法,我们考虑到多标记任务中不同标记的可预测性和影响力的差异,提出一种确定标记重要性的方法,并且将标记重要性分析应用到了两种多标记分类方法里,实现了比基准方法更优的结果。偏标记学习场景下样本集的每个示例也可以与多个类别标记相关联,但在这些标记中有且仅有一个为该示例的真实类别标记。已有方法解决偏标记学习问题的主要思路是通过标记消歧实现的,即在学习过程中去区分每个示例的候选标记集中的真实标记和无关标记。近年来,基于特征空间相似性的偏标记学习方法被提出,该方法利用特征空间和标记空间的平滑性实现标记消歧。但是已有基于特征相似性的偏标记消歧算法都是采用的固定相似图,在数据集存在噪音样本的情况下,这种方法的分类效果不能得到保证。基于这个原因,本文我们提出了一种基于自适应相似图的偏标记消歧方法,该方法将标记消歧、相似图优化和模型训练在同一框架内完成,在处理实际应用时具有更好的鲁棒性。本文分为五章。第一章介绍多标记学习和偏标记学习的基本概念,并作出已有相关方法的综述和有待解决的问题。第二章和第三章分别提出两种不同的多标记学习方法。第四章提出一种新型的偏标记学习算法。第五章对本文工作进行了总结,并作了对未来工作的展望。"
1660,基于CNN和SVM的无线电同频干扰检测,"随着无线电事业的快速发展,无线电干扰现已成为通信传输过程中十分严峻的问题,而传统检测无线电干扰的算法,对于先验知识和检测人员专业性的依赖十分强。针对无线电干扰中较为突出的同频干扰问题,本文将深度学习应用于干扰信号检测,提出了新的方法检测无线电调频广播中的同频干扰。本文首先制作出用于训练深度学习算法的数据集。通过信号发生器发射干扰信号,再利用接收机接收广播信号和干扰信号的同相正交分量,然后在MATLAB中还原信号并利用时频分析算法绘制出能体现信号特性的时频分布图作为数据集。近年来,深度学习算法中的卷积神经网络在图像识别领域大放异彩,根据数据集特征,本文设计了一个七层卷积神经网络作为干扰检测模型,将数据集输入卷积神经网络并训练其学习信号的时频特征,通过分析训练结果不断优化模型,最后利用卷积神经网络提取到的信号特征对时频图进行分类,从而检测出广播信号中是否存在同频干扰。实验结果表明,在本文验证数据集上,模型能达到较高的识别精度,能准确检测出广播信号中的同频干扰,证明了本文算法的有效性,且与其他网络模型相比本文算法能在保证准确率的情况下提高训练速度,缩短训练时间。同时,本文将深度学习和传统机器学习相结合,提出了另一种检测同频干扰的算法。本文利用卷积神经网络模型提取信号的时频图特征,并将其作为数据集训练传统机器学习算法。通过对比实验发现支持向量机相比其他传统机器学习算法能取得更好的分类效果。本文还提取出了信号时频图的方向梯度直方图与灰度共生矩阵特征并将其组合作为特征数据集,同时将信号的短时傅里叶变换作为另一特征集,通过对比三种特征集训练后的支持向量机的混淆矩阵来分析卷积神经网络在本文干扰检测任务上的优劣性。实验结果表明,用卷积神经网络提取的特征训练出来的支持向量机,其准确率要高于用另外两个数据集训练的支持向量机。相对于单独使用传统机器学习算法,本文将卷积神经网络与支持向量机相结合能更便捷更准确地完成本文的分类任务。"
1661,基于深度学习的蛋白质相互作用预测研究,"蛋白质是生命活动的物质基础,在细胞生命活动中扮演着十分重要的角色。绝大部分蛋白质通过与其他的蛋白质发生互作从而执行多样的生物学功能。蛋白质相互作用是蛋白质组学研究的热点和难点之一,正确地识别蛋白质相互作用不仅有助于更全面地理解活细胞的生物分子生理过程,而且对于新药物的研发和疾病机制的探索等方面都具有重要的意义。基于传统湿实验识别蛋白质相互作用的技术存在费时,覆盖度有限且价格昂贵的缺点。近年来,研究者已经研发了一些利用机器学习和蛋白质氨基酸序列识别蛋白质相互作用的方法。但是这些方法普遍存在以下不足:1)蛋白质氨基酸序列向量化编码方法无法充分提取互作特征;2)忽视多种氨基酸序列编码和分类器间的互补信息,即仅使用单个编码算法和单个分类器预测蛋白质互作;3)蛋白质非相互作用数据集缺失或包含有大量噪声。为此,本文开展了如下工作:(1)针对蛋白质序列特征编码算法不能充分刻画氨基酸序列的连续和不连续区域中残基间的互作的问题,本文提出了一种基于局部三联体特征编码算法(LCTD:Local Conjoint Triad Description)和深度神经网络的方法―DNN-LCTD。局部三联体特征编码算法(LCTD)集成了三联体特征编码算法(CT:Conjoint Triad Descriptor)和局部特征编码算法(LD:Local Descriptor)的优点,因此它能更好的描述氨基酸序列连续和不连续区域隐藏的互作信息。深度神经网络(DNNs)不仅可以从原始数据中自动学习稳定的特征,而且还能描述和刻画数据的层次表示。DNN-LCTD在酵母菌蛋白质相互作用数据集上取得了优越的性能且仅耗时718秒,其中准确率(accuracy)达到93.12%,精度(precision)达到93.75%,AUC(Area Under Curve)达到97.92%。这些实验结果显示,DNN-LCTD能够高效且准确地预测蛋白质相互作用,同时还进一步证明了LCTD编码算法的优越性。(2)针对现有蛋白质相互作用预测方法忽略了多种氨基酸序列编码和分类器间互补信息的问题,本文提出了一种基于集成深度学习和集成蛋白质序列编码算法的分类方法―EnsDNN。EnsDNN首先分别利用自协方差特征编码算法(AC:auto covariance descriptor),LD,多尺度连续不连续局部特征编码算法(MCD:Multi-scale Continuous and Discontinuous local descriptor)编码氨基酸序列间的互作模式。然后基于每个特征编码算法训练不同配置的DNNs。最后为了利用AC,LD,MCD编码算法和不同DNNs间的互补信息,EnsDNN利用一个集成预测器自动地为每个DNNs分类器分配权重,并进行蛋白质互作预测。在酵母菌蛋白质数据集上,EnsDNN取得了优越的性能,准确率(accuracy)达到95.29%,召回率(recall)达到95.12%,精度(precision)达到95.45%。(3)针对蛋白质非相互作用数据集缺失或包含有大量噪声的问题。本文提出两种生成高质量非相互作用数据集的方法―NIP-SS和NIP-RW。NIP-SS和NIP-RW分别基于序列相似度和图上的随机游走的方法选择蛋白质非相互作用对。NIP-SS首先计算互作数据集中各蛋白质间的序列相似度,然后选取前m个最不相似的蛋白质对作为非相互作用对,同时控制已选择非互作用对的蛋白质的度分布与正数据集中的蛋白质度分布相似。NIP-RW则在蛋白质相互作用网络上进行k步随机游走,最后从更新后的邻接矩阵中选择无连接的蛋白质对作为非相互作用的数据。考虑到效率问题,本文使用AC编码氨基酸序列且使用深度神经网络作为分类器模型。大量的实验结果表明相较于其他已经存在的蛋白质非相互作用数据集生成策略,NIP-SS和NIP-RW可以生成更高质量的非相互作用对。实验结果还表明基于NIP-SS和NIP-RW策略生成的非相互作用数据集的DNNs模型的预测性能将更加准确和健壮。"
1662,基于信息熵与深度森林的蛋白质亚细胞位置预测,"蛋白质的亚细胞位置信息能够为理解其生物学功能提供有力线索,在药物设计、病理分析等领域的研究中有着重要作用。在后基因组时代的当下,蛋白质测序技术取得了长足的发展。新发现蛋白质的数量正以惊人的速度飞速增长。如何快速准确的获取蛋白质的亚细胞位置信息已经成为了蛋白质组学中的一项关键任务。现有的蛋白质亚细胞位置识别方法主要分为基于生物化学实验的方法和基于计算的方法。其中,基于生物化学实验的方法是目前获取蛋白质亚细胞位置信息的主要手段。但是由于时间成本巨大,此类方法已经难以满足人们在识别效率方面的需求。与之相对,基于计算方法的出现为高效解决海量蛋白质序列的亚细胞位置识别问题提供了可行方案。近年来,人们对基于计算的蛋白质亚细胞位置预测方法做出了大量的研究。然而,受制于特征提取技术以及分类算法的性能,相关方法的预测准确率仍待提高。针对这一现状,本文在信息熵与深度森林的基础上对现有蛋白质亚细胞位置预测技术进行改进。在蛋白质特征提取方面,本文在分析了现有蛋白质特征提取技术缺陷的基础上,探究了基于信息熵的改进方案的有效性。在分类算法的构建方面,本文首先讨论了深度森林对蛋白质亚细胞位置预测问题的适用性,随后针对性的提出了两种改进模型以进一步提高最终预测结果的准确率。本文主要工作如下:(1)针对现有蛋白质序列信息特征提取技术以及进化信息特征提取技术的缺陷,提出了一种新的蛋白质特征提取方法,即IE-MoAC-PFR方法。其中,对于蛋白质序列信息特征的提取,针对传统n-gram-frequency特征不能有效表示蛋白质序列中氨基酸位置信息的缺陷,IE-MoAC-PFR方法使用信息熵刻画不同氨基酸片段在蛋白质序列中的分布情况,从而提升特征向量对蛋白质序列信息的反映能力。对于蛋白质进化信息特征的提取,针对传统基于自协方差的位置特异性矩阵的特征转换方法忽略了蛋白质序列中不同氨基酸在进化过程中的关系信息,IE-MoAC-PFR方法将自协方差扩展到位置特异性矩阵的不同列上。最后,为了能够更好地将蛋白质的序列信息和进化信息用于亚细胞位置的预测当中,IE-MoAC-PFR方法将所提取的蛋白质序列信息特征与进化信息特征结合生成蛋白质最终的特征向量。(2)针对蛋白质亚细胞位置预测问题小样本高维度的特性,提出一种深度森林改进算法,即FS-DF算法。为避免蛋白质高维稀疏特征向量中的无关特征以及噪声特征对模型最终预测准确率的影响,FS-DF算法将基于基尼系数的特征选择机制引入到深度森林的层级结构中。通过逐层筛除原始蛋白质特征向量中的无关特征以及噪声特征,相较于深度森林方法,FS-DF方法能够极大提升各层模型的性能,并在此基础上进行更为有效的表示学习。(3)FS-DF算法中,随着层级的不断加深,被筛除特征的不断增多可能会导致部分有用信息的丢失。为了更加充分地利用蛋白质特征向量中所蕴涵的亚细胞位置相关信息,从寻找并利用最优特征子集的角度出发,提出了一种新的深度森林改进算法,即Tabu-DF算法。在Tabu-DF算法中,面向最优特征子集的禁忌搜索机制被用于改进深度森林的层级结构。基于禁忌搜索可以避免陷入局部最优解的特性,Tabu-DF算法能够更有效地处理高维稀疏的蛋白质特征向量,并进一步提升最终预测结果的准确率。本文在Plant,NonPlant以及PsortNeg三个标准数据集上对新提出方法的性能进行了验证。实验结果显示,相较于现有的方法,新提出的方法能够有效提高蛋白质亚细胞位置预测结果的准确率,为相关研究提供更为有效的信息。"
1663,基于机器学习的重力式深水网箱受灾风险评估分析研究,"近十年来,随着我国深水离岸养殖装备技术的提高,以重力式深水养殖网箱为代表的海水设施渔业规模日益扩大,养殖区域不断向深远海拓展。由于我国近海处于台风、风暴潮等海洋灾害性天气高发区域,近海及深远海渔业设施面临台风、强流等恶劣海洋环境的严峻威胁,严重阻碍了我国海洋设施渔业的健康发展。我国海水设施渔业整体水平较低,多以仿制国外的渔业设施结构为主,且每年因海洋灾害的影响而损失严重。针对渔业设施的致灾因子(风、浪、流、设施结构脆弱性)、设施受灾响应及受灾破坏机理尚不清楚,导致每年海洋设施渔业受灾破坏的灾前预判和应对对策都不具有针对性。通过开展重力式深水养殖网箱的受灾风险评估分析,从而为养殖网箱在灾害天气下的风险预警提供技术支持。通过收集重力式深水养殖网箱受灾破坏历史统计资料,养殖网箱的受灾破坏形式主要包括浮架开裂、网衣严重变形和锚绳脱锚。本研究以分布在温州南麂岛附近海域的重力式深水网箱作为研究对象,分别选取了周长分别为40m、60m和80m的单体重力式深水圆形网箱为研究样本,根据当地的水文参数设计相应的计算波况,波高在4m~10m,周期在5.4s~12.5s,水深分别为20m、22m以及23m,流速分别为0m/s和0.4m/s,计算单体重力式深水圆形网箱在设计波况下的数值水动力响应。通过人工神经网络(ANN)构建立重力式深水网箱破坏的致灾因子与网箱结构受灾破坏的定量关系,并利用灰色关联度识别出网箱受灾破坏的主控致灾因子。根据重力式深水网箱受灾破坏历史资料,制定出网箱受灾破坏等级水动力指标阈值表及对应的描述。本文中以1808号台风“玛利亚”为例,通过灾前调研,灾前预报以及灾后调研验证了养殖网箱风险预警模型的可行性和正确性。并且结合养殖网箱受灾破坏等级水动力指标阈值表,确定和绘制出南麂岛附近海域重力式深水网箱在不同破坏等级下的波高阈值表和在不同重现期下受灾破坏等级的空间分布图。"
1664,基于机器学习的固态电解质构效模型研究,"固体电解质具有较宽的电化学窗口、较高的稳定性等优点,使得固态电池拥有较高的安全性、较大的能量密度、较强的循环性,因此,可以将固体电解质作为一种良好的锂电池电解液替代品。尽管发展前景不错,但其研发推广仍然存在许多障碍。传统的固态电解质材料研发模式主要基于经验和实验的“试错法”,发现周期长,偶然因素大。针对固态电解质材料发现困难的问题,本文提出一种将机器学习用于固态电解质材料筛选的思路。具体地说,本论文的主要内容包括以下方面:首先,针对需要研究的固态电解质待选材料,以Materials Project数据库为基础,建立了可拓展的、实验与计算并举的本地数据库,并对数据库内包含的主要条目进行了数据解析,包含形成能、晶格能、晶胞体积、晶格大小等信息,有助于更好的理解内部结构与性能的相关性,为接下来的筛选工作打下基础。特别是对于含有多子集条目的弹性信息,根据一元、二元、三元材料中的数据,假定各子集之间可能存在的相关关系,通过验证证实了假定的可行性,为后续实验数据的存储与扩展提供了渠道。其次,在对数据库内信息充分理解的基础上,聚焦固态电解质材料应具有的较低电子电导率、较好的稳定性、较高的离子电导率等特性,建立与内部结构信息包括能带、晶格能、布尔常量、形成能、电子传导量、原子分布等的联系,获取相关的“构效关系”。尤其需要指出的是,对于离子电导率的筛选,因无经验公式可以借鉴,且难以直接建立内部结构某个参数与之的对应关系,因此,选定可以由内部结构信息(原子坐标、晶格体积等)计算获得的、与离子电导率关联性较强的20个特征,充分利用他人的实验数据,使用梯度下降的逻辑回归算法,获得离子电导率的预测模型。实现了对数据库内12000多种材料的筛选,得到预估性能优良的41种固态电解质候选材料。最后,从41种固态电解质候选材料出发,找寻其并列举已被研究体系的制备方法与相关性能,并着重研究了41种固态电解质候选材料中的Li_5GaO_4体系,使用固相合成法制备出相应材料并初步测量了其室温离子电导率。随着材料大数据的出现、机器学习方法的更迭、电池安全性要求的提高,机器学习用于固态电解质的筛选将会是一个重要的关注点。我们所做的初步研究,将为这项工作提供一些帮助。"
1665,基于智能手机的人体异常步态识别研究,"步态是步行时的姿态,正常步态是人体协调运动的结果。疾病、遗传、意外伤害等因素可能导致步态改变,造成步态异常。分析、识别和评价异常步态在临床诊断和康复中有重要的价值。传统临床医学上异常步态的分析评估多采用价格昂贵的专业设备而难以在日常生活中得到应用。随着基于智能手机的步态识别技术发展,人体异常步态的识别和分析有了更为经济便利的测量手段,但随之出现的问题亟待研究。本文通过实验设计,利用智能手机采集人体正常和异常步态数据。在进行数据预处理后,分别进行特征提取、分类识别和参数估计、量化分析,并建立异常步态的理论模型进行验证对比,从而实现基于智能手机的异常步态定性识别和量化分析。全文主要工作内容概括如下:1.基于智能手机中内置的加速度和旋转矢量传感器,开发和设计Android系统下步态数据采集APP。针对数据采集过程中的抖动、手机朝向等问题,利用四元数法将手机的相对坐标系转换为地球的绝对坐标系,同时运用双树复小波算法进行数据预处理。2.在步态领域缺乏参数估计和量化分析等定量分析的情况下,采用生物力学参数:时间、空间及时-空参数,进行步态周期、步数、步长及角度等研究;考虑到人体步态的周期性,构建步态模板,进行步态循环序列的提取。构建基于人体下肢的异常步态模型-钟摆模型,并进行实验验证。3.在异常步态的定性分析中,利用双树复小波算法提取出的时频特征和时域中的统计学特征作为原始输入的18维特征。针对人体异常步态运动中特征维数较复杂、存在冗余以及特征之间相关性较高的问题,着重选取有效特征,利用特征选择算法CFS进行特征选择以及数据降维。在构建分类器模型设计中,选择不同的机器学习算法,根据不同分类器的特点,选择最优参数,设计参数优化方案,评估分类器指标,选择最优的IBK分类器模型。分类识别准确率可以达到96%,在IBK分类器模型泛化后的准确率可以达到88.5%。"
1666,基于LSTM神经网络模型的因子选股策略研究,"量化投资具体理论的提出距今已经近七十年的历史,量化投资的策略也经历一系列的演变。如今随着高性能计算机的普及,人工智能开始在各个领域施展自己的威力。其中最近几年机器学习领域在深度神经网络方面也取得了重大技术性突破并应用到了量化投资领域之中。在量化投资领域中,对于深度学习模型应用的探究也是循序渐进的。从传统神经模型(ANN)到传统循环神经模型(RNN)再到长短期记忆网络模型(LSTM)的过程中,理论模型分别解决了引入时间序列、长时间记忆训练以及缓解梯度爆炸等多种问题。本文就是基于LSTM神经网络模型对选取的因子进行训练和合成,并用合成后的因子进行量化投资。在研究方法方面,本文借鉴了因子选股模型的理论,通过选取估值因子、成长性因子、财务质量因子等不同大类因子70个,来进行因子的训练和合成。在因子处理方面,本文使用了缩尾处理、中性化以及标准化剔除异常数据,保证了数据的平稳性。在模型结果分析上采用了正确率变化、AUC变化和损失率变化验证模型的实用性,证实了模型具有一定的区分度。在创新性上,由于神经网络模型固有的“黑箱子”属性,使得其在模型的可解释性上一直受诟病。本文在优矿平台的环境下,使用Python Keras包,对其中的部分因子进行尝试性的解释,试图打开“黑箱子”探其究竟,并得到了很好的解释。在量化选股模型的构建及回测方面,本文使用了因子分层测试法对于合成因子区分度上做出了研究和论证。最后用反复证实过的因子进行量化投资选股策略的构建。在回测过程中应用对比论证的方法,将非线性的神经网络模型和传统线性统计模型进行对比,说明神经网络模型具有较好的投资回报。本文在整个过程中,可以得出以下结论:第一,长短期神经网络模型(LSTM)训练的因子具有不错的区分度。第二,可以通过Python Keras包对深度神经网络模型进行解释。第三,使用神经网络模型对因子进行训练、合成、预测并投资是可行的。第四,长短期神经网络模型(LSTM)对比传统统计学模型和传统循环网络模型(RNN)具有更好的预测能力和投资能力。本文通过使用2007年至2018年的全A股数据,分别建立了LSTM因子训练和合成模型、LSTM因子评价和5分位分析模型以及LSTM因子量化投资模型。并通过Python Keras包对模型可解释性做出尝试性分析。全方位的论证了神经网络模型中的长短期记忆模型LSTM在量化投资中具有很好的表现。不过论证过程中仍有一些问题等待进一步研究,如:循环神经网络需要较多参数,模型训练速度和调参较为缓慢且依赖于计算机性能,数据量小不利于模型的训练及发挥等问题。"
1667,基于多变量的时间序列分析预测研究,"基于时间序列的预测可以为人们的日常生活带来许多便利,其在股市走向、天气预报等多种生活场景中都有广泛的应用。同时,拥堵是劳民伤财的交通现象,是目前亟待解决的社会问题。对车流量进行时间序列分析预测的研究,可以为交通管理部门提供合理的决策依据,也可以为民众带来良好的出行体验,具有充分的研究价值和意义。本文针对多变量时间序列进行分析预测研究,主要工作内容和创新点如下:(1)提出基于多变量灰色模型的时间序列预测方法,该方法一方面对传统的灰色关联度分析方法进行改进,在原有的计算方法之上加入方向性关联度的分析,形成综合灰色关联度计算方法,从而可以更加准确地分析变量间的关联关系,筛选出更利于预测的外部变量;另一方面,在带卷积积分多变量灰色模型的基础之上,使用人工鱼群算法对模型中的微分方程系数进行优化,得到基于人工鱼群算法优化的带卷积积分多变量灰色模型AFSA-GMC(1,n)。(2)提出融合预测模型,从数据分解和结果加权两个方面提出不同的融合模型,以扩大模型适用范围,提高预测的准确性和稳定性。基于数据分解的融合模型对数据内在特性进行分解,使用多元季节性时间序列分析法SARIMAX模型预测数据的季节分量和余项,使用AFSA-GMC(1,n)模型预测数据的趋势分量,最终进行分量集成得到SARIMAX-AFSA-GMC(1,n)模型;基于结果加权的融合模型使用梯度提升决策树模型GBDT对数据整体趋势进行学习,AFSA-GMC(1,n)模型对短期数据变化进行把控,最终以预测误差平方和最小化为原则进行结果加权融合得到GBDT-AFSA-GMC(1,n)模型。(3)将模型应用于真实的高速公路车流量预测当中,并通过应用演示系统对预测结果进行可视化展示。本文提出的各类模型的预测精度都通过各自的算例分析得到了验证,并将其实际应用于真实的车流量预测环境中,说明模型能够在真实场景下发挥其预测效果,具有一定的稳定性和适用性。"
1668,基于卷积神经网络的金刚石NV色心自动识别系统,"由于具有荧光强度高且稳定性好、其中的电子自旋相干时间较长、能够被光学激发和微波操控等优良特性,金刚石氮-空位色心(Nitrogen-Vacancy color center,NV色心)被广泛应用于量子技术领域。在基于金刚石NV色心的量子调控平台上,快速、准确地识别和定位色心的位置对以后的实验有着关键影响。在目前的实验平台中,主要依赖实验人员以往的经验来判断金刚石NV色心的位置,继而借助光探测磁共振(Optical Detection Magnetic Resonance,ODMR)方法来确认是否为NV色心,但是由于不可避免的存在噪音,人工识别金刚石NV色心存在误识别、无法识别出所有可用NV色心等问题。为了更准确的检测金刚石NV色心,本文把NV色心的识别当作目标检测问题来处理。本文对目前已有的各类检测方法进行调研,通过调研发现,基于卷积神经网络(Convolutional Neural Network,CNN)的目标检测方法在检测效果、速度上更具优势。因此,本设计针对金刚石NV色心的识别问题提出了基于卷积神经网络的自动识别系统。在系统设计过程中,本文着重解决了金刚石荧光计数易受噪音干扰、NV色心目标尺度较小、待检测NV色心数量多等问题。和人工识别相比,该框架不仅降低了NV色心目标的误识别率,而且极大提高了目标的检出率,为后续的实验提供多个定位准确的NV色心目标。"
1669,基于改进近红外漫反射技术与流形学习的东北松子霉变分类研究,"近红外光谱技术作为一种光谱测量技术,其特点是分析简单、速度快并且可以在线进行,常用于食品、工艺中间体和最终产品的成分与功能分析,已成为食品质量和安全分析的有力技术。在林特产品深加工与食品质量安全需求日益提高的今天,坚果的无损检测预测成为众多研究者关注的热点问题。新采摘的松子含有大量水分,在储存过程中极易霉菌、酵母菌的影响导致氧化变质。但霉变松子存在经过炒制,化学试剂浸泡等操作处理后,难以与正常松子区分开的问题。针对这一问题,本文运用近红外光谱技术甄别霉变松子并对松子进行正常、霉变分类建模研究。首先,采用傅里叶转换红外光谱技术进行松子近红外数据的采集,并运用SNV、Norris-Williams求导与小波变换方法对采集到的近红外光谱数据进行预处理,达到光谱聚合、波长曲线平滑的结果。近红外漫反射光谱存在精度差、误差大的问题,为此研究漫反射光谱指标的改进,以提高漫反射光谱数据指标与样品化学成分之间的相关性。在此基础上,运用李群测地线度量方法对局部线性嵌入、等度量映射方法进行改进,并借助随机森林与提升树模型进行数据特征降维研究,并使用主成分分析降维同改进后的降维方法进行比较验证。研究结果表明:改进后的降维方法更适应于新的近红外光谱漫反射评价指标。最后,结合李群测地线度量方法和高斯过程进行松子分类建模研究。对七种不同核函数分别建立对应的核函数-高斯过程分类模型并对比选择。将概率校准技术引入对所建改进高斯模型的精度校正中。改进高斯模型的精度进行校正。根据建模实验可知使用周期-径向基组合核函数作为改进高斯过程的核函数能够获得最好分类效果,使用改进局部线性嵌入对松子数据进行降维后使用周期-径向基组合核函数-高斯过程建模的模型精确度为0.888;使用概率校准后的模型精确度为0.864;使用改进等度量映射对松子数据进行降维后使用周期-径向基组合核函数-高斯过程建模的模型精确度为0.849;使用概率校准后的模型精确度为0.958。依模型分类数据分析可知:使用改进漫反射评价指标能够提升最终分类模型精度;周期-径向基组合核函数兼具周期核函数与径向基核函数的优点,为霉变松子建模的最佳选择;概率校准并不能保证模型分类效果变得更高,但改进等度量映射降维的松子使用概率校准方法获得了松子霉变分类效果更好的模型。"
1670,光学扫描全息术中切片成像关键技术研究,"光学扫描全息术是一种具有实时性、高分辨率的数字全息技术,它能够获取荧光细胞标本的三维图像信息,在生物医学成像领域有广阔的应用前景。本论文结合理论推导、软件仿真、实验验证的方式,对光学扫描全息术中切片物体成像问题进行研究与探索,主要从以下几个方面进行论述。(一)通过二维傅里叶变换,卷积和相关等数学原理对波动方程和菲涅尔衍射定理进行推导,然后重点对光学扫描全息系统中全息图像的记录和重建理论进行分析,指出光学扫描全息术中切片成像关键技术问题。(二)介绍切片成像关键技术,包括自聚焦问题、自聚焦技术的研究进程、离焦噪声的两种形式,散斑噪声消除技术的研究进程等,另外对离焦噪声的两种形式进行了重点分析。(三)介绍常用图像评价指标函数,例如,标准偏差相关函数、图像拉普拉斯函数的能量等等,分析切片物体的全息图像在盲重建过程中重建图像的特征变化,提出基于图像评价指标函数的自聚焦算法以及改进的基于边缘灰度差异函数的自聚焦算法,最后通过软件仿真和实验验证相结合的方式来验证算法的性能。(四)首先简要介绍机器学习的概念,发展进程等,然后介绍了一种无监督学习算法―SOM神经网络,包括SOM神经网络的起源、特性以及它的训练方式,根据散斑噪声的特征和SOM神经网络的聚类特性,提出一种基于SOM神经网络的离焦噪声消除算法,算法训练完成后,结合仿真数据和噪声消除评价函数对其进行验证。"
1671,基于深度学习的农作物基因剪接位点识别研究,"准确的识别基因剪接位点对于理解以及控制基因性状的表达具有十分重要的意义。本文基于拟南芥、水稻、玉米三类农作物基因剪接位点数据集,结合卷积神经网络与递归神经网络设计了一种深度学习网络模型DeepAS(CNN+GRU+LSTM)。并根据DeepAS模型开发了农作物基因剪接位点识别系统,目的是能够实现快速准确的识别农作物基因剪接位点,从而方便研究者的使用,加快科研工作的效率。主要研究内容如下:1、基于拟南芥、水稻、玉米三种原始农作物的基因数据提取基因剪接位点数据集,并分别制作基因剪接位点模型训练集。2、基于Tensorflow+Keras深度学习框架提出了一种农作物基因剪接位点识别模型,设计了51种不同的模型结构用于训练并测试三种农作物基因剪接位点数据集以及他们的混合数据集,挑选出在每种数据集上识别准确率最高的网络模型,命名为DeepAS,并保存其模型与权重。实验表明DeepAS网络模型在用于识别农作物基因剪接位点时具有很好的准确率与泛化能力,在农作物混合基因数据集上识别准确率为97.09%,精确率为96.88%,召回率为0.9692,F1_Score为96.90%,结果优于传统的机器学习模型与本文对比的其他研究者的深度学习模型。3、进一步对剪接位点序列的特征进行研究,使用特殊的非剪接位点数据集进行验证,在去除GT-AG法则这一主要特征的情况下,识别的准确率依旧保持在96%以上,这证明了学习到的特征不只是GT-AG法则,而是综合复杂的,在另一方面也证明了DeepAS模型具有很好的稳定性与泛化能力。此外,在二分类模型基础上设计了可以识别受体剪接位点、供体剪接位点、非剪接位点的三分类模型,并且在混合三种农作物的基因剪接位点数据集上进行了测试,准确率为85.91%,填补了三分类识别问题的空缺。4、基于设计的DeepAS模型开发了农作物基因剪接位点识别系统,系统可以根据用户选择的不同数据匹配相应的模型,在输入或上传数据并提交后可以实时反馈识别结果,系统网址为http://www.deepbiology.cn/DeepAS/。"
1672,基于序列信息对真核复制起始位点预测,"DNA复制是保持亲代到子代遗传信息稳定传递的关键步骤,是生物遗传的基础。复制起始于基因组的特殊位点,称为复制起始位点(ORIs)。复制起始位点对DNA复制的起始进行调控,在复制机制中扮演着十分重要的角色。研究复制起始位点不仅有助于理解细胞分裂周期和基因的表达调控,而且在遗传病的新药研究中会提供新的策略。因此,对DNA复制起始位点的准确识别将为DNA复制机制的探究及药物研发提供十分重要的线索。目前,众多湿实验技术能够精确捕获复制起始位点的位置,但庞大的数据量需要较长的周期,还需要投入大量的经费,因此,开发基于计算机的研究方法是很有必要的。而与此同时,生物信息学手段已经成功应用于功能基因组学和蛋白质组学领域,并随着三代测序产生的爆炸性数据量,使得采用计算机方法识别复制起始位点成为可能。本文中研究中,我们构建了第一个多物种真核生物复制起始位点的集成预测器ORi-Pred。首先,从数据库DeOri和OriDB获取了人类、小鼠、果蝇、拟南芥、酿酒酵母、毕赤酵母、裂殖酵母和乳酸克鲁维酵母八个真核生物的DNA复制起始位点数据集,基于支持向量机(SVM)五折叠交叉检验分别用k-mer、理化性质矩阵、二进制编码三种特征提取算法表征序列并比较结果,对最佳特征提取算法获得的特征用F-score进行特征筛选,并基于最佳特征集将SVM与其他算法比较获得每个物种的最佳分类模型。由于酿酒酵母具有作为模式生物的独特优势,前人在研究真核DNA复制起始位点时多将其作为实验研究对象,因此提升模型对酿酒酵母复制起始位点的预测精度对实验人员具有重要的指导意义。基于此,我们在现有的准确率为84.83%的酿酒酵母复制起始位点分类模型的基础上,使用二型伪核苷酸方法提取序列特征,通过两步特征筛选策略,最终获得了准确率为88.53%的酿酒酵母最佳分类结果。综上所述,人类、小鼠、果蝇、拟南芥、酿酒酵母、毕赤酵母、裂殖酵母、乳酸克鲁维酵母八个物种的最佳模型的准确率和ROC曲线下的面积分别为88.40%和0.947、85.03%和0.909、87.38%和0.946、82.64%和0.870、88.53%和0.905、90.45%和0.948、93.99%和0.978、83.82%和0.890。最后为了方便相关领域研究者使用,我们基于八个物种的最佳分类模型构建了一个多物种真核生物复制起始位点集成预测器ORi-Pred(http://lin-group.cn/server/ORI-Pred/)。"
1673,基于序列的细菌终止子识别,"转录终止是基因表达的重要调节步骤,而转录的结束由终止子决定。如果基因中没有终止子,则转录不能停止,从而导致基因表达异常。检测细菌中的终止子不仅可以确定细菌生物中的操纵子结构,还可以改善基因组的注释。因此,准确识别转录终止子对于转录调控的研究来说是非常重要的。虽然生物化学实验方法可以清楚准确地识别终止子序列,但是非常耗时且昂贵。为提高效率,人们已提出一些计算方法。这些方法主要分为两类:(1)使用核酸组成信息来描述终止子。(2)将发夹结构特征以及下游的T富含区域作为特征用于描述终止子。由于这些方法不能反映终止子的统计特征,所以本文提出了基于序列信息,用机器学习的方法来识别细菌终止子。本文基于低冗余性基准数据集构建了用于识别细菌转录终止子的“iTerm-PseKNC”模型和“DeepTerm”模型。(1)“iTerm-PseKNC”是基于支持向量机(SVM)开发的终止子预测模型,该模型使用二项分布特征筛选技术得到伪K-元组核苷酸组成(PseKNC)的最佳特征子集,利用五重交叉检验来测试模型的预测性能,结果显示,该模型的预测精度达到了95%的准确率。(2)“DeepTerm”是一个基于卷积神经网络的终止子预测模型。该模型使用One-Hot编码作为输入特征,五重交叉验证测试结果显示“DeepTerm”能够获得99.40%的准确度。为了进一步评估“iTerm-PseKNC”模型和“DeepTerm”模型的泛化能力,本文构建了两个独立测试集,分别是经实验验证了的大肠杆菌和枯草芽孢杆菌Rho非依赖终止子序列。结果表明“iTerm-PseKNC”模型和“DeepTerm”模型都可以识别大肠杆菌独立测试集中的所有终止子序列,在枯草芽孢杆菌独立测试集上的测试精度分别为87.5%和99.24%。本文基于“iTerm-PseKNC”模型建立了的服务网站http://lin-group.cn/server/iTerm-PseKNC/,实验人员不需要做复杂的计算,可以直接使用该网站很轻松的预测序列是否为终止子。"
1674,基于机器学习算法对海浪波高的预测及优化研究,"海浪是海洋表面重要的运动过程,机器学习是目前国内外热门研究领域,本文将海洋科学与机器学习相结合,探索了机器学习在海洋科学领域应用的可行性,为今后的研究奠定基础。本文采用了机器学习中的两种不同算法对海浪有效波高进行预测和修正。(1)建立使用支持向量机(SVM)的预测模型,选取风场和波浪场作为学习要素,对比不同特征向量对有效波高预测结果的影响。取台湾岛东部海区作为实验区域,使用NCEP再分析的数值模式数据作为学习样本。选用支持向量分类机,建立了四组不同特征向量的模型对海浪有效波高进行预测,并对四种模型的结果进行比较和分析。实验表明,当输入的特征向量过多或过少时,会对模型的预测结果和计算效率产生不同的影响。当使用风场和波浪场共同作为特征向量进行学习时,在该区域预测结果更接近模式预报结果,相关系数将近99%,均方根误差约为0.2m。(2)使用神经网络模型建立模式结果的优化模型,对MASNUM海浪模式的有效波高进行优化。选用风场,波浪场作为学习要素,选取南海海域作为实验区域,按季节划分了夏季、秋季、冬季3个模型进行训练。与卫星观测的数据相比,修正后结果的均方根误差与绝均差减少了约30%。"
1675,测井曲线岩性识别的神经网络集成策略研究,"在油田的勘探开发中,精细储层描述是降低当前油气勘探成本,改善油气勘探精确性,增强非常规油气资源有效动用能力的必要条件。其中,利用测井曲线进行岩性识别是精细储层描述中重要的方面之一,根据其识别结果可以将岩石性质转化为相关的储层参数并应用于油气勘探中,有效的降低了开发成本并同时提高了勘探工作效率。因此,根据油田的实际生产需求,本论文对岩性识别这一课题进行了三个方面的研究:测井曲线复原、测井曲线特征提取以及特征提取后的测井曲线集成神经网络岩性识别。(1)针对因测井设备不完善造成测井曲线缺失问题,利用稀疏字典学习算法,研究了一种基于DCT分频稀疏表示的测井曲线复原方法。该方法首先运用离散余弦变换(DCT)对无缺失训练测井曲线进行分频;然后针对不同频段分量上的测井曲线进行字典学习;最后,运用稀疏表示对缺失测井曲线进行高精度的复原。(2)针对测井曲线分布复杂、混杂随机噪声的问题,本文研究了一种多频特征联合的测井曲线特征提取方法。该方法首先提取了原始测井曲线的统计特征和纹理特征;在此基础上,利用离散余弦变换(DCT)对不同属性的特征信号进行分频处理,并提取出不同属性特征数据的频率信号;最后,将不同频段分量上的特征数据进行联合,实现对原始测井曲线的特征提取。(3)为提高岩性识别精度,本文研究了一种针对多频特征的集成神经网络岩性识别方法。该方法在是以现有人工神经网络法为基础进行的改进,主要是通过对单一岩性进行识别,由此获取各类岩性的识别标签,并且,针对岩性样本数据较小的岩性识别问题,采用岩性中心聚类的形式进行中心值的提取;然后对不同类型的岩性标签进行权值投票;最后,实现未知井口的全岩性的高精度识别。"
1676,基于电磁超声的油气管道无损检测技术研究,"管道是运输石油天然气的主要工具。目前国内长输管道大多输送高温、高压、易燃、易爆、剧毒和有腐蚀的介质,当管道存在缺陷时,如果处理不及时,会引起泄漏或爆炸等事故。所以管道完整性检测具有必要性。由于管道表面凹凸不平,裂纹缺陷容易出现在环焊缝处等问题,使油气管道上的缺陷较难被检出。电磁超声检测技术由于其耐高温,无须耦合剂,范围广,无须清理管道表面,尤其是允许探头和被测物体间存在一定的提离距离,成为了新兴的管道检测技术。本文首先分析了电磁超声在不同材料中的激励和接收原理,建立了物理模型和数学方程,讨论了电磁超声技术应用于西南油气管道的可行性。其次,针对高提离干扰下的电磁超声回波信号,提出了一种新的电磁超声回波模型,新模型假设并验证了高提离干扰电磁超声回波信号中,回波信号是由超声信号,高频的窄带背景噪声信号以及白噪声所组成。再次,提出了一种针对高提离干扰的电磁超声消噪算法,此算法成功去除油气管道的电磁超声目标信号中的噪声,实现了弱信号的提取,并且此算法能够保留缺陷信息特征,提取缺陷回波,对不同类型的缺陷进行了验证。最后,通过结合主成分分析和支持向量机模型,验证了管道环焊缺陷信号的识别性能。"
1677,改进极限学习机带钢厚度预测系统的设计与实现,"随着社会的进步,汽车、家电、电子产品等许多行业得到快速发展,同时也提高对工业轧制产品质量的要求。在工业轧制过程中,带钢出口厚度是衡量轧制产品质量的重要评价指标,但影响带钢出口厚度的精度存在很多因素,而且每个因素对带钢出口厚度影响不同。因此对带钢出口厚度精度的智能控制,是轧制工业亟待解决的首要问题。目前钢铁轧制智能控制理论研究相对较少,随着人工智能技术在各个领域智能化、精细化的发展取得显著成就。轧制智能控制也成为人工智能研究的重要内容。通过学习机器学习理论,本文提出一种改进的极限学习机神经网络模型―混合蛙跳的反馈极限学习机(SFLA-FELM),将其应用于轧制控制中,设计并实现了改进极限学习机的带钢厚度预测系统,主要实现的功能:系统注册登录、系统信息管理、数据管理及预处理、带钢厚度预测模型构建、带钢厚度预测。其中数据预处理和带钢厚度预测模型构建是本文研究的重点。本系统使用的数据来源于国内某钢厂的热连轧带钢实际生产过程,数据预处理中,首先利用互信息法计算带钢出口厚度与各影响因素的互信息值;然后选择对带钢厚度影响较大的因素,完成特征提取,从而降低模型的复杂度,提高预测精度;最后归一化带钢数据,使数据量纲统一,进一步提高系统预测精度。在带钢厚度预测模型构建中,在极限学习机中引入卡尔曼滤波思想,将网络的实际输出与期望输出的差值反馈给输入层,形成一种反馈极限学习机(FELM)算法。同时运用混合蛙跳算法对FELM算法的随机参数进行优化,从而构建一种SFLA-FELM预测模型,并设计实现带钢厚度预测系统。经测试,本文设计实现的带钢厚度预测系统取得较高预测精度,系统在功能和性能方面都能满足预期效果,并能够稳定运行。"
1678,Ti、Nb和Ti-Nb合金EAM势的开发及应用,"钛基合金作为目前研发热门的金属材料之一,由于其优异的结构性能,具有非常广阔的应用前景。钛铌合金材料在航空航天领域,生物医学工程领域和船舶舰艇制造工程中应用越来越广泛,同时在其他领域也存在着巨大的应用前景。应用领域决定了钛合金需要长期服役于苛刻的工作环境中,这对材料性能要求较高。为了解材料使役过程中的失效机制,引入组织和缺陷相关的原子模拟是非常重要的。而原子间势正是原子尺度模拟的关键。近年来虽然势函数开发工作取得了较多的成果,但用于大尺度材料模拟且计算精度高的较少,特别是在层错等材料变形机制方面很难精确再现。本工作在这方面做了很大的努力,目的是开发可以提高材料分子动力学模拟精度的原子间势。基于EAM的框架,本文开发了Ti、Nb和Ti-Nb合金的原子间势,提出了新的函数形式以及新的截断函数。势参数拟合是通过均方差最小法再现平衡晶格常数、结合能、弹性常数、未弛豫空位形成能等物理性质来确定。在这些物理性质的基础上又加入第一原理计算合金单方向拉伸数据用来拟合合金势参数。同时运用第一原理对Ti、Nb和Ti-Nb合金材料相应的性能计算,为势函数提供相应物理性质的理论数据参考。作为原子间势的检验与应用,采用分子动力学软件LAMMPS和ParaMD对材料缺陷性能模拟计算。首先计算了拟合参数时所用到的几种物理量,检验势函数精准性,结果表明本文的原子间势可以很好的再现晶格常数等性能,并且均方差值小,精度较高。原子间势曲线符合原子间相互作用关系,并且曲线光滑有利于材料原子尺度模拟。对纯金属势函数的结构稳定性稳定性做了检验,结果表明Ti和Nb最稳定的结构分别为HCP结构和BCC结构,这一结果表明本文原子间势可以很好的描述材料的结构。其次分子动力学模拟了材料的缺陷性能,如单、双空位形成能、自间隙形成能、表面能、稳定层错能和面层错能,计算结果显示本文原子间势可以很好的描述材料缺陷性能。以往开发的Ti的EAM势函数在层错能方面的表现都不尽人意,导致材料分子动力学模拟表现欠佳。本文原子间势计算得到Ti的基面层错能可以达到107.54mJ/m~2,这比大多数同样使用EAM构建Ti的势计算值更接近实验值。这一结果对分子动力学模拟非常有利,因为如果原子间势计算层错能过低,当模拟材料其他结构形变时,会优先出现层错结构,不利于计算。并且在层错能计算工作中也发现了如果对势函数计算层错能的需求过高,会导致势表征材料的其他性能时急剧下滑,虽然目前工作中Ti的层错能虽不及实验值,但也应该是本方法的计算极限。Ti面层错能的计算结果表明,本工作的原子间势可以很好的模拟该材料的形变行为。对Ti-Nb合金势在弹性模量、晶格常数、结合能和合金中空位原子不同时的空位形成能等物理性质做了计算分析,计算结果表明相应的物理性质与第一原理结果符合很好,Nb含量不同时Ti-Nb合金的结合能变化趋势与第一原理计算趋势符合,合金势函数曲线光滑,可以很好的再现材料的物理性质。"
1679,危险液体检测可移动设备的研究,"2001年9月美国发生了911事件,从此以后恐怖组织的威胁愈演愈烈,全球开始进行反恐运动。因为机场、地铁、汽车站等公共场合长期受到恐怖活动的威胁,所以市面上出现了各种各样的检测设备,特别是瓶装液体安全性检测越发受到重视,而现有的检测手段准确度不高,检测效率低下,容易出现检测漏洞。在此背景下,开展对危险液体检测手持设备的研究变得尤为重要。本文首先对现阶段已成熟的危险液体检测技术进行介绍,并比较了每一种方法的使用范围和其优缺点,介绍了电磁波在多层均匀介质中传播与反射的理论,以及机器学习分类算法,然后提出了微波法和电容法两种方案,建立了等效模型并制作了样机,全文以微波法为主要方案,电容法作为对比方案。微波法根据电磁波在不同液体分界面的反射率不同来进行区分,首先在一个宽频带范围内获得不同液体的大量反射率数据,然后加上标签,使用支持向量机SVM训练,使用线性核得到各个维度的权重参数,最后根据决策函数实现分类。根据需要,本文设计并实现了一对工作在0.5GHz~3.5GHz的宽频带微带天线,组装扫频仪模块,实现电源模块和显示模块,并在DSP上实现了噪声消除算法和分类算法,最后开发出样机。电容法依据低频电容的决定式,利用不同液体相对介电常数(简称相对介电)的不同所对应的电容值差异来进行区分,在低频范围测得阻抗后,与事先设定的阈值进行比较,从而辨别不同液体;根据需要,本文设计并实现了矩形叉指平面电容以及相关测量电路,在ARM单片机上实现了分类算法。最后,本文利用两种方案搭建的测试样机,完成对不同液体的实际测试,并比较两种方案的准确度,根据测试误差对结果进行分析,并找出了误差来源。与其他液体检测设备相比,本文方案主要有以下优点:第一,本方案使用了微波技术以及机器学习理论,准确度高,检测速度快,能区分的液体种类多;第二,作为手持设备,体积小携带方便,容易使用;第三使用超宽带频点测试,稳定性和重复性较好。"
1680,产品设计历史数据驱动的设计方案生成方法研究,"随着科技进步和生活水平的提升,客户对产品的需求越发个性化、多样化和复杂化,这对产品的设计提出了更高的要求。而产品设计是集需求、意图、功能、结构、层次、规则等多种元素集成的产品功能结构原创型或改进型开发过程。因此,有必要开发一种产品方案快速生成方法,以实现产品对市场和需求变化的快速响应。针对此问题,本文提出了一种基于客户需求多层次分解和产品历史设计案例数据驱动的产品设计方案生成方法,实现了基于客户需求的产品的快速设计。主要研究内容如下所示:(1)基于FAHP和改进QFD的客户需求分层映射研究。采用FAHP确定客户需求的权重,建立基于FAHP和改进QFD的客户需求分层功能映射模型,将性能需求和功能需求转化为对应的工程特性指标。然后,根据指标权重值将性能特性划分为三级,同时利用FAST模型分解功能特性。(2)基于专利文本的设计历史案例数据挖掘研究。首先,建立专利文本的知识表达模型,利用文本挖掘方法对专利文本进行词性标注和句法分析,抽取出功能文本和结构文本数据。在此基础上,建立基于功能结构数据的设计案例样本数据,为后文的设计模型构建奠定基础。(3)基于案例数据的模型构建与设计方案生成研究。选用多层前馈神经网络作为训练模型,利用样本数据训练模型,通过调整参数使其达到最优。同时,利用相似匹配法则确定功能特性数据。将该数据输入到训练好的神经网络产品设计模型中,模型自动输出符合要求的产品设计方案,实现产品的快速设计。"
1681,基于深度学习的遥感影像语义分割方法研究,"遥感对地观测技术是一种快速、高效的数据获取方法,获得的影像数据在包括林业在内的多个行业被广泛应用。语义分割是林业遥感影像分析中主要的应用之一,与影像分类相比,能够获取遥感影像中更为丰富的语义类别信息,并为生态监测、退耕还林等任务提供决策信息。研究快速、精准的语义分割方法对于林业具有重要的意义。由于遥感影像中林木具有分布无序,形态无规则等特点,基于深度学习的经典语义分割模型U-Net无法对林木达到较高的语义分割精度,此外,U-Net还具有模型复杂度高、计算耗时、对类别不平衡数据集的语义分割效果欠佳等主要问题。对于上述问题,本文对经典语义分割神经网络U-Net进行多步结构优化,提出用于林木/背景二类别语义分割的神经网络STS-Net(Simplified Tree Segmentation Network);对语义分割数据集内存在的类别不平衡问题,提出类别敏感加权损失函数;对于使用遥感瓦片语义分割结果拼接得到的大幅面语义分割图的平滑度欠佳的问题,提出重叠预测后处理算法。本文的主要工作如下:(1)以提升神经典语义分割经网络U-Net的语义分割精度、减少神经网络复杂度及加快神经网络运算速度为目标,使用4步结构改进方法优化神经网络模型,并提出STS-Net语义分割神经网络。改进方法包括使用紧凑卷积模块替代标准卷积层、裁剪网络中不必要的计算模块、使用残差连接增强卷积模块、使用改进的级联空洞卷积增强卷积模块序列。实验结果证明与经典语义分割网络U-Net相比,STS-Net以更少模型权重、更快的运行速度,达到了更高的语义分割精度。(2)为改善遥感影像语义分割数据集内的类别不平衡问题,提出了类别敏感加权损失函数。所提出的损失函数使用当前时刻神经网络对每一像素的语义分割精度,作为可变权重因子改进经典交叉熵损失函数,能够降低已经达到较高语义分割精度的像素点在损失函数平均值中所占的比重,实现类别均衡化处理。实验证明与经典交叉熵损失函数相比,类别敏感加权损失函数能够提升神经网络对类别不平衡数据集内小类别样本像素点的分割精度。(3)在使用遥感瓦片语义分割结果拼接为大幅面遥感影像语义分割图后,出现图内局部语义分割不连续的问题,对此提出重叠预测后处理算法。该算法使用单模型多数据副本的处理策略,对相邻遥感瓦片的重叠区域,首先合并神经网络对同一像素在各瓦片中像素副本的分割结果,再计算得到大幅面语义分割图中该像素点的最终语义类别。实验证明该算法能够进一步提升已训练神经网络在测试集上的语义分割精度。"
1682,基于深度领域自适应的振动数据故障分类方法研究,"深度学习理论以其强大的建模和表征能力成为数据驱动的智能故障诊断领域中最活跃的研究方向之一,然而使用深度学习训练故障分类模型需要大量有标注的数据以及训练数据与测试数据满足独立同分布,在实际应用中这两个条件通常难以满足。首先,数据的标注是一个昂贵且耗时的操作,另外机械设备通常会工作在不同工况下,导致采集的振动信号数据分布产生差异。因此,如何利用少量的有标注数据或者辅助领域数据,来建立一个可靠的数学模型,对具有数据分布不同的目标领域开展故障诊断是待解决的问题。迁移学习是一种利用现有知识解决不同但相关领域的机器学习新方法,为解决此类问题提供了基本思路。因此,本文将深度学习和迁移学习结合起来,用于滚动轴承的振动数据故障分类,在有标记数据稀缺甚至没有的情形下依然能达到较高的故障分类精度。本文的主要研究工作包括以下几点:(1)介绍了基于深度学习的滚动轴承故障诊断的研究背景、当前的研究现状和存在的问题。然后对深度学习和迁移学习的基本原理进行了深入研究,提出将迁移学习和深度学习相结合的思想,用于滚动轴承的故障诊断。(2)提出了一种基于深度卷积孪生网络的振动数据故障分类方法,用于解决目标领域中仅含有少量有标注训练样本的监督迁移学习问题。首先将源域中的样本和目标领域中的样本进行配对,在深度卷积网络基础上设计了一个卷积孪生网络,通过多层非线性变换进行特征提取,并使用多层适配来将两个领域中的数据映射到同一个特征空间中,通过定义平衡因子来达到更好的适配效果。实验结果表明在变工况环境下所提方法可以有效解决训练样本不足的问题。(3)提出了一种基于深度对抗迁移网络的振动数据故障分类方法,用于解决目标领域中只包含无标注训练样本的无监督迁移学习问题。采用生成对抗网络中的对抗训练思想,让特征提取器与领域判别器进行对抗训练,并以Wasserstein距离作为度量标准,用以学习出一个领域无关的特征,达到领域适配的目的,并同时最小化分类误差,在保证所学特征不包含领域信息的同时,包含故障类别信息,最终达到跨领域进行故障分类的目的。"
1683,基于支持向量机的房颤识别研究及常见心律失常监护系统模型设计与实现,"无论是便于携带的单导联心电采集设备,还是多导联的心电采集设备,采集到的心电信号均可能包含呼吸、运动和导联脱落等导致的噪声。心电伪差的出现会导致心电特征参数(如RR间期、QT段等)失真,引起基于心电图疾病诊断的误诊或漏诊。严重的心电伪差可能掩盖真实的心电信号,使得被掩盖的心电信号失去辅助诊断和监护心脏疾病的价值。因此,识别并去除心电伪差可以有效提高心电图质量。房颤是一种常见的心律失常疾病。随着城市化和社会老龄化速度的加快,其发病率不断增长。高效、准确的房颤自动识别方法是实现大规模房颤监护和管理的技术保障。为此,本文采用支持向量机(SVM)技术,开展了心电伪差和房颤识别方法研究,并在此基础上,开发了一套常见心律失常监护系统模型,为提高基于心电信号的多种心律失常早期判别与监测以及任何时间、任何地点的健康状态实时监护提供技术保障。具体研究内容如下:(1)基于支持向量机的多特征参数心电伪差识别研究。提取心电信号的第一主成分贡献率、R波幅值的标准差、模板匹配的相关系数、QRS波能量占比和样本熵等5个心电信号质量指标(SQI),并采用网格参数寻优方式的支持向量机算法,构建伪差和心电信号分类识别模型。将PhysioNet Challenge 2011、PhysioNet Challenge 2017、MIT-BIH Arrhythmia Database和Noise Stress Test Database 4个心电数据库的伪差数据和非伪差数据融合,构建了一个验证数据集,并采用10折交叉验证该模型的性能。实验结果表明,本文方法的敏感度、特异度、阳性预测率和准确率分别达到98.33%、98.14%、98.04%和98.24%,具有较强的心电伪差检测识别能力。(2)基于不均衡多分类支持向量机的房颤识别方法研究。首先从现有研究中收集房颤、非房颤、伪差和正常心电信号相关的134个候选特征。考虑到P波难以准确定位,因此去掉P波相关的24个特征。然后对剩下的110个候选特征做两两相关分析,再滤除相关系数大于0.9的冗余特征和复杂度较高的特征,形成一个有效特征集,用于房颤、非房颤、伪差和正常心电信号的分类识别。接着,通过分析各类样本数量的分布情况,设计一种不均衡四分类支持向量机,并与有效特征结合建立了一种识别房颤、非房颤心律失常、伪差和正常4类心电信号的方法。最后,采用PhysioNet Challenge 2017比赛提供的数据验证本文方法并与其他相关方法比较。实验结果表明,本文方法整体上获得了较好的性能。进一步,采用MIT心律失常数据库和MIT房颤数据库中的数据对本方法选择的有效特征进行验证。实验结果表明,本文方法在上述两个数据库上识别房颤的分数均达到0.97及以上,识别非房颤心律失常、伪差和正常的分数均达到0.9以上,在房颤辅助诊断和监测方面具有良好的应用前景。(3)房颤与非房颤心律失常监护系统模型设计与实现。根据房颤及其他心律失常监护与管理的真实需求,设计了一种基于心电信号的房颤与非房颤心律失常监护系统模型。采用心电信号获取模型模拟真实系统的数据采集过程,采用心电信号无线传输模型模拟各数据之间的传输过程,采用心电信号智能处理模型模拟真实系统的信号处理过程,采用心电信号显示模型模拟真实系统对判别结果的展示。测试结果表明,该模型功能全面、实时性和可操作性强、界面友好,使用方便,为实际应用提供了理论和技术保障。"
1684,基于深度学习的多车牌字符识别算法研究,"随着社会经济的高速发展,汽车数量的急剧增加,智能交通管理成为当今社会主流,其中车牌识别是智能交通的核心环节之一。目前,市场上已出现各种各样的车牌识别系统产品且取得不错效果,但针对单一车牌来说,当光照不足、背景复杂、车牌倾斜变形时,识别效果就差强人意了。如何克服这些问题,让车牌识别系统变得更加稳定和通用,成为新的研究热点。本文就近几年在图像识别领域取得巨大成就的深度学习方法进行研究,采用其中的卷积神经网络来实现多车牌字符识别,主要包括三个步骤:车牌定位、字符分割和字符识别。首先是车牌定位环节。由于拍摄的图像质量参差不齐,提出基于改进二维离散小波变换的图像增强方法改善图像质量,获取车牌边缘信息;接着,利用车牌字符在车牌底色上整齐排列产生规律的纹理信息,检测到车牌边缘线的跳变次数,可以粗略定位车牌所在行;然后,根据车牌底色的阈值范围,将小范围的车牌信息图经过颜色空间转换,找到多车牌的可能位置;最后,通过先验知识,筛选车牌,精确定位所有车牌。实践证明,这种定位方法准确率高、速度快。但其中的颜色筛选过程对光照敏感,使得夜晚的定位效果欠佳,因此,又加入基于机器学习的方法弥补这一不足,通过Adaboost算法对特征进行训练,不依赖于颜色特征检测车牌,实现夜晚条件下的多车牌的定位。其次,字符分割是中间环节。由于拍摄角度可能影响车牌倾斜,因此,提出基于角点仿射变换的方法来快速矫正倾斜车牌。其主要思想是根据车牌的形状特征,找到车牌矩形框的角点,取其中不共线的三个点仿射变换成直角三角形,实现整个车牌的倾斜矫正;接着,对于矫正后的车牌提出基于垂直投影和连通域判断的方法分割字符,得到用于识别的单个字符。最后是字符识别。通过分析当前流行的AlexNet、VGGNet、GoogLeNet和ResNet等卷积神经网络,根据字符识别的难度和特点,设计基于改进的AlexNet模型用于字符识别。由于整个网络的模块较多、不同的卷积核大小、批量化大小和Dropout率对于网络性能的影响不一,需要通过设计实验来得到最优化的网络参数;最后,通过开源的OpenCV平台,将字符识别结果打印在待识别的车牌图像上。"
1685,雾霾天气条件下车牌识别算法的研究,"在雾霾天气下,由于大气的散射作用导致反射光减弱光线变暗,以及大气的光参与成像导致户外相机拍摄的车牌图像产生颜色失真、模糊不清以及图像偏移等现象,从而导致车牌识别系统的识别率降低,无法达到工程应用的标准,严重影响道路交通管理。为解决雾霾天气车牌识别率低的问题,本文以雾霾天气为基础,对车牌识别算法进行了研究,主要内容包括:车牌图像预处理:雾霾天气会使车牌识别系统出现不能正确识别字符信息的现象,本文对传统Retinex算法求解照度分量的方法进行改进,使其更适用于车牌识别系统中图像的恢复与增强。该算法有效降低雾霾天气下图像退化带来的图像色彩失真和细节信息缺失的影响,进而有利于车牌识别系统中车牌定位,字符分割和识别。实验结果从主观和客观两个方面表明,改进后的算法在增强图像的同时能够保留更多的细节信息,能有效提高雾霾天气下车牌的识别率。车牌定位实现:在上一步的基础上,将获得的车牌图像进行定位。由于雾霾天气下获得的图像清晰度较差,所以本文对常用的车牌定位的算法进行了改进。首先通过处理速度快Canny边缘检测算子结合形态学与迭代融合处理进行车牌粗定位,再利用简化后的Alex Net卷积神经网络模型去除伪车牌进行车牌精定位。该方案解决了目前车牌定位技术在雾霾天气下定位准确率低且花费时间长的缺点。车牌识别:为了提高雾霾天气下车牌字符识别率,本文对基于卷积神经网络的字符识别算法进行改进,通过参数的调整和网络层数的设计,简化网络复杂度。然后改进网络训练方式,在训练集中增加识别准确但网络输出不确定性高的样本,组成新的训练集,进行再次测试,这样既减小了网络训练所需的样本,也能保证分类器性能。此方法在提高车牌识别准确率的同时解决了收集大量样本的难度。最后通过系统测试对本文算法进行综合评估,并对测试结果进行分析总结。"
1686,基于深度学习的无人驾驶感知与决策若干方法研究,"无人驾驶是人工智能领域重要的应用方向,它主要通过计算机系统以及一些智能传感器来达到无人驾驶的目的。它包括感知,决策和控制三个方面。感知方面如车道识别与车辆检测依然存在许多问题,如实时性问题,光照遮挡问题,点云数据的处理问题,二维车辆识别与车道线识别对驾驶环境描述不够具体等问题。而决策方面对于安全和可靠性有着严格的要求,现阶段的决策算法大多根据规则构建,仅能应对正常的驾驶环境,而面对驾驶环境的各种突发情况则很难做出及时正确的决策。本文针对环境感知中的车道识别、车辆识别与驾驶决策部分进行了相关研究,研究的主要内容如下:(1)传统的车道识别算法大多是基于传统图像处理技术的车道线检测,然而传统的算法需要进行预处理,边缘检测,霍夫变换等步骤,每个步骤独立进行却又相互影响,难以达到整体最优的目的,并且实时性问题也使得算法的应用性不高,最重要的是传统的车道线识别方法在应对车道的变化以及复杂的驾驶环境时适应性不佳。本文针对以上的问题提出了基于全卷积神经网络和条件随机场的车道识别方法。该方法将基于车道线的车道识别任务转化为图像分割任务,整个车道的分割过程达到端到端的结构,对于输入的各种驾驶环境图片有自学习能力以适应各种复杂环境下的车道识别。同时基于图像分割的车道识别技术更加符合真实的驾驶环境,对于车道中的各种行人车辆等障碍物具有很好的分离效果。(2)传统的车辆检测算法大多都是基于2D图像下的检测,尽管深度学习的一些相关网络算法如Faster RCNN,YOLO,SSD等在2D图像中的目标检测效果已经达到很高的准确率,并对于无人驾驶场景分析也有了不错的效果。但是对于3D真实世界场景的描述依然不够,例如在无人驾驶中,除了能检测行人,车辆,障碍物以外,对于其物体的速度,方向的检测与定位也十分的重要。针对这些问题,本文利用光学雷达的点云数据结合RGB图像来实现3D车辆的检测任务以更完整的描述真实驾驶场景,使用了PointNet网络来高效的处理点云数据信息,同时在检测过程中本文利用CNN网络以及级联拒绝分类器和比列相关池化的实时性以及准确性优势来提高3D环境下车辆检测的实时性。(3)现有的无人驾驶决策算法大多是采用规则的方式构建,对于具体的驾驶场景进行具体的规则定义。然而真实的场景下,由于复杂多变的气候交通等环境,以及棘手的突发情况,传统算法很难完全的做出正确的决策。为了解决这些问题,让无人驾驶系统更具有智能的决策方案,本文提出了基于强化学习的决策算法,强化学习是一种无监督的机器学习算法,相对于大多的深度学习算法,它不需要人工的标注标签从而省去了大量的成本。本文将RGB图像输入作为状态空间,而定义车辆的转向刹车等做为行为空间,同时将在不违反交通规则以及安全的情况下尽快完成路程作为奖惩机制,使得算法模型可以自发的在行驶的过程中学习驾驶的决策方法。"
1687,基于在线评论文本分析的汽车产品选择方法研究,"近年来互联网的快速发展,使得在线购物和社交媒体迅速普及,用户在网上产生大量的关于汽车产品等方面的文本评论。这些用户数据中具有大量有价值的信息,包含了用户在使用过程中对该产品的体验满意情况,采用合适的文本分析技术进行情感分类,能够从评论文本中了解用户诉求。目前关于汽车在线评论情感分类及产品选择的研究相对较少,尤其是缺乏采用深度学习等技术对该问题的探索和改进。对此,本文针对汽车在线评论情感分类和产品选择方法存在的问题,开展了基于门限递归单元的情感分类和产品选择的研究。使用深度学习方法能够更充分高效地提取评论文本中的用户体验情感信息,帮助企业提升产品性能,让消费者更全面了解产品的使用情况,具有重要的理论意义和现实意义。主要完成了以下工作:(1)完成了汽车在线评论文本的多通道建模。针对在线评论文本的特征,以及其在情感分类方面存在的问题,构建了词向量通道、词性向量通道和词情感信息通道,并完成了多通道融合。(2)提出了多通道建模的F-BiGRU情感分类模型。为提高汽车在线评论文本情感分类的准确率,在门限递归循环神经网络的基础上进行模型改进,该模型通过特征强化层对在线评论文本提取更充分的语义信息,并使用双向门限递归单元进行文本语义提取,完成文本情感分类任务。使用该模型,更适应于互联网评论文本随意性、口语性等特点,并和传统机器学习模型及卷积神经网络等模型进行对比实验,本文模型提升了情感分类的准确率,能更好完成情感分类任务。(3)提出了在线评论情感值排序的汽车产品选择方法。通过多通道建模的FBiGRU模型对评论文本进行情感值计算,得到不同车型各个属性的情感值并进行可视化。使用TOPSIS法对各属性情感值进行计算,得到各候选汽车的综合情感值,给消费者提升参考,使消费者更全面了解汽车的用户体验情况,帮助消费者更好的进行汽车产品选择。"
1688,一个汽车问答领域的中文自然语言理解子系统的设计与实现,"近些年来,随着人工智能技术的爆发式发展,越来越多的公司开始了在人机对话领域的探索。目前很多企业已经将对话机器人投入到生产中,如百度的小度、天猫的天猫精灵、小米的小爱同学、京东JIMI等,应用在智能家居、机器人客服等领域。在对话处理的自然语言理解(NLU)过程中,大都使用规则的方式对用户的意图和词槽进行抽取。这种方式虽然简单且稳定,但是随着规则的增加,维护和扩展的成本将会剧增。本文提出使用深度学习技术,设计并实现一套提供汽车问答领域的中文自然语言理解模型训练及管理的子系统,提供数据管理、模型训练、服务配置和NLU解析服务。通过对国内外自然语言理解相关技术的研究,及对国内相关的产品体验和使用,结合具体的业务场景,对自然语言理解子系统进行了需求分析,将子系统划分为四大模块,分别为训练数据管理、模型训练、服务配置和NLU解析服务。训练数据管理模块包含训练语料管理、词典管理和规则管理两个子模块,提供网页可视化的训练数据的录入或者删除。模型训练模块包含意图识别模型训练和实体识别模型训练两个子模块,配置模型训练用到的可选超参数,启动业务模型训练。服务配置模块展示了所有已经训练好的意图识别模型和实体识别模型,根据需求选择意图识别模型和实体识别模型进行自然语言理解解析测试,启动NLU服务。NLU解析服务模块是一个Thrift服务,接收调用请求,提供解析功能。系统使用Python语言实现,模型设计使用Pytorch框架,远程服务调用使用Thrift框架,使用Flask框架构建Web应用。自然语言理解子系统实现屏蔽了模型训练的具体细节,为模型开发用户提供了简单易用的界面,为服务调用方提供了高效、精准的模型。"
1689,面向认知地图的地标识别研究及其应用,"地图在智能驾驶中扮演着十分重要的角色,地图是智能车能够顺利抵达目的地的保障。地图的核心元素是存储在其中的各类地标及其代表的实际意义,这些地标贯穿智能驾驶的整个过程,包含车辆定位、辅助感知、辅助决策,因此进行地标识别的研究是十分有必要的。为了识别这些地图核心元素,本文提出了基于深度学习的地标识别方法,包含道路级地标识别方法以及车道级地标识别方法,本文主要内容如下:针对道路级地标,包含各类交通标志牌、交通信号灯、指示牌、路灯等交通标志,本文首先建立了电子科技大学清水河校区的交通标志数据集并分析交通标志牌具有小目标且类别间相似的特点,然后提出了基于多层次融合多尺度预测的道路级地标识别网络。网络主要分为两个结构:1、多层次融合结构,本文首先根据道路级地标分布特点改进了特征提取结构,然后提出了基于稠密连接方式的特征融合结构,更加关注网络低层的特征图,旨在提升网络对于小目标的识别效果;2、多尺度预测结构,在网络的预测阶段通过多尺度的特征图来进行预测,不同尺度的特征图负责识别图像中不同尺寸的目标,使得网络对于大目标和小目标均能实现较好的识别效果。最后在数据集上进行训练和测试,实验结果显示,本文方法相较于当前主流的目标检测网络Yolov3在mAP指标上提升了3.81%。针对车道级地标,包含车道线、允许直行、允许左转等交通标线,本文首先分析了车道级地标局部相似的问题,然后提出了融合全局特征和局部特征的车道级地标识别网络。在特征图层次,针对局部相似的问题提出了基于多尺寸大卷积核的特征融合结构,通过大尺寸的卷积核使得特征图保持更大区域间的紧密连接;在网络层次,提出了基于通道注意力机制的高低层特征融合结构,提高特征的有效性;在预测层次,将上采样阶段不同尺寸的特征图先融合后预测。实验验证本文提出的网络实现了车道级地标的识别功能,相较于Unet网络在mIoU指标提升了7.11%,在mAcc指标上提升了7.89%。为了验证本文网络的泛化能力,首先介绍了智能车平台和数据采集模块,通过该平台采集了校园区域的真实数据,测试验证了本文网络对于地标识别的可靠性和稳定性。"
1690,支持汽车维修自动问答的案例匹配方法研究,"汽车维修案例资料获取难、故障诊断效率低以及故障诊断门槛高是汽车维修领域的服务顾问与车主面临的主要问题。基于ASP/SaaS的制造业产业价值链协同平台构建的服务协同体系,及其维保数据档案库尽管能支持服务顾问对汽车维保问题的初判,但基于平台的维保项目诊断咨询协同模式还存在服务不直接、不便捷,服务受人为因素影响大,提供的信息不透明、不对称,对语义相关的问题无法理解区分,以及维保案例的查询结果信息冗余等问题。迫切需要建立一种第三方中立的,通畅、透明的信息渠道以辅助车主与服务顾问独立、自主地完成汽车故障初判、维保知识获取、维修技术了解等。据此,本文依托国家重点研发计划课题“分布式资源巨系统及资源协同理论”(课题编号:2017YFB1400301)中的第三方“基于ASP/SaaS的制造业产业价值链协同平台”(以下简称平台)的近10年上万家车企的积累的售后维保服务业务数据展开研究,重点基于该平台的“汽车维修案例”大数据,在分析车企服务顾问技术支持、车主自主维保信息获取等共同需求的基础上,提出基于第三方支持汽车维保方案匹配的自动问答系统解决方案,并分析了该自动问答系统实现的关键需求问题,在此基础上完成了自动问答系统的功能设计和总体设计。论文重点围绕支持系统实现的三个核心关键点:问题语句文本信息解析、语义理解、方案匹配结果提取的方法展开研究,根据“汽车维修案例”数据特征完成基于NLP的关键词提取与词组扩展工作,以支持用户查询意图的初步解析;针对查询语义相似问题,在完成基于word2vec模型的文本向量化和BM25答案排序算法设计的基础上,提出了基于词项融合与词项位置关系的改进算法,以支持语义理解并实现相似案例的归集;提出了基于连续语言模型的案例结果提取方法,消除了问答结果冗余问题;并通过实验验证了本文所提出的方法的有效性。"
1691,风电功率预测不确定性及含风电的电力系统鲁棒优化调度,"风能作为清洁能源,在世界各国得到了广泛应用。但是风资源本身的波动性决定了风能利用时必然会产生不确定性问题,无论是陆地风电还是海上风电,在利用风能时都将面临风电功率预测的不确定性。因此,如何提高风电功率预测精度,是风能利用丞需解决的问题之一;另外,大规模的风电并入电网也会对电力系统的调度带来很大影响,如何提高风能利用率,减少弃风量,降低电力系统发电成本,提高电能可靠性和电能质量是风能利用所要解决的另一大问题。因此,本文提出了一种基于支持向量机的风电功率预测方法,并研究了风电功率预测不确定性,构建了适用于电力系统鲁棒优化调度的不确定集合以及含风电场的电力系统鲁棒优化调度模型。主要研究内容有:1、建立基于支持向量机(SVM)的风电功率预测模型。研究了风电场的风资源的风速特性和风向特性以及支持向量机算法,并利用实际风电场数据进行样本筛选,采用支持向量机功率预测模型,将预测结果与采用RBF和小波分析法得到的预测结果进行对比分析,最后通过算例分析验证了支持向量机预测方法具有较高的预测精度。2、本文分析了影响预测结果的不确定性因素,引入置信区间来描述风电功率不确定性,通过对比分析三台机组在不同置信度下的置信区间,来反映预测结果的波动范围;3、通过对预测结果的不确定性分析来构建可用于电力系统调度的不确定集合,所构建预测误差不确定集合是椭圆型集合,可以在保证集合精度的情况下大大减小其保守度,最后通过仿真分析验证其收敛性,结果表明,构建的椭圆型集合在降低保守度的情况下,仍然具有很好的收敛性。4、依据不确定性集合中风电的可能场景,合理计划自动发电控制(AGC)机组出力,建立以最小化发电成本和最大化利用风电为目标的鲁棒优化经济调度模型,并用某区域的电厂数据做算例分析,结果表明构建的调度模型具有很好的鲁棒性和经济性。"
1692,基于支持向量机理论的风电预测算法研究,"随着风电渗透率和清洁能源经济高效环保体系需求的不断提高,减少风电的弃风量,提升风电利用率成为风电研究的重要问题。因此,提高风电场的功率稳定性和改善风电场电能质量尤为重要。本文根据辽宁某风电场特性,对支持向量机方法的风电预测进行了研究。首先研究了机器学习理论的原理和统计学习理论中的相关概念,包括VC维和经验风险最小化。在大样本数据的情况下,通过学习输入和输出之间的映射关系,从样本的分类和回归问题两个方面对支持向量机进行了全面的阐述和研究。其次,研究了布谷鸟算法的搜索过程,通过加入自适应调整动态步长和模拟退火过程对布谷鸟算法进行了改进,提出利用改进布谷鸟算法对惩罚因子参数和核函数参数寻优的方法,在Matlab中分别利用网格法、布谷鸟算法和改进的布谷鸟算法三种算法对风电功率进行预测,并对预测结果进行分析。引入经验模态分解,对风电信号进行平稳化。阐述了经验模态分解的几个重要概念,包括瞬时频率、本征模态函数以及特征时间尺度。重点说明了经验模态分解的基本原理、流程、主要性质和存在的问题,然后根据存在的问题提出改进的方法,并将经验模态分解与改进布谷鸟算法的支持向量机相结合,建立了基于经验模态分解的改进布谷鸟算法支持向量机算法模型,并用风电场实际数据证明了该模型预测的准确性。"
1693,基于机器学习的居民电力消费特征研究,"近年来,居民电力需求占社会电力总需求的比例正在逐渐上升,与工业电力需求相比,居民电力消费需求具有增长快,弹性大的特点,容易通过相应的政策进行宏观调控。因此减少不合理居民电力消费有助于降低整个社会的电力消费,从而降低能源消耗,有利于经济持续健康发展。从需求侧角度来看,研究居民电力消费特征以及相应的电力消费行为有助于电力服务公司制定更加有效合理的干预政策。近年来,大数据技术和人工智能技术在能源消费模式与能源消费预测领域发挥着越来越重要的作用,因此本文利用机器学习技术对居民电力消费特征进行了研究。本文分别研究了居民电力消费模式和居民电力消费概率密度预测,并且利用江苏省南京市2014年电力消费数据进行了实证研究。首先通过k-means聚类算法研究了居民节日电力消费特征,结果表明:春节期间存在三种典型电力消费模式,符合春节期间居民行为规律;劳动节与国庆节期间存在两种典型电力消费模式,符合居民劳动节与国庆节期间行为规律。其次,分析了居民的季节性电力消费特征,研究发现:居民在冬季与夏季期间电力消费量高于春季与秋季期间电力消费量,并且夏季与冬季期间电力消费波动性较大;冬季居民电力消费量与夏季电力消费量容易受到极端高温与极端低温的影响;夏季高温会导致居民电力消费量明显增加,并且电力消费峰值对高温存在滞后效应,随着高温次数逐渐增加,居民电力消费对高温的响应时间逐渐变短。最后本文研究了居民电力消费概率密度预测问题,利用特征工程构造了影响居民电力消费的特征。如温度相关特征、历史电力消费相关特征、空气质量相关特征、天气相关特征、日期相关特征等。在此基础上,利用深度前馈神经网络与核密度估计方法分别构造居民电力消费点预测与概率密度预测模型。结果表明:温度、日期、历史电力消费是影响居民电力消费的主要因素;与随机森林和梯度提升树相比,深度神经网络预测精度更高;与点预测相比,概率密度预测可以给出准确的预测区间,从而为决策者提供更有效的信息。根据上述分析结果,本文有针对性地提出相关政策建议来鼓励我国居民节能用电。"
1694,电力系统暂态稳定性智能评估方法研究,"广域监测系统(WAMS)如今已被广泛应用于电力系统中,而基于WAMS的电力系统暂态稳定分析的研究进行的如火如荼。目前研究方法主要包括时域仿真法、直接法和人工智能法等。由于电力系统大数据的快速发展,基于人工智能的暂态稳定分析方法被看作是最具有前景的方法之一,国内外研究学者提出了多种应用于暂态稳定分析的智能算法(包括人工神经网络、支持向量机、决策树等)以提高预测精度,然而上述算法仍然存在准确率低、可解释性差等问题。针对这些问题,本文主要研究内容包括:1)通过分析电力系统暂态稳定的机理,研究影响暂态稳定性的物理因素,利用电力系统分析综合程序(PSASP)模拟真实电网中相量测量单元(PMU),设置电网中常见的扰动(如短路、断路等),采集电网中发电机的角度、角速度、有功功率、母线电压、电流等数据。2)提出一种基于XGBoost的电力系统暂态稳定预测方法,基于PMU数据构建暂稳特征,并分析特征之间的皮尔逊相关系数以进行特征选择。将上述得到的特征作为模型输入,在电力系统故障切除后及时预测该故障是否会导致系统失稳。基于模型得到特征重要度排序,挖掘出对暂态稳定性影响较大的特征,同时又可以剔除不重要的特征,加快模型训练速度且可以防止过拟合。然后针对电网中发生的某一具体故障,利用XGBoost模型进行预测,结果表明可以达到暂态稳定实时预测的要求,并使用LIME算法对预测结果进行解释,提高了模型的可解释性。3)由于传统的机器学习算法应用于暂态分析中需要基于PMU信息进行人工构建暂稳特征,特征构建的好坏直接影响到预测结果,并且构建特征的过程费时费力。为了解决该问题,提出了基于深度学习的暂态稳定评估,由于深度学习较于传统机器学习有两个优点:一是面对大数据量时,深度学习的拟合能力更强,二是可以自动提取特征。因此分别将卷积神经网络(CNN)和长短期记忆网络(LSTM)应用于电力系统暂态稳定预测中。4)为了进一步解析电网受到的扰动,除了判别扰动是否会导致系统失稳外,又提出基于深度学习的电力系统故障定位。在新英格兰10机39节点系统进行算例分析,该系统中有34条交流线路。基于CNN模型的暂态稳定性预测和故障定位准确率均可达到99%以上。"
1695,苹果叶片病害识别及品质预测管理系统研发,"近年来,气候变化对苹果品质的影响程度逐渐增强。针对气象因素进行科学的品质预测对于果农收入、果品供求、市场流通等具有重要作用。苹果病害时常发生,但由于果农缺乏病害识别与防控技术,易导致错判苹果病害种类而不当施药,造成经济损失。若及早发现并诊断病害种类,进行精准防控,对保障我国苹果品质具有重要作用。随着机器学习、深度学习的不断发展,借助算法有效地进行科学预测成为可能。本文针对苹果品质预测、图像识别模型等问题展开研究,主要研究内容及研究成果如下:(1)针对堆叠稀疏自动编码器训练时间较长的问题,提出了一种基于K均值聚类优化堆叠稀疏自动编码器模型。该模型共有2点改进:在传统堆叠稀疏自动编码器模型的基础上,引入了K均值聚类算法和并行级联学习机制,前者通过对输入层及各隐层的输入向量进行聚类,生成K个子类并行输入到K个稀疏自动编码器中训练,减少并行稀疏自动编码器的输入数据规模;后者通过并行级联学习,有效地融合并行稀疏自动编码器的权值参数,加快模型运行速度。该改进模型与最近提出的堆叠降噪稀疏自动编码器相比具有更高的识别准确率,且极大地减少了模型的预训练时间,加快模型开发速度。实验结果表明传统训练方法存在冗余训练现象,小样本集划分有助于优化网络学习参数。(2)针对迁移学习机制及图像增强方法在小样本数据集上存在过拟合现象,提出了混合图像扩增方法,即将去噪声图片和有噪声图片一同输入网络进行训练,缓解网络过拟合现象。实验表明,混合图像扩增方式在苹果叶片病害小样本数据集上有较好的识别效果。其次,将基于模拟退火粒子群算法优化支持向量机回归模型引入到苹果品质预测上。采用模拟退火算法对每次迭代过程中的粒子进行局部寻优,可以有效避免早熟现象,但收敛性能一般,需要更多的迭代次数。粒子群优化支持向量机模型虽然收敛速度快但容易陷入局部极小值。综合比较,采用模拟退火粒子群算法优化支持向量机算法构建苹果品质预测模型更佳。(3)开发了苹果叶片病害识别及品质预测管理系统。为实现苹果叶片病害的及时诊断和品质的科学预测,本系统共设计数据采集层、数据存储层、数据挖掘分析层和数据信息及结果可视化层,完成了苹果管理系统的整体系统架构及功能模块的构建,并挖掘所采集信息,实现了苹果基础数据子系统、苹果品质预测子系统和病害图像识别子系统的研发,为果农、政府提供更优质的辅助决策服务,为苹果病害精准防控提供支撑。"
1696,基于数据驱动的温室黄瓜霜霉病监测预警系统,"黄瓜霜霉病是危害黄瓜的主要病害之一,在各地的各种种植方式下均有发生。此病传播速度快,流行性强,危害较重,极易对黄瓜的生产造成损失。而日光温室相对封闭的结构特点非常容易满足黄瓜霜霉病对于中温高湿的环境要求。因此及时监测预警黄瓜霜霉病的发生,为病害预防提供决策依据,对于降低损失、稳定产量及保证质量具有重要意义。随着科技的进步,将信息技术应用到农业,为病害预测提供了更多更有效的方法。其中机器学习是一种通过提取出数据中的内在规律或模式来预测未知数据的方法,不需要考虑各种因素与发病情况之间复杂的机理过程,此类数据驱动模型相比传统经验模型准确性更高,相比数学模型更便于建立各种发病因素与发病情况之间的联系,为温室黄瓜霜霉病监测预警提供了一种便捷、有效的方法,方便黄瓜种植者对霜霉病采取适时的防控措施。本文主要内容如下:(1)确定模型输入因子。阅读分析大量国内外相关文献,了解黄瓜霜霉病发病规律及主要影响因素。根据大量专家学者的研究成果以及实际可操作情况,确定了温室黄瓜霜霉病预测模型的输入因子为室内夜间平均温度、室内夜间平均相对湿度、室内白天平均温度、室内白天平均相对湿度、室内相对湿度≥80%的累积时数、室外日最高温度、室外日最低温度、室外日平均相对湿度和室外日平均风速。(2)数据采集及模型构建。采集试验基地温室室内环境数据和黄瓜霜霉病发病数据以及温室室外环境数据,结合历史试验数据,对所有数据进行整理及标准化处理。利用支持向量机和决策树算法分别构建温室黄瓜霜霉病预测模型,其中支持向量机算法分别选用径向基核函数、线性核函数和多项式核函数来构建模型。采用上述模型预测三天内是否发生黄瓜霜霉病,并对这四种模型的预测结果进行评估,结果发现基于径向基核函数的支持向量机预测模型在各项评估标准中的值均为最高值,表明其效果最好。(3)系统设计与实现。基于构建的预测模型,并结合MVC框架和Web Service技术设计开发了Web端的基于数据驱动的温室黄瓜霜霉病监测预警系统,同时为方便采集温室霜霉病发病情况,辅助开发移动端病虫害信息采集APP。监测预警系统主要包括对温室内黄瓜霜霉病的监测预警和对黄瓜种植基地中各类信息的管理等模块。在该系统中,通过温室黄瓜霜霉病预测模型对温室黄瓜霜霉病发病时间进行预测,实现数据驱动预测。再利用APP获取的真实发病情况对预测结果进行校验,并将本次采集的数据进行存储,用于下次黄瓜种植中霜霉病预测模型的构建中,形成一个环状的数据流,使得模型可根据数据的变化进行更新,更好的为用户提供决策支持。"
1697,基于随机森林和卷积神经网络的年轮分割与参数测量研究,"树木年轮学的研究需要统计树龄和测量轮宽,由此推算环境变换和树木生长信息,因此准确提取年轮特征信息至关重要。传统的树木年轮研究方法主要通过肉眼对年轮进行识别,然后通过测量工具采集需要的年轮信息,为防止测量误差,一般需要多人协同工作,这种人工方法工作繁琐且效率低下。近年来,计算机技术在林业方向得到了广泛应用,较好地替代了一些手工测量工作,尤其计算机视觉和图像处理技术的进步,使得开发一套自动提取树木年轮信息的系统成为可能。目前比较成熟的商用年轮分析软件主要是加拿大REGENT公司的WinDENDRO和德国Frank Rinn公司的LINTAB,这两款软件虽然能实现年轮参数测量,但其自动化程度较低,需要大量的人工交互操作且价格昂贵,维护成本高。精准地识别出年轮图像中的早材、晚材和树皮是实现自动化测量年轮参数的首要工作。然而树木年轮生长过程中存在早晚材边界过渡模糊、节疤和伪年轮等现象,且年轮圆盘在砍伐和采集过程中表面会存在毛刺和噪声点,传统图像分割算法如基于阈值和区域生长的图像分割方法难以取得理想的效果。本文结合图像的颜色和纹理特征,用随机森林算法构建像素分类器对年轮图像进行分割,同时考虑到卷积神经网络在图像特征学习和分类上的优越表现及其强大的模型泛化能力,本文构建了基于卷积神经网络的年轮图像分割模型,实现年轮早晚材和树皮的精准分割。然后对分割后的年轮图像自动定位髓心,应用环形扫描的方法测量树龄、年轮宽度和晚材率等年轮参数。主要研究内容如下:(1)图像预处理、特征提取和基于随机森林算法的年轮图像分割。在分析了年轮图像特征的基础上,提出了结合图像多个颜色空间特征和纹理特征,基于随机森林算法训练像素分类器分割年轮图像的方法。首先,通过变换图像的颜色域空间,提取出样本图像在RGB、HSV和L*a*b*模型下的9个颜色分量,基于灰度共生矩阵提取样本图像的对比度、相关性、能量和熵的均值与标准差共8个纹理特征。然后,将颜色特征和纹理特征进行随机组合作为训练特征,基于随机森林算法构建像素分类器并进行学习训练,实现年轮图像的早晚材分割。为了提高分割图像的质量和准确度,对分割后的图像使用形态学方法消除孤立和黏连噪声。(2)图像增强与基于卷积神经网络的年轮图像分割。深度神经网络需要大量的标注样本进行训练学习,针对大规模年轮圆盘图像难以获得且标注工作量大的问题,通过数据增强的方式扩充年轮图像数据集。数据增强除采用传统图像旋转、透视和色彩变换等方式外,还实现了基于移动最小二乘的图像变形算法,满足了小样本条件下训练深度神经网络的需求。然后分析并实现了典型的图像分割模型FCN、U-Net和DeepLab-v3-plus,并针对其在年轮图像分割问题上存在的髓心附近晚材识别困难、部分极窄轮丢失等问题,提出了一种改进的U型卷积神经网络I-UNet。I-UNet增加了网络深度,用残差连接的方式避免梯度消失,并采用多重损失计算的方式保留图像底层信息。同时,还采用了批归一化(BN)和随机失活(Dropout)的策略加速网络训练,增加模型的泛化能力。实验证明,I-UNet模型提升了年轮图像的分割效果,较好地解决了髓心附近晚材识别困难和极窄轮丢失的问题。(3)基于环形扫描的年轮参数自动测量算法与系统开发。从图像中心出发沿水平和垂直方向拉取扫描线,由穿过年轮数目最多的扫描线的交点确定髓心位置。然后从髓心出发每隔15°辐射一条半径线,记录每条半径线上的年轮线坐标,树龄就是所有方向半径线中年轮线数目的众数。选择树龄正确的半径线,计算年轮宽度和晚材率等参数。实验证明环形扫描算法在树木年轮参数测量中,不仅测量准确率高且能够较全面地保留相关数据。基于上述研究内容,本文基于Python语言的pyQT工具包开发了年轮参数自动测量系统,为树木年轮相关研究人员进行年轮图像分析和参数提取提供便利。"
1698,基于机器学习与链路预测的医疗问答检测与推荐系统,"随着“互联网+医疗”的政策不断推动,市场上以患者为中心的医患问答平台越来越多,人们现在可以轻松的在网上进行一些医疗咨询与疾病诊断。但是目前还是存在许多问题,比如各个医患问答平台的数据不互通、平台医生的质量良莠不齐、不能在用户有限时间内回答问题、医生根据片面的描述容易误诊等。本文通过市场调研和分析,开发一个在B/S架构下的医疗问答检测与推荐系统,该系统使用命名实体识别算法和链路预测算法,来实现诸如问答分析、疾病自查、历史记录检索、误诊疾病预测、疾病预测等功能。不仅如此,系统还可以进行新的疾病、症状以及问答记录的更新,可以让系统不断注入新数据。具体来说,本文主要有以下几个方面工作:首先,利用java的htmlunit工具类,针对目前使用频次最多的几个医患问答平台依次编写相应的爬虫规则,爬取当前已经记录的疾病、病症以及医患问答记录,并对数据进行结构化处理。其次,使用双向长短时记忆网络和条件随机场算法,对每个问答记录进行命名实体识别,提取出每个问答的疾病和症状的相关信息,并构建相应的“疾病-症状”网络。然后,本文针对实际数据的特点提出一个更能表现单节点预测正确率的N点连接精确度指标,并在已有的链路预测算法上进行改进,提出NIS算法来进行疾病之间连边的预测和症状之间连边的预测。同时,本文分析了医患平台上疾病频次的分布以及症状在每个疾病中的分布,提出了两种权重矩阵的计算方法来进行疾病的预测。最后,使用SSM框架来搭建该系统,在系统中集成了命名实体识别算法、链路预测算法以及疾病预测算法。系统的前端开发,使用AJAX异步传输所有信息,提升用户使用系统的流畅度。为了提高系统的可维护性,在开发该系统时候,采用前后端分离,前后端的交互利用JSON格式传输数据。同时对外提供了API接口,方便其他开发人员使用本系统的方法和结果。"
1699,基于机器学习的尿沉渣图像有形成分检测算法的研究,"尿沉渣中各类有形成分对人体肾脏、泌尿系统疾病具有重要的诊断和鉴别作用,临床中常检测红细胞、白细胞、上皮细胞和管型,管型分为透明管型、颗粒管型等多个种类,不同种类管型的数量对泌尿系统疾病有重要的临床诊断参考意义。尿沉渣图像存在有形成分种类繁多,纹理轮廓千变万化,图像清晰度不统一,色彩亮度分布不均匀和散焦严重等特点。上述特点导致尿沉渣中各类有形成分识别困难、识别速度慢。本文针对上述特点,首先研究了尿沉渣图像形态学变化,并采用图像增强、边缘检测和分割等手段处理图像,然后提取图像的特征矩阵,最后采用基于机器学习的组合算法对其进行分类,并针对管型详细分类为透明管型和颗粒管型。主要研究内容如下:尿沉渣图像预处理和初筛选。通过电子显微镜拍照得到的尿沉渣图像有着噪声较严重、杂质干扰强、对比度低、光照不均等问题。首先对原始图像进行去噪声、增强和细胞分割等处理,以此来完成所有尿沉渣图像有形成分的初筛选,从中获得尿沉渣的各类有形成分,处理过程涉及到滤波算法、二值化算法、边缘检测算法以及形态学等处理手段,针对高低倍镜下不同尿沉渣有形成分采取Canny算子和分水岭算法相结合的方式进行边缘检测。图像处理之后的尿沉渣有形成分的特征提取。将原图分割为单个目标物图像之后,提取图像的几何、纹理和统计特征矩阵。将特征矩阵数据送入分类器学习,根据学习结果研究这些特征的合理性以及各类特征维度组合对最终分类效果的影响,最终选取识别准确率最高的41维特征。此外,针对Gabor特征数据量大的特点,提出采取(2D)~2PCA降维手段来提升算法效率。根据高低倍镜下不同有形成分的特点,提出基于形态学、决策树和SVM分类器的组合算法。运用交叉验证法获得分类器的最佳参数,对尿沉渣图像中的红细胞、白细胞、上皮细胞和管型进行有效的分类,并针对管型的子类透明管型和颗粒管型进行更加详细的识别和分类,整体分类识别率达到95%。"
1700,基于机器学习的白带菌类光学图像识别算法研究,"阴道疾病是女性的高发病之一,其中白带常规检查是最常见的检查项目之一,而阴道清洁度是其中最重要的一个指标,阴道清洁度主要是通过判断白带中菌类的种类以及数量来得出的。目前国内外大多数医院,还是依靠人工镜检的方式,通过观察显微镜视野中的有形成分的种类以及大致数量,然后根据经验得出清洁度指标。传统方法缺乏一个定量的标准,存在检测效率低下、准确度不高等缺点。鉴于此,本文提出了一种白带显微图像菌类的自动识别算法,能精确快速得出白带显微图像中霉菌等细菌的数量及类型。该算法主要采用主成分分析、Haart特征、方向梯度直方图以及机器学习等方法来准确识别白带显微图像中的霉菌、杆菌等细菌。本研究主要内容如下:首先,介绍了传统人工白带常规检查的缺点和不足以及对白带显微图像进行智能识别研究的学术意义和社会意义,进一步描述了国内外对医学显微图像自动识别的研究现状。其次,介绍了用于获取白带显微图像的仪器及其参数,紧接着,讲述了如何对获取的白带显微镜检图像进行预处理,从而精确地获得待检测区域,该步骤包括灰度化,图像平滑,形态学处理,图像分割。然后对获得的待检测区域通过圆形度和面积等几何特征识别出球菌和杆菌。最后,结合图像的Gabor特征、LBP特征、Haar特征和Hog特征,利用决策树、Adaboost和SVM三种机器学习方法来训练霉菌的分类模型,由于某些特征的维度较高,利用PCA算法先降低维度再训练。通过不同分类器对应不同的图像特征进行训练,利用交叉验证法得出每种分类器训练不同特征得到的分类模型的平均性能,并以准确率,灵敏度和特异度为指标,对训练结果进行了分析。在此基础上,本文提出了一种综合多种特征并对分类器识别结果进行投票的算法。经过相关理论分析后,对700幅白带显微镜检图像采用改进后的算法进行了测试,统计得到霉菌的识别率高达96.7%,误检率和漏检率均控制在4%以下,杆菌和球菌的则识别率接近百分之百,满足临床指标要求。"
1701,人体粪便隐血检测试剂卡光学图像自动分类技术的研究,"作为检验科常规的检验项目,粪便常规检查在临床检验中具有重要的地位。目前,粪便隐血检测仍然采用人工处理加读卡的方式,该方式具有效率低和容易造成污染等缺点。随着智能分类技术的发展,医学检测自动化已经成为现代医学检验的发展趋势。本文对粪便隐血检测试剂卡的自动分类技术进行研究。依托于全自动粪便常规分析仪,通过摄像头获取粪便隐血检测试剂卡图像,将图像处理技术和机器学习技术相结合用于试剂卡的自动分类。本文的主要工作如下:首先,对粪便隐血检测试剂卡的光学图像进行人工标记,根据反应线(T线)颜色浅深将其标记为阴性、弱阳性或阳性以及一个[0,10]之间的分数。然后对图像进行预处理。试剂卡在实际使用过程中存在被粪便污染的情况,通过对多种图像分割方法进行对比,本文采用阈值和频率域相结合的方式对光学图像进行分割,并且使用LAB颜色空间模型进行辅助验证,准确提取出试剂卡图像中的反应区域;其次,研究了试剂卡反应区的特征提取和选择,通过对试剂卡反应区的图像和基本特征进行分析,得出单一的图像基本特征不符合直接作为试剂卡的分类依据,故本文提出将纹理特征和颜色特征相结合的特征作为试剂卡分类的依据。最后,对支持向量机的多分类算法和回归算法进行了讨论。将提取到的特征向量进行处理,分成训练集和测试集。将训练集送入支持向量机中训练调整参数,并通过验证集对训练的模型进行验证,得到参数最优的分类模型。使用测试集对得到的分类模型进行测试得到最终实验结果。提出使用回归模型对数据进行打分,得到更精确的分类结果,辅助医生更准确的判断和掌握病人的实际情况。本文研究的特点在于需要自动分类的粪便隐血检测试剂卡光学图像背景复杂,且试剂卡分类为多分类问题,分类边界处无明显界限,由于污染的情况导致图像无明显可区分的特征。实验结果表明,本文的方法对粪便隐血检测试剂卡光学图像的自动分类准确率达到了98.4%,单卡平均检测速度为0.69 s,满足了临床检验的要求。目前该技术已在国内部分医院投入临床使用阶段。"
1702,基于卷积神经网络的心脏病预测方法研究,"随着时间的推移与技术的进步,计算机与医疗领域的联系逐步密切,解决了很多以前无法回答的问题。在农村向城市转型的进程加快与我国教育水平的提高之时,人们越来越关注自身的健康问题。心脏病作为一种高死亡率的疾病与人类死亡的第一因素,其预测方面存在的问题也日益明显。但是目前在医疗领域方面,计算机等设备大部分应用于检测而非预测,并且只是对图像进行处理最终结论需要医生判断。医生是整个过程的核心,计算机只是辅助工具。由于医生研究的领域,掌握的知识及个人经验的差异,对疾病判断的结果可能不同,这样会造成严重的后果。因此,利用先进的计算机技术对其进行预测,进行早期治疗,避免心脏病恶化造成难以挽回的后果,有重要的实际意义。为了达到提升心脏病预测准确率的目的,本文将分为特征工程中的数据预处理和卷积神经网络两部分展开讨论。首先,结合医学领域相关知识,通过获得患者某些心血管疾病的重要指标,用数据预处理技术改善数据质量,提出了将传统机器学习应用的一维向量组合成矩阵形式的特征组合算法,使神经网络结构在预测方面和特征的关联性方面均有加强。随后探讨了不同类型的参数对网络结构的影响,构建并优化了心脏病预测模型,为心脏病疾病的防治提供参考。经过与传统心脏病预测方法比较,证明了本文提出的基于卷积神经网络的心脏病预测方法分类更加准确。辅助医生判断患者是否有心脏病,使计算机不仅在医疗上用于检测,更能应用于预测,同时较好地避免人为导致的误差。"
1703,心音诊断信息自动识别方法研究,"心音诊断信息是心音中可用于诊断个体心脏或身体其他部分病理情况的信息。由于在临床听诊时,医生只能对病人当时的心脏跳动情况进行分析,极易因病人当时的情绪、身体动作等引起心脏跳动方式的改变而产生误判。因此,长时间记录的心音信号已受到重视。但对于长时间心音信号的识别,其工作量无疑是巨大的。考虑到机器学习以及深度学习算法的优良特性,本论文将深度学习算法、机器学习算法与心音诊断进行结合,研究了高效识别异常心音的过程和方法,主要研究内容包括:首先,为了研究深度学习网络对心音信号的识别,将心音信号转为二维图像,利用深度学习网络进行训练建模。图像的转换涉及两种方法,一种是常见的语谱图格式,另一种是MFCC(Mel-frequency Cepstrum Coefficient，MFCC)特征图格式。其次,针对图片数据进行网络的搭建以及相关参数的调整,直接利用卷积神经网络对这两种格式的图片进行分类。进一步地,通过抓取网络中部分层次提取的特征,并使用机器学习分类器对提取的特征数据进行训练、分类,对比分析实验结果。接下来,为了进一步提高对心音的识别能力,选择对心音信号进行多特征的提取。为了避免由于心音信号的不正确分割而导致后续处理过程的性能受到影响,本论文选择不对心音信号进行周期性的分割。因心音信号是非平稳信号,选择只对心音信号进行常规的分帧操作,以保证每一帧信号近似为平稳信号便于处理。对每一帧信号提取6种特征参数,共18维。利用机器学习分类器对特征数据进行分类识别,并进行多组对比实验,通过对比多个评估指标,选择出了在本论文所选用的数据集上表现最优的模型XGBoost。最后,根据信号特征的数据分布特性,将特征进行分开处理,使用高斯混合模型对MFCC特征进行处理,将处理后的结果作为MFCC特征数据的权重,并与非MFCC特征组合,得出了本论文实验结果中的最佳实验结果。"
1704,基于眼底图像的糖尿病视网膜病变智能诊断,"糖尿病视网膜病变是导致不可逆转性失明的主要因素之一,早期筛查和及时的诊治具有重要的意义。糖尿病视网膜病变诊断主要是根据眼底相机拍摄得到的彩色眼底图像判别患者的糖尿病视网膜病变程度。本文结合视网膜整幅图像的全局特征和不同类型病灶区域的局部特征实现疾病智能诊断,主要研究工作如下:针对不同严重程度的糖尿病视网膜病变图像之间差异十分微小且特征提取困难的问题,本文提出了基于残差-双线性网络的疾病诊断方法。通过引入双线性特征,设计了残差-双线性卷积神经网络以提取出眼底图像丰富的语义信息,使网络关注到具有辨别性的关键区域。基于传统残差块进行改进,避免部分重要特征信息丢失,通过双线性池化使不同通道之间的特征进行组合,获取高级语义特征。另外,针对部分小病灶无法在深层网络特征图上较好的表达的问题,提出多层级特征融合方法,形成了不同层级的上下文信息。通过在EyePACS公开数据集上实验对比分析,本文方法设计的网络在敏感度和Kappa系数上均有提升。针对目前主流的病灶检测算法中无法在一个统一的算法框架下实现同时提取不同类型病灶特征的问题,同时为了避免微小病灶被忽略,本文设计了基于图像块的病灶分类方法为疾病诊断提供病灶特征。针对眼底图像中不同病灶区域形态差异较大的问题,提出了多尺度特征融合方法,通过引入空洞空间金字塔池化方法提取眼底图像不同区域范围的病灶特征。本文通过实验证明了在IDRID公开数据库上能够较好的识别出不同的病灶区域,其中微动脉瘤召回率和精确率分别为84.54%、79.97%,硬性渗出物召回率和精确率分别为90.84%、95.27%。针对糖尿病视网膜病变相邻严重程度的图像,特别是正常和轻度图像容易混淆的问题,提出了基于病灶特征融合的疾病诊断方法。为了提供病灶区域的先验知识,本文采用图像处理的方法提取出可疑区域图像块。为了结合局部病灶特征进行辅助诊断,本文将整幅眼底图像和对应的可疑区域图像块分别输入疾病诊断网络和病灶分类网络,基于训练好的网络模型进行调优训练。通过在EyePACS公开数据库上进行实验,本文诊断方法敏感度达到89.5%,特异度达到86%,Kappa系数为0.846。综上所述,本文针对糖尿病视网膜病变诊断问题提出了基于残差-双线性网络的疾病诊断方法和基于病灶特征融合的疾病诊断方法,为疾病诊断研究提供了新的思路,并在EyePACS国际公开数据库上通过实验验证了两种方法的有效性。"
1705,帕金森病患者步态特征与机器学习模型参数协同优化研究,"随着我国老龄化情况的凸显,老年人高发的帕金森病已成为了家庭和社会的一个巨大问题。在临床上医生多借助于量表和经验判断的方式对患者进行诊断,但这样会存在漏诊误诊的风险。因此,为了辅助医师对帕金森病患者进行更好的临床诊断,本文使用遗传算法和蚁群算法对患者的步态特征和支持向量机参数进行协同优化,提供基于患者步态特征的辅助诊断方法。本文的主要工作如下:(1)使用遗传算法研究患者步态特征和支持向量机参数的协同优化,以患者特征构成算法中的染色体,同时将支持向量机参数也编入其中,探究两者的协同优化。本文针对协同优化的结果还选取了部分特征选择算法,以及只使用遗传算法进行特征选择作为对照组,实验结果表明使用遗传算法来进行协同优化相对于对照组算法提高了模型的分类精度。(2)使用蚁群算法研究患者步态特征和支持向量机参数的协同优化,将患者特征作为蚂蚁算法搜寻路径上的节点,并将支持向量机参数作为特征的一部分一同进行搜寻,在特征选择过程中同时完成参数的选取。在与对照组的仅使用蚁群算法进行特征选择以及其他的选择算法相比时,实验结果显示使用蚁群算法进行协同优化具有明显的优势,具有较高的分类精度,平均准确率为85.77%。"
1706,基于长时间可穿戴社交数据集的语音分割方法的研究,"随着工作和学环境压力的增加,心理健康问题已经成为当前社会研究的主要课题。通常研究人员通过使用社交感知行为来分析心理健康状态。社交感知信号通常包括语音信号,行为信号,心理感知信号等。其中语音信号由于包含丰富的情感和社交信息,是可靠的身心健康评估特征。在本文中,使用所提出的可穿戴设备进行了为期四周的长期监测实验研究。在完全自然的情况下分析具有分段的语音-社交特征。我们设计了用于基于极少特征语音分割的迁移学习模型算法。对经典的深度学习VGG-net网络进行修改,加入残差学习单元,以加深网络的深度,通过修改卷积核的大小,改变感受野大小。通过在TUT Acoustic Scenes数据集上训练模型,并在该模型上学习基本声学场景特征,基于模型的迁移算法,仅用四个可穿戴语音社交特征(能量、熵、亮度、共振峰)将模型迁移到长时间社交数据集。所获得的结果显示使用可穿戴长期语音社交数据集在无约束的自然情况下对语音场景可以进行有效的分割。对于长期社交语音监控,本文主要研究内容包括:1)基于长期语音-社交特征分析设计可穿戴智能设备来评估心理健康。该分析能够以有说服力的方式处理语音信号。客观地使用有限的四个语音-社交特征信号(能量、熵、亮度、共振峰)进行分析,避免直接记录语音,以保护个人隐私和减少计算复杂度。以大学生作为研究对象,设计了长达一个月的心理健康监测实验,用于评估他们的身心健康状况。2)将基于模型的迁移学习算法应用于语音分割领域,并通过基于模型的迁移学习模型研究提高对语音分割的精度。通过加入残差学习单元以增加网络结构的深度,提供网络的泛化能力。并通过改变卷积核的大小以调整感受野的大小。使得网络在少数特征(能量、熵、亮度、共振峰)的数据集上可以收敛。最终通过对基于模型的迁移学习模型的研究,以解决传统算法中经常发生的训练样本不足的问题。3)最后,建立分段语音-社交特征与焦虑(自闭症)水平状态之间的相互关系,用于协助研究大学生的心理健康状况。"
1707,基于神经网络的眼底血管分割技术研究,"眼底血管的异常变化揭示了许多疾病的严重程度,如糖尿病,高血压,动脉硬化,心血管疾病和中风。因此,血管分割是许多疾病诊断的重要前提。通常血管的提取是由医生手动完成的,但这是一个耗时的任务,并非常依赖医生的专业性。随着图像处理技术在医学领域的快速发展,对眼底血管进行自动分割和检测已经成为一种可能。然而,由于人的眼底结构特征复杂,毛细血管较多,分割难度较大,现如今的血管分割技术在分割精度上仍待改进的空间。本文在阅读大量文献的基础上,提出了一种改进型的U-Net卷积神经网络的眼底图像分割方法,采用公共数据库DRIVE的眼底图像进行训练和检测,最终分割出效果较好的血管树。该分割方法分为预处理与血管分割两部分。本文选用RGB图像的绿色通道图像,对该眼底图像进行对比度受限直方图均衡化(CLAHE)处理、伽马校正,提高血管树与背景的对比度。然后利用二维Gabor滤波器进行滤波,滤去去绝大部分背景噪声,并对眼底血管进行增强处理,为之后的血管分割提供了高对比度的图片。本文详细地介绍了神经网络、卷积神经网络、FCN、U-Net网络的结构和原理,搭建一种改进型的U-Net卷积神经网络结构,该神经网络包含八层,其中第二层至第七层为隐藏层,仅含有两个下采样层。本文采用DRIVE数据库的眼底图片对网络进行训练和测试,得到的图片能够较完整地分割出血管树。与前人的方法相比,本文的三项血管分割指标均优于前人文献,其中准确率Acc为0.9691,灵敏度Se为0.8122,特异性Sp为0.9761。同时本文的方法具有以下三个优点:(1)血管边缘光滑无残缺,血管粗细与原图像近似,且血管断裂极少,整体血管树与医学专家分割的血管树极其相似。(2)能够较好地识别并分割毛细血管,分割出的毛细血管顺滑完整,断裂较少。(3)能够较好地分割视盘、视杯、黄斑部位的血管,避免将这些眼底结构误识别为血管。"
1708,眼底图像病变区域的提取与识别,"近年来,由于视网膜图像具有广泛的应用场景,视网膜图像分割越发受到学者们的关注和研究。视网膜本身非常稳定且不易磨损和退化,临床上,医生可以通过收集患者的眼底图像来诊断和治疗多种眼科疾病,包括糖尿病性视网膜病变、黄斑病变、青光眼、白内障等。与此同时,随着计算机的普及,数据处理技术得到了迅速发展,并逐渐应用于医学领域的各个方面,其中,医学图像处理技术为医学发展和人类健康做出了巨大贡献。眼球包括多种结构,在由眼底照相机拍摄的视网膜图像中,眼底血管、黄斑和视盘等区域出现的病变较为常见。基于图像处理和机器学习的方法,本文从局部病灶的提取和全局病变的识别和判断中做了相关方法的研究:1.首先对眼底图像进行预处理,包括色彩空间的选取以及图像的增强和均衡化;2.在局部病灶提取中首先对眼底血管进行分割,并对血管病变中的微动脉瘤进行提取,最后对微动脉瘤病变像素点进行分级;3.接着对眼底图像中的硬性渗出物进行了提取,对算法的评价采用机器学习中的相关分类器,对分割出的病变像素点进行训练和测试,计算各项指标;4.全局病变识别中运用卷积神经网络对眼底图像病变与正常进行识别和判断,并用网络对微动脉瘤和硬性渗出物单个病变进行识别。本课题在研究过程中主要针对糖尿病性视网膜病变的一些临床表现,采用了相关的标签数据集,实现了对病变区域的提取和识别,未来的工作中,将更加注重运用非监督学习对临床数据集的病变检测工作,提高算法的应用性。"
1709,融合集成学习与解释性方法的老年健康知识发现研究,"国家老龄事业发展和养老体系建设规划指出,预计到2020年,全国60岁以上老年人口将增加到2.55亿人左右,占总人口比重提升到17.8%左右。人口老龄化成为无法回避的社会问题,并影响着我国社会、经济等方面的发展。随着老年人年龄的不断增长,老年人的健康问题也会日益凸显,行动不便和罹患各种慢性病的几率增加,带来医疗和护理成本的提升。因此对老年人健康需求问题的研究是研究者们关注的一个重要方向。如何能够挖掘出老年人健康状况的影响因素,识别出潜在因素和高风险因素,以及因素之间的相互作用机制,为政府做出决策和制定针对性的政策提供科学全面的依据,从而更好地为老年人提供保障,是研究者们需要考虑的重要问题之一。随着数据时代的到来,人们越来越关注如何从已有的数据中去获取知识,由此催生了以数据挖掘为代表的人工智能技术的快速发展。同时数据挖掘在各行业中得到了广泛的应用,并为解决行业问题提供了新的思路和方法。本文将数据挖掘方法应用到中国老年人健康影响因素分析工作中,综合运用数据挖掘技术对老年人的健康影响因素进行分析。文章首先介绍了老年人健康影响因素的研究现状,以及数据挖掘在知识发现中的应用。然后通过对2014年中国老年人口健康状况数据(Chinese Longitudinal Health Longevity Survey,CLHLS)进行分析,初步获取关键特征,并使用集成学习思想,提出基于多准则集成的特征选择方法,运用梯度提升决策树集成模型进行建模,与一般的数据挖掘只注重于挖掘的效率和精度,而对于其挖掘结果的可解释性和可理解性关注相对较少,缺乏对数据的理解不同。我们将所提出的模型与数据挖掘解释性研究的最新方法相结合,对结果进行了不同角度的详细分析。最后基于本文的研究结果,为健康养老提供了决策建议。实验结果表明,本文所提出的方法能够有效识别老年人的健康状况,并发现影响老年人健康状况的各种因素及因素间的作用。对老年人健康数据的知识发现和辅助决策具有重要的参考意义。此外,本文使用复杂数据挖掘方法对老年健康调查数据进行研究,为数据挖掘方法在相关社会调查数据中的应用提供了参考范式,具有重要的意义。"
1710,群体性突发事件互联网舆情传播干预机制的研究,"伴随互联网的迅速发展和社会的日益进步,日积月累的社会矛盾在互联网背景下传播、扩散,使得原本濒临爆发的群体性事件被无限放大,造成网络舆情传播速度更快,影响范围更广,同时具有更高的危害性。在突发事件网络舆情的传播过程中,找到事件爆发的“激化”边界,并确定在“激化”边界之后起关键作用的信息传播节点,对实现突发事件网络舆情的及时干预,有效降低突发事件带来的不良社会影响具有重要价值。微博是突发事件网络舆情传播的主要介质,用户通过发布带有明显情感倾向的帖子来交流对事件发展的看法和态度。这种情感倾向对事件发展的态势具有较强的指引作用,影响网络舆情的发展和走向。这使得在突发事件网络舆情的分析过程中,通过融入对舆情发展情感倾向的分析,更有助于捕捉事件网络舆情的发展态势,从而辅助相关部门及时实现对事件发展的监控和干预。本文以微博平台为主要的数据源,在探讨如何更好地实现微博文本细粒度多元情感分类的基础上,分析事件相关舆情多元情感的分布演化规律,结合舆情的地域分布特性实现对突发事件舆情发展“激化“边界的识别;同时,对突发事件舆情传播网络结构进行发掘,得到事件舆情的主要传播者,结合多元情感分析,识别在事件舆情传播中,需重点监控和干预的关键传播者。具体研究内容如下:(1)基于word2vec与扩充情感词典的微博细粒度多元情感分类。该研究将深度学习方法引入进来,实现微博文本情感词的向量化表达,通过考察情感词的上下文语境信息,提升微博文本多元情感分类的效果,更细致地捕捉微博文本所体现的网民的真实情感。结合微博文本中用以表达特定情感的情感符号,提取微博文本中特有的表达情感的特征词,实现对现有的多元情感词典的扩充;引入word2vec模型训练扩充情感词典中的情感词,得到情感词的分布式表达,以解决情感词典不能有效考虑上下文语境的问题,并最终实现微博文本句子级别的多元情感分类,为后续基于情感分析的突发事件临界点和关键节点识别奠定基础。(2)基于多元情感分析的突发事件“激化”时间点识别。对突发事件发展过程各时间窗口内的微博帖子进行细粒度多元情感分类,得到各时间窗口内网民对于事件舆情的多元情感倾向;结合各时间窗口下事件相关网民发帖的地域分布特性,综合考察事件舆情在各时间窗口下每一元情感的影响范围和演化特性,以发掘影响事件舆情发展态势的主要情感倾向,得到突发事件舆情发展的”激化“时间点。实验结果发现在多元情感中,网民对事件舆情展现出的“愤怒”和“悲伤”情感与事件发展的演化规律趋同,有助于识别突发事件爆发的“激化”时间点。(3)基于用户综合影响力的突发事件干预节点挖掘。在确定突发事件“激化”时间点的基础上,结合微博发帖用户属性以及帖子自身属性,利用变异系数计算属性权重,确定用户在事件舆情发展过程中的综合影响力,识别事件网络舆情的主要传播者。对主要传播者发布的事件相关微博帖子进行多元情感分析,考察主要传播者对事件舆情的情感倾向,识别呈“愤怒”和“悲伤”情感的主要传播者,作为重要的干预节点,辅助相关管理部门实行有针对性的监管和干预。综上,本文主要探讨了多元情感分析技术在群体性突发事件网络舆情干预管理中的应用。通过对突发事件网络舆情的多元情感分析,有助于获取网民呈现的不同情感倾向对事件发展态势的预示和影响作用。这为相关部门提前把握事件发展态势,识别事件爆发的“临界点”,获取影响事件舆情传播的主要传播者,并在此基础上采取合理的方式对事件舆情进行有效地干预提供了一定的理论支持。"
1711,基于机器学习算法的犯罪预警系统设计与实现,"全球经济、政治和文化正在飞速发展,犯罪是这些发展的障碍,危害着人们的财产安全,然而使用传统预测方法无法对犯罪进行精确的预测,论文基于机器学习算法对犯罪进行了预测。犯罪预测是指通过对过去犯罪纪录进行分析,从而对接下来一段时间内犯罪发生的热点地区、数量、类型等进行预测。因此本文围绕区域犯罪数量、犯罪热点和犯罪类型进行了以下研究。论文引入循环神经网络对区域犯罪数量进行预测,建立了基于LSTM算法的区域犯罪数量预测模型并提出了两种实现方式:LSTM 一维时间序列和LSTM多维时间序列。对研究区域实施网格划分操作,形成小的网格区域,然后选取目标网格,传统时间序列算法ARIMA仅仅利用目标网格的历史犯罪数据,而LSTM还利用了目标网格周围网格的历史犯罪数据,考虑了周围网格犯罪数量对目标网格犯罪数量的影响。论文基于芝加哥历史犯罪数据集进行了实验,结果表明LSTM的均方根误差比ARIMA低0.73,平均绝对百分比误差比ARIMA低4.96%。进一步地,论文对LSTM进行了改进,将节假日、温度、天气因素纳入模型,实验结果表明改进模型的均方根误差比未改进LSTM低0.57,平均绝对百分比误差比未改进LSTM低2.62%。针对区域犯罪热点预测,论文提出了一种将目标区域时间、空间均嵌入模型进行考虑的时空神经网络。该模型引入时空窗口的概念,将预测某区域是否为热点的问题,转化为时空序列预测问题,基于时空累积影响来预测某区域是否为热点。为了验证论文算法的有效性,同时利用决策树、随机森林、逻辑回归等六种经典的分类算法进行了预测。实验结果表明,随机森林在传统算法中效果最佳。而论文提出的时空模型的准确率比随机森林高5.5%,精确率比随机森林高6.5%,召回率比随机森林高6.9%,F1-score 比随机森林高0.061。论文研究了犯罪类型预测的数据预处理过程,原始数据集中独立坐标对过多导致无法建立模型。论文使用聚类算法将巨量独立的经纬度坐标对应到20个不同的区域,同时将原始的多种犯罪类型合并为3种,然后调用sklearn库中的分类器建模,最终可依据输入的地点、时间输出3种犯罪类型各自发生的概率。"
1712,基于循环神经网络的时间序列预测方法研究,"时间序列作为一种常见的数据组织形式,在工业、市场、社会、环境、教育等各行各业都有着极为广泛的应用。通过对时间序列数据的分析和挖掘,可以建立起相应的预测模型,以此来预测未来数据的走向。通过时间序列预测,可以为用户提供前瞻性的意见和指导性的策略,以应对未来可能发生的变化;同时也可以发现蕴含在这些时间序列数据之中的潜在规律,从而可以更好地认识和理解各种科学理论和社会现象。然而,由于时间序列数据本身的特殊性以及当前环境下时间序列数据呈现出的新特点,时间序列预测任务仍面临着诸多挑战。一方面,时间序列数据有别于一般的数据形式,其自身的特殊性带来了两方面的问题。首先,时间序列是一种时序性数据,其内部各个数据点之间具有很强的相关性,进行预测时理应充分考虑到这种相关性;此外,时间序列长短不一,且受马尔科夫性质的约束,因此一般的预测方法都需要选取一个固定大小的滑动窗口截取序列进行建模,而如何选择一个合适的窗口尺度是时间序列预测问题中独有的技术难点。另一方面,有别于传统的时间序列分析,当前时间序列数据呈现出诸多新特性,也随之带来了新的挑战。首先,随着技术的不断进步,每时每刻都有数以百万计的时间序列数据产生,面对海量的数据,预测的效率问题变得尤为关键;第二,这些序列数据多以小时、半小时、分钟甚至秒为单位采样得到,如此高采样频率下的时间序列会引入大量干扰噪声,不利于分析建模;最后,时间序列是一种流式数据而非静态数据,其数据分布会随着时间不断变化,模型如何适应这种漂变也是一个重要问题。为了解决上述时间序列预测任务中存在的数据相关性、窗口尺度问题、数据量大、采样频率高、易漂变五大困难,本文基于循环神经网络模型,提出了两种时间序列预测方法,并成功地应用到了实际的生产环境中,其主要内容如下:1.本文提出了一种基于Multi-Lag集成与时间序列分解的GRU神经网络预测方法。该方法采用了GRU神经网络作为时间序列预测的基础模型,GRU网络专门用来对序列建模,从而解决时间序列中数据相关性的问题。另外,本文提出了Multi-Lag集成学习策略,充分利用了GRU网络可以处理变长度序列的优势,有效地缓解了窗口尺度难以确定以及会随着时间漂变的问题。最后,该方法引入滤波式时间序列分解法,可以将原始时间序列中的高频噪声部分分离,以应对高采样频率带来的问题。2.在第一个工作的基础上,为提高模型的训练和预测效率,同时更加充分地考虑时间序列数据之间的相关性,本文提出了一种专门用于时间序列预测的RNN模型,称之为时间步残差循环神经网络,简称为TSR-RNN。此模型在不同时间步的隐藏状态之间引入残差连接,可以有效减缓训练网络时梯度消失的现象,同时可以很好地捕获时间步之间的增减模式信息,使得模型具备更好的可解释性。与LSTM和GRU等常见的RNN变体网络相比,TSR-RNN在没有引入多余参数的前提下,训练和预测都更加高效,但预测精度却仍然与前两者相近。3.基于上述两种预测方法,本文实现了两个应用案例。一个是在大规模云平台硬件资源预测任务中应用本文的预测方法,另一个则是以本文预测方法为基础搭建而成的一整套全流程的库存管理预测平台。相关的实验表明,本文提出的两种方法可以很有效地解决上述的五大困难,相较于常见的时间序列预测模型,其预测误差得到了大幅降低。在相关应用实践中,本文的预测方法也表现出了较高的预测精度和很强的鲁棒性,充分证明了其实用价值。"
1713,可分凸优化的算法设计及其在投资组合中的应用,"可分离凸优化问题是运筹决策中的一类重要模型,在管理科学、金融与机器学习等领域中有着重要的应用。在金融领域中,投资组合是一个重要的研究方向,旨在为投资者提供更科学的投资建议。一类重要的投资组合问题是鲁棒投资组合,它主要考虑模型中参数(收益率,方差)估计具有不确定性,如何在最坏情况下保证最优投资组合;另一类问题是短期稀疏投资组合,它根据一些经验性的金融规则,对投资组合中较小比例资产的潜在收益作出较大的提升,以实现投资组合累计净值的最大化。这两类问题都可以转化为可分凸优化问题。此外机器学习中也有很多可分凸优化问题,如Lasso和稀疏逆协方差选择问题,可以用于各种数据的预测,有着重要的应用。上述模型对于算法的求解速度要求较高,要求算法快速甚至接近实时地给出模型的最优解。传统的一阶优化算法,如交替方向法(ADMM),在接近解点是收敛较慢,往往不能满足快速求解的要求,所以本文提出了一种过松弛的交替方向法(ADMM),通过增加每一步迭代中步长的方法使得求解速度能够有较大的提高。同时本文证明了过松弛的ADMM算法的全局收敛性,并且给出了o(1/∈)收敛率。此外,我们利用所提出的算法求解了鲁棒投资组合问题、短期稀疏投资组合问题、Lasso问题以及稀疏逆协方差选择问题,并将其数值结果与过松弛的定制PPA算法和经典ADMM算法进行比较。数值实验表明我们所提出的过松弛ADMM算法有着更快的求解速度,效率更高。"
1714,基于序列分段近邻编码的蛋白质热点残基预测方法研究,"在蛋白质与蛋白质相互作用时,其结合自由能仅由一小部分氨基酸残基贡献,这部分关键残基被称为热点残基。蛋白质功能的实现往往依赖热点残基,热点残基大部分聚集在蛋白质相互作用界面的中心位置,对蛋白质与蛋白质的结合起着至关重要的作用。因此,加深对热点残基的理解对于生命科学的发展具有积极的贡献。当前,科研工作者们主要依靠丙氨酸突变扫描技术来判定热点残基,但是这种方法成本较高又耗时耗力,只能在小范围应用。所以急需要更准确、更高效的方法来识别蛋白质界面热点残基。本文提出了序列分段近邻编码方法,并基于随机森林(Random Forest)分类算法来构建预测模型,从而鉴别蛋白质相互作用界面中的热点残基。首先从ASEdb数据库中抽取训练集,然后提取了 10个氨基酸理化属性、16个与突出指数(PI)和深度指数(DI)相关的特征以及25个与溶剂可及表面积(ASA)相关的特征。本文改进了蛋白质编码方式,对蛋白质热点残基的预测方式提供了新思路。不同于以往蛋白质序列的自相关描述符编码、三联体组合信息编码等方式,本文考虑到与热点残基临近的氨基酸以及有一定间隔的氨基酸对热点残基的影响,调整热点残基所在区间的滑动窗口长度,并将蛋白质序列平均分割成3、4、5段,由此建立预测模型,通过交叉验证最终选取了最佳的设置参数。为了验证预测模型的可靠性,本文从BID数据库中提取出独立测试集,来验证提出的模型。最后,将本文的预测模型与现有的热点残基预测方法进行了对比,这些模型在热点残基预测研究方面具有重要意义,其中包括APIS、Robetta、FOLDEF、KFC以及MINERVA模型。在使用相同训练集构建的模型之中,本文的模型在相同测试集上,明显地提升了对蛋白质界面热点残基的预测能力,表明了本文方法的可靠性。"
1715,蛋白质突变位点数据库的构建及位点预测研究,"随着生物数据不断地增长,研究人员开始借助于计算机来分析海量的生物学数据。蛋白质的研究一直是热门话题,研究深度逐渐拓宽。随着越来越多的蛋白质结构被解析,研究人员获得了大量的蛋白质晶体,也为研究蛋白质-蛋白质相互作用提供生物学数据支持。蛋白质-蛋白质相互作用通过控制细胞内外的生物学通路从而对生命活动的完整性产生重大影响。而热点残基扮演着蛋白质间相互作用界面的功能性位点的角色,并且对整个相互作用过程有着调节功能。近些年来,研究人员借助解析热点残基的研究工作,来进一步研究蛋白质间相互作用在细胞生命活动中的影响。本文首先收集蛋白质间相互作用的相关生物学数据,构建一个突变蛋白质间相互作用动力学和热力学数据库,并在此基础上,构建集成机器学习自相关模型来预测蛋白质复合物界面处的热点残基。具体的研究内容总结如下:1、构建突变蛋白质间相互作用动力学和热力学数据库。基于先前研究者整理收集的数据库,从以下两个方面来收集数据。首先,收集并整合以前的数据库并获得部分的数据。这些数据库收集和储存突变蛋白的热力学和动力学数据,包括SKEMPI,BID和AB-Bind。其次,再利用文献挖掘获取近三年新增的突变蛋白质的热力学和动力学数据。进行文献搜索时,本文基于两点进行考虑。第一点,从蛋白质结构开始,通过搜索关键词来锁定蛋白质复合物,将这些蛋白质复合物置于PDB-Bind数据库中进行比对,以获得具有Kd值的蛋白质复合物,然后阅读文献,获取文献中需要收集的数据。第二点,基于发表的相关文献,通过关键词进行搜索近三年所发表的相关文献,通过阅读文献的方式获得突变蛋白质的热力学和动力学数据。由此,最终获得了5291个突变体,这些突变体来自于341种蛋白质复合物。基于得到的突变数据,构建一个突变蛋白质间相互作用热力学和动力学数据库网站-dbMPIKT。用户可通过搜寻网址进入网站浏览突变数据,进行查询和下载等操作。此外,对突变数据进行简单的统计分析,利用cytoscape工具创建蛋白质相互作用网络,用户可以在网站的文件界面看到有关突变数据的生物学分析。因此,dbMPIKT数据库提供较全面的突变体数据,并对近三年的数据进行更新,更加方便研究人员获取到突变体数据。2、构建集成学习自相关模型来预测PPI界面处的功能性位点-热点残基。基于已构建的突变蛋白质相互作用热力学和动力学数据库,利用得到的数据集来进行热点残基的预测。首先,在数据集的选择上,基于相关人员的研究,最终选择五套数据集,包括:ASEdb,BID,SKEMPI,dbMPIKT以及构建的混合数据集。其中:ASEdb和BID是用于训练和测试的标准数据集,其他三组数据集用作独立的测试集。为增加模型的可靠性,将这三个数据集进行整合,得到一个数据量较大的数据集作为独立测试集。其次,本文提出将自相关函数方法应用到氨基酸序列的编码,在AAindex1上经过相关因子的筛选,得到46种氨基酸的物理化学性质来表征氨基酸序列,再利用自相关函数结合滑动窗口的思想来获得最终的特征。在分类器选择上,构建集成分类器,将支持向量机和K-最邻近算法结合进行模型的训练和测试,最后得到最终的预测模型。本文构建一个突变蛋白质间相互作用的生物学数据库和有效的预测模型,可预测热点残基且预测结果良好。本文旨在对蛋白质间相互作用的数据和热点残基预测模型方面进行研究,为蛋白质功能相关研究的研究人员提供数据基础和研究思路。"
1716,癌症驱动错义突变预测方法的比较分析和性能提升初步研究,"癌症作为一种人类复杂遗传疾病,一般是由基因组上不断累积的大量突变所导致。在众多突变中,仅有一小部分突变对于癌症的发生发展起到关键作用,这些突变被称为驱动突变。驱动突变的发生会显著改变正常细胞的分子运行系统,并且刺激肿瘤细胞的生长。由于癌症基因组的不稳定性,通常驱动突变的发生会伴随着大量的乘客突变,这些乘客突变一般不会参与癌症的发生发展以及治疗等过程。考虑到驱动突变是作为癌症的诊断和预后的分子标志,并且是癌症相关药物的研发或者作用的靶标,所以从癌症基因组上众多的突变中识别出驱动突变是非常重要的。错义突变是基因组上数量最多的一种突变,目前已有多种策略用于预测癌症驱动错义突变。第一种策略是通过传统生物学实验方法鉴定驱动突变,但是比较耗时耗力,难以处理和挖掘众多测序项目产生的海量突变数据。第二种策略是通过统计学方法发现驱动突变,但是需要较大数量级的癌症样本,一般难以获取到。最后一种策略是基于序列位点保守性,蛋白质结构与功能等特征开发相关算法,预测对癌症发生发展有功能影响的驱动突变。目前已经有很多算法用于预测癌症驱动错义突变,这些预测算法有着不同的设计特点。已有的关于癌症驱动错义突变预测算法评估性研究工作指出不同类别预测算法存在着预测偏向性问题,并提出了集成不同预测工具的解决方案,但是没有对造成不同预测工具预测偏向性的原因进行深层次地分析。通过标准测试集(癌症相关、有代表性、非冗余)上的实验结果,本文参照模型的设计方法系统地对不同类别的突变预测工具的预测性能进行了评估和分析。根据评估结果,构建了基于高质量负样本的癌症驱动错义突变预测模型。本文的主要工作如下。1.分析比较了现有错义驱动突变预测工具,在多套标准测试集的预测结果表明,癌症特异性突变预测工具比广谱性疾病突变预测工具对负样本预测性能较差。本文共获取34种错义驱动突变预测工具(包括5种保守性分数预测方法),基于6套标准测试集对这些突变预测工具的预测性能进行了比较分析。根据对癌症特异性突变预测工具和广谱性疾病突变预测工具的评估,癌症特异性突变预测工具相比广谱性疾病突变预测工具表现了较低的综合预测能力,主要原因是其对负样本的预测能力较差,有待提升。2.提出了一种基于高质量负样本数据集的驱动错义突变预测方法,建立了驱动错义突变预测模型CMMPred(Cancer Missense Mutation Predictor)。训练集的正样本和负样本分别来源于COSMIC和dbCPM数据库。借助CRAVAT工具,本文为所有样本编码生成85维特征,并基于XGBoost算法建立了CMMpred模型。在独立测试集上,CMMPred的AUC、Sensitivity和Specificity分别为0.77、0.75和0.66,比紧随其后的PolyPhen2工具在AUC上高出7个百分点,表现了比其他所有工具更好的综合预测能力。实验结果说明经过人工注释的高质量乘客突变有效提升了癌症驱动错义突变预测性能。"
1717,基于深度学习的大雾短临预报研究,"雾是影响能见度的一种重要天气现象,与人类生活息息相关,雾的准确预报对于人们生活和生产都具有极其重要的作用。传统的统计预报方法由于气象因子的挑选过程繁杂,且手工设计的特征比较单一,使得模型在复杂的背景下不具有很好的泛化能力,进而影响了大雾预报的准确性。近些年,深度学习技术快速发展,深度神经网络模型的强大的特征表达能力使得数据中的相关特征能够被自动提取与学习,模型的学习性能被大大增加,使得其分类和预测效果也有了明显的提高。在本文中,我们将利用深度学习来进行雾的短临预报研究,这也是深度学习在大雾预报研究方面的首次尝试。现将本文研究内容总结如下:(1)利用卷积神经网络(Convolutional Neural Network,CNN)构建大雾短临预测模型,通过对气象要素时间序列的分类来实现对未来1-4小时的雾短临预报。首先,对于原始气象要素数据进行标准化处理,去除数据中缺省值和异常值以构造不同长度的时间序列数据。为解决大雾的样本不均衡问题,本文采用随机欠采样方法构建平衡样本数据集。在该数据集上通过对网络进行优化,构建了卷积神经网络短临预测模型的最优网络结构,并通过实验验证构建的网络模型的有效性。(2)为了进一步提高短临预报的准确率,本文利用长短期记忆网络(Long Short-Term Memory,LSTM)构建大雾短临预测模型,同时利用合成少数类过采样技术(Synthetic Minority Oversampling Technique,SMOTE)算法对原始气象要素时间序列数据进行数据增强,以解决样本不平衡问题。在优化模型中加入Dropout层预防在训练过程中出现的过拟合现象。并通过实验确定长短期记忆网络预测预测模型的最优参数。在进一步实验中,将CNN与LSTM结合,实现了CNN-LSTM预测模型,实验结果证明了提出的LSTM预测模型的有效性。最后本文利用PyQT5编写了雾的预报实时显示软件,实现自动的加载模型,调用气象数据,实时预报和实时显示等功能,效果良好。"
1718,氮气在分子筛中吸附性质的理论研究,"沸石材料是由SiO4和AlO4构成,以桥氧原子相连的3D结构的硅铝酸盐,其具有独一无二的骨架结构和孔道体系,广泛应用于石油化工、医疗、污水处理等领域。如何快速、准确地模拟出沸石分子筛的吸附等温曲线,从而筛选出具有优异吸附性能的材料?我们通过密度泛函理论结合机器学习和巨正则蒙特卡洛模拟的方法研究了沸石材料与氮气相互作用能,结合Langmuir吸附模型模拟其等温吸附曲线,利用BET实验方法验证了理论预测的结果,为筛选具有良好氮气吸附性能的沸石材料提供了一个简便的方法。本文的主要研究内容如下:我们用巨正则蒙特卡洛方法模拟出氮气分子在MFI型沸石中分布情况,表明氮气分子分布在体积足够的空间中,而尺寸过小的空间无法吸纳氮气分子,因而对吸附性能没有贡献。我们通过密度泛函方法计算其结合能,由于对称位置的孔道周围的每个硅氧原子可同时与氮气分子两端发生静电极化相互作用,因而具有更强的结合能。我们计算了其他沸石分子筛与氮气之间的结合能,并将其作为机器学习的数据集进行训练。机器学习筛选出的三个描述符,即沸石中NBU结构单元的顶点数(V)、孔道中最大包含球直径(PLD)以及几何形变程度(RDLS)可以很好地对沸石吸附氮气的结合能进行预测。氮气所吸附的空间大小通过V体现,而PLD描述了沸石孔道结构的几何的“凹凸”特征。RDLS与局部硅氧原子电荷的差值相关,表明静电相互作用是氮气吸附行为的驱动力。我们用密度泛函理论计算结果对机器学习预测的结果进行验证,表明结合能预测模型的合理性。我们根据密度泛函计算结合机器学习的方法得到氮气与235种沸石拓扑结构的结合能,利用Langmuir吸附理论,模拟出吸附等温线。与实验BET方法和巨正则蒙特卡洛方法所得到的吸附等温线定性吻合,发现其在低压区域迅速吸附,体现出沸石微孔结构的特征。这种方法能够快速、较为准确地模拟出沸石的等温吸附曲线,有望模拟其他结构更为复杂的多孔材料,如MOFs和COFs等材料的等温吸附曲线,筛选出具有优异吸附性能的材料。"
1719,机器学习算法在刀具磨损状态评估上的应用研究,"智能生产是当今机械加工业的热门话题,而实现产品的全自动化生产模式,也成为了现代工厂发展的必然趋势。在此条件下,如何使生产设备自主判断其运行状态并及时做出调整,是保证其产品质量与生产效率的重要一环。对刀具磨损状态的智能评估,能在刀具达到使用寿命前做出预警,保障生产精度与设备安全,对工厂的智能化生产具有重要意义。本文选取了在刀具切削过程中与其磨损相关性较强的切削力信号与加速度信号进行研究,将多种机器学习算法应用在刀具的磨损状态评估上。主要研究内容包括对信号的特征提取、支持向量机(SVM)分类模型的优化与随机森林(RF)算法在刀具的磨损评估中的应用。由于原始的加速度信号与切削力信号不便于直接分析,本文首先对其在时域与频域内进行特征因子提取,然后利用小波分析获取原始信号的频段能量占比。针对特征量过多可能出现数据冗余,同时也为了提高分析效率,使用主元分析方法(PCA)对得到的特征矩阵进行降维处理,得到低相关度的特征矩阵。其次,考虑到SVM具有良好的小样本、非线性数据的处理能力,对其在刀具磨损状态评估中的应用进行了研究。使用机器学习算法优化SVM模型的参数,并采用交叉验证方法对优化后的SVM模型对刀具的磨损状态识别效果进行验证。结果表明,经过特征提取与处理后,机器学习算法优化的SVM模型对刀具的磨损状态评估有较高的准确度。最后,针对SVM模型构建时间较长的不足,本文基于RF算法,提出了新的评估模型。由于RF算法良好的高维数据快速处理能力,将未降维的特征数据直接作为输入得到评估模型。最终得到的评估结果说明,使用RF算法处理刀具磨损状态评估问题能兼顾模型建立速度与识别准确度。研究结果表明,本文提出的多种机器学习算法优化后的SVM模型与RF模型均能有效地对刀具磨损状态进行评估,为在线评估系统的建立奠定了基础。"
1720,土地生态适宜性约束下的未来城市扩张优化研究,"在当今国内的城市化进程中,为了满足不断增长的人口生存以及生产建设需求,城市空间也需要不断向外延伸。这使得城市扩张日益成为土地资源利用变化的主导特征,同时也对城市的生态空间质量维持造成了更大的压力。为此,我国政府提出了生态文明建设的总体要求,强调在未来城市发展规划上要增加更多人地和谐、绿色发展方面的考量。在这一背景下,有必要转变当前土地资源的粗放利用方式,对未来的城镇用地布局优化开展前瞻性研究,探索更加符合时代要求的新型城市发展道路。常州是长三角的核心城市之一,将其作为典型区域开展研究对于东部经济发达地区的城市发展具有重要借鉴意义。论文从协调城市增长与生态环境保护的角度出发,基于元胞自动机模型对未来城镇用地演化进行建模,并将土地生态适宜性约束纳入到城市扩张过程中对空间格局进行统筹和引导,减少耕地、水体等生态用地的随意侵占。在获取元胞转换规则的过程中,采取了基于Stacking的集成策略对多个机器学习模型进行融合,进一步提升了对空间数据特征的挖掘能力,从而实现对元胞自动机模型的改进。最终,论文形成了一个未来城市空间发展优化方案,地方政府在国土空间规划编制及实施中可以将其作为理论支撑,参照具体发展方案进行空间落实。论文的主要研究内容与结论如下:(1)城镇用地扩张过程分析在2009-2015年这段时间之内,研究区的城镇用地共增长了64.3 1km2,其增加规模呈现出减小的趋势,分别位于南部和北部的武进区及新北区是城镇用地扩张的主要方向。多环缓冲区分析表明,各圈层内的城镇用地比重不断提高,该时间序列后期的城镇用地扩张强度有所下降,这与新增城镇用地规模的减小趋势相一致。而在城镇用地扩张模式方面,飞地式和边缘式增长占据着主导类型。以上结果表明,尽管城市增长有所放缓,但是整体上仍然呈现出明显的“外扩”趋势。此外,在该时期的城市化进程中大量诸如耕地、水体之类的生态用地遭到占用,整个研究区的碳储量也随之减少了63.50万吨。(2)土地生态适宜性约束计算论文从自然地理条件、人类活动胁迫、生态功能区限制三个角度选取11个指标,并基于层次分析法获取不同指标对应权重,最终对研究区进行多因子土地生态适宜性综合评价。评价结果表明,土地生态适宜性较高的区域分布在武进区西南、东南和新北区北部,其主要是集中连片的优质基本农田或重要水体和生态公益林等。此外,以评价结果作为阻力基面数据、2015年城镇用地作为扩张源数据输入到最小累积阻力模型,生成了城市扩张土地生态阻力约束的空间图层。(3)基于元胞自动机的城镇用地扩张模型设计针对现有基于单机器学习模型的元胞自动机城市扩张模拟研究的不足,采取Stacking集成策略对支持向量机、随机森林和多层感知机三个模型进行了融合,有效改善了新增城镇用地转换概率获取的精度和效率,促进了整体空间数据挖掘能力的提升。此外,将基于土地生态适宜性评价生成的空间阻力与城市扩张过程耦合至同一框架下,设计并实现了土地生态适宜性约束下的未来城镇用地扩张推演模型。(4)未来城镇用地扩张模拟与优化对研究区2030年城镇用地进行预测,并以不同土地生态适宜性约束强度设置现状延续情景、平衡发展情景和严格约束情景三个情景进行对比分析。结果表明,土地生态适宜性能够有效引导、约束城市扩张与实现土地利用结构优化。且随着约束强度的增强,城镇用地空间布局更加紧凑,占用耕地、水体等生态用地面积显著减少,扩张热点区域更加远离重要生态用地。最后,论文基于土地生态适宜性评价结果提取重要生态核心区域,并结合平衡发展场景下2030年城镇用地扩张布局,设计形成了一个城市空间发展综合优化方案,以便在实际的区域政策实施和国土空间规划中提供更加灵活、全面的战略支持。"
1721,基于波束形成技术的运动声源识别方法研究,"噪音污染使得人们越来越意识到其对环境的负面影响,从而促进了噪声控制工程的发展。实现噪声控制的主要前提是获取声源信息,保证声源的精准识别,其中波束形成技术是声源识别方法的一个重要分支。由于运动声源所辐射出的声信号会因多普勒效应而失真,使得常规波束形成技术不能精确实现运动声源的识别。针对此问题,本文将研究基于波束形成技术的运动声源识别,具体内容如下:首先简述了选题背景,介绍了运动声源识别方法的研究历史和最新技术,并分析了关于运动声源识别方面尚且需要解决的问题。提出了基于CLEAN的旋转声源识别方法,该方法通过旋转框架技术进行去多普勒效应处理,再引入CLEAN算法来识别旋转单极子声源,提高了声源识别分辨率。随后,通过数值仿真的方法,证实了所提方法的可行性,且提高了DAMAS2在1500 Hz～5000 Hz左右声源频率和不同测量距离下的识别精度。其次,对于应用机器学习进行旋转声源定位的方法较少,因此提出了基于机器学习算法的旋转声源定位方法。首先分析了支持向量机(SVM)和朴素贝叶斯(Naive Bayes)的基础理论,再获取去除多普勒效应后的旋转单极子声源的声压信号并计算其声压互谱矩阵,得到特征向量,将此特征向量作为输入,通过一系列训练过程得到声源位置分类模型,从而实现旋转声源的位置识别。随后,通过数值仿真的方法,验证了方法的可行性,且获得了较高的识别精度和准确率。针对低信噪比情况下匀速及匀变速运动声源的识别问题,提出了基于快速反卷积波束形成技术的直线运动声源识别方法。首先通过时域―波数域方法去除直线运动声源的多普勒效应,再引入DAMAS2和FFT-NNLS-DAMAS来识别直线运动声源,提高了声源识别的分辨率。随后,经过仿真和实验对方法进行了验证,得出所提方法可以准确的识别出低信噪比情况下匀速及匀变速声源的位置。论文研究了基于波束形成技术的运动声源识别方法,在一定程度上解决了目前运动声源识别尚且存在的问题,为运动声源的识别提供了可行的方法。"
1722,基于葵花8卫星遥感数据的大雾识别研究,"大雾是常见的自然天气现象,也是不可忽视的自然灾害。近年来,随着经济的快速发展,大雾影响着人们的生产生活。因此,研究者们逐渐开始重视大雾的监测和识别。而随着科学技术的快速发展,卫星遥感技术也趋于成熟,遥感数据比传统的地面数据具有更新快,检测范围广,时效性高等方面,因而很多的领域使用到遥感卫星技术。本文中所使用的为葵花8卫气象卫星数据,无论是从云图的质量,截取的频率,波道,清晰度都比上代卫星大幅改善。因此,使用葵花8卫星数据进行雾的监测与识别研究,可以提高大雾的识别性能。本文在进行研究之前首先要进行大雾数据的提取与标注,根据地面站的经纬度找出安徽省所对应的地面站的位置,然后与卫星数据进行经纬度匹配,提取该位置上的卫星数据,在根据地面站的能见度判断该位置雾的情况。本文主要通过两类算法对大雾识别进行研究,第一类算法是基于传统的机器学习方法的大雾的识别,第二类算法是基于深度学习的大雾识别。主要研究内容如下:1)基于机器学习的分类方法进行雾的识别。在平衡样本和非平衡样本的条件下,使用多种传统的机器学习分类算法进行雾的识别。所使用的算法中有支持向量机,朴素贝叶斯,决策树等。实验验证在平衡样本下,机器学习分类算法对大雾的检测有较好的效果。在非平衡样本的情况下,本文使用合成少数类过采样算法(Synthetic Minority Oversampling Technique,简称SMOTE)算法进行数据扩充也能有效的提高大雾的识别精度。2)基于深度学习的分类方法进行雾的识别。本文通过搭建卷积神经网络模型,优化网络参数,从数据中提取相关特征,通过实验表明在平衡样本的情况下,卷积神经网络对大雾识别能力较好,并且效果要高于传统机器学习的分类算法。在非平衡样本下,SMOTE算法结合卷积神经网络,也能提高大雾的识别精度,其识别性能效果也同样超过传统的机器学习分类算法。"
1723,基于改进卷积神经网络的电力系统暂态稳定评估方法,"暂态稳定分析是电力系统安全分析的重要内容,对电力系统的安全稳定运行、为电力系统运行调度的控制决策提供参考依据具有重要作用和价值。如何在系统发生故障的前期准确、快速的评估暂态稳定状态和裕度,一直是电力系统安全分析环节中亟待解决的问题。传统的解析方法中的时域仿真法和直接法,因前者计算量大、耗时长,后者在复杂系统中难以构建满足条件的能量函数等缺陷,而无法满足大电网安全稳定评估的实时性要求。近年来,人工智能方法因其评估精度高、耗时短等优点而逐渐成为快速暂态稳定分析的主要工具之一。然而此类算法因其浅层结构的限制,在求解高维数据分类问题时泛化能力受到制约。且多为判定暂态稳定与否的二元分类问题,缺乏量化评估。本文针对上述问题,将具有自主学习和抽象表达能力的深度学习方法引入电力系统暂态稳定评估中,提出一种基于短时受扰轨迹和改进卷积神经网络的电力系统暂态稳定评估方法。本文的主要研究内容如下:(1)通过卷积神经网络(Convolutional Neural Network,CNN)建立起发电机端电气量的短时受扰轨迹与系统暂态稳定性之间的映射关系,并引入考虑故障初期发电机受扰程度的暂态稳定信息样本矩阵构建,使提取的特征更具鲁棒性,有效减少误判漏判样本,从而提高模型的泛化能力和评估性能。(2)根据CNN层间计算的维度原则,以网络的综合评估指标最优来选择网络结构参数。在暂态稳定信息样本矩阵构建的基础上,构建输入特征与暂态稳定性间的映射模型,进一步减少误判漏判样本,有效提高网络模型的评估准确率。(3)构建改进CNN建立短时受扰轨迹与暂态稳定裕度间的映射关系。该改进模型结合了CNN的特征提取层和BP预测神经网络,并且与CNN的暂态稳定分类模型构成复合网络。首先利用CNN进行数据样本的预分类,然后利用改进CNN预测模型对预分类的样本进行裕度预测,最终实现基于短时轨迹的电力系统暂态稳定裕度评估。IEEE-39节点系统算例结果表明本文所提方法能够实现基于短时受扰轨迹和改进CNN的电力系统暂态稳定评估,可为电力系统运行调度的控制决策提供参考依据。"
1724,基于统计综合法的电力负荷建模方法研究,"作为电力系统数字仿真的重要组成部分之一,电力负荷数学模型的准确性会直接影响系统仿真的结果。而由于负荷自身所具备的非线性、时变性、分散性等特点,使得有关其建模的研究进展缓慢,尤其是有关基于统计综合法的建模研究,已经明显处于落后的地位。随着我国经济发展与社会进步,电力系统的规模越来越大,对电网稳定运行与可靠性的要求也越来越高,电力负荷的容量与构成也正发生着巨大的变化。在这样的大背景下,研究建立能真实准确反映实际电网负荷的模型就成为了负荷建模研究领域的重点问题。本文以典型感应电动机的负荷数据为基础,采用机器学习的有关算法作为技术支撑,进行了基于统计综合法的负荷建模研究。本文首先就传统统计综合法建模中存在的缺陷提出了改进,引入层次凝聚聚类算法对以感应电动机为代表的电力负荷分类问题进行了研究,研究结果表明该算法可以有效对电力负荷按其特性进行分类,分类效果良好,符合预期结果。然后研究了将人工神经网络应用于负荷建模的有关问题,提出了一种改进的BP算法对网络训练过程进行了优化。改进的方面主要有两点,一是改固定的学习率为自适应学习率,使得算法自身可以根据学习的情况自适应地调节学习率,以提升学习效率,二是引入新的神经元激活函数,改善网络性能。测试结果显示,这一改进策略有效提升了算法的计算速度与精度。本文还分析了多项式形式和幂函数形式负荷静态模型的特点,对同一静态负荷曲线进行参数辨识,发现幂函数形式具有更好的优越性,更适合作为静态负荷模型。基于时下流行的TensorFlow框架,编写实现了人工神经网络搭建动态负荷模型,在进行模型建立时,首先利用统计得到的负荷数据计算得出负荷的动态特性数据,再用这些数据作为网络训练的样本对神经网络进行训练,训练完成后的神经网络即可以作为真实负荷的模型进行其他相关的数字仿真计算。验证计算的结果表明,本文提出的改进BP神经网络可以较好地完成动态负荷建模,得到的模型动态特性与原始负荷十分接近,是一种可行的负荷建模方法。"
1725,基于长短时记忆网络的棉花病虫害发生预测研究,"随着计算机科学的发展以及云计算、大数据时代的到来,机器学习和深度学习方法广泛应用于各个领域,在农业领域也初见成效。长短时记忆网络(LSTM)是在传统循环神经网络(RNN)的基础上经过改进的一种人工神经网络。改进后的LSTM不仅继承了RNN在处理时间序列问题上的优势,而且解决了RNN经常出现的梯度消失和梯度爆炸问题,具有更长期的记忆功能。本文利用LSTM来预测棉花病虫害的发生,通过对LSTM网络的不断训练,迭代优化,最终在棉花病虫害发生问题上取得良好的预测效果。本文搜集了1981-2011年间印度地区棉花病虫害数据、天气因素变化数据和部分大气环流数据,并利用LSTM网络构建了病虫害发生预测模型。本文的主要内容概括如下:1.统计分析天气与棉花病虫害之间的内在联系。本文统计了1981-2011年间印度地区的8种天气因素和棉花病虫害发生数据的年平均变化趋势,结果显示病虫害发生危害程度逐年上升,且在2005-2011年间危害程度加剧。与此同时,印度地区的温度、湿度、降雨量等呈逐年减少的趋势,与病虫害发生危害趋势相反。然后,本文分别对数据中的年份、月份以及天气因素与病虫害发生情况进行相关性分析。结果表明,印度不同地区、不同种类棉花病虫害的发生均与天气因素显著相关,其中,温度、湿度和日间蒸发量三种天气因素的显著性较为普遍。天气与病虫害发生存在的普遍规律,为本文接下来的病虫害发生预测建模提供了理论依据。2.基于LSTM的棉花病虫害发生的二分类预测。本文所获取的天气-棉花病虫害数据是时间序列类型的数据,在时间上有一定的规律可循。LSTM作为一种改进的RNN,非常适合用于这类问题的建模。首先,从农作物病虫害决策支持系统中下载了1981-2011年间印度地区棉花病虫害发生数据和8种天气特征数据,进行简单的数据清洗和预处理以达到建模输入的基本要求。然后,利用单一变量原则对LSTM网络的重要参数进行设置。最后,利用历史的天气-棉花病虫害发生数据对未来印度各地区棉花病虫害的发生情况进行预测。为了突出LSTM在处理长时程依赖问题上的优势,使用传统机器学习模型与该模型进行对比。结果显示,LSTM在各项性能指标上均优于传统机器学习模型。3.基于LSTM的棉花病虫害危害程度的多分类预测。基于原始数据,本文将印度地区棉花病虫害的发生危害程度分为四个等级:不发生病虫害、轻微病虫害、中等病虫害和严重病虫害。在查阅了大量文献后发现,部分大气环流指数可以通过影响各地区的气候变化来进一步影响当地农作物病虫害的发生。因此,本文从中国气象局国家气候中心下载了部分大气环流指数用来作为补充特征,与天气因素一起用于LSTM网络建模。随后,搭建了LSTM模型并进行数据预测。同时测试了不同地区、不同种类的棉花病虫害数据,以检验模型的普适性。最后,本文还测试了不同预测时间长度下本模型的性能。结果表明,本模型不仅在预测未来一周病虫害发生时表现良好,同时也能为未来两周甚至一个月后的棉花病虫害发生情况提供参考。"
1726,基于深度学习的多疾病风险预测模型研究,"随着医疗数字化技术、人工智能和大数据技术的发展,医疗模式逐渐从以治疗为主转变为以预防为主。将人工智能和大数据技术结合用于疾病风险预测是智能医疗领域的一个研究重点。疾病风险预测是指发现疾病的潜在风险和趋势,对于疾病的预防、干预和管理具有重要作用。在实际生活中,经常发现人们同时患有多种疾病的潜在风险和趋势,这种问题属于多疾病风险预测问题。为了有效地处理多疾病风险预测问题,研究学者已经设计了许多较好的算法。本文采用深度学习来处理多疾病风险预测问题,因为深度学习技术最近非常受欢迎。在多疾病风险预测模型设计中,本文专注于深度学习算法设计和改进。本文首先采用问题转化方法将多疾病风险预测问题转化为多标记学习问题。因为问题转化方法能够使算法独立,只需进行多疾病标记转换工作,并采用Binary Relevance(BR)和Label Powerset(LP)这两种常见的问题转化方法对多疾病标记分别进行转化。在问题转化方法基础之上,本文设计了一个新颖的卷积神经网络框架,命名为GroupNet,并分别与BR和LP方法进行结合。GroupNet网络框架的核心组成部分是本文提出的组模块,组模块由组卷积和聚类卷积两部分组成,组模块具有缓解卷积冗余和聚类作用。通过实验结果比较可知,GroupNet网络框架的性能优于几个经典的卷积神经网络框架。其次针对BR方法没有考虑到标记之间的关联性这个局限性,本文提出了一种关联损失函数来缓解这个局限性。本文将关联损失函数与焦点损失函数和交叉熵损失函数进行比较,实验结果表明关联损失函数的表现优于其他两种损失函数。为了进一步提高多疾病风险预测模型的性能,本文将GroupNet和集成算法(如随机森林算法、LightGBM)进行有机地结合,得到集成模型,集成模型能够集成多种算法的优点。实验结果表明,集成模型比单一的GroupNet网络和集成算法在准确率上至少提高1%。最后为了验证本文提出的方法的性能,本文采用多种经典的机器学习算法与本文提出的方法进行对比。本文提出的GroupNet网络框架和集成模型的准确率分别达到了81.13%和82.68%,实验结果明显优于其他机器学习算法,并且在精度、召回率和F1这些评价指标上也有类似的提升。"
1727,基于疾病预测的体检结果生成系统设计与实现,"随着医疗科技的发展,越来越多的智能系统被用来辅助医疗诊断。体检系统是一种智能系统,通常具有体检结果自动生成、查询和统计分析等功能。当前体检结果自动生成,主要基于医学专家知识库,通过对体检项设定阈值,当所属体检项的体检结果值出现异常时,系统自动匹配生成相应的体检模板。该方式存在体检结果生成不精准的问题,体检结果受预先设定的规则影响较大。为了有效地解决以上问题,本文基于大量历史体检数据,通过建模分析,进行疾病预测,并对体检结果进行关联分析,提出基于疾病预测的体检结果生成系统解决方案。本文的主要内容包括以下几个方面。首先,数据集来源于河南省某三甲医院,在数据预处理阶段,采用多种缺失值填充方法进行对比,基于准确率和F1评价标准,选择均值填充法对数据集的缺失值进行填充,并对数据进行标准化操作;采用皮尔森相关系数方法进行特征筛选,通过准确率评价标准筛选出相应特征子集,构建6个多标签疾病预测模型,通过对比分析实验数据,确定选择Ensemble of Classifier Chains(ECC)算法作为多标签疾病预测模型;其次,采用Apriori算法,基于体检数据集中疾病和体检结果关系,利用置信度筛选疾病对应的体检结果的频繁项集,通过准确率、召回率等评价标准确定参数,构建体检结果生成模型;基于原始特征和预测疾病信息,利用多标签分类算法,构建基于特征和疾病的体检结果生成模型;最后,整合基于Apriori方法的体检结果生成模型和基于疾病和特征的体检结果生成模型,通过对每个算法设置权重,构建体检结果生成集成模型。基于疾病预测的体检结果生成系统,建立两台服务器划分业务功能,利用接口进行跨平台的数据传输,设计并实现了基于疾病预测的体检结果生成系统。"
1728,经冠状动脉造影冠脉不同狭窄程度患者中医证候特点及规律研究,"背景冠状动脉(以下简称冠脉)造影是诊断冠心病的金标准,冠脉粥样硬化是冠脉狭窄的病理基础,可根据患者冠脉狭窄的程度和范围将其分为冠脉轻度狭窄患者(狭窄冠脉临界病变患者(43.46%)>拟行CABG患者(33.10%)>拟行PCI患者(32.66%),而男性在拟行PCI患者的比例(67.34%)>拟行CABG患者(66.90%)>冠脉临界病变患者(56.54%)>冠脉轻度狭窄患者(47.51%)。②年龄分布:4组不同狭窄程度患者在年龄分布上差异有统计学意义(P=0.000气虚证>气滞证>热蕴证>痰浊证>阴虚证>阳虚证>寒凝证,河南地区气虚证>痰浊证>气滞证>阴虚证>血瘀证>阳虚证>热蕴证>寒凝证,云南地区气虚证>血瘀证>痰浊证>热蕴证>阴虚证>气滞证>阳虚证>寒凝证。北京地区气滞证(45.24%)和热蕴证(39.64%)明显高于另外两个地区,河南地区痰浊证明显较高(44.58%),云南地区以气虚证(75.48%)较为突出。(3)冠脉不同狭窄程度患者中医证候呈现一定变化规律。①证候要素特点:冠脉轻度狭窄患者气虚证>气滞证>血瘀证>痰浊证>阳虚证>阴虚证>热蕴证>寒凝证;临界病变患者气虚证>血瘀证>痰浊证>气滞证>热蕴证>阴虚证>阳虚证>寒凝证;拟行PCI患者气虚证>血瘀证>气滞证>热蕴证>痰浊证>阴虚证>阳虚证>寒凝证;拟行CABG患者气虚证=血瘀证>痰浊证>热蕴证>气滞证>阴虚证>阳虚证>寒凝证。4组患者在气滞证(P=0.000暗红舌(0.0659)>紫暗舌(0.0515)。②气虚证:模型准确率84.4%,贡献度排序为乏力(0.1261)>气短(0.0581)>纳呆(0.0266)。③气滞证:模型准确率92.6%,贡献度排序为心烦易怒(0.1371)>太息(0.061)>胸胁胀满(0.0299)。④痰浊证:模型准确率为85.1%,贡献度排序为腻苔(0.0743)>厚苔(0.0483)>肢体困重(0.0413)。⑤热蕴证:模型准确率为89.7%,贡献度排序为黄苔(0.155)》白苔(0.0544)》小便黄(0.0443)。⑥阴虚证:模型准确率为81.8%,贡献度排序为盗汗(0.0513)>少苔(0.0411)>恶热(0.0272)。⑦阳虚证:模型准确率为96.7%,贡献度排序为畏寒(0.2716)>肢冷(0.2127)》腰冷(0.0198)。两证候要素组合:①血瘀证+气虚证:模型准确率为93.4%,贡献度排序为乏力(0.061)>暗红舌(0.0388)>口唇紫暗(0.0274)>舌下络脉青紫(0.0223)。②血瘀证+痰浊证:模型准确率为94.7%,贡献度排序为暗红舌(0.0418)>厚苔(0.0375)>腻苔(0.037)>舌生瘀斑(0.0364)。③气滞证+血瘀证:模型准确率为98.0%,贡献度排序为心烦易怒(0.1623)>口唇紫暗(0.0888)>太息(0.0523)>紫暗舌(0.0269)。④痰浊证+热蕴证:模型准确率为94.6%,贡献度排序为黄苔(0.0903)>腻苔(0.0567)>白苔(0.0261)>大便秘结(0.0258)。⑤气虚证+阴虚证:模型准确率为91.0%,贡献度排序为乏力(0.0643)>气短(0.0336)>面色红(0.0248)>盗汗(0.0226)。多证候要素组合:①血瘀证+痰浊证+气虚证:模型准确率为98.4%,贡献度排序为暗红舌(0.038)>乏力(0.0357)>腻苔(0.0258)>厚苔(0.0249)。②血瘀证+痰浊证+热蕴证:模型准确率为97%,贡献度排序为黄苔(0.0462)>腻苔(0.0324)》胸刺痛(0.0236)》大便秘结(0.0219)。③血瘀证+痰浊证+热蕴证+气虚证:模型准确率为98.2%,贡献度排序为腻苔(0.0254)>暗红舌(0.0251)>黄苔(0.0204)>纳呆(0.0204)>乏力(0.0194)。④血瘀证+痰浊证+气滞证+气虚证:模型准确率为98.1%,贡献度排序为心烦易怒(0.0532)>乏力(0.0351)>腻苔(0.029)>结代脉(0.0258)>数脉(0.0239)>口唇紫暗(0.0217)。结论冠脉不同狭窄程度患者呈现出以“虚”为本,以“痰热瘀滞”为标的核心病机,虚证以气虚为主,实证以血疲为要,不同地域间略有不同,不同狭窄程度上也各有侧重,冠脉轻度狭窄患者以气滞证和阳虚证较为突出。此外,神经网络算法对中医证候具有良好的分类性能,可挖掘出对中医证候诊断贡献度较大的症状体征,为冠脉临界病变患者中医证候量化诊断标准的制定提供备选条目,为临床辨证提供参考。"
1729,基于颜色气味数字化及信息融合的苦杏仁走油监测系统的研究,"中药质量的稳定性和可控性是中医临床疗效的重要保证。中药在贮存过程中,受外界条件及自身特性的影响,常发生变质现象。“走油”是中药材或中药饮片贮存过程中常见的变质现象之一。药材走油后,药性散失,疗效下降,严重时产生毒性,危及生命。因此,中药贮存中走油现象的快速鉴别、走油程度的客观判断以及走油过程中药材质量的实时监控,都是亟待解决与研究的重要课题。苦杏仁是常用大宗中药,同时也是易“走油”变质的典型代表。本课题以苦杏仁为研究载体,从颜色、气味数字化及融合信息等方面建立苦杏仁不同走油程度判别模型及质量预测模型,研究的主要内容及结果如下:(1)不同走油程度样品的制备及人工感官评价。本文通过在北京自然放置存储和在高温高湿环境下存储获得不同走油程度的苦杏仁样品。采用模糊数学法对苦杏仁的外观性状进行综合评价,根据评定结果,苦杏仁样品被划分为四个不同的走油等级。(2)不同走油程度苦杏仁的质量变化研究。随着走油程度的加深,苦杏仁苷含量下降,酸值和过氧化值逐渐升高。走油程度为I级和II级的样品其内在指标成分无显著性差异,走油程度为Ⅲ级和Ⅳ级的苦杏仁样品均不能再药用。苦杏仁走油后挥发性成分发生变化,壬醛和2-溴苯丙酮可能是苦杏仁走油哈喇味的主要成分。(3)基于颜色数字化的苦杏仁走油监测研究。本文运用日立3010紫外可见分光光度计和柯尼卡美能达CM-5型分光测色仪分别测定了苦杏仁粉末颜色和剖面颜色。建立基于颜色数字化的苦杏仁走油程度判别模型:基于粉末颜色数字化,Naive Bayes算法建立的模型经十折交叉验证法和外部测试集验证法验证,其正判率均在85%以上;基于剖面颜色数字化,Logistic和Multiple Layer Perception算法的正判率较高,其十折交叉验证法的正判率均高于80%,外部测试集验证法的正判率均为78.57%。经相关性分析,苦杏仁内在质量与粉末颜色及剖面颜色均存在显著相关性。建立了基于粉末颜色的苦杏仁苷含量和酸值预测模型,以及基于剖面颜色的苦杏仁苷含量预测模型。(4)基于气味数字化的苦杏仁走油监测研究。本文使用α-FOX3000气味指纹分析仪对苦杏仁样品进行气味测定。基于气味数字化,选用高温高湿存储环境样品用机器学习算法对苦杏仁走油程度进行判别,Logistic算法的识别效果最好,十折交叉验证法的正判率为97.44%,外部测试集验证法的正判率为87.50%,可较好的完成对不同走油程度苦杏仁的分类鉴别。经相关性分析,苦杏仁内在质量与气味存在显著相关性。建立了限定存储条件下基于气味信息的苦杏仁苷含量预测模型。(5)基于颜色气味融合信息的苦杏仁走油监测研究。本文采用特征变量融合的数据融合方法,将苦杏仁的颜色信息和气味信息相结合,以获取更全面的感官信息。建立了基于颜色气味融合信息的苦杏仁走油程度判别模型。基于粉末颜色-气味融合信息,Logistic、IBK、KStar、LMT和Random Forest算法的正判率较高,十折交叉验证法的正判率均在90%以上,外部测试验证法的正判率均为100%,可较好的完成对不同走油程度苦杏仁的分类判别。基于剖面颜色-气味融合信息,Logistic算法和KStar算法的正判率较高,十折交叉验证法和外部测试集验证法的正判率率均在80%以上,可较好的完成对不同走油程度苦杏仁的分类判别。经相关性分析,苦杏仁内在质量与融合信息存在相关性。建立了基于颜色气味融合信息的苦杏仁苷含量和酸值预测模型。(6)不同质量监测模型的比较。本文所建的对不同走油程度苦杏仁的判别模型中,判别效果最好的是Logistic和IBK算法基于粉末颜色-气味融合信息建立的判别模型。本文所建的苦杏仁苷含量预测模型,拟合度最好的是基于剖面颜色特征值所建的回归模型和基于剖面颜色-气味融合信息所建的回归模型。本文所建的酸值预测模型是基于粉末颜色特征值所建的回归模型和基于粉末颜色-气味融合信息所建的回归模型。研究表明,基于颜色气味数字化及其信息融合对苦杏仁走油进行监测是可行的,所建立的质量监测系统可快速对苦杏仁进行走油程度判别和内在质量预测。"
1730,基于分子振动特征的药物靶点识别及活性预测模型研究,"背景:目前,多数中药化学成分作用靶点及其生物活性尚不确定,这已成为阐明中药物质基础及其作用机制的瓶颈之一。中药化学成分作用靶点及其生物活性的研究有助于揭示中药在治疗疾病过程中发挥药效的程度以及为中药化学成分在体内发挥疗效的机制提供线索与指导,也有助于中药化学成分作用靶点的重新定位。随着科学技术的进步与发展,越来越多的中药化学成分被发现。由于时间与资金成本的限制,利用传统实验的方法进行中药化学成分与相关靶点之间生物活性的测定面临很大的挑战,花费昂贵且效率较低。采用机器学习的方法构建药物与靶点的定量预测模型进行中药化学成分作用靶点的识别及活性预测弥补了传统实验的不足,具有高效低耗的特点,被认为是研究化合物作用靶点与其生物活性的有效手段。近年来,越来越多关于药物与靶点相互作用关系预测的模型被报道,这些模型大多数是判断药物与靶点之间是否存在相互作用关系,不能进行活性预测,只有少数模型用于预测药物与靶点之间的定量关系,这些定量模型预测性能较差且只是针对少量靶点,即模型的准确性和适用范围还需要进一步提高。因此建立预测性能高与适用范围广的药物与靶点相互作用关系的定量预测模型是研究中药化学成分潜在作用靶点及活性预测亟待解决的问题。目的:本文旨在构建预测性能高及适用范围广的药物靶点定量预测模型,弥补当前采用实验手段确定药物潜在作用靶点及生物活性所带来的不足之处,提高当前药物靶点定量预测模型的预测性能及适用范围,以期为阐明中药的物质基础及作用机制提供一定的线索与指导。方法:(1)药物与靶点相互作用定量关系数据库的考察。从数据的可靠性,准确性,完备性,可获得性以及适用性五个方面对已有的药物与靶点相互作用关系数据库进行考察。数据的可靠性主要是考察数据的来源,准确性主要考察数据库收录数据的标准(主要是活性值的单位)是否一致,完备性主要考察数据库对当前药物与靶点相互作用关系的覆盖程度,可获得性主要考察数据获得的难易程度,适用性主要考察数据信息是否完善。最终,基于这五个方面确定本文的最佳数据源。(2)药物与靶点定量预测模型的构建。①根据收集的药物与靶点相互作用关系数据,计算化合物的分子描述符及靶点的序列描述符,从分子振动的角度对化合物的描述符进行筛选得到化合物的特征描述符子集,最后整合为药物靶点定量关系数据集。②对数据集进行数据预处理,包括数据的清理,集成,变换,规约。数据清理是指清除异常值,数据集成是指对收集的数据进行整合,数据变换是指将数据转化成适用于建模的形式,数据规约是指对数据进行归一化处理。③特征筛选及模型构建,采用“Boruta”程序包进行特征筛选构建数据集的特征子集,分别采用随机森林,支持向量机,人工神经网络三种机器学习算法进行药物靶点定量预测模型的构建。通过交叉验证的方法对模型的稳定性及预测性能进行验证,采用构建的模型对训练集和测试集分别进行预测,计算实验测得的值(真实值)和预测值之间的差值以及差值绝对值,分析训练集和测试集在每一差值范围内的样本量分布。绘制真实值与预测值的散点图,计算决定系数(R2)和均方误差(MSE)等回归模型的评价指标筛选最优模型。(3)通过与已报道的模型进行比较,判断本文所构建模型的准确性及适用范围。(4)最优预测模型在中药化学成分作用靶点识别及活性预测中的应用。收集Binding DB数据库中未参与本文模型建立的中药化学成分与靶点之间的定量关系,依据数据考察原则对数据进行收集整理获得新的数据集,采用已获得的最优模型对新的数据集进行预测,将预测值与真实值进行比较证明最优预测模型的准确性及适用性。结果:(1)选用ChEMBL数据库中的药物靶点定量关系数据作为本文的数据源。(2)建立了6个分别由EC50和KD值量化的药物靶点相互作用定量预测模型。基于本文收集的数据集分别建立了由EC50和KD值量化的药物与靶点相互作用关系的定量预测模型,涉及2207个化合物和1254个靶点共计21999条关系。从分子振动角度筛选出813个描述符表示化合物的特征子集。①采用随机森林算法构建的模型在训练集和测试集上具有良好的预测性能,EC50值量化的模型R2均大于0.96,MSE小于0.09;KD值量化的模型R2均大于0.94,MSE小于0.12;②采用支持向量机算法构建的模型在训练集上的预测性能优于测试集,EC50值量化的模型在训练集上的R2=0.9317,MSE=0.1270,测试集R2=0.5759,MSE=0.8356;KD值量化的模型在训练集上的R2=0.9099,MSE=0.1254,测试集R2=0.5083,MSE=0.7290;③采用人工神经网络算法构建的模型在训练集的预测性能也优于测试集,EC50值量化的模型在训练集的R2=0.7350,MSE=0.4867,测试集R2=0.5211,MSE=0.9590;KD值量化的模型在训练集上的R2=0.5857,MSE=0.5612,测试集R2=0.2961,MSE=1.019。比较数据集在每一差值绝对值范围内分布的样本量及上述回归模型的评价指标,随机森林算法构建的定量预测模型预测性能最好。(3)采用相同的模型评价指标与文献已报道的模型进行比较,结果表明本文构建的最优模型具有更高的预测准确性及适用范围。(4)采用本文构建的最优预测模型对Binding DB数据库中已有的但没有参与本文模型构建的中药化学成分与靶点的定量关系进行预测,结果表明本文预测的药物靶点相互作用关系与实验测量结果一致。在活性预测方面,实验测量的预测值均大于真实值,但是它们之间的差值集中在某一范围内。出现这种系统误差的原因可能是由于数据收集的来源不同,Binding DB数据库与ChEMBL数据库中的数据收入标准有所差异。可以通过设置校正因子来消除系统误差,校正因子可以由所有差值的平均值来表示。这也在一定程度上证明了本文建立的定量预测模型在中药化学成分作用靶点及活性预测方面的适用性。结论:本文首次提出了从分子振动的角度筛选化合物的分子描述符。成功建立了药物与靶点相互作用关系的定量预测模型。通过回归模型评价指标确定了随机森林算法构建的药物靶点定量预测模型为最优预测模型即模型具有更好的预测性能,支持向量机算法构建的药物靶点定量预测模型可能存在过拟合,人工神经网络算法构建的药物靶点定量预测模型可能存在欠拟合。通过比较,本文建立的最优模型的预测性能及适用范围均优于文献已经报道的最优模型。最终,在最优模型的基础上,对Binding DB数据库中的部分中药化学成分与靶点相互作用关系进行了定量预测,结果表明本文构建的药物与靶点相互作用关系定量预测模型在中药化学成分作用靶点及活性预测中的适用性,证明了从分子振动角度确定化合物描述符的客观性。"
1731,命名实体识别在中药名词和方剂名词识别中的比较研究,"背景:命名实体(Named Entity)是指语言中的专有名词,如地点名词、机构名词等。而命名实体识别(Named Entity Recognition)是用于识别文本中出现的专有名词,并依照专有名词的类别进行区分。以往研究中,命名实体识别多用于识别地点名词、人名、组织结构名词等相对常见的专有名词,而用于识别中药名词和方剂名词的研究相对较少。但是,利用命名实体识别技术识别中药名词和方剂名词具有潜在的研究价值。例如,中医药领域的研究人员可以借助此技术识别文本中的中药名词和方剂名词,以加快中医药相关文本阅读、中药名词和方剂名词搜索速度。此外,此技术可以作为信息抽取(Information Extraction)流程中的初始步骤,以丰富信息抽取技术可以处理的信息种类。目前,训练神经网络模型是实现命名实体识别的常用方法。而利用分词工具配合关键匹配也能够实现命名实体识别,但是未见报道此方法被用来识别中药名词和方剂名词,也没有报道比较这种方法和训练神经网络模型在识别中药名词和方剂名词的表现。目的:首先,采用中文分词工具配合关键词匹配的方法实现中药名词和方剂名词命名实体识别;之后,训练能够识别这两种名词的神经网络模型;最后,比较这两种识别中药名词和方剂名词方法的表现。方法:通过比较中文分词工具配合关键词匹配和神经网络模型识别相同文本中的中药名词和方剂名词的精确率、召回率和F1值,明确这两种方法的优劣。所使用的文本取自中医药教材。采用中文分词工具配合关键词匹配识别中药名词和方剂名词命名实体识别时,分词阶段由现有的分词工具完成,而识别阶段通过匹配分词结果中的词条和预先收集的中药词典和方剂词典中的词条实现。比较当前较流行的三个分词工具,“结巴”中文分词工具、清华大学THU Lexical Analyzer for Chinese(THULAC)分词工具和北京大学pkuseg分词工具,配合关键词匹配识别中药名词和方剂名词的表现,并优化三者中表现最优的分词工具。以优化后的分词工具配合关键词匹配识别此文本中中药名词和方剂名词的表现作为分词工具配合关键词匹配的最优表现。之后,训练能够识别中药名词和方剂名词的双向长短期记忆(Bi-directional Long Short-Term Memory)神经网络模型以及双向长短期记忆-条件随机场(Bi-directional Long Short-Term Memory with Conditional Random Field)神经网络模型,同时比较两种神经网络模型识别中药名词和方剂名词的表现。并选择其中表现较好的神经网络模型识别文本中的中药名词和方剂名词,以其识别的精确率、召回率和F1值作为神经网络模型能够达到的最好识别效果。最后,比较这两种方法识别相同文本中的中药名词和方剂名词的精确率、召回率和F1值,明确其中识别表现较好的方法并分析比较它们的优点和缺点。结果及结论:“结巴”中文分词工具、清华大学THULAC分词工具和北京大学pkuseg分词工具相比较,“结巴”分词工具配合关键词匹配识别中药名词和方剂名词的表现最好。并且,“结巴”分词工具在载入包含中药词条和方剂词条的自定义词典后,其表现可以进一步提高。BLSTM神经网络模型和BLSTM-CRF神经网络模型相比较,后者的识别效果较好。最后,比较“结巴”分词工具配合关键词匹配和BLSTM-CRF神经网络模型识别相同中医药领域文本中的中药名词和方剂名词的精确率、召回率和F1值的结果说明:前者的识别能力高于后者。此外,通过分词工具配合关键词匹配识别中药名词和方剂名词的实现过程相对简单。但是,此方法的识别表现依赖于关键词词典的完备性,并且无法解决歧义问题。与之相比,通过训练神经网络模型识别中药名词和方剂名词的实现过程相对复杂,需要较长的调试周期。但是,此方法的识别表现完全不依赖于词典,而且具备解决歧义问题的能力。"
1732,基于深度学习技术的ECG自动分类算法研究,"心血管疾病是导致死亡率较高的疾病之一,而心电图(Electrocardiogram,ECG)作为一种有效的非侵入式诊断工具,通常被用于筛查和诊断心血管疾病。然而,由于动态心电图数据量大,以及医学专家人员有限,因此造成医生诊断任务非常繁重。使用计算机辅助心电图分析工具可以大大减轻医生的工作量,并提高心血管疾病的筛查和诊断效率。本文旨在结合心电数据的时间序列特征,建立基于深度学习技术的心电数据自动分类模型,本文主要研究内容如下:(1)针对ECG中存在噪声,导致特征提取困难等问题,本文采用小波变换算法对ECG信号进行降噪处理。论文根据ECG数据的特性,采用Daubechies6(db6)小波函数将ECG信号分解为8层,在此基础上,根据噪声系数,设定合理的阈值进行降噪处理,最后重构阈值处理后的各层小波,得到降噪后的ECG信号。实验结果表明,小波变换有很好的降噪效果。(2)针对传统机器学习算法严重依赖手动提取特征的问题,本文对深度学习技术中的卷积神经网络模型进行优化改进,设计了一个高效的卷积神经网络E-CNN(Efficient convolutional neural network)用于单导联ECG自动分类。E-CNN能够从同一输入中提取ECG数据的多级特征,可以高效的获得ECG数据的内部结构特征表示。实验结果表明,E-CNN在ECG分类中获得了良好的分类性能。(3)针对二维结构的多导联心电图,本文提出了一个多通道卷积神经网络MC-CNN(Multi-channel convolutional neural network)。MC-CNN模型将多导联ECG数据中的每个导联输入到不同通道中自动提取特征,MC-CNN模型多通道的设计不仅保证了导联之间数据的独立性,还能够使每个导联找到适合自己的滤波器,进而提取高质量的ECG特征。实验结果表明,MC-CNN模型在多导联心电图自动分类方面具有很大的优势。本文结合心电数据的特点,设计了两种基于深度学习技术的心电自动分类模型E-CNN和MC-CNN,分别在MIT-BIH心律不齐数据集和PTB心肌梗塞数据集上进行了验证。实验表明,本文提出的模型不仅解决了手动提取特征的问题,还能够提取高质量的ECG特征,都获得了不错的ECG自动分类结果。"
1733,基于冠状动脉CT血管成像的血流储备分数在心肌桥的应用研究,"第一部分 基于冠状动脉CT血管成像的血流储备分数对心肌桥病变特异性缺血诊断性能的研究目的:以有创性血流储备分数(fractional flow reserve,FFR)为诊断标准,评估基于冠状动脉CT血管成像(coronary CT angiography,CCTA)的FFR(CT-FFR)对心肌桥患者病变特异性缺血的诊断性能。方法:数据来自于中国CT-FFR多中心研究,其中8个研究中心回顾性搜集2015年5月至2018年6月行CCTA示左冠状动脉前降支心肌桥,且60天内行有创性冠状动脉造影(invasive coronary angiography,ICA)和有创性FFR检查的患者。在CCTA图像上测量心肌桥的位置、长度、深度、肌肉指数和狭窄程度。根据心肌桥的深度将其分为表浅组(≤2mm)和纵深组(>2mm),根据心肌桥的长度将其分为短心肌桥组(≤30mm)和长心肌桥组(>30mm)。根据ICA记录的心肌桥前端病变最严重处管腔狭窄程度将所有的心肌桥血管分为0.05)。50%-69%狭窄组的阳性预测值低于≥70%狭窄组[分别为 0.59(0.33-0.81)、0.97(0.84-1.00),P<0.001);舒张期对照组CT-FFR为0.93(0.90-0.94),表浅组为0.84(0.69-0.92),纵深组为0.82(0.68-0.90),差异具有统计学意义(P"
1734,基于改进支持向量机的脑胶质瘤影像分级研究,"影像组学是计算机医疗的重点科研方向,受到全世界政府、医院、高校的重视。影像组学的重点研究领域为癌症和肿瘤,脑胶质瘤是目前肿瘤精确诊断中存在较大难度的肿瘤病症之一,目前缺乏有效的影像识别方法对脑胶质瘤进行精确地分级评估。影像组学通过影像获取,肿瘤分割,特征提取,数据分析等步骤实现对肿瘤的分级预测。本文使用影像组学方法对脑胶质瘤进行分级预测研究。本文获取了两组脑胶质瘤影像数据,BRATS2017脑胶质瘤数据285例和河南省人民医院放射科脑胶质瘤数据161例,分别验证本文中的方法在科研方面的效果和临床应用方面的效果。所有影像由放射科医师手动分割,使用特征提取算法对肿瘤影像提取特征,共提取了包括强度、形状、纹理、小波等特征共357种。针对提取的特征,本文使用最小冗余最大相关性准则(mRMR)进行特征选择,并根据不同的特征选择数量使用LIBSVM和HLSVM算法进行训练和预测,结果显示使用mRMR选择的100个特征为最优特征子集。使用最优特征子集进一步实验,使用多种机器学习评价指标进行评估,并绘制出ROC曲线,结果显示HLSVM比LIBSVM在脑胶质瘤数据集上有更好的训练精度和更快的预测速度。使用十折交叉验证方法对最优特征子集进行实验,结果显示在训练精度和预测精度相差不大的情况下,HLSVM的速度比LIBSVM的速度大约快了一个数量级。根据两个数据集的实验对比,BRATS2017数据集是经过多个医疗机构和专家挑选的,影像清晰,分辨率高,肿瘤分割精准,与河南省人民医院的数据集相比具有更好的实验结果,但不具有广泛性。而河南省人民医院的实验结果显示使用两个分类算法的十折交叉验证平均预测精度分别为83.8235%和80.1102%,具有临床代表意义。分析实验结果后发现数据集存在数据不平衡问题,同时使用的支持向量机算法还有待提高,因此本文使用自适应合成采样算法对数据集进行过采样处理,并提出动态惩罚支持向量机,将两种算法相结合后的自适应动态惩罚支持向量机对脑胶质瘤进行分级预测,并取得了较好的实验结果,同时使用LIBSVM、HLSVM、DEC和FSVM进行对比实验。结果表明,该算法能够有效的提高不平衡数据集中少数类样本的预测精确度,同时大幅降低误诊率,G-mean指标显示该算法能有效处理脑胶质瘤数据不平衡问题。本文中所提出的分类预测算法和建立的预测模型对影像组学和临床医学有着重要的现实意义。"
1735,基于DNA甲基化不平衡数据的胃癌分类模型研究,"胃癌的发病率在我国各类癌症中居首位,胃癌早期无明显症状,不易被发现。因此,早期胃癌的筛查对其及时治疗有着重要的临床价值。目前,胃癌的分类研究大多基于病理学图像,这种方法主要依靠主治医师的临床经验判断,准确率低。为了克服胃癌诊断在形态学和影像学方法上存在的缺陷,本文提出了一种基于DNA甲基化测序数据的胃癌分类方案,实现了对早期胃癌的精准分类。本论文针对癌症和肿瘤基因图谱(The Cancer Genome Atlas,TCGA)中DNA甲基化测序数据不平衡和高噪声现象,提出了一种基于合成少数类过采样技术(Synthetic Minority Oversampling Technique,SMOTE)和Tomek Link算法的集成混合采样模型,有效地解决了数据不平衡问题;其次,为了解决DNA甲基化测序数据样本小和高维度问题,本文采用十折交叉验证划分训练集和测试集,然后利用最小冗余最大相关(mRMR)方法对训练集数据进行特征选择,筛选出122个相关性最大的特征;最后,针对小样本数据集分类中end-2-end模型训练模式容易产生过拟合现象,本文采用pre-trained模型提取特征,再训练其他分类器的方法,涉及到的训练参数少,降低了模型的过拟合风险。本论文使用卷积神经网络(Convolutional Neural Network,CNN)训练pre-trained模型,其后将输出特征送入支持向量机(Support Vector Machine,SVM)、改进的深度森林(Deep Forest,DF)和随机森林(Random Forest,RF)三种分类器进行模型训练,得到最终的分类结果。实验结果表明,本文提出的基于DNA甲基化不平衡数据的胃癌分类模型在TCGA数据库上获得了98.5%的准确率,在本校药学院提供的自建数据库上获得了96%的准确率,具有较好的泛化能力。相较于目前研究中最好的分类模型,本文提出的模型准确率提高了5%以上。"
1736,基于卷积神经网络的乳腺肿瘤良恶性分类方法研究,"乳腺癌已经成为对女性健康产生重大影响的疾病之一,随着生活压力的增大以及环境恶化的因素影响,成年女性患上乳腺癌的机率也在逐渐增加。乳腺钼靶X线摄影是检测乳腺癌重要的手段,影像科医生可以通过阅读乳腺钼靶图像,初步判断乳腺是否发生病变,但这种早期筛查主要依靠的医生自身的先验知识和主观判断,很容易会出现漏诊,误诊的情况,因此要想提升乳腺癌的防治的关键是提高医生阅片速度和效率,实现双重阅片,减少因医生个人经验所造成的漏诊和误诊的现象。计算机辅助和诊断系统为影像科医师在检测病变和诊断病变时提供辅助意见,提高影像科医师的工作效率,进而提升乳腺癌的早期筛查和防治。传统的机器学习辅助诊断和深度学习辅诊断是目前计算机辅助诊断的两种技术路线。机器学习主要依靠手工先对影像数据进行特征提取,利用提取的特征进行模型训练,过程费时费力且存在不稳定性。基于深度学习的辅助诊断技术能自动提取特征,不存在因医生的先验知识差异而导致的特征不稳定性。本文对乳腺肿瘤良性恶性分类的研究,主要做了以下的研究工作:(1)本文对钼靶数据进行了分割和去中心化等预处理。本研究针对钼靶图像尺寸过大且只有小部分面积是乳腺组织,大部分都是与实验目标无关的背景图像,采用了阈值分割的技术将图像的背景和乳腺组织分割出来,并重新定义了尺寸,使图像与模型的需要尺寸相接近,降低模型的复杂度。本实验的数据是基于两个公开数据集DDSM和INbreast,这两个数据集的图像采集数据机器和采集参数都是不相同的,这就会导致图像的对比度,格式,大小等参数是不一致的,导致生成多中心数据,多中心数据会严重影响分类实验结果的精度,本文采用直方图的规定化来对多中心数据进行去中心化。经过本文所提出的预处理方法,实验结果提升了将近10%,使用残差网络(Residual Net,ResNet)模型进行训练,模型结果的准确度高达81.6%。(2)乳腺肿瘤的良恶性分类。本文选取ResNet作为本次实验的模型,为优化模型,提升实验结果,对ResNet模型进行了修改,并分别对修改后的模型命名为ResNet-B,ResNet-C和ResNet-D。本文还使用SVM分类器来替换模型原本的softmax分类器,使用迁移学习的方法来进行模型参数的初始化。最终基于改进后的三个模型分类的准确度分别为89.8%,90.2%,91.4%。"
1737,基于影像组学的胰腺肿瘤精准分类方法研究,"胰腺导管腺癌(PDAC)和胰腺神经内分泌肿瘤(PNET)是最常见的两种胰腺肿瘤,非功能性神经内分泌肿瘤(NF-pNET)约占所有pNET的80%。NFpNET显示各种非典型的临床表征,它们与PDAC临床表征非常相似,很可能被误认为是PDAC诊断的典型影像学征象,因而非典型NF-pNET很容易误判为PDAC,精准分类成为临床难题。由于非典型NF-pNET与PDAC的治疗策略和预后存在显着差异,因此非典型NF-pNET与PDAC的精准分类是临床实践中的一个重要问题。数据来源于北京协和医院,包括80例PDAC和67例非典型NF-pNET,数据类型为电子计算机断层扫描(CT)影像及临床病理信息。目前,临床上还没有找到较好的方法来进行非典型NF-pNET与PDAC精准分类。本文提出一种新的解决思路,基于影像组学方法,并结合机器学习算法来进行胰腺肿瘤精准分类方法的研究。本研究从CT影像中提取大量高维的影像组学特征,并采用逻辑回归(LR)、支持向量机(SVM)和随机森林(RF)算法来构建非典型NF-pNET与PDAC精准分类模型。我们构建了影像组学特征加临床信息的综合分类模型,并实现了对非典型NF-pNET与PDAC的精准分类。本研究共构建了5个分类模型,并进行了分类模型之间的对比,选取最好的模型作为我们最终的精准分类模型。在独立的测试集,基于逻辑回归的临床信息加影像组学特征综合分类模型的AUC为0.884,与临床信息模型(AUC:0.775)相比性能显著改善,AUC提升了11%;且两者之间存在显著性差异(p=0.018,<0.05),p值也说明了我们提出的综合模型相比于医生提供的临床信息模型,性能显著提高。另外,测试集中综合模型的分类准确率(ACC)为80.4%,敏感度(Sensitivity)为80.0%,特异度(Specificity)为80.8%,阳性预测值(PPV)为76.2%,阴性预测值(NPV)为84.0%。本文也设计了诺模图(Nomograph),在训练集和测试集中有良好的分类性能,C-index分别为0.960和0.884。最后,校准曲线(Calibration)显示分类模型有较高的稳定性。"
1738,基于机器学习的司法案例筛选系统设计与实现,"司法文本逻辑严谨,结构清晰明确,适合采用计算机进行分析和处理。依托于近年来司法公开的相关政策,可用的司法语料大幅度增长,为机器学习方法在司法领域的应用提供了数据支撑。为了帮助司法从业者进行快速地案例检索,同时为民众法律询提供辅助工具,本文研究并设计实现司法案例筛选系统。这一系统的核心功能是对获取的文本进行分析,并从数据库内备选的海量裁判文书中筛选出相似案例供用户参考,同时包含裁判文书分析等辅助功能。文章的主要工作是将机器学习及相关自然语言处理技术引入司法领域内。首先,本文对系统所属的司法智能领域进行了研究现状介绍。进一步,介绍了分词技术、文本关键词提取算法TF-IDF、文本分类技术fastText及web应用框架技术Django等与本文系统构建相关的技术,并完成系统设计及实现。本文拟通过机器学习技术fastText对文本进行分类,进一步依据文本分类得到的标签结果进行相似案例筛选。系统的总体设计分为四部分,包括文件上传模块、文本输入模块、裁判文书分析模块和案例筛选模块。主要完成的工作如下:采用Django框架实现裁判文书上传模块和文本输入模块,用于实现与用户之间的交互,为整个系统的获取需要分析的文本。采用关键字匹配和TF-IDF算法抽取文本关键信息,实现对上传裁判文书的分析工作,帮助用户快速理解裁判文书。采用fastText框架训练多个机器学习模型,用于对输入文本进行分类;进一步实现依据分类标签及文本相似度的筛选和排序,最后展示筛选结果并提供下载等辅助功能。司法案例筛选系统最终以web应用的形式运行良好。用户可以通过浏览器访问这一系统,进行文本输入、裁判文书上传和分析,并依据输入的文本进行相似案例的筛选。经实验,系统裁判文书解析正确率达到86%,案例筛选相关率达到81%,具有一定实用性。"
1739,基于支持向量机的股指期货交易策略研究,"股指期货可以“反向交易”,既可做多,也可做空,具有价格发现、套期保值等多种功能。同时,股指期货交易具有高杠杆性,风险巨大,因此能否对股指期货的价格运行趋势进行大概率准确的预测对实战成功具有现实指导意义。对于金融数据的预测,传统预测方法包括基本面分析、技术分析以及时间序列分析等。但是,面对非线性的金融数据,这些方法存在着各种各样的局限,预测效果也不是很理想。随着统计学理论、数据挖掘以及人工智能技术的发展,更多的机器学习方法被应用到金融数据领域,并且取得了不错的效果。支持向量机作为近年来机器学习领域的研究热点,由结构风险最小化的统计理论发展而来,具有较强的泛化能力。由于支持向量机在预测小样本、非线性数据具有一定的优势,于是,本文建立了基于支持向量机的股指期货价格分类预测模型,并在此基础上构建了相应的交易策略。本文以我国上证50股指期货为研究对象,将期货价格的未来趋势划分为涨、跌两种,通过历史交易数据来预测未来交易价格的涨跌情况。具体过程如下:(1)基于鞅理论利用历史数据找出收盘价的异常值,即“离群点”数据,对样本进行筛选,从而实现数据的清洗。(2)选择影响期货价格的相关指标时,本文选择了7个基本行情指标和18个技术指标。为统一指标的量纲,采用最大-最小值标准化法对数据进行归一化。另外,为避免指标之间的信息重叠,采用主成分分析法对数据进行降维处理。(3)为提高分类预测模型的精度,本文采用了网格搜索、遗传算法和粒子群算法,对支持向量机的两个参数进行寻优,从而建立分类预测模型。(4)利用训练集得到的模型对测试集样本进行预测,发现基于粒子群算法的支持向量机分类预测模型的预测效果最好,价格预测的准确率达到62%。基于上述做法,本文利用最优的分类预测模型,建立初步的股指期货交易策略。通过回测实验计算交易策略的各项指标数据,验证了基于支持向量机的交易策略具有68.29%的获胜率,并且收益率跑赢同期大盘。"
1740,中美iSchools院校大数据相关专业人才培养方案的调查及思考,"面向大数据的图书情报教育变革是当下我国图书情报教育研究中一直被学者们关注的热点,而美国iSchools院校领跑大数据专业教育,这对于我国院校面向大数据的图书情报教育变革具有较高的指导价值。本文选取美国iSchools院校为研究对象,调查分析18所美国iSchools院校的培养目标、培养内容及课程设置等方面,然后对比我国iSchools院校人才培养内容、课程设置等相关情况,找出其优势与可取之处,从而为我国高校面向大数据的图书情报教育变革提供参考意见。本论文共分为五个部分:第一部分引言,主要介绍本论文的选题背景、研究意义及国内外研究现状和论文的研究方法、研究内容及创新之处。第二部分是调查18所美国iSchools院校大数据专业人才培养方案并对其培养目标、培养内容、培养形式等方面进行详细分析。第三部分调查我国iSchools院校大数据专业人才培养情况并对其培养内容、课程设置等方面进行分析。第四部分对前文调查的中美iSchools院校的大数据专业人才培养情况进行比较,并在分析面向大数据方向的图书情报教育变革的重要性的基础上,针对国内面向大数据的图书情报教育变革提出建议。第五部分结语是对本文研究的总结,笔者对全文做了总结,指出了本论文存在的不足与改进方向,并对未来的研究重点做出展望。"
1741,基于改进随机森林的硬盘故障预测方法研究,"随着工业物联网、云存储、云计算、大数据等新兴信息技术的出现和迅猛发展,全球数据总量呈现指数级的增长,全球接近90%的数据存储在数据中心的硬盘中。由于硬盘自身结构和数据存储机制,硬盘一旦出现故障,硬盘中存储的数据可能永久丢失,给企业和个人带来严重的损失。虽然数据的冗余备份机制可以预防硬盘故障时数据的丢失,但是增加了数据存储的成本,对硬盘进行故障预测成为目前最主流的方法。硬盘的S.M.A.R.T.(Self-Monitoring,Analysis and Reporting Technology)技术和数据中心运维技术的发展,为硬盘的故障预测奠定了基础。目前,几乎所有的硬盘都支持S.M.A.R.T.技术,这为硬盘的故障预测提供了数据基础,同时数据中心的运维方式正由自动化运维向基于机器学习方法的智能化运维方向转变,使用机器学习方法进行硬盘故障预测,可以提高硬盘故障预测的准确率,保障数据存储的安全可靠。本文分析了真实数据中心场景下硬盘S.M.A.R.T.数据的特点,同时选择使用改进随机森林算法建立故障预测模型,对硬盘故障进行预测。本文的主要研究工作包括:(1)针对真实数据中心场景下,硬盘S.M.A.R.T.数据多维的特点,提出了基于相关系数的数据降维方法。通过计算不同S.M.A.R.T.属性间的相关系数,选择一个属性来代替其它与其强相关的属性,对硬盘S.M.A.R.T.数据进行降维。(2)针对真实数据中心场景下,硬盘S.M.A.R.T.数据中正常和故障样本数量不均衡的问题,以及传统随机森林算法在处理不均衡数据的缺点,使用改进的SMOTE算法对数据进行平衡化处理。(3)对传统随机森林模型进行优化,包括增加决策树的剪枝操作,决策树的选择和分配决策树的权重,进一步提高模型预测的准确率和效率。(4)针对真实数据中心场景下,硬盘S.M.A.R.T.数据具有的时序性,提出增量学习的策略。通过增量学习策略,利用新增数据更新模型,保障硬盘故障预测模型具有持久的学习能力。"
1742,基于集成学习的个人信贷决策模型的设计与实现,"随着我国市场经济体制的不断完善,越来越多的个人逐渐接纳个人信贷这种消费模式,个人信贷在银行贷款业务中所占的份额也不断上升。但是由于个人信用的缺失,个人信贷的风险也逐渐凸显。个人信贷违约对银行信贷业务造成了严重的冲击,成为银行迅速发展壮大的阻碍。如何有效的预测借贷人是否能够如期还款对于商业银行具有重要的意义。本文通过分析个人信贷业务的需求,结合现有系统开发工具,设计并实现了以集成学习算法为基础的个人信贷决策系统。本文设计实现的个人信贷决策系统包括个人信贷评估模块、数据库模块和系统管理界面三个部分。其中个人信贷评估模块采用当前主流的集成学习算法,使用支持向量机、随机森林、XGBoost、Light GBM四个模型作为基学习器,通过相对多数投票的方式进行模型融合,得到个人信贷决策模型,该模块同时完成客户信用指标的提取、数据预处理、标准化等数据处理操作,最后使用面向对象的设计方式对个人信贷决策模型进行封装,对外提供统一的调用接口。数据库模块主要包括员工信息表、客户信息表、模型预测结果存储表、模型超参数调优表的设计。系统操作界面采用基于C/S架构的Java Swing技术为个人信贷决策系统的使用和管理提供接口,包括对系统用户的管理和权限验证、客户资料管理和更新、评估结果的查询等。最后对所设计实现的个人信贷决策系统在模拟环境下进行了测试和验证,结果表明所设计的系统各项功能均能达到预期效果,系统的预测准确率较高,可为人工审核提供参考依据。"
1743,深度学习在软件开发环境提升中的研究,"现有的软件开发环境主要是集成开发环境(IDE),如Eclipse,Intellj和Visual Studio。软件开发环境的优劣很大程度上取决于它对程序员给出的提示的准确率,现有的方法主要是使用概率模型或者上下文无关文法来实现的,本文主要集中在使用上下文无关文法与深度学习相结合的方法来提高软件开发环境在代码提示和语法错误提示两个任务上的准确率。本文的主要贡献有两方面:1.代码提示是软件开发环境的重要功能,它会对程序的下一个token给出提示。为了实现代码提示的功能,主要使用语言模型来预测下一个token的概率。这些语言模型原本是为了在自然语言处理任务中基于前文预测后一个token而设计的,然而却并不完全适用于程序设计语言。在程序设计语言中所有自定义的标识符的含义都是由它的上下文定义的,标识符的名字只是用来区分不同的标识符,这与自然语言中token的含义主要是由token的名字决定的情况有比较大的不同,所以这些语言模型只使用token的名字来输入就有些不适用了;另一方面程序设计语言的语法有着明确而清晰的定义,这与自然语言中语法无法完整定义的情况也是不同的,所以现有的语言模型可能会预测出不符合语法的token的情况是可以避免的。因此本文提出了基于语法的语言模型,在从Codeforces中爬取的C99数据集上获得了74.23%的Top-1准确率,比之前的主要语言模型准确率都高。2.语法错误的提示是软件开发环境的重要功能,它的提示是基于编译器的出错信息生成的,然而编译器的出错信息是通过上下文无关文法或者概率上下文无关文法实现的,这些方法的提示是基于终结字符的,所以它们无法提示出具体的token。同时现有的机器学习方法在语法错误提示任务上的准确率很低,本文提出了利用上下文无关文法的端到端模型的语法错误提示模型,在DeepFix的数据集上获得了56.97%的准确率,远高于DeepFix的33.36%,证明了将上下文无关文法和深度学习相结合的方法可以显著的提高准确率。"
1744,面向服务的一站式机器学习算法系统的设计与实现,"随着机器学习技术的发展,机器学习算法模型在工业界中被运用的频率越来越高,使用范围越来越广泛。但新技术的出现往往会带来问题和挑战,在菜鸟网络科技有限公司应用机器学习技术时遇到了两个比较棘手的问题:一个是机器学习模型使用门槛高,即使是对小规模需求建模也需要资深算法工程师的参与,导致模型开发成本大;另一个是机器学习模型与传统软件系统紧耦合,这会导致系统的可拓展性差,每一次模型线上化都需要对原有系统代码造成较大入侵。针对上述难题,本文设计并实现了一个面向服务的一站式机器学习算法系统。该系统提供从数据采集到模型线上化的一站式服务,旨在让只具有基础机器学习知识背景的普通开发人员也可以根据业务熟练地开展常见机器学习模型的建模工作,从而降低机器学习模型使用门槛,最终降低算法模型开发成本。除此之外,系统将模型线上化的过程与面向服务的思想结合起来,使得机器学习模型与业务系统解耦,提高了新增模型的可拓展性。本系统采用模块化的思想进行设计,主要拥有五个核心模块:数据采集存储模块,该模块主要负责训练数据的存取,它将不同的数据源存取方式封装起来,对外提供统一的数据存取API。模型解析模块,该模块主要负责处理前端传输过来的模型描述,将模型描述转化为系统当中的计算图对象。数据预处理模块,该模块主要接收源数据信息,然后对源数据进行清洗和标准化工作,随后执行特征工程工作。算法引擎模块,该模块基于Tensorflow框架实现算法库中各个算法,默认采用参数服务器的方式对模型进行分布式训练。最后是算法服务模块,该模块主要负责将训练好的模型加入到系统所提供的模型服务当中。目前,系统已在生产环境中稳定使用,相较系统投入生产环境前,缩减了模型开发与线上化成本,通过系统所创建的模型的正确率能够达到业务标准,每月上线的模型数量也稳定增长,达到系统开发的预期目标。"
1745,基于机器学习的显著目标检测,"人眼能够从复杂的场景中快速而准确地找到与众不同的目标或者区域,此即人眼的视觉注意机制。显著目标检测基于视觉机制,旨在利用计算机模拟人眼的视觉机制功能,通过算法找出图像中最显著的目标。作为一个视觉任务的预处理过程,在其他的计算机视觉,模式识别任务中发挥了巨大的作用,比如图像分割,图像压缩,视觉追踪,场景重建等。目前图像显著检测主要分为两个部分,单幅图像显著目标检测和协同图像显著目标检测,单幅图像显著目标检测旨在检测单幅图像中的显著目标,而协同图像显著目标检测旨在检测一组图像集中的共同显著目标。随着Depth信息的广泛应用,Depth信息被证明在显著目标检测领域是十分实用的特征,因此显著目标检测的对象也从RGB图像逐渐扩展到RGB-D图像。因此单幅图像显著目标检测可以分为RGB图像显著目标检测和RGB-D图像显著目标检测,而协同图像显著目标检测可以分RGB协同图像目标检测和RGB-D协同图像目标检测。本文主要研究RGB协同图像目标检测和RGB-D显著目标检测。在现有RGB协同图像显著目标检测中,没有真正做到将一组图像作为整体考虑,从而难以获取好的协同一致性,并且会包含许多协同背景。目前RGB-D显著目标检测需要解决的问题有两个,一是设计Depth特征,二是有效地结合RGB特征和Depth特征。传统的模型通过手工设计特征,虽然能够取得一定的效果,但是泛化程度很低,而基于将RGB特征和Depth特征分别处理,然后融合两个流的显著图得到最终的显著图,虽然能够取得一定的成果,但是Depth图如果效果很差或者完全无用的话会对最终结果产生很大的影响。本文提出了一种新的模型来获取协同目标的一致性,并且可以降低在复杂背景下对协同目标的干扰。模型包括一个基于树的结构化稀疏规则化项可以使得相同类中的超像素具有一致性显著值,另外模型整合了一个拉普拉斯约束规则化项可以平滑同一类中超像素的显著值。此外,为了提高模型的有效性和精确度,本文定义了一个协同权值并且融合到模型中,通过矩阵分解,将原始特征空间分解为低秩部分和稀疏部分,稀疏部分为最终的协同显著目标。本文提出的RGB图像协同显著目标检测模型在iCoseg,iCoseg-sub,Image Pair三个公开数据集上与其他当前最新的模型进行了比较,实验结果表明本文模型具有较好的结果。针对RGB-D图像显著目标检测,本文提出了一种以颜色特征为主要线索,Depth特征为辅助特征的单流递归神经网络的显著目标检测模型。首先将RGBD四通道输入VGG-16网络,生成RGB-D图像最原始的多级特征。网络深层特征可以检测和定位显著目标,但会丢失边界和一下细微结构。因此,将深度递归卷积神经网络应用于各层次特征中,实现了从深到浅的层次递进的显著目标轮廓优化。利用Depth特征、原始Depth图像和粗糙显著图,各层次特征可以预测不同尺度下的显著目标。最后将各个层次的显著图融合在一起,得到最终的显著图。本文模型在最广泛使用的NLPR1000,NJU2000,LFSD,STEREO四个RGB-D数据集上对本文提出的RGB-D单流网络显著目标检测模型和当前最新的RGB-D图像显著目标检测模型进行了验证和评估,实验结果表明本文模型取得了较好的结果。本文针对RGB协同显著检测和RGB-D显著目标检测提出了上述两种模型,并且取得了较好的结果,为显著目标检测的研究提供了多种思路,为计算机视觉和模式识别领域研究工作做准备。"
1746,基于主动学习的软件缺陷预测方法研究,"随着软件技术的迅速发展,软件产品的使用渗透到社会的各个方面。因此,软件质量保障对于大型软件项目尤为重要,如果无法及时发现并修复软件中的缺陷,不仅可能会造成巨大的经济损失,甚至会危及人类生命安全。软件缺陷预测技术通过预测软件模块的缺陷倾向性指导质量保障人员合理分配资源,即质量保障人员可以对缺陷倾向较高的模块进行充分测试,从而减少由于对无缺陷模块的测试造成的资源浪费。然而,缺陷预测模型的构造需要大量质量可靠的训练数据集,如果一个软件项目缺乏有效的训练数据,则很难建立高效的缺陷预测模型。针对缺乏有效训练数据的问题,近年来研究人员提出利用主动学习算法从被测项目中直接选择实例进行标注的方法构建训练集。已有的方法大多基于主动学习的不确定性采样策略选择实例,但是当初始训练集与总体数据分布不一致时,该方法容易导致训练集的分布偏差进一步加强,如果选择标注的实例数不够多,则难以在该训练集上构建正确的预测模型。并且缺陷预测数据集中存在类不平衡问题,在挑选实例的过程中,主动学习方法并未处理由该问题导致的构造训练集中数据分布不均衡的现象,进而导致在该训练集上构建的缺陷预测模型的性能难以得到有效提高。本文提出DAL方法和BDAL方法分别解决上述问题。DAL方法基于双重不确定性采样策略从不同特征子空间中综合评价实例的不确定性,避免在总特征空间中因绝对的单一不确定性造成的采样偏差;BDAL方法则通过合成少数类实例缓解训练集中的类不平衡问题。本文主要贡献总结如下:1.提出了一种基于主动学习的项目内缺陷预测方法DAL。为了解决软件缺陷预测领域中缺乏有效训练数据的问题,本文提出了基于主动学习双重不确定性采样策略的DAL方法,该方法旨在花费最少的标记成本构造较高质量的训练集。本文分别介绍了提出DAL方法的动机和该方法在缺陷预测领域的应用流程,然后通过在AEEEM和Relink数据集上的实证研究验证该方法的有效性,最后总结并分析其优缺点。2.对DAL方法进一步改善提出了BDAL方法。针对缺陷预测数据集中存在的类不平衡问题,本文对DAL方法进一步改善提出了基于FS-BSMOTE过采样策略的BDAL方法。该方法利用特征子集合成少数类实例以缓解训练集中类不平衡问题,可以有效提高缺陷模块的召回率。本文通过在AEEEM数据集上的实证研究验证了BDAL方法对DAL方法的改进性能。"
1747,传统机器学习到深度学习行人检测若干研究,"行人检测技术在智能交通系统、公共安全、机器人等诸多领域有着广泛的应用。然而,由于姿态、穿着、遮挡以及尺度等因素的影响,鲁棒、准确、高效的行人检测仍然是目标检测中的一个经典难题,同时也是计算机视觉的一个研究热点。在过去的研究中,行人检测算法大致分为两类:一类是基于传统机器学习的方法,这类方法主要集中于手工特征的提取、特征分类器的学习和后处理等方面;另一类是基于卷积神经网络的行人检测算法,这类算法主要集中于分类网络的研究。传统机器学习检测方法对硬件要求较低,检测速度较快,但是由于提取的手工特征简单、后处理不完善等原因,在有遮挡或者光照条件差的情况下检测效果大打折扣。深度学习行人检测算法在精度上往往占据优势,但是池化和卷积操作具有降维的特性,会使得卷积特征图分辨率逐步减小,一些小目标的特征到最后可能会完全消失,所以对小目标的检测效果不理想。本文在详细分析了机器学习行人检测的理论基础上,针对上述两类行人检测算法存在的问题分别进行了部分有效改进。主要研究内容如下:(1)为了改善传统机器学习行人检测算法在光照条件恶劣、遮挡严重等环境下不理想的检测效果,本文提出使用kinect深度相机引入深度图,利用多模态数据之间的互补性来丰富特征,有效提升了行人检测的精度,并且制作了目前较为缺乏的RGB-D行人数据集。本文以行人检测算法ACF(Aggregate Channel Features)为基础,在RGB-D Person Database行人数据集上的实验结果表明通过引入深度图检测精度提高了 16%,平均对数漏检率降低了 15.9%。(2)在行人检测方法中,非极大抑制算法作为后处理模块的核心,其算法的优劣对最终的检测效果影响很大。本文通过结合行人检测的特点来改善非极大抑制算法的抑制机制,利用位置和置信度综合判断,对检测框进行重复利用和有效抑制,进一步去除误检并保留正确的检测框。本文在INRIA数据集上进行了多组对比实验,结果显示与经典的贪心非极大抑制算法相比,本文改进的贪心非极大抑制算法抑制精度提高了 18.85%,进一步去除了约870个误检框。(3)本文针对深度学习一阶段目标检测方法中回归精度不高和小目标检测效果差的情况,提出了上采样反向特征融合网络进行改善。在卷积神经网络中低层特征能够有效描述图像的纹理细节,但是感受野较小。相反,在高层特征图上,丰富的语义信息占据主要部分,但是细节信息却所剩无几。本文以目标检测算法SSD(Single Shot MultiBox Detector)为基础,通过上采样反向融合方法将高层特征层与低层特征进行有效融合和激活,使得这些低层特征具有更丰富的语义信息的同时保留了原有的纹理信息,更有利于小目标的检测。本文在VOC Person Dataset行人数据集上进行了实验验证,结果表明本文的算法在SSD检测算法的基础上精度提升了5.97%,小行人目标(小于100像素)的检测精度提升了6.54%。在VOC2007数据库上的检测精度值取得了 74.8%。(4)为了让低层特征能学到更多的细节纹理特征而抑制其他的噪音等无用信息,本文使用了分割监督学习机制,设计了一种分割监督网络来监督低层特征的学习,对比发现这种情况下低层神经网络能学到更丰富的特征信息。在VOC Person Dataset行人数据集上的实验结果表明本文的分割监督机制能进一步将检测精度提高1.95%,小行人目标(小于100像素)的检测精度进一步提升了2.57%。"
1748,基于监控视频的群体行为识别算法研究,"视频监控是保障公共安全的重要手段,对于大量的视频监控设备获得的视频,依靠监控人员来分析识别视频中的行为不仅耗时费力,而且效率不高。群体行为活动作为视频中最常出现的人类行为活动,群体行为识别将拥有着比较广阔的应用价值。通过研究视频图像的分析处理方法,使其能够自动检测和识别视频中的群体行为,能有效预防危险事件的发生,提高监控效果。群体行为不是个体行为的直接叠加,群体行为中个体与个体之间存在交互关系,群体行为难以通过一个确定的模型来描述。它还有场景与个人的关系,个人与群体的关系以及群体与场景的关系。近些年群体行为分析与识别一直被研究学者所关注,但现阶段的群体行为识别仍面临着很多困难和挑战,如复杂背景、运动速度变化、视角变化、光照变化,这导致很少有算法能在提高识别精度的同时具有较好的鲁棒性。本文首先介绍了与群体行为识别相关的机器学习算法,然后分别利用传统的机器学习和深度学习给出了两种相关算法,所提算法在群体行为数据集2(Collective Activity Dataset 2,CAD2)和自建数据集上都取得不错的识别效果,本文主要研究内容如下:(1)介绍了群体行为识别的研究意义,总结了国内外相关学者所做的工作。介绍了几种用于群体行为识别的机器学习算法:支持向量机,卷积神经网络VGGNet以及迁移学习。(2)给出一种结合张量特征和孪生支持向量机的群体行为识别算法。首先通过群成员关节点骨架的姿态结构信息和群成员的社会网络信息描述群体在每一帧中的行为,并采用张量形式表示,然后使用多路非线性特征映射来分解张量核,并利用粒子群优化张量核孪生支持向量机的模型参数,最后结合张量特征和孪生支持向量机实现视频中的群体行为识别。CAD2数据集和自建数据集上的实验结果表明,张量特征能够有效地表示群体行为,相较于经典算法,所提算法能有效提高群体行为识别的准确率。(3)提出一种基于迁移学习双流卷积网络的群体行为识别算法,将用于源域与目标域的迁移学习用于双流卷积神经网络。利用双流卷积网络的空间流网络和时间流网络获取图像深层特征,再将时空特征投影到高维空间,并通过多核最大平均差异使两种不同领域的特征迁移到一起,进而获得同时具有时空特性的特征。通过特征的迁移,网络获得了更加鲁棒的深层特征,所获得的特征不再局限于单一的运动特征或外观特征而具有相互融合相互叠加的效果。实验结果表明,相较于其他基于深度学习算法的群体行为识别,所提算法能有效提高群体行为识别的准确率。"
1749,基于视频的群体异常行为检测算法研究,"群体异常行为检测作为视频监控领域中的关键技术,有着非常重要的研究价值。及时准确地发现人群中发生的异常行为,如人群异常聚集、打架斗殴等,并采取相对应的措施,对维护公共安全、保障人民群众的生命财产具有重要意义。随着机器学习特别是深度学习的快速发展,基于图像的个体异常行为检测技术越来越成熟,但是基于视频的群体异常行为检测技术仍有很多难点亟待解决,如实时性不够好、检测精度低等。本文首先介绍了群体异常检测方面的相关知识,其中包括传统机器学习和深度学习的相关理论,然后在UMN数据集、UCSD数据集、和自建数据集上分别采用了传统机器学习和深度学习的方法来进行视频的群体异常行为检测,并将实验结果与其他算法进行了对比分析。本文的主要工作内容为:1、分别从传统机器学习和深度学习方面介绍了群体异常行为检测的基本理论。在传统机器学习方面介绍了群体异常行为检测流程,重点介绍了稀疏光流法和稠密光流法的基本原理,然后介绍了常用二分类模型支持向量机。在深度学习方面介绍了深度学习相关概念、神经网络的结构及其训练过程,并详细介绍了深度学习模型中的自编码模型和卷积神经网络模型。2、提出一种结合复小波域去噪和粒子群优化孪生支持向量机(PSO-TSVM)的群体异常行为检测算法。首先通过Horn-Schunck光流法提取视频中群体行为的速度、加速度、方向特征和人群密度特征,然后利用非抽样对偶树复小波包变换(NS-DTCWPT)对提取的特征进行多分辨率分解,利用双变量模型去除所提取特征中的噪声。NS-DTCWPT在整个频段实现了更精细的频带划分,且具有平移不变性,双变量去噪模型考虑了信号经过多分辨率分解后不同小波系数之间的相关性,提高了去噪效果。孪生支持向量机(TSVM)对不均衡数据具有很好的处理能力,经过粒子群算法优化后的孪生支持向量机模型具有更好的泛化性能。在UMN视频数据集和自建数据集上的实验结果表明,相较于社会力模型和粒子熵模型等方法,所提算法具有更高的检测准确率。3、提出一种基于多列时空自编码器的群体异常行为检测算法。该算法利用一种简单有效的多列时空自编码器网络架构来将视频图像作为输入,在自编码器的帮助下自动捕获数据中的空间结构,这些空间结构被组合在一起构成视频表示。这种表示被馈送到多列时空自编码器的栈中以学习常规时间模式。所提出的多列时空自编码器允许输入图像具有任意大小或分辨率,通过利用不同大小感受视野的滤波器,使每列自编码器学习得到的特征可以自适应由于透视或图像分辨率引起的视频中异常事件大小的变化。同时引入了三层卷积长期短期记忆LSTM模型,LSTM能解决RNN无法有效利用大跨度历史信息的问题,也避免了模型训练时梯度消失的问题。"
1750,脊柱侧凸影像Cobb角计算机辅助测量算法研究,"随着计算机视觉和图像处理技术的发展,为X射线、MRI、CT和PET等医学影像提供了新的计算机辅助诊断方式。探寻一种较少依赖先验知识和个人操作并能得到较稳定测量结果的计算机辅助测量Cobb角的方式具有一定研究意义。本文以某医院提供的脊柱侧凸患者的X射线、CT以及MRI影像为研究对象,进行了如下方面的研究:(1)提出了一种针对MRI和CT脊柱侧凸影像的基于传统图像处理算法的Cobb角自动测量算法。首先采用增强的分水岭分割算法对MRI或CT脊柱影像中脊椎进行分割并提取各脊椎中心点,然后使用六次多项式对中心点集进行曲线拟合得出脊柱曲线。最后通过计算脊柱曲线中二阶导为0的点切线之间夹角自动计算出Cobb角。经实验验证,算法可达到94.2%的脊椎分割精度与±4°的Cobb角测量误差,解决了临床脊柱侧凸影像Cobb角测量以及现有Cobb角计算机辅助测量算法中需手动定义脊柱上下端椎的问题。(2)提出了一种针对X射线影像的基于传统机器学习的脊柱侧凸Cobb角自动测量算法。首先引入了特征表达能力较强并能有效描述目标外观轮廓等特征的聚集通道特征,对脊柱X射线影像提取多尺度聚集通道特征并使用Adaboost分类器训练级联分类器完成脊柱区域检测。然后使用基于邻域信息与强度值的分割算法进行脊柱轮廓分割。最后对脊柱轮廓进行曲线拟合得出脊柱曲线并自动计算Cobb角。经实验验证,算法可达到99.0%的检测精准率、80.33%的分割精度与±4.99°的Cobb角测量误差,扩充了脊柱侧凸影像Cobb角自动测量时图像类别,适用于临床应用较广的脊柱侧凸X射线影像。(3)提出了一种针对X射线影像的基于卷积神经网络的DU-Net脊柱检测分割算法。首先引入上述脊柱检测算法进行模型训练构建脊柱检测模型,然后使用语义分割网络U-Net作为脊柱轮廓分割框架,构建脊柱分割模型,并与脊柱检测模型相结合形成DU-Net检测分割网络。经实验验证,算法可达到平均90.28%的Dice系数、86.3%的分割精度与82.29%的IOU。提高了脊柱X射线影像轮廓分割精度,适用于Cobb角自动测量算法中脊柱轮廓分割模块。"
1751,基于密度函数估计的高密图像目标计数算法研究,"随着当今技术的迅速发展和理论的不断深入,智能化图像处理与分析已经成为一个非常重要且活跃的研究领域。智能图像分析主要是研究图像和视频中特定的目标对象的分类,检测和语义分割。目标计数也是图像分析中的一项重要研究内容,低密度图像目标计数通常可以通过目标检测算法实现,高密度目标计数其计数精度仍然有限,虽然近年来深度学习在高密度图像计数领域获得了广泛的关注,但深度学习对硬件平台要求较高,如何在较低性能的计算平台中实现一种具有更高的精准度和更好的鲁棒性的高密度计数算法仍然具有很强的实践价值,本文主要研究内容总结如下:1.通过2D高斯核函数,构建密度函数模型来对真实密度进行估计。在高密计数数据集上,根据标定数据中每个训练样本中的像素点定义一个真实密度函数。通过在每个像素点中提取图像的特征向量,并利用高斯模板卷积与高斯函数对真实密度进行建模,进一步使用L2正则化控制参数范围,从而获得最优密度参数模型,最终得到密度估计的积分值,并根据密度估计的积分值计算出相对准确的目标对象数量。2.基于构建的密度函数参数模型,本文使用了三种不同类型数据集进行实验,并使用两个评估标准以验证提出的模型在不同高密度场景下目标计数的准确性和鲁棒性。实验结果证明,相比较于传统的回归计数方法,本文提出的方法计数的准确率更高,具有更大的优势与效率。而相对于基于深度学习的计数方法,本文提出的模型需要的硬件要求更低,计算时间更少,更适用于嵌入式等性能较低的计算平台。"
1752,基于生成式对抗网络的特定场景生成技术及应用研究,"近年来,生成式对抗网络(GAN)已成为深度学习领域最热门的研究方向之一,尤其在图像生成领域取得瞩目成就。特定场景生成属于图像生成任务,不同于现有算法生成与输入数据相同或相似的图像,特定场景生成需要将输入图像重建。在保持其属性特征前提下,融合新的场景并生成多种包含输入图像的合理场景,这需要复杂的方法来解决。为此,本文基于GAN对高质量特定场景生成和语义控制的多域场景生成算法进行研究。本文主要研究内容如下:首先,本文以GAN不同模型及其在计算机视觉领域的应用为研究对象,对GAN进行综述。从理论角度分析GAN的原理与优缺点,在不同模型上进行对比实验,分析每个模型的基本思想、方法特点及使用场景。归纳GAN模型的改进思路并综述GAN在计算机视觉上的应用。不同实验表明,不同的改进方法都对生成质量有提升作用,但又存在其他方面的不足,如收敛慢、模型崩溃。其次,针对GAN存在的模型崩溃,生成样本不真实、缺乏多样性等问题,本文提出一种基于频谱正则化的高质量场景生成算法SPSceneGAN。该算法以条件GAN为基础,组合多种损失函数,将频谱正则化应用于SPSceneGAN以增加模型的稳定性并提升场景生成质量。多次对比实验表明,与其它基准模型相比,SPSceneGAN不仅实现高质量特定场景的生成,还解决了GAN常见的问题,如训练困难,生成结果缺乏多样性等。最后,针对场景在跨域生成时可扩展性差的问题,本文提出一种基于语义控制的多域特定场景生成算法MPSceneGAN。该算法构建一个双条件特定场景生成模型,将目标场景与语义结合以充分提取场景中的图像特征与域标签的映射关系,实现语义控制在一个生成模型上生成多个特定场景。多次对比实验表明,MPSceneGAN能够准确的按照语义描述生成相应的合理场景图像,并且定量评估与定性评估两个方面都达到了最好的结果。综上,本文基于GAN提出两种场景生成算法分别实现高质量特定场景生成与语义控制多域场景生成。通过频谱正则化和语义标签解决了模型崩溃和多域场景生成的问题,进一步扩展生成场景的应用范围,能够解决一类场景生成问题。实验表明,这些算法在生成质量与域生成准确性比现有方法有巨大优势。"
1753,手势识别算法研究及实现,"通过键盘或鼠标操纵机器是目前人机交互最普遍的方法,而手势识别技术的出现改变了这一现象,使人机交互更自然,也是该领域的研究热点。在真实人机交互的手势识别场景中,由于背景的多样性、光线强度、手掌大小、肤色干扰及遮挡等,使手势识别具有一定的挑战性。手势识别包括传统机器学习和深度学习方法,对于传统的手势识别,其关键因素在于检测出场景中手势区域并分割提取具备辨别性的特征。深度学习的手势识别中,除了具备一定规模且高质量的训练数据集之外,网络结构设计、损失函数设计、权值调节和参数设计是手势高鉴别力的决定性因素。针对实际应用中对手势识别算法的精确性和实时性的需求,论文分别在传统方法的手势区域检测及特征提取和深度学习算法的研究与系统实现两方面展开。主要研究内容和创新工作如下:1.给出了一种结合聚合通道特征(ACF)和双树复小波变换(DTCWT)的手势识别算法。针对目前手势识别方法受环境、光线、旋转、缩放、肤色等影响,导致手势识别精度下降的问题,该算法在手势图像预处理过程中引入聚合通道特征,采用Adaboost分类器和非极大值抑制算法(NMS)进行目标手势的检测;利用DTCWT对目标手势图像进行多尺度多方向分解,对高低频系数的每一块分别提取梯度直方图(HOG)和局部二值模式(LBP)特征;最后融合各个方向上的高低频特征并通过支持向量机进行分类识别。实验结果表明,相较于传统肤色检测和时间域或空间域上单特征提取,聚合通道特征的引入能够更准确检测手势,同时基于DTCWT的手势图像频域特征提取和再融合的方法有效地提高了复杂背景下手势识别精度。2.给出了一种基于深度学习模型的多尺度特征图检测的手势识别算法及系统实现。针对目前所研究的传统方法的手势识别算法中存在的精确度不够高、实时性不强和算法复杂度高等问题,算法采用深度学习SSD模型,特征提取部分使用去掉全连接层的VGG16的预训练模型网络取代,并对网络结构和参数进行微调,以防止较差的初始权重,使用更高学习率的批量归一化和最大池化来加速收敛、防止过拟合。同时,在特征提取网络后添加额外网络层,使用多尺度特征检测经过前向网络后的边界框选取和非极大值抑制(NMS)等策略实现手势识别。在自制数据集中对RCNN、Faster R-CNN和YOLO算法的比较实验结果表明,所提算法的有效性更强,并且随着数据集数量的增加,与本文传统方法相比,实验精度升高,实时性增强。且利用该算法基于QtDesigner实现了手势识别系统,该系统实现了手势识别算法的实用性和可移植性,使手势识别应用更方便快捷。"
1754,中文命名实体及实体关系的自动抽取研究,"命名实体识别和实体关系抽取是信息抽取的两个重要任务。本文根据军事文本特点,结合ACE 2005中文数据集的命名实体类型和实体关系类型,定义军事领域文本中命名实体和实体关系的类型,进行人工标注,构建了军事领域标注数据集,并提出两种不同的抽取方法,包括基于管道方式的抽取方法和基于联合方式的抽取方法。本文的主要研究内容如下:(1)基于管道方式的抽取方法。将两个任务看成分离的子任务,独立进行处理。本文采用Lattice LSTM(Lattice Long Short Term Memory)模型对输入文本进行编码表示,融入词表匹配的词语信息,采用CRF(Conditional Random Field)层进行解码,实现中文命名实体识别。在此基础上,将关系抽取问题看作分类任务,采用PCNN(Piecewise Convolutional Neural Networks)网络模型,实现实体关系抽取。(2)基于联合方式的抽取方法。将两个任务看成一个统一的任务,任务之间信息融合,同时抽取中文命名实体和实体关系。本文提出基于状态转移网络的联合抽取方法,设计并定义转移动作,将联合抽取任务转换为转移动作序列的生成过程。该方法首先利用Lattice LSTM网络对输入文本进行编码表示,采用Stack LSTM(Stack Long Short Term Memory)实现栈的记忆功能,然后根据当前栈的状态,利用SoftMax层决定下一步转移动作,一直达到终结状态。基于状态转移网络的联合抽取方法能够识别中文嵌套实体,并实现命名实体和实体关系的联合抽取。本文在ACE 2005中文数据集和军事领域标注数据集上进行实验,根据实验结果评估管道方式和联合方式的模型性能。在ACE 2005中文数据集上,基于状态转移网络的联合抽取方法在中文命名实体识别结果上,F1值达到75.26%,实体关系抽取F1值达41.28%。相比于管道方式,命名实体识别结果提升8.45%,实体关系抽取结果提升12.41%。实验结果表明基于状态转移网络的中文命名实体和关系联合抽取方法优于基于管道方式的抽取方法。"
1755,基于特征融合的手势识别,"随着信息技术的发展,人机交互面临着从传统的交互方式向感知型和友好型交互方式的发展。基于手势的人机交互方式具有自然性、直观性、语义丰富等优势,被广泛应用于手语翻译、机器人控制、体感游戏以及康复系统等领域。本文采用特征融合分别对静态和动态手势识别问题进行研究,所取得的主要研究成果如下:1、对手势识别中常用的预处理、特征提取和分类算法的原理、各种算法的优势和劣势进行了分析、总结和实验验证,为手势识别研究提供了理论基础和方法依据。2、提出了适用于近肤色复杂背景的多尺度多角度静态手势识别方法。首先,将单高斯模型(SGM)和Kmeans算法组合以分割近肤色的背景中手势;然后,将HOG特征和改进的9ULBP描述符进行特征融合以实现手势的特征提取;最后,利用SVM分类器对手势进行分类并在自制数据集、NUS和MUGD数据集上进行了实验验证。实验结果表明:与其他手势识别方法相比,本文所提出方法可以实现最高99.01%的识别率。3、提出一种新的视频描述符(HOG~2-9ULBP~2),基于该描述符完成了动态手势识别。首先,利用Kinect同时捕捉动态手势的RGB图像序列和深度图像序列;然后,从深度图像序列中提取手势的HOG~2特征和从RGB图像序列中提取手势的9ULBP~2特征;接着,将两种特征进行融合以表征动态手势的运动特征;最后,将融合特征馈入SVM进行手势识别。将提出的动态手势识别方法在SKIG公共数据集进行实验,实验结果表明:与其他手势识别方法相比,该方法可以实现最高98.51%的识别率。"
1756,基于神经网络的中文分词研究,"近年来,随着中文互联网世界的不断发展和人工智能研究的不断深入,中文自然语言处理变得愈加重要。在中文自然语言处理领域中,中文分词是一项基础技术,在诸多应用中不可或缺。将中文分词视为一种基于字符的序列标注问题以便采用机器学习的方法去处理是当前较为有效的一种思路,这种思路简称为字标注法。然而传统的统计机器学习方法需要人工仔细地设计大量特征,特征设计的好坏依赖人的经验,进一步提高模型效果受到制约。深度神经网络模型近年来在诸多模式识别任务中大放异彩。从计算机视觉领域、语音识别领域到自然语言处理领域,采用基于深度神经网络的研究方法成为一种趋势。中文分词任务中同样涌现了很多出色的神经网络方法,其中比较主流的是基于可以处理长距离依赖信息的长短时记忆(Long Short-Term Memory,LSTM)网络的模型。但是,一方面,长短时记忆网络固有的序列特性使其训练时间较长,不利于神经网络模型的实际应用;另一方面,当使用包括长短时记忆网络在内的神经网络方法处理中文分词问题时,很多工作依然需要必要的特征工程来增强模型捕获局部特征的能力。有鉴于此,本文主要做了以下的工作:一是针对现有的长短时记忆网络模型训练困难问题,本文不再采用长短时记忆网络来提取上下文特征,而是将在序列对序列任务中最新提出的自注意力机制(Self-Attention)引入中文分词任务中作为新的特征提取器。据我们所知,这是第一次将自注意力机制引入中文分词任务中。二是为了验证局部特征在中文分词任务中的重要性,本文设计一种局部自注意力机制。局部自注意力机制改变原有的自注意力机制建模全局信息的做法而使模型只关注一定范围内局部上下文信息。相对于原有的自注意力机制,新的局部自在注意力机制并不引入额外的参数。三是为加强自注意力机制捕获局部信息的能力,本文将卷积神经网络(Convolutional Neural Network,CNN)与自注意力机制相结合,目的是利用卷积神经网络为自注意力机制补充提取局部特征的能力。该方法以编码器块为基本组成元素,在每个编码器块里,首先使用卷积网络提取局部特征,然后再将局部特征输入进自注意力机制以捕获输入序列的全局信息,最后通过堆叠编码器块提取高层次的文本特征用于最后的标签预测。本文使用两个公开数据集PKU和MSR验证所提出的的模型。实验结果显示在同样实验条件下,局部注意力机制的比原有的自注意力机制拟合速度更快且几乎不损失性能;基于卷积神经网络和自注意力机制相结合的模型与基于长短时记忆网络的中文分词模型相比,在计算效率与分词效果上均有一定的优势,为中文分词任务提供了新的思路和方法。"
1757,SDN环境下的DDoS攻击检测与防御方法研究,"随着互联网的飞速发展,网络已成为人们生活中不可或缺的一部分。人们在享受着互联网为生活所带来的便利的同时,也面临着十分严峻的网络安全问题。传统网络架构配置复杂且可扩展性差,无法满足灵活、高效的网络管理要求。软件定义网络(Software Defined Network,SDN)是一种新型的网络架构,打破了传统网络架构的垂直整合,其核心思想是数控分离,即将底层设备的控制功能和数据转发功能解耦。网络安全问题近年来愈加频繁,目前网络中各种攻击手段层出不穷,其中分布式拒绝服务(Distributed Denial of Service,DDoS)是一种破坏力强、攻击面广且易于实施的攻击手段,是目前SDN所面临的主要安全威胁之一。随着SDN架构在云数据中心的应用日益广泛,如何保障SDN的安全问题成为了研究的重点。本文主要研究了SDN环境下的DDoS攻击检测与防御问题,具体研究工作如下:第一,针对消耗SDN控制器资源的DDoS攻击,提出了一种基于机器学习算法的DDoS攻击检测方法,包括异常检测模块,流特征提取模块和攻击检测算法模块三部分。通过分析DDoS攻击的特点,DDoS攻击数据包的目的地址通常只有一个,其目的地址的熵值相对较低。本文利用数据包中目的地址的熵值作为异常检测的方法,设置了一个DDoS攻击检测算法的触发机制。由于熵值的计算简单,所占用CPU资源较少,可以减轻网络的负担。通过提取流的4个特征组成特征向量作为攻击检测算法的输入能够很好地区分正常流和攻击流。DDoS攻击检测算法组合了支持向量机(Support Vector Machine,SVM)和K均值聚类算法(K-means)算法的结果,避免了单个机器学习算法在不同的训练数据集上检测结果的偏差。检测的结果也将作为输入的数据集用来训练SVM和K-means算法,通过这种模型再训练完成算法的优化。第二,当检测到网络正在遭受DDoS攻击后,提出了一种基于回溯的DDoS攻击防御方法,包括攻击溯源和攻击缓解两个部分。结合SDN的特性,改进了传统的概率包标记算法(Probability Packet Marking,PPM),利用IP数据包中较少使用的40位比特位作为数据包的标记空间,标记空间充足且对网络的影响较小。攻击溯源包括数据包标记和攻击路径重构两部分,数据包标记过程利用SDN交换机中维护的标签记录表,无需构造网络拓扑。使用动态标记概率来标记数据包,加快了数据包的标记速度且标记信息所占空间小。路径重构算法从受害主机开始,利用数据包的标记信息和SDN交换机的标签记录表来还原攻击路径,耗时短且溯源精度高。攻击溯源过程完成之后,结合SDN的特性与现有的DDoS攻击缓解方法,如访问控制列表(Access Control List,ACL)和流量管理策略,设计了一种适用于SDN环境下的DDoS攻击缓解方法。通过Mininet仿真平台模拟真实的SDN网络环境验证了所提出的DDoS攻击检测和防御方法的有效性。"
1758,基于分布式架构的网络流量分析系统设计与实现,"随着互联网的快速发展和大数据时代的来临,数据正在呈现出爆发式的增长,其价值也正在被不断挖掘和利用,数据在某种程度上决定着企业的发展方向,网络作为数据交换和共享的基础条件,正在承载着日益增长的数据传输需求,其性能决定着数据共享和交换效率。在庞大的网络数据和高速的网络传输面前,如何实现对网络数据的实时获取、存储和分析是网络流量分析必须面对的问题。当前,单台服务器的性能已经远远无法满足网络数据分析的要求,分布式网络数据获取和分析模式是该工作的发展方向和必要手段。因此,采用分布式结构是当前的必要选择。分布式网络流量分析系统将重点解决超高速条件下的网络数据获取、数据存储、数据分析及可视化等能力,并且采用松耦合的方式实现各功能模块的分布式部署。本文是以中科院高能物理所为背景,高能所每日数据传输超过10亿条以上,国内进口流量峰值在每十分钟152G以上,国外出口流量峰值在每十分钟126G以上,并且流量还在稳步上升。所以,现在需要一个统一流量计算系统,能够承受日益增长的流量,并且能够完整、稳定的统计流量系统,并且有可视化功能。针对以上问题,本文设计了一个基于分布式架构的网络流量分析系统。该系统利用Spark计算框架对大规模流量进行实时分析处理,以时间为界线对数据进行划分。使用Pmacct接收流量,并通过Kafka对流量进行传输并保证在特殊情况下数据的完整性,然后将非关系型数据库Mongodb作为主数据库存储数据。采用Prometheus和Grafana对Mongodb性能监控,保证能够快速的在出现问题时做出反应。最后,在设计上使用了现在流行的展示结构Influxdb和Granfana的思想,对数据按需求进行展示。形成一个仅仅使用一个简单的数据流向,就可以轻松的对实时数据进行处理分析,同时,系统也具备强可扩展性。本文对系统中遇到问题提出对应的技术创新。首先针对Kafka与Mongodb数据传输速度问题,提出三种不同的的传输方法,并进行对比,选取最好的方式。其次,针对Saprk的数据倾斜问题,定义了一个数据倾斜指标,并在超过谁定阈值时通过重新Shuffle其中Task和使用广播的方式减轻数据倾斜,达到降低整个任务的运行时间。最终,完成了高能所所提出的要求。"
1759,面向大规模数据的直接优化AUC算法研究,"近些年来,机器学习和数据挖掘成为了人工智能领域的研究热点。二分类学习作为机器学习和数据挖掘的一个重要研究内容,也受到越来越多的关注。传统的二分类算法一般都是以精度作为评价标准,并不适用于不平衡应用环境。针对不平衡二分类问题,直接优化不平衡准则的算法因其目标函数与评价标准的一致性具有重要的研究价值,其中最为常见的就是直接优化AUC算法。而在真实的不平衡二分类应用中,例如信息检索和金融欺诈等领域,随着数据的急剧增长,已有的基于批学习的AUC优化算法训练速度较慢,不适用于大规模不平衡分类问题。本文提出了面向大规模数据的直接优化AUC算法,利用随机/在线学习在大规模环境下的优势,首先提出了基于mini-batch随机梯度下降法的直接优化AUC算法,再针对大规模数据的噪音问题,提出了基于自适应鲁棒性的在线AUC优化算法。本文的主要工作如下:(1)首先提出了一种基于随机学习的AUC优化算法,称为AMAUC。具体地说,算法采用mini-batch的框架结合L2正则项构成目标函数。mini-batch的方法可以有效降低AUC的平方级别的复杂度,L2正则项则可以防止模型过拟合,在模型更新方式上采用投影梯度法进行内部优化。为了进一步提高性能,还采用了一种自适应更新学习率策略,利用梯度的历史二阶信息提供特征更新,能给予低频特征以较高的学习率更新,高频特征以较低的学习率更新。并且进一步将AUC优化的收敛性提高到了O(log(T)/T),有效提高了算法的收敛速率,在大规模的基准和高维数据集的实验也验证了所提出算法的有效性和效率。(2)真实的大规模不平衡应用环境往往含有噪音数据,而现有的在线AUC算法虽然在不平衡分类问题中能取得较好的分类效果,然而对离群点较为敏感。因此,对此进一步提出一种自适应鲁棒性的在线AUC最大化算法,名为AROAM。针对噪音问题,首先定义基于ramp损失函数的面向AUC度量标准的目标函数,这种损失函数具有较强的抑制噪音影响的能力。因为ramp损失为非凸的损失函数,不能用传统的凸优化方法求解,采用CCCP(凹凸过程)对目标函数进行凸逼近,进一步在每轮迭代训练中采用自适应步长策略来提高AROAM的性能,结合动量法并充分的利用梯度的一阶和二阶信息,可以有效更新分类器。基准数据集的实验验证了所提出算法的有效性,在不同噪音率的数据集上的实验也验证了算法的鲁棒性。"
1760,基于元学习的机械臂模仿学习研究,"目前,随着工业的快速发展,机械臂在智能工厂、航天航空、医疗手术等领域得到了广泛的应用。因此,对能够执行复杂任务具备智能决策功能的机械臂有着巨大的需求。虽然大容量模型例如深度神经网络能够学习复杂的任务和技能,但是这往往需要系统耗费大量的时间和数据从头学习。而元学习和模仿学习使得机械臂可以通过模仿专家示例的行为实现快速学习。所以,探究如何将元学习与模仿学习相结合,使机械臂快速学习新任务在理论和应用方面都有着重要的意义和价值。本文的主要研究工作及成果如下:(1)结合元学习特性,提出了适应于元学习算法的记忆权重整合项,通过调整神经元的可塑性使机械臂在学习多任务的过程中更有效地学会学习,改善多任务学习的遗忘问题。从概率角度对记忆权重整合项进行解释,利用少样本图像分类任务验证了整合项的有效性并与其他正则化项作对比,实验表明记忆权重整合项强化了元学习的学习能力,并且学习效果明显优于其他正则化项;(2)在元模仿学习中添加记忆权重整合项并与卷积神经网络相结合,改进了元模仿学习算法,构建了深度元学习模型。采用层归一化策略、Xavier初始化和Adam算法优化模型,利用七自由度机械臂OpenAI gym Pusher仿真实验探究整合系数对模型性能的影响,统计机械臂执行任务的成功率来评判模型性能,仿真结果表明改进的元模仿学习算法在整合系数为0.6时其任务成功率有着显著的提高;(3)为实现从机械臂视频演示中学习新任务并去除机械臂行为的监督,利用时间卷积网络构建自适应目标函数为策略提供适当的梯度信息,进一步地改进深度元学习模型架构。采用SELU激活函数和Dropout层优化模型,改进后模型在OpenAI gym Pusher实验中评估其学习性能,最后与双头架构的元学习算法作对比。实验证明改进后的深度元学习模型能够仅从机械臂视频演示中高效地学习新任务,与双头架构的元学习算法相比大幅提升了任务成功率。"
1761,非中心化分布式机器学习中的通信优化,"随着数据规模的快速增长,基于大数据的机器学习技术在各行各业中得到广泛应用。对于超大规模数据集,单台机器已经满足不了需求,人们往往需要使用分布式机器学习方法。目前,分布式机器学习技术已经得到广泛关注,被应用到各行各业。如何提高分布式机器学习算法的效率已经变成当前的热门研究课题。在分布式机器学习中,多个机器组成一个集群共同完成一个机器学习任务。不同机器之间有着大量通信,因此,提高分布式算法的通信效率就变得尤为重要。目前已有的分布式机器学习框架可以分为中心化分布式框架和非中心化分布式框架两种。中心化分布式框架存在中心节点,中心节点上有通信瓶颈。非中心化分布式框架没有中心节点,不同节点上通信负载均衡。尽管非中心化分布式框架中不同节点的通信负载均衡,但不同节点之间往往需要通信非稀疏的参数向量。当模型参数很多时,非中心化框架总通信量很大。此外,当分布式集群不同节点速度差异较大时,同步非中心化算法还有高昂的同步开销。本文针对非中心化分布式机器学习展开研究,通过优化非中心化分布式机器学习中的通信来提高分布式机器学习算法的效率。本文提出三种优化通信的方法,分别从数据划分、异步通信、梯度量化这三个角度来提高通信效率。本文工作主要包含以下三个创新点:一、大多数现有的分布式方法都是按照样本划分数据,本文提出一个基于特征划分数据的新型分布式SVRG方法FD-SVRG。FD-SVRG通过改变数据划分方式来减少通信量。理论和实验表明,在高维线性分类任务中,当训练集的数据维度大于数据样本个数时,FD-SVRG相比较其它按照样本划分数据的分布式方法具有更少的通信量,并且收敛速度更快。二、RingAllreduce是当前常用的非中心化分布式算法,但是RingAllreduce采用同步通信机制。本文基于RingAllreduce提出一个异步的RingAllreduce算法A-RingAllreduce,A-RingAllreduce算法使用异步通信来减小同步时间开销。真实数据上的实验表明,当集群不稳定时,也就是集群中的节点速度有快有慢时,A-RingAllreduce可以有效减少节点之间的同步等待时间。同时,采用异步通信的A-RingAllreduce可以取得与其它同步方法相同的模型精度。三、已有的RingAllreduce算法在通信时需发送32比特浮点数表示的梯度向量。本文将量化技术应用到RingAllreduce中,提出一种量化RingAllreduce算法Q-RingAllreduce,使用更低比特数目的表示对梯度进行量化,从而减小通信量。真实数据上的实验表明,Q-RingAllReduce比RingAllReduce具有更少的通信量。当我们将梯度量化为4比特和8比特时,Q-RingAllReduce可以取得与原始RingAllreduce相同的模型精度。"
1762,基于多模态进化计算的集成学习器研究与应用,"集成学习指的是通过构建若干不同学习器来完成同一学习任务的一种机器学习方法。近年来,集成学习以其鲁棒性高,泛化能力强,成为机器学习领域的一个研究热点。集成学习的任务是构建合适的集成模型,并使其达到不弱于其中任意一个体学习器的效果。研究指出,提高学习器的个体精度和种群的多样性是提高集成学习泛化能力的主要手段。然而,多样性和个体精度通常是是相互冲突的。对于同一学习任务来说,当个体的精度很高后,若想再增加多样性,就必须牺牲准确性。这也是集成学习研究的核心出发点。传统集成学习主要通过调整样本分布,集成权重寻优等策略构建集成模型。这类集成学习方法构建集成模型的方式比较单一,没有考虑到进一步提升个体学习器的性能。另外,个体学习器之间的信息交互对集成模型多样性的构建也极为关键。近年来,由于群集智能进化计算的兴起,有学者指出将进化计算和集成学习进行结合。进化计算可以针对集成学习存在的一些问题对其进行寻优。然而目前大部分进化计算和集成学习结合的研究将重点放在个体学习器的选择以及结合策略的寻优。这些方法的实现通常需要基于已训练完毕个体学习器集合,因此其性能很大程度上取决于预生成的个体学习器集合的性能。针对目前集成学习存在的一些问题,本论文提出了一种基于多模态进化计算的新型集成学习策略。算法采用人工神经网络作为个体学习器类型,并将个体学习器的参数进行编码,利用多模态优化算法对其进行寻优。同时,由于多模态优化算法自身的特性,算法可以在寻优的同时构建个体学习器参数之间的多样性。因此,算法可以同步实现集成学习“好而不同”模型的构建。论文的主要工作如下:首先,绪论部分详细介绍了集成学习问题的研究背景及意义,阐明了该问题的研究价值以及重要性。然后描述了集成学习的国内外研究现状,并介绍了一些经典的集成学习研究的出发点及其思想。其次,第2章介绍了多模态进化计算的基本概念及其发展现状。论文首先对多模态问题进行了描述,并详细介绍了传统的小生境策略解决多模态问题的主要思路及其实现过程,分析了基于小生境策略的多模态算法的优缺点。然后,针对传统小生境策略存在的一些问题,论文介绍了新兴的多模态优化算法并分析了其优势所在,给出了其大致实现步骤。论文在第3章介绍了集成学习的相关概念,其中多样性和个体准确性是集成学习的两个重要因素。论文分析了传统集成学习策略构建集成模型的主要手段,传统策略构建多样性的手段过于片面,而且没有考虑到个体学习器内部之间的信息交互。另外,论文对目前基于群集智能优化算法的集成学习策略进行了相关介绍,分析了目前存在的算法构建集成模型的主要出发点及其优劣性所在,为后续的算法设计,对比分析等进行铺垫。然后,本论文在第4章对所提出的基于多模态进化计算的集成学习策略进行了详细的阐述。论文对所设计算法中涉及到的相关策略给出了具体介绍,并且在章节的最后给出了算法的具体实现过程。最后,为了验证算法构建集成模型的有效性,本论文在第五章给出了相关对比实验及其参数分析。首先,论文介绍了若干相关分类问题,并对所提算法和对比算法进行性能测试和结果分析。然后,本论文给出了节点数、多样性以及时耗性等参数分析,以进一步了解算法在训练过程中的内部信息。"
1763,互联网广告点击率预测模型的研究,"随着互联网的日益壮大与电子商务的不断发展,计算广告学,作为一门新兴的学科交汇科学,受到了广泛关注。计算广告学涉及到诸多学科的理论和技术,包括广告学、信息检索、文本分析、统计模型、机器学习及微观经济学等。计算广告旨在向特定的观众群体做广告,并且一直是新兴互联网应用领域的热点问题。在线广告的点击率预估(Click-Through-Rate Prediction,简称CTR Prediction)问题作为计算广告领域的核心问题,对互联网广告应用起着至关重要的作用。点击率预估通常用来判断一条广告被用户点击的概率,对每次广告的点击做出预测,把用户最有可能点击的广告找出来,是广告技术最重要的算法之一。广告点击率关系着广告投放的排序和点击收费等因素,良好的点击率预估模型可以为广告平台提高平台收益,为广告主的产品和预算带来优化,为用户带来更好的广告体验。现代的互联网广告主要分为搜索广告和展示广告,其中搜索广告是规模最大,增长最快的广告形式,搜索广告的点击率与广告投放顺序、点击费用等相关,这对整个搜索广告的收入起着至关重要的作用。以搜索广告为例,本文利用了Light GBM框架对点击率预测,相对传统的机器学习算法(如XGBoost),Light GBM具有更快的训练速度,可处理大规模数据集,占用更低的内存等优点,从海量数据出发,本文系统研究了数据预处理、特征选择和集成模型等相关理论和技术。根据常见的广告点击率预测模型,本文主要研究了其中几个模型,主要改进的方面是特征提取和模型改进,集成了几个单模型的优点,充分挖掘线性和非线性特征,提出一种集成模型,从而提出了更好的点击率预测解决方案。论文完成的主要工作概括如下:(1)数据的分析和处理。在已有的数据集上对数据进行分析和预处理,从统计分析的角度分析了样本的差异性、分布性等,对缺失值数据进行分析处理。(2)特征的处理。删除不相关或冗余的特征,基于原始数据集构造人工特征,对类别特征进行独热编码(One-Hot Encoding),测试了人工特征在多种模型下的效果,验证了所构造的人工特征的有效性。(3)模型的处理。本文实现了传统的逻辑回归(Logisitic Regression)模型和时下流行的几种机器学习算法(如LR,FM,FFM,RF)方法对点击率进行预测,并基于以上模型,提出了一种融合集成学习的广告点击率预测模型,实验结果证明了该模型的有效性。"
1764,基于机器学习的安徽省粮食产量预测方法研究,"粮食产量预测是粮食储藏、农田管理和国家农业决策的关键,是国家粮食安全评估和粮食政策制定的重要组成部分,农作物生长监测及产量预测是调节农业种植系统和农业经营管理的关键。人口增加、耕地面积和水资源减少、环境恶化、全球气候变暖等一系列因素对农业生产影响显著,威胁着粮食安全。预计到2050年,世界总人口将达到91.5亿人,粮食安全保障至关重要,准确的区域作物生长监测和产量预测对于指导农业生产、保障国家粮食安全以及维持农业的可持续发展至关重要。本文对安徽省地理条件及粮食产量变化趋势深入了解后,首先针对各因素对安徽省粮食产量的影响机制进行具体阐述,最终确定安徽省粮食产量主要影响因素有粮食播种面积、有效灌溉面积、受灾面积、化肥施用量、塑料膜使用量、农药施用量、农用柴油使用量、农林牧渔劳动力、农业机械总动力、已建成水库数、农业生产资料价格指数1 1个指标。其次,基于1990-2014年安徽省粮食产量相关数据,分别构建BP神经网络、支持向量回归模型、随机森林回归模型对安徽省粮食产量进行拟合,并以2015-2017年粮食产量相关数据作为测试集对各模型进行检验。结果表明,各模型拟合效果及预测能力均存在一定缺陷,故本文提出基于方差倒数法的组合预测模型,将上述所构建三种模型进行有效结合,并对其预测能力进行评估,结果显示,组合预测模型对训练集的拟合效果较为良好,具有一定的稳定性,且模型一定程度上加入了全局最优的特点,使得预测结果更具有可靠性。最后,本文对安徽省2018-2020年粮食产量进行预测,分别为3459.83万吨、3478.57万吨、3505.57万吨。"
1765,一阶随机优化算法求解有限和函数的研究,"以支持向量机等为代表的结构风险最小化问题是机器学习领域中的一类重要问题。这类问题具有通用的结构,也就是目标函数都是有限和函数加上一个正则化项的形式。基于梯度下降的一阶算法是目前解决这类问题的常用算法。在有限和函数规模过大的情况下找到高效的求解算法是一个重要的研究问题。自适应随机梯度下降算法作为一个随机梯度下降算法的改进,在迭代选取样例的过程中根据一个特定的分布p,并且给出了一种有效的停机准则。新的停机准则可以使得支持向量机模型的样例规模过大时能够在较早期停止迭代。当正负样例不平衡时,由于分布p的存在,可以调整分布使得算法较好的适应非平衡数据。对于有限和函数非凸并且正则化项非光滑的情形,带有加速正则化项的基于方差减少的随机梯度下降算法在求解时分两步来进行处理。第一步处理非凸的有限和部分。该算法能够有效利用目标函数的非凸参数,使得每次迭代时目标函数从非凸函数转化为强凸函数再进行求解。该算法对于加速正则化项的改进很好的处理了原目标函数与带有加速正则化项的新的目标函数之间的差异问题,从而使得求解带有正则化项的新问题所得的近似局部最小解仍旧是原问题的近似局部最小解。第二步,对于非光滑的正则化项无法求导的问题,该算法采用近端梯度算子来处理。根据所提出算法梯度估计的方差界,可以给出了为了求得满足E[||Fη(x)||2]≤ε的自变量所需要的迭代次数的估计。进而可以得出算法的计算复杂度为O(n+n/ε)。数值实验证明了所提出算法的有效性。"
1766,基于卷积神经网络的细胞图像分割与类型判别,"随着人工智能、大数据等最新前沿技术大面积落地及推广,近年来以卷积神经网络为基础的深度学习领域一直是科学研究领域的热点。基于深度学习技术在图像检索分类和特征提取融合等方面的优势,本文主要内容以卷积神经网络为基础将其应用于医学图像分割领域并进行分类判别研究,以实现将深度学习技术应用于医学图像数据分析研究。针对医学图像中的细胞尺寸大小不同、形态各异、纹理变化多样等特点,导致难以分割出精准的细胞区域问题,本文提出了一种基于卷积神经网络结合边缘聚类的新算法用于细胞图像分割。(1)首先用染色校正预处理方式提高原始图像样本的色彩对比度,(2)然后利用卷积神经网络得到初步的分割结果,(3)最后通过边缘聚类方式以提升分割结果的连续性和完整性。此外,本文中还利用了深度学习目标检测技术做细胞区域目标检测,也取得了一定的实现效果,更加直观显示细胞图像中有效目标区域,帮助广大医学工作者识别判定,为病理学家提供一些客观的数据参考。实验表明:相较于经典的卷积神经网络、模糊聚类、阈值分割等其他细胞图像分割算法,本文提出的细胞分割方法在分割结果的完整度方面提升了6.15%;较经典的VGG19结构提升了1.17%。在实际临床医学诊断过程中,细胞的尺寸大小通常用作评判细胞生理状态类型好坏的参考依据,在此基础上本文使用了目前较为流行的计算机视觉技术,以此方式获得分割图像中细胞颗粒的基本属性特征,即周长、面积等,并通过支持向量机分类器进行细胞类型判别。另外,本文还结合了现有机器学习中常用方法将细胞颗粒进行分类聚类操作,也得到了一些有效识别分类的效果。"
1767,基于改进Unet的遥感影像语义分割在地表水体变迁中的应用,"陆地地表水体是江、河、湖的总称,它是被水覆盖地段的自然综合体,更是自然万物和人类文明的摇篮。但是,自从人类文明进入工业化阶段,一些超负荷甚至是破坏性的开发使地表水体满目疮痍。地表水体变迁越发频繁,有效地对水体变迁进行监测是对水资源进行高效开发利用的前提条件。伴随着遥感技术的快速发展,空间遥感平台提供的高分辨率图像信息日渐丰富,其中地表水体的空间与光谱信息占据着重要的组成部分。遥感影像携带的丰富的地表水体数据为地表水体变迁的监测打下了坚实基础,但是丰富的数据量并不能直接被使用,需要人为提取有效信息进行高效的分析量化。本文将地表水体变迁作为研究目标,目的是对给定的同一地区不同时刻的遥感影像通过算法标定变化状态。传统的分割变化检测采用地物的分布、形状、结构、纹理、色调等特征,在处理单一场景时表现较好,但是当地物信息繁杂或者影像分辨率高时算法性能会受到影响,且传统的阈值由人为实验检测设定,算法鲁棒性较低。为了解决此问题,本文以超像素作为基本分析单元,使用机器学习算法构建多个非线性变换组合的深度学习模型对超像素内在的高级抽象特征进行建模,以提高图像分割的准确率与鲁棒性。论文主要内容如下:(1)获取多个同一地区不同时间段的遥感影像并进行几何校正,然后采用面向对象的方法使用eCognition软件标注影像获取基准值(Ground truth)。(2)针对传统阈值分割方法无法有效地分割高背景复杂度的遥感影像,本文提出了一种基于深度卷积神经网络的水体变迁分割方法,该方法在Unet网络构架的基础上优化并改进为D-Unet(Deep-Unet)与DS-Unet(Deep Separable-Unet),可以从遥感影像中精确地提取水体信息,为后续的地表水体变迁研究以及水域面积测算打下坚实基础。(3)针对深度卷积神经网络进行粗分割存在边界不平滑和像素点定位不准确等问题,使用全连接条件随机场对粗分割结果进行细化处理达到更加精细准确的结果。(4)针对遥感影像的特点提出了地表水体面积测算与水体迁移可视化方法。(5)本文针对数据集所采集的基准数据测试了方法的有效性,DS-Unet获得了88.74%的平均分割准确率,并在Intel Core i7(2.2 GHz)下达到15s处理1幅6000*6000px遥感影像的分割速度;D-Unet可以达到91.59%的平均分割准确率以及在Intel Core i7(2.2 GHz)下45s处理1幅6000*6000px遥感影像的分割速度;在使用全连接条件随机场优化后使得分割结果更加细致,在Intel Core i7(2.2 GHz)下处理的平均时间为166s,环境噪声的鲁棒性提高,分割边缘的光滑度更高,是一种有效的水体提取方法。本文最后提出基于像素的地表水体面积测算与地表水体变迁可视化方法在实验中被证明是一种良好的测算方法,取得了良好的展示效果。"
1768,基于机器视觉的白酒液体杂质检测系统研究,"酒作为中华文化的重要组成部分,在人们的生活中起着不可替代的作用。在白酒生产过程中,生产环节繁多且工艺复杂,特别是在灌装环节中,灌装瓶清洗不干净、过滤系统故障、压盖包装时机械冲撞等原因会导致瓶内液体中混入玻璃碎片、絮状物、毛发等杂质。如果这些含有杂质的白酒流入市场,不仅严重损害消费者的身体健康,也对企业和社会造成极大的负面影响。因此有必要研究一种实时可靠的白酒液体杂质检测系统。本文针对当前透明瓶装白酒液体杂质的检测方法效率低下以及现有的杂质检测系统复杂、抗干扰能力差、价格昂贵等问题,提出了一种基于机器视觉的在线检测方法,并在该方法的基础上设计了一套检测透明瓶装白酒液体杂质的检测系统,主要根据透明瓶装白酒液体中杂质的运动特性,通过工业计算机驱动工业相机对透明瓶体图像进行连续采集并进行图像处理分析,从而实现对液体中的杂质进行检测。本文首先根据所提出的视觉检测方法和设计要求,设计了一套视觉检测方案,包括图像采集、光源及照明、系统机械硬件和软件平台等。其中图像采集设备采用迈德威视公司的MV-GE1000M-T CMOS型号的可见光工业相机,光源及照明方式采用平行LED背光源,系统机械硬件主要为垂直翻转机构,系统的软件平台是基于Microsoft公司的Visual Studio 2013和德国MVTech公司的机器视觉图像处理算法库Halcon的Windows平台。根据白酒液体中杂质的特点,设计图像处理检测算法是本文研究的主要内容。论文中对图像处理技术的基本概念和方法等做了相关介绍,并将图像滤波、边缘检测、灰度变换、特征提取、帧间差法、KNN学习算法等算法结合起来,实现了透明瓶装白酒液体杂质检测算法的设计,将具有动态干扰的气泡、污渍和位于透明瓶体内的杂质区分开来。本文通过编程对检测系统的上位机进行设计,该上位机主要采用C#语言和Halcon图像处理算法在Windows平台上实现白酒杂质检测与剔除功能,以及在上位机中实现数据显示及发送、存储等功能。主要包括图像获取模块、杂质检测模块、存储模块、通讯模块、及人机交互界面模块等。为了验证该检测系统的实时性和稳定性,本文搭建了实验平台,并对实验数据和结果进行分析。实验结果表明,即使在动态干扰环境下,所提出的白酒液体杂质检测系统的实时性和稳定性都有很大的提高,在一定程度上解决了透明瓶装白酒液体自动化生产过程中的杂质检测难题。"
1769,铁路浪涌保护器中压敏电阻剩余寿命模型研究,"随着铁路系统智能运维的推进,对浪涌保护器进行在线状态监测以及剩余寿命预测的需求已日益迫切。铁路浪涌保护器是一种应用数量巨大的雷电防护设备,在铁路雷电防护场所承担着吸收浪涌、保护设备的作用。压敏电阻是铁路浪涌保护器的核心器件,在浪涌防护的过程中伴随着自身劣化。铁路浪涌保护器寿命预测研究的关键点是压敏电阻劣化过程的描述研究,对压敏电阻开展剩余寿命模型研究十分必要。首先,本文执行了压敏电阻的劣化探究实验。在实验室采用8/20μs的浪涌冲击压敏电阻,直至其完全损坏。采集了压敏电阻在整个寿命周期中的14种电参数、残压波形和表面温度,并将这些参数的变化趋势进行了分析。分析结果表明,14种电参数能够表征压敏电阻的劣化,但是参数之间不独立、可合并,在使用时需要对其进行筛选。然后,根据劣化探究实验的结果,筛选了5种劣化敏感参数。以5种参数为输入,采用机器学习中的k最近邻和线性回归算法,构建了压敏电阻的剩余寿命模型。k最近邻算法用于判别压敏电阻损坏与否,线性回归算法输出压敏电阻的剩余寿命值。接着,采用实验数据对模型进行了测试。测试结果表明,该模型对压敏电阻的劣化过程刻画良好,但是机器学习的方法对数据具有严重的依赖性。最后,结合压敏电阻经受的历史浪涌、自身特性参数以及筛选的劣化敏感参数构建了表征压敏电阻保持健康状态程度的劣化核。依据随机过程理论,以劣化核为统一输入,分别采用马尔科夫链和伽马过程构建了两个压敏电阻的剩余寿命模型,并分析了模型中关键参数对输出结果的影响。用冲流幅值随机的50次8/20μs浪涌测试了两个模型,并进行对比。对比结果表明:两个模型都能刻画压敏电阻的劣化过程。基于马尔科夫链的模型具有清晰的物理概念,计算量小,在中期和后期劣化的速度一致;而基于伽马过程的模型在中期劣化速度较缓,后期劣化较剧烈,变化趋势更贴近于实际经验情况,但计算量较大。考虑现场监测装置计算资源的限制,采用基于马尔科夫链的寿命模型是一种经济和安全的选择。"
1770,组合知识图谱和深度学习的城市交通拥堵区域预测研究,"交通拥堵在大中城市己日趋严重,导致了出行时间延迟和车辆污染排放显著增加。智能交通系统是缓解交通拥堵、提高出行安全的有效途径,城市交通拥堵预测是智能交通系统的关键技术之一。本文基于交通大数据,研究城市交通拥堵区域预测方法。论文的主要工作如下:1.地图匹配算法研究在城市交通拥堵区域预测模型研究中,需要使用公交轨迹数据和路段速度数据相结合来表征模型的标签,即是否发生拥堵,我们需要使用地图匹配算法处理轨迹数据将轨迹匹配至对应的路段上。为了提高匹配的准确率,引入了随机森林多分类的策略,将匹配问题作为分类问题看待,充分利用海量的历史轨迹数据。为了进一步加快匹配速度满足实时匹配的要求,本文利用分布式处理机制,提出了一种基于分布式随机森林多分类DRFMM的方法来处理轨迹数据的地图匹配问题。采用真实的合肥市路网和出租车轨迹数据表明,同经典的点线匹配算法和神经网络分类方法相比较,本文提出的基于分布式随机森林多分类的地图匹配算法DRFMM有效提高了匹配的准确度和速度。2.城市交通拥堵区域预测模型本文提出了一种结合知识图谱和时空卷积神经网络(KG-ST-CNN)协同预测城市拥堵区域的模型。具体而言,通过对多源异构的的城市交通大数据进行离散化和语义化,构建城市知识图谱,并引入图卷积网络来进一步提取城市知识图谱的特征,这些特征被处理为时空卷积神经网络的输入。该方法将城市交通网络视为图像,有效地捕捉了区域之间的空间相关性,并通过分析交通数据的时间相关性,构建了多个卷积网络分别捕捉不同时段的特征,从而准确地预测出交通拥堵区域。通过北京市的交通数据将本文方法和经典预测模型进行比较,实验结果验证了本文提出的KG-ST-CNN预测模型的有效性,显著提高了拥堵区域预测的精准度和召回率。3.城市交通拥堵区域预测系统设计与实现基于本文提出的分布式随机森林多分类匹配算法以及结合知识图谱和时空卷积神经网络的城市拥堵区域预测模型,设计并实现了拥堵预测系统,作为城市交通智能控制系统的一个子系统,将提出的算法和模型优化其服务层地理位置服务和应用层决策分析模块。"
1771,城市交叉口短时交通流的配时优化方案研究与应用,"准确、高效的交通流预测是智能交通系统的核心功能,也是实现智能交通诱导和控制的前提;而改善交叉口信号配时,则是提高交通运行系统效能的关键。本文以短时交通流预测为基础,对交叉口配时优化进行研究,具有一定的理论意义和实际应用价值。本文在研究现有短时交通流预测模型基础上,融合传统机器学习和深度学习模型,提出了一种混合预测交通流模型,以及基于该模型的交叉口多目标配时优化模型,实现了基于预测交通流的交叉口交通控制信号多目标配时优化计算。论文主要工作与贡献包括:1.分析交通流量的主要特性和时空相关性,以及交通流数据集特点,并从不同维度分析交通流的特征。在此基础上,针对短时交通流预测,提出CNN-XGBoost混合预测模型。将CNN-XGBoost模型与其它四种预测模型进行实验对比,验证该模型的优势。2.基于短时交通流预测,建立交叉口多目标配时优化模型,并提出一种改进的非支配排序遗传算法(Nondominated Sorting Genetic Algorithm Ⅱ,NSGA-Ⅱ)算法。3.利用河北育才街和裕华路交叉口几何条件和相位相序,以及基于实际交通流生成数据,对该交叉口使用VISSIM进行仿真,并和Webster配时法从多个性能指标进行对比,验证了本文提出的多目标配时优化模型及求解算法的有效性。4.基于本文的交叉口多目标配时优化模型及求解方案,设计并实现了交叉口配时优化计算子系统,作为城市交通信号智能控制系统的一个子系统,该子系统主要包括参数分析和仿真优化两大模块。其中,参数分析主要对交通流量进行查询和预测,仿真优化主要计算出配时方案和性能指标。目前,该子系统主要功能已基本实现,可以方便地对信号机进行管理和控制,同时可以为决策者生成配时方案以供参考。"
1772,基于机器学习的自行车安全驾驶行为研究,"随着绿色出行概念的提出,越来越多的人选择自行车作为出行方式,骑行过程中骑行人不良的行为习惯和复杂的路况都能导致事故发生,因而对人们骑行行为进行识别和监测有着非常重要的现实意义。本文目标是通过手机传感器采集自行车骑行过程中的人体行为数据,对采集的四种传感器数据进行数据融合,然后运用阈值法和机器学习算法联合来设计分类器,实现对自行车骑行中五种行为的识别。骑行行为的识别不仅有助于分析居民骑行行为的数据和特征,形成交通大数据,也能在骑行过程发生的意外发送预警信号,既能保障出行安全,又有利于路面交通的监测管理。研究主要内容如下:(1)数据采集和预处理。针对手机上各种丰富的传感器,为了获得骑行行为的姿态和速度信息,选取了智能手机上加速度传感器、陀螺仪传感器、磁力计传感器及GPS(Global Positioning System,全球定位系统)定位传感器等作为数据来源,通过手机端数据采集APP将原始数据发送至PC端网络数据库管理系统。采集的数据存在各种缺失值和噪声,在PC端对传感器数据进行完整的预处理流程:为了数据的完整性,采用拉格朗日插值法处理缺失值;同时选用采用2s的窗口滑动均值滤波对原始信号进行去噪处理,实验表明,滑动均值滤波达到了较为理想的效果。(2)多传感器数据融合算法。针对实际应用中手机的摆放位置随意,导致手机坐标系与自行车坐标系不一致的问题,采用基于磁力计和加速度计结合的初始相对姿态测定方法,实验证明,初始相对姿态矩阵的测定能快速实时地将手机坐标系的数据转换到所在自行车载体坐标系中。然后采用基于四元数的扩展卡尔曼滤波算法进行SINS(Strap-down Inertial Navigation System,捷联惯性导航系统)/GPS姿态和轨迹数据融合,实时更新得到载体的姿态角、速度、轨迹、加速度、角速度数据。(3)基于阈值和支持向量机结合的行为识别。现实中模式识别行为检测算法实时性低、误报率高的问题,本文通过信息融合所得到的运动学数据,利用两次判定进行行为检测。首先根据设定的阈值初步判定骑行过程中的正常行为和危险行为,根据速度、加速度、角速度、姿态角的统计量和变化趋势来构建特征空间,使用分裂法来优选特征空间并最终构建最优的特征空间,最终获取五种行为分类模型,其中,阈值法对危险速度的识别率达到100%,支持向量机模型对左/右转、急变速行为、危险碰撞行为和跌倒行为等总体准确率分别达到94.2%、90.8%、96.3%、95.4%。"
1773,基于机器学习的电网虚假数据注入攻击检测方法研究,"2019年1月17日,国家电网公司在两会报告中将建设运营“泛在电力物联网”提升至企业战略地位,随着我国电力系统智能化程度的进一步提升,网络攻击所产生的破坏程度可能超出正常预期。电力系统已经具备信息物理融合系统(CPS)的典型特征,发生信息安全事件可能引发大规模停电事故等严重后果。虚假数据注入攻击(FDIAs)作为一种新型电力系统网络攻击,可以成功绕过不良数据检测机制,使电力量测数据发生偏移,在极其隐蔽的条件下误导控制中心操作,严重威胁电力系统稳定运行。传统的检测方法难以检测这种攻击,为保证智能电网的运行安全,本文通过分析虚假数据注入攻击机理,利用机器学习在处理二分类问题上的优势,以监督学习的方式,将虚假数据注入攻击的检测工作归纳于模型训练与分类决策两个步骤,从数据样本构建、特征提取和检测模型构建三个方面着手电网虚假数据注入攻击检测方法的研究。本文基于机器学习构建攻击检测模型,那么包含正负样本的电力量测数据样本集是模型训练与检测实验的基础。首先,考虑攻击者掌握完整电网拓扑信息和非完整电网拓扑信息两种条件,深入分析讨论了虚假数据注入攻击的攻击机理;然后,分别构建了IEEE-14-bus与IEEE-118-bus标准节点系统网络拓扑并生成电力量测数据,由于实际中攻击者难以掌握完整的电力系统参数和网络拓扑,本文在非完整的网络拓扑信息条件下构造FDIAs攻击向量。通过仿真实验,生成了攻击检测所需的正常与受攻击后的正负数据样本,为进一步攻击检测模型的实现提供基础。电力量测数据有维度高、噪声强的特性,难以直接应用于模型训练和检测实验,单独对量测数据进行数据降维方法无法保证攻击检测针对性。利用孤立森林(iForest)与局部线性嵌入(LLE)分别在异常检测和数据降维上的优势,创新性地将异常分值提取和数据降维相结合,提出一种专门针对于FDIAs检测的iForest-LLE电力量测数据特征提取方法,既保证了数据处理阶段用于攻击检测的针对性,又兼顾了特征提取的数据质量。最后通过实验验证了所提特征提取方法的有效性和优越性。FDIAs攻击检测的首要目标是保证精度,单独依靠电力系统相关理论难以检测精心设计的FDIAs。本文设计了一种基于改进梯度提升决策树(GBDT)的攻击检测模型,将基本的决策树算法与梯度提升框架相结合,使单一的决策树分类模型在串行训练中不断提升精度,以此组合构建高精度的攻击检测模型。针对GBDT模型超参数选择对结果影响较大且确定困难的问题,在原始果蝇优化算法的基础上提出了三维自适应混沌果蝇算法,设计了超参数在训练过程中的自动寻优策略,改进了基本的GBDT检测模型,记为V3ACFOAGBDT。仿真实验表明,本文方法在攻击检测的运算效率和检测精度上均具优势。"
1774,无人机多光谱遥感反演棉花光合参数与水分的模型研究,"作物植株水分含量直接反映其遭受水分胁迫的程度,土壤水分是作物稳产高产的基础,光合参数可以一定程度反映作物的旱情和水分利用状况。无人机遥感可以对对作物的光合参数、植株水分和土壤水分进行实时有效地监测,成为实现精准灌溉的重要技术手段。因此本文以棉花为研究对象,使用六旋翼无人机搭载多光谱相机观测棉花花铃期的冠层光谱特征,同时采集不同水分处理下的棉花冠层的光合参数、植株含水率和不同深度的土壤含水率数据,分析棉花在不同水分处理下的光谱响应特征及光谱反射率、植被指数和植被供水指数与光合参数、植株含水率和不同土壤深度土壤含水率的相关性,采用一元和多元回归方法建立了基于特征波段或敏感植被供水指数的棉花光合参数和植株含水率的反演关系模型,采用机器学习算法建立了土壤含水率的反演模型。得到的主要结果如下:(1)构建了不同光合参数的反演模型并筛选出最佳反演模型。多光谱6个波段的反射率在一日中均呈现先减小后增大的趋势,蓝光波段(490nm)和红光波段(680nm)表现出较低的反射率,变化不明显,绿光波段(550nm)、红边波段(720nm)和两个近红外波段(800、900nm)变化趋势比较明显。不同水分处理下的棉花冠层光合参数的变化趋势基本一致,其中净光合速率(Pn)、气孔导度(Gs)和蒸腾速率(Tr)呈现先增加后减小的近似抛物线变化,胞间二氧化碳浓度(Ci)则恰恰相反,表现出先减小后增加的反向抛物线变化。4种光合参数都有与其敏感的波段,部分相关系数达到了0.8以上,净光合速率(Pn)反演的最佳模型为13:00的基于蓝光波段反射率的一元线性模型,气孔导度(Gs)反演的最佳模型为15:00的基于红光波段反射率的一元线性模型,胞间二氧化碳浓度(Ci)反演的最佳模型为15:00的岭回归模型,蒸腾速率(Tr)反演的最佳模型为15:00的基于红光波段反射率的一元线性模型。(2)构建了棉花植株不同部位含水率的反演模型并筛选出最佳反演模型。对叶片含水率敏感的波段为波长为490nm的蓝光波段和波长为680nm的红光波段,对茎秆含水率敏感的波段为波长为900nm的近红外波段,对蕾铃含水率敏感的波段为490nm的蓝光波段、波长为680nm的红光波段和波长为900nm的近红外波段,都呈极显著负相关;引入冠层温度构建的基于不同植被指数的植被供水指数(Vegetation supply water index,VSWI)与植株含水率的相关性较单一植被指数与植株含水率的相关性有所提升。其中,VSWI_GI与叶片含水率的相关系数达到了-0.853,VSWI_DATT2和VSWI_MTCI2与茎秆含水率的相关系数均达到了-0.895,VSWI_MTCI2与蕾铃含水率的相关系数达到了-0.872;叶片含水率的最佳反演模型为基于VSWI_GI的一元线性模型,茎秆含水率为基于VSWI_MTCI2的一元线性模型,蕾铃含水率的亦为基于VSWI_MTCI2的一元线性模型。(3)构建了棉田土壤水分的反演模型并筛选出最佳反演模型。VSWI_VARI、VSWI_GI、VSWI_MCARI和VSWI_MTCI1与45cm土壤深度含水率的相关系数达到0.8以上,其中VSWI_MTCI1与土壤含水率呈负相关关系,VSWI_VARI、VSWI_GI和VSWI_MCARI为正相关;由VSWI_VARI、VSWI_GI、VSWI_MCARI和VSWI_MTCI1等4组植被供水指数构建的支持向量机(Support vector machines,SVM)、反向传播神经网络(Back propagation neural networks,BPNN)和随机森林(Random forests,RF)等机器学习模型反演棉田土壤含水率取得了更高的精度。建模和验证R~2均在0.8以上,且RMSE小于0.02,RE小于5%。综合分析敏感植被供水指数模型和机器学习模型发现,机器学习模型的预测精度明显优于敏感植被供水指数模型。其中随机森林法(RF)构建的反演模型的建模决定系数R~2、均方根误差RMSE和相对误差RE分别为0.906、0.010和0.719%,均为所有模型中的最优值。这表明随机森林模型为棉田土壤含水率的最优反演模型。"
1775,基于卷积神经网络的农作物病害图像识别研究,"农业是国民经济建设与发展中必不可少的基础产业。农作物作为农业领域的主要产物,其发展及其重要,但每年的农作物病害问题都会造成农作物产量损失严重。目前人工诊断是最常见的农作物病害问题处理方法,因实施过程中受限于时间、空间等因素的影响,导致大面积的农作物病害诊断处理普遍存在不及时的情况。由于这种问题的存在,依据农作物病害图像识别的诊断方式也在迅速发展。近年来,参与ILSVRC竞赛(ImageNet Large-Scale Visual Recognition Challenge)的佼佼者们使用的模型大都基于卷积神经网络(convolution neural network,CNN)模型及优化模型。因为CNN共享权值、自主选取特征训练权重等优点使其在图像识别领域效果显著,所以本文以提高农作物病害图像的识别准确率和泛化性为目的,展开基于CNN的农作物病害图像识别研究,主要完成工作如下:(1)针对小样本和样本不均衡条件下的农作物病害图像识别,首先使用辅助数据集ImageNet训练Inception、ResNet等预训练模型;然后利用迁移学习的方法迁移预训练模型的网络结构和特征参数,训练农作物病害识别方法;最后融入focal loss方法和组归一化算法优化模型,提高识别率。接着以10个农作物病害测试集为实验对象进行试验,与未优化模型以及传统分类方法所得识别结果进行比较,最终验证了此分类方法具有一定的可行性及有效性。(2)针对类别之间相似度极高的农作物病害图像识别问题,提取Inception-v3结构中每个inception block最后一层的卷积特征矩阵并进行融合,训练多特征融合模型。接着将模型放在不同的农作物病害数据集中进行测试,发现识别正确率均得到了提升,提升了约1%-10%,也验证了该分类方法具有不错的鲁棒性。"
1776,远程会诊服务质量测评及优化策略研究,"随着“互联网+”行动计划的实施、分级诊疗体系的建设以及互联网技术的快速发展,我国的互联网和医疗卫生领域进行了深度融合。以远程会诊为代表的远程医疗服务已成为优化资源配置,促进分级诊疗,解决群众看病难、看病贵问题的新手段,实现了远距离问诊,使得患者就医模式进入了新的阶段,极大的帮助了医疗资源匮乏的地区,促进了优质医疗资源下沉。然而,我国远程医疗起步较晚,体系还不完善,缺乏对远程会诊质量的控制体系,尚未形成远程会诊质量评价体系。因此,如何识别影响远程会诊服务质量的关键因素、如何科学评价和提升远程会诊服务质量是远程医疗研究人员最为关注的问题。本文在文献研究的基础上,结合远程会诊服务特性,借助机器学习算法,实现对远程会诊服务质量的测评和优化模型构建。本文的主要工作体现在以下三个方面:(1)借鉴移动服务质量和医疗服务质量的研究,结合远程会诊的服务特性,构建初始的测评指标体系。引入语言信息评价,计算评价指标的梯形模糊数与评价短语之间的相似度,根据指标重要性程度识别关键指标。(2)通过机器语言算法预处理数据,将异构数据转换为标准化数据,并在此基础上构建了基于GA_BP模型的远程会诊服务质量优化模型。(3)通过案例研究对实践数据进行分析和讨论。借助控制变量的方法,观察预测结果的变化趋势,结合指标权重识别服务质量优化方向,并有针对性的提出优化策略。本文的研究成果为远程会诊服务能力的提升提供了参考价值,为远程会诊质量准确定向,提供理论指导和有益启迪,也为远程会诊服务质量的研究提供了新的思路。"
1777,针对HIV相关神经认知功能障碍诊断的临床及影像学技术方法研究,"第一部分简易智力状态检查量表诊断HIV相关神经认知功能障碍的可行性研究目的:以神经心理测验为金标准,研究简易智力状态检查量表能否替代神经心理测验成为临床诊断HIV相关神经认知功能障碍(HAND)的方法之一。方法:按照纳入排除标准,收集20l7年09月至20l8年12月期间首诊于南宁市第四人民医院感染科的艾滋病患者,共纳入未进行抗病毒治疗的艾滋病患者29例(HIV阳性组),16位男性,13位女性。与此同时,本研究招募年龄性别相匹配的正常对照组20例(HIV阴性组),12位男性,8位女性。受试者均为右利手,且患者的病情分期均为无症状HIV感染期。采用简易智能量表(MMSE)和神经心理测验(NP测验)分别对HIV阳性组和HIV阴性组进行神经认知功能评估的测试,采用SPSS20.0统计学软件分析两种认知评估量表的相关性,比较两者对HIV相关神经认知功能障碍诊断的筛查能力。结果:(1)HIV阳性组和对照组间MMSE的差异具有统计学意义(p<0.05);(2)使用NP测验得出HIV阳性组和HIV阴性对照组间在数字符号、连线测试、概念流畅性、词汇流畅性、Stroop-C和Stroop-CW共5项测试差异均有统计学意义(p0.05);(3)MMSE与NP测验的相关性较低(r=0.485,p"
1778,反复发作抑郁症患者SSRIs抵抗的预测：一项基于支持向量机的预测模型研究,"目的以既往接受过选择性5-HT再摄取抑制剂(selective serotonin reuptake inhibitors,SSRIs)治疗的反复发作抑郁症患者为研究对象,利用5-HT介导的AC-cAMP通路相关基因tagSNPs及其临床特征分别构建数据库,通过数据挖掘,寻找SSRIs抵抗(SSRIs resistance,SSRIs-R)的临床和遗传学特征,探讨早期预测SSRIs-R的方法,为抑郁症的个体化精准医疗提供理论依据。方法1.构建临床特征数据库:对857例反复发作抑郁症患者进行跟踪随访,建立包括人口学资料、临床特征和首程抗抑郁治疗的效应特征等三个方面的临床特征数据库。2.构建tagSNPs数据库:围绕5-HT信号通路相关的HTR1A、HTR2A、CREB1、BDNF、ADCY7、ADCY9、ADCY3、NOS1、PDE4A等9个目的基因,利用质谱分析,检测857例反复发作抑郁症患者9个目的基因的34个tagSNPs,构建tagSNPs数据库。3.对符合反复发作抑郁症入组标准的857例患者,按SSRIs终末疗效(HDRS-24总分减分率)筛选出302例SSRIs-R和304例SSRIs-NR患者,用于病例对照研究和机器学习的训练样本和测试样本分类。4.采用SPSS21.0 for windows软件包进行一般数据处理,tagSNPs的初级筛选采用关联分析。5.SSRIs-R预测模型的建立运用支持向量机(support vector machine,SVM)。结果1.SSRIs-R与SSRIs-NR两组临床特征的比较比较302例SSRIs-R与304例SSRIs-NR组间的临床变量发现,精神运动阻滞(c2=11.068,p=0.001)、精神病性症状(c2=13.795,p=0.000)、自杀(c2=9.559,p=0.002)、体重下降(c2=9.145,p=0.002)、首程平均耐量(c2=10.049,p=0.002)、首程疗效(c2=25.343,p=0.000)、睡眠障碍(c2=8.386,p=0.004)、残留症状(c2=9.650,p=0.002)、个性倾向(c2=18.091,p=0.000)、起病年龄(p=0.048)、发作频度(p=0.031)、发作时限(p=0.014)等12个变量差异有显著性意义,其他变量差异无显著性意义(P>0.05)。2.tagSNPs的筛选围绕5-HT第二信号通路的9个目的基因的34个tagSNPs进行分型检测,发现30个tagSNPs的基因型和等位基因分布符合H-W平衡定律(P>0.05),可进行关联分析。另有4个tagSNPs在取样人群中未检出多态性,包括rs2059336在均为TT型,rs143117860均为CC型,rs2551926均为GG型或CC型,rs889895均为TT型。3.SSRIs-R与SSRIs-R两组tagSNPs等位基因及基因型频度分布比较比较SSRIs-R组与SSRIs-NR组之间的30个tagSNPs基因型及等位基因频度,发现CREB1rs2551645、CREB1rs4675690、BDNFrs18035210、BDNFrs7124442等4个tagSNPs位点的基因型及BDNFrs18035210、BDNFrs7124442的等位基因分布在两组间的差异有统计学意义(P0.05)。4.参数优化将302例SSRIs-R和304例SSRIs-NR研究样本混合,按5:1的比例随机分为训练样本和测试样本。训练样本的样本含量505例,其中包括SSRIs-R 254例(254/505,50.3%)。测试样本的样本含量101例,其中包括SSRIs-R 48例(48/101,47.5%)。本研究利用多重交叉验证的方法和网格搜索法寻找c和γ,得出预测模型核参数取值范围在=-3~15,=-15~13的区域内,交叉验证准确度为59.60%~90.38%。5.SSRIs-R预测模型筛选将这12个初步预测变量进行随机组合,共产生11个队列,4083组合。根据每个队列中每一组合的预测准确度,灵敏度和特异度筛选SSRIs-R最佳预测模型(SSRIs-R prediction model,SSRIs-R-PM),其中以预测准确度,灵敏度及特异度均为达到60%为筛选标准逐步剔除,最终有10个预测模型入选,分别命名为SSRIs-R-PM1~SSRIs-R-PM10。6.tagSNPs对预测准确度的影响本研究纳入CREB1和BDNF两个目的基因的4个tagSNPs(CREB1rs2551645、CREB1rs4675690、BDNFrs10835210、BDNFrs7124442),将CREB1和BDNF的tagSNPs联合突变的风险合并时,一定程度上提高SSRIs-R-PM的预测准确度,SSRIs-R-PM 8的预测准确度可达87.5%。结论1.SSRIs-R和SSRIs-NR患者在临床特征上的差异,提示个体可能在病因学方面具有异质性,这些临床特征早期出现时也能一定程度提示SSRIs-R。2.CREB1与BDNF的基因多态性可能与反复发作抑郁症SSRIs-R关联。当CREB1与BDNF联合突变时,可提高SSRIs药物抵抗的风险;也提示5-HT在第二信号转导通路层面可能受基因多态性的影响,导致SSRIs临床疗效上的差异。3.基于机器学习方法训练出的预测模型准确度可达87.5%,提示可用机器学习的方法建立数学模型用于临床对个体是否对SSRIs抵抗做出早期预测;从临床或生物学角度预测某个体的SSRIs-R,为个体化用药提供依据,同时可用此来验证生物学标记的临床意义。"
1779,半监督自训练算法在乳腺癌分析预测中的应用研究,"近年来罹患乳腺癌的女性数量大幅增加,乳腺癌已成为全世界女性最常见的癌症,其死亡率仅次于肺癌。目前为止,早期诊断发现从而遏制乳腺癌的发展仍然是乳腺癌治疗的基础。伴随着人工智能领域的不断发展,利用机器学习的方法对乳腺癌医学数据进行归纳分析,探索规则,建立乳腺癌智能诊断系统已成为医疗卫生领域的研究热点。目前,建立乳腺癌智能诊断系统仍存在许多问题:首先,研究人员往往能搜集到大量的疑似乳腺癌样本,而能够确诊肿瘤良恶性的有标记样本往往需要专家花费大量时间会诊得出。智能诊断系统往往因为有标记样本的不足,导致模型分类精度不高,泛化性较差。其次,研究人员手中大量的无标记样本没有得到充分利用,如何选择出有价值的无标记样本加入训练尚具有盲目性。最后,原始的乳腺癌数据往往存在属性关联冗余的问题,不利于直接进行建模预测,研究人员也同时鲜有对乳腺癌原始医学数据进行具体的归纳整理分析。为解决上述乳腺癌智能诊断系统建立中存在的问题,充分发掘乳腺癌医学数据的价值,建成分类精度高,泛化性较强的诊断系统。本文所做的工作如下:(1)将半监督自训练方法应用在乳腺癌智能诊断中,提出了一种结合密度峰值优化模糊聚类的半监督自训练方法。该方法先对无标记样本集进行密度峰值聚类,在人工地选出聚类中心后,将新的聚类中心作为模糊聚类的初始聚类中心进行模糊聚类,从而筛选出有价值的无标记样本。实验结果表明,该方法与结合其他聚类算法的自训练方法相比分类精度有所提高。(2)对美国威斯康辛大学医院的乳腺癌数据进行了数据分析处理。通过数据可视化的方法与数据进行交互,将特征属性冗杂的乳腺癌数据进行归纳整理,筛选出决定肿瘤良恶性的关键特征属性,为探索乳腺癌的病因病理和乳腺癌早期的排查诊断提供了重要的检测方向。(3)利用改进的自训练方法对经过预处理的乳腺癌数据进行分类预测,建立了一种基于半监督学习的乳腺癌智能诊断系统。该系统能在初始有标记数据较少的情况下,通过迭代自训练,分类精度不断提高,泛化性不断加强,为乳腺癌的智能诊断提供了新的思路,促进了智能医疗的发展。"
1780,硅藻DNA条形码及微单倍型的法医学应用研究,"水中尸体死亡原因的判定、溺水地点的推断和个体识别是溺死案件法医学鉴定的重要问题,也是法医学面临的有挑战性问题。溺死是一种常见的意外死亡原因,水中尸体的发现地点往往不是其实际的溺水地点,因而溺水地点的推断工作对于寻找尸源至关重要。而在水中尸体的个体识别中,通过筛选高效的遗传标记对水中尸体的区域来源进行预测,可以有效缩小排查范围,为破案提供线索。综上,本研究建立了长江南京段冬季和秋季硅藻DNA条形码数据库用于溺水地点的推断工作;筛选出了更加高效的具有族源信息推断能力的微单倍型位点用于水中尸体区域来源的判断。硅藻是一种分布广泛的单细胞微生物,性质稳定种类繁多。在溺水过程中,硅藻随溺液进入人体,通过血液循环可以到达肝肾等器官,同时硅藻对环境变化敏感,不同地点硅藻的分布差异明显,因而硅藻检验除可以用于溺死鉴定外,还可用于落水点的推断。本研究将长江南京段的主干按照经纬度划分为10个采样点,于2016年12月至2017年1月进行冬季水样采集,2018年9月进行秋季水样的采集。研究初步建立了长江南京段冬季和秋季法医硅藻形态学分布数据库,并以形态学研究结果为基础,建立长江地区的DNA条形码数据库。秋冬季的硅藻形态学实验表明,采水点位置和季节因素也是决定硅藻分布的两个重要因素。因此有必要建立多地、长时效的硅藻检测机制进行进一步的深入探索。DNA条形码数据的研究结果表明以分子生物学为基础的条形码设计,可以大大增加水域内硅藻组成的多态性,有着良好的法医学应用前景。此外,针对电子显微镜拍照数据量大,人工处理费时费力的问题,研究利用机器学习算法证实了硅藻电镜图片自动识别有着良好的实际应用潜力。根据DNA中的遗传信息来推断个体的族源信息一直是法医学中的一项重要工作。自Kidd等人首次提出和定义微单倍型(≤200 bp)后,微单倍型在法医生物地理学中的应用潜力受到人们的广泛关注。本研究中,通过计算Rosenberg等人提出的I_n值,筛选得到了35个微单倍型位点。研究中,选择千人基因数据库中来自26个民族和5个区域的2504个个体作为参考数据库并将SGDP数据库中147个民族和7个区域的279个个体用于验证筛选位点的族源信息推断能力。采用STRUCTURE分析、主成分分析、Neighbor-Joining系统发育树构建及机器学习技术对数据进行分析。实验结果表明千人基因组数据库和SGDP数据库中人群可以被很好的区分和聚类。并且预测人群区域来源的准确率也相对较高。研究表明微单倍型在法医学族源信息推断工作中是一个很好的补充,在水中尸体的个体识别中潜在的应用前景。"
1781,基于情感分析的E-learning学习行为评估与预测方法研究,"作为我国教育信息化事业的重要部分,E-learning教学模式以其独特的开放式教育特点,打破了传统教学模式僵化的时间与空间格局,促进了优质教育资源的共享,推动了教育的普及化与个性化。该教学模式在教学方式上的改革无疑取得了巨大成功,但是其所面临的教育数据难以处理、高注册率低毕业率等问题,却是限制该教育模式可持续发展的重要难题。如何有效分析与评估学生学习行为,从而及时发现其辍学倾向并采取具有针对性的教学干预,则是提升该教学模式核心竞争力的关键性难题。本文针对E-learning学习平台教育数据难以有效利用、学习者学习行为难以准确量化评估、学习者辍学倾向难以及时发现,以及该学习平台无法采取具有针对性的教学干预四个问题,以学习者的文本数据、毕业情况等多种学习行为数据为研究对象,提出了基于情感分析的E-learning学习行为评估与预测方法。首先,针对现有E-learning教育数据中非结构化数据难以有效利用的问题,以及传统情感分析方法中所存在的情绪分析结果粒度较粗的问题,提出基于细粒度情绪分析的多极化情感评估模型。本模型基于依据情感词典分析方法,将传统情感分析方法中积极与消极的两极化情绪细化至快乐、悲伤、愤怒、恐惧、信任、厌恶、惊喜与期待8种人类基本情绪,提高了情感分析的粒度,并结合中文情感表达特点与语义关系,建立了较全面的情感量化规则,提高了情感强度计算的精度。此外,为进一步理解学习者的情感变化趋势,提取了学习者的各阶段性主导情感,从而构建了E-learning学习者的多极化情感变化链。其次,提出基于情感变化趋势的行为预测与课程推荐算法。本算法以学习者的多极化情感变化链与毕业情况之间的映射关系为研究对象,建立多元线性回归方程,在分析小批量梯度下降算法局限性的基础上,以改进的学习率热启动方法对其性能进行优化,并以改进后的算法对所建立多元线性回归方程进行求解。在此基础上,以条件概率与文本互信息度为课程筛选标准,为毕业概率较低或毕业概率出现较大幅度下滑的学习者推荐相关兴趣课程,同时,为确保所推荐课程的时效性,以学习兴趣衰减函数动态更新课程兴趣度。最后,以算法对比分析、接受者操作特性曲线分析、5折交叉验证等评估方法对本文方法进行了综合实例验证。本文所提出的研究方法,为评估与预测E-learning学习者的学习行为提供了新的研究思路,有利于及时发现学习者的辍学倾向,并以推荐相关兴趣课程的干预方式,提高其毕业率,从而优化学习者的学习体验,促进E-learning教学平台的个性化教育与有效教学的发展,对加快我国教育信息化的改革进程提供了一定参考价值。"
1782,基于LSTM神经网络在线个性化问题解答的设计研究,"2018年4月13日我国教育部发布《教育信息化2.0行动计划》,强调要构架“互联网+”人才培养模式、发展基于互联网的教育服务新模式。同年8月份智能教育2018观塘宣言发布,国内10位信息化教育领域专家也提出探索人工智能与教育深度融合,创新教育教学模式,构建智能教育新体系。应用人工智能新技术加强教育服务智能化,逐渐成为关注的聚焦点。随着人工智能新技术的发展,针对目前在线课程学习过程中学习者问题不能得到及时有效解答的现状,自动问答系统作为在线课程开展的支持服务,受到了越来越多专家学者的关注。从交互距离教育理论和个性化学习文献资料研究分析,增加对话、交互可以有效提升在线课程学习和个性化学习服务。本研究试图通过自动问答系统为媒介来帮助学习者完成在线课程的个性化学习,探索基于深度学习技术开展自动问答系统的设计研究。本文通过文献研究、基于设计的研究、观察法和访谈法进行开展。通过对文献的研究,分析国内外自动问答系统的研究现状及实现方式,确立本文研究的设计思路,再根据设计思路进一步对深度学习神经网络模型进行文献研究分析,选择适合本研究的LSTM神经网络模型。通过前期组织学习者学习测试,收集学习过程中存在的学习问题,以此为基础构建适用本研究网络模型训练的数据集,接着构建神经网络模型并进行三轮模型识别准确率的迭代优化设计研究,不断调整使得神经网络模型识别准确率达到较高的数值,支持项目实验测试的开展。接着通过程序设计通过对输入问题的相似度检测实现对学习者输入问题的识别回答。在实现自动问答之后,再组织学习者进行在线课程项目实验测试,在这个过程,通过观察法和访谈法,观察并记录学习者的实验数据,通过对实验测试数据的研究分析,探究学习者在线课程个性化问题解答对学习成效和课程内容思考深度的影响。"
1783,基于改进半监督自训练方法的高校毕业生就业预测应用研究,"在高校毕业生就业前进行预测分析,可以为提高大学生就业质量提供了方向,更好地衔接高校的招生、培养和就业工作。目前,各大高校建立了较为完善的学生信息,这些数据包含了学生的生源籍贯,学业状况、就业情况等具有价值的信息,能帮助高校有针对性地挖掘出就业与各个因素之间隐藏的联系。使用传统人工的方式管理这些信息,对时间、人力、数据资源有极大的浪费。随着计算机技术的发展,数据挖掘技术在教育领域的应用使得高校管理更加便捷。由于形势政策和学生群体风格差异导致不同届学生就业情况分布不能完全吻合,半监督分类方法可以利用无就业信息的毕业生样本进行训练,扩大训练集,使预测模型更符合真实分布。本研究将改进的半监督分类方法(Semi supervised)应用到毕业生就业预测中,并对预测结果进行验证。概括起来,本研究的主要工作如下:(1)分析和总结了目前高校毕业生就业指导的意义和目前就业指导工作存在的缺陷,通过建立毕业生就业预测模型来提高就业指导工作的效率。其次,阐述高校毕业生就业预测模型的意义,通过分析影响毕业生就业情况的因素,引进数据挖掘方法到高校毕业生的就业预测中,得出基于数据挖掘方法的预测模型基本流程。(2)从机器学习的视角介绍了常见的半监督分类算法,重点对半监督自训练分类算法进行了研究,并针对基于朴素贝叶斯的自训练算法在样本数量分布不佳的情况下分类器的精度低的情况,提出改进。改进算法将相似度计算方法引入到半监督自训练方法中,通过计算未标记样本与有标记样本的相似度――欧式距离及余弦相似度,筛选置信度高的样本加入到训练集中,不断迭代至训练好贝叶斯分类器进行分类。最后通过在选取相关数据集仿真实验,验证改进算法的有效性。(3)针对重庆市S高校的毕业生信息进行数据收集、数据预处理。在MATLAB环境下,利用改进的结合相似度的半监督朴素贝叶斯自训练算法,对收集到的数据集进行实验,将改进算法的预测精度和效率与其他算法相比较,改进算法优势明显,能够更好的预测未标记样本,为下一步就业指导提供参考。其次,使用构建好高校毕业生就业预测模型对待毕业生数据进行预测,分析其结果结合S高校的实际情况提出就业指导对策。"
1784,基于机器学习的图像视频自适应高效传输,"随着移动通信技术的迅猛发展和智能终端硬件的不断升级,以图像和视频信息为载体的应用已经成为日常生产生活中不可或缺的一部分。据预测,到2021年,移动图像视频业务将占到全部移动数据业务的78%。随着图像视频信息的爆炸式增长以及用户在多元化场景下日益提升的用户需求,越来越多的业务提供商基于有线结合无线的异构网络来进行图像视频信息的传输。这种方式下的信号在发送端对其进行发送之后,经过核心网的有线传输和边缘网络的无线传输,最终到达接收端。多样化的部署方式以及更加灵活的业务模式,让该异构网络模型在现有的传输系统中得到了广泛的使用。由于图像视频业务数据量的大幅增长以及业务场景日趋多元化,当前无线网络资源和计算能力的局限性愈发明显,传统的图像视频传输方案正面临巨大的挑战。一方面,端到端传输的环境处于不断的动态变化之中,且极易受到外部干扰,如何自适应动态变化的网络环境是端到端传输方案要面临的挑战之一。另一方面,无线传输在图像视频传输中是非常重要的一部分,而爆炸式增长的图像视频数据正使得无线带宽资源变得日益紧张。因此,研究自适应性能更好且更加高效的图像视频传输技术具有重要的意义。在线视频播放是图像视频业务中的一个重要场景,而码率自适应算法被证明是一种有效的端到端性能提升手段。该方法通过部署在客户端的码率自适应算法来对在线视频的下一个视频块的码率进行选择,从而提升系统整体的传输性能。现有的码率自适应传输大都基于对速率的预测或者对缓存占用的预设来进行衡量。然而这类方法的预测效果一般较为保守,不能最大化用户体验,同时无法对日趋复杂的多样化环境进行很好的适应。本文第一个研究内容就是针对这样的问题,提出一种性能更优的码率自适应算法。近年来,机器学习方法已经在众多领域被证明具有高效且复杂度低的特点,且可以有效解决传统方法可拓展性不高,对多样化环境适用性不足的问题。因此本文基于增强学习准确的预测能力,对客户端网络环境的多种状态变量进行在线的学习过程,从而达到更好的视频体验性能,以提升码率自适应算法对播放环境的自适应能力。同时,为了满足在线视频场景下实时性的要求,该方案通过设计网络适配算法以及设计基于复用卷积核的简单神经网络结构,既可以减弱外部输入对算法本身的影响,也可以降低算法本身的复杂度,从而共同加速神经网络的收敛过程,以满足在线视频的端到端播放需求。另一方面,日益增加的图像视频数据使得无线带宽资源正变得越来越紧张。近年来,基于压缩感知的图像高效传输正得到广泛的研究。该方法在发送端直接对稀疏后信号进行部分采样,经过信道传输后,通过部署在接收端的重建算法采样信号进行完美重构。目前已有的方法虽然有较好的传输性能,但普遍存在复杂度高且极易收到无线信道干扰的问题。针对这一问题,本文第二个研究内容提出一种基于深度学习的压缩感知图像传输方案,用以缓解无线带宽资源的紧张情况,同时完成图像在无线信道中的高效传输。该方法在发送端基站上对图像信号进行部分采样,之后将采样信号送入无线传输信道,当到达接收端时,通过部署在接收端的重构算法对其进行重构。相比起已有的方法,本文在接收端部署了一种更加高效的方法。该方法先通过一种预处理算法将信号从变换域转换到像素域,并进行初步的粗粒度重构,再通过卷积神经网络对其进行进一步的质量提升。该方法有效的降低了重构的算法复杂度,同时可以适用于任何采样率,并且可以输入任意尺寸的图像。同时,该方法对大量不同信道信噪比下的图像信号进行训练,可以有效抵抗无线信道中信道噪声对其重构产生的影响,从而完成高效的图像无线传输。"
1785,麦克风阵列下互相关函数分类的声源定位算法研究,"声源定位技术作为语音信号处理领域的一个研究热点,广泛应用于智能机器人、人机交互、智能语音识别系统等领域。传统的声源定位方法需要利用当前接收语音信号所包含的空间信息,而不依赖于预先获得的某些先验信息。在一些情形中,例如会议室或者汽车中,声源的位置仅局限于预先设定的区域内,因此可以预先测量预定区域内的代表性样本,建立数据驱动模型,将测量信号与对应的声源位置相关联。这类方法优点是它不需要对声学环境进行精确的建模,对混响和噪声具有更好的鲁棒性。本文结合麦克风阵列信号处理技术,对基于互相关函数分类的声源定位算法进行研究,提高算法在强混响环境下的定位精度。本文完成的主要工作如下:1.介绍了语音信号的不同模型,着重研究了语音信号的预处理方法、麦克风阵列远近场模型和拓扑结构;2.介绍了几种典型的用于声源定位的机器学习和分类算法,包括深度神经网络、支持向量机和K均值聚类算法,简单说明了这些算法的缺点;3.由于相位变换加权的广义互相关函数在不同位置提取的特征之间相似程度较高,造成定位准确率下降。为提高算法的定位性能,本文以互相关函数分类的声源定位算法为基础,分别采用两种改进算法:(1)引入平滑滤波器;(2)使用归一化的相位-平滑相干变换联合加权的广义互相关函数进行特征提取,改进的算法在不同位置提取的特征之间具有明显的差异。仿真结果显示,两种改进算法在强混响环境中有较好的定位性能;同时设计并实现了实际场景下的声源定位平台,验证了改进算法在实际场景下的定位性能。4.上述算法中各个属性特征对于分类决策的重要性判断是一致的,然而实际应用中不同属性与类别之间具有一定的关联性。本文在上述研究内容的基础上,引入了Fisher判别准则函数,将特征加权算法和朴素贝叶斯分类器相结合,利用Fisher判别准则函数建立各个特征属性的分类权重,通过仿真实验和实际场景实验验证了算法的定位性能。"
1786,基于多视场信息的运动物体姿态分析,"近十几年来,随着航天航空、军事武器等领域的蓬勃发展,在多视场下对运动物体进行姿态分析十分重要。姿态参数不仅能反映运动物体的运动状态,同时对分析运动物体的各项物理参数,实验判定及排除故障危险等问题具有极其重要的现实意义。本文基于此对目前姿态分析的研究现状进行了详细的介绍,以飞行器为研究对象,设计了基于级联卷积网络的关键点定位算法,以及基于BP神经网络的姿态角回归算法,并在多视场环境下对运动物体飞行器进行了实验验证。本文的主要研究内容和创新之处概括如下:1)针对运动物体的姿态分析问题,结合运动物体的几何特性,提出一种将运动物体的坐标信息作为输入特征,姿态角信息作为输出标签的算法模型,提高了姿态分析模型的训练精度与速度。2)以飞行器为例进行分析,首先基于级联卷积网络思想,设计了一种定位二维图像上目标物体关键点的算法,并引入距离度量,对传统损失函数进行改进。同时,基于BP神经网络设计了姿态角回归算法,采用平均绝对误差、拟合系数等评价标准评估模型。仿真实验表明,本文设计的姿态分析算法中预测的姿态角的平均绝对误差可控制在0.6°-1.6°间,约有98.91%样本的预测姿态角与真实姿态角的绝对误差可控制在3°内,相比于传统姿态分析算法,具有更高的预测精度。3)搭建多视场实验装置,评估本文设计的姿态分析算法在多视场环境下的预测精度。将预处理后的多个视频序列输入至训练完成的算法模型中,预测其目标物体的姿态角。实验结果表明,在多视场环境下,能较精准的预测运动物体的姿态角变化情况。"
1787,基于深度学习的情感分类与评价对象判别,"随着时代的发展,对海量信息的有效和高效处理成为了现代社会必须解决的首要问题。在此种环境下所催生出的自然语言处理(NLP)技术就是面向文本信息的一个解决手段。情感分类、评价对象判别是NLP领域研究的热点。本文致力于实现更高效的能适用于情感分类和评价对象判别任务的深度学习模型,通过对传统的神经网络模型进行相应的改进,使得在相应的NLP问题上能够有更好的效果。本文主要包含两个研究内容:结合decoder结构的LSTM-CNN神经网络的情感分类模型:作为自然语言处理的一大研究方向的情感分类就是分析和评判一个语句它所包含的情感色彩。常用的这个情感倾向可以是简单的只有正向情感和负向情感,也可以是具体的多种情感,比如,难过,崩溃、喜悦、惊恐等。情感分类对于社会舆情反应以及产品的用户回馈都具有重大的意义。常见的长短期记忆神经网络(LSTM)模型用于情感分类时,往往需要更长时间的训练,而多层卷积神经网络(CNN)运用于情感分类时,很难学习到文本的上下文信息。本文所提出的模型充分利用多层LSTM-CNN网络,其中LSTM可以“记住”序列上下文信息,CNN通过卷积核的作用可以很好地学习文本的局部信息。该模型中的Encoder-Decoder框架由多层LSTM-CNN网络作为编码器,相应的反卷积层作为译码器,Encoder-Decoder的结构将使得整体的学习更加高效。最终实验结果表明此模型在情感分类的任务中具有优异的性能。基于注意力机制的评价对象判别(ABAE)弱监督模型:伴随着日益提高的分析需求以及日益多样化和复杂化的语言环境,更细粒度的情感分析成为了研究重点。ABAE模型是一种无监督的,有效运用于类别提取的模型,它将通常在同一上下文中的单词映射到向量空间中的邻近点。然后,使用注意机制在一个句子中过滤单词向量,并使用过滤后的单词构造类别向量。无监督的ABAE模型的问题在于需要人工判别主题分类的结果,这使得很难迅速有效的达到最优的结果。针对此问题,本文通过对少量的标注数据进行卡方检测运用,得到各个词与类别的相关性,从而避免了人为评判的步骤,极大地提高了该模型的有效性。在实际数据集上的实验结果表明,该方法可以达到和原来一样的最优效果,却不需要多次的人工判别试错,该方法使得该模型更具有实践性。"
1788,基于情感分类的酒店评论文本挖掘研究,"互联网的普及与移动端的应用促进了电子商务的迅速发展,消费者在各大电商平台进行活动交易时产生了大量的行为数据,在线评论文本就是其中一种。在线评论文本是消费者对消费对象切身体验后以文本的形式反馈至电商平台,被作为大众的舆论观点导向,对此类观点进行有效情感分类不仅可以帮助消费者进行决策,还可以帮助商家对服务进行改善。目前,对评论短文本进行情感分类时,由于短文本存在特征维度高、领域差异性、表达隐含性等问题,从而影响分类的性能,本文对上述问题将已有情感分类方法进行改进研究,并用于酒店评论文本进行情感分类,主要研究内容如下:(1)针对领域情感词的差异性及基础情感词典的不完备而引起情感分类精确度不高的问题,提出一种融合语义的情感词扩充方法用于构建酒店评论文本的情感词典。爬取在线酒店评论文本作为语料库,结合种子词使用Word2vec和SO-PMI进行情感词的扩充,构建酒店评论文本的领域内情感词典,通过实验表明所构建情感词典在情感分类上的有效性。(2)构建一种基于依存句法分析与LDA主题模型相结合的方法进行特征提取。首先,使用依存句法分析结合情感词典对评论文本情感要素进行抽取;其次,利用LDA主题模型对情感要素进行特征项提取,该特征提取方法既直接考虑与主题和情感有关的特征,也间接考虑了影响情感的上下文语义信息。实验表明相比传统的特征提取该方法更具优势。(3)对文本情感分类方法进行改进,构建一种基于主题与情感特征的深度学习情感分类方法。将依存句法分析与LDA主题模型提取的特征项向量化表示与文本向量相融合,作为长短期记忆网络分类模型的输入向量进行情感分类,用来改善已有情感分类方法未考虑文本主题特征与语义情感信息对分类性能的影响。实验结果表明,该方法用于情感分类效果优于传统方法,能有效提高情感分类的性能。通过爬取携程网、去哪儿网、大众点评网站的在线酒店评论文本作为实验数据,仿真实验表明,本文所构建的领域情感词典与基于主题与情感特征的深度学习情感分类方法提高了对文本情感分类的性能。"
1789,基于神经网络的中文词义消歧研究,"词汇的歧义性是自然语言的固有特征,词义消歧作为自然语言处理的一个基础任务,其结果对信息检索、机器翻译和信息抽取等上层任务具有直接影响。通过大规模语料训练的词向量包含了丰富的语义和句法信息,将其加入词义消歧模型中,可以提高模型的准确率。随着神经网络的发展和计算机处理能力的提高,神经网络在许多自然语言处理任务中取得了重大进展,但基于神经网络的中文词义消歧研究相对较少,且已有的少数工作忽略了目标词的外部知识。故本文对于中文词义消歧任务,分别从统计机器学习方法和神经网络方法进行研究,具体工作如下:(1)提出了基于词向量的支持向量机(Support Vector Machine,SVM)中文词义消歧模型。使用词向量表示的上下文词特征和词性特征代替之前统计机器学习方法中的复杂特征,作为SVM分类器的输入特征。本文使用ngram2vec模型训练的中文词向量,在词向量训练时将字特征和ngram特征加入到上下文特征中。该模型在SemEval 2007 task5中文采样词词义消歧任务中宏平均准确率为80.44%,相对于该数据集中机器学习模型的最好结果,宏平均准确率提高2.56%;在郑州大学构建的汉语词义标注语料库中微平均准确率达到83.18%。(2)提出了基于语言知识和神经网络的中文词义消歧模型。首先提出了基于双向长短时记忆网络(Bidirectional Long Short Term Memory,Bi-LSTM)的中文词义消歧模型,模型使用Bi-LSTM建模目标词上下文语义信息,通过softmax函数进行词义分类。然后提出了融合词典信息的中文词义消歧模型,将词典中的释义和例句作为外部知识添加到神经网络模型中,借助外部知识辅助词义判断。模型通过两个Bi-LSTM分别建模目标词的上下文信息和词典信息,使用注意力算法建模两者之间的语义关系,最后综合上下文信息和词典信息进行中文词义消歧。该模型在SemEval 2007语料中宏平均准确率达到85.28%。"
1790,基于字符级卷积神经网络的民宿顾客意见挖掘,"在线评论蕴含着丰富的顾客意见信息,传统意见挖掘的方式具有数据稀疏和样本分布不均匀的问题,本文以公开在线非结构化数据为基础,通过数据的结构化抽取、无监督聚类和深度学习分类技术,以在线民宿的评论数据开展了顾客意见挖掘方面的研究,最后将多种文本分类算法进行对比实验,叙述了本文模型在情感分析上的优势,具体的研究贡献体现在以下三个方面。第一,设计了基于Requests POST和Scrapy相结合的携程民宿评论数据采集方法。该方式针对民宿板块网页的特殊结构,利用Requests POST解决网页动态加载的问题,结合Scrapy解决爬虫多线程采集的问题,通过这两种技术相结合所得到的数据,可以方便的对数据进行抽取,并将处理后的结果自动存入数据库。仿真实验表明,该方式可以增加携程民宿板块的数据采集效率,在采集速度和质量上均优于基于网页加载的Selenium技术。第二,设计了基于隐含狄利克雷聚类的民宿主题属性词典构造方法。首先民宿评论容易一句中出现多个民宿主题,以标点符号为间隔能使得分散在一段评论中的不同评价主体通过标点符号被分开,通过词性标注技术选取每段评论的名词,然后利用多种向量化方式对评论文本进行向量化,以隐含狄利克雷方法对评论主题进行聚类,建立民宿主题属性词典,对比民宿标准文件以及携程网中客栈民宿的评价指标,本文丰富各个评价指标。通过实验验证了本方法在民宿意见隐含主题挖掘中的应用是有效的。第三,提出了一种字符级卷积神经网络的情感极性计算方法。将顾客打分和评论情感进行两极映射,使用数据自动标注和基于弱监督预训练的数据增强方式自动扩充和优化数据集,实验证实了在情感分类中,使用本文的字符级卷积神经网络(C-CNN-SA)可以在不依赖分词的情况下,达到的精度和F值均高于词级粒度,并在字符级向量化分类模型中,结果显示卷积神经网络在短文本情感分类中效果最好,字符级卷积神经网络在训练速度和效果上优势明显。"
1791,基于文本挖掘的餐饮商家评价系统,"互联网的普及带动了传统餐饮业向电子商务行业的转变,越来越多的消费者选择在网络上订餐,由此产生的在线评论也越来越多。对消费者客户评论进行分析能够解决餐饮商家和消费者信息不对称的问题,让商家更了解消费者,消费者也能个性化选择。当前市面上对评论处理的平台不多,有的对评价的处理不是很细致。例如美团,有对评论中的提到的主题进行计数,按用户标记的标签进行文本分类。结合某平台上餐饮商家的结构化数据和非结构化数据的分析,开发出基于文本挖掘的餐饮商家评价系统,研究贡献包括以下四个方面。第一,以提升速度为目的的商家评价数据预处理。将餐饮网站上的商家评论作为研究数据,针对网络评论数据量巨大、数据维度多的特征对数据进行分类存储,设计出根据城市和菜品类别的主题模型。这种存储方式较原始的存储来说,分词、情感分析速度有大大的提高,并且对系统功能的数据查询效率有所提升。第二,以获取准确全面商家主题为目标的主题提取。通过特征降维处理后的数据,针对不同类别主题词的不一致,用不同类别的商家评论数据进行LDA主题提取,再根据词频和共现度筛选出餐饮的一级主题词;为了避免中文的同义词表达和主题词的全面性,利用Word2vec相似词提取得到二级主题词。这样的提取主题的方法包含了所有餐饮的共性主题,保证了主题词的全面性。第三,为了准确评价商家为目的设计的情感分析。针对一个句子中的多个主题识别,系统利用依存句法分析对评论文本进行分析,提取出句子中的主题-情感关系对。再结合HowNet情感词典对主题对应的情感进行计算,设计出每个主题评分和商家综合评分的计算方法。计算得到的评分与美团网上的评分进行对比,计算结果保持一致,证明了商家评价的准确性。最后,该系统采用B/S架构,运用Web相关技术进行餐饮商家评价系统的开发。根据评分结果设计出商家查询、商家对比、满意度分析的功能,满足当前用户和商家的需求。"
1792,谷歌知识图谱热点前沿分析及共词网络聚类改进研究,"领域热点和前沿的研究通过对文献中关键词的处理分析并可视化展示,给研究者提供一个清晰的研究重心和未来发展趋势的指导。谷歌知识图谱作为使机器拥有认知能力的核心技术,已经发展了很多年,却从未有对该领域的相关研究工作,因此有必要对谷歌知识图谱进行热点与前沿的研究。然而,由于图书情报领域“科学知识图谱”与“谷歌知识图谱”这两种概念的混淆,导致相关资料的获取和研究都有一定的困难,因此有必要对谷歌知识图谱的数据进行人工筛选。另外,由于市面上相关的分析工具在分析的过程中存在不少问题,例如网络聚类的效果不佳、缺乏效果评估等,因此有必要并针对这些数据设计出更加合适的相关算法,并将其应用到谷歌知识图谱的领域热点研究和趋势分析上。最后通过对谷歌知识图谱热点词突显值的计算,并可视化到整个时间维度上,从而得出谷歌知识图谱领域的前沿。本文提出了一种基于密度敏感的改进的谱聚类算法,解决了现有分析工具中对共词网络聚类效果不佳以及缺乏聚类效果评估的问题,在对比实验中,它的归一化互信息平均提高了0.131,聚类错误率指数平均降低了0.145。再将基于密度敏感的改进的谱聚类算法应用至共词网络聚类算法中,对谷歌知识图谱进行相关热点分析,同时与现有且较为流行的Citespace工具分析谷歌知识图谱的结果对比分析。最后本文创新式地将突显词探测算法,应用到谷歌知识图谱的趋势分析中,实现了对谷歌知识图谱未来研究方向的预测及验证。"
1793,基于机器学习的图像检索研究,"随着多媒体技术的发展,图像相比于语言、文字等表达方式等能更直接的表现事物的特点,且内容丰富没有语言鸿沟,因此海量的数字图像在互联网上以爆炸性的方式增加。如何高效迅速的从海量数据中检索出目标图像成为当今计算机视觉研究热门的方向之一。受卷积神经网络在图像识别、检测和分类任务中的应用影响,近几年一些研究将卷积神经网络应用于图像检索中,并取得较大的成功。但是现有的研究通过提取全连接层输出作为图像特征,然后进行基于统计学的数学方式度量相似度,基于这些步骤建立的图像检索模型没有充分利用卷积网络,使得检索性能较差。针对上述问题,本文详细的研究了机器学习在图像检索中的应用,并重点研究了基于深度学习的算法,分别融合最近邻和分类两个方向,利用深度卷积网络模型设计实现对图像语义特征和相似度度量融合的架构。(1)建立深度学习与最近邻算法融合的模型。首先通过迁移学习方式微调卷积神经网络参数,并采用最近邻算法进行图像间相似度度量,即由图像语义特征库建立KD-Tree。然后在此基础上建立基于图像细粒度特征的深度学习模型,通过三元组损失函数调节神经网络参数,并应用在车辆细粒度识别检索中,在数据集VRID上,分别建立基于深度学习单标签的检索模型、基于深度学习多标签的检索模型和基于深度学习细粒度的检索模型,实验证明通过对车辆的细粒度微观特征提取,能有效的检索出同一辆车的图像,实现了在车牌识别失败情况下的车辆安全监控。(2)基于KT-Tree的最近邻搜索并没有充分利用卷积神经网络,因此本文提出一种新的基于深度学习预分类的图像检索算法,在检索模型中添加分类器并保存分类信息。模型充分利用卷积神经网络,可以同时完成特征提取和图像预分类,图像预分类的结果为检索提供反馈信息,在大规模图像集中实验证明了该模型在提高检索精度的前提下并减少了检索时间。(3)在前面研究的基础上,创新性的将融合图像分类的检索模型应用到阅卷系统中,降低了联考阅卷时需要根据定位点手动分配试题的难度和成本,为更加高效的智能阅卷系统提供了一种新的思路方法。"
1794,基于改进Mask RCNN的不规则3D物体抓取点识别,"近年来由于人工成本提高,各行各业都在寻求产业升级的方法。在自动生产线上使用机器人进行自动抓取可以有效减少生产成本,提高生产效率。在工厂自动化生产线升级的过程中,对使用图像技术自动识别目标并进行抓取的研究尤为重要。卷积神经网络,机器学习在图像处理和图像识别领域取得了重要进展。相较于传统的视觉算法,卷积神经网络具有泛化性高、识别精度高等特点。基于应对自动化产业升级的需求和机器学习理论的发展,本文设计出可以识别目标物体抓取点的网络模型,以解决工业机器人自动抓取目标准确率低的问题。本文使用两级网络来生成抓取点,创新性的使用深度图像,灰度图像和目标轮廓图像同时送入网络进行训练。在设计网络前研究了卷积神经网络的经典网络结构和训练检测方法。使用类神经元激活grad-CAM方法设计实验,验证了在一般的抓取点生成网络中权重更加受到纹理信息的影响的猜想。依据卷积神经网络的浅层网络注重纹理特征的特点,提出增加边缘信息可以增加抓取成功率的假设。考虑更改图像通道信息会引起特征丢失从而降低抓取准确率的可能性,设计实验使用随机图像通道分别替换掉RGB图像中的一通道至两通道作为训练集,分别训练网络并且得到网络的准确性。得到结论:通道信息缺失的情况下会导致准确率降低,但将掩膜图像和深度图像替换到训练图像的通道中时,相对于完整图像信息只降低9.3%的准确率,此数据集具备的特征信息可以完成分类任务。通过上述实验,设计了具备两级网络的抓取点检测网络。其中第一级网络使用ResNet101作为特征提取网络,RPN作为目标分类网络,反卷积层作为掩模生成网络的Mask RCNN网络。一级网络生成目标的分类信息和掩膜图像。在得到掩膜图像和目标分类后,将灰度图、掩膜图和深度图组成新的三通道图像,送入第二级抓取框预测网络。将第一级网络预测的图像分类结果作为独热码拼接到卷积层生成的特征之后。使用RPN网络作为抓取框回归预测,全连接层作为抓取角度的分类输出。该网络最终得到87.5%的抓取点预测准确率。相较于使用RGB三通道图像作为训练集,该网络的准确率提升了11.3%。同时设计了具备8种额外目标的网络泛化性实验,验证在对确定分类之外的目标进行检测时,也可以由网络生成抓取点的猜想。最后搭建仿真模拟环境对抓取动作进行模拟,得到该二级网络可以在仿真环境中对目标实施准确抓取的结论。"
1795,基于卷积神经网络的医学图像分类方法研究,"随着信息技术和医学影像成像技术的发展,医疗大数据时代已经到来。医学图像爆炸式增长需要更多的具有丰富经验的医师完成疾病的诊断,这无疑会给医师带来沉重的工作压力,误诊漏诊情况时有发生。计算机辅助诊断系统能够克服人工识别易受主观经验、疲劳程度等主观因素的影响,不但可以提高放射医师诊断的效率,还能提高其精度。目前卷积神经网络在图像识别方面得到越来越多的应用,具有不需要过多人工干预,能够自动提取图像特征且学习能力强等优点。本文应用卷积神经网络对两类医学图像进行了分析和研究,一类是用于肺部疾病筛查的肺部X光图像,另一类是鉴定骨骼损伤的骨骼X光图像。浅层的卷积神经网络具有结构轻便、参数数量少、适用性强等特点,但是在医学图像分类效果方面不理想,本文对浅层的卷积神经网络进行了改进,提出了基于改进卷积神经网络的医学图像分类方法,经过与经典的卷积神经网络进行实验对比,验证了改进方法的优良性,有效的解决了浅层的卷积神经网络分类效果不理想的问题。针对医学图像数据量不足,训练起来容易出现过拟合的问题,将迁移学习应用到医学图像分类领域,提出了基于迁移学习的医学图像分类算法。通过与传统的随机初始化参数的模型进行对比实验,验证了迁移学习的有效性,成功地将迁移学习应用到了医学图像分类领域。在基于迁移学习医学图像分类算法的基础上提出了基于多尺度迁移学习的医学图像分类算法,经过对比实验验证了此算法的可行性。本研究在医学图像特征分析及分类方面具有一定参考价值。"
1796,多线索植物种类识别方法研究,"植物识别是从给定图像中自动识别出植物的名称。现有的大多数关于自动植物识别研究,集中于利用植物的单一器官进行植物种类识别,例如,使用花、叶或果实,或者使用单张图像识别植物。使用植物的单个器官识别植物并不可靠,因为许多不同的植物却有着极其相似的器官。对于野外直接采集的图片,通常都有着复杂的背景,所以使用单张图片很难从图片中剥离出植物最有区分能力的特征。为了克服植物图像识别准确率不高的问题,本文研究了基于图像集的植物种类识别方法,并提出了基于深度卷积神经网络的多线索植物种类识别方法。本文的主要研究内容和结论如下:(1)改进了两种基于图像集的算法并将其应用于植物识别。改进了两种经典的图像集算法,基于成对线性回归图像集分类和基于原型判别学习的图像集分类,仔细介绍了改进后的基于图像集算法的思想、算法原理和算法流程图,并将其应用于植物识别,结合植物图像集训练植物识别模型。由于植物图片的背景复杂且与待识别植物及其相似,为了更好凸显植物特征,对植物图像采用了数据增强技术来扩充图片数量。且最后两种改进后的基于图像集的植物识别模型的识别准确率为62.01%和64.22%。(2)改进了GoogLeNet的网络结构并将其应用于植物识别。提出了NewInception模块结构,并采用新的激活函数h-Swish替代传统的激活函数ReLU。在PlantCLEF2016数据集中挑选了12类植物,利用该数据训练基于改进后的GoogLeNet的单器官模型。通过对ImageNet迁移学习,并调整改进后GoogLeNet最后的全连接层神经元个数为12个,训练最优的花、果、叶和整株的单器官分类器。最后花、果、叶和整株的单分类器模型的识别准确率为82.74%,86.23%,63.25%,65.06%。(3)提出了基于改进后GoogLeNet网络的多线索植物种类识别方法。根据各个单分类器预测的标签和得分进行多器官融合识别,每个单分类器根据其识别的平均准确率具有不同的权值,植物的最终预测类别由单分类器的预测标签、单分类器给出的预测分数以及单分类器本身的权值共同决定。本文提出的多线索模型在PlantCLEF2016数据集中,对12类植物的识别准确率为92.33%。实验结果表明,基于传统的图像集识别方法在识别具有复杂背景的植物图像时,识别准确率不高,要达到更高的准确率则需要更精细的预处理工作。基于深度卷积神经网络的多线索模型的识别准确率明显高于基于图像集的植物种类识别方法。"
1797,基于深度学习的Android恶意软件检测研究与应用,"随着经济社会与通信技术的蓬勃发展,智能手机迅速普及,并已经渗透到了人们生活中,成为了人们生活中必不可少的重要工具。Android系统的开源性,使其迅速成为了智能手机应用最广泛的操作系统,同样也成为了恶意攻击的重要目标。Android软件市场的开放性,使得用户可以从不同平台下载各种Android软件,而许多非官方的电子市场的Android软件则通常容易被非法开发者嵌入恶意代码。因此研究一种有效的针对Android恶意软件的检测方法具有重要现实意义。机器学习技术如今已经被广泛应用到Android恶意软件检测的研究中,但是面对不断新增的Android恶意软件,传统的机器学习方法存在对新增的恶意软件检测能力低的问题。对此,根据深度学习具有能够通过表面特征来学习抽象的深层特征的优势,本文提出了一种基于深度学习的Android恶意软件检测方法。首先,从静态分析角度出发,提取Android软件的多种特征作为特征数据;其次,根据自编码器(Auto Encoder,AE)与深度置信网络(Deep Belief Network,DBN)的优势构建AE-DBN模型进行特征学习和恶意软件检测;再次,通过实验证明本文方法的有效性;最后,把该模型应用到贵州省信息系统安全测评实际工作中,对近期20个被测评单位的Android软件如:和贵阳、贵州好行、哆达达、贵州通村村II等进行了安全评估,获得了较好的运用效果。本文完成的具体工作和创新点如下:详细介绍了Android系统架构和安全机制;分析了Android安装包的组成,恶意软件类别以及Android软件的分析方法,并对深度学习的自编码网络和深度置信网络的原理进行了研究。针对传统机器学习方法存在对新增恶意软件检测能力低,且在恶意软件检测研究中特征工程复杂的问题,提出了基于AE-DBN的Android恶意软件检测方法。为了能够进一步提高Android恶意软件检测的准确率,根据Android软件的特征信息对于恶意软件检测的重要意义,提出利用权限、组件、意图和敏感API等多种特征来作为恶意软件识别的依据,并对提取的原始特征数据进行了转化。构建AE-DBN模型则是根据AE具有不同维度的空间映射能力将其用来对原始特征向量进行降维,特征学习并抽象出主要特征。在此基础上,再将DBN作为深度学习分类器,通过对分类器进行训练、参数优化,得到最优模型。通过将多特征与单一特征作为检测依据,用实验证明了本文提出的使用多特征的方法比仅使用单一特征更能表现应用程序的行为,能够提高Android恶意软件检测的准确率,有助于Android恶意软件的检测。并将本文方法与DBN,SVM和KNN进行比较,证明了对于Android恶意软件的检测,使用深度学习取得的效果比使用传统机器学习方法取得的效果更好,该方法提高了Android恶意软件检测的准确率,降低了误报率。将本文提出的检测模型应用到实际工作中,证明了本文的方法能够对Android恶意软件进行准确识别,并且具有一定现实意义和实用价值。"
1798,基于遗传算法的模型参数选取及其在文本分类中的应用,"随着计算机技术的不断发展,信息数据大量增加,甚至呈指数级态势迅猛增长。有效利用这些信息数据的难度也随之增加。同时,在这些信息数据中还存在大量的无用信息以及有害信息,为处理信息的过程带来了极大的负面影响。因此,如何高效地利用信息数据,已经成为了机器学习领域的研究热点。此外,文本作为一种常见的信息数据形式,如何有效地对文本数据加以分类,则是文本信息处理过程中的重要任务。为了提高文本分类的快速性和准确性,针对分类效率及分类准确率的问题,本文采用了一种将遗传算法(GA)和支持向量机(SVM)相结合的文本分类方法。该方法将支持向量机的参数看作遗传算法的一个染色体,并进行二进制编码,将支持向量机的分类准确率用作遗传算法的适应度函数,对每一个个体适应度进行评价,并通过选择、交叉和变异的遗传操作,得到对文本分类数据最优的支持向量机参数,最后利用带有最优参数的支持向量机对属于既有类别的文本数据进行分类。一般情况下,对于新进的文本信息数据,我们可将其归入既有类别,然而既有类别往往无法满足大量新进的文本信息内容,即新进文本数据的类别往往会超出既有类别的范围。因此,如何有效地判断新进文本信息数据是否可以分类至既有类别,同时又可将不属于既有类别的文本信息数据进行分群处理,新增不属于既有类别的群聚类别,同样具有一定的实际意义。针对新进文本信息数据无法被分类至既有类别的问题,本文提出了一种渐进式分群方法。首先利用遗传算法选取合适的特征词组合来训练既有类别文本信息的支持向量机,并用测试文本信息将属于既有类别的文本信息数据进行分类;然后对于未分至既有类别的文本信息进行分群,利用遗传算法进行分群群数的最优化,并且选取模糊分群法(即FCM)的最佳分群中心点。最后,使用效果衡量指标Precision、Recall以及F-measure评估本研究的效率及分类准确率Macro-average和Micro-average。实验结果表明,使用GA-SVM方法可以有效地提升分类效果,而使用GA-FCM方法进行分群也可以取得较好的分类效果。"
1799,基于条件随机场与改进LSTM的短文本挖掘研究,"随着互联网技术的不断发展,诸如微博、QQ、微信等社交平台,京东、淘宝等网购平台,可以说互联网的产物层出不穷。而在日常生活中,人们日渐频繁的上网行为,通过这些平台发布的评论形成了散布在互联网中数量级巨大的短文本数据。挖掘这些短文本数据中蕴含的丰富情感观点以及态度,对于政府部门进行舆情监控、卖家制定营销策略以及买家做出购买决定等具有重要且明确地指导意义。短文本数据往往呈现出篇幅较短,上下文特征稀疏以及语言表达口语化等特点,这为短文本数据挖掘带来了巨大的挑战。近年来,条件随机场与深度学习模型在图像处理、文本挖掘以及个性化推荐系统等领域的应用越来越广泛。条件随机场是一种基于条件概率分布的模型,克服了标注数据时常见的标记偏差问题,可以有效地提取评论文本中包含的评价对象等相关信息,而深度学习模型可以在弱监督下,主动学习评论文本中包含的情感倾向信息,这些优势决定了两种模型在短文本挖掘领域受到的关注度越来越高。由于评论文本体现出的情感倾向,与文本中的评价对象有着密切的联系,本文在条件随机场与深度学习模型的基础上,分别提出了针对于短文本评价对象识别与情感分析两个方面的短文本挖掘方法。本文的工作主要有:(1)针对短文本数据上下文特征稀疏、语言表达口语化导致的语法运用缺乏准确性,语法特征很难发挥作用的情况下,本文提出了基于词特征与语义特征的评价对象识别方法。该方法是在条件随机场模型中引入语义特征,捕获评论文本中类似于“施事者+形容词性情感词”、“动词性情感词+受事者”形式的结构,然后将该特征转化成特征函数,训练一个特定的条件随机场模型,最后将语义特征与其它不同类型特征进行组合,分别训练得到各自组合对应的条件随机场模型,根据模型的识别效果找到最佳的组合特征。通过在酒店评论语料与手机评论语料上进行实验,相较于引入语法特征,语义特征的识别效果在准确率(P)、召回率(R)、F值上均有提高,表明了引入语义特征的有效性,并且将词特征与语义特征进行组合取得的识别效果最佳。(2)由于短文本上下文特征稀疏,而且句子中的每个词语对情感极性的影响并不相同,本文针对这一问题提出了基于Attention-BiLSTM模型的短文本情感分析方法。该方法利用标准的LSTM模型对句子进行正反两个方向的建模编码,并且引入Attention机制,为句子中比较重要的词语赋予更高的权重。考虑到句子中不同评价对象可能对应不同的情感极性,本文又在隐层向量输入Attention层之前融入了评价对象信息,对模型作了进一步的改进。通过在SemEval 2014 Task4中的餐厅评论语料上进行实验,与LSTM、BiLSTM以及TD-LSTM模型相比,所提模型取得了更高的准确率。"
1800,基于改进的文本相似度算法的中文文本分类技术研究,"随着大数据时代的到来,各种类型的数据呈几何级数增长,如何在海量的数据中挖掘出真正有价值的信息就成了重中之重。而对于文本数据,如何对繁多的数据进行高效、准确的分类十分关键,这就需要我们对文本分类技术进行深入的研究和分析。另外,文本分类技术作为自然语言处理中的关键技术,也是实现许多常用应用的前提和基础,诸如问答系统、情感分析、关系抽取等等。中文文本分类技术虽然起步相对较晚,而且面临更加复杂的语法分析问题,但随着相关文本处理算法的研究和改进以及数据运算性能的提高,中文文本分类技术也取得了长足的进步和发展。本文先是对比分析了几种基于文本相似度算法的文本分类技术,然后说明了中文文本独特的语义、语法结构,即中文文本是以词语作为句子含义表述的基本单元;中文文本中不同词性的词语所包含的信息量差异较大等特点。基于此,对中文文本分类中的文本相似度算法进行了改进,采用了基于统计学和基于语言学相结合的方法来计算中文文本相似度。另外,在数据预处理之后进行中文分词时对现有的分词方法进行了改进和优化,并结合实验数据特点对常用的评价标准也进行了改进。最后通过对比实验和分析,基于改进后的文本相似度算法的中文文本分类方法在最终实验中取得了72%的准确率,和基于向量空间模型的相似度算法的中文文本分类方法相比提高了近20%,表明了改进后的中文分词方法和基于词性标注和词向量模型的文本相似度算法在中文文本分类中确实能够取得更为理想的分类结果。"
1801,云端卷积神经网络算法的安全增强机制研究,"机器学习即服务(Machine Learning as a Service,MLaaS)是一种全新的云端服务模式。在该服务模式下,云服务提供商通过将机器学习模型部署在云端来便捷地为广大用户提供各种基于机器学习的服务,例如图像分类、语音识别、在线翻译等。云端的机器学习模型一般来说有三种获取途径,第一种是云服务提供商自己进行部署来为用户提供免费或付费的服务;;第二种是第三方将模型托管到云端来为用户提供服务,因此模型的所有权是第三方;第三种是用户自行训练模型,即云端提供计算服务来根据用户提供的训练数据和机器学习代码来为用户训练模型。无论是哪种部署方式,该服务都需要直接获取用户的数据来驱动机器学习模型,即数据需要上传至云端。然而,当用户的输入数据包含个人隐私时,例如人脸图片和医疗数据等,这种服务模式则会对用户的隐私构成直接威胁。为了解决这一服务模式下的安全风险,研究人员已经提出通过使用安全计算技术来保证隐私数据以密文的形式在云端进行计算,从而使得云端无法获取明文隐私数据。然而,由于安全计算技术的开销往往较高且云端模型的计算较为复杂,导致这种方法的计算和通信开销较大。本文关注用户在使用云端部署的机器学习模型时的隐私保护问题,具体地,本文研究用户如何在不泄漏自身数据的情况下使用云端部署的卷积神经网络模型。针对该问题对应的不同场景和需求,本文提出了安全高效的卷积神经网络算法和模型输出获取算法,来解决云端部署卷积神经网络时的安全和隐私问题。本文的主要贡献如下:1.安全高效的卷积神经网络算法:本文通过分析卷积神经网络中不同神经层的计算特点提出了针对性的安全计算方法。对于卷积层,本文使用快速傅立叶变换来对用户输入数据和云端模型参数进行预处理,使得云端能够在同态密文域中高效地对用户的隐私数据进行计算;对于全连接层,本文通过将其转换成等效的卷积层,来使用提出的卷积层安全算法对其进行高效实现;对于激活层和池化层,本文使用安全两方计算方案设计了安全实现算法,并通过优化处理逻辑减少了这两种神经层的操作,从而提高了计算效率。综合来看,本文同时使用了全同态加密算法和安全两方计算方案来共同完成卷积神经网络模型的安全实现。2.安全高效的模型输出获取算法:本文通过分析两种不同场景下的模型输出获取需求和安全性要求,提出了对应的两种不同的解决方案。对于用户仅需要获取云端分类标签的场景,本文提出了一种使用全同态加密的安全计算协议来保证用户在获取云端分类标签的同时无法获取云端输出的其它信息;对于用户需要同时获取云端分类标签和对应概率值的场景,本文提出了首个基于安全两方计算的安全实现协议,并通过提出的简化定理对其进行了优化。对于提出的算法,本文均进行了安全性分析或证明,并通过充分的实验及与相关工作的对比来证明方案的有效性。"
1802,基于深度学习的异常检测模型研究,"异常检测的基本目标是区分出偏离整体数据特征的稀少数据,在现实中具有重要的研究意义和应用价值。随着大数据技术的蓬勃发展,数据的维数和数量都有了质的提升,传统的异常检测模型已经不能适应当下的异常检测需求,基于深度学习的异常检测模型逐渐成为研究热点。混合模型和生成模型是深度异常检测的主要模型。混合模型结合特征降维算法和传统异常检测算法,使得检测效率有所提升。生成模型通过学习生成训练数据进行表征学习,应用于高维数据空间中的异常检测。针对现有深度异常检测模型的优缺点,提出两个改进深度异常检测模型。论文主要工作如下:(1).对深度异常检测相关工作的讨论和分析介绍了深度学习的发展现状,对深度学习在异常检测领域的相关技术进行了归纳总结。深入研究基于重构误差的异常检测技术和基于混合模型的异常检测技术,并分析了优势与不足。(2).基于多粒度扫描和自编码器的异常检测模型首先提出随机超平面的隔离机制以改进孤立森林算法,提高对复杂数据模式中局部异常数据的检测能力。其次提出多粒度扫描机制进行特征选择,利用自编码器进行特征提取,构造出两个混合模型。最后在KDD99和P53Mutant数据集的实验评估中,混合模型提升了iForest的稳定性和检测性能。(3).基于优化对抗自编码器的异常检测模型首先阐述对抗自编码器在异常检测中存在的问题。其次利用评估网络优化对抗自编码器。最后在图片数据集MNIST和CIFAR-10中进行异常检测实验,与混合模型的对比实验表明,在图片异常检测领域,对抗自编码器比混合模型更有优势。最后对论文进行总结与展望。"
1803,基于深度学习的多因子股票价格预测方法研究,"随着社会经济的日益发展与进步,股票市场的日益丰富与繁荣,数据显示股票投资者的数量逐年增加,因而对于股票的相关分析需求日益突出。股票价格预测是股票分析领域的关键之一,然而目前诸多关于股票价格预测的模型与方法的效果不尽人意,并没有达到实际的应用需求。得益于近年人工智能的相关技术在金融领域受到广泛应用,也尤其推动了股票价格预测的发展。为了进一步提高股票价格预测的准确率,本文将量化选股中的多因子模型引入到股票价格预测方法中,并对一般的股票价格预测方法进行了改进。本文主要内容及贡献如下:1、针对一般多因子模型中的因子筛选方法效果不佳导致股票价格预测结果不理想的问题,本文提出了一个基于梯度提升决策树(Gradient Boosting Decision Tree,GBDT)与域显因式分解机(Field-aware Factorization Machine,FFM)融合模型的股票因子筛选方法。利用GBDT与FFM的模型特性完成股票因子筛选,提升了因子筛选的效果。方法主要包括两点:第一,利用GBDT模型的特征重构特性,重构原始特征。GBDT所构造出的新特征集合相比原始特征集合对股票价格有更强的描述能力。第二,利用FFM模型的特征交叉特性,使用GBDT所重构的新特征,进而筛选出合适的股票因子组合。最后选取真实的股票数据集进行实验,验证了该模型的可行性,并分别采用未筛选的因子组合、传统方法筛选的因子组合、单一 GBDT模型筛选的因子组合以及本文方法筛选的因子组合作为特征进行股票价格的预测,最终使用本文提出的方法筛选的因子组合的股票价格预测的准确率最高,证明本文的方法可以筛选出更佳的股票因子组合。2、针对一般长短期记忆网络(Long Short Term Memory,LSTM)模型无法接受多因子形式输入的问题,本文在一般LSTM基础上建立了多因子LSTM股票价格预测模型。通过改变一般LSTM的输入层、循环层和输出层的映射结构,并为循环层引入dropout,使得新的模型结构不仅可以适应多因子模型的输入形式,也没有导致模型训练时间的大幅增加。最后在真实的股票数据集上的实验结果表明,得益于多因子模型的引入,相比一般的LSTM模型,不仅提升了股票价格预测的准确率,同时在一定程度上也带来了更好的模型鲁棒性。3、利用以上叙述的研究成果,搭建了多因子股票预测系统,并将该系统在实际股票交易场景下进行了模拟运行,进而对本文所提出的模型与方法的实用性进行了验证。"
1804,基于卷积神经网络的绿色信贷信用评价研究,"我国金融业中履行环境责任的关键角色之一是银行,因此开发新的银行信贷产品――绿色信贷。想要发挥绿色信贷真正作用,更广泛、更顺利的发展,离不开加强绿色信用评价的研究。长期以来,我国商业银行信用评价体系不健全,缺乏高效的绿色信贷信用评价模型来控制和衡量企业的违约风险。现今,随着信息技术的不断发展,人工智能方法和机器学习模型被应用于解决绿色信用评价问题,本文尝试用尚未应用于绿色信用评价领域的卷积神经网络模型对商业银行绿色信贷信用评价做一些探讨和研究。本文以绿色信贷信用评价为研究对象,概述总结了其国内外相关研究和相关金融理论,包括可持续金融理论、企业社会责任理论,赤道原则理论和银行信用评价理论。首先总结分析绿色信贷信用评价指标的发展现状与选取原因,在此基础上,构建出包含ESG(Environment,Society,Governance)发展指标和传统财务指标在内的绿色信贷信用评价指标体系。之后,选用来自上交所和深交所中的247家上市公司的数据,并利用支持向量机,BP神经网络和卷积神经网络建立合适的商业银行绿色信贷信用评价模型,并对其结果进行了对比分析。其研究结果显示,比起传统的,只包含财务数据的信用评价模型,引入ESG发展指标的绿色信贷信用评价体系能够更好地综合反映企业的信用水平。同时,本文还发现,在没有人工干预的情况下,相对于支持向量机和BP神经网络的分类效果,卷积神经网络模型的分类预测能力更好,准确率更优。"
1805,分布式深度学习推理系统中任务调度子系统的设计与实现,"深度学习作为机器学习领域的一个重要分支,在近年来得到了工业界及学术界的高度关注,并且取得了令人瞩目的发展,在机器视觉、语音识别等领域得到了广泛应用。深度学习使用深度神经网络模型对数据进行分类和识别,可分为训练和推理两个阶段。将深度学习应用到实际的生产环境中主要关注的是深度学习推理阶段。据全球著名市场研究公司IDC估计,在未来人工智能大规模应用阶段80%的算力将集中应用于推理场景。目前有大量的相关研究致力于提高深度学习推理过程的计算效率,例如英伟达的GPU、国内的寒武纪科技研发的人工智能专用芯片以及基于FPGA的深度学习加速器等。这些工作都大大提升了单节点上进行深度学习推理的计算效率。然而面临海量数据的处理时,如YouTube等网站需要对用户上传的海量视频进行内容审查,单节点的计算能力仍显不足。一直以来,分布式系统都是提供计算力的重要途径,因此,搭建分布式的深度学习推理系统是非常必要且紧迫的,而分布式系统中任务调度子系统起着至关重要的作用,不断涌现的深度学习加速器使得分布式深度学习推理系统中的软硬件环境复杂且多变,任务调度系统必须做到对这些新型硬件的灵活支持以及调度策略的灵活调整。本文主要着眼于分布式推理系统中任务调度子系统的设计与实现,在对分布式系统中任务调度问题进行调研与分析的基础上,设计并实现了高可靠性、高效性以及高灵活性的任务调度子系统,包括任务管理机制与系统信息管理机制,任务管理主要完成任务调度的基本功能,系统信息管理则负责收集与处理各类系统信息并为任务管理提供依据。两部分的工作分别如下:1.针对深度学习应用的特点,为所搭建的分布式深度学习推理系统设计了任务调度子系统的任务管理机制,包括任务划分、任务迁移、任务监测、结果收集。同时为了应对分布式系统中固有的不稳定性,设计并实现了基于双机备份的主节点容错机制以及工作节点容错机制,实验结果表明,在使用经典网络模型对大规模数据进行处理时,系统具有良好的并行加速效果以及可扩展性,此外,集群系统在节点出现宕机等意外情况下,具有较好的健壮性。2.深度学习硬件加速设备多样性与快速迭代,导致了深度学习分布式系统软硬件环境的复杂多变,而深度学习应用对硬件的敏感性较高,不同设备在性能和能效方面相差巨大,为支持任务子系统灵活应对系统环境的复杂性和多变性,本文设计了灵活的系统信息管理机制,作为任务调度子系统的一部分,具有高度的可定制性以及平台无关性,支持任务调度子系统对各类硬件资源灵活兼容,以及依据具体场景对任务划分策略进行调整。最后,依托于所搭建的分布式深度学习推理系统,对本文所设计的任务调度子系统的健壮性、性能以及可扩展性进行验证,测试了使用多种经典的神经网络模型如alexnet、googlenet等对ImageNet数据集进行分类处理时的性能,实验结果表明,在100节点的规模之下,相比于单节点的计算性能,系统可获得37.7x至90.6x加速比,同时对系统的可扩展性进行测试,在节点规模由20节点逐步扩展至100节点的情况下,系统的加速比基本呈线性增长趋势。此外,验证了在节点宕机等意外情况下,系统仍能够正常工作,具有良好的健壮性。本文设计并实现了一个分布式深度学习推理系统下的任务调度子系统,具有任务管理的基本功能、容错机制,以及根据软硬件环境变化而进行任务调度策略调整的能力,以应对深度学习硬件以及上层深度学习应用种类繁多且发展迭代迅速的特点。"
1806,梯度下降算法中的动态采样方法研究,"前馈型神经网络的求解大多属于非线性非凸优化问题,神经网络算法的日益流行使得在优化领域非线性非凸问题的求解问题研究变的更加重要。梯度下降算法是前馈型神经网络最常见的求解算法。即使在如今深度学习盛行的年代,该方法依然被用于深度神经网络的训练。算法简单、有效、易实现,但也面临一些缺点,比如易陷入局部极小、求解过程缓慢且不稳定。在本篇论文中,我们以梯度下降算法为基础,提出一种动态随机采样的梯度下降的方法,并从理论上证明该方法可以保证解的稳定性,并通过实验也验证理论结论。本文采用的是动态采样的方法,目的是实现真正梯度的一种无偏估计逼近来代替梯度,避免随机梯度产生的噪音影响。利用梯度估计来代替真实梯度虽然可以减少求解过程的计算量,但是由于梯度估计存在方差,也就导致了一定的不精确性。相比于随机梯度下降方法和小批量随机梯度下降方法,采用这种方法不仅可以减少求解过程的计算量,而且随着迭代次数的增加,动态采样算法的梯度估计也越来越稳定,梯度估计的方差最终会收敛到零。本文证明了该方法在求解非线性非凸优化问题时具有次线性收敛性。这种方法本质上就是减少了每次迭代时梯度估计的方差,从而加速算法的收敛,减少了迭代次数。相比于方差削减算法SVRG,本文的算法具有更快的前期收敛速度和更高的后期收敛精度。最后的实验部分给出了改进的动态采样算法在收敛速度,运行时间以及计算精度的表现。在一些常见数据集上的模拟实验证明了本文方法的有效性。"
1807,基于流结构变分推断的深度生成模型研究,"在机器学习领域,主要有两种类型的任务:监督学习和无监督学习。近年来,利用无监督学习推断数据的自然结构,探索具有高效表示能力的数据生成是当前机器学习研究的热点之一。无监督表示学习的研究主要集中在深度隐变量模型的学习上,通过最大化边际似然或证据来拟合这些模型通常是很困难的,因此一种常见的方法是引入参数化的隐变量推断模型,利用变分推断最大化边际似然的证据下界(ELBO)。变分推断为生成式建模提供了一个统一框架。变分推断中一个重要的问题是如何以可伸缩的方式选择合适的后验分布,来逼近真实的复杂后验分布。具有流结构的灵活后验变换对这个问题作了进一步的扩展研究,能够逼近更为复杂的概率密度函数。然而,当数据维数增加时,较长的序列变换结构带来较大的训练方差,甚至会使模型崩溃。本文在总结前人的工作基础上,在归一化流模型中嵌入动态路由机制,提出了动态路由流变分推断算法。该方法引入耦合系数保证了函数变换的多样性,推断效果相比标准的归一化流结构实现了进一步提升,某种程度上减轻了变分自编码器KL散度项消失和后验概率塌陷的问题。同时,将高维随机变量拆分成子模块,并对子模块间权重进行共享,通过协议路由组合了每个子模块的表达能力,实现了一组加权混合函数变换。并且该方法很容易借助TensorFlow等实验平台实现并行处理,提高推断效率。实验结果表明,动态路由流变分推断模型在推断效果和后验分布估计上均有显著提高。动态路由流变分推断算法,用给定的有限个样本来推断真实数据的概率结构,计算并逼近隐变量的后验分布。引入一种灵活的先验更新机制,有效的约束了模型平均绝对偏差,借助于耦合系数学习潜在空间表示从而增强模型的推断学习能力。"
1808,基于最大间隔和半监督学习的偏标记学习算法研究,"在机器学习中,偏标记学习是一种重要的弱监督学习框架。在该学习框架中,训练示例不再具有单一明确的标记,每个训练示例的真实标记被淹没在候选标记集中,并且真实标记在学习过程中不可获知。偏标记学习问题最棘手的地方在于示例的真实标记被淹没在非真实标记之中,并且非真实标记会对学习过程产生一定的干扰。解决该问题有两种思路:采用消歧的方法和采用非消歧的方法,其中采用消歧的方法又可以分为平均消歧和辨识消歧。采用消歧思想的偏标记学习方法是从每个训练示例的候选标记集中找出对应的真实标记。其中平均消歧的思想是将示例的每个候选标记都赋予相同的权重,通过学习模型在每个候选标记上的输出来达到消歧的目的;辨识消歧的思想是将示例的真实标记视为一个隐变量,通过不断迭代更新的方式来优化目标函数,进而达到消歧的目的。采用非消歧思想的偏标记学习方法是将训练示例的候选标记集作为一个整体进行处理,利用纠错输出码来解决偏标记学习中的多分类问题。本文分别从辨识消歧和非消歧两个角度对偏标记学习展开研究,主要的工作内容如下:第一,采用辨识消歧的思想,结合最大间隔准则,本文提出了一种偏标记学习算法PL-MM。该算法弥补了PL-SVM算法的不足,将示例的候选标记之间的差异作为模型训练的一部分。PL-MM算法不仅对示例的候选标记在模型中的最大输出与示例的非候选标记在模型中的最大输出之间的间隔进行优化,而且对示例的候选标记在模型中的最大输出与示例的候选标记在模型中的其他输出之间的间隔进行优化,来达到偏标记学习的目的。对于优化问题,PL-MM算法采用了改进的次梯度Pegasos算法求解,通过不断迭代更新的方式优化模型参数,完成了模型的学习。第二,采用非消歧的思想,结合半监督学习,本文提出了一种偏标记学习算法PL-S2ECOC。该算法通过构造无冗余的编码矩阵,将偏标记学习中的多分类学习任务拆分成一系列二分类学习任务进行求解。在编码阶段,首先PL-S2ECOC算法构造了一个无冗余的编码矩阵,使得编码矩阵中不存在相同或者互补的列编码,保证训练得到的二分类器互不相同。然后PL-S2ECOC算法采用半监督学习器作为二分类学习器,使得每一个二分类器的学习都能充分利用整个偏标记训练集。最后通过训练好的半监督学习器来预测测试示例在二分类问题中的类别标记。在解码阶段,PL-S2ECOC算法先用二分类学习任务中没有监督信息的示例来构建加权矩阵,再通过加权损失解码的策略对测试示例生成的码字进行解码,损失最小的类别标记为测试示例的预测标记。实验表明,与多个偏标记学习算法相比,PL-SVM算法和PL-S2ECOC算法在人工改造的UCI数据集和真实的偏标记数据集中都表现出了良好的性能。"
1809,基于用户画像的UGC质量预判方法,"随着大数据时代的到来,互联网数据量已经成爆发式增长。人们可以随时随地以任何形式的设备接入互联网,对网络信息进行搜集、利用和传播。互联网信息量的剧增,为用户带来高质量内容的同时,也带来了无序异构、难以利用的低质量内容。如何对低质量UGC(User-Generated Content)进行及时有效地评估和鉴别,以及对高质量UGC进行有效地管理和组织,对互联网信息环境的健康发展有着较大的影响。目前,在UGC质量评价与控制研究方面,大多是以UGC的内容本身为出发点,用户行为因素没有得到应有的重视,也鲜有将内容、行为两者结合起来进行综合性的研究。本研究拟从社交网络用户的信息行为角度出发,在对用户行为与UGC质量关系的挖掘的基础上,筛选出产生低质量UGC的异常行为数据,为用户构建个体画像,通过采用机器学习算法,对用户画像数据进行训练,得到基于用户画像的UGC质量预判模型,从而实现对用户未来UGC质量的有效预判。本研究全文共分为六个章节,第一章和第二章是对国内外UGC相关研究和理论基础进行文献梳理;第三章和第四章主要是对用户画像原理及构建方法和基于用户画像的UGC质量预判模型的构建,通过分析与挖掘用户在社交网络中与UGC相关的行为,对用户的异常行为进行识别,并进一步筛选出产生了低质量UGC的异常行为,为用户构建基于低质量UGC异常行为的个体画像,建立起基于用户画像的UGC质量预判模型;第五章是实证环节,通过编写爬虫进行数据采集以及对数据进行预处理,对模型的有效性和效果进行验证;第六章是总结,在总结全文的基础上对未来进行展望。由于目前对低质量UGC的判定尚没有统一的评估标准,致使本研究中存在一定程度上的主观性。同时,没有将用户的即时数据动态更新到用户画像模型中,这对模型的准确性有一定程度上的影响。因此,未来的研究可以在建立低质量UGC的统一评判标准的基础上,更准确地识别用户产生低质量UGC的异常行为,并动态地将即时数据更新到用户画像预判模型中,可以提高UGC质量预判的精准度。"
1810,基于集成学习的上市公司高送转预测模型及投资策略设计,"近年来,我国证券市场的高速发展催生了一批题材股,根据重大事件的不同分类,可以分为资产重组板块、WTO板块以及新能源板块等等。在这些众多题材股中间,高送转这一题材无疑是中小投资者强烈追捧的对象,但同时也产生了一些市场乱象,导致投资者盲目炒作高送转股票。此时,准确预测下一年可能实施“高送转”行为的上市公司,并筛选出相应的标的加入组合,设计出高效稳定的投资策略就具有很大的现实意义。本文尝试对基于集成学习的上市公司高送转预测模型及投资策略设计做一些深入的探讨。结构安排上,第一章主要阐述本文研究的背景、研究的意义、研究内容和方法以及主要贡献等内容;第二章梳理了国内外学者对“高送转”预测模型主要影响因素和投资策略的相关研究成果,以及介绍了相关统计学习方法,包括特征选择、逻辑回归模型和支持向量机SVM算法;第三章从“高送转”现状分析为出发点,主要剖析高送转的界定、当前我国上市公司分红送转流程和历年“高送转”基本情况回顾,为进一步的实证分析铺路,提供现实案例依据;第四章首先从初步选定的四种影响因子指标出发,通过数据预处理,包括数据缺失值和标准化处理,其次运用基于树和递归特征消除的特征选择筛选出影响“高送转”的6个主要因子,最后创新性的运用逻辑回归和支持向量机SVM的集成学习模型,为预测下一年的高送转提供了一种高准确率、低波动率的方案;第五章从上述集成学习模型出发,筛选出各年度预测的股票,并结合最佳持仓时间进行样本外回测分析,研究结果表明能取得较高的超额回报收益率;第六章得出本文的研究结论,并指出研究的不足和未来的研究方向。得出的结论主要为:我国“高送转”事件投资时间段较为固定,一般为“高送转”预案公告日前两个月左右,且该事件具有很强的可预测性;通过对“高送转”行情内在规律的分析,将每年“高送转”预测标的股构建的组合进行样本外测试,得到的组合收益率效果明显优于同期沪深300指数收益率。"
1811,对P2P网贷平台信用风险的研究,"本文所指的P2P网贷平台信用风险是指以P2P网贷平台为主体,出现延期兑付、提现困难、经侦介入、平台关停跑路等不能及时偿付投资人利息及本金的信用风险事件。为规范我国互联网金融的发展,保护投资者的合法利益,优化市场监管体系,本文对P2P网贷平台信用风险的研究,将各类平台按信用风险情况的不同进行等级划分,分析各类平台的特点并筛选关键信用风险指标,形成针对P2P网贷平台的信用风险预测模型,以指导投资者进行决策,并为监管者提供预警和建议。本文所基于的数据挖掘视角,具体是指运用了数据挖掘技术中,当前最经典的两种算法――无监督学习和有监督学习,其中无监督学习主要运用了K-means聚类和层次聚类,有监督学习包括支持向量机和决策树。相较于传统信用评级方法(本文中具体指专家打分法、主成分分析法和层次分析法),数据挖掘方法具有三方面的优势:第一,不需人为设定指标权重和变量的等级区间,排除了专家打分法和主成分分析法固有的主观性影响;第二,机器学习算法直接根据数据内部联系,探寻数据点内部的规律与关联,不依赖前人研究经验,有可能得到具备不平凡性的结果,也更适用于在我国快速发展、具备显著动态性的P2P网贷行业评级领域;第三,机器学习算法调用简便、建模速度快,方便对比不同类型提升算法的准确性,且随着训练集的扩充,预测精度将不断提升。本文首先利用无监督学习方法对搜集的268个平台、根据15个指标进行聚类分析,得到每类之间最大不同且每类内部各平台最大程度相似的5种类型,并分析各类型的主要特点,得到对不同信用风险等级分类贡献度最大的关键指标。第二步运用有监督学习方法,首先利用SVM对无监督学习方法所得结果进行验证,然后通过已进行标签化的数据,包括正常、经侦介入、延期对付三类平台,训练出有监督学习模型,并对比SVM、ID3决策树、CART决策树以及C4.5决策树模型在这一领域的适用性,利用这些模型可对其他的无标签数据进行识别和划分,实现一定程度上的风险预测功能。"
1812,基于XGBoost算法的个人信用评分方案策划,"近年来,随着经济的快速发展,人们的消费观念也随之改变,人们越来越倾向于提前消费,越来越多的人向银行或者商业公司等金融机构申请贷款,申请人往往关心能否被授予贷款。银行等金融机构则关注申请人是否能按事先约定的时间偿还贷款,他们应用信用评分模型来作为评估个人信用评分的工具,判断是否将贷款授予申请人,同时预测申请人是违约顾客还是信誉顾客。如何将银行等金融机构的损失降到最小,使利润获得最大,是信用决策者一直关注的问题,因此,建立合适有效的信用评分模型显得尤为重要。本文主要针对当下个人信用评分体系发展中所存在的问题,试图在原有个人信用评分系统的基础上进行优化改善,将机器学习竞赛中用到的数据接入个人信用评分体系中,并将所选指标进行适当删减后通过机器学习模型剔除个人信用评分方案,从而形成一套统一的、联动性好、共享性强的个人信用评分体系。传统的信用评分以逻辑回归为主要模型,其过程主要包括变量分箱、变量的WOE(证据权重)变换和变量的信息价值(IV值),最后进行逻辑回归估算。本文依据前人对信用评分的探讨以及信贷领域从业人员的建议,将数据中与逾期与否相关性较大的自变量进行筛选构建指标体系,使用XGBoost进行建模。进一步,利用stacking验证了XGBoost在模型的拟合效果上具有优越性。再则,针对本文的非平衡数据,提出Ensemble-XGBoost算法将概率转化为个人信用得分。最后将模型的评估结果与逻辑回归、支持向量机、多层感知机和随机森林进行比较,验证方案的合理性及可用性。"
1813,基于相似性指标的复杂网络链路学习预测,"链路预测一直是复杂网络科学领域研究中的一个热点问题。大多数现有的复杂网络链路预测算法主要是基于单个相似性指标来进行研究,然而,它们的应用范围都有各自的局限性和分离性。针对这一问题,本文研究了在机器学习若干算法的框架下,基于四个相似性指标融合的复杂网络链路预测问题。主要的研究工作包括以下两个方面。(1)基于四种相似性指标,即局部信息-CN、路径-LHN-II、随机游走-COS+和矩阵森林指数-MFI,本文通过提取复杂网络中任意两个节点的特征,构造出特征向量,并应用机器学习中的随机森林算法进行模型的训练学习,提出了一种新的复杂网络的链路预测算法。以美国航空网络为例,对比已有的基于单个相似性指标所得到的AUC值,发现本文所提出的算法AUC值有所提高,稳定性更好(2)为了进一步提高链路预测的精确度,本文将集成学习的思想引入复杂网络链路预测研究领域。通过逻辑回归算法和Xgboost算法对上述融合性指标构建基模型,每个基模型得出网络节点对是否存在连接的概率特征,并在此基础上再次利用逻辑回归算法对此概率特征进行Stacking集成训练模型。最后,以真实的美国航空网络和线虫神经网络为例,对比已有的算法,实验显示本文所提方法的AUC值有提升,且具有更好地稳定性和召回率。"
1814,考虑数据分布特征的多元数据完备化方法研究,"在大数据时代,数据缺失的情况经常发生甚至是不可避免,不完备数据会影响到数据统计分析。若数据完备效果不佳,数据信息不能得到充分有效的利用。因此,缺失数据的处理是数据质量的关键影响问题,不完备数据的完备也是一项具有价值的研究。本文首先综述了国内外关于不完备数据的研究方法,阐述了统计学、聚类、智能化三类完备化方法的相关理论。其次,通过构造函数集实验证明了数据分布特征对数据完备化效果影响较大;再介绍了数据完备的BP神经网络方法,是利用DBSCAN密度聚类方法对样本数据进行分类,分析其分布特征,剔除噪声数据选择训练样本,运用BP神经网络拟合数据属性间的非线性关系,预测数据缺失值;最后,分别对小麦种子和鸢尾花卉两个多元数据集的数据进行处理,选择一定的观察值作为实验数据,将完备的实验数据某一属性或者某些属性作为缺失项,运用最小二乘法、K近邻、考虑数据分布的BP网络方法和不考虑数据分布特征的BP网络方法进行完备化实验,预测缺失项的数值,计算准确率,比较四种方法的完备化效果。通过实例数据集分析可知,考虑数据分布特征的BP神经网络数据完备准确率最优。"
1815,基于LSTM网络的设备健康状况评估与剩余寿命预测方法的研究,"随着科学技术的发展,航空航天、制造业、能源、冶金等领域的设备系统日益智能化、复杂化,传统维护策略存在着“维护不足”或“维护过剩”等问题,难以满足实际维护需求。为了保障设备系统安全可靠运行,在当前大数据时代背景下,针对设备系统复杂工况应用场景,研究基于数据驱动的故障预测与健康管理(Prognosis and Health Management,PHM)方法具有重要的意义。PHM的核心内涵是,基于状态监测数据,借助智能化的算法模型,实时评估系统健康状况及预测设备剩余使用寿命(Remaining Useful Life,RUL),并据此制定维护计划。长短期记忆(Long Short-Term Memory,LSTM)网络作为典型的深度学习模型,由于其对时期依赖特征的提取优势,促使其在机器翻译、时间序列预测等领域得到广泛应用并取得了较好成绩。因此,本文针对复杂工况下设备系统PHM的核心问题,结合LSTM网络,深入研究了基于数据驱动的健康状况评估建模方法和RUL预测方法,具体内容如下:1.研究了一种基于LSTM网络和变分自编码器混合模型的健康状况评估新方法。该方法以无监督方式训练,一方面通过引入LSTM网络,可有效提取监测数据中的长短期时间依赖特征:另一方面结合变分自编码器(Variational Autoencoder,VAE),可将特征数据映射到连续隐空间中,实现深层次的特征提取,同时对多工况切换干扰具有很好的鲁棒性。本文基于PHM08数据集进行算法性能验证,并与传统建模方法开展了对比实验。实验结果验证了其有效性和优越性,对比实验表明,本文所提方法具备更好的单调性和鲁棒性。2.研究了一种基于多层LSTM网络的RUL直接预测方法。传感器监测数据本质上就是时间序列数据,结合LSTM网络处理时序数据的优势,本文通过时间窗滑动法构造样本,并设计了基于多层LSTM网络的RUL直接预测框架。在PHM08和C-MAPSS两个公开数据集上开展了验证实验,实验结果表明多层LSTM网络相较于传统浅层模型取得了更高的预测精度。3.设计并开发了基于Azure云平台的健康管理系统。基于本论文的主要研究算法,以涡轮发动机设备系统为应用研究对象,搭建了基于Azure云的涡轮发动机健康管理系统,并对其核心功能模块进行了验证测试。上述研究结果表明,针对复杂工况下设备系统PHM的应用场景,结合深度学习理论,本文提出的基于LSTM-VAE健康状况评估新方法与多层LSTM网络的直接RUL预测方法,一定程度上解决了传统方法存在过多依赖领域专家经验、深层特征无法获取以及不具备通用性等问题,通过在PHM08等公开数据集上进行比较测试,取得了更好的结果。"
1816,基于ARIMA-GARCH和SVR组合模型的股指预测研究,"随着大数据时代的到来,人们对金融市场的认识进一步深化,金融数据预测成为经济学、统计学和计算机科学研究的热点话题。如何能准确地预测金融资产的价格,对社会经济发展具有重大意义。对金融市场波动性的深刻描述一般是从ARIMA-GARCH模型开始的。然而,传统的时间序列ARIMA-GARCH模型对非线性因素的把握存在一定的不足。而诸如支持向量机等机器学习方法,对数据有着更少的假设,并且能检测数据中的非线性模式,这就克服了传统方法的线性限制。因此,这些方法被普遍用于处理金融市场的非线性和波动性。考虑到ARIMA-GARCH模型处理时间序列数据条件异方差的优势,以及支持向量回归(SVR)处理非线性数据的优势,本文提出SVR-ARMA-GARCH模型。它是ARIMA-GARCH模型和SVR模型的组合模型,是传统时间序列分析和现代机器学习模型的组合。同时,本文还提出了另一种组合模型GARCH-SVR模型,以便后续对若干模型进行比较。为了检验模型的性能,本文利用ARIMA-GARCH模型、SVR模型、GARCHSVR模型和SVR-ARMA-GARCH模型,对股票指数进行预测研究,检验模型的性能。同时,特征选择是也是SVR的重要问题。本文利用股票技术分析指标和特征选择算法,以此来选择SVR中的变量,并利用多组股票数据构建四个模型并利用模型评价指标对其进行评价。实证结果表明:(1)SVR-ARMA-GARCH模型在四个模型中预测精度最高,加入了SVR预测结果的SVR-ARMA-GARCH模型比ARIMA-GARCH模型的MAE、RMSE均有明显地提升。(2)在SVR中进行特征选择,尤其是加入了GARCH项的GARCH-SVR模型,能够提高SVR的预测精度。"
1817,基于深度迁移学习的赖氨酸乙酰化位点预测问题的研究,"蛋白质翻译后修饰是计算生物领域最重要的问题之一,通过将碳、氧、氮原子上引入乙酰基CH3CO-,以及功能基团添加到一个及以上的氨基酸上改变蛋白质的性质的反应被称为乙酰化。乙酰化一直以来,是最重要的翻译后修饰之一,在许多生物机制中发挥重要作用,例如转录调节机制,细胞凋亡以及细胞的因子信号传导。研究某个氨基酸残基是否会发生乙酰化反应,以及对乙酰化机制的探索和学习对理解细胞的遗传信息表达、生物机理的调控有重要意义。用于鉴定蛋白质乙酰化位点的现有方法可以分为两大类:质谱法和计算方法。基于质谱的实验方法可以发现来自真核生物的乙酰化位点,但是可能耗时且昂贵。因此,有必要开发能够有效且准确地鉴定蛋白质乙酰化位点的计算方法。现有的计算方法通常依赖特征工程,数据收集、特征提取的好坏严重影响乙酰化位点判断的准确,多余的特征和不相关的特征将分别导致冗余和判断失误。基于这些问题,本文使用深度学习框架帮助乙酰化位点预测,它能够通过多层网络和非线性映射操作从大规模训练数据集挖掘潜在特征。在这项研究中,本文提出了双模型深度学习架构帮助乙酰化位点的预测。首先从蛋白质赖氨酸修饰数据库(PLMD)中收集数据,包括泛物种乙酰化数据以及三个物种的乙酰化数据,并划分为训练集、验证集和独立测试集。再从数据中提取两类特征,一是蛋白质序列信息,二是理化属性。针对两类特征,先训练了两个不同的网络,再将两个网络融合增加预测位点的准确性,并使用贝叶斯方法进行调参优化。为了预测数据集规模较小的物种特异性数据,利用迁移学习,将网络迁移到特定物种数据集上进行乙酰化位点预测,也取得了好的效果。实验结果显示了本文网络的有效性,准确率为70.8%,敏感性为72.3%,特异性为70.7%,MCC值为0.251。在物种特异性数据上也取得了比其他工具好的表现,说明本网络可以适用于乙酰化位点预测。"
1818,基于随机森林和夜间灯光数据的建筑物尺度人口估算,"在快速城镇化的社会发展背景下,城市人口呈现持续增长的态势。实现城市内部精细化尺度的人口分布监测对于城市空间规划、资源配置、灾情预警等方面具有重要意义。本文在归纳总结前人研究成果的基础上,汲取现有研究的优势、分析现有研究不足,以快捷准确地获得建筑物尺度人口分布数据为研究目标,确立了基于随机森林和多源数据的建筑物尺度人口估算的方法。研究过程中,以上海市黄浦区为研究区,主要使用了POI(Point of Interest,兴趣点)数据、珞珈一号夜间灯光遥感数据、上海市实有人口数据、上海市建筑物轮廓数据。通过随机森林人口估算模型获得了上海市黄浦区建筑物尺度的常住人口分布数据,评价了模型精度,并对模型进行了详细解释分析。主要研究成果有以下两点:(1)提取POI数据、珞珈一号夜间灯光遥感数据、建筑物轮廓数据中的特征向量,并经过特征工程和特征筛选后得到模型多维特征库。基于随机森林回归算法和多维特征库建立随机森林人口估算模型,并对模型进行参数调整,获得了估计效果最优的人口估算模型。该模型输出上海市黄浦区建筑物尺度人口数据,与实有人口数据进行对比,R~2为0.68,模型精度较好。(2)在完成模型训练及结果输出后,通过基于决策路径估计的随机森林解译方法,运用特征重要性和特征贡献两个指标,定量分析各特征在人口估算模型当中的重要程度,以及各特征对人口估算结果的影响与贡献。从特征值与特征贡献的关系、个体样本的特征贡献构成、不同功能区的特征贡献组成等角度来对特征贡献进行深入分析,探究产生误差的潜在原因及模型改进的方向。本文提出的建筑物尺度人口估算方法可以基于容易获取的数据获得较为准确的人口分布数据,丰富了人口分布数据的获取途径,为人口分布监测提供了新方法、新思路。"
1819,基于多源数据和XGBoost算法的上海市能见度预测模型研究,"影响能见度的因子众多且作用机理复杂,对能见度的预测构成了重大挑战。进行能见度的精准预报,对于保障交通安全,提高人们出行质量有着重要的意义。上海作为超大型城市,也是我国最重要的交通枢纽之一,以上海为典型研究区域,研究针对能见度的精准预报体系对公共安全管理具有重要的现实指导意义。在能见度预测研究方面,目前广泛采用的数值预报模式忽略了预报因子与能见度之间的非线性关系,而使用机器学习算法对能见度预报的研究则大多仅依赖于实测数据,缺少对数值预报产品的挖掘,此外现有研究多关注能见度预测的精度,缺少对模型内部机制的探索和解释。针对目前研究的不足,本文开展基于多源数据和机器学习算法的能见度预测研究。论文主要研究内容和结论如下:1)基于多源数据和XGBoost的能见度预测模型构建。论文结合实测数据、WRF数值预报模式预报数据和EC-thin高空预报数据,应用XGBoost算法,创建并训练上海市11个站点未来24小时的能见度预测模型。结果表明:能见度预测模型预测精度整体较好,预测结果较WRF数值预报精度有明显提升,模型的决定系数约60.2%,逐级预报的准确率为81%。2)模型中影响能见度的各因子的重要性分析。通过计算能见度预测模型各因子的重要性,获得对模型精度提升有显著影响的因子。结果表明:污染物浓度,风速风向和相对湿度对模型的精度提升影响较大;相对于WRF预报数据和实测数据,EC-thin高空数据对能见度模型的精度有着较大的影响。3)特征贡献与模型的关系探讨。基于决策路径估计,计算影响能见度模型预测结果的特征贡献。结果表明:起报时间点能见度、WRF预报能见度和WRF预报的PM_(2.5)浓度,是对能见度预测结果贡献较大的3种特征。随着预报能见度的不断增加,WRF预报数据和实测数据,EC-thin高空数据的特征贡献总体上呈由小到大,由负到正的变化。预报数据(WRF预报数据和EC-thin高空数据)对能见度特征贡献总和有着重要的贡献。"
1820,基于机器学习的半干旱地区地基微波辐射计反演算法研究,"大气温湿度廓线是描述大气热力和动力状态变化的重要参数。传统的系留气球探测方法可以在多种复杂天气条件下进行观测,但是运作耗费大,探测频率低,而地基微波辐射计具有全天候自动观测能力,能够提供高时间分辨率的观测资料,对提高短时临近预报的准确性、研究天气的演变过程、人工影响天气的实现具有重要意义。本文利用兰州大学SACOL站TP/WVP 3000型号地基微波辐射计观测资料和榆中站探空资料,提出了地基微波辐射计受云影响的观测亮温订正算法,选取BP神经网络算法、RBF神经网络算法、多元线性回归和SVR算法研究了多种机器学习算法在半干旱地区地基微波辐射计气象要素反演方面的适用性,并对比了观测亮温训练方案和模拟亮温训练方案在微波辐射计反演算法本地化应用的中差异;选取SVR为最优算法进行了小时分辨率的大气温度、相对湿度和水汽密度反演,检验了订正算法和SVR反演算法在半干旱地区多种大气条件下的适用性,并研究了以榆中为代表的半干旱地区大气边界层的变化特征,主要结论如下:(1)选取268 K作为判断地基微波辐射计是否受云影响的红外亮温阈值并对微波辐射计亮温观测数据进行判定,将云样本与MonoRTM模拟亮温对比可以发现云对地基微波辐射计1~7通道的观测影响较大,会造成亮温异常升高。利用模拟亮温和观测亮温基于支持向量机回归训练得到订正算法,对云样本进行订正,订正后12通道观测亮温的均方根误差均减少,其中对4、5、6通道的订正效果最为显著,但是会引起9~12通道亮温偏差增大,因此该方法仅适用于1~8通道的观测亮温订正。(2)对BP神经网络算法、RBF神经网络算法、多元线性回归和SVR算法的观测亮温和模拟亮温训练方案进行了对比,得出以下结论,就温度廓线而言在0~0.2 km的近地层,四种算法的模拟亮温训练方案均能取得较好的结果,但是在其余高度层上观测亮温训练方案效果更好;就湿度廓线而言BP神经网络算法、RBF神经网络算法和SVR算法的相对湿度廓线的对比验证结果与温度廓线类似,而OBS-MLR算法除在0.4~3.5 km的高度层更有优势外,在其余高度精度均低于SIM-MLR;就水汽密度廓线而言,四种方法水汽密度廓线训练方案的对比结果与相对湿度类似,由此可以得出三种非线性算法的观测亮温训练方案更适用于半干旱地区微波辐射计温度、相对湿度和水汽密度的反演,而线性算法多元线性回归的观测亮温训练方案仅在大气温度廓线反演方面更有优势。(3)将观测亮温训练所得的四种反演算法进行对比可以看出,四种算法反演的温度廓线均方根误差均随高度升高而逐渐增大,在4 km以下四种算法精度较为接近,4 km以上OBS-SVR均方根误差最小;反演的相对湿度廓线在0~5 km反演结果的均方根误差均随高度逐渐增大,5 km以上均方根误差逐渐减小;OBS-SVR反演所得温度廓线的相关系数在所有高度层上均大于OBS-BP;OBS-SVR反演的水汽密度廓线的均方根误差随高度逐渐降低,其余三种算法在0~1 km随高度升高,1 km以上随高度逐渐降低,除近地层外OBS-SVR的均方根误差均小于其他三种算法,OBS-SVR为地基微波辐射计反演算法本地化训练最佳方案,SVR算法在半干旱地区地基微波辐射计反演算法本地化方面更有优势。(4)利用OBS-SVR反演所得2009年6月到2010年6月小时分辨率的大气温度廓线研究了以榆中为代表的半干旱地区边界层年和季节平均日变化特征显著。榆中地区在15:00达到全年日平均最大高度为1163 m,6:00达到全年日平均边界层高度最低值为304 m;大气边界层高度日变化有明显的季节性差异,最大边界层高度由夏季的1557 m减少为春季的1012 m,春、夏均存在大气边界层高度达到最大高度后维持和波动,而冬、秋大气边界到达最大值后就开始降低。(5)利用OBS-SVR分别反演晴天和阴天个例,对比研究了以榆中为代表的半干旱地区晴天和多云天气状况下边界层发展及边界层内气象要素的变化特征。晴空天气条件下,该地区大气边界层高度日变化显著,日出加热地表,促进对流发展,边界层高度开始抬升水汽由地面向上输送,日落后地面辐射冷却,温度降低,对流减弱有逆温层形成,残留层保留了日间混合边界层特征,水汽分布均匀;多云天气条件下,边界层高度没有显著的日变化,物质和能量向上输送减缓,水汽输送效应不明显。(6)利用OBS-SVR反演所得的温度、相对湿度廓线和水汽密度廓线可以完成全年多种复杂天气情况下温度、相对湿度和水汽密度反演,其反演资料能够应用于晴天和多云天气条件下的气象要素演变特征研究,说明SVR订正算法能够减少云对地基微波辐射计观测亮温的影响,提高观测亮温的反演精度,OBS-SVR训练方案训练所得的SVR反演算法具有较好的泛化能力,能够适用于半干旱地区多种天气条件下的气象要素反演,在半干旱地区地基微波辐射计反演算法本地化中具有优势。"
1821,基于灰色关联分析和PSO-SVM的煤与瓦斯突出预测应用研究,"煤与瓦斯突出预测是一个多维的、复杂的非线性预测系统,随着数据挖掘技术和机器学习的快速发展,运用一些智能化的机器学习方法可以有效地解决这种类型的问题,将它们引入煤与瓦斯突出的预测中,有较高的适应性。通过总结分析煤与瓦斯突出的机理,分析提出了对突出影响较大的七个方面因素,在此基础上,结合实际情况,建立了预测突出的参数体系,但是,如此之多的参数作为输入进入预测模型,模型会由于输入参数的维度较大而变得复杂,影响计算效率,降低模型的泛化能力。引入灰色系统理论中的灰色关联分析方法,分析每个参数与研究问题之间的关联程度,通过对它们之间关联度的计算,根据其结果筛选出能够最大程度反映研究问题的主控因素,以此达到维度优化的目的。选择主控因素作为输入进行煤与瓦斯突出的预测,在煤矿收集的样本数据分为训练样本集和测试样本集,样本集用来训练模型,测试集用来验证模型的预测精度。首先运用支持向量机(SVM)预测模型进行突出训练预测,预测结果的决定系数为0.90935,通过与BP神经元网络预测模型的预测结果对比分析,结果显示支持向量机预测精度较高,表明在对小样本数据的预测中,SVM比BP神经元网络有更高的适应性。由于SVM核函数中的惩罚因子C和核函数参数g的组合选取会影响模型的预测性能,传统的方法在寻找C和g的组合时容易陷入局部最优解的窘境,文章引入粒子群算法(PSO)来对SVM的这两个参数进行优化,粒子群算法从全局的角度出发对参数进行寻优,能够极大程度的降低局部最优解出现的情况。运用PSO-SVM预测模型对突出进行训练预测,并且通过与目前常用的优化算法――遗传算法(GA)优化后的模型GA-SVM预测结果比较,结果显示,两种优化算法都有较好的寻优效果,PSO-SVM模型的预测结果决定系数为0.93654,高于GA-SVM预测结果,相较于遗传算法,粒子群算法结构简单,收敛速度快,计算效率高,有较高的推广能力。文章还对PSO-SVM模型的稳定性作了测试,测试结果显示其稳定性高,并对预测结果作了验证,验证结果显示PSO-SVM模型预测的结果与实际情况一致,加之其较高的预测精度,可以看出其在煤与瓦斯突出预测中有较高的应用价值。"
1822,基于数据驱动的浮选过程智能控制,"煤泥浮选过程复杂,影响因素众多,部分变量检测手段落后,存在测量精度不高或时效性差等现象,由于缺失部分变量,过程模型输入变量的维度低而导致模型精度不高。因此,本文通过过程变量采集、药剂预测模型、控制系统这三方面,基于在线、离线数据对浮选过程智能控制作了研究。论文以煤泥浮选过程为研究对象,对煤泥浮选过程进行了变量分析,并根据实际生产现状,确定了煤泥浮选过程变量的采集方式、检测设备与药剂添加的执行机构,基于变量数据的采集,建立了基于DNN算法的浮选药剂用量预测模型,以药剂用量预测模型为基础,构建了基于数据驱动的浮选过程智能控制系统,实现浮选过程药剂智能添加。结合浮选车间实际情况,通过硬件的选型以及几何位置布置,建立了泡沫图像采集系统。对泡沫图像装置的相机、镜头、光源等硬件及几何位置作了分析与比较,发现采用帧率达到30fps、全局曝光方式的工业相机所采集的图像清晰、质量高。对采集到的浮选泡沫图像作预处理,提取泡沫图像特征并分析,并确定主要特征值。以平均梯度作为图像清晰度评价函数,挑选出质量高的图像,通过滤波效果比较,采用核尺寸为3的中值滤波。在泡沫图像的预处理的基础上,通过图像的灰度化提取颜色特征,通过灰度共生矩阵提取纹理特征,通过带标记的分水岭分割方法提取图像的尺寸特征,通过特征点匹配的方式提取图像的动态特征,并分析泡沫图像特征与药剂添加量的相关性,确定灰度均值、熵、方差、平均面积、移动速度为主要相关变量。提出了基于图像特征的浮选尾矿灰分的软测量方法,设计了尾矿图像采集系统与硬件,确定了图像的主要特征。确定了在光强12400lux,搅拌速率为830r/min条件下进行图像采集。发现图像灰度均值随着灰分变大而变大,提取图像的灰度特征进行相关性分析,发现灰度均值、方差、平滑度、偏度、能量、熵与灰分的相关性较大,将这6个变量作为软测量模型的输入。基于尾矿图像特征建立,建立尾矿软测量模型,并设计尾矿图像自动采集与灰分自动预测平台。利用试验采集的81组数据,分别建立基于GA-SVM、PSOSVM算法的浮选尾矿灰分软测量模型。误差数据分析表明,PSO-SVM预测的精度更高,绝对误差在6%以下,且模型的稳定性更强,适用于尾矿灰分的软测量。基于尾矿软测量模型,开发了基于Labview与Matlab的尾矿灰分自动预测平台。基于不同算法建立浮选药剂用量预测模型,并通过对比分析确定最适用的模型。将浮选原煤灰分、原煤量、入料灰分、入料浓度、精煤灰分、尾矿灰分,泡沫图像的灰度均值、熵、方差、平均面积、移动速度为输入,捕收剂、起泡剂流量为输出,利用采集的120组数据,分别了建立浮选药剂用量的GRNN、SVM、DNN预测模型,数据误差表明:基于DNN模型的预测效果强于GRNN、SVM的预测效果,捕收剂的绝对误差在12%以下,起泡剂的预测误差在8%以下。在建立的DNN药剂添加量预测模型的基础上,建立了基于数据的煤泥浮选过程智能控制系统。通过模糊控制器的设计,对预测的药剂用量作补偿,进行微调;通过对泵的药剂流量标定,实现药剂的准确添加。通过采集程序的设计,实现变量采集与交互,通过上位机下位机的设计,实现了具体的控制过程。"
1823,矿井皮带区域矿工不安全行为识别方法的研究,"煤矿行业是以矿工为主体的劳动密集型产业,长期单一繁重的体力劳动和井下复杂恶劣的环境导致大多数矿工情绪波动较大,自我控制能力下降,导致矿工不安全行为的发生。国内外学者尚未开展基于人体三维骨骼点的矿工不安全行为识别方面的研究,是矿工行为研究领域新的研究方向。皮带运输机是井下运输系统的重要组成部分,不少矿工铤而走险,在皮带区域进行一些不符合安全生产规范的行为,例如攀爬皮带运输机、倚靠运输机等不安全行为,这些不安全行为是引发皮带区域安全事故的主要原因。综合矿山实际环境以及对比主流的行为识别技术,采用基于Kinect传感器的人体行为识别技术对皮带区域的矿工不安全行为进行识别。以Kinect传感器作为感知设备捕捉矿工体感信息和皮带运输机区域RGB视频,结合矿工20个骨骼关节点的坐标信息和皮带区域彩色图像信息以识别矿工的不安全行为。基于矿工行为的动态性和复杂性,提出一种基于多层次互补特征的矿工行为表示方法,融合运动姿态相对位置特征、运动姿态角度特征、运动姿态帧间位移特征对矿工行为进行描述。为了降低矿工行为特征维度和去除冗余特征,本文移除与矿工行为关联度较小的特征量,使用基于随机森林的特征重要性评估算法对标准化后的行为特征进行分析以达到特征选择的目的。为了防止行为特征维度过大,建立基于余弦相似度的矿工行为关键帧序列搜索模型对矿工行为关键帧进行提取。为了准确识别皮带运输机区域的矿工行为,引入集成学习中的加权平均投票模型和Stacking算法。借助大型带式输送机动态试验平台,完成皮带运输机区域矿工行为数据的采集,在自建的矿工行为数据集上验证了基于集成学习的矿工行为识别模型的有效性,加权平均投票模型和Stacking算法对于7种矿工行为的识别率分别达到91.2%和92.7%。为了对矿工不安全行为进行有效判识,基于Mask R-CNN卷积网络和Kinect人体骨骼关节点坐标映射构建皮带运输机区域矿工不安全行为判识模型。为了进一步提高矿工行为识别的准确率,提出一种基于多重Stacking算法的行为识别模型,其对7种矿工行为的识别率达到94.8%。且在UTKinect数据集、Florence数据集上验证了本文所提行为识别算法的有效性和可拓展性。"
1824,基于CSI的煤矿井下被动入侵检测方法研究,"随着无线网络技术和智能设备的快速发展,以Wi Fi信号为核心的无线感知技术得到了广泛的关注,并在诸如室内定位、入侵检测等领域中得到应用。无线信号将通信和感知合二为一,早期的无线感知检测技术是利用无线信号中接收信号强度值(Received Signal Strength Indication,RSSI)的波动进行判断,但RSSI有粗粒度、单值以及稳定性差的缺点。近几年,研究者开始转向从Wi Fi信号中获取具有更细粒度的信道状态信息(Channel State Information,CSI)的研究中。以信息化、智能化技术为驱动,重点研究煤矿生产事故的监测、预警、预防等科技问题。实现CSI无源入侵检测,对煤矿井下一些危险区域进行监控监测,通过已安装的无线设备获取到环境中的无线信号,实现无源被动式的入侵检测对于提高矿山安全生产水平具有重大意义。本论文的主要工作体现为以下三个方面。(1)提出并设计了一套利用CSI数据的井下关键区域闯入检测系统。该系统利用装有Intel 5300网卡和修改驱动后的主机与普通AP(Access Point)之间的通信,采集原始CSI数据包,对幅度信息使用Hampel滤波器滤除离群点,利用PCA(Principal Component Analysis)降噪。针对原始相位紊乱的问题,采用线性校正算法进行校正,并从相邻天线间提取出相位差信息,利用机器学习算法对特征进行离线训练以及分类,建立用于目标监测的判别模型。(2)利用相位差作为基本信号,并融合多天线链路特征信息,提出新的入侵检测方法。利用滑动窗口的方式在时间维度上对所有的子载波提取特征,构建特征矩阵,使用机器学习算法对不同环境下的特征信息进行一个分类处理,对结果加以判识。针对不同链路对环境变换的敏感度不同的问题,结合不同的链路上的特征信息,提出了基于不同链路特征融合的检测算法,提高了系统的稳定性和鲁棒性。(3)在不同实验场景下的不同测试时间段进行实验,验证本论文所提出方法的有效性和可靠性,评估系统性能。实验结果表明,本文所提出的基于CSI相位差的入侵检测方法具有更好的灵敏度和鲁棒性,有效的提高了检测的准确度,平均检测精度可达99.4%以上。"
1825,基于多源信息融合的井下皮带机驱动电机状态识别方法研究,"随着科技水平的不断创新与发展,矿井大型设备运行状态的监测与诊断愈发得到重视。驱动电机作为皮带输送机与其他设备驱动系统的核心部件,其安全高效的运行关系着矿井生产的可靠性与稳定性。电机故障不仅会导致相关设备的损毁,而且会造成矿井生产停滞,带来难以预计的人力、物力损失。因此,监测皮带机驱动电机的运行状态,对于其故障情况进行状态识别与预警,具有重要意义及实际价值。传统电机故障诊断往往针对单一信号进行分析,在信号采集方面存在片面性,应当考虑电机的综合性构成。在特征处理时,需要将特征选择与状态识别模型结合,得到针对性较强的特征子集。在信息融合时,需对信号经过多分类器训练得到的识别结果进行融合,并将融合结果以可视化的界面进行展示。针对以上问题开展研究工作。(1)分析电机振动信号与定子电流信号在不同运行状态下的故障特性,对基于经验模态分解(Empirical Mode Decomposition,EMD)的信号分析方法进行研究,提出基于完备平均经验模态分解(Complementary Ensemble Empirical Mode Decomposition,CEEMD)的振动与电流信号分析方法,有效解决EMD分解中存在的“模态混叠”问题,并对虚假分量进行甄别。通过计算IMF分量与原始信号的相关系数,选择前四阶IMF分量,与包络谱、边际谱分量组成信号样本序列。(2)计算信号样本序列包含时域、频域参数在内的11种统计特征,构建高维原始特征集,并提出基于随机森林(Random Forest,RF)平均精确率减少的特征选择方法FSMDA,对原始特征集进行处理。该方法利用随机森林模型对特征进行训练与测试,将加入噪声干扰前后的特征袋外误差率差值用于描述特征重要度,作为特征选择的依据。结合线性局部切空间排列方法(Linear Local Tangent Space Alignment,LLTSA)与极限学习机(Extreme Learning Machine,ELM)、模糊C-均值聚类算法(Fuzzy C-Means,FCM)、随机森林等分类器,构建基于驱动电机振动信号与定子电流信号的状态识别模型,设计同工况与变工况的两组对比实验,利用实验台电机故障数据对模型的有效性进行验证。(3)分析传统信息融合存在的的问题,提出基于优化D-S证据理论的两级信息融合框架,其中一级融合集中于同一类信号的多种状态识别模型结果,再将不同类信号的融合识别结果进行二级融合。利用Jousselme距离度量原始距离间的相似程度,在融合时避免了证据间的高度冲突带来的问题。利用第三章所提状态识别模型同工况下的识别结果,对所提多源信息融合框架的有效性进行验证。(4)通过分析矿井操作人员对于皮带机驱动电机监测与诊断的需求,设计研发了基于.Net平台的矿井皮带机驱动电机状态识别与智能决策系统。结合状态监测模型与多源信息融合结果,为矿井操作人员提供了快捷、高效的信息处理系统,具有较强的可拓展性,有效提高现场工作效率。实验结果表明,本文所提出的特征选择方法FSMDA能够有效选择对状态识别模型重要度较高的特征,构建的状态识别模型CEEMD-FSMDA-LLTSA-ELM/FCM/RF具有良好的适应性,明显提高了电机同工况与变工况状态的识别精确率,结合多源信息融合结果所设计的矿井皮带机驱动电机状态识别与智能决策系统能有效描述故障类型,可操作性强。"
1826,基于快速活动轮廓模型和BP-AdaBoost的织物缺陷检测,"制造业的迅速发展对于各类产品的缺陷检测提出了新的挑战,基于机器视觉的自动检测方法逐渐取代人工肉眼检测成为趋势。针对目前织物缺陷检测定位效率低和分类准确率不理想的问题,提出了基于快速活动轮廓分割模型和BP-AdaBoost的织物缺陷检测算法,将算法分为定位和分类两部分,用以实现对织物缺陷的自动检测。对于缺陷位置的定位要靠图像分割来完成,在总结分析了目前已有的各种分割方法的优缺点后,在活动轮廓分割模型的基础上提出了快速活动轮廓模型。首先分析了C-V模型、LBF模型和LIF模型这三种传统活动轮廓算法,由于这些算法的能量函数都是非凸的,在求解过程中易获得局部最小值,受初始轮廓位置设置和图像灰度不均影响较大。本文基于上述算法,引入凸优化技术,将求解问题变成了一个凸优化问题,从而解决了活动轮廓模型受初始位置影响大的问题,同时对求解过程进行优化,使算法求解速度得到了较大提升。在几种不同类型图片上进行了对比实验,实验结果表明快速活动轮廓模型分割精度高,且速度明显优于传统活动轮廓模型,平均分割时间仅需0.13秒。鉴于机器学习在图像分类中的实用性,在分析了几类典型的机器学习分类算法后,选用BP神经网络来完成对缺陷的分类,这种网络结构简单有效,通用性强。为了进一步提高网络的分类能力,引入AdaBoost算法,将算法中的弱分类器以BP网络代替,得到BP-AdaBoost算法。在MNIST、Fashion-MNIST和TFDS三类不同类型的典型数据库上进行算法分类对比实验,实验结果表明,BP-AdaBoost算法在上述三种数据库上的分类准确率明显优于传统SVM和KNN算法,且相比CNN而言,更符合实际产品检测中对实时性和准确性的要求。基于活动轮廓模型和BP-AdaBoost分类算法设计了织物典型疵点检测算法,完成了对织物缺陷的定位和分类任务。针对两种不同类型织物的破洞和污渍这两种典型缺陷设计了一系列对比实验,确定了网络的最佳参数。在此基础上,对四种缺陷进行了算法有效性实验,实验结果表明算法分类准确率高,定位精确,完成了对织物缺陷的定位和分类任务,能有效的应用于织物的缺陷检测中。"
1827,基于旋转森林算法的荒漠区植被信息提取：以毛乌素沙地为例,"植被是陆地生态系统的重要组成部分,植被能够保持水土,保护区域内生物多样性,荒漠区植被更是与全球气候变化及环境研究等密切相关。荒漠区植被信息提取能够客观地反映区域内的植被类型和植被生长状况,并且对于生产管理决策部门科学评价荒漠化地区的生态恢复效果、研究荒漠生态系统的碳循环过程以及实现荒漠生态系统的健康发展具有十分重要的意义。本文使用旋转森林算法,结合多光谱遥感影像和地形数据,计算得到光谱特征、纹理特征和地形特征三类共98个特征完成了以毛乌素沙地为例的荒漠区植被信息提取;基于植被信息提取的精度,对比了本文使用的分类方法和研究区已有的分类方法,并使用基于交互式数据语言(Interactive Data Language,IDL)将分类性能较高的旋转森林分类方法集成到ENVI软件中;最后对研究区内的植被类型空间分布情况进行分析。通过研究得到以下结论:(1)决策树“最小节点待分类个数”为5%平均类别样本数,旋转森林算法能够很好地防止模型的过拟合,提高模型的训练效率,最终提高模型的性能。此外,模型的决策树个数为10,特征子集内的特征数为3时,模型已经能够达到遥感影像分类的精度要求。因此,对于本研究区,上述参数设置为旋转森林算法最优的参数组合。(2)在荒漠区植被遥感信息提取的应用中,旋转森林算法能够达到遥感影像信息提取的精度要求,其精度要优于已有的分层分类与多指标结合的遥感信息提取方法。此外,基于旋转森林算法的植被信息提取方法比分层分类与多指标结合的遥感信息提取方法更加简单,分类时引入的主观因素更少,分类结果更为可信。因此,基于旋转森林算法的植被信息提取方法更适合用于荒漠区植被信息提取。(3)研究区内各县级单位植被类型分布空间差异性较大,毛乌素沙地核心区和毛乌素沙地外围区域的植被覆盖差异较大。具体来讲,毛乌素沙地核心区的内蒙古三个旗的植被覆盖度较低,植被类型较为简单。毛乌素沙地周边,陕西省五个县和宁夏两个县植被覆盖度较高,且植被类型分布多样。综上所述,基于旋转森林算法的植被信息提取能够快速准确地得到荒漠区的植被分布情况,可以为进一步研究水热格局以及土地利用类型对当地生态环境的影响提供基础和支撑,为其他区域的植被信息提取提供借鉴,为区域内的生态环境研究及全球气候变化研究提供支撑。"
1828,基于机器学习的道岔转辙设备故障智能诊断研究,"铁路信号室外设备主要有三大件:转辙机设备、轨道电路和信号机。在轨道交通行业内直接影响列车运行前进方向的关键设备之一便是转辙机,决定该设备动作方向并告知尖轨位置状态的电路称为控制电路,为了对转辙机这种关键设备的运行状态进行实时监测,铁路部门运用信号集中监测系统实时监测并记录设备的运行情况,记录下的状态供电务部门技术人员进行分析和研究。目前对设备的管理和监测能力还达不到状态修的水平,但是随着人工智能、数据融合和大数据等技术的应用,对设备状态的诊断技术将变得越来越智能化,诊断技术的提升将促进铁路信号设备检修方式向状态修演进。目前,针对转辙机设备的状态诊断主要依靠技术员调阅信号集中监测系统的关键参数曲线进行经验判断,在交通枢纽站,技术员需要调阅大量曲线,依靠经验进行判断的方式在准确性和时效性方面存在不足,且由于技术员业务素养不同,导致各单位故障诊断能力参差不齐。本文针对这些不足选取信号室外设备三大件之一的转辙机设备为研究对象,主要目标:一是从电务角度出发,选取道岔的几种典型故障案例进行分析,实现对道岔运行状态进行快速诊断;二是选择合适的算法进行道岔故障诊断建模,实现对道岔运行状态的智能诊断,减轻调阅人员工作的繁重程度。针对上述目标,本文需要完成的主要内容如下:(1)明确道岔系统机械和电气部分的基本组成和工作原理,掌握正常动作电流曲线的特点、道岔故障应急处理流程和典型故障现象及原因。(2)利用失效模式与影响分析方法实现对道岔故障模式和原因的分析,并依据铁路应用可靠性、可用性、可维护性和安全性标准文件进行风险评估。对典型故障案例的严重度、频度和不可探测性进行评分,并由此计算出风险优先值,为模型参数的设定提供一定的参考依据。(3)对机器学习的几种算法进行简单介绍,从研究对象的实际应用场景和各算法的优缺点出发,进行分类器算法选型分析,选择神经网络作为道岔故障诊断的模型。(4)设计误差反向传播神经网络的网络结构并提出基准线和区段划分技术,对各区段进行特征提取,总共提取30个时域特征值;实现基于基准线的误差反向传播神经网络道岔故障诊断模型。优化算法并验证模型故障诊断正确率可达94.6%。本文主要针对转辙机设备提出基于基准线的概念,并使用BP神经网络方法对道岔动作过程中的状态进行识别研究,通过仿真实验表明,该方法具有一定的可行性与有效性,为转辙机设备安全运行提供可靠的保障,并为转辙机设备检修方式向状态修演进做出一定的贡献。"
1829,基于旋翼式无人机航拍的车辆检测跟踪系统研究,"近年来车辆检测跟踪技术在国内外发展迅速,在固定监控设备中已经有很完善的应用及推广,但仍存在监测范围有限,灵活性差和成本高昂等缺点。通过无人机搭载监控设备实现对视频图像的采集,再结合图像处理对地面车辆进行检测和跟踪的技术应运而生。但是目前无人机在交通监控和数据采集方面的应用还不太成熟,从航拍视频中检测跟踪车辆和提取其它交通信息的可靠方法还比较匮乏。为此本文以道路上行驶的车辆为对象、以交通监控和数据采集为应用背景展开研究。本文的主要研究内容如下:(1)提出一种基于机器学习的航拍车辆检测算法,针对无人机航拍视角与固定监控设备不同的问题,提出了四种符合航拍视角的车辆矩形特征补充到原有的Haar-Like矩形特征库,然后结合HOG特征以弥补Haar-Like特征在表征物体形状方面的不足,之后使用大量的正负样本对每一种特征训练形成弱分类器,最终级联形成Adaboost强分类器,实现对车辆的分类和检测。对比实验结果可知,改进后的算法能够有效描述车辆特征,提高车辆检测的准确率。(2)无人机在对地面目标进行跟踪时,针对传统Camshift算法存在易受相似颜色背景、遮挡等干扰的问题,提出一种改进Camshift的目标跟踪方法。通过提取跟踪目标的Hue、Saturation和LBP特征分量建立基于三维联合直方图的跟踪模板,并采用自适应加权策略来调整三种特征分量的权重值,提高算法的跟踪准确度;在跟踪目标受到遮挡干扰时,引入Kalman滤波机制,增强算法的鲁棒性。实验结果表明,改进后的算法能够满足无人机对目标跟踪准确性与实时性的要求。(3)以前面提出的检测跟踪算法为理论依据,结合无人机硬件设备与软件平台开发设计了基于无人机航拍的车辆检测跟踪系统,实现了显示道路类型、限行速度、车辆行车方向、车道占有率、平均速度和车辆计数等功能。通过统计违章违法车辆,协助交管部门维护交通秩序、保障交通安全。"
1830,基于特征价格理论和CatBoost的旧机动车价值评估模型研究,"随着我国社会经济的高速发展,旧机动车交易量快速的增长。但由于旧机动车市场发展速度过快,在交易过程中产生了一系列的问题,例如:交易过程中的信息不对称让消费者权益无法得到保障,大量的线下评估工作增加了人力运营成本等问题。因此,在这个高速发展的旧机动车市场中,怎样让消费者能够简单直接的了解到商品的价值,怎样快速地对旧机动车价值进行评估,怎样减少运营的人力成本,是目前亟待解决的问题。本文的主要研究内容如下:1)本文使用了大宗商品价值评估过程中较为常用的特征价格理论,将其应用到旧机动车价值评估领域中。通过使用该方法将旧机动车的价值拆分为21个特征各自的功能和效用价值。按照市场特征向量、汽车自身车况特征向量、汽车损耗特征向量三个大方面对汽车价值进行划分,并按照一定的规则进行量化。特征价格理论具有更高的客观性和更强的可信度,弥补了传统方式对消费者心理感知的忽略。2)使用特征价格理论进行变量的筛选工作后,对数据进行预处理,使其满足模型的应用。在数据预处理阶段,第一步采用人工插补、变量剔除的方式对数据中的缺失值进行填补。第二步使用描述性分析和差值比较法查找出数据中的异常值,并对其进行处理。第三步按照业务角度和市场角度对变量进行编码处理,主要使用了映射序列编码和one-hot编码。最后对数据进行标准化处理,去除数据量纲对模型效果的影响。3)预处理后,本文采用了XGBoost、Extratree、随机森林和CatBoost等四种算法分别对训练集进行训练,获得评估模型。再针对各个模型的泛化性能进行对比,使用RMSE和coverage作为评测指标,挑选出效果最优的模型,建立最终的旧机动车价值评估模型。在训练过程中,CatBoost在coverage(±5%)的范围内泛化能力达到80%以上,相比较优于其他几个模型的表现能力,达到行业应用水平。4)采用CatBoost算法建立旧机动车评估模型,其模型的泛化性能和表现能力优于其他几个模型。利用CatBoost对特征重要性进行排名,判断特征对价值的重要性,使用该方法发现使用时间具有最高的影响性,其次业主期望价格、裸车价格、产量和品牌市场占比分别占据了排名第二位至第五位,我们可以了解到在旧机动车的评估过程中上面的五个特征起到决定性的作用。本文的研究分析,建立了一种基于特征价格理论和CatBoost相结合的旧机动车价值评估模型。通过建立价值评估模型,减少了人工成本的投入,降低了运营成本,减轻了人工评估过程中对车系车型的局限性,提高了评估的准确率。"
1831,基于逻辑回归模型的汽车评论挖掘研究,"近些年,伴随着国民经济水平的上升,汽车在居民出行上的比重越来越大。同时,由于网络的高速发展,互联网平台上出现了各种汽车评论网站,比如爱卡汽车、汽车之家和易车网等。顾客在进行购买汽车前通常会借助相关网站去了解汽车的品牌、款式、性能和价格等信息。在购买汽车后,顾客经常会主动分享购车经验到这些平台上。因此,这些平台拥有大量的汽车评论数据。各大汽车厂商越来越关注此渠道的信息挖掘分析,以期达到分析用户需求、改良已有产品不足和挖掘竞争对手信息的目的。经过大量的观察发现,网站上的汽车评论普遍存在着主观性和随意性的特点,导致很多评论反馈出的情感极性和厂商关心的汽车指标的主题句并不确切。因此,论文对汽车评论数据的挖掘研究主要包括两个方面的内容:一方面,快速识别出每条评论所表达的情感极性,有利于厂商得到顾客准确的情感倾向。另一方面,从短文本汽车简评中提取厂商关心的特定汽车评价指标的主题句,有助于提高各大厂商对评论数据检索关键信息的效率、快速提升产品的质量和实现对顾客的个性化营销。因此,本文利用爬虫技术收集了国内综合排名前五的爱卡汽车网站上两万多位顾客的汽车评论数据并对此进行挖掘研究。首先,确立针对汽车评论数据的“情感分类分析”和“主题提取分析”为两类探索分析目标。其次,通过统计学理论对获取到的数据进行处理分析和建立特征工程,为提升评论数据挖掘研究的效果打好基础。然后,针对两个分析目标分别构建相关模型。最后,进行模型的评估和研究结果的输出展示工作。具体研究内容和相关结论如下:(1)在情感分类分析中,首先进行文本数据标记、数据清洗和特征选择等工作。其次,利用XGBoost、朴素贝叶斯和正则化逻辑回归三种算法进行用户评论的“正向”或“负向”的情感二分类建模。从情感分类分析的结果可知,基于正则化逻辑回归算法所构建的模型做分类器时效果最好。(2)在主题提取分析中,首先,对爬取的文本数据进行切句、预处理之后,进行多分类正则化逻辑回归模型的建立。其次,针对每段测试文本,预判每条断句的所属类别概率。在此基础上结合合理的句子拼接规则进行包括“外观”、“内饰”、“空间”、“舒适”、“油耗”、“动力”、“操控”、“四驱”和“性价比”这九个相关的主题句提取工作。从提取的结果中发现,此种主题提取的方法准确度较高。在理论方面,本文所提出的基于汽车评论数据的分析方法在其它领域数据的挖掘研究上有一定的参考价值。在应用方面,该方法对汽车各大厂商进行消费者行为分析和实现精准营销存在很大程度上的指导作用。"
1832,基于人工智能的大型载重汽车识别系统设计及实现,"随着社会经济的飞速发展,城市交通环境越来越便捷,这使我们的交通出行得到改善,然而伴随而来的是我们不容忽视的交通安全问题。在各种媒体的报道中不难发现,大型载重汽车的安全隐患指数是非常高,如果能实现大型载重汽车识别智能化,将使智能交通系统更快捷方便地为人们的出行服务。本文主要研究了人工智能的机器学习理论和深度学习理论,设计并实现了基于人工智能的大型载重汽车识别系统,该系统将机器学习方法和深度学习方法应用于大型载重汽车识别,实现了智能交通应用创新。该系统分别采用机器学习中的HOG+SVM方法和深度学习中的VGGNet-16模型,使用这两种方法分别对大型载重汽车进行识别,同时对这两种算法进行了优化,经过实验测试表明使用深度学习模型VGGNet-16识别效率更高,在开发过程中使用OpenCV+Python+TensorFlow工具。该系统的工作流程如下:首先进行区域选择,把所选区域各个路口监控视频通过OpenCV工具实时转换为图像,然后通过建立好的两种具备识别能力的识别模型分别进行识别,如果在城区内禁行时间段识别到大型载重汽车通行则会触发警报。该系统数据库采用MySQL,它存储过往车辆的信息,用来统计大型载重汽车在各个时间段出现的数量,这些信息有助于用户分析载重汽车出行的规律及为后期系统升级做准备。"
1833,基于机器学习和小波包变换的故障选线方法研究,"配电网故障选线问题是研究的热点。快速、准确地选出故障线路,对于电力系统安全、可靠地运行具有重大意义。本文以故障选线方法研究为对象,通过引入机器学习,将故障选线转化为多分类问题,利用机器学习中的分类器选择故障线路,开展的研究工作如下:(1)以四出线10 kV配电网为例建立模型,在对单相接地故障发生时各线路稳态、暂态电气量进行分析的基础上,确定运用暂态量进行故障选线,通过大量的仿真计算,形成了用于机器学习的数据集。(2)以小波理论为基础,利用小波包变换对不同故障情况下各出线零序电流进行特征提取,得到零序电流在特征频带上的能量与模极大值后用于遴选故障线路。大量算例的遴选结果显示,仅以故障线路零序电流在特征频带上能量最大、模极大值最大且与健全线路极性相反作为遴选故障线路的判据存在误选率较高的问题,因此提出了一种将机器学习与小波包变换相结合的故障选线方法。该方法将零序电流经小波包变换后得到的能量与模极大值作为机器学习中使用的数据集,选择随机森林作为分类器进行故障选线。经测试,该方法既继承了利用能量与模极大值选线方法的优势,又发挥了随机森林的作用,能在模极大值特征不明显时降低误选率。(3)提出了一种以原始零序电流数据集为对象,直接使用随机森林进行故障选线的方法。原始零序电流数据集相比于基于小波包变换的数据集,样本维度升高、信息量增加。为选择最优的分类器,利用训练集对支持向量机、前馈神经网络、决策树、随机森林四种分类器进行训练,在测试集上进行了分类效果的评估,得到了随机森林分类效果相对较好的结论。经测试,以随机森林构建的故障选线方法具有交叉验证时间短、选线准确的特点,不受接地电阻大小、故障点距母线距离远近、故障初始角位置的影响。(4)搭建了一个由“离线训练”和“在线识别”两部分组成的故障选线系统,为机器学习在故障选线领域的应用提供了一种参考方案。"
1834,基于集成学习的有机太阳能电池光电转化效率预测模型研究,"太阳能电池可以将太阳能直接转化为电能,是太阳能利用的最有效途径。而有机太阳能电池由于其低成本、轻质、可制备大面积柔性器件而备受关注。其中太阳能光电转化效率(Power Conversion Efficiency,PCE)是评价有机太阳能电池(Organic Solar Cells,OSCs)性能的一项至关重要的参数,其预测的精度直接影响到太阳能电池的性能。但是电池器件的复杂结构使得从分子结构性质准确计算有机太阳能电池的光电转化效率难以通过量子化学计算或实验直接得出。而集成学习作为机器学习的一个分支,能有效地绕过复杂的实验过程,直接构造出分子结构性质与太阳能电池光电转化效率定量构效关系(Quantitative Structure-Activity Relationship,QSAR),打破弱学习器的瓶颈,通常比基础学习器更准确。因此为了提高有机太阳能电池光电转化效率的预测精度与所建QSAR模型的泛化能力,本文运用多种集成学习方法构建QSAR模型。一方面从全局建模的角度出发,构建了三种类型的全局集成模型,包括同质集成方法Boosting方式的GBDT,Bagging方式的随机森林(Random Forest),以及异质集成SVM-KNN-WMA。另一方面,本文研究了一种“先聚类,再建模”的方案,建立局部异质集成模型L-SVM-KNN-WMA。其中全局异质集成SVM-KNN-WMA即使用加权多数算法(WMA)以组合基回归器支持向量机(SVM)、K最近邻(KNN)的意见,通过在多个有机太阳能电池数据集上的实证分析表明,其性能优于单一学习器支持向量机,并比另外两种集成方法GBDT、RF所建的QSAR模型具有更好的泛化能力;而根据分子的结构相似性对训练集应用K-Means聚类方法生成子集建立的局部异质集成模型L-SVM-KNN-WMA实现了更高的预测精度与更强的泛化能力。本文研究结果表明,基于集成学习构建分子结构性质与光电转化效率QSAR模型可以预测出具有较高PCE的新型有机太阳能材料,并解决了传统的量子化学计算方法耗费大量的计算资源问题,降低了实验成本与实验时间,对今后的实际应用具有重要意义。"
1835,基于门控循环单元的短期风电功率预测研究,"风电的随机性和波动性给电力系统的安全控制和稳定运行带来了严峻挑战,其自身的不确定性经常让当前的电力系统难以消纳,而解决这一问题的有效方法是对风电功率进行预测。随着智能电网的升级改造、电力市场的放松管制和可再生能源的全面渗透,风电功率预测变得越来越重要。基于目前深度学习技术在语音识别、自然语言处理、计算机视觉、医疗等领域取得重要突破,以实际短期风电场数据为研究对象,研究了深度学习算法―门控循环单元在点预测和概率预测方面的问题。主要研究内容包括:(1)为了利用更长的时序特征以提升短期风电功率点预测的精度,将一种门控循环单元算法应用于短期风电功率点预测。分析了风电数据的时序特征,设计了3+1层深度门控循环单元网络架构及其参数,系统比较了模型在迭代预测、集成预测、多输出预测等多步预测方法上的表现,实验结果表明,相比其它主流机器学习模型,门控循环单元具有更优秀的预测性能,集成预测会稍微优于其它两种多步预测方法。(2)为了更好地量化与风电功率预测相关的不确定性,提出一种基于门控循环单元分位数回归的短期风电功率概率预测模型。设计了所提模型,并对不同的分位数进行风电功率预测建模,构建了不同置信水平的概率预测,实验结果表明,相比神经网络分位数回归等模型,所提模型具有更高的区间预测性能,并获得了不同置信水平的短期风电功率概率密度曲线。(3)针对非平稳的短期风电功率数据,单一模型难以挖掘出更深层次的时序特征,提出一种集合经验模式分解-样本熵和门控循环单元的组合算法用于提高点预测性能,提出一种集合经验模式分解-样本熵和门控循环单元分位数回归的组合算法用于提高概率预测性能。首先利用时序分解法将风电功率数据进行分解,然后引入样本熵进行重构以减少建模数量。在组合点预测上,采用门控循环单元分别对分量数据进行预测建模及其重构;在组合概率预测上,采用门控循环单元分位数回归分别对具有预测滞后性的高频分量进行预测,并将所得结果与分量点预测进行重构,获得了不同组合场景的概率预测。实验结果表明,相比单一模型,所提组合点预测模型能够大幅度提升点预测的精度;所提组合概率预测模型能够有效地压缩预测区间的宽度,且获得的概率密度曲线更高更窄。"
1836,基于面向对象方法的水稻种植区提取方法研究,"水稻是我国种植面积最大、总产量最多的粮食作物。遥感技术具有速度快、范围广、周期性等特点,在水稻信息快速获取领域具有明显的优势。获取水稻生产信息,准确及时掌握水稻种植面积、空间分布及布局,对粮食安全、社会稳定等具有十分重要的意义。本文基于中等分辨率多源遥感卫星数据(Landsat 8、Sentinel-1),以详尽的地面观测数据为依据,利用遥感数据融合的方法,结合面向对象农作物分类,解决在水稻信息提取过程中的特征筛选、精度不高问题。并对影响水稻信息提取精度的因素进行定性分析和定量研究,旨在提高在水稻遥感识别中多源数据、面向对象方法和数据挖掘算法的理解与认识。本研究以辽宁省灯塔市为研究区,综合利用Sentinel-1雷达数据和Landsat 8光学数据,结合2016年9月对研究区的调查以及Digital Globe高清卫星影像产品,进行以下两方面的研究:1)研究多源数据对水稻信息提取中精度改善效果,确定在该数据下适宜特征和分割尺度,以支持更加精确的水稻种植区提取。2)基于多尺度分割下对影像进行分割并对对象特征进行筛选,研究水稻信息提取精度以及在不同分类器下精度的变化,确定在不同的数据特征下最优的水稻种植区提取算法。最终为农业及粮食宏观决策所需水稻种植区空间分布与规划提供技术参考。根据研究目标,分别设计了两个实验:1)基于多源数据的水稻识别。利用光谱数据、指数数据、雷达数据、纹理数据等多元特征构建特征空间。利用单变量特征分析,运用面向对象方法对构建的特征空间,进行水稻种植区提取。2)基于多空间尺度的水稻遥感多算法识别。针对多源数据进行多种分割尺度和提取水稻种植区,并在各个尺度上进行构建随机森林、决策树、支持向量机分类模型,对比多源数据在不同分类器下的水稻种植区提取精度。本文的主要结论如下:1)不同多元特征空间,在水稻种植区提取中的重要程度有差异。指数数据、雷达数据、纹理数据,在构建多元特征空间中,指数数据与雷达数据的加入对水稻提取的精度有明显的提升。2)在水稻种植区提取中,基于单一光学数据下,支持向量机与随机森林相对于决策树分类器表现比较稳定,即特征空间较少的情况下支持向量机和随机森林相对决策树在水稻提取精度上表现优异。增加特征空间,决策树分类模型在水稻提取精度上提升幅度较大,总体精度提高7.9%,kappa系数提高8.1%;支持向量机与随机森林分类模型在总体精度方面提升分别为3.6%与2%,kappa系数分别提高3%与2.1%。"
1837,基于机器学习算法的不同生育期夏玉米生理参数遥感模型研究,"叶绿素含量与叶片含水量是玉米生长状况的重要指标。本研究以西北地区广泛种植的夏玉米为研究对象,应用地物光谱辐射仪测定不同生育期夏玉米的非成像高光谱数据,同步获取叶绿素含量与叶片含水量数据,分析不同生育期的高光谱遥感数据与其的相关性,构建基于特征波长、植被指数和高光谱特征参数的反演模型。得到主要结论如下:1.叶绿素含量与叶片含水量特征分析:从拔节期到乳熟期叶绿素含量不断增加,随着植株的衰老,到完熟期开始减少,各时期光谱反射率在“绿峰”区域差异显著;叶片含水量均值呈不断增加,但增长速度从乳熟期开始减缓。2.相关性分析:夏玉米叶绿素含量值与光谱的相关性从拔节期、抽雄期、乳熟期到完熟期,原始光谱反射率与叶绿素含量在547nm、342nm、719nm、343nm波长处相关性最大,最大相关系数分别为-0.170、-0.293、-0.476、-0.196;一阶微分光谱与叶绿素含量在964nm、835nm、707nm、910nm波长处相关性最大,各时期最大相关系数分别为0.482、0.358、-0.499、0.269;NDWI、VOG1、MTCI、TVI分别为各生育期的最佳植被指数,与叶绿素含量的相关系数为0.284、-0.279、0.507、-0.127;(SDr-SDb)/(SDr+SDb)、SDr/SDb、(SDr-SDb)/(SDr+SDb)、SDy分别为各生育期的最佳高光谱遥感参数,与叶绿素含量的相关系数为0.284、0.285、0.479、0.133。夏玉米叶片含水量值与原始光谱各个生育期分别在450nm、367nm、353nm、353nm波长处相关性最大,最大相关系数分别为-0.580、-0.266、0.337、-0.165;叶片含水量值与一阶微分光谱在1654nm、960nm、1072nm、1070nm波长相关性最大,最大相关系数为-0.588、-0.478、-0.450、-0.388;NDVI、NDVI、WI、VOG1分别为各时期的最佳植被指数,相关系数分别为0.431、0.135、-0.261、0.158;高光谱遥感参数SDy、Ry、Ry、Db分别与各时期的叶片含水量相关性最大,相关系数分别为0.334、0.253、-0.342、0.308。3.最优估算模型:叶绿素含量反演,单变量最优估算模型为乳熟期以一阶微分特征波长构建的KNN模型,模型建模与验证R~2分别为0.366与0.330,;最优多元回归模型为乳熟期植被指数构建的XGBoost模型,该模型建模与验证的R~2分别为0.525、0.821。叶片含水量反演,单变量最优估算模型为完熟期以SDr/SDb参数建立的XGBoost算法模型,建模与验证R~2分别为0.741与0.285;多元变量最优估算模型为拔节期植被指数构建的XGBoost多元回归模型,建模与验证R~2分别为0.264,0.298。"
1838,基于遥感数据的水稻生育期识别研究,"水稻的生育期信息是农田管理的重要指标,通过作物生长发育的时间和进程信息可以判断作物的生长状况及其所处的环境,此外,还可辅助大范围的作物提取和环境分析。遥感技术以其覆盖范围大、快速无损、空间连续的优势成为监测作物生育期的有力手段。本文研究首先对水稻不同生育期的冠层光谱特征进行分析,进一步利用不同平台获取的遥感数据进行水稻生育期识别,研究的主要结果有:(1)分别基于地面和无人机平台获取的水稻光谱反射率,利用K近邻、决策树、支持向量机、随机森林、梯度提升决策树和Stacking方法对水稻生育期进行识别。基于地面平台获取的反射率,以随机森林作为次级学习器的Stacking模型的整体识别精度最高,为89.44%。基于无人机平台获取的反射率,梯度提升决策树模型的整体识别效果最佳,精度为98.75%。(2)将基于地面平台获取的高时间分辨率数据建立的水稻生育期识别模型推广应用至无人机平台获取的数据,进行模型跨平台应用的适用性评价。决策树模型的跨平台应用整体识别精度最高,为76.25%,水稻的拔节孕穗期和抽穗扬花期混淆样本数量较多。(3)造成模型跨平台应用的适用性较差的主要原因是两个平台获取的反射率存在差异,次要原因是水稻在拔节孕穗期和抽穗扬花期的四波段光谱特征较为相似。首先通过简单线性模型进行光谱同化,弥补两种数据反射率之间的差异,对无人机平台获取的数据同化后,支持向量机模型的识别精度最高,为78.96%。在支持向量机模型的基础上,进一步分别结合可见光大气修正指数阈值(0.27)和MCA影像第5波段信息熵阈值(0.4)区分拔节孕穗期和抽穗扬花期,最终水稻生育期的整体识别精度分别为86.67%和83.54%。通过光谱同化后结合植被指数阈值或纹理特征阈值均能有效地提高模型跨平台应用的适用性,结合植被指数-可见光大气修正指数的方法效果最佳。"
1839,基于模糊神经网络的联合收割机远程故障诊断系统研究,"作为收割谷类作物的主要设备,联合收割机在达到一定工作时长后具有较高故障率,但在国内中小型主流联合收割机中,远程故障诊断系统还远未进入实用阶段。在此基础上,联合收割机远程故障诊断系统的研究与应用,对保障农作物及时收获、作业机械精准维护具有重要的现实指导意义。联合收割机的远程故障诊断系统是针对联合收割机作业时发生的常见故障,监测系统关键工作部件的实时状态数据,远程对监测数据进行处理获取潜在的故障信息或实时故障信息,从而实现故障的远程预警或报警。远程故障诊断系统既要考虑实用性,又要考虑诊断结果的准确性,实用性为系统在不影响收割机工作的情况下进行实时诊断,准确性表现为系统诊断结果正确率高。针对此需求,本文以模糊神经网络算法为核心,初步建立了一个联合收割机远程故障诊断系统。针对国内外联合收割机故障诊断系统的现状,重点分析了我国在该领域中存在的问题。在此基础上,提出本课题的研究内容和方法;接着搭建基于LabVIEW的联合收割机车载数据监测模块,通过传感器分别采集联合收割机关键部件的工作数据,将实时工作数据同时进行本地实时存储和远程服务器存储,并在本地完成简单的阈值故障报警,远程数据作为历史数据供进一步的学习挖掘;在服务端,实现了用于联合收割机典型故障的模糊神经网络诊断预警算法,并依次用训练集和测试集对算法模型进行训练和验证,结果表明诊断算法可以达到80%以上的准确率。在车载端和服务器端,通过GPRS远程通讯模块将车载监测模块和远程故障诊断模块结合起来,构成了联合收割机远程故障诊断系统;最后进行了联合收割机水稻收割试验,并对试验结果进行分析,试验结果表明本系统可远程准确的诊断联合收割机堵塞故障。"
1840,基于机器学习和零膨胀模型估算大兴安岭树种生物量,"森林在全球碳循环中具有重要作用,而森林生物量不仅标志着森林固碳能力,评估森林的碳收支能力,量化森林碳汇的关键也需要精确估测森林生物量,森林生物量对于全球碳循环研究和森林可持续发展具有重要作用。本研究以大兴安岭林区为研究区,以Sentinel-1雷达数据和Sentinel-2光学遥感数据为主要数据源,结合森林资源清查数据、地形、和气候等辅助数据,探究在估算大兴安岭森林和兴安落叶松、白桦、山杨、樟子松及云杉生物量时,K阶最近邻(KNN)、支持向量机(SVM)、分类回归树(CART)、随机森林(RF)、随机梯度提升(SGB)五种常用机器学习模型在估算不同生物量时的模型表现力,并使用零膨胀模型对云杉和樟子松的生物量估算模型进行优化,进而筛选出估算不同树种的最优模型。在此基础之上,通过最优的建模方法对大兴安岭不同树种的生物量进行估算并分析生物量的空间分布特征。主要的研究内容和结论如下:(1)提取Sentinel-2光学遥感数据的单波段信息,并计算相应的植被指数,提取Sentinel-1雷达数据的后向散射系数和后向散射系数的纹理特征,同时辅以地形数据和气候数据,共提取到44个特征因子。以这44个特征为基础,通过五种常用机器学习方法(K阶最近邻、支持向量机、分类回归树、随机森林、随机梯度提升)来建立特征与生物量之间的关系。以十倍交叉验证的精度指标作为标准,比较五种常用机器学习方法在估算大兴安岭森林和兴安落叶松、白桦、山杨、樟子松及云杉生物量的精度,以此来选择估算不同树种生物量的最佳模型。在估算不同树种的生物量时,总体上是随机森林和随机梯度提升两种模型的效果比较好。在估算森林的生物量时,随机梯度提升模型的精度最高;随机梯度提升是估测兴安落叶、山杨和云杉的生物量的最优模型;随机森林是估算白桦和樟子松的最优模型。(2)对于云杉和樟子松,样本含有许多零值,当使用常用机器学习的回归模型估算这两种树种的生物量时,出现了零值样本数据被过高估计,非零样本数据被过低估计现象。使用零膨胀模型来估算云杉和樟子松的生物量,包括两个步骤:首先对目标树种进行分类;然后在目标树种存在的区域预测目标树种的生物量。在两个步骤中,均比较K阶最近邻、支持向量机、分类回归树、随机森林、随机梯度提升的分类或回归精度,分别选择出分类精度最高的模型和回归精度最高的模型,以此作为估算生物量的最佳的零膨胀模型。随机梯度提升-随机森林零膨胀模型是估算樟子松的最佳模型,随机森林-随机森林零膨胀模型是估算云杉的最佳模型。(3)使用最佳模型估算不同树种在整个研究区的生物量。大兴安岭森林生物量在整个研究区平均为136Mg/ha,在西林吉、图强、阿木尔林业局,森林的生物量值较低。兴安落叶松在大兴安岭林区都有分布。白桦在整个研究区,分布比较均匀,但生物量总体要比兴安落叶松低。樟子松主要分布在大兴安岭北部区域。在五种树种中,云杉分布面积最小,仅在大兴安岭林区的中部区域有小面积分布。(4)使用随机森林特征重要性评价法分析估算树种生物量的44个特征的重要性。在估算树种生物量的44个特征变量中,气温和降水在不同树种的生物量估算中均表现除较强的重要性,VV的信息熵也具有重要影响。在对云杉的生物量进行拟合时,雷达数据的纹理特征影响较小。"
1841,面向中文医疗问题检索的语义匹配技术研究,"随着医疗问答社区逐渐兴起,越来越多的用户通过这些医疗服务平台进行在线查询和问诊。目前医疗问答社区主要通过搜索引擎提供问题检索服务,基于精确匹配的检索方法不能充分地理解用户查询的语义,同时难以应对多样的医学实体表述。有监督学习方法是解决语义匹配任务的常用方法,由于中文医疗领域缺乏语义匹配标注数据,难以很好地利用有监督的语义匹配模型提升医疗社区的问题检索效果。因此,本文重点研究了面向医疗问题检索的语义匹配方法,通过数据集构建、模型改进和迁移学习等方法缓解医疗领域缺乏问句匹配标注数据的问题。本文主要工作包括如下几个方面:・中文医疗领域语义匹配数据集的构建为了解决中文医疗领域缺乏问句匹配标注数据的问题,本文提出了一种半自动化的语料挖掘和数据集构建方法。基于医疗社区的公开问答数据,构建了大规模的中文医疗相似问句对数据集(CMSQP数据集)。为了正确理解和区分医学实体多样化的表述,本文利用开源知识库和医疗垂直网站的百科知识,获取医学实体及其多种表述,构建大规模的中文医疗实体表述词典。・基于Transformer改进的语义匹配模型由于大多数基于LSTM的深度语义匹配模型存在复杂度高、计算速度慢等问题,本文在Transformer模型基础上进行改进,提出了一种面向语义匹配任务的TMTransformer模型。该模型利用Multi-Head Attention机制同时学习语义表示和语义交互特征。在本文构建的CMSQP数据集和公开数据上进行实验,TMTransformer模型比现有工作实验效果更好、复杂度更低,验证了该模型在语义匹配任务上的有效性。・基于迁移学习的语义匹配方法本文设计了两种迁移学习方法提升医疗领域语义匹配任务的效果:跨领域的迁移学习和跨任务的迁移学习。跨领域迁移学习方法实现了不同数据源之间的知识迁移过程;跨任务迁移学习方法通过预训练多分类任务提升语义匹配模型的性能。通过实验验证了两种迁移策略对医疗领域语义匹配任务的提升作用,对比分析了两种迁移策略的效果、收敛速度及适用场景。"
1842,基于不完备医疗数据的疾病风险预测研究,"我国医疗数字化体系经过十年的大规模建设,积累了大量的电子健康记录,这为疾病风险预测研究提供了丰富的数据基础。然而,这些医疗数据中存在着严重的数据缺失问题,即数据在收集或者保存时由于主客观等因素所产生的数据值缺失或者属性缺失,从而丢失系列信息和知识。目前,缺乏对于这种数量化及结构化的医疗数据进行学习的有效方法。疾病风险预测所采用的深度学习模型,多数不能提供模型内部的运行机制和解释,而疾病诊断和临床决策需要模型提供充分合理的证据支持。此外,传统医疗诊断很大程度上依靠医生的经验和领域知识,为使医生在与机器交互的过程中迅速积累经验,补充知识的不足,模型需提供判断的依据。因此,如何结合深度模型的优良性能,同时增强预测模型的可解释性,也需要做进一步的研究。针对上述问题,本文提出了一种适用于疾病风险预测的模拟学习方法,采用谱正则化方法对不完备的医学数据进行学习及填充。谱正则化方法可以准确地对原始数据的遗漏进行估测并且加以填充,该方法能够处理大规模的矩阵并利用问题和数据自身结构。经实验证明,在缺乏特定领域知识或领域专家标注的情况下,该方法可以获得高质量的填充数据并有效降低对后续算法所产生的累计误差。在此基础上,本文利用深度森林对填充后的数据进行分类学习。深度森林利用多粒度扫描及级联结构,获得解释性较好的预测分类结果,具有所需参数少及对参数设置不敏感等优点,同时可以得到精准率较高的疾病风险预测结果。本文评估了基于公共数据集(肌萎缩侧索硬化数据集)及私有数据集(甲状腺癌数据集)所提出方法的有效性。其中,肌萎缩侧索硬化数据集包括6842名ALS患者临床试验的信息,甲状腺癌数据集包括超过11745名甲状腺癌患者及216个患者属性信息。从实验结果可知,本文方法优于其他对比方法,获得了相对高效稳定的分类预测结果。"
1843,肾脏占位性病变CT影像组学模型研究,"肾脏占位性病变(Renal Space-Occupying Lesions,RSOL)是常见的肾脏疾病,其发病率正逐年增加。随着体检的普及以及人们健康意识的提高,早期RSOL的诊断率以及良性肿瘤的发现率有所提升。然而,目前仅通过临床医生依据影像学图像对病人进行人工鉴别诊断仍存在一定的困难,其诊断的精准度存在一定误差,存在一定的误差、误诊和漏诊现象。因此,如何更加准确有效的在术前做出诊断,减少因误诊所导致的不必要的肾切除,就显得尤为重要。近年来,影像组学在肾占位性病变中的应用逐渐增多。影像组学作为一种融合影像、临床表型和基因等信息的研究方法,利用先进的计算机技术进行图像分析。它可以从医学图像(例如CT和MRI)中提取和分析图像特征,并基于这些图像特征构建模型,对疾病进行分析或预测。这对辅助临床做出精准的治疗决策十分有意义[1]。本文基于影像组学方法,对常见且易造成误诊的肾脏占位性病变进行研究,以辅助临床诊断。本文的具体内容包括以下几个方面:1.实验数据预处理。使用从广东省南方医院提供的确诊患者的CT图像作为样本集,通过临床医生手动勾画出的感兴趣区域,并进行三维容积重组得到感兴趣容积。并基于感兴趣容积,利用MATLAB工具包提取了包括几何特征,统计特征以及纹理特征在内的362个特征,用于后续的特征选择以及构建分类模型。2.影像组学在伴结石肾积水是否伴发肾细胞癌中的临床应用研究。本文提出一种SVM-InfFS的特征选择模型,去除特征中的无关特征、冗余特征以及噪声干扰,同时使用支持向量机(Support Vector Machine,SVM)进行分类模型的构建;另外,还研究和比较了不同特征集和特征选择方法对图像分类的影响;并且结合临床医生的诊断情况分析所构建的分类器作为临床辅助诊断应用的可行性。实验结果表明,基于SVM-InfFS特征选择方法所训练出的SVM分类模型可以有效鉴别伴结石肾积水是否伴发肾细胞癌,其准确率高达82.5%。3.影像组学在鉴别肾脏囊性病变中的临床应用研究。首先利用基于ReliefF的前向选择算法(SVM-ReliefF)对特征进行筛选,然后训练极限学习机(Extreme Learning Machine,ELM)以构建分类模型,同时使用敏感性、特异性、准确率、假阳性、假阴性及AUC作为评估指标对分类模型进行评估,并比较分析不同分类器进行分类的准确性。实验结果表明,基于SVM-ReliefF特征选择方法所训练出的ELM分类模型可以更为准确有效的对肾囊肿及肾肿瘤患者进行鉴别,其准确率高达83.1%。"
1844,人工智能引导的宫颈癌特殊染色图像分类算法研究,"随着医疗技术的进步和人工智能技术的飞速发展,跨学科结合的技术手段对于传统的医疗技术产生了极大影响。由于医疗成像设备的普及,医学图像的数量成爆发式增长,如何对其智能判读以减少劳动强度成为广泛探讨的问题。在众多癌症中,宫颈癌作为妇科高发性的恶性肿瘤,发病率及死亡率常年位居各种恶性疾病的前列,然而该病的早期发现及治疗可以大大减少死亡率,因此对于该病的早期筛查工作非常重要,与飞速发展的人工智能手段相结合辅助宫颈癌筛查更是值得研究。传统的宫颈癌筛查通过细胞学检测方法获取的宫颈细胞涂片,包括巴氏涂片检测和液基细胞学涂片检测(TCT),该方法流程复杂繁琐,十分不利于筛查工作的进展。近年来基于叶酸受体介导的宫颈特殊染色方式,借助亚甲基蓝的显色反应来实现快速准确的筛查宫颈癌及癌前病变。本文针对亚甲基蓝宫颈特殊染色液检测图像,设计了完整的图像采集方式,并且制作专门数据集,提出对于宫颈癌筛查通过与计算机视觉技术结合的监督学习分类算法,绕过传统的TCT检测方式,利用监督学习算法提升分类效果和精度,以满足宫颈癌疾病筛查工作的要求。本文研究并概述了机器学习中的经典算法,包括KNN最近邻算法、贝叶斯算法、SVM支持向量机算法、集成学习算法,以及经典的深度学习方法,包括AlexNet网络、SqueezeNet网络、ResNet网络。本文对上述算法进行了全面的分析总结,并通过实验验证的方式,对每种算法进行了参数优化实验,通过大量的实验验证每一类算法在宫颈癌筛查数据集上的分类效果,并通过多个指标确定最适合宫颈癌筛查一体化系统的分类算法。在最终的测试数据上可以达到准确率和召回率均达到90%以上的精度"
1845,新辅助治疗后乳腺癌细胞密度估计研究,"乳腺癌(breastcancer)是女性最常见的恶性肿瘤之一。其易伴随早期淋巴结转移,因此局部手术切除难以达到理想预后。新辅助治疗(neoadjuvant therapy,NAT)可以缩小肿瘤体积并改善预后,已成为乳腺癌术前治疗手段之一。残余肿瘤负荷(residual cancer burden,RCB)是评估NAT后肿瘤反应的指标,对预后预测和指导后续治疗有重要意义。RCB主要通过对病灶部位H&E(hematoxylin and eosin)染色切片的镜下检查来测量,其计算需要6个参数,其中包括癌床区域的癌细胞密度(cancercellularity),即癌细胞在切片中的面积占比。在临床实践中,病理医生通常先在显微镜下确定癌床范围,然后在其中移动视野,并确定每个视野内的局部癌细胞密度,肿瘤整体的癌细胞密度即为视野内癌细胞密度的平均值。这样的估计方法易受到主观因素以及观察者间偏差的影响,同时要求估计者具有较高的专业素养,且费时费力。近年来,机器学习(machinelearning)在数字病理(digitalpathology)中的应用倍受关注。本文旨在设计基于机器学习的病理切片癌细胞密度自动估计算法。本文回顾了支持向量机(SVM),卷积神经网络(CNN),梯度提升决策树(GBDT)等经典模型,简要介绍了实验背景和数据集,提出或改进了以下两类方法:第一,基于细胞核分割与分类的方法。本研究利用颜色反卷积提取图像中的细胞核染色,并通过自适应阈值与高斯拉普拉斯(Laplacianof Gaussian,LoG)滤波器等方式分割图像中的细胞核。针对细胞核分割中常见的重叠问题,本研究提出一种迭代阈值化算法分离重叠细胞核。接着,本研究提取细胞核的形状、灰度、纹理、梯度等特征,训练SVM、决策树等模型,将细胞核分为淋巴细胞,良性上皮细胞,恶性上皮细胞三类,并通过计算恶性上皮细胞在图像中的面积占比来估计癌细胞密度。该方法与人工估计的组内相关系数(intraclass correlation coefficient,ICC)达到了 0.83(95%CI:[0.75,0.86]),超过了改进前的方法(ICC 0.74,95%CI:[0.70,0.77])。第二,基于迁移学习的方法。以CNN为代表的深度学习方法已经被广泛应用于图像信息挖掘中。本研究利用在大规模数据集上预训练的CNN模型从切片图像中提取深度特征,并利用基于互信息的特征选择方法和主成分分析((principal component analysis,PCA)从中筛选有效特征,用于训练GBDT和SVM。该方法使用了范数回归以及排序学习两种模型用于癌细胞密度估计。其中排序学习的目标是计算样本的排序分数,因此还需要通过k近邻将排序分数映射为癌细胞密度值。该方法与人工估计的ICC达到了 0.95(95%CI:[0.93,0.96]),超过了其他已发表方法(ICC 0.88,95%CI:[0.86,0.91])。本文针对癌细胞密度估计问题展开深入研究,提出的两类方法与人工估计都具有较高的相关性,有望在临床上取代人工操作。未来研究重点可放在建立大规模的病理图像数据集,训练更有效的病理图像特征表示等方面。"
1846,基于深度学习的化合物与蛋白质相互作用关系的研究,"化合物与蛋白质相互作用的研究,能够产生对药物设计和研发有重要提示性作用的化合物-蛋白质组合。传统的药物研发通常基于实验验证,可能会遗漏重要的候选组合,并且研发周期长、费用高、成功率低。目前,临床和动物细胞实验积累了大量化合物与蛋白质相互作用的数据,这些基础数据为发现新的组合模式提供了可能。近年来,基于深度学习的方法在很多领域都取得了突破性进展,该方法受生物神经系统信息处理的启发,能够从大量训练数据中自动分层提取特征,因此,使用该方法训练百万级别的数据集,可探索和发现新的化合物与蛋白质相互作用模式,并据此预测与特定化合物相互作用的蛋白质,从而为药物设计和研发的实验验证提供小范围、相对可靠的假设。本文的主要工作是使用TensorFlow框架构建并训练用于预测化合物和蛋白质相互作用的深度学习模型。本文的数据来源于BindingDB数据库。在本文中,将BindingDB中提取的化合物-蛋白质组合数据作为正样本,标签为1;将化合物与蛋白质序列随机组合并去除正样本后的数据作为负样本,标签为0。将正负样本混合后按照98:1:1的比例划分训练集、验证集及测试集。本文构建的深度学习模型是由循环神经网络和深度前馈神经网络组成的复合网络。本网络模型包含以下部分:第一部分是三个动态RNN特征提取网络,分别用来提取化合物中原子块、化学键块数据和蛋白质氨基酸序列数据中的特征,然后将三个特征提取网络的输出结果拼接为一个特征向量后作为第二部分网络的输入。第二部分是一个五个隐层的全连接神经网络,用于学习化合物与蛋白质之间的相互作用关系。最后一层是输出层,有2个节点,以one-hot形式表示标签。这样就将化合物与蛋白质相互作用关系的研究转化成为一个二分类问题的研究。本文从分析原始数据、确定方案、编写调试代码到训练出最终模型,整个研究过程尝试过近百种解决方案,历时两年时间。最终版模型在测试集上得到的准确率为97.32%,F1-Score值为97.39%,AUC值为99.58%。根据结果可以看出,本文使用深度学习对化合物与蛋白质相互作用的研究结果对于探索和发现新的化合物-蛋白质组合有着重要的启示作用。"
1847,从目的论看消费电子产品发布会直播的同传技巧,"随着新科技的普及和社会生活的飞速发展,电视直播这种形式开始愈加频繁地进入大众视野,为大众带来各领域的咨询和信息。如此,针对电视直播节目的电视同声传译也就越来越受到关注。电视直播节目种类繁多,例如新闻播报、访谈节目、重大事件或盛会的实况转播等,这些节目的工作环境和要求各不相同,相应地,针对不同节目的电视同传也就面临着不同的问题和挑战。本文研究的是消费电子产品发布会直播同传面临的问题和挑战。笔者选择了苹果2018年秋季新品发布会的两个现场中文同传版本,利用目的论三原则进行实例分析。上世纪八十年代弗米尔提出目的论,这是德国功能翻译学派的主要理论。目的论认为所有翻译都有目的,而翻译目的决定翻译技巧和策略。目的论有三大原则,分别是目的原则、连贯原则、忠实原则,目的原则是首要法则,即翻译目的决定翻译手段;连贯原则又称语内连贯原则,译文要符合译语语言习惯;忠实原则又称语际连贯原则,译文不违背原文;连贯原则与忠实原则都从属于目的原则。笔者利用目的论三原则探讨两个中文同传版本选择的不同翻译策略及译文产出的不同效果,并邀请同系同学对两个版本同传进行评价,结合笔者的研究和同系评审的评价,笔者找到消费电子产品发布会直播同传面临的共性问题,并提出解决意见和方法,希望以此提升这种形式电视同传的质量。"
1848,拍客侵权行为研究,"科学技术的蓬勃发展为社会经济发展提供了新的引擎,加上互联网的普及化、自媒体平台的飞速发展,拍客的出现是情理之中的,也是顺应时代的要求的,在信息传播方向,拍客侵权行为具有大众媒介不同的特点,及其对个人信息权等人格权益造成侵害在范围、程度、表现等方面和传统媒介的不同,由此得出应对拍客侵权的问题应当采取的新措施。在侵权认定方面,传统媒体侵权认定与拍客侵权的认定也存在不同,及后对其二者所应尽的审查也应当采取不同的形式。现代技术的发达、手机等摄像设备使用的普及,拍客所拍摄的短视频画面或其直播的画面日趋成为与主流大众媒介并驾齐驱的舆论猎场,其在舆论导向及与未成年人价值观的导向方面有着十分重要的作用。拍客在信息传播方面是占据着优势地位的,其各方的条件也是得天独厚的,网络技术的加身使得拍客行为具有传播速度快、具象化、范围广、审查起来较为困难等特点。公众自我表达的意愿不断提高,拍摄设备的亲民化,人们为丰富精神生活的需要,使得拍客成为最受受众所喜闻乐见的民间信息传播者。本文尝试以拍客侵权行为为切入点,在人格权益的范围里探讨拍客行为的特点,及其与传统媒介在侵权认定、特点等方面的区别。本文的第一章列举拍客侵害个人信息权的认定及侵权程度不同的两个阶段,因拍客以图像、短视频侵权为主,而传统媒介大多以文字侵权为主,且多为具有新闻资质的主体。传统媒介在发布信息的时候,内容受到更为严格的监管与审查。而拍客除了相关行业规范对其有所规定外,现行法律并无明确的规定。但在对个人信息权的影响上,有着异曲同工之处,即都是从较小的信息碎片汇集,直到信息量汇集到一定程度,成为信息集,其中单一的信息能够直接识别到自然人,亦或是拍客与传统媒介发布的信息包括他人的敏感信息,在此情形下应构成对他人个人信息权的侵害。第二章通过比较传统大众媒介与新型拍客在肖像权、名誉权、隐私权侵权的认定及侵权行为发生后救济方式、责任承担的异同,提出新的应对措施。主要论述拍客侵权行为相较于传统媒介侵权特点的比较,肖像权、名誉权、隐私权在网络时代如何得到保障,新型侵权软件的出现增加的侵权的类型自媒体平台是如何做出应对等。拍客侵权行为与传统的大众传媒侵权有许多不同之处,Fake app等视频编辑软件的出现使得拍客侵权影响层级加深,范围更大,种类新颖丰富。机器学习技术是一把双刃剑,一方面可以使得人们的娱乐生活更为丰富,但另一方面也成为少部分人侵害他人人格权益的利器。第三章论述拍客行使其言论自由权利的时候,如何界定其边界,权利不是无边界的,无边界的自由意味着绝对的不自由。因而,本文列举了拍客侵害人格权利的除外情形:1、当事人自愿放弃,即当他人个人信息的披露有利于社会教化,且当事人自愿放弃其相应的人格性权利时,拍客在此情形下的拍摄行为应属于言论自由的范围之内2、符合社会公共利益,社会的进步离不开先进思想的传播,如果拍客拍摄行为是为了公共教育,科技发展等目的,则应该不列于侵权之列。3、拍客所拍摄的信息不能定位到个人,即并不能定位到某个具体的自然人,而是作为背景出现,此种情形未造成任何权益的损失,因此不能视为侵权。第四章讨论网络服务提供者在平台上出现他人拍摄的侵权画面和短视频时,应当承担怎样的责任,有无免责规则,以及在责任承担之后是否能够采取相关措施弥补平台服务提供者和受侵害者权益的损失。从讨论中得出网络服务提供者应该承担审核义务,但该审核义务并不是无限度的,而是在力所能及的范围内,利用机器学习技术进行审查。本文从拍客侵权行为的特点出发,逐一比对其与大众传媒侵权的不同。目前,我国没有专门的法律法规对拍客言论自由进行限制,因此给拍客们自由发挥的余地很大,常常会因为无边界而陷入侵害他人权益的情况。若拍客通过不正当拍摄手段拍摄侵害他人名誉权或隐私权的画面,并上传至自媒体平台,如抖音、西瓜小视频、微博等自媒体平台,如何可以利用现有的技术,更快速的,以效率较高的方式及时止损,回复他人的名誉也是机器学习可以解决的一个问题。关于拍客侵权行为,我国尚未明确立法,因其与现代科学技术紧密相连,具有匿名性、广泛性、便捷性、互动性等特点,宜以立法保护为主,行业自律为辅的保护模式。网络服务提供者在拍客侵权行为发生后应当承担什么样的责任,应当采取什么样的措施对拍客侵权行为造成的恶果进行补救。如何利用现今最流行的机器学习技术来代替复杂的人工审查,简化网络服务提供者巨大的审核工作量,也是对未来以人工智能等先进技术取代一部分专业的法律识别的一种展望。"
1849,基于过采样方法的信用卡用户违约预测分析,"随着信用卡业务在全球范围内的迅速普及,信用风险也急剧扩张。大量信用卡用户违约行为的出现,给银行等金融机构带来了较大的损失。因此,对信用卡用户的信用风险进行预警,提前识别违约用户就变得尤为重要。它能够为银行等金融机构提供决策依据,帮助其制定合理的放贷策略,降低自身风险,促进自身健康发展。一般来说,信用卡数据集中各类别的分布是极度不平衡的,未违约人数占比较大,违约人数占比较小,传统的人工信用风险评估模型已不适用。本文将利用数据挖掘技术和机器学习方法,从数据和模型两个方面对信用卡数据集进行探索分析。本文使用的数据集来自Kaggle官网,为国外某银行2015年到2017年两年间信用卡用户的历史消费及违约记录,该样本集中的类别分布极度不均衡。首先,本文将分别采用SMOTE算法和ADASYN算法对数据集进行过采样处理,使得处理后数据集中的类别相对平衡,这样做的优点是不会损失样本中多数类的信息。然后基于过采样后的数据,分别建立逻辑回归、随机森林、神经网络、XGBoost预测模型,通过对各个模型的评价指标的对比,找到最优的预测模型,使得其能够最大限度的识别违约用户。最后通过对各个模型结果的分析,找到影响用卡用户出现违约行为的主要因素。"
1850,面向种群的Android安全风险评估和恶意应用检测,"在Android系统安全问题中,Android应用的权限调用合理性是一个不确定性问题,某些权限是否逾越了应用本身的功能范围,一些隐私权限是否会造成用户隐私泄露。从单个应用的角度很难确定应用所申请权限的合理性。同时,在Android安全问题中,应用的恶意性和其申请的权限密切相关。应用程序所申请的权限是进行安全性评估和检测的重要对象。相似用途的应用具有相似的功能,从而形成相似的权限需求。相比于个体层面的独立性,种群中的应用是具有关联性的。本文从种群视角展开研究,克服个体角度难以判断Android应用权限调用合理性问题。借鉴生物学中种群的概念,本文提出了一种面向种群的适用于大规模Android应用评估和恶意应用检测的方法。主要工作如下:(1)面向种群的Android应用隐私泄露风险评估。现有的Android应用评估方法,主要考虑评估的准确率而忽视了评估的效率,并且现存方法大多是将不同功能类型的应用混合在一起构建数据集,没有很好的考虑应用功能之间的差异。针对现存问题,提出了一种种群角度的Android应用隐私泄露风险评估方法,可以同时为大规模应用提供评估服务。通过群体特征分析和种群聚类,进行高效大规模的应用隐私泄露风险评估。实验结果可以为用户提供下载推荐和应用软件权限设置参考。(2)基于集成学习的Android种群恶意应用检测。应用的恶意性和其申请的权限密切相关。针对目前恶意软件检测技术存在漏报,特征冗余导致检测周期较长,检测过程中良性样本和恶意样本数据量不平衡导致检出率不稳定等不足,面向种群,提出了一种基于集成学习的Android恶意应用检测方法。从群体角度开展检测工作从而提高恶意应用检测的准确率和检出率。利用卡方检验和信息增益算法,在进行分类检测之前进行特征筛选能去除大量冗余特征,从而提高检测效率。以种群为检测单位,可以在未进行种群划分的基础上,提高恶意应用检出率。同时运用了改进的SVM算法和改进的朴素贝叶斯算法组成集成分类器,在种群的基础上利用多模型投票的方式进一步提高Android恶意应用的检出率。"
1851,面向微博文本的情感分析模型研究,"随着互联网和移动通讯的飞速发展,人们参与网络活动越来越频繁,微博每天都产生了大量数据,其包含了用户对事物的情感表达和评论分析,如何从这些信息中挖掘出情感倾向有着巨大的价值。因此,本文对微博文本展开了情感分析模型的研究。通过调研国内外文献,目前对于情感分析模型的研究主要有情感词典方法、机器学习方法和深度学习方法。本文通过爬取微博数据,对这三种方法进行对比实验,寻找最优的情感分析模型。基于传统情感词典方法的研究。利用波森情感词典,将文本数据分词后遍历词典并加权得到其情感极性,然后在此基础上利用添加情感副词的方式提升情感词典的效果。情感词典方法的优点是速度快,易于判断主观情感比较明确的句子,但是其缺点是针对不同场景的迁移能力弱,并且人工构建针对某一领域的情感词典耗时耗力。基于机器学习方法的研究。首先对文本数据进行数据预处理,将经过预处理后的数据分词结果通过Word2vec中Skip-gram方法转化为词向量,同时利用腾讯开源词向量进行对比输入,然后利用主流的机器学习分类方法(Logistic回归、随机梯度下降法、朴素贝叶斯、支持向量机、随机森林、XGBoost)进行有监督学习,最后对比每种模型的测试集混淆矩阵,发现腾讯开源词向量训练的模型效果均优于Word2vec方法训练出来的词向量。在这些方法中,随机森林、XGBoost这类利用集成思想方法训练的模型效果远远优于单一的分类模型。虽然机器学习方法模型的准确率对比传统情感词典有了很大的提升,但是不足之处是每个训练器都涉及到大量的调参,并对于不同业务场景的迁移能力不强,机器学习方法已经发展到了瓶颈。基于深度学习方法的研究。通过对经典的多层感知机神经网络、循环神经网络、卷积神经网络和自注意力机制进行对比实验,各类深度学习模型的准确率比情感词典和机器学习的准确率有了较大的提升,其中自注意力机制模型在测试集的准确率达到了91.12%。通过对所有模型进行对比实验,发现自注意力机制所训练的模型无论在训练速度上还是在模型测试集的准确率等方面均优于其他模型。并且它利用序列内部的自我关注,加快了模型收敛的速度。所以,自注意力机制的模型是情感分析任务中综合表现效果最好的模型。"
1852,基于长短期记忆网络的事件抽取研究与应用,"近年来,随着互联网的爆炸式发展,海量的数据通过文本数字化的形式呈现出来。面对信息爆炸的时代,如何从无结构的文本数据中提取出人们关注度高的热点信息成为自然语言处理当前的主要研究方向。信息抽取技术被作为这一问题的解决方案受到研究人员的广泛关注。其中,事件抽取是信息抽取技术的重要环节,也是信息抽取领域中最具挑战性的任务之一。事件抽取的目的是从无结构的文本数据中抽取出描述事件的关键元素,并将事件结构化的展示出来。当前事件抽取技术主要是基于语料的有监督学习,对高质量的语料标注依赖性较强。事件抽取从抽取的过程上可以划分为事件触发词抽取和事件要素抽取两个阶段。事件抽取技术的研究对知识图谱、舆情分析,自动文摘和机器翻译等自然语言处理任务具有重要的指导意义。传统事件抽取方法大多存在关键特征提取不足,容易忽略上下文语境信息等问题。为了解决上述问题,本文在长短期记忆网络的基础上,引入卷积操作和注意力机制,进行了一系列事件抽取相关的研究。本文的主要研究内容包括:1、本文提出了基于卷积长短期记忆网络模型的事件触发词抽取方法。在事件触发词的特征选择上,采用词向量和位置向量作为事件句的文本向量化表达。为了解决传统事件抽取方法中一词多义现象造成的事件分类错误问题,利用长短期记忆网络提取句子级别特征,卷积操作提取词级别特征,而后将两种特征结合起来进入输出层进行事件触发词抽取结果的预测。最后,除了标准的事件触发词抽取结果外,本文还在模糊触发词抽取任务上验证了模型的有效性。2、本文以注意力机制为核心,在长短期记忆网络模型的基础上,搭建了基于Encoder-Decoder框架的事件要素抽取模型。在特征选取上,除了词向量与位置特征外还选取了事件触发词类型特征作为文本向量化的表示。在事件要素抽取模型的构建上,注意力层能够有效表现出事件触发词和其它事件要素对候选事件要素的影响,解决了当一个事件句中包含多个事件时,事件要素角色容易识别混乱的问题,从而提高了事件要素的抽取效率。3、本文将事件抽取模型应用在新闻舆情领域,实现了新闻舆情事件抽取原型系统。新闻舆情事件抽取原型系统在具体的事件触发词和事件要素两个阶段中,分别采用基于卷积长短期记忆网络模型和基于注意力机制的长短期记忆网络模型,以流水线的方式完成事件抽取的全部过程。为了解决系统在实际应用过程中训练语料规模不足、无法适应新领域的问题,本文设计了增量学习框架,增强了系统的健壮性和普遍适用性。在事件具体展示的实现上,本文除了实现事件的结构化展示,还从时间和空间的不同维度上设计了事件时间轴和事件地图功能,使新闻舆情事件的记录有序化、系统化和完整化。"
1853,基于事件感知的可对抗模型衰退的安卓恶意应用检测系统,"随着智能手机和安卓系统的普及,越来越多的针对安卓系统的恶意应用软件不断出现在各大应用商店,由于这些恶意应用会造成用户隐私泄漏以及财产损失,它们受到了研究者、民众以及攻击者越来越多的关注。然而,现在大多基于机器学习的静态和动态恶意软件检测方法都是直接从API水平提取统计特征来进行分类,无法获得足够的有效行为信息来检测隐藏的恶意行为。同时,随着恶意应用不断的变化和改进,基于旧样本训练出来的模型不能适应恶意应用的这种快速变化,随着时间的推移性能不断衰退,难以有效地检测新出现的恶意应用。针对以上问题,本文提出了一种基于事件感知的,具有强适应性的、可对抗模型衰退的安卓恶意应用检测系统。首先,它能够综合利用安卓应用中不同事件所包含的行为模式来有效地检测新的恶意应用。其次,本文使用自然语言处理和聚类算法识别API功能来捕获变化的API,以此来对抗机器学习模型衰退。最后,本文还设计了一个浅层神经网络来提取特征以及分类。本文提出使用事件群来描述应用在事件层面的行为模式,这种方式能够比API层面提取更加高层的行为信息,以此来检测那些具有隐藏行为的恶意应用。事件群是由不同事件的行为特征组成,在事件群中,本文进一步使用了功能集群来表示每个事件的行为特征。功能集群通过自然语言处理工具,基于事件中的API组成的语义信息,将事件API泛化为对应事件的特征向量,这样系统可以在恶意应用更新时仍然能捕捉到它的恶意行为。为了能够从事件群中提取足够有效的特征,本文特别设计了一种神经网络来联合不同事件的特征并自动挖掘事件之间的关系,综合地评估一个应用是否为恶意应用。通过事件群和功能集群,本文系统能够适应恶意应用的进化,在模型训练完成很长一段时间内,还能够保持模型较高的检测准确度。为了验证本文检测系统的有效性,本文在包含了14,956个正常应用以及28,848个恶意应用的数据集上进行测试,实验结果表明本文系统能够抵御恶意应用进化带来的模型衰退,并比现有相关的工作更好。"
1854,基于生成对抗网络的手写体汉字生成,"自数字化时代以来,手写汉字生成一直是计算机视觉领域的重要研究方向。传统方法主要关注汉字的局部特征信息,而未学到数据的整体分布情况。生成对抗网络(Generative Adversarial Networks,GANs)能够通过自动学习真实数据的分布来生成以假乱真的样本。对于手写汉字生成任务,不仅需要学习汉字的书写风格,更重要地是保证生成汉字具有准确的笔画结构。然而由于手写汉字数据集包含结构复杂、风格多样的汉字样本,一般的GANs算法难以生成结构清晰且笔画准确的结果。本文针对手写汉字生成存在的难点,提出以下两个新的模型与算法:(1)本文提出Optimized Feature Matching Conditional GAN(OFM-cGAN),基于改进的特征匹配算法与结构一致性损失,来进行手写汉字生成。原始特征匹配算法(feature matching)通过直接优化训练数据与生成数据之间特征的平方差损失,使得GANs能够学到更多的真实数据分布信息,然而生成的图像却存在多样性不足、轮廓模糊等缺点。本文提出改进的特征匹配算法(optimized feature matching),在计算特征匹配损失时使用L1范数代替原始算法中的L2范数,并在生成器与判别器的训练中同时应用提出的改进算法。为减少笔画不规则的训练样本带来的干扰,本文提出结构一致性(structure consistency)损失,进一步限制生成器的映射范围。实验结果与分析表明,相比于原始特征匹配算法,OFMcGAN能够生成更加逼真的手写汉字图像。OFM-cGAN在其它通用数据集上也取得了较好的生成结果。(2)本文提出Optimized Feature Matching CycleGAN(OFM-CycleGAN),通过少量的手写汉字样本,来自动实现从标准汉字到手写汉字的转换。CycleGAN能够在不成对匹配的数据集上进行图像到图像的转换。然而由于手写汉字数据集中笔画与结构较为复杂,尽管CycleGAN能够生成具有手写风格的汉字图像,但生成结果中存在较多的笔画错误,无法匹配其原始的标签信息。为提高生成汉字的笔画准确性,本文提出基于改进的特征匹配算法的OFM-CycleGAN模型。本文在CycleGAN的正向与逆向映射过程中同时应用改进的特征匹配算法,促使模型在循环映射过程中学到更多的真实数据分布信息。与传统方法相比,本文的算法不需要笔画提取等复杂流程。实验结果与分析表明,相比于原始CycleGAN,OFM-CycleGAN有效地提升了手写汉字的生成质量,并实现了不同字体的标准汉字到手写汉字之间的转换。大量的实验数据显示,本文所提出的两种模型有效地提升了手写汉字的生成质量,不仅具有清晰的图像结构信息,能够学到多种不同的手写风格,同时提高了生成汉字的笔画与结构的准确性。"
1855,基于深度学习的跨领域跨语言知识获取,"随着互联网上信息的生产与积累,如何从大量纯文本中获取高质量的结构化知识,是目前自然语言处理的研究热点。通用领域的知识注重广度,在搜索引擎的查询理解、智能问答的推理等领域已经有广泛应用。然而,由于长尾效应的影响,通用知识在特定领域的覆盖度往往严重不足,因此近年来学术界和工业界的研究兴趣逐渐转向垂直领域。领域知识获取有诸多挑战,一方面领域知识上下文的稀疏性导致传统基于模式的抽取方法准确率较低,另一方面不同领域之间的差异性导致在某个领域学到的知识无法有效迁移到其他领域上。此外,领域知识的跨语言迁移也是目前的研究热点。本文利用深度学习的技术,针对跨领域和跨语言的知识获取,做了如下三方面的工作:・单一领域的探索式关系分类 我们提出了探索式神经网络关系分类的模型,用于解决领域知识抽取中长尾关系无法被完整定义的问题。该模型一方面学习在预定义关系上的神经网络分类器,另一方面通过相似度敏感的中餐馆过程算法,在未标注数据中发现新的关系种类,持续扩充预定义的关系集。该算法在维基百科的领域知识图谱上有较高的分类准确率,同时能够发现高质量的新关系。・跨领域的知识体系抽取 针对不同领域之间的知识迁移,我们分别提出了基于全共享网络、部分共享网络的模型和基于预训练语言模型的微调策略。其中,超大规模的无监督文本数据可以学习到不同领域间通用的底层语言学的特征。在三个领域的概念依赖分类任务中,实验结果显示提出的模型能够有效地将知识在不同领域中迁移。・跨语言的术语翻译 考虑到领域知识在不同语言之间迁移时会出现由于词汇分布不一致性所导致的偏差,我们提出了基于多矩阵的软映射方法,将源语言的向量空间映射到目标语言向量空间上。利用源语言向量空间的聚类信息,标注数据可以学习到其对于每个隐含类别的权重,使得领域知识在语言之间更合理地进行迁移。本文针对双语词典生成的任务,在通用数据和领域数据上均进行了实验,结果显示该模型在特定领域具有更大的优势。"
1856,面向中文医疗文本的命名实体识别研究,"命名实体识别主要研究从非结构化文本中识别出包含特殊含义的词汇或专有名词,是自然语言处理领域中一项重要的基础性技术,在信息检索、问答系统等领域有着广泛的应用。目前,大量工作聚焦于开放域的命名实体识别且以英文为主,本文则主要研究中文医疗文本的命名实体识别问题,以不同类型的医疗文本为研究对象,既有以临床电子病历为代表的专业医疗文本,也有来自大众医疗领域的医疗搜索查询和在线问答数据。本文首先基于神经网络方法构建基本框架,然后提出外部知识获取与融入方式来利用医疗词典信息增强模型效果,最后基于迁移学习方法利用外部数据进一步提升识别效果。本文的主要工作和贡献如下:・基于神经网络方法的命名实体识别 为避免对特征工程的依赖,本文首先基于神经网络方法构建解决命名实体识别问题的基本框架NN-CRF,标注和整理得到三个中文医疗文本的命名实体识别数据集。通过实验比较了字粒度输入和词粒度输入对识别效果的影响,验证了神经网络方法在不依赖特征工程前提下,相比传统统计机器学习方法仍然可以取得更好的效果。另外,对比三种典型神经网络模型的识别效果差异,并给出合理设计模型的指南。・基于外部知识增强的命名实体识别 考虑到医疗领域存在大量的外部资源,本文通过引入外部知识以辅助模型识别在训练集中很少出现或没有出现的实体。本文以医疗词典信息为例,提出两种获取外部知识的方式,分别是特征模板法和字词联合法,并设计两种外部知识的融入方式,即直接输入法和间接输入法,最后通过实验验证上述方法能够增强模型的泛化能力。・基于外部数据提升的命名实体识别 为缓解缺乏标注数据的问题,本文基于迁移学习方法利用外部数据提升已有模型的效果。主要探究两种解决思路,其一,以语言模型为任务利用大量无标注数据预训练模型,借助参数迁移加速模型收敛和提升效果。其二,以多任务学习方式充分利用相关的标注数据集,提出共享私有模式的参数共享框架,并且在改进的迭代策略下有效训练,从而更大限度地提升目标领域的识别效果。"
1857,基于3D残差密集网络的视频烟雾检测研究,"视频烟雾检测技术因其响应速度快、不易受环境因素影响等优势,所以被广泛应用,为早期火灾预警提供有效保障。传统的视频烟雾检测方法主要通过提取烟雾的图像特征,采用机器学习的方法分类识别烟雾,检测准确率虽有提高,但仍存在高误报率和高漏报率等问题。运用卷积神经网络识别图像可以自动从图像数据中学习特征,更好的刻画图像的本质信息,有利于分类识别。针对传统检测方法和二维卷积神经网络只能提取图像的空间信息而导致误报与漏报的问题,本文提出了一种基于三维卷积神经网络的3D残差密集网络检测视频烟雾的方法。基于3D残差密集网络检测视频烟雾的方法,主要处理的是连续帧的视频图像,本文综合运用分块运动检测和烟雾运动方向检测疑似烟雾,快速滤掉大部分非烟区域,降低了烟雾检测的计算量,提高了后续检测的精度。同时,将残差模块Residual Block和Dense Block进行整合,形成了Residual Dense Block(RDB),并将其拓展到3D Residual Dense Block,以提取烟雾的时空特征,并使用公开的数据集进行算法性能的验证,并与目前较主流的检测方法进行比较。实验证明本文方法在检测准确率上明显提高,误检率与漏检率也有所降低。"
1858,基于神经网络的命名实体识别与实体关系联合抽取,"随着网络信息化的逐步发展,非结构化的文本信息不断增长,如何对大量产生的非结构化文本信息进行有效的处理成为研究的热点。信息抽取技术因其能够从非结构化的文本信息中进行结构化抽取,受到学者们的广泛关注。其中,命名实体识别与实体关系抽取作为信息抽取领域的重要课题,目前解决这个问题的方法主要分为两类:串联抽取和联合抽取。串联抽取方法是通过首先进行命名实体识别,再进行实体关系抽取。这种抽取方式将命名实体识别与实体关系抽取定义为两个相互独立的子任务,它的优点是各个模块之间相互独立、灵活度较高且易于实现。但是,它忽略了两个任务之间的内在联系,而且通过串联抽取方法进行命名实体识别的结果会直接影响到后续进行的实体关系抽取,极易产生误差累积。联合抽取方法旨在构建联合抽取模型,当命名实体识别与实体关系抽取之间存在较强内在联系或依赖关系时,联合抽取模型能够更好的整合两者之间的信息,降低各个中间步骤产生的错误,进而提升抽取模型的性能。本文通过充分分析命名实体识别与实体关系联合抽取方法的研究现状,对目前在命名实体识别与实体关系联合抽取领域效果显著的几种方法进行分析与实验,依据传统联合抽取模型存在的不足,本文提出以下工作:1.为解决串联抽取方法带来的一系列问题,并且避免复杂的人工特征工程,本文通过构建基于神经网络的联合抽取模型进行命名实体识别与实体关系联合抽取任务,基于神经网络的联合抽取模型将命名实体识别与实体关系抽取整合到一个模型中,能够在充分考虑两者内在联系的同时减少人工抽取特征工作。2.针对典型联合抽取模型在训练时需要先进行NER,再根据NER的预测信息进行两两匹配来进行关系分类,易于造成信息冗余的问题。本文提出一种标记策略,将联合抽取问题转化为标注问题,在一定程度上避免了信息冗余的产生。3.本文的研究重点是对于命名实体以及实体间的关系组成的三元组进行抽取,这种抽取方法需要对三元组进行建模,所以,本文基于新的标记策略,构建LSTM-LSTM端到端联合抽取模型,端到端联合抽取模型可以直接通过LSTM神经网络进行建模且无需复杂的特征工程。此外,本文在LSTM解码层添加带有偏置的目标函数,使标签与基于LSTM-LSTM的端到端模型更契合。4.在LSTM-LSTM-Bias模型中引入注意力机制,对模型的输入与输出的相关性进行有效分析,从而获得更多的上下文语义信息。实验结果表明,基于LSTM-Att-LSTM-bias的联合抽取模型能够更准确地识别命名实体并预测实体对关系,实验结果验证了本文提出的算法的有效性和准确性。"
1859,基于数据挖掘的告警关联关键技术研究,"信息技术在给人们的生产、生活带来巨大改变的同时,也带来了许多的安全问题,网络安全形势日益严峻。入侵检测系统(Intrusion Detection System,IDS)作为保护网络安全的重要工具已被广泛投入使用;然而,IDS产生的告警冗余度高、误报率高且不能反映出攻击者的多步攻击策略。因此,应用告警关联技术分析IDS告警信息以重构多步攻击场景显得非常重要。数据挖掘作为一种数据智能分析技术,能自动地从大量数据中提取出有用信息。本文以基于数据挖掘的告警关联技术为研究内容,对IDS告警预处理方法、IDS告警关联方法进行了研究,主要内容可归纳如下:(1)研究了数据挖掘技术在告警预处理方面的应用,提出了一种面向IDS告警的预处理方法。IDS产生大量冗余度高、误报率高的告警,若不去除这些大量存在的误报及冗余告警,将会对后续多步场景挖掘的有效性提出巨大挑战。为此,提出了一种面向IDS告警的预处理方法。通过分析告警样本,提出了四个用于区分误报与真实告警的群体特征,结合决策树等分类算法训练误报判定模型对IDS告警进行误报判定,降低了误报带来的影响;将滑动时间窗口用于冗余去除,降低IDS告警的冗余度。实验结果表明,本文所提出的IDS告警预处理框架能大大降低误报和冗余告警,为后续的关联分析提供数据质量保证。(2)研究了面向IDS告警的多步攻击场景重构技术,提出了一种基于多因素的告警关联方法。告警关联分析通过对底层告警进行综合分析与处理,揭示出其中包含的多步攻击行为。许多的告警关联方法通过在原始告警中挖掘频繁模式来构建攻击场景,方法容易受冗余告警、误报影响,挖掘出的多步攻击链在某些情况下不能反映出真实的多步攻击行为。为此,提出了一种基于多因素的告警关联方法。通过聚合原始告警以得到超级告警,降低了冗余告警带来的影响;将超级告警构造成超级告警时间关系图,同时结合超级告警间的多因素关联度评价函数从图中挖掘出多步攻击场景。实验结果表明,该方法能克服冗余告警及大量误报带来的负面影响、有效地挖掘出多步攻击链。"
1860,基于边界特征和代理模型的实例选择,"大数据时代的到来,使得海量数据的存储代价、基于实例的机器学习算法的性能和效率均面临极大挑战。通过从原始训练集中选取对数据分析有显著贡献的实例,即实例选择是解决上述问题的可行途径之一。然而,目前已有实例选择方法计算代价较高,且难以均衡筛选子集性能与约简率之间的关系。为此,本文提出基于边界特征和代理模型的实例选择方法,以尽可能保持选择样本的性能及减小计算代价,主要研究内容如下:(1)基于可移除性和边界特征的动态重要数据查找实例选择:边界实例对保持样本分布特性及学习器至关重要,同时,考虑计算复杂度,提出一种基于可移除性和边界特征的动态重要数据查找的实例选择策略。首先,随机初始化实例的重要性权重,选择权重小的样本作为待删除实例;给出基于K-means聚类的实例选择可移除性定义;然后,计算删除实例与原始聚类中心的距离,衡量实例的边界特征,进而给出基于实例可移除性和边界特征的重要性权重更新策略;动态调整删减比例,给出基于重要性权重和删减比例的样本选择机制。所提算法在20个UCI典型数据集上的应用,验证了其保持样本学习性能的有效性。(2)基于代理模型预测数据重要性的实例选择:针对研究内容(1)实例选择因迭代次数多而导致算法耗时的问题,提出基于代理模型预测数据重要性的实例选择方法。首先,利用裁剪最近邻算法去除数据集类边缘的噪声实例;然后,根据研究内容(1)中数据重要性的标记策略,计算待删减样本的统计特性以及删减样本后聚类中心到初始类中心的距离,构建高斯过程预测模型,预测实例选择精确性(类中心距离);给出融合降噪和代理模型的实例选择策略。将所提算法应用于内容(1)的典型数据集,实验结果表明,所提算法在对实例选择的精度预测方面具有较好的预测性能,且在相同约简率的条件下,大大降低了实例选择过程的计算成本。本文提出的基于可移除性和边界特征的重要性动态更新实例选择策略,利用聚类迭代过程可在一定程度上选择出类边界实例,进而根据实例的可移除性及边界特征更新数据重要性权重,逐步删除权重较小的实例,达到降低数据集规模并提高基于实例选择的机器学习算法性能的目的;基于代理模型预测数据重要性的实例选择算法,在裁剪最近邻降噪的基础上,利用高斯过程预测实例选择的精确性对内容(1)实例选择方法进一步改进,从而在保证筛选子集分析性能的条件下大大降低了算法的时间复杂度。"
1861,基于随机矩阵理论的高维数据分析方法研究,"在生产实践中收集并存储了越来越多的维度p接近甚至超过样本数n的高维数据。与传统的数据分析不同,高维数据分析更加复杂和困难。作为数据分析的重要工具,机器学习方法同样面临着高维数据的挑战。如何利用机器学习方法完成对高维数据的分析,目前已成为数据领域广泛研究的问题。随机矩阵的渐近性和非渐近性理论打破了经典多元统计分析的框架,非常适用于高维数据统计特性的研究,可以帮助机器学习算法完成对高维数据的分析,扩展其应用范围。本文针对传统的机器学习方法在高维数据分析中存在的问题,利用随机矩阵理论的相关研究成果,提出了正则化的判别分析算法、均值良好估计的正则化判别分析算法以及高维缺失数据的降维算法。论文的主要工作如下:(1)线性判别分析算法尽管在解决许多实际问题时表现良好,但是在处理高维数据时效果却很不理想。其原因在于:当数据维度p接近或者大于样本数目n时,样本协方差矩阵不再是真实协方差矩阵的一个良好估计,导致线性判别函数值产生了较大的偏差。为此,提出一种基于随机矩阵理论的正则化判别分析算法。首先,分别以非线性收缩法或特征值截取法对高维协方差矩阵做出良好估计;然后,使用估计的高维协方差矩阵计算判别函数值并进行分类。在模拟数据集和真实数据集进行的分类实验表明,所提算法不但适用范围更加广泛,而且具有较高的分类正确率。(2)判别模型中的样本均值同样受到高维数据的影响,样本均值估计会出现偏差,从而导致判别模型误分类率的增加。为此,提出一种基于均值良好估计的正则化判别分析算法。在正则化判别分析算法的基础上,首先利用最优收缩估计方法重新对判别模型中的均值进行估计;然后,将重新估计的均值代替判别模型中的样本均值,进一步提高了正则化判别模型的分类性能。通过对模拟数据集和真实数据集的分类实验分析,也显示出所提算法的优越性与有效性。(3)数据在采集和存储的过程中可能会造成一些数据的缺失。当高维数据含有缺失值时,大多数数据分析方法很难对高维缺失数据进行分析或分析效果不理想。为此,提出一种可用于高维缺失数据降维的主成分分析算法。首先,基于随机矩阵理论的相关理论,利用矩阵的Lasso估计得到高维缺失数据的协方差矩阵估计;然后,对其进行特征分解,选取主要的特征向量构成低维投影矩阵,并利用投影矩阵将高维数据投影到低维空间;最后,结合线性判别分析算法对高维缺失数据进行分类。在模拟数据集和真实数据集上的分类实验表明,所提算法可以完成对高维缺失数据的降维,同时也能提高线性判别分析算法在高维缺失数据上的分类正确率。"
1862,基于改进深度学习的移动APP广告转化率预估,"在移动APP广告转化率预估场景中,用户交互产生了大量数据,广告转化率预估面临数据高维稀疏、特征间高度交互和用户兴趣模型难以构建等挑战。如何利用大量的高维异构数据,自动获取特征之间的交互关系,并通过采集到的用户行为序列数据构建用户兴趣偏好模型,是实现转化率准确预估的关键,近年来蓬勃发展的深度学习为上述问题的解决提供了可行途径。鉴于此,本文研究基于改进深度学习的移动APP广告转化率预估(简称转化率预估),主要内容如下:(1)基于改进Wide&Deep自动特征交互关系抽取的转化率预估:针对转化率预估问题特征高维稀疏、特征间高度交互等特点,提出了融合域因子分解机(Field-aware Factorized Machine,FFM)和深度卷积神经网络的改进Wide&Deep模型,以有效获取高维度稀疏特征的低阶和高阶交互关系,实现特征自动高效组合,提高移动APP广告转化率预估精度。针对稀疏数据的嵌入,提出了基于宽度模块FFM挖掘低阶特征交互关系的特征组合算法;然后,根据FFM所提取隐特征向量,进一步给出了基于深度模块多层卷积神经网络提取高阶交互关系的特征提取策略;最后,将宽度和深度模块分别获取的特征组合用于转化率预估。所提算法在腾讯移动APP广告转化率预估中的应用表明了该方法在提高预估精度上的有效性。(2)融合注意力机制深度学习用户多行为动态演化的转化率预估:转化率与用户兴趣偏好密切相关,而用户兴趣偏好往往通过其行为特征体现,鉴于此,本部分研究基于用户行为特征的转化率预估,考虑用户兴趣模型和行为模型的动态演化性,提出融合注意力机制的深度学习策略,获取用户行为动态演化特征,进而构建基于该特征的转化率预估模型。首先,构建基于GRU和注意力机制的用户单个行为序列模型,将提取出的用户行为嵌入表示作为用户行为的动态变化特征;然后,利用自注意力(Self-attention)对用户的多行为动态演化进行建模;最后融合所提取的用户多行为序列向量作为用户的行为特征,构建移动APP广告转化率预估模型。实验结果表明所提取的用户行为序列特征能有效改善转化率预估效果。(3)基于交互特征和用户多行为动态演化集成的转化率预估:基于研究内容(1)和(2),提出融合交互特征和用户行为序列特征的转化率预估方法。首先,对机器学习中模型集成策略及收益进行分析;然后,给出交互特征和用户多行为动态演化特征集成的移动广告转化率预估框架;最后,给出基于加权平均和Stacking机制的集成算法,通过在腾讯移动APP广告转化率预估的应用实验,表明了所提集成方法的有效性。"
1863,基于粒计算数据重要性标记的实例约减,"当前,不同领域产生的数据量呈指数趋势增长,然而,这种增长趋势严重制约了基于实例的机器学习算法分析和处理数据的能力,且数据存储也成为亟待解决的问题。因此,实例约减成为大规模数据分析和处理的重要研究内容之一。已有实例约减算法处理大规模数据时,往往面临算法耗时、约减率和约减子集的数据分析性能难以平衡的问题。本文针对上述问题,研究基于粒计算数据重要性标记的实例约减算法,主要内容如下:(1)基于粒化数据重要性标记的快速实例约减算法:借鉴粒计算在特征选择领域的研究成果,提出一种基于粒化数据重要性标记的快速实例约减算法。首先,构造二维粒化映射函数,将原始数据集的高维特征粒化降维至低维粒空间,并采用K-means聚类的粒化方式将低维空间中的实例粒化为K个粒子;然后,分别针对K个粒子,基于Hausdorff距离标记各粒子中每个实例的重要性;选择重要性权重低于设定阈值的实例作为待删除对象集,进一步计算待删除实例集中具有相同重要性实例的拥挤度,删除拥挤度较大的实例,以保证数据分布的均匀性。将所提算法应用于18个UCI公共数据集上,通过与7种经典的实例约减算法进行比较说明该算法性能。实验结果表明,在相同约减率下,所提算法可显著降低大数据集实例约减时间,并较好地保持数据集分类精度。(2)融合降噪和特征降维的改进粒化数据重要性标记实例约减算法:研究内容(1)所提算法虽能快速地完成约减过程,但大数据集约减子集的分析精度相对降低,为此,在研究内容(1)的基础上,进一步提出融合降噪和特征降维的改进粒化数据重要性标记实例约减算法。首先,利用裁剪最近邻算法去除数据集中的含噪实例,并给出基于主元分析的粒化映射方法;针对同时包含数值型和类别型的混合数据集,设计欧氏距离和VDM测度融合的实例重要性标记策略。将所提算法应用于内容(1)的典型数据集,并通过与内容(1)和经典实例约减算法的比较说明其性能。实验结果表明,在相同约减率下,所提算法在可接受约减时间内,所得约减子集数据分析精度明显提高。本文研究内容采用“分而治之”的策略,经数据粒化、数据重要性标记,可快速从原始数据集中去除较大比例不重要数据。研究内容(1)所提算法对大规模数据进行实例约减具有明显的低计算代价优势;研究内容(2)所提算法在研究内容(1)的基础上进一步改进,通过去噪、降维以及基于混合距离测度的数据重要性标记方法,从而能更精确地保留重要实例,提高约减子集的分析精度。"
1864,基于穿戴传感感知的手势识别模型与应用研究,"随着虚拟现实技术、智能家居技术和浸身学习技术等技术的发展,现有的交互控制方式难以满足日益丰富的交互场景的需求。手势识别技术可以充分发挥手部灵活的特点,释放手部的交互天性,是交互方式的重要补充。但现阶段的手势识别技术研究主要集中于视频手势识别,相比之下,基于传感器的手势识别研究较少。并且,多数研究需要使用专业设备或自制设备,不便于使用和推广。本文利用已商用的智能穿戴设备、手势交互理论及机器学习方法,旨在提供一种基于穿戴传感感知的高效准确的手势识别和实时交互系统。该研究利用商用智能手环作为实验设备,采集四种常见场景下的抬手手势的加速度计数据和陀螺仪数据。通过数据预处理、数据分段、特征提取和分类模型训练等步骤训练分类模型。其中,改进的基于分类结果反馈的变步长滑动窗口结合双阈值的实时手势分段算法,可以兼顾交互的实时性和识别的准确性。本文引入Flappy bird游戏和智能灯泡来评估实时交互效果,通过抬手手势控制游戏中小鸟向上飞和切换灯泡的颜色。该系统可以实现对简单手势的高准确率的静态识别和流畅的实时交互控制,不但丰富了人机交互方式,还将充分挖掘利用穿戴设备产生的数据,为穿戴行业发展带来新的突破口。同时,也将为智能家居控制、VR交互、游戏控制、帕金森病人手功能康复、聋哑人手语识别、手势输入等应用场景提供新的解决思路。"
1865,基于网格点密度估计的聚类算法研究,"机器学习算法的研究是人工智能领域中的一个重要分支,它涉及到众多学科的交叉融合。机器学习算法的研究对象是怎样模拟人类的行为以学习新的知识从而更新知识结构、改善自身的性能。机器学习领域的研究在近些年来已经取得了很大的进展,各种各样的机器学习算法也被提了出来。机器学习算法通常情况下可以被分为三大类:有监督学习算法、无监督学习算法和半监督学习算法。聚类分析算法是其中最具有代表性的一种无监督机器学习算法。该类算法依据数据点的某种属性将数据集中相似的数据点划分到同一个类簇中而把非相似的数据点划分到不同的类簇。尽管各种各样的聚类算法已经被提出,但是大多数传统的聚类方法只能适用于球形类簇的聚类并且算法的聚类结果可能会受到参数设置和初始化的影响。此外,当数据集中数据点数量和数据维度的规模变得非常大时,聚类算法的效率将受到时间复杂性和空间复杂性的限制。因此,本论文中提出了一种快速稳定基于网格的能够识别任意形状类簇的聚类方法,该算法还能够稳定地应对大数据集的聚类。改进的方法中,首先该方法运用给定的公式自动化确定网格的划分区间数目,然后算法计算划分网格中网格节点处的密度值而非传统方法中的网格密度。最后,算法依据网格节点的密度值采用经典的广度优先搜索算法进行聚类操作。在多个人工数据集和真实数据集上的实验结果表明,该方法比传统的聚类方法更加有效。此外,聚类算法结果的评价通常需要计算聚类评价指标的值,传统的点对比较方法对于大数据集的评价指标计算效率比较低。本论文中给出了利用混淆矩阵计算聚类结果评价指标的方法,实验结果表明该方法能够明显地提高获取评价指标值的效率。"
1866,基于深度学习的车标图像检测技术研究,"计算机视觉、图像目标检测,是机器学习领域中一个重要的研究方向。在现代智能交通系统(Intelligent Transportation System,ITS)中,每天均会产生大量的图像数据,检测这些图像中所需识别出的目标,可以为日常交通的管理执法等工作提供有效的帮助。因此,不断探究高效的目标检测方法就显得尤为重要。车辆商标识别(Vehicle Manufacturer Recognition,VMR)是ITS中一个重要的应用。由于车标是各大汽车制造商最清晰、最具典型特征的标识,所以大多数识别车辆品牌的方法都是基于车辆标志识别的方法。当前,从包含各色车辆的图像中精确分割出车标仍具有一定的难度,而在各种成像环境下,VMR技术会因为几何畸变或者各种成像条件的不同而变得实现更加困难,但车标识别对于鲁棒性的又有很高的要求,因此,车标识别仍然是一个极具挑战的识别问题。在应用传统的目标识别方法时,需人工提取图像特征,这一过程仍存在很多的局限性,因此鉴于卷积神经网络(Convolution Neural Network,CNN)近年来在许多机器视觉任务中取得的成就,在卷积神经网络的卓越性能的启发下,本文设计了一个基于卷积神经网络的车标识别系统,并进行了深入的研究。将卷积神经网络算法用于车标识别系统,可以消除传统机器学习方法中对于车标精确检测和分割的要求,同时为了解决卷积神经网络在训练时计算成本较高的问题,本文引入了一种有效的网络改进策略,以使网络在现实应用得以实现。本文采用Faster R-CNN算法来训练网络,这在显著提高训练速度的同时降低了计算成本,并且使用该方法有助于防止过拟合,避免算法陷入局部最优。在本文的实验中制作了包含10家汽车制造商的10000个标识图像数据集,其中8000幅图像用于训练,2000幅图像用于测试,将所用的改进算法用于数据集并评估算法性能。实验表明,本算法识别平均准确率达到92%,与经典的卷积神经网络以及传统的机器学习算法相比,该算法识别效果最好,识别准确率最高。这表明该方法具有较高的分类能力,针对各种不良成像环境也具有较好的鲁棒性,该算法可以在现实的应用程序中进一步加以运用。"
1867,基于集成采样与特征选择机制的不平衡多类网络流量分类方法研究,"目前,网络流量分类在网络管理和安全中发挥着很重要的作用。近年来,由于基于有效载荷和端口的方法的性能下降,使得基于机器学习(Machine Learning,ML)的方法变得越来越重要。但是,网络流量分布的不平衡严重降低了ML技术的分类性能,因为使用此分布不平衡的数据集会训练出一个有偏差的分类器,从而在多数类的准确度方面获得更高的性能,而少数类的准确度则更低。近年来,很多研究者针对两类不平衡的问题提出了自己的解决方案,但在现实应用中往往会出现多类不平衡问题,即多个少数类和多个多数类的学习问题,而此问题解决起来比两类问题困难。因此,为了解决多类不平衡分类问题,本文提出了两种新的集成采样方法,分别采用智能欠采样与过采样法用于决策树(Decision Tree,DT)和随机森林(Random Forest,RF)算法上。第一种方法,即ADCUT,是将改进的自适应综合过采样方法(Modified Adaptive Synthetic Over-Sampling,MADASYN)与基于Mini-batch K-means的欠采样(Clustering Under-Sampling Technique,CUT)相结合,此方法在训练决策树(Decsion Tree,DT)前应用于训练数据集。而第二种方法,即ADTO,是通过将Tomek Link(Tomek)欠采样技术和MADASYN重采样技术与RF算法相结合来提高分类器的性能。ADTO是用来平衡RF中的每个Bootstrap的数据分布,使每个基分类器更容易学习到少数类。在这两种方法当中,MADASYN为本文基于ADASYN算法提出的一种改进算法,该方法是在生成合成样本之前增加了基于K最近邻算法的噪声滤波器,以排除少数类中的噪声样本。此外,CUT与Tomek为本文的欠采样方法。在欠采样过程中,通过考虑多数类的每个子空间,本文提出了CUT方法来缓解多数类的类内与类间不平衡问题。并且,Tomek是用来去除决策边界上的多数类样本,使得在类之间有个更清晰的边界。第二方法用Tomek而不是CUT,以减少RF中的每个Bootstrap数据的欠采样时间。这两种集成采样方法的目的是通过MADASYN引入新的知识(样本),并通过CUT和Tomek去除信息不足的多数类样本,从而解决多类不平衡与概念漂移问题。对于计算资源有限或实时性要求高的网络环境,建议使用ADCUT,对于计算资源丰富的网络环境或高性能要求,建议使用ADTO。此外,本文还对每种方法的各个参数进行了全面的研究,以供给未来的研究者参考。在此基础上,本文还提出了集成特征选择(EFS)方法,通过去除冗余和无关特征来进一步提高分类器的性能。EFS建立在现有的四种不同类型的特性选择(Filter Feature Selection,FS)方法和包装方法(Wrapper)之上。首先,初始特征集是通过四个FS进行过滤,得到次优特征子集。然后,EFS采用以DT为指导分类器的包装方法并以曲线下面积(Area Under ROC curve)为评价指标去选择最终的最优特征子集。本文在NetFlow记录上建立分类器,该记录可以从NetFlow的设备中以流的形式提取,这与大多数研究中使用的常见包级特征相比,可以降低成本和额外的工作,因为包级特征的提取需要额外的设备来收集并计算。本文使用四种不同的评估指标,即总体准确度(OA)、几何平均值(G-mean)、F-measure和AUC。本文将所提出方法与现有流行的采样和FS方法在四个不同规模和不平衡的现实网络流量数据集上进行了比较。实验结果表明,与现有的方法相比,该方法在不影响整体分类性能的前提下,对少数类性能有较大的提高。"
1868,面向实时策略游戏微操的智能博弈决策方法,"实时策略(Real-time Strategy,RTS)游戏微操是指操纵多个战斗单元以赢得遭遇战胜利,属于同步博弈问题,是人工智能(Artificial Intelligence,AI)领域最具挑战性的研究方向之一。现有解决方法主要分为搜索方法和多智能体深度强化学习(Deep Reinforcement Leaning,DRL)两种,分别通过在线搜索、环境交互式学习完成决策。在面对大规模战斗场景时,前者存在搜索效率下降和搜索空间有限的问题,后者存在学习困难和泛化性弱的问题,均难以保证决策性能。结合深度学习、蒙特卡洛树搜索(Monte Carlo Tree Search,MCTS)的思路在棋类问题上取得了巨大成功,为解决此问题提供机遇。本文融合学习与搜索的优势,由学习模型引导搜索过程,尽可能地搜索大概率存在最优解的动作空间。因此,先进行多智能体联合动作的端到端学习,再进行学习模型指导下的搜索决策。针对多智能体联合动作的端到端学习,通过特征设计和特征编码完成了状态表达,参考动作精炼思路完成了动作表达,提出了基于卷积神经网络的联合策略网络(Joint Policy Network,JPN)。特别地,不同于多智能体DRL将战斗单位视为个体,仅能学习局部状态至个体动作的映射,JPN将它们视为群体,可以学习全局状态至联合动作的映射。针对学习模型指导下的搜索决策,将JPN融入三种典型的搜索方法(PGS、POE和SSS+),提出了三种对应的改进方法,分别称之为为PGS w/JPN、POE w/JPN和SSS+w/JPN。三种改进方法的思路类似,即由先验概率分布指导初始解设置和迭代优化过程,输出有限时间内搜索到的局部最优解。特别地,不同于以MCTS为代表的树搜索方法,改进方法没有展开搜索树和频繁调用学习模型的时间开销,符合实时性要求。为了评估所提出方法的性能,本文构建了覆盖基准战斗场景的数据集,在SparCraft,StarCraft:BroodWar和gym-starcraft上展开了大量评估实验。实验结果验证了JPN结构设计和损失函数设计的有效性,其决策性能接近PGS方法,且模型耗时不受战斗场景的规模影响,在各方控制单位数量达到8及以上时,明显低于多智能体DRL方法;三种改进方法的决策性能均超过GAB方法和内置AI,且SSS+w/JPN的决策性能超过SAB方法,达到当前搜索方法的最高水平;JPN和改进方法更适用于大规模战斗场景,搜索方法性能的提升主要得益于良好的先验概率和所采用的结合机制。综上,该文面向RTS游戏微操问题,提出了结合深度学习与搜索的智能博弈决策方法,该方法在各项指标上均取得很好的效果,具有实际应用价值。"
1869,基于稀疏表示的参数自适应选择流形学习算法研究,"流形学习是当前机器学习的热门领域,它是非线性降维的代表之一。流形学习算法在对非线性数据集进行降维处理和特征提取时效果突出,但是也有一些缺陷。例如,大多数流形学习算法都有一个繁琐的调整参数的过程。这是因为大多数流形学习算法是通过描述样本点的局部性来进行降维处理的,这就不可避免地需要手动选取控制邻域大小的参数。为了解决这个问题,本文提出了两种基于稀疏表示的参数自适应选择流形学习算法。本文的主要工作包括以下两个方面:(1)提出了一种基于组稀疏的参数自适应选择判别投影算法。使用组稀疏来描述样本点的几何结构,自适应地构造样本点的近邻图,避免了传统流形学习算法中需要手动调整参数的弊端。同时,提出局部稀疏散度和非局部稀疏散度,将稀疏表示和局部性理论统一到一个数学模型当中,增加了算法的分类性能。(2)提出了有监督的参数自适应选择判别投影算法。在原算法基础之上,利用样本的类别信息,提出了能更准确描述样本点几何结构的有监督稀疏框架,限制了伪近邻点的干扰。并且在算法中加入了全局类内和类间约束,进一步提高了算法的判别能力。在几个常用的人脸数据集上的结果表明,本文提出的基于组稀疏的参数自适应选择判别投影算法在人脸识别任务中的准确率优于一些先进算法。而且,有监督的参数自适应选择判别投影算法的分类准确率得到了进一步的提升。"
1870,基于时间序列的学科热点主题预测,"在特定学科研究领域中,从科技文献中快速和正确地识别研究热点主题是了解该学科研究领域发展状况的重要手段,也是推动科技政策制定的重要环节。本文采用Relim算法从“动物遗传与育种”领域文献中识别出研究热点主题,并采用了四种机器学习算法对研究热点主题进行预测,发现集成后的预测模型对时间序列预测效果较好,选择提前两步的预测效果最好。实验结果表明热点主题预测有助于了解未来一段时间内的研究热点主题状况。本文的主要研究工作:(1)基于Relim算法的研究热点主题识别。主要通过对若干个识别主题算法的对比研究,在前人研究基础上确定将Relim算法作为识别主题的核心算法,实现了从动物遗传与育种领域的科技文献中对研究热点主题的自动挖掘。本文从实验数据中共挖掘了“animal”、“association”、“behavior”、“animal_association_behavior”、“breed”等283个热点主题。为了去除冗余的数据,对研究热点主题进行精简,精简后为“animal_association_behavior”和“breed”等250个热点主题。将2000-2017年精简的主题的频数按年份顺序排列得到时间序列。(2)基于机器学习算法对热点主题的演变趋势预测。本文采用了线性回归、支持向量机、径向基函数回归、径向基函数神经网络四种机器学习算法,对单个主题“breed”进行预测。对比发现对于同一时间序列,由于不同算法彼此间的多样化或独立性的本质,导致四个单个预测模型的均方误差、均方根误差、平均绝对误差值之间存在着巨大的差异。通过将单个预测模型的预测值进行综合加权(集成预测)作为对热点主题演变趋势的预测模型。在集成预测模型中,将性能表现不好的预测模型与性能较好的预测模型进行加权组合,最终可以得到性能更加稳定的集成预测模型。通过对主题“weight body”提前五步的预测实验,发现提前2步的预测方案是最优的。最后,利用集成预测模型对主题“ability”、“acid”、“activation”进行提前2步的预测。主题“ability”在2017年之后,主题的频数有下降的趋势;主题“acid”在2017年到2018年频数有下降的趋势,但是2019年,主题的频数有所回升;主题“activation”在2017年之后主题的频数保持平稳的状态。实验结果表明,该方法能够较为准确地从动物遗传与育种领域的文献集合中预测该领域热点主题,特别是对未来2年的热点主题预测具有较好的预测结果。该方法也同样适合基于科技文献的其他学科或领域的热点主题预测,帮助用户快速了解未来一段时间内的研究热点主题状况。"
1871,基于机器学习的Gstore消费额预测,"消费额预测是企业经营预测的起点和基础,与各项企业的经营活动密切相关。消费额预测的准确与否对于提高企业经营决策的科学性具有重大意义,且直接关系到企业的经济效益,关系到企业的生存和发展。一方面有利于掌握产品市场需求端的基本动态和产品销售变化的一般规律,另一方面消费额预测也是制定业务决策的主要依据。随着帕累托法则(80/20定律)的提出,即当一家公司发现自己80%的利润来自于20%的顾客时,就该努力让那20%的顾客乐意扩展与它的合作,于是许多公司将消费额预测的重点转向创造大部分收益的少数客户。因而如何准确预测每个消费者在未来某个时间段内的消费额并从中发掘出潜在的大客户成为各大企业最为关注的焦点问题。以往的消费预测一般基于时间序列或者BP神经网络方法,但由于时间序列更多考虑时间趋势和季节性,而受限于单个用户历史消费信息比较稀少,只能预测大体销售总量,面对单个用户的消费额度预测问题往往束手无策,无法利用帕累托法则发掘消费水平最高的20%用户。而BP神经网络的输入数据存在冗余,算法学习收敛的速度低,误差存在局部极小值等问题。本文通过特征工程和使用以LightGBM,XGBoost,CatBoost为代表的机器学习方法,依据网页点击次数、总浏览页数、平均点击率等特征,从单个模型到组合模型进行精度比较,从中选出较优的组合模型,并根据客户未来的浏览行为预测消费额度,为企业决策和运营方案的制定作出参考。文中使用著名的Google Merchandise Store(简称GStore)903653条销售数据以预测每位客户未来在Gstore的消费额。首先,通过探索性数据分析查看数据分布与缺失情况;其次,使用特征工程将含有复杂信息(如购买时间)的列按年,月,周,日等进行拆分,再利用可视化技术,找到对消费额预测影响最大的特征,然后使用XGBoost、LightGBM和CatBoost算法对消费者未来一年的Gstore消费情况进行预测,对特征重要性进行绘图排序使重要特征得到更直观的展示,并横向比较不同单模型在客户消费额预测上的性能;最后对模型进行线性组合,从中筛选出精度最高的线性组合模型。在对数据进行处理并建模后,采用RMSE(Root-mean-square error)作为四种基本模型的评价标准,研究表明单模型预测准确度GBM>CatBoost>XGBoost,而对模型进行组合研究中发现,三元组合模型准确度GBM+XGB+CatBoost>任一二元组合模型准确度>单一模型准确度,由此获得了优化的基于机器学习的Gstore消费额预测模型。"
1872,机器学习在汽车金融反欺诈模型上的应用研究,"中国的汽车产业随着经济的飞速发展而发展,中国已成为世界排名第一的汽车消费市场和世界最大的消费潜力市场。汽车产销量增长对汽车金融形成明显的带动效应,中国的汽车金融渗透率从五年前的13%提升到了目前将近40%。随着汽车金融渗透率的提升,对风险控制能力的要求也越来越高,相关企业也开始将科技手段与汽车金融风险控制相结合。由于汽车贷款的标的金额较高,驱动骗贷机构伪造资料或哄骗无信用记录人通过分期购车的形式获得车辆,再将汽车通过非法途径进行转让。因此对于购车人的反欺诈风险识别成为目前风险控制的关键点。本文利用互联网金融公司用户的样本数据,探讨机器学习技术在反欺诈模型上的应用情况,研究客户的相关特征,提出建立反欺诈规则的建议。建立在工业界比较认可的逻辑回归模型,并将它作为标准。建立支持向量机、Adaboost、XGBoost反欺诈模型,介绍各类模型的主要参数,探索最优的参数组合来优化模型效果。结合机器学习分类模型的评价指标,对比各个模型性能,最后得出结论:XGBoost在本次研究中模型效果最优,模型性能相比于逻辑回归有较大提升。最后结合特征分析与反欺诈模型为企业建立反欺诈体系提供参考,并对未来反欺诈体系发展进行展望。"
1873,基于机器学习的信用评分模型研究,"利用个人历史贷款行为数据对用户未来的信用表现进行预测一直是互联网金融领域广大学者关注的热点问题。为此,本文以某贷款机构的历史贷款数据为例,通过构建信用评分模型并建立信用评分体系来预测用户的违约情况,降低用户的违约风险。首先,对贷款数据进行数据预处理和指标筛选。数据预处理主要解决数据的无效性、集中度高、缺失值、异常值以及不一致性等问题。在考虑变量的预测能力和变量之间的相关性的基础上,采用Ⅳ值筛选法和相关性检测相结合的方式进行变量的筛选。第一步,对变量进行WOE分箱并计算Ⅳ值;第二步,对Ⅳ值低于0.02的变量进行剔除;第三步,进行相关性检测,对相关系数超过0.6的两个变量进行筛选,保留Ⅳ值较高的变量。最终选取11个变量作为信用评分指标。其次,利用信用评分指标建立信用评分模型。选择传统的信用评分模型―Logistic回归和精度较高的XGBoost算法进行建模,以AUC和KS作为评价指标对模型进行评估和对比。实证结果表明,XGBoost模型(KS=0.3290,AUC=0.7181)在KS和AUC的表现都优于Logistic回归模型(KS=0.3129,AUC=0.7052),因此选择XGBoost作为最终的信用评分模型;由XGBoost模型输出的变量重要程度排名得知,收入对客户是否会构成违约行为起着重大的作用,同时贷款或贷记卡合同金额、贷款提前还款月数、教育水平也具有重要影响。最后,利用对XGBoost模型的预测结果建立评分卡,将得到的信用评分从高到低划分四个信用评分等级:A、B、C、D。其中D等级用户违约概率超过50%,属于违约高风险人群,对于这类用户应该拒绝贷款。"
1874,多任务学习在多标签分类和时间序列预测中的研究和运用,"多任务学习是传统的机器学习中一个重要的分支,通过考虑相关领域的相似性,通过学习一个任务的特性,将这种特性迁移到相关的领域中,从而解决标记数据少的情况,或者为另外的领域提供辅助的信息。在真实的机器学习任务中,一般会遇到有标记的样本量少,类别不平衡等等的问题。多任务学习通过学习相关领域的知识,将这些有效的知识迁移到别的领域。在视觉领域里,目标检测和深度预测学习的知识可以辅助对方,多任务学习也可以为辅助任务提供不同视角的表达。多标签分类是传统机器学习的一个重要课题。和传统的方法不同,我们假设一个更加完备的标签空间,并且引入相似度矩阵来刻画这样的完备空间。传统的方法往往通过核范数来表达标签之间的联系,本文提出一个对传统核范数加速的方法,将每一个标签当做一个任务,考虑任务之间的联系,效果和传统的核范数效果相当。实验证明,本文提出的对核范数加速的方法,不仅考虑了标签之间的联系,而且速度明显加快。多任务学习在时间序列检测任务上也可以取得比较好的效果。传统的时间序列检测分为两种思路,一种是通过加特殊的正则化项,刻画时间序列的变化趋势。但是这些正则化项往往需要先验知识,同时有很大的局限性,只能刻画某种变化。另一种是通过随机的方法,比如高斯过程。但是这些随机方法也只能假设某一类分布的变化,无法应付真实生活中多样的变化。和传统的方法不同,我们思考解决预测不同变化趋势的时间序列问题,而众筹问题符合这样的假设。不同产品的变化趋势不同,但是产品本身具有相似度。本文提出了一种基底生成的方法,通过选择合适的基底,最终使得这些选择出来的基底可以应付多样的变化。实验证明,文本提出的方法可以应对样本量变化多样性强的情况,对各种自然的时间序列检测任务效果得到明显提升。"
1875,基于机器学习的图划分算法的可预测性研究,"传统的图划分方法是基于边的划分,目的为最小化切割边的数量。人们考虑在分布式系统上运行图算法的可能性,但是传统的边划分并不是处理真实世界中的具有幂律分布的图形。解决该问题更好的方式是将图基于点进行划分,即分割点,将高维度节点分配进不同划分之中,从而平衡分区边数。但是由于由于近几年才对基于点的划分策略有所研究,所以大家都对基于点的划分知之甚少,也鲜有人对已提出的不同划分策略进行评估。为了弥补这一缺陷,本文在机器学习的基础之上,设计了多个基于点划分的度量指标,从各方面评估将划分策略应用到具体大规模图后的分区质量。本文的主要贡献如下:创新性地提出多个基于点划分的度量指标。基于点的划分策略更注重于分区的均衡性和分区的通信成本,我们所设计的度量指标涵盖了这两方面,能够对分区后的图进行有效描述。证明图特征影响最终图算法运行时间。在划分后不同结构的图,通过计算所得的度量指标不同,通过实验证明度量指标与图算法(例如PageRank)有强关联关系。并通过实验证明最影响划分质量的指标为通信成本指标,而关于均衡性的指标相比而言没有通信指标重要。首次使用机器学习算法对给定图预测最优划分策略。我们设计了两种不同的方案,运用统计分析方法和机器学习分类方法建立模型,能够以较高的准确率预测给定图的最优划分模型,能够大幅度减少预期时间。"
1876,面向结构化特征向量输入的卷积网络结构设计与实现,"基于机器学习的预测(例如分类和回归)在现实世界的应用中无处不在。尽管取得了极大的成功,但总体上没有一个算法是解决问题的万灵药,研究人员和工程师必须仔细选择哪种算法更适合给定的数据集。随着时代的发展,深度学习技术已经发展了几十年。其中卷积神经网络(CNNs)在计算机视觉各种任务上大放异彩,并且还在自然语言处理,语音任务中也有所作为。但是,在传统的机器学习任务中,卷积神经网络很少被使用,浅层模型仍然占主导地位。这可能归因于一些实际的挑战:i)传统的任务涉及到矢量结构的数据,并不像在视觉和音频方面的数据有空间/时间的局部依赖性;ii)学习数据的规模要小得多。例如,在流行的UCI机器学习仓库中,其大小通常从数百到数千;同时原始的特征维度要小得多。此外,传统的数据分析倾向于应用特征选择来寻找更紧凑和可解释的特征。数据降维就失去了以各种非线性的方式探索特征的复杂相互作用的机会。为了弥补上述差距,本文尝试开发一种针对结构化向量的数据集进行学习的卷积神经网络,即便原始数据没有空间或时间的关系。首先,把一个输入样本的一维原始特征向量转换为多个通道的特征图。具体来说,转换涉及填充,随机排列,重塑,连接,最终获得一些二维特征图谱,并将多个通道合并作为2D卷积的标准输入,可以把这个过程称为ShuffleAdapter。此外,由于不同的数据集和任务本质上具有不同的结构和复杂性,为了不失一般性,所以使用改进的遗传算法来寻找合适的网络结构以避免不合适和过度拟合。简而言之,本文研究的主要目标是缩小卷积与传统的浅层模型在学习中等大小矢量结构数据之间的差距,虽然传统的浅层模型仍处于主导地位。根据研究与探索,发现这是一种通过卷积网络网络学习结构化数据的新尝试。它与卷积神经网络主要用于空间和时间依赖无所不在的非结构化数据(如视频、图像)情况相反。为此,本文算法设计了ShuffleAdapter,以丰富原始数据,同时将矢量转换成友好的特性图。然后,本文还提出并且设计了一种基于遗传搜索的方法,以自动发现合适的网络结构,这样模型就可以与给定的数据集相匹配。最后实验结果也表明通过本文提出的面向结构化特征向量输入的卷积网络结构设计的方法获得的卷积神经网络在结构化数据上表现十分良好。"
1877,众包数据标注质量的改善算法研究,"许多以数据为支撑的研究领域的发展及应用离不开大规模的标注数据,特别是机器学习等人工智能领域。近年来,利用众包系统收集标注数据正变得越来越受欢迎,它能方便地帮助研究者快速和低成本地获得大量的标注数据。但是由于众包标注者的各种不稳定因素,并不能保证标注者标注标签的质量。目前为了改善众包数据的标注质量,研究者们已经提出了一些有效的标注数据的标签真值推断算法。本文针对上述问题提出了两种比公认的基准算法表现更好的算法,主要研究工作总结如下:(1)分析了导致众包数据标注质量低下的原因,并系统地定义了旨在改善众包数据标注质量的标签真值推断问题。探讨了一些典型的基准算法的基本原理和实现,为本文提出的算法和对比实验提供基础。(2)提出了基于黄金标准数据和激励策略的标签真值推断算法。该方法在使用黄金标准数据的条件下,全面考虑了实际众包环境中存在的标注者的类型并过滤了低质量的标注者。其次针对同样基于黄金标准数据的ELICE算法的不足点,合理地估计了标注者自身的标注能力。最后通过改善激励机制策略来增强标注者动机,进一步提高算法的效果。(3)提出了基于标注者能力和标注难度的标签真值推断算法。该方法并不依赖黄金标准数据并且适用于多标签标注任务。它主要考虑了标注者能力和标注实例难度建立了有效的多标签任务标注过程的概率模型,并合理地估计了标注实例的难度。最后采用EM迭代算法求解标注模型的极大似然估计,并推断出标注数据的标签真值。本文利用开源实验工具在多个公开数据集上对本文算法和其它基准算法进行对比实验。通过实验结果与分析,验证了本文提出的两种算法的有效性和相对于其他一些基准算法的优势。"
1878,基于杂交水稻算法的分类器权重优化研究,"分类是机器学习最重要的任务之一。分类器的性能主要受结构和参数权重的影响。其中,参数权重的优化仍是一个难以求解的问题。为了增强分类算法的性能,许多参数权重的优化算法被提出。传统的优化方法例如梯度下降,仍有易陷入局部最优、收敛性差等不足。通常参数权重的优化需要在实数范围内搜索最优解,是一个计算复杂度非常高的问题。基于概率搜索机制的智能优化算法具有良好的寻优性能,如差分进化算法、粒子群优化算法等,已经成功用于该类问题的求解,然而该类问题仍未完全解决。作为一种新提出的智能优化算法,基于杂种优势理论的杂交水稻算法具有寻优速度快、搜索能力强的优点。因此,本文尝试将杂交水稻算法用于优化机器学习分类算法中出现的权重优化问题,以探索其在机器学习领域应用的潜力,主要工作如下:1.利用杂交水稻算法优化机器学习分类器的特征权重。本文提出了基于杂交水稻算法加权的K最近邻分类器和基于杂交水稻加权的朴素贝叶斯分类器,并进行了原始分类器和基于智能优化算法改进的分类器的对比实验,结果表明通过杂交水稻算法杂交、自交的育种机制对K最近邻算法和朴素贝叶斯算法的特征权重进行寻优,训练出了性能更佳的分类器。2.将杂交水稻算法用于分类器集成算法,对多分类器的集成权重进行优化,提高分类器的泛化性能。通过对基分类器进行差异性度量,选取差异性较大的基分类器进行集成,利用杂交水稻算法的搜索能力,找寻最优的权重向量,从而得到具有更高精度的分类器集成模型。3.将本文提出的算法应用于解决遥感领域的图像分类问题,探究基于杂交水稻算法优化的机器学习分类算法在遥感图像领域的适用性。总的来看,本文将杂交水稻算法用于K最近邻分类器、朴素贝叶斯分类器以及分类器集成的权重优化问题中,并使用部分机器学习公开数据集和遥感图像对其进行测试,实验结果表明本文提出的算法能有效地提升分类器的分类精度和鲁棒性,特别是当实际应用中数据集出现样本多噪点、特征冗余等问题时,改进后的分类器的分类正确率有所提高,在机器学习的性能优化中具有一定的潜力,在遥感图像领域有着广阔的应用场景。"
1879,卡方检验神经网络,"人工神经网络(ANN)自1980s以来一直是人工智能领域的研究热点。它从信息处理的角度抽象出人脑的神经网络,建立一些简单的模型,并根据不同的连接方式形成不同的网络。它由彼此连接的大量节点(或神经元)组成。卡方检验是一种广泛使用的假设检验方法,主要用于分类数据的统计推断。它通过计算实际观测值与理论推断值之间的偏差来确定卡方值。本文结合ANN和卡方检验,研究了一种基于卡方检验的二分类神经网络。该算法是单隐藏层的反向传播神经网络,算法中利用卡方检验的原理重新定义的损失函数和误差函数。并根据标准BPNN来修改神经网络的权值和阈值。算法中利用卡方检验同分布特性,将少量的带标签样本划分成一个个子区间,并计算每个子区间内的某类样本的理论概率作为参照,训练模型时使用无标签数据进行训练。由于卡方检验的同分布特性,训练时的输入样本的分类结果落在每个子区间内的预测概率应该和理论概率近似,将两个概率代入卡方检验统计量公式里与临界值作比较来判断是否结束训练。若不能,根据改进的误差公式更新参数,继续训练模型。所以本文提出的算法可以仅利用少量有标签样本作为参照,将大量无标签样本用来训练模型。并将该算法在UCI机器学习库提供的五组公共数据集,和私有数据集苹果近红外光谱数据和肺部CT图像上进行了测试。该算法在训练集和测试集上有数据一致性的优点,能被用来进行数据的二分类。其在真实数据集上的结果表明该算法与相关算法相比能有效提高分类结果的准确率,由此证明该算法是可行的。并且一定程度上解决了带标签数据采集困难的问题。"
1880,基于条件随机场的中文期刊论文信息识别与抽取,"期刊论文作为知识信息的载体和研究人员获取专业知识的一个重要渠道,对促进专业技术的推广、研究成果的传播有极其重要的作用。基于期刊论文全文信息的相关研究有利于提升期刊资源的使用价值以及用户获取信息的效率。目前,已经存在很多论文信息抽取的相关工具,但其在中文期刊论文信息的抽取中效率并不高。所以在此基础上,本文对现有的论文信息抽取工具做了适用性改进,使其更好地应用在中文领域。通过对期刊论文信息抽取方法及工具的对比分析,本文选取条件随机场算法和GROBID工具进行中文期刊论文信息的识别与抽取。主要研究内容与取得成果包括:(1)深入对比分析了期刊论文信息识别与抽取的相关方法和工具,发现条件随机场算法和GROBID工具在论文信息抽取中准确率更高,因此本文采用条件随机场算法和GROBID工具进行中文期刊论文信息的识别与抽取。同时,详细介绍了基于条件随机场的中文期刊论文信息识别与抽取的关键技术。(2)基于条件随机场算法和GROBID工具构建了中文期刊论文信息识别与抽取级联模型,包括segmentation模型、header模型、reference-segmentation模型、citation模型以及fulltext模型。针对中文期刊论文信息的特点,通过文本预处理、特征选择、序列标注和特征模板制定一系列流程完成了对模型的设计与实现。(3)选取12种农业领域中文期刊论文数据对模型进行训练,利用准确率、精准率、召回率以及F1值四个指标对各个模型的效果展开评估,并与GROBID工具的抽取效果进行对比。实验结果显示,中文期刊论文信息抽取模型中segmentation模型、header模型、reference-segmentation模型、citation模型的效果相对GROBID工具显著提升,该模型能够准确、高效的识别和抽取出中文期刊论文头信息和引文信息。"
1881,基于文本挖掘的用户反馈服务质量及影响研究,"在大数据的时代下,信息媒体多元化和通信技术先进性促进了社会经济形式的不断创新。作为一种新兴产业,共享经济如雨后春笋般在全国范围内甚至全球发展迅猛。而共享经济的理念是鼓励协同创新和价值共创,它响应了中共中央和人民群众的号召,所以全民参与共创的行为逐渐受到了大力推崇,即消费者可以从服务接收方转化为服务提供方来分享自身的闲置资源。如今,中国的经济市场面临着重大的住房问题时,房屋租赁开始被大多数人所提倡,但是住宿领域的服务质量仍旧存在着巨大的挑战。在线短租作为共享经济在空间上的分享,房客通过浏览线上的产品信息后会选择与陌生房东分享房间,因为当地接触和社交互动可以满足自身对民宿体验的憧憬。在在线短租中,房子和房东的感知服务质量是房客选择居住的关键要素,也是房东保证其核心竞争力的必要条件。随着平台不断透明化和消费者发言权得到保护,由平台和消费者生成的大量信息增加了潜在客户的搜索成本。但是,由消费者产生的口碑是最能够反馈产品信息如产品或提供商的服务质量,而消费者评论是挖掘有用信息的重要渠道,因此本文以在线短租为研究对象,从用户产生的内容中挖掘出产品服务质量来探索消费者的核心需求以及潜在客户的购买行为产生过程。本文采用python爬取了小猪短租2017年3月的累积数据,获取了房东和房客属性特征、产品和订单信息以及消费者评论等。本文主要包括两个部分,即文本分析阶段和计量回归阶段。文本分析部分主要提取相关的研究变量:从整体层面,笔者基于LDA主题建模从评论中挖掘了用户体验,提取了12个主题,分别是情感成分包括态度意愿(如回购意愿与推荐意愿)和评价描述,感官成分是房间舒适(如设计美感和温馨舒适),实用成分包括房子位置、房屋设备和周围配套,认知成分包括性价比、描述相符、安全保障、问题解决能力和热情周到,关系成分是社会互动(如主客互动和当地接触等)。从小猪短租评论文本的主题成分来看,用户体验包括了服务质量、感知价值、顾客忠诚和满意度等维度;从个体层面,笔者采用机器学习分类算法模型SVM对产品所对应每条评论包含的主题进行识别,结合情感词典对每个主题进行情感计算以获取不同主题的评价指标,从而构建产品服务质量的移情性、有形性、可靠性、保证性和响应性五个维度情感值;计量回归部分主要是探究变量间的因果关系:笔者提取了用户体验中的服务质量作为自变量来探究其对顾客忠诚和潜在消费者购买行为的影响,同时观察了羊群效应和信息披露是否会调节他人顾客忠诚对潜在消费者的购买行为的影响。结果显示,在线短租的产品或服务提供商的服务质量(如移情性、有形性、可靠性、保证性和响应性)会正向显著影响顾客忠诚和消费者的购买行为,而他人顾客忠诚会给潜在客户传递出感知信任,是服务质量和消费者行为之间的中介桥梁;除此之外,羊群效应反映出消费者观察学习的行为偏好,而信息披露会传递出提供商利他性信号,两者会正向显著调节他人顾客忠诚对潜在用户购买行为的影响;最重要的是,在在线短租情境下,移情性(如社会互动)在服务质量层面影响消费者态度意愿最强烈,由消费者产生的信号会明显强于平台或提供商的信号对潜在客户购买的影响。本文探究在线短租中用户反馈的服务质量对消费者心理感知和购买行为的影响,具有一定的理论意义和现实意义。从理论角度,笔者挖掘用户体验中的重要成分来观察由用户产生的信号是如何基于服务质量-感知价值-满意度-信任的有向链条影响顾客满意度和消费者购买行为,同时观察了羊群效应和信息披露两种不同信号在态度对行为影响中的调节作用,对于消费者行为研究具有启示作用。从现实意义,笔者挖掘用户的核心需求可以改善服务提供商的产品策略、优化平台布局设计以及帮助消费者减少搜索成本去捕捉有用信息。"
1882,互联网金融中基于GBDT的三类信用风险度量及其驱动的海萨尼转换,"互联网金融中,贷款企业与申请者之间存在不完全信息博弈,但实践中传统的海萨尼转换需要用到的新的贷款申请者的信用类型的概率分布很难获得,本文尝试利用统计学习方法解决此问题。主要的研究工作包括如下三部分。第一,构建互联网金融企业与贷款申请者之间的不完全信息互联网贷款信用博弈(3ILCG),采用传统的海萨尼转换分析进行理论分析;并提出了采用统计学习方法预测贷款申请者的信用风险,以驱动海萨尼转换的方法。第二,采用三种统计学习方法度量贷款申请者的信用风险。首先,定义了信用风险,并采用梯度提升决策树(GBDT)模型度量之。其次,提出了耦合支持向量机(SVM)的GBDT模型(SVM-GBDT),选择SVM中的支持向量作为新的训练集,在保证数据信息的同时大大减少数据规模;并利用该模型度量了信用风险,结果表明:SVM-GBDT在保证正确率的前提下效率提升了73.72%。最后,采用eXtreme Gradient Boosting模型(XGBoost)度量信用风险,实证结果表明:该模型相比于GBDT模型,精度提升了0.0107且效率提升了44.34%。三种方法综合比较表明:在征信数据规模较大时适合采用SVM-GBDT模型,在一般情况下优先采用XGBoost模型。第三,在3ILCG中,提出了信用风险驱动的海萨尼转换。基于本文数据特征,采用XGBoost驱动海萨尼转换。实证分析表明:互联网金融贷款企业依据XGBoost驱动的海萨尼转换做出的贷款决策准确率为94.8%。因此,面对新贷款申请者时,本文提出的信用风险驱动的海萨尼转换有助于互联网金融企业做出科学的贷款决策。"
1883,基于经典评分卡与机器学习的金融风险识别模型及其应用,"互联网金融的蓬勃发展,在为有融资需求客户提供更快捷金融服务的同时,也产生了信用风险和用户欺诈等问题,因此,通过有效的信用评分体系,并借助于量化分析模型来定量预测并控制风险是当前风险领域研究的热点问题,本文针对大数据背景下,利用逻辑回归度量风险存在的不足,以某消费金融公司2017、2018年的线上现金贷数据为基础,采用GBDT、XGBoost、LightGBM三个机器学习算法建立模型,与逻辑回归所建立的模型进行比较分析,并在此基础上建立了Stacking模型,期望达到更好的模型效果。首先,本文样本数据量为22925,变量为1327个,包括商品消费、稳定性、网购、借贷意向(多次申请)、实名信息和地址信息6个方面的信息,并通过删除缺失值95%和单一值占变量份额95%以上的变量、对变量进行WOE分箱删掉IV值小于0.02的变量、对分类变量进行哑变量处理等操作,得到843个变量。其次,对843个变量进行lasso回归、逐步回归和变量衍生等操作,筛选得到87个重要变量建立模型。然后,选取逻辑回归和GBDT、XGBoost、LightGBM三个机器学习算法分别进行信用评分体系的构建,根据AUC和KS两个指标来对比分析各个模型效果,结果表明GBDT、XGBoost和LightGBM三个基模型的模型效果均优于单一模型逻辑回归的模型效果,其中LightGBM的模型效果最好,并在此基础上建立以GBDT、XGBoost、LightGBM为第一层基模型,逻辑回归为第二模型的Stacking模型,为此期待达到更高的模型效果,而Stacking组合模型的AUC与KS值是其余模型中最高的,KS值相对于逻辑回归提升了接近6%,GBDT、XGBoost和LightGBM提升了接近1%。最后,根据逻辑回归的预测结果建立了评分卡,通过对比分析用户的信用分数和实际违约率,验证结果的可靠性,并通过信用分数和违约率的分布情况,给予一些建设性意见。GBDT、XGBoost和LightGBM三种算法中后者都对前者进行了一定的改进,故本文采用这三个算法建立模型,已在模型效果、过拟合问题和运行速度等方面验证其优势,并在此基础上,结合逻辑回归建立了Stacking模型,有一定的创新性。"
1884,环境因素对呼吸道疾病的影响分析,"近年来长春极端天气变化日益增多,春冬季空气污染严重,呼吸道患病人数也较以往同期明显增多。针对此现象,本文主要研究长春市空气污染物(SO_2、NO_2、CO、O_3、PM2.5和PM10)、气象相关指标(平均气压、平均湿度等)与呼吸道疾病周住院人数的关系。收集吉林省综合性医院吉林大学第一医院2013―2017年日呼吸道疾病住院人次病例、空气污染物及相关气象指标。首先对收集到的患者数据进行性别、年龄差异化分析,对收集到的数据进行相关性分析及显著性检验等统计性分析。然后通过LASSO算法选择出PM2.5和平均气压作为自变量后,分别建立关于周吸道疾病住院人数的多元线性模型、ARIMAX模型和机器学习模型(决策树、支持向量机回归)。根据AIC信息准则及标准化均方误差(NMSE)最小原则选择出较优模型―ARIMAX模型,并给出1周预测,最后得出结论,给出适当建议。"
1885,基于机器学习的GNSS反射信号土壤湿度反演方法研究,"土壤湿度是一个重要的水文变量,对研究生态系统水循环、植被水分供给、土壤承载能力等起着举足轻重的作用。GNSS卫星发射的L波段信号具有很强的穿透性,其反射信号对土壤水分十分敏感,因此基于GNSS反射信号发展起来的GNSS遥感技术,为土壤湿度监测提供了一种全新的、高效的监测手段。目前利用GNSS反射信号反演土壤湿度的理论,还没有研究出较为完善的解析模型。由于土壤表面粗糙度、植被覆盖和积雪覆盖等环境因素影响大,需要人工测量较多数据,建模复杂,模型泛化特性不强。因此,论文从合理有效抑制环境影响因素,构建GNSS卫星反射信号土壤湿度反演模型展开研究,提出一种以伪距多路径误差代替植被因素,结合机器学习算法的GNSS反射信号土壤湿度反演模型,并通过仿真实验和实测实验对模型可靠性进行了深入分析。(1)NDVI是一种能够有效反映植被生长状态和植被覆盖度的植被指数,对其简单、有效的监测有助于植被生长的研究。论文从信噪比观测值中提取L1频点的伪距多路径误差MP1,L2频点的伪距多路径误差MP2,并与NDVI之间进行时间序列、频谱以及相关性分析,结果表明:MP1、MP2与NDVI均存在明显的年周期性和季节特性,两者之间存在显著的线性相关,相关系数在0.6084~0.7554之间。同时,通过熵值法对两个频点的伪距多路径误差进行融合处理后发现,融合后的伪距多路径误差MP与NDVI的相关系数较MP1,MP2分别提高了3%~17%,说明通过熵值法对两个频点的伪距多路径误差进行融合处理,可明显提高NDVI反演精度。(2)针对GNSS反射信号反演土壤湿度中,建模复杂,模型泛化特性不强等问题,论文利用机器学习算法不仅能够学习和存贮大量的输入-输出模式映射关系,且具有无需事前揭示描述这种映射关系、模拟复杂数量关系的能力的特性,以SNR观测值的相位作为输入项,土壤湿度作为输出项,利用机器学习算法分别构建SOM-BP反演模型、SOM-SVR反演模型和线性反演模型,其仿真和实测实验表明:SOM-SVR模型相关系数最高,均方根误差RMSE和平均绝对误差MAE最低,反演效果明显优其它反演模型;线性反演模型的相关系数R均低于其他反演模型,均方根误差RMSE和平均绝对误差MAE也相应高于其他反演模型,其反演模型的性能最差,说明SOM神经网络的聚类能力和SVR良好的泛化能力能够有效抑制植被覆盖等这些不易采集或建模的影响因素,提高土壤湿度反演精度。(3)利用伪距多路径误差与NDVI的显著相关性,将融合后的伪距多路径误差作为植被信息,与SNR观测值的相位共同作为输入项,再次构建三种反演模型,其仿真与实测实验结果表明:在加入植被信息后,三种反演模型由于获得了更多的环境特征因素,相关系数R比未加入植被信息的反演模型提高了5%左右、均方根误差RMSE,平均绝对误差MAE均比未加入植被信息的反演模型降低了5%左右,所以在植被信息很难获取的情况下,以伪距多路径误差最为植被因素替代品,可以进一步提高土壤湿度反演精度。"
1886,吉林省和龙地区多元地球化学异常识别的几种机器学习方法比较,"当代的矿产资源预测与定量评价是复杂高维非线性系统的建模与评价过程,通过提取和识别地质、地球物理、地球化学及遥感等多源地学观测数据中的特异信息,并以此为依据预测矿产资源的空间分布规律。单一信息来源为依据的找矿模型存在局限性,只有通过将多种来源的观测数据进行全方位的分析与综合,才能更好的完成矿产资源勘查与定量评价工作。水系沉积物测量是区域勘查地球化学研究的重要数据源,对于寻找近地表的浅隐伏的矿产资源十分有效。本文以吉林省和龙地区为实验研究区,在Sklearn的Python语言代码基础上,开发了基于一类支持向量机、孤独森林、连续约束玻尔兹曼机和局部特异因子法的多元地球化学异常识别方法程序,从1:5万水系沉积物测量数据中提取多元地球化学异常。把实验区已知矿床和矿点的空间分布位置作为“地真”数据,对多元地球化学异常识别结果进行了ROC曲线分析,绘制了四种机器学习算法多元地球化学异常识别结果的ROC曲线并计算AUC值,用来对比四种方法的多元地球化学异常识别效果。以便更好的分析基于机器学习理论的几种方法对于多元地球化学异常识别的应用存在的差异和适用范围。研究结果表明:(1)四种机器学习算法都能够有效识别多元地球化学异常,所提取的多元地球化学异常与已知矿点具有显著的空间关联性;(2)在数据处理耗时方面孤独森林算法最优,其次是一类支持向量机,耗时最长的是连续约束玻尔兹曼机;(3)四种机器学习方法中,多元地球化学异常识别效果最好的是连续约束玻尔兹曼机,其次是一类支持向量机,最差的方法是局部特异因子方法。"
1887,基于机器学习近30a艾比湖湖面变化及自然驱动因素分析,"干旱区内陆湖泊作为在全球变化中扮演这重要角色,由于观测资料稀缺,相关水文研究仍不够充分。然而,干旱区内陆湖泊对本地生态环境、经济发展起着决定性作用。正是这种不对称的关系,使得生态安全问题频发。艾比湖作为天山北坡经济带的生态屏障,其湖面面积波动剧烈,已成为全疆第二大生态问题。因此,精准监测艾比湖动态变化具有重要意义。机器学习的兴起,使得高精度识别成为可能。只有精准把握艾比湖湖面面积,才有利于确定相关驱动要素引起湖面变化的机制。基于此,本文通过近30年的Landsat数据集,利用集成学习算法分别获取不同季节的湖面面积以及确定不同驱动因素的重要性。分析气候水文要素与湖面面积的延迟响应关系,并尝试探讨艾比湖湖面面积的潜在生态阈值,为区域可持续发展提供依据。本研究主要得到以下结论:(1)随机森林识别体系表现优异,kappa系数最高为0.99。DEM在各传感器下的影像数据中均保持最高的重要性得分。艾比湖在近30年中出现两个峰值,即2003年和2017年,以2003年艾比湖湖面面积最为之大(湖面面积最大为965.22km~2)。年内排序为春季>夏季>秋季,夏-秋湖面损失比春-夏损失更多。(2)全流域表现出明显增温增湿,径流量明显增加,而总入湖量仅仅是缓增,潜在蒸散量表现出递减的趋势。艾比湖流域气温、径流量和潜在蒸散量存在两个完整周期。平均降水和总入湖量有三个完整周期震荡。(3)GBRT算法对气候水文要素影响湖面面积变化进行重要性排序,博河入湖量重要性最高。流域内气温优先湖面面积变化;平均降水和入湖量在2004年后基本保持近似同步正相关周期;径流量和湖面面积存在同步正相关关系;潜在蒸散量与湖面面积呈现近似负相关关系,且强度逐渐减弱。探讨艾比湖湖面面积的生态阈值在生态-环境-经济尽可能平衡的原则上。2012年艾比湖湖面面积606.5km~2,基于气候水文要素估算2012年湖面面积为615.21 km~2。"
1888,情绪线索记忆重播对相关事件记忆表现的影响和预测,"人们往往对带有强烈情绪色彩的经历记忆深刻,难以忘怀,尤其是那些负面的,痛苦的回忆。这种负性情绪对记忆的造成的不良影响可能导致一些情绪问题和障碍,如恐怖症、抑郁症、创伤后应激障碍等。因此,通过记忆重播效应来探究情绪刺激影响记忆加工的神经机制将有助于我们更全面详尽地了解情绪障碍的形成和发展。已有研究证明,记忆重播在人们记忆巩固过程中起关键性作用,并且情绪线索使得相关事件的记忆效果更好。但目前大多数研究都聚焦在陈述性记忆在海马体的重播效应对记忆巩固和整合的促进作用以及情绪线索对个体记忆的影响上。实际上,由于相关事件在大脑中的记忆重叠现象,新旧相关事件的记忆会通过记忆重巩固的方式整合为一个整体的记忆网络结构。然而,情绪记忆是如何影响记忆重播活动以及在记忆编码阶段如何作为线索追溯到已有相关事件并影响其记忆巩固和整合,对此我们并未有详细地了解。本文通过两个研究对上述问题进行阐述。第一个研究中实验一采用事件相关设计的功能磁共振脑成像实验以及同步皮肤电记录技术,探究了预学习阶段(面孔-物品)和情绪学习阶段(面孔-声音)的脑激活活动。结果发现情绪刺激显著的激活了杏仁核,脑岛等区域;此外,通过记忆主效应的研究,发现左侧海马体在记忆任务中有重要作用。实验二则为后测行为实验,探讨了情绪线索对相关事件记忆巩固和整合的影响。被试分别对面孔、面孔-物品配对、面孔-声音配对进行回忆测试。结果发现,情绪线索对面孔-物品的关联记忆有增强作用,但是对面孔的个体记忆没有显著影响。研究二通过机器学习算法探究相关功能性脑区的重播效应,并且根据情绪线索记忆的重播强度来对被试的记忆表现进行预测。结果表明,海马体记忆重播强度对陈述性记忆表现有出色的预测效果,而脑岛,杏仁核等区域的重播强度可以很好的预测情绪线索所指向的关联记忆。上述研究结果说明,情绪线索可以倾向性和回溯性的增强过去相关中性事件的记忆巩固和整合;而记忆重播不仅会发生在海马区域,情绪性记忆的重播会在脑岛、杏仁核等情绪性脑区产生,并且可以根据情绪线索记忆的重播强度潜在地预测相关中性记忆的记忆表现。这些研究结果为探索相关情绪障碍的形成机制及其有效预防、干预和矫治的方法提供了重要的科学依据,也有助于人们对相关事件的记忆强化。"
1889,基于自编码器的Wi-Fi指纹定位算法研究,"现代社会的场景更加广泛和复杂,人们对定位服务的需求不断增加,而采用GNSS定位无法在室内接收到定位信号,对于现代大型复杂的室内环境来说,必须采用其他信号源进行定位。本文详细研究了基于Wi-Fi信号的指纹定位技术,围绕着指纹库数据预处理和指纹定位方法两方面,基于机器学习的方式,实现了比传统方式更准确的指纹定位。主要研究内容如下:首先,对采集到的原始接收信号强度(Received Signal Strength Indication,RSSI)数据进行预处理工作,对比两种处理RSSI数据的滤波方法效果,提出采用二次高斯滤波,能够明显减少指纹信号波动,降低噪声和粗差测量值的影响。指纹库采集的原始数据经过两次高斯滤波后取均值作为位置指纹库特征,对指纹库进行聚类分析,针对RSSI指纹向量的高维特点,提出采用基于调整余弦相似度的层次聚类方式对指纹库进行聚类。并且采用机器学习分类方式对在线测量点进行分类,能够将在线测量点先分到子指纹库中,再进行后续的定位处理。针对位置指纹库的维度较高问题,采用自编码器学习其主要特征,通过研究和分析几种自编码技术,提出一种适合处理Wi-Fi指纹数据的堆叠降噪自编码技术,并通过实验寻找最优的深层网络结构,使得能够将降低指纹库维度的同时不损失主要的RSSI指纹特征。然后使用softmax层将自编码器的输出转化为RSSI向量所属的参考点概率,在堆叠降噪自编码技术的基础上采用加权最近邻方法(Weighted K-Nearest Neighbor,WKNN)得到堆叠降噪自编码器的定位结果。最后研究了SVR和RF回归这两种机器学习回归方式对在线测量点进行定位,并使用传统的KNN、WKNN以及提出的Sparse SDAE WKNN方式对在线点定位。对比研究两种定位的模式:“粗定位―精确定位”模式和直接定位模式,通过实验表明,提出的Sparse SDAE WKNN方式定位效果最好,精度更高,采用“粗定位―精确定位”两步模式的定位精度远高于直接定位模式。采用两步定位模式进行动态实验定位,直接进行Wi-Fi定位和卡尔曼滤波定位的结果对比显示,采用卡尔曼滤波定位的轨迹更平滑,能够有效解决Wi-Fi定位轨迹的点位重叠和跳动现象,提高动态定位的精度。"
1890,基于Windows驱动过滤的网络入侵检测技术研究,"随着互联网技术的迅猛发展,数以万计的网络接入点产生的海量数据,给网络空间安全带来了前所未有的挑战。入侵检测系统是维护计算机系统安全的有效手段,入侵检测系统执行检测时的数据主要源自:主机系统、底层程序、用户程序以及网络流量信息,检测系统通过对以上几个区域进行严密的监控,发现其中违反安全规则以及危害系统安全的行为,一个性能强大的入侵检测系统对于保障计算机系统资源安全来说是必不可少的。在技术不断更新换代、大数据兴起的当今,网络攻击手段也呈现出复杂化、多样化和自动化等新的特点。而与此同时,在实际应用中,较高的漏报率和误报率是入侵检测系统需要重点解决的问题。为了应对当下频繁出现的多目标、分布化、隐蔽化组合式的恶意攻击,提出了基于Windows驱动过滤的网络入侵检测技术研究,关于该项研究本课题主要做了如下工作。首先,介绍并明确与入侵检测技术相关的基本概念,然后分析目前入侵检测技术存在的不足。根据目前技术存在不足设计并实现一种基于内核层的网络数据采集驱动以及用户层的数据处理程序。其次,对整个检测系统进行逻辑上和功能上的划分和设计:将系统划分为运行于内核态的数据采集模块、同时运行于内核态与用户态的数据协同模块以及运行于用户态的数据存储与分析模块。对于数据采集模块,主要采用了Windows过滤平台技术(Windows Filtering Platform,WFP)实现一个运行于内核态的网络采集模型,在此模型中具备了对截获的数据进行初步过滤的能力:即可以在内核态下采用一种误用检测方法过滤掉带有明显的网络攻击实例。对于数据协同模块,分析数据交互的关键技术,重点设计并实现了内核态数据采集驱动与用户态数据分析应用的交互策略,该策略在当前系统环境下能够保证内核层与应用层进行大规模、实时数据交互。对于数据分析模块,主要负责将从内核获取的网络数据进行归纳和整理,以此产生成若干可供分析程序作为输入的网络连接实例。最后,介绍和分析了机器学习技术在网络入侵检测领域中的一般应用流程。除此之外,采用了著名的UNSW-NB15网络综合数据集,并实现了对其预处理和特征提取。最后采用了极端随机树机器学习算法训练了分类模型并分析其性能,以此可以作为整个入侵检测模型的异常分类器。"
1891,基于机器学习的网络性能异常检测与预测,"随着互联网技术的高速发展和网络规模的不断扩大,互联网已经成为人们生产生活中的重要部分。网络多媒体业务、网络应用、网络用户对网络通信质量的要求也越来越高。与此同时,网络传播过程中的出现性能欠佳、网络安全隐患等问题的机率也大增加,比如网络拥塞、网络故障、自然灾害等突发状况影响网络性能。因此,研究网络性能的监测、预测和异常检测已经成为重要课题,通过监测大规模网络数据流可以及时地了解网络状况、网络故障,从而优化网络结构、提升网络性能。本文主要是围绕PingER(Ping End-to-End Reporting)网络性能监测平台,通过PingER网络性能监测平台获得端到端的网络性能数据,最后研究网络性能的异常检测与预测。主要工作如下:1.本文首先介绍网络性能异常检测和预测的研究背景,主要介绍了PingER框架、PingER的监测机制、监测指标等,研究利用ICMPv6协议实现IPv6环境下的网络性能监测,并成功采集实验数据。2.研究基于神经网络的网络性能异常检测,本文详细介绍了深度前馈神经网络、基本单元、误差逆传播、优化函数等。并提出了基于前馈全连接神经网络的异常检测模型,最后通过计算其正确率、误报率以及和基于聚类的离群因子算法进行对比实验分析,验证模型的有效性。3.研究网络性能数据预测,使用多元线性回归算法、随机森林算法、Gradient Boosting、XGBoost分别建立网络预测模型,然后利用均方根误差(RMSE)算法对比了不同模型对网络性能预测的准确率。实验结果表明,利用多元线性回归算法模型提高了网络性能预测精度,实现了网络流量准确预测,并有较强的实用价值。本文研究网络性能数据的特性,使用合适的机器学习算法,建立数据分析模型,实现网络性能的异常检测和预测,从而在提升网络性能、优化网络结构方面,为网络用户、网络管理人员提供有效的数据支撑。"
1892,基于高通量测序数据的跨界sRNA数据分析方法研究,"Small RNA(sRNAs)是一类长度在几十至几百个核苷酸之间的非编码小分子RNA,在生物体内通过和靶mRNA碱基互补配对结合进而调控基因表达,从而参与控制细胞的多种生物过程。最初,sRNA由于长度过小,很难被检测到。随着高通量测序技术的出现,越来越多的sRNA不断被发现,其作为调控基因表达的重要调节因子也逐渐成为生命科学研究的热点问题。现有研究证实sRNA在跨界调控中起着重要作用。由于sRNA的序列及结构与其进入宿主细胞的能力息息相关,因此从序列及结构方面对跨界sRNA进行数据分析,进而寻找并识别类似的跨界sRNA,不仅可以发掘sRNA序列及结构和功能的相关性,也对有效识别未知的跨界sRNA有重要意义。截止到目前,有关sRNA的研究主要集中在对sRNA的序列分析和靶基因功能识别方面,而对于跨界sRNA序列的研究还处于初期研究阶段,且均是针对特定物种进行研究。本文从生物计算入手,在研究常见RNA数据分析方法基础上,基于真菌和植物、植物和人体sRNA高通量数据提出了一种跨界sRNA数据分析方法。首先应用统计学方法分析跨界sRNA序列及结构信息,其次在对差异表达的跨界sRNA分析的基础上,识别出可能影响sRNA进入宿主细胞参与跨界调控的分子特征,构建基于机器学习的跨界sRNA识别模型,用来识别可能被宿主吸收的外源性sRNA,进而挖掘跨界sRNA可能存在的生物学意义及生物功能。本文首先收集真菌和植物、植物和人体sRNA数据并对其进行质量、剪切识别等一系列预处理;然后,应用机器学习方法对sRNA序列及结构特征进行选择构建特征子集,进而构建跨界sRNA识别模型,用来对能够进入宿主细胞的sRNA进行识别;最后,对模型进行评估,并对识别的跨界sRNA进行靶基因筛选、功能富集分析及基因相互作用关系挖掘,从而分析出其在生物系统中的功能。本文选用真菌和植物数据以及人类和植物sRNA数据作为实例分别用本文提出的数据分析方法进行研究,其中,对真菌和植物模型的正确率在84.5%,植物和人体正确率在78.2%。本文提出针对跨界sRNA高通量测序数据的分析方法为研究跨界sRNA进入宿主细胞的能力与其结构和特征间的关系提供了新的研究思路,为今后研究sRNA的跨界调控机制提供了新的研究方向,同时在农作物,药物和疾病等方面都有部分指导意义。"
1893,基于机器学习算法分析BamA蛋白质分子动力学模拟轨迹,"β-桶状膜蛋白是一种跨膜蛋白,常被称为β-桶状外膜蛋白(β-barrel Outer Membrane Proteins,OMPs),主要在真核生物的叶绿体与线粒体以及革兰氏阴性菌外膜上存在。它参与了许多生物进程,包括物质的跨膜运输、信号传导、运动等。值得注意的是,它与革兰氏阴性菌的致病毒素――内毒素的释放有关。所以研究β-桶状外膜蛋白的生物发生有可能对内毒素引发的疾病起预防或治疗作用。β-桶状外膜蛋白的装配与插膜过程是由β-Barrel Assembly Machinery(Bam)复合体介导的,而本文的研究对象BamA蛋白质是Bam复合体的核心蛋白,因此研究BamA蛋白质可能对寻找新的治疗靶标有帮助。BamA蛋白质主要由β-桶结构与5个POTRA(Polypeptide Transport-Associated)结构域组成。随着越来越多蛋白质的晶体结构被解析以及计算机的飞速发展,分子动力学模拟被广泛地应用到各类学科的研究中。由于它可以动态观察蛋白质的运动状态,因此可以弥补实验的不足,为问题的研究提供新视角。该方法主要原理是通过求解牛顿第二定律中的运动方程来获取下一步的运动坐标,本质上是一个采样的过程。本文所用的BamA蛋白质轨迹数据的时间尺度约为12.5微秒。目前大多数关于BamA蛋白质的研究都基于β-桶结构作用机制与5个POTRA结构域的运动机制,即以相对较大的层面进行研究。而本文从更细节的层面,通过残基构象变化、平移旋转、整体运动以及蛋白质构象变化几个方面对BamA蛋白质的运动进行研究,找出与BamA蛋白质结构转变相关的残基位点,从而为BamA的工作机制提供参考。由于轨迹数据高维的特点且分布未知,因此本文利用了机器学习相关算法(降维和聚类)对数据进行处理。降维提取了数据的主要特征并且将数据可视化,聚类算法可以估计出数据的具体分布,为接下来的研究提供思路。本文所选用的降维算法为主成分分析(Principal Component Analysis,PCA),聚类算法为MeanShift算法和高斯混合模型(GMM)算法。本文根据不同方面的聚类结果分别计算了不同残基间的互信息,通过查找分析残基间的远程相关性,并与相关研究进行对照后,找出了A318、T724、W718以及A755这几个位点,猜测它们为BamA蛋白质潜在的结合位点或e构位点,这些位点可能在BamA蛋白质的结构转换中起重要作用。同时根据对残基构象变化、平移旋转与残基整体运动的分析得出当平移旋转与构象变化同时存在时,平移旋转更加明显。"
1894,长链非编码RNA-蛋白质相互作用及疾病关联算法的研究,"长链非编码RNA(lncRNA)是长度大于200碱基,且可以通过折叠的方式形成稳定的空间结构,但是不能编码蛋白的RNA。随着下一代测序技术与生物信息学的发展,近年来lncRNA研究引起了越来越多的关注,深入探讨lncRNA与蛋白质的相互作用关系以及疾病关联分析是推断lncRNA功能和深入研究lncRNA的主要途径。目前lncRNA与蛋白质的互作预测仍处于初步阶段。lncRNA在众多生物学通路与生物分子功能中扮演着重要的角色,且与众多疾病的发生、发展息息相关,lncRNA通过生物大分子之间的相互作用来实现生物学功能,lncRNA最重要的分子机制之一是与蛋白质的相互作用。网络科学的兴起以及其在生物信息学领域的应用深入也为lncRNA的深入挖掘提供新的方法。目前已经有多种预测lncRNA与蛋白质相互作用的方法被提出。主要分为两大类预测lncRNA与蛋白质相互作用的方法:第一大类是基于序列、结构及理化性质的内在特征预测lncRNA与蛋白质相互作用的计算模型;第二大类是基于网络方法的外部关联预测lncRNA与蛋白质相互作用的计算模型。一方面反映了学界对lncRNA与蛋白质分子相互作用关系的这一问题有着浓厚的兴趣和一定的重视,另一反面也表现了机器学习与网络科学在探索生物领域所蕴含的远大前景。在本研究的第一部分,分别对基于机器学习与网络分析方法预测lncRNA与蛋白质相互作用的计算模型进行了系统和全面地分析与比较,归纳了这两大类计算方法的不同优缺点,以及适用范围。这部分内容不仅可以全面地展示当前lncRNA与蛋白质分子相互作用的研究进展,帮助用户在不同的数据集下选择合适的预测相互作用的方法,最终取得更加可靠的相互作用结果。在本研究的第二部分,提出了新的预测lncRNA与蛋白质分子相互作用的算法。构建异质网络,利用网络表示学习DeepWalk算法深度挖掘分子外部的关联特征以及异质网络中生物分子间的拓扑结构信息,构建多种分类器模型预测lncRNA与蛋白质的互作,并进一步与其他预测lncRNA-蛋白质互作的算法相比较,本部分提出的算法在效果和方法方面都有着良好的表现。此外,目前已收录在公开数据库中的lncRNA与疾病关联的数目相比于已经鉴定出来的lncRNA的数目是不能相提并论的,仅有极少一部分lncRNA与疾病关联的数据,为此,在本文第三部分的研究中,构建了利用异质网络拓扑相似性的lncRNA与疾病关联的预测模型。首先构建了包括lncRNA-microRNA的相互作用、lncRNA-疾病的关联、microRNA-疾病的关联、lncRNA-lncRNA的相互作用和疾病-疾病的相互作用所组成的异质网络,基于DeepWalk得到节点的向量表示,计算拓扑相似性并基于规则推理预测潜在的lncRNA与疾病关联的计算方法。利用10折交叉验证,与同样基于网络方法预测lncRNA与疾病关联的计算模型RWRHLD和RWRlncD进行比较,并进一步基于文本挖掘对预测结果进行验证与比较,本部分提出的预测lncRNA与疾病关联的计算方法获得了令人满意的表现,并优于RWRHLD和RWRlncD算法。通过本文的研究,总结并讨论了lncRNA与蛋白质相互作用预测的计算方法,并提出了新的基于异质网络中挖掘隐藏的拓扑结构信息提取分子外部关联的特征,构建机器学习模型预测lncRNA与蛋白质相互作用的计算方法。此外,构建lncRNA与疾病关联的异质网络,基于拓扑相似性质的关联规则预测lncRNA与疾病关联。通过本文的工作可以有助lncRNA的功能推断,全面推动lncRNA的研究。"
1895,基于集成学习的云底高度智能反演算法,"云是天气气候的重要影响因子之一,目前世界上有超过三分之二的地区被云层覆盖,云的存在能直接影响大气辐射的传输过程,从而改变大气辐射的时空分布。不仅如此,云层能直接参与水循环过程,因此世界各地的降水分布也与云层分布有关。在云底高度反演计算问题上,基于云高观测仪的反演计算受人为主观因素影响较为明显,在计算结果上与实际云高存在一定的偏差。为构造性能更优、智能化更高的云底高度反演计算模型,本文在处理云底高度反演计算问题上,将经典机器学习算法和卷积神经网络通过集成学习策略相融合,设计一种融合多算法的云底高度智能反演计算模型MCHIIC。本文主要创新点包括:1、在本文MCHIIC模型的云高实况要素数据采集模块中,为了能够对湖南省气象台所给定的相关数据进行实时筛选,以提取出适合云高反演计算的相关实况要素数据,本文设计了一个云高要素数据筛选器CLHF来实现对云高实况要素数据的提取,即当相关数据发生变化时,CLHF能以根据数据的变化,不限时间、地域、地形和观测站点个数的限制精确筛选出模型需要的云高数据,大量减少了人为筛选工作所带来的误差以及工作量。2、在本文MCHIIC模型的卷积处理模块中,通过对经典损失函数Softmax loss做出改进,在Softmax loss上对输出矩阵ω和偏置b进行了修改,设计出了针对于云高反演的损失函数CLH-Softmax loss,使得反演结果能维持在一个更加合理的区间,从而进一步提升云高分类输出的精度。3、在MCHIIC模型的云高分类输出模块中,为了进一步提升模型在云高实况要素数据集上的分类精度和泛化能力,本文提出多加权融合算法(Weighted Fusion,WF)和基于权重修正单元的堆叠套袋(Weighted-Regulate-Unit-StackingBagging,WRUSB)算法,在WF算法中,本文对CLH-CNN分类器和Adaboost分类器输出之后的结果做加权输出并输入到Softmax层进行概率分析。在WRUSB算法中,本文在Bagging算法投票输出之前对基分类器的输出权重做出了调整,对每个输出根据输出权重的大小赋予不同的修正系数,并用投票法的方式得到云底高度反演结果,在提升模型泛化能力的同时也提高了输出的分类精度。"
1896,基于多光谱传感器的内陆湖泊的叶绿素a浓度反演方法研究,"叶绿素a是水体浮游水生生物的重要组成部分,并且它在浮游生物中的含量比较固定,方便在检测室测量,因此通常利用Chla作为监测水体生物量和营养化程度的指标。Chla浓度反演模型的研究也成为水色遥感研究的重要领域,通过对Chla浓度的计算反演,可以得出湖泊中的各区域初级生产力的状况,进而得到水体的富营养化程度。传统湖泊叶绿素含量监测耗时耗力,而且难以得到区域叶绿素分布结果。随着遥感技术和机器学习技术的不断发展,这两者的结合为实现大面湖泊水质高效、低成本监测提供了一种全新的方法。本文把太湖选为研究区域,以太湖地区叶绿素a浓度实测数据及同期HJ1B星CCD传感器的遥感影像为基础,采用传统经验模型和不同机器学习方法进行太湖叶绿素a浓度反演。通过对不同模型反演结果精度的分析比较,得出适用于内陆湖泊水体监测的反演方法。本文主要工作及结论如下:(1)太湖叶绿素a浓度模型的建立。基于HJ1B-CCD数据和叶绿素a采样点数据,分别利用一元线性模型、多元线性逐步回归模型等两种传统统计模型和K-NN、SVM、RF等三种机器学习算法进行太湖Chla浓度建模,并详细阐述各模型原理、构建过程。(2)太湖叶绿素a浓度反演模型精度对比分析。利用IDL语言进行一元线性模型和多元线性回归模型的留一法交叉验证分别得到R~2=0.55、RMSE=0.007mg/L,R~2=0.72、RMSE=0.007mg/L。分别针对三种不同的机器学习方法进行参数设置,得到K-NN最邻近法的最优K值为4,随机森林决策树取值为600。最终得到K-NN最邻近法、支持向量机、随机森林反演模型的R~2=0.76、RMSE=0.0054mg/L,R~2=0.80、RMSE=0.0050mg/L,R~2=0.88、RMSE=0.0036mg/L。利用留一法交叉验证,使用均方根误差评价各个模型的精度,最大程度的排除随机分配训练样本和检验样本带来的误差和不确定性。实验结果表明,一元线性模型估测精度最低,多元线性逐步回归模型次之,随机森林估测精度最高;k最近邻法和支持向量机估测精度较为接近。"
1897,深度学习在中医舌象分类中的应用与实践,"中华文明历史悠久,源远流长,传统中医伴随着历史的发展一直流传至今,形成了一套坚实的中医理论基础。与西方医学不同的是,中医讲求全面了解和系统掌握疾病的相关信息,从而指导临床治疗,这与西方医学形成了完美的互补。中医的诊断技术举世闻名,其独特的四诊法(望闻问切)相传是中国古代战国时期的名医扁鹊根据民间流传的经验和他多年的行医实践,总结出来的诊断疾病的四种基本方法,即望诊、闻诊、问诊和切诊,总称为“四诊”。舌诊是望诊的一个重要环节,也是医生通过舌象来了解病人体内病例变化的一种有效的诊疗手段。近年来,随着中医现代化不断加深,人们对舌诊定量化、客观化有了新的要求。依托现代信息技术方法研究舌诊的原理,使其更加科学化和便捷化已经成为了舌诊研究的必然方向。但是,中医舌诊一直都是通过医生的目测观察进行判断,并通过医生的个人从医经验将患者的身体情况转化为凝练的语言文字,这种诊断形式缺乏定量化和客观化的度量,同时在舌诊的过程中容易受到外部条件(如光源条件、观察角度等因素)的影响以及一些人为因素(如知识水平、临床经验等)的干扰,并且从预约医生到现场诊断往往需要很长的时间。不过在另一方面,我们也可以看到这些不利的因素也为计算机辅助诊断创造了有利的机会,借助计算机方法来模拟中医舌诊过程的想法也自然是水到渠成。本文以中医体质为例,对传统中医以舌象为基础进行体质分类的过程进行了分析和研究,通过机器学习和深度学习算法实现了对一张图片中是否存在舌头部分的判别,同时模拟了借助舌象对中医体质分类的过程,构建了一个可以通过舌象图片进行中医体质分类的判别系统,用户可以通过手机便捷地了解自己所属的中医体质,并根据自己所属的中医体质获取饮食、生活方式等相关的推荐信息。本文的主要工作如下:1.对来自服务器中用户上传的舌象图片和上海中医药大学门诊部的舌象数据进行收集,并由中医师为原始无标签的舌象数据按照中医九种体质分类标准进行数据标定,构建了一个带有体质分类标签的舌象数据集。2.构建了舌象图片的识别模型。该模型能够准确地判断一张图片是否为舌象照片,通过机器学习中传统的分类方法和深度学习中卷积神经网络的方法加以实现,并对以上两种分类方法的结果做了对比和分析。3.基于深度学习中的残差神经网络结构,训练出一个中医九种体质的分类模型。并将训练好的中医体质分类模型加以应用,实现了一个智能中医体质分类平台。该平台能够对用户上传的舌象照片给出用户所属中医体质分类、体质特征描述和相应的生活建议。"
1898,多参数MRI影像组学术前诊断直肠癌淋巴结转移的价值初探,"目的:探讨基于机器学习建立的多参数MRI的影像组学模型对直肠癌淋巴结转移的术前诊断价值。方法:回顾性分析2016年1月至2017年3月于吉林大学第一医院经根治性手术后病理证实为直肠癌并于术前2周内接受过直肠MRI检查的140例患者,并随机将患者分为训练集(98例)和验证集(42例)。使用Intelli Space Discovery在T2WI序列上对原发肿瘤和肿瘤所在层面的直肠系膜筋膜进行感兴趣容积(VOIs)勾画,采用飞利浦影像组学工具对VOIs进行影像组学特征的提取。采用Spearman相关性分析评价提取的影像组学特征与直肠癌淋巴结转移的相关性,再使用最小绝对收缩与选择算子算法(LASSO)进行进一步的特征降维。采用23种不同的机器学习分类器建立影像组学预测模型。通过五折交叉验证在训练集中训练多变量模型,并在测试集中采用受试者工作特征曲线(ROC)的曲线下面积(AUC)、准确度、特异度、灵敏度和F1分数等评价模型性能。结果:训练集和验证集组间患者的临床及病理特征差异无统计学意义(P>0.05)。每个VOI总共提取1227个基于三维(3D)的影像组学特征。将每位患者两个VOIs的2454个影像组学特征集成在一起。通过Spearman相关性分析及LASSO算法后共保留21个影像组学特征用于构建预测模型。在23个机器学习模型中,岭分类器(Ridge Classifier)发现具有最佳的预测性能,其在训练集、五折交叉验证集和测试集的平均AUC分别为0.905、0.803和0.785,准确度分别为82.7%、79.5%和73.8%。同时,模型在测试集的平均特异度、灵敏度和F1分数分别为0.79、0.667和0.785。结论:基于机器学习建立的直肠癌多参数MRI的影像组学模型是个体化、无创性预测淋巴结转移的有力工具,具有较高的诊断性能。"
1899,基于影像组学的脑胶质瘤病理分级预测,"目的:通过使用影像组学和机器学习的方法构建随机森林模型,用于判读脑胶质瘤的MRI图像,探讨术前通过MRI图像预测脑胶质瘤病理分级的可行性和有效性。方法:首先获取BraTS训练集的DICOM图像,所有图像已经预先划分出ROI。使用Python平台下的Pyradiomics包进行全部图像的特征提取。将全部样本按照70%的比例随机划分出训练组,剩余30%进入测试组。随后将训练组(198例)划分为5个亚组(每个亚组分别有40、39、40、39、40个样本),使用R软件进行5折交叉验证拟合,以Gini系数作为随机森林中树的分枝规则,获得随机森林最佳参数mtry(每个节点可能分割的变量的数量)和min.node.size(即最小的节点的大小),将得到的最佳参数用于构建最终的随机森林模型,并输出特征重要性排名。最后进行测试组图像判读和分类器性能评价,输出混淆矩阵,计算准确度、敏感度、特异度、精确度、F1值,绘制ROC曲线,进行一致性评价等。结果:共获得训练集中高级别胶质瘤210例,低级别胶质瘤75例,每个病例包含T1、T2、Flair、T1ce 4个序列及1个预先分割的ROI序列。75例LGG中有3例因某些特征不能被提取而被剔除,其余72例LGG和全部210例HGG每例均提取形状特征14个,一阶特征18个,灰度共生矩阵特征24个,灰度相关矩阵特征14个,灰度游程矩阵特征16个,灰度区域大小矩阵特征16个,相邻灰度差分矩阵特征5个。5折交叉验证得到随机森林mtry值寻优结果为48,min.node.size为7,此时AUC为0.8958746,敏感度为0.6254545,特异性为0.9324138。经训练组拟合的随机森林模型特征变量及其所属序列按重要性排名前10位依次为:表面积体积比,GLDM低灰度小偏好性-T1ce,GLRLM游程熵-T1,球形度,GLSZM大面积高灰度级偏好性-Flair,GLDM高灰度大偏好性-T1ce,GLDM依赖不均匀-T1,GLDM依赖不均匀-T1ce,GLSZM大面积高灰度级偏好性-T2,NGTDM粗糙度-Flair。利用得到的最优参数构建的随机森林模型判读测试组MRI图像,最终评估病理分级的准确率为91.67%(95%CI为83.58%-96.58%),敏感性95.24%,特异性90.48%,精确度为76.92%,无信息预测率为75%,准确度大于无信息预测率的P<0.001。一致性检验Kappa值为0.7941,F1值为0.8511。结论:本研究构建的分类器有着较高的敏感性和特异性,一致性检验中表现出其分类能力与病理诊断有着高度一致性。综合多个评价数据可以认为利用本研究构建的随机森林分类器进行胶质瘤的病理分级预判具有良好的可行性,可以在一定程度起到辅助术前诊断的作用。"
1900,基于DCE-MRI的影像组学联合机器学习预测前列腺癌的侵袭性,"目的:研究基于多期动态增强(Dynamic contrast-enhanced,DCE)MRI原始图像的影像组学联合机器学习以预测前列腺癌(Prostate cancer,PCa)的侵袭性。方法:收集2016年1月至2018年5月在我院进行磁共振检查并经活检证实为前列腺癌的40位患者,每位患者的活检均在磁共振检查后4周内进行。收集每位患者的临床与影像资料,根据时间-信号强度曲线,在原始DCE-MRI图像上肿瘤强化的第一期和最强一期上逐层勾画病灶,并自动计算出每个病灶的1029个定量影像组学特征(这些特征可分为四类,类别一为一阶特征:通过常用的基本度量来定量描绘图像体素强度的分布,如均值,熵等;类别二为形状大小特征:反映感兴趣区的三维形状和各种径线;类别三为纹理特征:可以量化区域异质性的差异,主要是从灰度游程矩阵(Gray-level run-length matrix,GLRLM),灰度区域矩阵(Gray-level size zone matrix,GLSZM)和灰度共生矩阵(Gray-level co-occurrence matrix,GLCM)中计算的纹理特征;类别四为高阶特征:主要包括经滤波器变换后导出图像的强度和纹理特征,图像变换的滤波器如下:指数,平方,平方根,对数和小波),构成三个数据集:数据集-F(基于肿瘤强化的第一期提取)、数据集-S(基于肿瘤强化的最强一期提取)和数据集-FS(基于第一期及最强一期提取)。然后,依次采用方差选择法、单变量选择法及最小绝对收缩和选择算子(Least absolute shrinkage and selection operator,LASSO)算法进行特征降维,筛选出每个数据集的最优特征子集。最后,使用5种分类器:逻辑回归(Logistic regression,LR)、随机森林(Random forests,RF)、决策树(Decision tree,DT)、k-近邻(K-nearest neighbor,KNN)和支持向量机(Support vector machine,SVM)利用5-折交叉验证法建立预测模型,通过曲线下面积(Area under the curve,AUC)评估每个模型的预测性能。将具有最佳分类性能的特征子集与前列腺癌灶的GS评分(Gleason score,GS)之间进行相关性分析。结果:经过特征降维过程,数据集-F,-S和-FS中分别得到了8、4和16个特征作为最优子集。数据集-F的最优子集为:F-轴位最小径(F-Least Axis-shape)、小波变换(滤波器高-低-高)后的F-中值(F-Median)、小波变换(滤波器高-低-高)后的F-均值(F-Mean)、平方变换后GLSZM中的F-大区域增强(F-Large area emphasis,LAE)、小波变换(滤波器高-高-高)后GLRLM中的F-长距离增强(F-Long Run Emphasis,LRE)、指数变换后GLRLM中的F-长度不均匀性(F-Run length non-uniformity,RLN)、平方根变换后的F-总能量(F-Total Energy-square root)和F-总能量-一阶特征(F-Total Energy-first order statistics)。数据集-S的最优子集为:S-轴位最小径(S-Least Axis-shape)、GLSZM纹理特征中的S-大区域高灰度增强(S-Large area high gray-level emphasis,LAHGLE)、小波变换(滤波器高-高-低)后的S-中值和小波变换(滤波器高-高-低)后的S-均值。数据集-FS的最优子集为:F-轴位最小径、S-轴位最小径、F-总能量-一阶特征、对数变换后的F-总能量(F-Total Energy-logarithm)、小波变换(滤波器低-低-高)后GLSZM中的S-LAE、GLSZM纹理特征中的S-LAHGLE、小波变换(滤波器高-高-低)后GLSZM中的F-区域熵(F-Zone entropy,ZE)、小波变换(滤波器高-高-高)后GLRLM中的F-LRE、指数变换后GLRLM-中的F-RLN、小波变换(滤波器高-高-高)后GLRLM中的S-LRE、小波变换(滤波器高-低-高)后的F-中值、平方根变换后的S-峰度(S-Kurtosis-square root)、小波变换(滤波器高-低-高)后的F-均值、平方变换后GLSZM中的F-LAE、GLSZM中的S-区域差异(S-Zone Variance,ZV)和小波变换(滤波器高-高-低)后的S-均值。基于数据集-F各模型的预测性能为:LR(AUC=0.87)、RF(AUC=0.83)、DT(AUC=0.71)、KNN(AUC=0.88)以及SVM(AUC=0.84)。基于数据集-S各模型的预测性能为:LR(AUC=0.84)、RF(AUC=0.80)、DT(AUC=0.69)、KNN(AUC=0.82)以及SVM(AUC=0.83)。基于数据集-FS各模型的预测性能为:LR(AUC=0.93)、RF(AUC=0.82)、DT(AUC=0.77)、KNN(AUC=0.91)以及SVM(AUC=0.90)。在三个数据集中,基于数据集-FS的LR具有最佳的预测性能(AUC=0.93)。并且该数据集中的F-轴位最小径、S-轴位最小径、F-总能量-一阶特征、对数变换后的F-总能量、小波变换(滤波器低-低-高)后GLSZM中的S-LAE、GLSZM纹理特征中的S-LAHGLE、小波变换(滤波器高-高-低)后GLSZM中的F-ZE、小波变换(滤波器高-高-高)后GLRLM中的F-LRE、指数变换后GLRLM-中的F-RLN和小波变换(滤波器高-高-高)后GLRLM中的S-LRE这10个特征与GS呈正相关。同时,基于数据集-F模型的预测性能普遍优于数据集-S。结论:应用基于DCE-MRI肿瘤强化的第一期及最强一期原始图像的影像组学联合机器学习可以无创、准确且自动地预测前列腺癌的侵袭性。"
1901,头颈鳞状细胞癌的分期及存活问题的特征建模算法研究与开发,"随着社会以及网络的发展,人们会在日常活动中产生越来越多的数据,很多研究人员已经利用这些数据做了大量研究,比如,一些购物网站上的推荐算法,利用某个消费者以往的消费记录,可以预测此消费者可能需要的产品。商家也可以利用很多消费者的消费记录进行分析,以帮助制定合适的产品套餐。数据在当今的社会已经成为一种很重要的资源,利用数据可以挖掘出很多重要的信息。人体本身也带有很多数据,那么是否可以利用这些数据挖掘出一些重要信息,常见的基因方面的数据有转录组数据,以及甲基化数据等。转录组数据主要用来研究在单个细胞、或者特定类型的细胞、组织、器官或者发育阶段的细胞群内所产生的各类RNA(通常是m RNA)分子的类型和数量。转录组数据测量的是在某个特定样本里表达的基因丰度及其类型。其中,m RNA的丰度是指每个细胞里每一种m RNA分子的平均数。甲基化一般是指在酶的作用下,DNA胞嘧啶以特定方式被甲基化修饰。目前已经有多个研究发现,DNA甲基化水平以某种方式影响人类肿瘤的发生以及发展。检测得到的DNA甲基化水平值可用于判断肿瘤的分期以及肿瘤的预后判断,这对于肿瘤的治疗具有重要意义。在头颈部癌症中超过90%的癌症属于头颈鳞状细胞癌。头颈鳞状细胞癌是世界上十大常见癌症之一,并且存活率也较低。如果能找到与头颈鳞状细胞癌相关的基因标记,并对疾病的分期以及病人的存活时间进行有效的预测将具有重要意义。本文主要是利用原发性头颈鳞状细胞癌的转录组数据以及甲基化数据进行分期以及存活时间的预测。首先,甲基化数据和转录组数据都有上万级的特征,我们利用所设计的算法对合并后的数据集进行特征选择,也就是从大量特征中选择出对区分头颈鳞状细胞癌分期有用的特征。同时,由于数据样本类别分布不均衡,也就是处于Ⅳ期的样本数量最多,大约占总样本数量的60%,所以,我们设计算了“OROO”方法解决这个问题,提高预测效果。本文在进行特征提取以及参数优化后,从原来上万级的特征中选择出了154个特征,在这154个特征中,有144个特征属于转录组数据,有10个特征属于甲基化数据。最终,我们以较高的准确率预测了头颈鳞状细胞癌的分期,其中平均绝对误差为0.027、准确率为97.98%。同时也证明了我们选择出的特征与头颈鳞状细胞癌的分期密切相关。接下来,我们利用挑选出的特征再次经过特征选择,选择出了31个特征,以14.175个月的平均绝对误差预测了样本的存活时间。同时也说明了,这31个特征与存活时间密切相关。此实验对于头颈鳞状细胞癌的研究以及制定合适的治疗措施具有重要意义。最后,利用本文中提出的SFMC方法进行头颈鳞状细胞癌的二分类分期预测,并与目前的头颈鳞状细胞癌的二分类分期预测效果进行了比较,我们的实验方法取得了更好的预测效果。"
1902,基于大数据技术的学生行为分析,"随着时代发展,加快了校园学生数据信息化速度,学校的各个管理部门更多的将学生数据存储在电脑上,让学校里学生管理工作效率更高。各个部门的相关数据越来越多,而这些数据都与学生的在校行为息息相关,可以很好的反映学生在校的行为习惯和学习现状。因此,采用数据挖掘技术去对学生行为数据进行观测和分析,对于学校和学生的管理以及建设都非常重要,可以很好的提高学校的管理效率。本课题利用杭州某高校的校园一卡通消费数据和教务处资助名单来进行贫困生分类预测研究,利用郑州某高校的学生上网日志,来对学生的上网行为进行聚类分析。学校已经开始广泛使用校园一卡通系统,学生在日常的消费使用过程中产生了大量的一卡通数据,以学生在一卡通卡务中心、信息中心产生的相关数据为研究对象,将数据挖掘技术应用到校园一卡通的消费数据中来进行深度挖掘;本文基于机器学习分类算法构建高校贫困生的分类模型,提出了将PCA和SMOTE算法结合起来的PS-XGBOOST模型进行分类预测,为我国高校贫困学生的评定标准提供重要依据,保证学校贫困学生认定的公正。在深度学习K-MEANS算法和CANOPY算法的基础上,基于HADOOP平台设计了这两种算法的并行化的算法,同时提出改进的CAK-MEANS算法,并将改进的并行算法部署在3台机器组成的HADOOP集群上来对学生在校的上网数据进行研究。本课题通过结合大数据技术与聚类算法从各维度分析了学生的行为数据,得出的结果能帮助老师对学生有进一步的了解;而且采用大数据技术分析学生的上网数据,可以从技术角度来对校园网的管理工作提供决策帮助。"
1903,基于无线充电的低功耗网络协作传输技术,"随着物联网产业以及无线传感器网络技术的飞速发展,感应节点工作的可持续性问题日益凸显。由于节点寿命有限且置换不便,传统基于电池的供电方式已不再适用于这种能量受限的传感器网络,因此无线射频(radiofrequency,RF)能量收集(energyharvesting,EH)技术应运而生。无线电能量传输具有可控性,能够对网络中的节点进行持续供电,并且能够同时携带能量和信息,因此,无线充电通信网络(wireless powered communication network,WPCN)成为极具吸引力与创新性的研究领域。本文主要考虑在无线充电通信网络场景下进行信息和能量的传输机制设计和资源分配算法研究,并对系统网络布局以及无线资源做出优化配置,从而实现通过无线射频能量采集技术延长网络的使用寿命。具体来说,本文在三个节点组成的多输入单输出(multiple input single output,MISO)无线广播系统中研究了射频能量和信息传输的问题。在所研究的问题中,多天线发送节点作为信息源为两个单天线接收节点传输信息,其中一个接收端作为具有最佳服务质量(quality-of-service,QoS)要求的用户具有稳定电源供给,并为另一个无源接收端提供信息的中继转发服务和射频能量传输。为了进一步提升系统频谱效率,本文采用非正交的传输方式;并且,为了提升理论研究与实际情况的契合度,本文采用非线性能量采集模型。本文的创新点及主要内容包括以下三个方面:(1)在单时隙MISO下行链路系统中,设计了一种基于“三阶段”的传输协议,提出了一种高效的资源分配算法。算法实现了各阶段的时间比例优化、波束赋形设计和转发功率控制,从而保证了无源节点信息传输的可靠性和有效性,并且最大化的提升了系统吞吐量。仿真结果验证了该算法的良好性能。(2)在多时隙MISO下行链路系统中,提出了一种基于指示函数的传输策略,设计了基于遍历搜索、基于能量门限以及基于稀疏优化的三种算法,并成功地解决了多时隙联合优化问题,实现了业务机制选择、波束赋形设计以及转发功率控制。实验仿真与对比验证了基于稀疏优化算法的有效性与可靠性。(3)创新性地采用基于机器学习的方法对本文多时隙联合优化问题进行训练与学习。通过有效调整网络结构、超参数等,训练出一个全连接的前馈神经网络,实现了业务机制的选择。仿真结果证明了该方法具有很好的泛化性能,并且在保证系统性能的前提下显著提升了系统运算效率。"
1904,基于机器学习的雷达威胁分析识别,"本文对基于机器学习的雷达威胁信号分析识别方法进行研究。雷达技术快速发展,现代雷达参数灵活多变具有多模式、自适应捷变等特点。参数的多变给雷达发射信号的分析识别带来了更大的难度,而对雷达信号的有效识别分析是应对雷达威胁的关键。雷达参数变化有两种可能的原因,一是雷达根据本身体制和任务需要而采取的参数调制,二是雷达根据外界环境及照射目标特性,为了优化工作效果而调整工作参数。前者体现了雷达在不同体制不同任务下采取的必要参数变化规则,而后者是雷达受到外界综合影响的自适应调整行为。本文对雷达威胁信号的分析识别从上述两个角度出发,研究多模式雷达信号的分类识别方法以及雷达自适应行为特点的识别方法,主要研究内容包括以下几点:(1)针对雷达对象进行必要的研究分析。首先,构建了基于雷达参数变化模式和参数取值两层划分的层次化雷达信号模式描述方式,这种方法可以有效的将采取多种参数变化规则的雷达信号进行分类识别。另外,给出了雷达自适应波形行为的概念,将雷达通过与外界环境交互,并因此改变自身发射波形参数的过程定义为雷达的行为。介绍了雷达波形选择的基本原理,具体研究了跟踪雷达自适应波形优化的算法并进行了仿真验证了波形优化的效果。(2)研究给出了基于卷积神经网络和密度聚类算法的雷达信号模式层次化识别模型。该模型以雷达脉冲参数序列为输入,包含一次识别,两次分类。首先通过卷积神经网络对参数序列进行识别得到参数所采取的变化模式如参差、滑变、驻留切换等,以各个参数的变化模式识别结果对雷达信号进行第一次分类。在第一次分类基础上,通过聚类算法根据各个参数的取值特征进行第二次分类,最终将雷达信号划分为不同的模式。在构造的雷达信号框架下产生模拟雷达脉冲参数序列作为实验数据,对各部分识别算法和整体算法进行了仿真验证。该方法能够较好的对雷达威胁信号进行分类识别,且可以通过分类后的信号特征判断雷达所处的实际工作模式进而判断雷达的威胁等级。(3)根据雷达自适应波形行为概念和雷达自适应波形选择原理,研究雷达自适应波形行为识别方法。本文将雷达自适应波形优化过程抽象为以目标特性、杂波环境、干扰等外界影响和上一时刻发射波形参数为输入,下一时刻发射波形参数为输出的决策系统,从而将雷达自适应波形行为识别转化为对该系统的系统辨识。在此基础上,本文研究通过神经网络算法对雷达自适应波形选择系统进行学习的系统辨识方法,通过训练得到的神经网络预测雷达在外界影响作用下的波形参数选择。通过仿真验证了该方法能够对雷达自适应波形行为规律进行有效的学习,实现了根据目标特性和干扰预测雷达自适应波形选择的工作参数,从而有效应对雷达威胁。"
1905,创业领域文献知识图谱构建与应用研究,"随着知识图谱的发展,目前已经出现很多优秀的学术知识图谱,比较知名的有Aminer平台、微软学术图谱等,旨在对不同的学术数据进行集成,为科研人员提供更多学术搜索上的帮助。但这些学术图谱建立的是面向通用领域的知识库,在对实体的抽取上只考虑了论文、期刊、学者等通用实体,大量的语义信息没有被挖掘出来,本质的科学问题缺少对于文献实体深度的定义和分析,本文通过定义文献中隐含的语义实体,使用Text CNN分类算法关联研究方法与论文实体,融合语义信息借助随机森林算法梳理其语义模式,构建多语义属性的实体模型,搭建基于语义信息的多维度知识图谱,为科研人员提供多维度的语义检索方式,帮助其快速理解文献深层内容。本文选取分析的文献领域为创业领域,该领域的研究从1980年左右兴起,并迅速进入研究高潮得到研究学者们的青睐,文献内容详实,领域特征明显且论文数量处于快速增长阶段,现有的通用实体类型已不能很好地满足对数据的多维度信息搜索。本文利用知识图谱技术,以创业领域中常见且重要的研究方法这一语义信息为例,构建概念实体,在实体识别的过程中,利用Text CNN实现对文本的分类和定位,并对这一实体在摘要中的语义模式进行标注和自动化提取,构建基于创业领域的语义知识图谱,为学者提供包含研究方法在内的多属性语义搜索服务。当学者搜索某一类研究方法时,通过语义信息定位包含该方法的论文,同时在论文中高亮出相关语句,帮助学者进一步详细了解论文信息,从而实现对检索内容的快速定位和理解。本文主要工作内容如下:(1)定义了创业领域论文知识图谱的数据模式,包含实体类别、属性和实体之间的关系。(2)在对研究方法的实体识别任务上,运用卷积神经网络Text CNN算法依据论文的摘要和题目来实现论文的自动分类,通过与其他分类算法的对比实验可知,本文选择的方法在准确率和召回率方面具有更好的效果。实现对论文中含有描述研究方法语句的自动化抽取任务。(4)通过知识存储与查询,设计并实现围绕创业领域的多语义信息文献检索系统。实验表明,本文运用论文研究方法的自动分类算法和语句抽取算法相较于其他传统算法在准确率和召回率方面具有较好的表现,为知识图谱的构建提供了较高的质量保障。同时,实现创业领域多语义信息的检索系统,不仅有助于科研人员快速查找相关文献,更有助于多角度的理解文献信息,使得在信息量暴增的今天,仍能充分挖掘数据的隐含信息,高效的利用和传播知识。"
1906,基于fastText的新闻文本分类研究及在农业新闻中的应用,"互联网的飞速发展使得数据大量且迅速地增长,其中大量数据是以文本形式存储的,文本分类作为最常见的文本挖掘技术对于在大量杂乱的文本数据中发现知识具有重要意义。目前文本分类的方法主要有基于语义规则的分类方法、基于传统机器学习的分类方法以及基于深度学习的分类方法三种方法。其中,fastText快速文本分类模型是最近提出的能够快速高效进行文本分类的浅层神经网络模型,它可以在取得和深度学习相当的分类效果的同时拥有比深度学习更低的训练成本,所以在工业界应用广泛。fastText通过n-gram进行特征增强来获取局部的词序信息,但是经过n-gram特征增强后会产生一些无意义的低频词,干扰文本分类的效果。同时,对于新闻文本的具体问题,新闻标题往往是一篇新闻的高度概括,在fastText模型中是将整篇文章的词向量进行累加取平均值作为一篇文章的向量表示,没有考虑到新闻标题在表示一篇文章时应占有更高的权重。所以,本文针对以上问题对fastText模型主要进行了“对重要词进行加权筛选”和“融合新闻标题”两种改进分别提出算法CF-fastText和算法Title-fastText,同时将这两种改进方法融合提出算法CFT-fastText并将其应用到系统中用于解决农业新闻文本分类问题。主要工作如下:1.fastText算法改进:第一、提出CF-fastText算法。在输入层根据TF-IDF-CF算法的思想,对进行过ngram特征增强的序列进行加权筛选,去除掉一些低频生僻和无意义的词。实验表明CFfastText算法对文本分类效果有所提高。第二、提出Title-fastText算法。在隐藏层中计算一篇文章的向量表示时融合新闻标题向量。考虑到新闻标题向量在表示一篇文章时占有更高的权重,Title-fastText算法将新闻标题向量与新闻正文词向量均值进行拼接来表示一篇新闻。实验表明TitlefastText算法能够更好地对新闻文本进行表示,相对于只使用正文向量均值的表示方法可以取得更好的分类效果。第三、将两种改进方法融合提出CFT-fastText算法。同时“对重要词进行加权筛选”和“融合新闻标题”,实验结果表明CFT-fastText算法可以获得较单一改进更好的分类效果。2.CFT-fastText在农业新闻自动分类系统中的应用实现农业新闻文本自动分类系统并将CFT-fastText算法应用在系统中。系统能够定时爬取网络上的相关农业新闻并存入数据库,后台的分类算法CFT-fastText可以将未分类文本进行分类,分类后系统将类别标记存入数据库,最终将分好类的新闻内容呈现在前端界面供用户浏览查看。"
1907,基于SVM的图像分类算法,"所谓图像分类,就是针对于一幅图像,在所给定的类别中,选出与该图像相匹配的类别作为输出的图像处理方法。图像分类属于图像处理领域的一个基本问题,是计算机视觉、机器学习与模式识别等领域非常活跃的研究方向,并具有多种实际应用。因此,研究具有较强的鲁棒性和较高精确度的图像分类算法有着重要的理论意义和实际意义。本文选择支持向量机(Support Vector Machine,SVM)作为图像分类中的分类器有以下原因:SVM是结构风险最小化模型,较好的解决了样本数量较小时的过拟合问题,有效提高了模型的泛化能力。在样本非线性可分的情况下,SVM将样本特征映射到高维,使样本在高维空间中线性可分,将难以求解的非线性问题转化为较易求解的线性问题。且SVM引入了核函数,可高效计算高维向量的内积,有效降低了模型复杂度。本文创新点如下:核函数的选取对SVM的泛化能力有着很大的影响。比较常用的核函数的选取方法是穷举法,该方法带有一定的随机性,并且依赖于模型的训练,效率较低。针对该问题,文献On Kernel-Target Alignment中提出了一种基于核目标对齐的核函数选取算法,核函数经常视为样本在特征空间中的相似性度量,核目标对齐以此为前提,本文证明了有些核函数并不满足相似性度量的三个性质,因此,有些核函数并不能视为样本在特征空间中的相似性度量。针对该问题,本文提出了一种基于特征距离的核函数选取算法,证明出相比于比核函数,特征距离更适合作为样本在特征空间中的相似性度量,解决了核目标对齐中所存在的问题,并且定义了一个全新的评估函数,与核目标对齐中的评估函数相比,该评估函数无需做归一化,计算复杂度较低。最终实验表明,通过基于特征距离的核函数选取算法选取核函数构造SVM,所得到的模型泛化能力很好。"
1908,基于情感分析的评分预测模型的建立与优化,"随着旅游业的快速发展,在网上预订旅游相关产品的人数越来越多,对有关景点的评价也在爆发式增长,景区评论数据不仅可以影响游客制定旅游计划,帮助景区管理人员扬长避短,吸引顾客,而且可以为旅游网站的个性化推荐系统提供数据。如何从大规模景区评论数据中精准、高效的获得需要的数据,将景区评论数据数字化,根据评论文本进行评分预测就显得尤为迫切。本文基于情感分析对景区评论评分数据进行研究,先介绍了评分预测的基本概念与流程,对数据进行获取,将景区评论评论数据进行分词以及去停用词等预处理之后,再分别使用三种不同方法对景区评论数据进行特征提取,发现合适的特征提取方法可以提高模型的预测效果。之后对数据进行5折交叉验证有效避免模型的过拟合现象,然后提出本文使用的评价指标,其中MSE用于模型调参、迭代过程的比较,RMSE用于不同模型的预测效果对比。具体介绍了评分预测模型用到的基本算法,强学习器LightGBM以及模型融合的主要方法。基于基本算法和LightGBM构建评分预测模型,并对预测结果进行分析比较,对常用的模型结合方法进行介绍,将这些预测模型进行Stacking融合,其中LightGBM模型作为Stacking的次级学习器,其他模型用作初级学习器,对结果进行分析发现评分结果得到了明显的提升。之后将一部分单模型使用平均法进行组合,作为Stacking融合的初级学习器,进行进一步融合,最后将融合模型用于景区评论的评分预测,发现评分预测模型的预测结果有一定的提高。"
1909,基于机器学习的运动目标识别与跟踪研究与设计,"基于机器学习的运动目标识别与跟踪是机器视觉和模式识别领域的热门研究内容之一。基于无人机视频的目标识别与跟踪系统作为一种具有预警、防范和主动监测功能的系统,能够有效解决人工处理过程中不及时、误判等实际问题。本文紧扣运动目标识别和跟踪的核心问题,从目标识别、目标跟踪以及识别与跟踪系统设计这三个方面进行研究。首先,针对目标识别过程中识别精度不高、速率较慢以及存在漏检的问题,研究了一种基于随机森林和支持向量机改进的目标识别算法,该算法针对单一特征影响识别精确度的问题,将颜色特征(Lab)与改进的方向梯度直方图(FHOG)特征融合,再根据随机森林得出目标感兴趣区域中心,然后通过LIBLINEAR分类器在感兴趣区域进行识别。实验结果表明,本文的识别器在行人识别中比传统支持向量机召回率提高了9.35%,漏检率降低了0.68%,速率达到2.70帧/秒。其次,为提高融合了梯度直方图特征和颜色特征的相关滤波算法(ECO-HC)的跟踪性能,研究了一种基于特征融合和自适应学习率改进的相关滤波算法。该算法依据梯度直方图特征和颜色特征各自的特性以及其对无人机行人跟踪性能的影响程度确定特征融合权重,同时采用自适应学习速率方法,使跟踪器能够自适应应对复杂的目标运动的问题。实验结果表明,本文的改进算法在平均距离精度和重叠率上比ECO-HC分别高出3.3%和2.6%,跟踪速度达到51.8帧/秒。最后,本文设计了一套目标识别与跟踪系统,利用识别器识别出首帧图像中的目标,使其作为跟踪器的输入进行后续跟踪,针对在跟踪过程中可能会出现新进入目标的情况,该系统采用间隔帧启动识别器的方法,通过数据关联算法进行多目标并行跟踪,同时利用卡尔曼滤波算法进行辅助监督跟踪,以此确保跟踪精度。通过自建无人机视频集对本系统进行实验验证,结果显示该系统具有稳健的性能和实时性。"
1910,基于LSTM的恶意URL检测研究,"随着通信技术的飞速发展,计算机技术与通信技术相结合而产生的互联网技术的发展以及全面普及。以网络作为应用的服务、信息的开放、信息资源与数据共享等服务日渐深入社会的各个角落,日益广泛应用于生活的点点滴滴之中。如今全球范围内爆发的信息革命、机器学习、神经网络迅速发展。但是,于此同时,网络安全问题的情况也已经开始逐渐的复杂起来。可以认为,网络信息的安全与否,对于个人的安全,个人隐私的保障、社会稳定的发展都是非常有必要关心、关注和研究的前提条件。人们的生活离不开网络,但是网络开放、共享同时安全,是人类更好的利用网络的必要条件。因此,网络的资源管理与网络应用的安全,网络信息的维护就都已经成为当前计算机领域科学研究的一个非常重大的课题。借鉴文本分类算法,利用到恶意URL识别上,将会很有利的增强web安全。机器学习算法的恶意URL识别技术相较基于规则的识别技术,识别范围更广、所需资源更少。或许机器学习算法的恶意URL识别技术将为web安全中的防守端带来全新的突破。文章介绍研究背景、现状、目的、意义。对当前恶意URL攻击与识别现状进行了分析,接着通过Doc2Vec算法、LSTM算法的启发,优缺点分析,提出了URL2Vec-LSTM-Attention神经网络架构用于识别恶意URL。最后通过实验,将我们的神经网络架构与未使用URL2Vec向量化算法,以及不具有注意力机制(或称Attention机制)的神经网络进行对比,结果显示,我们的URL2Vec-LSTM-Attention神经网络对恶意URL有更加好的识别率。"
1911,云中心网络流量分类方法研究,"近几年,随着云技术的高速发展,各大企业也都纷纷建立属于自己的数据云中心。在云中心的环境下,应用行为和应用流量的数据规模也在逐步增长,怎样从云中心的网络流量中挖掘出有价值的信息已成为各大企业追求的目标,同时,对云中心的网络流量进行分类也是实现云安全和云管理的关键。然而由于云环境下的网络流量数据规模大、应用种类繁多,利用传统的网络流量分类方法对云中心的流量进行分类,不仅无法确保分类准确率也无法满足实时性要求。如何兼顾网络流量分类的准确率和实时性是云中心网络流量分类的一个技术难点,对此论文给出了一种基于CDH(Cloudera’s Distribution Including Apache Hadoop)平台的网络流量分类方法和基于随机森林的网络流量分类方法。论文的主要工作及创新点如下:(1)针对校园网网络环境下的Internet流量分类要求,本文给出一种云环境下基于CDH平台的网络流量分类方法,构建了CDH大数据平台,通过网络协议数据分析工具抓取实际的网络流量,提出一种基于模式匹配的网络流量分类算法PM,然后利用大数据实时计算框架Spark Streaming对PM算法进行并行化,实现实时网络流量分类。与传统分类方法相比,该方法在流量分类效率和分类精度上都有所提升,所提出的模式匹配算法PM,不仅可以对离线的网络流量进行分类,还可以对实时的网络流量进行分类,为实现实时网络流量分类提供了思路。(2)针对Ceph云存储系统数据优化分布需要,给出一种基于流统计特征的存储节点之间流量分类方法,该方法利用wireshark抓包软件抓取Ceph云存储系统中实际节点之间的流量,并对抓取的流量进行流特征统计分析,选用包大小、包个数、流的持续时间三个组合特征,利用随机森林算法实现对网络流量的分类。实验结果表明,所选的组合特征结合随机森林算法能够很好的将Ceph云存储系统节点之间的流量进行分类。"
1912,机器学习在中国A股市场的量化策略研究,"国外量化金融领域历经几十年的发展已日趋成熟,现如今量化投资已成为主流的投资方式和研究内容之一,其在中国A股市场也得到越来越广泛的应用。近年来,在人工智能的浪潮下,各大金融机构不断将机器学习、数据挖掘等领域的技术方法应用到量化交易中,这种新的技术和方法在证券分析中也扮演着越来越重要的角色。在此背景下,本文选用多种区别于传统线性回归的机器学习分类算法,将股票选择问题视作分类问题,结合资产定价理论分析机器学习算法下多因子量化策的略表现,并依据各机器学习模型的预测结果作出评价。本文选用六大类共计35个因子指标搭建因子库,选取2004年5月至2018年12月A股市场全部上市公司的月度数据作为样本,在每个月末截面期,核算因子库中的因子作为特征数据,核算下个自然月的股票超额收益作为标签相关数据。分别使用随机梯度下降、支持向量机、朴素贝叶斯、随机森林、神经网络模型对训练集上的特征和标签数据进行学习和参数调优,利用参数调节后的模型构造多因子量化策略,并依据策略表现给出各模型的测试效果分析。通过分析基于各模型的行业中性策略预测表现,发现各机器学习模型在回撤区间内均能获得正的年化超额收益,但是各模型的回撤表现要劣于HS300指数,其中随机森林模型的预测表现最优,随机梯度下降模型的预测表现最差。与传统线性回归模型的比较分析表明,随机森林、神经网络和朴素贝叶斯模型的整体表现要优于线性回归模型,但是神经网络模型的回撤表现要劣于线性回归模型。本文认为更为依赖输入数据的机器学习模型对未来市场的变化更为敏感,当面对未知市场信息时,机器学习模型可能会失效,预测结果可能会与市场结果间存在较大偏离。"
1913,Flink下的K-Means优化并行与任务调度研究,"K-Means作为机器学习算法的典型代表,在大数据背景下的应用十分广泛,但其存在随机选取初始质心导致的局部最优解、大数据规模下迭代次数多、计算耗时长、准确率低等问题。在大数据背景下,基于大数据计算框架的机器学习算法优化与应用研究已成为研究热点问题,当前很多大数据计算框架都包含机器学习库,且随着实时搜索引擎、社交软件等应用的出现,数据实时处理日益成为学者们的研究热点,传统的先存储后计算的批量计算理念已经不再适用于实时流数据的处理,因此如何构造高吞吐、低延迟的大数据流式计算框架成为亟待解决的关键问题。基于上述存在的问题,本研究从基于Flink平台的K-Means算法的优化、并行化加速以及Flink平台的任务调度策略方面进行研究。具体研究内容可概括如下:(1)为解决大数据规模下K-Means存在选取质心导致的局部最优解、聚类速度慢的问题,提出一种Flink平台下的CK-Means聚类优化及并行策略。从算法优化层面,采用Canopy算法确定聚类数目k并选取初始质心;从并行化加速层面,基于Flink平台设计了一种面向CK-Means的并行加速策略,并分析不同并行度对计算耗时的影响。经试验,相较K-Means算法,CK-Means算法的准确率与迭代次数间的比值更高,算法性能更优;不同并行度下的CKMeans算法的聚类耗时呈现先下降后上升的趋势,其聚类耗时的最小值与数据集的大小相关。(2)为提高K-Means算法的聚类速度和准确率,提出了基于k-d树分区的K-Means并行化加速策略。从算法优化层面,选择数据集中相距最远的k个点优化初始质心;从任务并行化加速层面,提出k-d树分区算法对数据集进行划分并实现任务并行化;从执行环境并行化加速层面,设置不同进程数目与CPU核数验证F-KMeans的加速效果。(3)为了提高Flink计算框架的资源利用率,提出了基于Flink流式计算环境下资源感知任务调度策略。针对Flink平台下先来先服务任务调度算法忽略了任务资源需求与节点可用资源之间的关系,导致不同节点任务负载不均,从而影响系统吞吐量的问题,提出了基于Flink流式计算环境下资源感知任务调度策略。首先,以GlobalState模块监测的资源数据为依据,考虑任务资源需求与节点可用资源间的匹配关系,提出一种任务选择算法与节点选择算法选取待执行任务与最佳调度节点;其次,通过资源感知调度策略把待执行任务调度至最佳调度节点;最后,通过设计实验验证了算法的有效性。"
1914,基于机器学习的电商在线消费者购买行为预测研究,"近年来人们的日常消费方式发生了翻天覆地的变化。由于网络的普及,人们开始使用PC以及移动设备进行网上购物,该种方式突破了时间和地域的限制。线上商品种类繁多齐全且价格更为低廉,能够更好的满足消费者多样的需求。但海量的商品呈现给消费者的同时,也使得消费者需要花费大量的精力来挑选商品。越来越多商家为了更好的满足消费者的消费需要而对消费需求进行细化,研发满足消费者细化需求的网络购物平台并推向市场,使得网络零售市场竞争更为激烈。如何能够准确的了解消费者的消费需求,并对其提供更有针对性的垂直服务,是电商接下来的发展过程中,不得不思虑的重要一环。随着数据科技的不断进步,大数据成为近几年的新兴话题,在大数据存储计算水平上有了较大的提升,进而衍生出了区块链技术。消费者每一笔交易数据都被记录在了服务器中,进而可以通过机器学习以及各种智能计算方法分析消费者的在线行为以及交易数据等预测消费者未来的消费行为。本文采用阿里云天池大数据平台提供的来自淘宝购物平台的已经进行脱敏处理的真实数据,对消费者的行为进行统计挖掘,预测消费者会购买哪种商品。对消费者购买行为预测模型的提出分为四步:第一步是数据异常值的处理。对原始数据去除噪声、去除缺省值,并对消费者行为进行初步统计得出基本的分布情况,为进一步的特征选择和提取以及机器学习方法的选择进行准备工作。第二步是特征选取。从商品的维度构造出消费者特征、商品特征以及消费者-商品交互的行为特征三大特征群。将消费者行为按照发生的时间顺序进行连接作为交互行为序列,并通过各种变换来找到更符合数据特点的其它不同的特征组合,将其加入特征集合。而后,以正样本集大小作为参考,对负样本进行不放回的随机抽样;由于正样本在整体数据集中占比过低,将正样本全部入样。第三步对于统计过的行为数据进行筛选处理,原始数据中存在大部分操作行为过少的记录,在训练中将会影响模型的精度。该问题通过对消费者行为的定性分析来对数据进行筛选处理,删除有嫌疑冲动消费以及行为次数过少的记录,并对数据按照不同行为序列长度对数据进行分层处理。第四步是模型训练和预测。本文尝试应用循环神经网络算法(RNN)对消费者行为序列进行研究,利用N vs 1结构RNN来对行为序列行为倾向进行二分类,得出消费者行为倾向得分。而后将得分作为新的特征,将新的数据集利用朴素贝叶斯算法进行进一步的预测。将其结果和利用单一朴素贝叶斯算法建立模型所得结果进行比较。利用训练集对模型进行测试后的实验结果表明,使用RNN和贝叶斯融合后的模型预测效果更稳定,能够降低时序序列长度对预测准确度的影响;预测准确度相对单一朴素贝叶斯模型也有一定的提高,模型结果AUC值最优能够达到0.92。最后,本文提出了模型在电子商务实际交易场景中应用方向以及思路,并分析模型自身不足,对该课题进一步研究方向进行更为详细的讨论。"
1915,基于知识的战场数据样本标签匹配方法研究,"多军种的协同作战已成为了当今信息化作战的主要形式,面对复杂的作战体系,指挥员全面准确地理解战场态势是做出正确决策的基础,在态势评估工作中占据重要的地位。战场数据样本标签作为战场样本数据的提炼与概括,承载了战场样本数据的重要信息。因此,对战场数据样本标签匹配工作的研究在战场态势认知领域起到了愈发重要的作用。本文为实现标签匹配的目标,建立了一种战场数据样本标签框架,并赋予战场数据样本标签数值化定义,采用梯度提升树(GBDT)算法实现了战场数据样本的标签匹配。本文首先介绍了国内外学者在标签匹配和态势认知领域的主要工作和目前本体领域的研究进展,并阐述了机器学习中回归算法的基本原理和理论。然后,本文根据实际战场的特征和特点,设计了一种基于本体的态势知识库的设计框架,包括态势本体的构建和基于本体的态势知识库构建两部分。态势本体的构建过程包括对战场态势要素的抽象概念进行描述和确定构建本体的方法。基于本体的知识库构建过程包括确定态势概念的分类、对态势概念属性的阐释、加入兵棋推演规则以逻辑和产生式表示方法对态势规则库进行构建三个部分。同时,本文针对任务、资源、能力和战局四方面构建了四种势标签框架并详细解释其功能与含义。其中,任务势标签对作战任务信息进行定性描述,资源势标签与能力势标签对战场资源和作战能力进行定量描述,战局势标签对整体战场局势进行描述。进而,针对战场数据样本标签包含信息多、关联性强等特点,本文选取GBDT算法实现标签匹配过程。对于未知战场数据样本,首先进行初步的数据筛选,利用GBDT多元分类算法实现任务势标签的匹配;对于资源势标签与能力势标签,因为标签数据是连续的实数值,因此采用GBDT算法进行回归,得到匹配结果,通过人工添加战局势标签,完成四种态势标签的匹配工作,设计出战场数据样本标签的匹配模型。最后,本文根据上述方法和模型,利用兵棋推演平台数据进行了标签匹配的验证实验。对于任务和能力势标签分别计算标签匹配与实际标签结果的正确率和接近度,依据标签匹配结果自动添加知识库中的相似标签。最终,通过展示其对应的战场数据样本中的全部标签,证明本文提出的基于知识和GBDT算法的匹配模型具有可行性和实际使用价值。"
1916,移动CDR数据分析平台的实现与应用研究,"在移动电话用户趋于饱和的今天,国内各家运营商为提升竞争力和市场占有率,纷纷建设了大数据分析平台,用于挖掘用户数据,以期更好地了解用户行为,为用户提供更好更精确的服务。移动CDR数据中既包含移动电话用户的通话时长、通话频次等个体特征,又包含着移动电话用户之间的通话关系,是运营商进行数据分析和挖掘的重要数据源。并且,随着近年来社会网络分析方法在移动CDR数据上的广泛应用,移动电话用户之间的通话关系得到了充分的挖掘和利用。因此,建设一个能够综合分析移动电话用户的个体特征和移动电话用户之间的通话关系的移动CDR数据分析平台的时机已经成熟。首先,本文总结了电信大数据分析的发展概况,详细阐述了现有的大数据技术和大数据框架以及各个框架的适用场景,并对移动CDR数据分析的相关算法进行了归纳。其次,本文基于Spark框架设计并实现了一个移动CDR数据分析平台,并将社会网络分析方法引入移动CDR数据分析平台,从而使得该平台能够综合分析移动CDR数据中移动电话用户的个体特征和移动电话用户之间的关系。同时,为保证平台的灵活性与扩展性,本文将整个平台按照功能的不同分成数据采集、存储、分析和可视化四个层次,并分别进行了设计和具体实现。最后,本文利用设计并实现的移动CDR数据分析平台对实际的移动CDR数据进行了分析和挖掘,主要包括移动CDR数据的社区发现、社区画像和用户画像。进一步地,本文通过移动CDR数据分析平台提供的数据开放接口,将分析平台绘制的移动电话用户画像应用于商家号码推荐和电信诈骗号码识别等两个方面,进一步挖掘了移动CDR数据分析平台的深层次应用。"
1917,面向微博的短文本分类算法研究,"随着社交媒体的广泛兴起,微博等一系列应用产品火速发展。到2018年据微博官方统计其日活跃用户达到1.6亿以上,每日访问量达到百亿级别。如何从从这些数据中提取重要信息以及如何更快、更准确提供给消费者想要看到的东西成为了重中之重。本文以微博新闻数据为基础对中文短文本分类进行了两方面的研究。一是基于词向量的微博短文本分类,在词向量微博短文本分类上,基于k近邻算法(KNN),FastText,卷积神经网络(CNN)作为模型的选择,词向量的构建阶段已Word2vec为基础。二是基于特征扩展的微博短文本分类。在微博短文本特征扩展分类上,基于支持向量机(SVM),KNN进行模型构建,在特征扩展方面对主题模型、知识库、词向量进行扩展展开了研究,以及对词语的权重表示进行了研究。(1)本文在基于微博词向量分类方面,提出基于词语重要性的词向量文本生成模型(TFIWF-WES)。对KNN模型进行改进提出基于相似度的KNN算法(CS-KNN)。用CNN模型对微博短文本进行分类与传统的机器学习算法进行比较。(2)接下来,在微博短文本特征扩展分类上,提出了基于语义与相似度共同作用的特征扩展模型(SSE-BOW),为研究模型好坏,将其与基础模型和不同粒度文本扩展的短文本分类模型进行对比。(3)最后通过精确率(P)、召回率(R)、F1值(F1)等评价指标,对两个方面的研究分别进行对比实验,提出的SSE-BOW模型各评价指标分别为69.3%,69.1%,69.0%,与BOW模型对比提高了4.5%,5.7%,5.3%。提出的TFIWF-WES模型各评价指标分别为68.8%,68.4%,68.4%,与D-WES模型对比提高了2.7%,2.4%,2.5%。"
1918,基于深度学习的网站指纹攻击与防御技术研究和实现,"随着互联网技术的迅速发展,人们在享受便利网络服务的同时,也遭受着以隐私泄露为代表的各种网络安全问题。匿名网络通信技术通过隐匿通信双方的身份和关系可以有效的保护网络用户的个人隐私。但同时也存在恶意用户滥用匿名网络发布不良信息或从事违法犯罪活动,造成严重的社会危害。为了打击网络犯罪活动,保证网络监管的有效性,基于各种分类算法的网站指纹攻击技术应运而生。本文在分析以往网站指纹攻击和防御技术存在不足的基础上,提出了基于深度学习网站指纹攻击技术和基于对抗样本的网站指纹防御技术。提出了基于深度学习的网站指纹攻击技术。以往的网站指纹攻击模块使用传统机器学习算法进行分类,准确率依赖于特征选择的好坏,准确率存在上限且对抗网站指纹防御能力弱。本文提出的基于深度学习的攻击模型,通过其强大的特征学习和关系拟合能力,在当前最大的网站指纹数据集上实现了超过99%的分类准确率且能够很好的抵抗当前主流的网站指纹防御技术的防护。提出了基于对抗样本的网站指纹防御技术。以往的网站指纹防御技术不仅会导致网络带宽负载大幅度提高,而且无法抵御基于深度学习的网站指纹攻击。本文根据深度学习模型存在对抗样本攻击的弱点,提出了基于对抗样本的网站指纹防御方法,方法使用差分进化算法生成网站指纹对抗样本扰动策略,对网站指纹进行填充修改,不仅使传统的网站指纹攻击技术分类效果大幅度下降,而且使基于深度学习的网站指纹攻击技术分类准确率下降超过了61%。本文最后基于深度学习网站指纹攻击模型,结合实际应用场景,设计和实现了一个实时高效、交互友好的网站指纹攻击系统。"
1919,基于机器学习的drive-by download检测的研究,"互联网的不断发展,其中的安全问题也随着显现。Drive-by download攻击通过用户在访问含有针对其浏览器漏洞的利用代码的网页,分发恶意软件的下载并执行。自出现以来,Drive-bydownload攻击不断发展并且成为了恶意软件分发的主要途径。本文对国内外针对该攻击的检测技术进行了深入的研究,提出了基于AdaBoost-SVM算法的攻击检测方法,并设计实现了检测系统。本文的主要工作和创新点如下:通过对HTTP信息的统计,提出5个能够区分正常下载行为和Drive-by download行为的特征,能够克服已有研究对规避技术、重定向方式检测的不足。本文提出的5个新特征如下:下载经过站点数量、下载恶意文件数量、HTTP响应包含X-Powered-By字段次数、浏览器隐身次数、javascript混淆调用函数次数。基于重定向关系,通过HTTP请求中的referer字段、HTTP响应中的Location字段、响应实体中URL,提出获取可执行文件分发路径的方法。针对现有检测模型的缺陷,本文采用基于AdaBoost-SVM算法的Drive-by download检测方法。使用AdaBoost算法对分类过程进行等分,分为若干SVM弱分类器并对弱分类器进行迭代训练,生成强分类器。根据本文提出的特征使用本文采集到的数据集对分类器进行训练,并做了两次对照实验,采用控制变量的方法,证明本文提出的基于AdaBoost-SVM算法的检测模型能够有效检测而已下载行为,误报率与漏报率相较于传统机器学习算法分别下降1.1%、1.2%。设计并实现了 Drive-by download攻击检测系统,系统分为用户管理模块、数据包分析模块、攻击检测模块、数据存储模块、并实现了检测结果可视化。并且对系统主要的功能模块进行了测试工作。通过上述测试,系统整体功能已经全部实现。整个测试过程当中,充分发现了系统潜在的问题,并进行了及时的调优,整体测试结果达到预期。"
1920,基于区块链的用户信息增量学习方案研究,"随着互联网、物联网等科学技术的迅速发展,人类产生数据的速度急剧增长。大量的商业决策、生产活动都依赖于数据,通过一定的手段从这些数据当中挖掘出所需的信息是当今研究的热点课题。机器学习是利用数据价值的关键技术,通过对海量已知案例数据的学习,机器学习能够从中找出人类难以发现的规律,实现对未来的预测。但传统的用户信息价值发掘存在以下两个问题:其一是模型需求方需要具备存储、计算海量数据的能力及面临模型过时的风险,其二是用户无法控制个人数据价值的流转。在传统场景下,为了对用户数据进行价值发掘,企业或机构需要收集、存储、处理海量用户数据信息。这对模型需求方的计算存储能力提出了较高的要求,同时由于信息产生、更新的速度进一步加快,训练完成所得的模型无法有效整合新的增量数据信息,从而面临模型泛化能力逐渐下降的风险。针对传统用户信息发掘需要大量计算存储资源及模型容易过时的问题,我们提出了基于区块链的用户信息增量学习方案。原本需要依赖于企业中心化数据库完成的模型训练,利用区块链技术使得学习的过程可以在用户的本地设备当中进行,而增量学习算法可以保证模型的实时更新。方案利用区块链技术保证了模型的训练由网络中用户独立完成,使得企业或机构不必为存储、计算设备付出巨大成本,降低了用户信息价值发掘的门槛。方案为了实现对流式数据的在线学习,利用增量学习保证了模型可以实时整合新的增量数据所蕴含的信息,防止模型随着数据的产生而面临过时的风险。同时,方案保证了用户数据不会被模型训练方所采集,实现了对用户信息的隐私保护和个人数据的控制,而企业也可以在规避由用户数据泄露带来商业风险的前提下,获取用户信息当中的价值。对于数据生产者的用户而言,个人信息被大量采集使用,除了需要承受隐私数据被恶意利用的风险,其个人数据当中所蕴含的信息红利全部被企业或机构所获取,用户无法从中获得任何收益。针对用户无法控制个人数据价值流转的问题,同时保证将数据控制权归还给用户后,企业可以在不获取用户数据信息前提下完成模型训练的任务。本文给出了实现用户数据价值流通的方案。方案在区块链当中部署智能合约,在不引入权威第三方的前提下,保证了利用自有数据参与模型训练用户的权益,激励用户加入区块链网络中提供个人数据信息完成对模型的更新、传递。用户可以自主选择是否参与模型的训练,实现了用户数据价值的流通。文章最后对所做工作进行了总结,并对方案面临的一些问题进行了分析,为未来的研究方向提供了若干思路。"
1921,基于LSTM的脑电特征学习及癫痫发作预测系统研究,"全球约有癫痫患者5000万人,在我国大约有1000万人,癫痫发作是脑皮质中异常过度的神经元自发、同步放电导致的,持续发作的癫痫可能会造成患者的永久性损伤,甚至死亡。癫痫的发作具有突发性和反复性,严重影响了患者的正常工作和生活。因此,有效的癫痫发作预测能够减缓癫痫患者的痛苦,进一步保证癫痫患者的生命安全。在预测癫痫发作的基础上,还可以应用各种干预方法(例如通过递送短效抗癫痫药物或通过施加电刺激)抑制癫痫发作。目前,癫痫发作自动预测已经成为癫痫研究领域的热点。但是,用于识别癫痫发作前期的脑电特征学习是发作预测技术的瓶颈。本文利用深度学习来自动学习用于发作预测的脑电特征,有效地实现了癫痫发作预测。本文提出了基于双向LSTM的癫痫发作预测方法,首先将每个患者不同导联的脑电图(EEG)拼接滤波,同时提取描述脑电信号波形的多种线性特征,然后构建用于癫痫发作间期和发作前期的深度双向LSTM网络,并将特征向量送入该双向LSTM网络中针对癫痫发作前期和发作间期进行特征学习,经过网络的正反脑电数据处理最终实现发作间期和发作前期的脑电分类;最后通过一定规则的后处理实现结果的优化,提高了预测的正确率。本文在9例颞叶癫痫患者的临床脑电数据上,通过SOP、SPH、灵敏度、误报率、平均预测时间等性能指标对所构建的深层双向LSTM网络进行性能评估。实验中,总共发作次数为29次,预测正确为24次,平均误报率为0.17/h,从而证明了基于双向LSTM的脑电特征学习的癫痫发作预测系统有着较好的预测性能。对于平均预测时间,有一半以上的患者具有较长的预测时间,平均预测时间为35.47min,能够在癫痫发作之前为患者提供充足的治疗和心理准备。在颞叶癫痫患者的基础上,今后的工作会对其他病灶区患者进行实验,更加充分地完善预测系统。"
1922,智适应学习平台的研发及分类算法的应用与验证,"随着深度学习技术的飞速发展,互联网+教育和人工智能+教育的理念受到越来越多人们的关注,大量成熟的机器学习与深度学习算法被应用到教育领域。线下教育很难真正做到因材施教,教育大数据及人工智能智适应学习引擎应运而生,这类新技术可以模拟特级教师给学员一对一量身定做教育方案,一对一实施教育过程,大幅提升学习效率,实现教育教学的“私人订制”化。本论文为搭建智适应教育教学平台开发了一套软件系统,该系统能获取学员的学习数据,分析学员的学习水平,生成学习报告,初步实现了针对不同水平的学员,推送不同程度的学习素材,规划不同的学习轨迹,进而为后期教育教学大数据和智能推荐算法的研发提供了依据。论文的主要工作如下:1.详细分析了现有的学习平台的特点,结合实际的应用对象和场景,设计了智适应学习系统软件的功能模块和架构。2.以阿里云Centos系统为开发平台,结合多线程技术、线程池技术,采用MySQL数据库存储数据,利用python和javascript实现前后端的连接,平台以在线网站的形式呈现给用户。3.平台以React框架为基础,结合Javascript、CSS、HTML等技术,采用组件的核心编程思想简化了代码数量并提高了开发效率,实现了前端的页面和基本功能。4.本文提出了新的 TF-IDF(term frequency-inverse document frequency,词频-逆文档率)文本特征提取算法,在原算法的基础上加入特征词意义与特征词的分布,改进算法的文本特征提取效果较原算法有明显的提升,并把新算法运用于平台中,实现了平台的推荐功能和文本分类功能。"
1923,众包市场中面向供求双方的定价机制研究,"随着互联网的迅猛发展,外包模式与互联网相结合,产生了一种颠覆性的劳动协作模式――众包模式。在众包市场的环境下,如何制定一个“合适”的价格来招募工人以合理的质量和成本来完成给定任务是制约该模式发展的一个关键性问题。对于当前众包市场中存在两种典型的定价模式,即以平台(求方)为中心(SAT)和以用户(供方)为中心(WST)的定价,现有的定价方法主要存在以下问题:未考虑当前定价与历史交易间的联系;缺少标准数据集而导致数据量少、纬度少、机制不完整和定价误差大等问题;模型简单、模型不统一、不符合实际众包情境的问题。为此,本文开展了以下研究工作。面向SAT模式,采用数据挖掘的一般步骤进行研究,通过Python爬虫获取实际众包平台的数据并处理为标准数据集。在此基础上,提出一种基于随机森林和文本聚类方法的众包正向定价机制。实验表明,随机森林比其他机器学习方法具有更好的基础定价效果,调参优化后能够达到其最优性能,且加入文本聚类可以提取任务间更细粒度的特征表达,从而进一步提高定价精度。面向WST模式,提出一种基于VCG拍卖和质量全支付的协作众包逆向定价机制,综合分析了线上众包场景,并结合经济学相关理论(逆向拍卖、全支付拍卖、激励相容性等)设计了一种通用模型及对应定价算法,通过仿真实验证明了该机制可以达到较高的算法效率、更高的任务完成质量、合理均衡雇主和工人的收益以及确保工人投标真实性的效果。"
1924,基于XGBoost和BP神经网络的会员流失预测及内容推荐方法的研究,"随着社会经济发展,各类组织或企业越来越重视客户关系管理,而会员是对组织具有高粘度和做出较大利润贡献的客户群体,但出于种种原因的会员客户流失现象对组织或企业的运营有较大的影响。借助组织存储的会员资料和会员行为数据,利用数据挖掘方法预测潜在的流失会员,并通过协同过滤算法提前向其推荐特定的产品和服务来挽留会员,这对于组织或企业长期稳定的发展至关重要。本文的主要研究内容就是利用一个在线音乐网站KKBox的会员信息,使用XGBoost(Extreme Gradient Boosting)算法和BP(error Backpropagation,简称BP)神经网络算法设计了一个组合模型,用组合模型来对KKBox会员流失进行预测。之后,利用协同过滤算法对预测出的潜在流失会员进行内容推荐,从而达到挽留会员的目的。本文主要的研究内容由以下三部分组成:第一部分,首先对下载的原始数据进行建模前的各项准备,包括数据清理、数据整合、数据筛选、数据变换以及数据归一化等工作,为接下来的模型搭建打下基础。接着在前人关于客户流失预测方法研究的基础上,通过分析与对比,研究不同算法模型的优缺点。第二部分,利用XGBoost算法和BP神经网络算法,设计了一种新的组合模型,并对该组合模型进行构建与优化,通过调整两个单一模型在组合模型中的占比,找出准确度最高的组合模型,最终实验结果表明该模型不仅在准确度上比单一模型更优异,而且在拟合度方面也有很大的提高。接下来运用该组合模型对未知数据进行预测。第三部分,对预测结果为流失的会员,根据流失会员的历史信息,运用一种基于协同过滤的算法,找出与流失会员最相似的未流失会员,将未流失会员所喜欢而流失会员尚未关注的音乐内容推荐给该流失会员。可以在一定程度上防止会员流失。"
1925,基于深度学习的英文关系体抽取,"关系体抽取,即实体关系抽取,常用于问答系统和知识图谱构建等应用,是信息抽取领域中基础且重要的环节。本文主要讲述了结合ResNet、RNN以及Attention机制去完成关系体抽取任务。就目前而言,很多有效的实验普遍仅使用CNN作为encoder,经过多层卷积操作后,对池化的结果进行softmax分类。而本文使用RNN,并结合Attention机制对最后的结果做分类。在这个任务上很少有人将两者结合起来去做关系体抽取任务。本文模型用RNN结合Attention对卷积后的结果进行处理,而不是使用卷积神经网络的最大池化。此模型提高了使用深层CNN在远程监督的关系体抽取任务上的表现。有论文指出在完全监督的数据集Sem Eval-task8上使用RNN接卷积操作是有效果的,而在远程监督的数据集上受大量噪声影响,模型的效果并不尽人意。在本文实验中,结合ResNet残差块的特性,将残差块和RNN以及A ttention机制同时用于远程监督的关系体抽取当中去。最终,在NYT-Freebase数据集上获得的表现比使用单一模型ResNet的更要好。本文主要的贡献如下:(1)在弱监督关系体抽取考虑使用复合模型,结合ResNet和RNN去对数据中的噪声进行处理。(2)使用复合模型相比使用单一模型取得了更好的实验表现最终结果和PCNN+ATT齐平。(3)本文提出结合ResNet和RNN以及Attention机制的模型可以很轻易的迁移应用到其他NLP任务中。"
1926,基于百科和垂直网站的景点属性关系抽取研究,"随着信息技术的更新迭代,互联网的信息量正以指数级速度增长,面对日益增多的文本数据,如何从其中提取出用户感兴趣的信息已经成为近几年研究的重点,信息抽取技术应运而生。属性抽取技术作为信息抽取技术的一个子领域,也是构建知识图谱必不可少的一部分。属性抽取是将非结构化数据转化为结构化数据的一种途径,属性抽取技术日趋成熟,但针对特定领域属性抽取算法性能仍有提升空间。本文主要针对内蒙古旅游领域文本做属性抽取工作,旨在能够发现特定领域中实体和属性值之间的关系,并将抽取结果转化为供后续研究的结构化数据。本文的重点研究内容如下:(1)构建内蒙古旅游领域语料库。使用Scrapy爬虫框架,获取百科类网站和垂直网站的入口URL,对文本数据进行爬取。配置Brat工具对爬取的语料进行人工标注,将其转换为BIO标注模式。(2)确定旅游领域语料中需要抽取的属性。将属性抽取的任务转化为序列标注任务,分别构建基于CRF和神经网络两种模型。(3)提出基于篇章级架构的神经网络模型。该模型利用BLSTM捕获文本的上下文信息和时序信息,利用CRF输出最优标签序列。训练每篇文档的文档级向量,并通过实验验证模型架构的可行性。(4)研究不同粒度的训练语料及添加不同特征对模型性能的影响。分为字符级和词级两种粒度。在字符级模型中添加偏旁部首特征和文档级向量,在词级模型中添加词性、字符级和文档级向量,旨在寻找标注效果最好的模型。"
1927,基于HowNet和用户点赞的中文电影评论情感分析研究,"近年来,随着网络的普及,越来越多的人在观看电影之后,喜欢在电影平台上对观看过的电影发表评论。这些评论能表达出观影者对电影的喜恶,直接影响未观影者对该电影的第一印象,从而影响电影的票房。因此分析电影评论中的情感很有意义。目前,电影评论的情感分析主要分为三类:基于情感词典的方法,基于机器学习的方法和二者相结合的方法。基于情感词典的情感分析法的优势在于分析速度快,劣势在于无法准确的判断数据集中有褒词贬用或贬词褒用的评论数据。并且,当使用情感词典和情感公式计算情感倾向时,会忽略了很多的否定词、程度副词和情感词。基于有监督学习的情感分析方法准确率较高,但需要付出很高的人工标注代价。而无监督学习的方法虽然不需要标注类别信息,但是由于中文文本的复杂性,所以情感分析的准确率比较差。因此,本文针对以上问题,结合二者优势,提出了一种结合HowNet情感词典和用户点赞的方法对豆瓣电影评论进行情感分析。通过互信息算法构建电影领域词典并引入了用户点赞对电影评论的影响,使用支持向量机和逻辑回归和朴素贝叶斯训练数据并做了举例对比,通过引入多个评论数据集对该方法进行验证,达到了比传统基于情感词典方法更好的分类效果。"
1928,基于多维特征与深度学习的虚假评论识别研究,"随着电子商务的快速发展,越来越多的消费者开始倾向于网上购买商品,并对商品进行评论。为了做出正确的购买决定,消费者不仅会看商家给出的商品信息,还会阅读大量有关商品的评论。然而,商家为了自身利益,往往雇佣专业写手为自己撰写虚假好评,吸引潜在消费者购买商品,为竞争对手撰写虚假差评,打压竞争对手。这不仅误导消费者做出错误的购买决定,也不利于电商平台的稳定发展。因此,亟需有效的方法来检测虚假评论。本文基于评论内容和评论者行为人工提取了多维特征,使用传统机器学习方法建立模型来识别虚假评论。此外,采用深度学习的方法提取了深层语义特征,与多维特征结合,构建了DF-HAN模型来检测虚假评论。本文主要的研究内容如下:(1)构建了五种特征指标。通过分析评论的内容提取了N-gram特征、词汇特征、可读性特征和主题特征四类文本特征;通过分析评论者的行为提取了行为类特征。针对行为特征和四类文本特征构建了五种特征指标。(2)构建了使用传统方法识别虚假评论的模型。将提出的五种特征指标整合,使用LR、SVM、RF三种分类器构建模型。最后分类的F1值为87.37%,验证了该模型的有效性。(3)构建了使用深度学习方法识别虚假评论的模型DF-HAN。该模型采用LSTM和双向GRU挖掘深层次的语义特征,采用CNN处理本文提取的传统离散特征,该特征是多维的。然后将语义特征与传统特征连接,建立DF-HAN模型。与HAN模型85.99%的准确率相比,DF-HAN模型获得了更高的准确率91.76%,验证了本文提出的模型的有效性。"
1929,电商网红社交行为商业影响的分析与预测,"电商网红是指使用电商平台进行经营活动,并且借助社交平台开展营销活动的“网络红人”。基于电商网红的商业模式的经济规模在2016年已经达到了 580亿,超过了当年的中国电影票房。发现和研究电商网红在社交平台上的典型行为模式,挖掘电商平台与社交平台的潜在联系,以深入理解这种新的跨平台的经济现象,从而有助于评估电商网红自身的商业价值、改进社交营销方式。目前,对电商网红的研究仍停留在商业案例和定性概念层面讨论上,缺乏基于规模化的实际网络测量的量化分析。为此,本文以新浪微博和淘宝电商平台为具体测量对象,进行了跨平台地测量和数据融合,建立了电商网红原始数据集;基于该数据集,分析了电商网红在社交平台和电子商务平台上的社交商业行为和经营活动,建立电商网红商业价值模型,评估和预测电商网红社交行为商业价值。本文的工作主要有如下几个方面:(1)编写网络爬虫对微博和淘宝平台进行测量,形成电商网红社交平台数据集和相应电商平台销量数据集。该数据集包括108位网红在微博平台共8年零4个月的社交数据及其2018年4月的淘宝销量数据,和被网红点赞和转发过的46470位微博用户的基本信息数据。(2)首次构建了刻画网红营销行为的特征工程。基于电商网红社交数据集提取并分析了电商网红的三种典型营销行为,包括广告行为、促销行为和口碑营销行为。挖掘三种行为的统计规律,基于行为分析构建了电商网红营销行为特征35个、日常行为特征4个,提取了基本信息特征两个,共计41个社交特征。(3)首次构建了基于社交特征的电商网红销量水平评估模型。在上述特征工程的基础上,使用随机森林、逻辑回归、kNN等分类算法,构建电商网红销量模型,发现了最能影响电商网红销量的10个特征;实验表明,模型最高精确率可达0.83。"
1930,基于机器学习的用户恶意评论检测研究,"随着移动互联网的普及,人们可以随时随地在网络中发表自己的观点。一方面媒体公司需要用户积极参与评论,另一方面在众多评论中也混杂着恶意评论。这些评论不仅在精神上伤害了他人,而且也使得整个网络环境变得混乱不堪。更重要的是,受攻击者会逐渐使用其他产品,不利于公司的发展。公司管理者需要过滤出现的恶意评论,但是小公司无法承受人工检测的成本。因此,需要设计一个恶意评论自动检测方案。针对这些问题,本文提出一种基于机器学习的网络恶意评论检测方案。具体包括:首先,运用中国汉语言学对“詈语”的研究,从中挑选40个种子字,在此基础上通过扩展算法得到一份恶意词典。相比人工选取种子词,这样极大的节省人工的成本。另外,该词典也可作为中文分词器的自定义词典,用以提升分词准确率。其次,以用户为维度,分析每个用户下历史评论所在的新闻主题,使用LDA模型提取新闻内容的主题,以“用户id”、“用户评论”、“评论所属新闻内容”作为RNN模型的输入。实验表明本文改进模型提升对恶意评论的检测效果。最后,将前两章的实验结果与传统检测系统所选取的特征相结合。从数据集中提取13类特征,计算皮尔森相关系数并分析特征,最后将特征作为决策树和SVM的输入。实验结果表明,决策树算法实现效果最优,分类结果F1值达92.87%。所以本文的研究可以帮助管理人员检测网络中出现的恶意评论。"
1931,基于抗混淆技术的JavaScript恶意代码检测模型研究,"JavaScript是交互式网站开发广泛使用的一种技术,但由于其代码不进行预编译而直接被用户浏览器解释的特性,恶意的JavaScript容易被当作一种基于网页的攻击手段。而且为了逃避传统的基于静态特征匹配的检测系统的捕获,攻击者往往将恶意的JavaScript代码进行混淆操作,所以如何有效准确地识别出混淆恶意的JavaScript代码变得尤为重要。本文利用信息论测度知识来检测JavaScript混淆代码,可以捕获基于统计特征检测器的逃逸攻击,并对混淆代码进行反混淆,最后利用机器学习知识来检测JavaScript恶意代码。具体工作如下:1.通过对JavaScript代码语法分析,改进了基于统计特征的JavaScript混淆代码检测模型。改进后的模型对JavaScript代码进行N-gram分词并计算相应对象的频率,然后计算信息论测度值,最后通过One-class SVM单分类器进行分类。实验表明,改进的方法达到了更好的检测效果,并且验证了 Bigram分词比Unigram分词达到的效果更好。2.通过对基于统计特征的JavaScript代码检测模型的分析,构造了针对该模型的逃逸攻击,并提出了基于统计特征和混淆特征的JavaScript混淆代码检测模型。该模型将提取的JavaScript代码的混淆特征与统计特征相结合来捕获逃逸攻击。实验表明,该检测模型可以准确捕获构造的逃逸攻击。3.提出了一种基于多类特征的JavaScript恶意代码检测方案。该方案通过提取基本特征、动态执行特征、攻击特征和字符分割特征四个维度的恶意特征,利用机器学习方法检测JavaScript恶意代码。通过对比实验,验证了该方案的有效性以及非冗余性。"
1932,基于迁移学习的文本分类方法的研究,"随移动互联技术飞速发展,文本类信息爆发式增长,促进基于文本信息的信息安全研究快速发展,包括在邮件过滤、网络安全事件追踪、网络舆情分析等方面广泛应用。时间推移、数据采集条件变化等因素导致数据分布不断变化,致使以“训练/测试数据拥有共同特征空间和相同数据分布”为假设的传统机器学习在现实场景中受严重限制。迁移学习通过对数据、模型等进行适当处理,保证模型在上述情况下的训练效果,从而能更好解决实际信息安全应用中的文本分类任务。本文重点研究异构迁移技术如何挖掘异构领域之间的相关知识,从而更深入地促进目标领域文本分类任务的学习。首先,本文提出基于语义相关性的特征空间构造方法。利用word2vec建立两域特征词汇的向量,以向量间的余弦值表征特征相似性,提取两域相同特征词汇及相似性高于预设阈值的特征对,共同构成两域同构特征空间;经实验验证,该方法取得的分类准确率较未引入语义相似特征的方法平均提升3个百分点。接着,本文提出局部保留分段式异构投影算法。传统线性判别分析投影算法投影后,特征维度降为(分类类别数-1),应用到文本领域会导致大量有用信息丢失,通过分段式投影,使投影后的特征维度可控,更适用于特征空间高维的文本领域;引入局部保留投影算法,解决投影中对样本间局部结构信息破坏的问题;对目标域已标注样本作加权处理,平衡两域样本比例差异过大的问题;经实验验证,该方法在所选两个数据集上取得的分类准确率,较传统机器学习方法平均提高近10个和7个百分点。最后,本文将前两点结合,通过连接互联网的API拓宽目标域中训练数据的来源,设计并实现了应用于实际场景的基于异构迁移学习的文本分类系统。"
1933,iOS应用程序漏洞和恶意行为检测的研究,"随着移动互联网的不断发展,移动智能设备在人们的日常工作和生活中占据着举足轻重的地位,越来越多的用户使用移动智能设备存储个人隐私信息。为保护用户隐私信息,应用程序首先需确保自身的安全性,已有iOS平台安全性检测内容少之又少,无法为应用程序提供全面的安全性评估。其次,应用商店在审核应用程序过程中需确保恶意应用程序的检出率,现有iOS恶意应用程序检测算法存在准确率低、速度慢的缺陷,为快速检测大量iOS应用程序的恶意性带来挑战。本文针对现有工作的局限性,主要工作分为iOS应用程序安全性检测和iOS恶意应用程序检测两个方面,具体成果有:1)提出了多项iOS应用程序静态安全性检测内容,对新增检测内容进行了自动化检测实现。详细分析了iOS应用程序面临的静态安全性风险,结合iOS应用程序特点,对面临的风险提出了检测方案并进行了自动化检测实现,完善了已有iOS应用程序静态安全性检测内容。2)提出了iOS应用程序动态安全性检测内容,对检测内容设计了检测方案。本文通过分析iOS应用程序运行过程中面临的安全性风险,提出了iOS应用程序动态安全性检测内容并设计了检测方案。在应用程序完成动静态安全性检测后,还提出了应用程序安全性评估评分机制,对应用程序的安全性程度进行打分。3)提出将iOS应用程序权限使用情况作为iOS恶意应用程序检测特征,并通过对比实验,论证新加入的特征可以提高静态检测模块的检测结果。其次,本文还提出了动静态相结合的iOS恶意应用程序检测算法,利用静态检测模块对待测应用程序进行初筛,大幅减少动态检测模块待测应用程序个数,加快了 iOS恶意应用程序检测速度。"
1934,基于动态分析的安卓恶意软件种族分类研究,"随着安卓系统的普及,安卓恶意软件急剧增加,严重威胁了安卓用户的信息安全。恶意软件会盗取用户的敏感信息,甚至恶意扣费、盗刷资金,造成严重的经济损失,因此亟需研究恶意软件检测技术。恶意软件种族分类可以对样本进行系统性管理,根据已有恶意种族信息可初步判定新增恶意软件所属种族,确认其攻击目的、恶意行为等。恶意软件种族分类是当前恶意软件检测领域的研究热点,本文主要基于动态分析研究恶意软件种族分类问题。本文针对基于动态分析的恶意软件种族分类中存在的动态分析APK成功率低、分类粒度大、分类准确率低等问题进行研究,提出了新的动态分析方案及种族分类模型。具体研究成果有:1)针对现有动态分析方案中恶意软件动态运行成功率低的问题,结合Androguard、MonkeyRunner等工具,改进包名提取、压力测试等环节,优化动态分析方案,根据恶意事件集设计恶意行为触发器。利用Drebin数据集测试改进前后的动态分析方案,实验结果表明改进后的动态分析方案能大幅提高APK执行成功率。2)在优化后的动态分析方法的基础上,针对分类粒度大的问题,细化分类粒度,结合SVM算法和DBSCAN算法,提出了针对小样本的安卓恶意软件种族分类算法。实验部分根据各种族样本数量分为粗粒度(L)、中粒度(M)和细粒度(S)三个分类粒度,分类准确率分别为81%(L)、75%(M)、59%(S)。3)针对大样本种族分类准确率低的问题,通过融合两类动态特征构造分类特征,一类是由CPU、内存等资源消耗构建的特征,另一类是结合状态序列数据和马尔科夫链思想构建的特征。利用目前流行的多种机器学习分类算法进行验证,结果表明通过结合两类动态特征能更好地反映恶意行为,极大地提高了大样本种族分类的准确率。"
1935,基于Spark和N-gram的HTTP流量检测平台的设计与实现,"近年来,互联网技术的普及,给人们的工作和生活带来了极大的便利。然而,伴随着互联网的发展,网络安全事件也频频爆发,危害着互联网用户的隐私和财产安全。使用机器学习模型对HTTP网络传输流量进行安全检测可以有效识别攻击行为,保障用户的隐私和财产安全。然而,基于机器学习模型的流量检测方法也面临着流量特征提取困难、难以检测未知攻击和难以检测大规模网络流量数据等问题。本文通过对基于机器学习模型的流量检测方法中存在的问题进行研究,提出了基于增加了字符标志位的N-gram和Word2vec相结合的流量特征提取方法,该方法可以有效的对流量数据进行特征提取,解决了流量特征提取困难的问题。本文设计了基于向量空间距离的相似攻击聚类算法,将该算法应用于实际流量聚类,通过对聚类结果的人工分析,验证了该算法的有效性,解决了基于机器学习模型的流量检测方法中难以检测未知攻击方式的问题。结合以上的特征提取方法和聚类算法,本文设计并实现了HTTP流量检测平台。通过该平台的实际环境搭建、平台部署和平台功能测试,验证了平台的准确性和有效性。"
1936,基于局部近似秩的地海路径规划及导航技术,"导航技术在地海交通路线规划中有着广泛的应用,是合理规划行动路径节约行动成本必不可少的技术。但以往的导航技术存在着各种各样的问题,如决策依据信息估计不准确、更新不及时等,而且以往的路线规划方法往往利用静态信息作为导航决策的依据不能适应动态变化的环境。本文为解决以往技术的局限做了以下三方面的工作:1.提出了一种基于局部近似秩的路径规划及导航的统一模型。本文针对以往导航技术的局限之处,提出了基于局部近似秩的地海路径规划及导航技术的统一模型,利用机器学习技术提高了决策信息估计的准确性和实时性提升了动态环境中的路径规划效果,其中基于局部近似秩特征表示的方法能够高效的利用数据中的潜在空间结构,基于时空立方体的路线规划方法解决了在动态变化环境中的路线规划问题。2.将统一模型应用于陆路交通预测与导航并用真实数据进行验证。本文将提出的统一模型应用于陆路交通规划和导航中使用真实的交通轨迹数据验证了模型的有效性。使用基于局部近似秩的特征表达进行动态变化环境信息的预测并使用代价时空立方体进行路径规划,最终实验结果表明在路线长度变化不明显的前提下达到了路程耗时更少的效果。3.将统一模型应用于极地海冰预测与导航并构建真实导航系统服务于“雪龙”船。本文将提出的统一模型应用于极地海冰预测与导航中,并完成了名为“基于不充分信息机器学习技术的海冰现报与雪龙船航线指导系统”的实用系统,实际服务于“雪龙”船的多次极地科考,为极地科考船只提供了便捷的、科学的、可靠的、安全的航线指导服务。"
1937,基于多分类器融合的高光谱遥感图像分类,"高光谱遥感图像分类一直是遥感领域的热门研究方向,高光谱遥感在一定的波段范围内对目标区域进行连续成像,其影像包含了丰富的空间信息与光谱信息,可以有效的用于地物的分类与识别。高光谱遥感图像数据量大,波段数目众多、像元特征维度高等特点,给像元分类带来充分条件的同时,也带来了信息冗余增多,信噪比降低,分类效率难以提升等问题。若只使用光谱信息而忽略空间信息,也会导致像元的特征表达性不足的问题。针对高光谱遥感图像像元分类的以上问题,本文主要工作概述如下:数据预处理方面,首先,本文采用GBDT的特征重要性对原始图像数据进行波段选择,有效地去除了大量的冗余波段,提升了分类效率。其次,本文结合高光谱图像的特点,将相关系数融入双边滤波算法中对图像进行滤波,在不影响图像纹理的情况下,取得了很好的去噪效果,并使各类别地物特征更加集中,有效提高了分类精度。特征提取方面,本文对LPP降维算法做出了改进,使降维过程同时利用了高光谱遥感图像的空间维信息与类别先验知识,并取得了比使用PCA,LDA降维后更好的分类效果。本文还定义了一种提取高光谱遥感图像纹理信息的LBP算子,有效地提取高光谱遥感图像的空间维特征。模型选择与优化方面,本文采用了在分类任务中精度与效率都有优势的LightGBM模型作为研究过程中的基本分类模型,最后采用Stacking融合策略,将RBF_SVM、LightGBM和Random Forest三个分类模型通过Logistic Regression进行模型融合,取得了比单模型更好的分类效果。"
1938,基于数据流的风机故障实时监测系统开发研究,"近些年来随着环境保护理念不断地深入人心,以风力发电为代表的清洁能源在人类能源消耗中占据了越来越大的比重。为了提高风力发电的效率,风力发电机组往往被安装在远离市区较为偏僻的远郊地区,这就造成了风电机组故障发现迟缓以及故障维护困难的问题。风电机组的稳定运行对提高发电企业经济效益和社会效益具有重要的意义。现阶段风电机组故障相关研究大都是基于离线数据通过SAS、Matlab等分析软件完成,无法满足工业现场故障实时监控的需求。本文在阅读了大量风机故障诊断和数据流处理技术相关文献的基础上,针对上述问题提出了一整套风机故障实时监测系统的解决方案。基于Flink和Kafka搭建数据流处理平台,并在该平台的基础上结合风机振动信号的特点和机器学习算法开发出相应的算子,来实现风电机组运行状态的实时监测。首先根据风电机组原始振动信号的特点,实现了一种基于振动信号波形特征的故障预警方式。为了衡量波形特征的相似性,引入了相似性距离(SBD)这种新的距离测量方式,并结合机器学习分类算法实现了对风电机组正常运行状态和故障状态的有效识别。为了进一步分析风电机组故障的类型和故障的程度,结合数据流的特点对传统的经验模态分解方法进行改进,实现了一种基于滑动窗口的在线经验模态分解方法(SWEMD)。在此基础上通过希尔伯特变换提取了振动信号分量的频率特征和能量特征,然后结合随机森林算法和振动信号的频率特征实现了对风电机组故障类型的诊断,并对振动信号的能量特征进行回归分析实现了对风电机组的健康程度评估。最后本文介绍了平台搭建和部署的过程,并对整个系统进行了功能上和性能上的测试,验证了系统的有效性。这对实际工程应用中风电机组的故障实时监控具有很大的参考价值。"
1939,基于医学知识库扩展的深度医疗检索模型研究,"现有研究表明,在临床上查阅大量相关医学文献可以有效帮助医生做出更准确的判断,减少失误发生,从而为病人提供最佳的治疗。但是由于网络上存在的生物医学文献数量太多,如何迅速有效地获取最相关文献是一个亟需解决的问题。另一方面,临床医生所掌握的知识和方法的更新速度无法与当前飞速增长的最新医学理念和技术同步,知识的滞后在临床上可能会导致巨大的损失,科学使用医学检索可以帮助临床医生及时了解其所在领域最新的医学知识。医学检索的目的是从己发表的海量生物医学文献中快速有效找到对当前临床案例有帮助的信息,从而减少可能出现的临床差错,提高临床质量,辅助医生做出临床决策支持,为患者提供更好的治疗方案。本文的主要任务是以给定的电子病历(Electronic Medical Record,EMR)作为查询,从海量生物医学文档集中检索出最相关的文档,从而为当前病历提供文献支持,帮助临床工作者做出临床决策。但医学检索有其特殊性,在应用以往的检索模型时效果不够理想,主要是由于以下原因:一是电子病历的描述过于粗糙,包含的患者信息不够完整,无法反映用户真实的信息需求;二是电子病历中相同的症状可能属于完全不同的疾病;三是同一疾病概念可能存在多个不同的术语表示。根据实际临床经验,在进行医学信息检索之前,如果能够预先根据专业医疗知识推测患者可能的疾病、检查和治疗等相关信息来进行查询扩展,将有助于提高信息检索的效果。基于上述问题,本文提出了一种具有普适性的能够基于相关医学知识进行查询扩展的深度医疗检索模型(Deep Medical Retrieval Model,DMRM)。本文首先对数据进行预处理,针对不同的数据源出现的同一医学概念的不同表达方式而造成的医学概念不匹配的问题,引入统一医学语言系统1(Unified Medical Language System,UMLS)对医学数据进行处理,确定医学概念的唯一标识,对医学概念的不同表达方式进行统一表示。其次,本模型以给定的电子病历作为查询,使用MetaMap2抽取出其中的医疗概念,利用医学知识库推导出与查询相关的医疗概念扩展项进行查询扩展。然后,使用扩展后的查询利用BM25模型检索得到伪相关反馈文档(Pseudo Relevance Feedback,PRF)集合,将得到的伪相关反馈文档集合和扩展后的查询一起输入到神经网络模型对候选文档进行排序,从而得到最终的文档排序列表。为验证检索效果,本文采用文本检索会议3(Text REtrieval Conference,TREC)临床决策支持(Clinical Decision Support,CDS)项目在2014年和2015年的标准数据集。实验结果证实了本文所提出的基于医学知识库进行查询扩展的深度医疗检索模型DMRM具有优越的性能,其检索效果明显优于已有模型。本文所提出的模型易于实现,且适用范围更加广阔。"
1940,基于Super learner的结直肠癌预后预测研究,"结直肠癌是危害人类健康的常见恶性肿瘤之一,其所造成的的疾病负担正在不断增加。在我国男性人群中结直肠癌发病率位居第三位,死亡率居第二位;而在女性人群中,其发病率与死亡率均位居第三位。实践证明,准确判断结直肠癌患者预后及其影响因素,进而及时调整治疗干预方案,是降低其死亡率和疾病负担的有效策略。然而,目前临床上判断结直肠癌预后往往仅基于TNM分期(包括肿瘤病理浸润深度、区域淋巴结转移数目及是否远处转移等),凭借医生经验进行评判,其评估准确性通常不高。为了提高预后预测准确性,增加预后判断的客观性,国内外已有研究在TNM分期的基础上增加其他常见的预后相关指标,采用常规的单一疾病预测模型(如Weibull回归、Cox 比例风险回归模型、基于机器学习的随机生存森林模型等)构建结直肠癌预后预测模型。然而,单一预测模型各有其局限性,针对不同人群、不同预测变量的情形时,其预测效果差异很大,必然严重影响模型外推预测的准确性。为了提高结直肠癌预后预测的准确性和外推泛化能力,本研究在新近发展的Super learner理论方法框架下,组合运用Cox 比例风险模型、随机生存森林、加法风险模型、Weibull回归模型、指数回归模型、对数正态回归模型、对数logistic回归模型及基于条件推理树的随机森林共八种预测方法,构建新一代的结直肠癌预后预测模型。首先,通过理论模拟系统比较Super learner与8个传统单一预测模型在不同类型数据中的预测准确性和精确性。然后,利用来自不同种族、不同地区真实世界研究的6个结直肠癌预后队列,分别建立了基于Super learner的组合预测模型和8个单一预测模型,并进行了实效性比较和验证。研究结果:1.统计模拟结果显示,在数据结构相对简单和预测变量数目较少的模拟情境下,Super learner预测效果较好,其判别准确性(C-index)均值为0.715,而校准能力(O/E)的综合评价指标|1-O/E|均值为0.069。Super learner组合预测模型表现出校准能力(O/E)接近1的稳健校准能力;而其它单一预测模型在不同结构的外推预测集中表现出校准能力(O/E)不稳健的状态。2.在不同真实世界研究的6组结直肠癌预后队列组合中,Super learner组合预测模型均表现出较为稳健的预测效果,具有稳定的外推泛化能力;而其它单一预测模型在不同分布特征的结直肠癌预后队列中,表现不稳健,预测能力的一致性较差。具体表现为:(1)在第一组队列(本课题组构建的结直肠癌预后队列为训练集,TCGA-COADREAD队列为验证集)中,C-index依次为对数正态回归模型(0.819)、对数logistic回归模型(0.815)、Super learner(0.813),位居第三位;O/E 比依次为Cox比例风险模型(1.086)、指数回归模型(1.087)、Weibull回归模型(1.088)、随机条件推理森林(1.111)、Super learner(1.113),位居第五位。(2)在第二组队列(“survival”包里的结肠癌预后队列作为训练集,本课题组构建的结直肠癌预后队列为验证集)中,C-index依次为加法风险模型(0.819)、对数正态回归模型(0.730)、对数logistic回归模型(0.729)、Weibull回归模型(0.727)、指数回归模型(0.727)、Super learner(0.723),位居第六位;O/E比依次为随机条件推理森林(1.213)、Weibull回归模型(1.216)、指数回归模型(1.235)、加法风险模型(1.252)、对数正态回归模型(1.269),对数logistic回归模型(1.277)、Super learner(1.292),位居第七位。(3)在第三组队列(本课题组构建的结直肠癌预后队列为训练集,TCGA-COADREAD队列为验证集)中,C-index依次为Super learner(0.816)、对数正态回归模型(0.816),位居第一位;O/E 比依次为Weibull回归模型(1.053)、对数logistic回归模型(1.054)、指数回归模型(1.054)、随机条件推理森林(1.070)、对数正态回归模型(1.071)、Superlearner(1.077),位居第六位。(4)在第四组队列(GEO数据库中下载的GSE40967数据作为训练集,GSE41258数据作为验证集)中,C-index依次为随机条件推理森林(0.822)、加法风险模型(0.820)、Superlearner(0.818),位居第三位;O/E比依次为随机生存森林(0.929)、随机条件推理森林(0.886)、Super learner(0.878),位居第三位。(5)在第五组队列(GEO数据库中下载的GSE40967数据作为训练集,TCGA-COAD数据作为验证集)中,C-index依次为加法风险模型(0.790)、Super learner(0.820),位居第二位;O/E 比依次为随机条件推理森林(0.981)、Cox 比例风险模型(0.980)、随机生存森林(0.979)、加法风险模型(0.975)、Super learner(0.973),位居第五位。(6)在第六组队列(本课题组构建的结肠癌预后队列为训练集,GEO数据库中下载的GSE40967数据作为验证集)中,C-index依次为随机条件推理森林(0.733)、Superlearner(0.725),位居第二位;O/E 比依次为对数正态回归模型(0.998),Super learner(0.990),位居第二位。(7)对预测模型在六组队列组合中的预测效果进行综合评价,在内部验证中,C-index均值依次为随机生存森林(0.929)、随机条件推理森林(0.800)、Super learner(0.795),位居第三位;校准能力(O/E)的综合评价指标|1-O/E|依次为随机条件推理森林(0.041)、随机生存森林(0.042)、加法风险模型(0.042)、Super learner(0.046),位居第四位。在外部验证中,Super learner的C-index均值0.780,位居第一位;校准能力(O/E)的综合评价指标|1-O/E|为随机生存森林(0.079)、Weibull回归模型(0.081)、指数回归模型(0.083)、加法风险模型(0.071)、Super learner(0.092),位居第五位。研究结论:1.在数据结构相对简单和预测变量数目较少的模拟情境下,Super learner预测效果较好。2.在较为复杂的真实世界结直肠癌预后队列中,单一预测模型表现较不稳定,其预测准确性呈忽高忽低的趋势;而Super learner组合预测模型无论在何种情况下均表现出较为稳健的预测效果,外推泛化能力稳定。3.基于Super learner组合预测策略的结直肠癌预后预测模型,具备稳健性强、准确性高以及外推泛化能力强的优良特征,为临床结直肠癌预后预测提供了新方法。"
1941,基于强化学习的客户调度算法及应用,"客户调度模型和客户直接进行交互,进而可以直接影响到公司的声誉,所以客户调度系统在一个公司尤其是一个大型金融服务公司中具有非常重要的地位。一个金融公司有多种业务,例如借款,还款,余额查询等。当客户咨询金融公司问题的时候,客户调度算法需要根据客户对遇到的问题的描述,猜测出客户遇到的问题,并为客户分配相应的业务线,这一问题被称为派单任务。派单算法的主要目标是猜测客户需要咨询的问题,并尽量减少客户调度模型和客户之间的通话时间。传统的监督学习只能猜测客户遇到的问题,而对减少通话时间这一目标无法量化,所以本文提出使用强化学习的思想来解决多目标的客户派单任务。当模型将大量的客户分配到具体的业务线,金融公司可能会开发多种咨询渠道服务客户,回答客户问题,来满足客户的多样化的需求,比如,聊天机器人,自助app和人工热线系统,将客户分配到咨询渠道的任务被称为客户分流任务。一方面,每一种渠道响应客户请求的容量都有一定的限制,例如人工热线渠道的容量就是在一定时间内能够回答客户遇到的问题的客服人员数量。另一方面,客户可能对不同渠道的偏爱程度不同。大多数客户都倾向选择人工热线渠道来解决问题,但是,人工热线渠道的容量又相对较小。而当前的客户调度系统主要建立在基于商业规则的基础之上,很少考虑客户满意度和系统资源之间的平衡问题。所以,本文提出了基于强化学习的分流算法,该算法能够灵活地平衡系统资源和用户满意度,提供个性化服务,在尽量保证每条咨询渠道不发生严重拥堵的情况下,为客户推荐接受概率较高的咨询渠道,提高客户的满意度。因为客户分流任务没有绝对正确的标签,所以本文结合三种基于值函数的强化学习算法double dqn,dueling dqn和prioritized experience replay,组成深度强化学习模型(PER-DoDDQN)对客户进行分流。本文所使用的真实实验数据来自于一个大型的金融技术公司,同时为了能够有效地评价和训练模型,我们根据真实数据的分布生成了模拟数据,在模拟数据上训练得到的参数应用到真实数据集上。为了提高客户满意度,本文利用客户的属性信息推测出客户对不同的咨询渠道的接受率。实验证明,本文提出的基于强化学习(PER-DoDDQN)的客户调度模型的性能要优于现有的基于商业规则的客户服务系统。同时,为了提前避免系统中的咨询渠道发生堵塞,本文提出使用时间序列预测算法对未来客户流量进行预测。最后,本文也验证了不同的DQN算法在客户调度任务上的性能,实验表明PER-DoDDQN算法提供了一个更有效的调度过程,该算法能够很好地平衡系统资源和客户满意度。"
1942,台球识别系统及分球装置的设计,"本文通过运用机器学习算法与图像处理相结合,以设计出的分球机构为执行机构,以51单片机为控制核心,同时以微型计算机为算法的处理中心,在MATLAB环境下以MATLAB语言为编程语言,采用串口通信方式来实现单片机与微型计算机的信息通信的一整套的台球识别系统。整个系统中分球机构,将落入袋中的台球送入照片采集箱中,在采集箱中采用普通的低成本的摄像头采集照片,所获照片将发送到微型计算机,经过微型计算机在MATLAB环境下编写的图像处理以及识别算法识别出当前采集箱中台球种类并将识别结果发送到下位机。识别完成后由分球机构将台球输送到下位机,这为系统的一个球的识别流程。本系统最大的特点在于将机器学习与图像处理相结合,只需通过摄像头采集照片就可识别出台球的种类,识别率高且成本低。要实现对采集到的球体有效的识别,需要采集大量的图片和进行大量的实验分析,来获取到最有效的特征,以实现快速且准确识别台球的目的。考虑到整个系统的结构与功能,本文完成了单片机控制系统的硬件选型,照片采集箱和分球机构的结构设计。在获取图片的过程中有开启摄像头、照片抓取、图像处理等过程,在系统工作过程中要建立图像采集模块、单片机控制模块以及下位机三者之间通信的纽带。综合考虑选用MATLAB,该软件能够满足以上的要求,并且可以加载机器学习算法,在该软件环境下完成整套识别系统的软件设计。将图像识别技术应用于对台球的检测与识别,适应了现代化工业的要求,具有良好的应用与发展前景,因此本课题具有重要的研究意义。"
1943,基于多类特征和深度学习的Android恶意应用检测系统,"随着智能设备的不断发展,Android系统有着越来越高的市场份额。各类安卓应用市场快速发展,但由于Android系统的开放性以及较弱的应用的监管手段,催生了数量惊人的恶意应用。目前有很多研究聚焦于安卓恶意应用的识别。其中基于机器学习的方法主要收集的特征有权限、组件和Java代码信息等,由于Android应用中原生代码反编译和分析的难度较高,几乎所有研究都将焦点放在Java代码层面上,而忽略了对Native层代码的分析。本研究想要解决目前安卓恶意应用检测工具不检测Native代码,不能分析原生库文件的安全性的问题,提出了一种基于多类特征和深度学习的Android恶意应用检测工具。该工具纳入了三个层面的特征,首先是Manifest.xml文件中的Permission特征,其次是Java层中Smali代码中的API调用特征,最后是Native层中的API调用特征,构建了完整的Jave层和Native层特征信息,可以准确反映程序的行为特性,也能够有效检测出将恶意行为隐藏于Native层的恶意应用。具体工作如下:1)针对应用原生层的Native代码,设计相应的算法,将Native层api特征纳入特征集范围,同时通过Native特征与权限特征的结合,Native特征与Java层API特征的结合所达到的精度提升证明了Native特征的有效性。2)整合所有的特征与深度信念网络算法,实现了一个完整的Android恶意应用检测系统。构建了包含5442个恶意应用和5215个正常应用的总共10657个数据集,由DBN算法进行训练,全特征集的检测精度高达98.71%,漏报率仅0.7%,同时进行详细的实验结果分析和时间统计,并与机器学习算法和现有工作进行对比。3)通过基于随机森林的特征选择算法压缩特征集数目,在保证分类精度的基础上减少了训练时间,压缩特征集后的训练时间仅为4分钟左右,生成更为轻量级的恶意应用检测工具。"
1944,致密油气藏试井及产能预测,"面对国内对油气资源日益旺盛的需求,致密油气藏作为具有良好经济性的非常规油气资源,是常规油气资源的重要补充。但非常规油气不仅流动机理不同,而且普遍采用复杂结构井或者大规模压裂的方式开采,其试井分析及产能预测方法都不同于常规油气藏。本文针对非常规油气藏的特点,开展相关研究,取得的主要成果如下:分支水平井是利用水平井技术构造出来的一种复杂结构井,目前多用于煤层气和页岩气的开采之中。针对分支水平井的特点,本文用Newman乘积法推导了它的地层压力分布公式,并与井底压力曲线结合进行了讨论。对计算地层压力分布过程中出现的性能问题做了逐步的优化,并引入了基于CUDA框架的GPU通用计算技术,最终极大的提升了计算效能。水力压裂技术是改善致密油气藏产出能力的重要途径。除了流行的水平井多段压裂技术以外,对传统垂直井进行压裂改造也可以大幅度提升致密油气藏的产能。本文结合多层油藏试井和压裂试井两者的研究方法,推导了基于层间无越流假设和无限导流裂缝模型的多层部分压开垂直裂缝井的试井模型,并结合现有的试井数据进行了对比和解释,成功解释了各层的裂缝半长等参数,较好反映了多层部分压开垂直裂缝井的特点。传统的油气藏生产数据分析方法是基于参数回归的图版分析法。在面对致密油气藏这种非常规油气资源时,容易体现出其局限性。本文在充分调研的基础上,在页岩气产能预测中引入基于支持向量机的统计机器学习算法。对实际生产数据进行了单井回归拟合和以多井学习模型预测单井压力曲线的检验。其中单井回归拟合效果良好,而多井模型预测单井则在数据密集区间取得了较好的效果。"
1945,基于深度学习的网络流量分类技术研究,"网络流量分类一直是学术界、产业界和网络监管部门共同关注的热点之一,是指将混合流量分成不同的流量类别,依据是不同的网络应用或协议的特征或参数。一方面,网络安全领域需要识别入侵流量;另一方面,进行网络管理时需要对不同应用的流量分类分析,从而合理控制和分配资源,保证网络QoS。随着网络流量的数据量和种类的大量增加,传统分类方法难以满足要求,基于机器学习的算法成为网络流量分类的研究热点。针对机器学习特征工程造成的瓶颈,本文研究了以卷积神经网络为主的深度学习算法在网络流量分类中的应用,主要工作如下:一、为充分利用网络流量数据的时间特征,本文将三维卷积神经网络应用于网络流量分类。将原始网络流量按网络流进行划分后,提取每个流前部相同数目的数据包,每个数据包保留前部的相同长度。每个流中数据包的序列作为一个维度,每个数据包中的数据利用one-hot编码转换为二维。预处理后的数据相当于视频处理中的多帧灰度图,构成三维卷积神经网络的输入。本文采用Tensorflow平台搭建三维卷积神经网络进行仿真,验证了方法的有效性:与基于二维卷积神经网络的网络流量分类器相比,本文取得了更高的准确率;与将时间特征用循环神经网络处理的组合分类器相比,本文在保证准确率的情况下参数量与计算量明显减小。二、针对卷积神经网络将未知类别强行划分为已知类造成的差错,本文对网络的类别判断层进行了改进。通过仿真实验,本文验证了类别判断错误(包括未知类别)时,概率最大的类别对应概率值的分布明显区分于判断正确时概率值的分布。根据以上发现,本文为类别判断层设置了动态阈值,在训练发现的最优阈值下,本文能有效识别未知类别。仿真实验证明,本文对未知类别的处理使系统分类准确率提升了 11个百分点。此外,本文对划分出的未知流量数据通过标记后用于系统更新,系统整体的准确性得到提高。"
1946,基于机器学习的肾病辅助诊断系统的研究,"目前我国利用机器学习技术解决的肾病辅助诊断多为基于中医证型的中医肾病辅助诊断,而以西医血生化、尿常规等化验项目为基础的西医肾病辅助诊断研究案例较少;并且中医证型的肾病诊断结果多为是否患有该肾病,对机器学习在多种常见肾病如肾衰竭、肾结石等肾脏疾病的明确诊断方面鲜有研究。本文将机器学习分类算法与医疗信息技术相结合,以常见的西医肾病化验数据为实验数据,利用K近邻、决策树、随机森林这3种分类算法建立肾病分类模型对6种常见肾病进行诊断。针对3种模型诊断性能的不足,本文提出利用二分类解决6种常见肾病多分类问题的方案,并利用随机森林算法进行了实验,得到新模型的肾病诊断准确率为87.7%的较好结果。本文的研究内容及研究重点如下:(1)通过介绍机器学习在医疗应用的工作流程解释了本文实验的流程。利用机器学习在医疗领域的功能分类引出本文实验利用分类算法解决常见肾病诊断的思想。根据机器学习常用分类技术的理论,提出了本文实验的建模方案。(2)介绍了实验数据的来源、数据特性。针对数据集的不规范、冗余、缺失等问题对数据进行了预处理;利用k近邻、决策树、随机森林这3种分类算法分别建立6种肾病多分类模型,实验得出随机森林的肾病分类模型的准确率最高,为63.7%。(3)为了提高随机森林肾病分类模型的准确率,本文提出利用多个二分类随机森林解决6种肾病多分类问题的猜想,并通过实验证明了猜想可行,设计了二分类随机森林诊断6种肾病的最优模型。(4)利用(3)中设计的最优模型对肾病辅助诊断系统进行需求分析,设计出系统的功能结构和角色业务。对系统框架、系统中重要模块的设计及实现进行了介绍。最后通过系统性能验证证实了系统的可靠性和实用性。本文设计实现的肾病辅助诊断系统可用来辨别肾衰竭、肾盂肾炎、肾病综合征等6种肾病,并且诊断准确率达87.7%。本系统能帮助医生进行肾病的辅助诊断,从而使患者尽早进行正确的治疗,避免病情恶化导致终末期肾脏病。"
1947,恶意网页检测技术的研究与实现,"随着信息化建设的快速发展,互联网已经成为人们日常生活不可或缺的一项,人们足不出户就可以享受到互联网带来的便利。然而互联网是一把双刃剑,方便和安全永远不能完美兼得,如此巨大数量的用户和网站由于安全问题而暴露出危险。互联网中存在各种各样的恶意网站、恶意软件、病毒木马,对用户个人隐私和财产安全造成巨大威胁,不仅给用户带来经济损失,甚至会危害社会和国家安全。这些网络攻击进化的越来越复杂和自动化,由于互联网传播迅速和各种类型的恶意网页层出不穷,为检测带来很大难度。论文分析了恶意网页的攻击与检测技术,针对URL检测中提取文本特征不足的问题提出了基于上下文信息的恶意URL检测方法,设计实现了基于该检测方法和网页源码静态检测方法相结合的恶意网页检测系统。主要工作和成果包括以下几个方面:(1)针对传统基于文本特征的检测方法没有考虑到URL中词的位置和上下文信息的不足,提出了一种基于上下文信息的恶意URL检测方法。该方法利用卷积神经网络模型自动提取文本特征,尤其是可以获取URL中词与词之间的上下文关系,减少了人工干预。(2)在基于上下文信息的恶意URL检测方法中,本文分析了URL分类和文本分类的不同之处,研究了URL混淆方式,对URL针对性的进行分词和预处理,暴露出恶意URL混淆意图,并且提出了利用字符之间视觉相似度改进后的编辑距离算法来计算域名相似性。使用开源工具Word2vec生成词向量,构建了适用于URL这种短文本分类的卷积神经网络,能够提取到现有检测方法无法捕获的文本特征。根据实验结果对比,该检测方法比传统利用词袋模型和支持向量机算法来分类URL在准确率和召回率均有所提升。然后利用基于机器学习算法的网页源码检测弥补了仅使用URL文本特征分类检测恶意网页类型不全面的缺点,结合两种检测技术的优点设计出一个检测方法,在低资源消耗的情况下保证检测率。(3)基于上述方法设计实现了恶意网页检测系统,描述了系统各主要模块的设计与实现方案,测试了整体系统的检测能力和检测效率。"
1948,利用软件演化历史识别并推荐重构克隆,"针对克隆代码在软件中存在的复杂性越来越高,仅靠检测出这些克隆代码并不能降低软件维护成本。因此基于克隆检测的结果,研究者们又开展了克隆管理方面的研究。为了有效管理克隆代码,重构逐渐成为人们关注的一个焦点。重构与软件的质量,如可维护性、稳定性、健壮性都有着密切的联系,经过重构的克隆代码往往比未经过重构的克隆代码具有更高的质量,所以重构对于软件质量保证有着重要的理论意义和应用价值。重构软件系统中所有克隆代码是不切实际的,也不是所有克隆代码都需要重构。盲目地重构可能会影响到软件中其他有益的代码,导致软件质量下降,因此,在对克隆代码进行有效维护之前识别出适合重构的克隆代码则变得尤为关键。现有方法在克隆代码重构的识别和推荐上存在着一定的局限性,亟需一种新的、有效的方法对重构的克隆代码进行识别和推荐。本文以”识别和推荐重构克隆”为切入点,为软件开发与维护人员提供有价值的参考信息。具体工作如下:1.克隆代码演化历史信息需要从克隆检测、克隆映射、克隆家系以及维护提交日志四个方面进行提取。首先使用NiCad检测工具获取软件中克隆代码检测结果;其次使用一种基于词频向量计算、克隆位置距离关系和克隆特征相结合的分层映射方法,来获取克隆代码的映射关系;然后基于前期预研成果FCGE克隆家系工具,提取7种演化模式;最后根据SVN来提取克隆代码维护日志。2.在克隆代码演化历史信息的基础上,识别出克隆代码重构和跟踪候选集。关注在演化过程中经过维护之后克隆群内的克隆片段发生了一致性变化的情况,将这种情况归入到重构候选集中。关注在演化历史过程中,克隆群经过维护之后克隆片段发生分离现象,并在之后的维护操作后重新合并成一个克隆群。将这种情况归入到跟踪候选集中。3.在重构候选集中,提取与克隆重构相关的静态特征和演化特征,构建特征数据库。在重构候选集中提取克隆代码段、克隆关系、克隆上下文三大类静态特征,使用重构工具SourceMonitor来提取这三大类静态特征。同时使用FCGE来提取演化模式、改变频率等相关的演化特征。4.使用机器学习的方法推荐出需要重构的克隆代码。本文将特征数据集分为四个子集,分别是克隆代码段、克隆关系、克隆上下文、演化信息相关的四个子集。然后使用决策树、贝叶斯网络等机器学习方法对这四个子集训练的分类器分别进行预测,最后选出效果最佳的机器学习方法来推荐重构克隆代码。经实验表明本文推荐重构克隆的方法达到90%的精度,同时使用决策树推荐重构克隆的效果最佳。"
1949,基于模式识别和机器学习的电网运行断面估计算法研究,"安全校核是对调度计划和调度操作进行全面的安全稳定校核的一类应用,对电网的安全与经济运行具有重要的意义。安全校核分析计算的基础是计划潮流的自动生成技术。计划潮流的生成技术应具有收敛性好、计算效率高、准确性高的特征。本文围绕安全校核计划潮流的生成技术进行研究,提出了一种电网运行断面估计算法,主要工作如下:提出了基于模式识别的相似断面搜索算法。计划潮流的生成计算过程需先对计划数据的缺失进行补充,借鉴相似日的概念,基于模式识别的方法在历史断面中搜索待校核断面的相似断面,以相似断面的部分潮流数据作为待校核断面计划数据的补充,以满足电网运行断面估计算法的数据需求。提出了基于状态估计的计划潮流生成算法。针对传统的基于潮流计算的计划潮流生成方法中普遍存在的收敛性能差、计算效率低的问题,本文采用状态估计算法进行计划潮流计算。借鉴信息学中的相关熵概念,采用基于最大相关熵准则的状态估计算法,进行待校核断面的计划潮流计算,获得满足输电断面功率约束和各类计划数据的平衡潮流。由于状态估计算法应用了冗余的量测值,且算法不需进行分步潮流调整,因此算法的收敛性好、计算效率较高。提出了基于机器学习的不平衡功率调整算法。计划潮流计算值与待校核断面的真实潮流之间存在不平衡功率,传统的不平衡功率分配方法为由指定机组承担,通过调整发电计划平衡区域潮流。本文提出基于单隐层神经网络模型和极限学习机学习算法的不平衡功率调整算法,通过对历史计划潮流计算结果进行事后分析,获得区域化的、精确化的不平衡功率分配特征,并修正状态估计算法的量测值,以提高计划潮流计算的准确性。设计了IEEE9节点算例和东北电网实际算例,对本文提出算法进行有效性验证。通过不同的历史断面潮流数据构造方法和不同的相似断面的匹配方式,在不同的算例中分别验证相似断面搜索、计划潮流生成和不平衡功率调整三大模块的功能,证明了本文提出算法的精确性较高,并论证了算法在收敛性和计算效率方面的优势。"
1950,基于LSTM-RNN的语言模型在K12英语题目中的自动化校验研究,"目前国内学生群体数量庞大而教师群体数量有限,随着教育教学的发展,自适应的高效学习成为越来越多教师学生的诉求。在这个大环境下,学生需要适合自己能力水平的题目,教师需要减轻出题负担。自适应测试系统的研究和应用,将有可能有效从根本上解决教师学生的问题。本文主要关注如何优化计算机自适应测试(CAT)中题目推荐策略中过于依赖信号量和曝光度的传统题目推荐方案,增加其复杂度,高精确度,改良自动化校验的方式;如何设计自动化的题目检验方案,减轻教师和专业人员在构建题库时的负担,为他们构建题库供一个参数的参考,推进自动化题目校验的发展;语言模型的调试和整体的工程应用,如何完成从词向量训练到语言模型最终输出题目句子概率并探讨用这些概率实际辅助自动化校验的开展;本文主要对一个命令行工具类的系统进行了设计开发,在确定了语言模型所要达到辅助推题策略改进和题库构建的任务后,实际使用了包括了高性能爬虫、大型数据集清洗、词向量以及神经网络语言模型等技术,完成了一个工程项目,并且实现了实际的输出。最终输出的结论表明,不同的句子在语言模型的验证中确实出现了实际的概率差,语言模型可以通过给予更高的平均概率肯定更贴近学习过的语料、更接近常见语义的句子;通过给予更低的平均概率来否定不那么贴近常见语义和学习过的语料的句子。通过这些判断,在题库构建阶段和题目推荐筛选阶段结合其他算法信息或反馈给使用者一个参数信息,从而供辅助决策支持。"
1951,机器学习在水稻病斑图像识别中的方法研究,"当今世界人工智能发展迅速,已经渗入到人类生活的方方面面。我国作为一个农业大国,水稻是我们最重要的粮食作物,如何利用机器学习促进农业的发展成为研究热点。本文以水稻病斑的识别为背景,结合图像处理技术分别采用支持向量机和深度学习两种不同的机器学习方法展开研究,通过对算法的优化改进以建立水稻病斑识别最优模型。本文主要内容包括:(1)建立四种水稻病斑图像数据集。采用矢量中值滤波、基本矢量方向滤波和距离方向滤波三种滤波方式对图像进行预处理,通过计算均方误差和峰值信噪比对滤波效果进行评价,最终选择矢量滤波方法对图像进行滤波。(2)建立基于显著性的GrabCut图像分割模型。为了克服传统GrabCut分割方法由于需要手动框选目标像素而造成的巨大工作量,本文利用图像的显著性算法实现目标区域自动提取:利用AC算法得到图像的全局显著性和局部显著性,将两者结合得到的显著性图设计成约束项加入到Grabcut区域项中以实现Grabcut的自动分割。(3)利用改进的支持向量机算法实现水稻病斑图像识别。首先利用图像的颜色特征和HOG特征实现病斑图像的特征提取,将提取到的特征作为支持向量机的输入对分类模型进行训练。为了优化支持向量机参数,提高模型泛化能力以及分类准确率,引入了粒子群算法,利用粒子群算法的全局搜索能力对支持向量机参数进行寻优,将训练好的模型用于水稻病斑图像识别过程,并对分类结果进行评价。(4)建立了基于预训练的DDC深度迁移学习算法模型。针对水稻病斑图像集样本数量不足的情况,引入迁移学习的概念,提出了一种基于预训练的DDC深度迁移学习算法,将在大型数据集上预训练好的卷积神经网络模型迁移到水稻图像集进行再次训练。并针对不同的训练样本差异较大的问题,提出用DDC算法进行优化,将最终得到的训练结果与直接在训练集上训练的结果进行比较,验证了所提出算法的有效性,证明了该算法具有更强的表征能力,同时为了进一步提高网络性能,用PSO-SVM分类器替换网络原本的SoftMax分类器,结果证明网络的性能进一步得到了提高。"
1952,基于机器学习的定量网络口碑分类预测,"随着当今主要旅游网站的竞争愈演愈烈,争夺潜在消费者与维护已有用户已经成为进驻旅游网站的酒店平台的强烈需求。正因为良好的网络口碑(OWOM)传播会给酒店平台和旅游网站带来良好的声誉与可观的收益,由生产消费者(Prosumers)所留下的网络口碑评论生成(Review Generation)和评论消费(Review Consumption)的相关信息需要被密切关注。鉴于网络口碑的重要性,对于酒店管理者和旅游平台来说,判断消费者评论的哪些方面与其评论的满意度密切相关就变得至关重要。正因如此,我们聚焦于消费者评论文本内容所展现的多种维度信息。在本论文中,我们用到了机器学习方法,来探究是否能通过定性的网络口碑评论文本内容来正确地对一条评论的好坏程度做分类。特别地,我们挖掘了网络口碑文本内容中所隐含的情感极性与情感主观度等多种维度与观点的信息。通过用五种机器学习算法构建的二分类分类器,我们尝试对网络口碑定量的消费者评论评分和评论有效性评分做预测。我们的预测结果显示,文本中所隐含的情感极性和七种维度的观点特征对评论评分可以做出很好的预测,这对酒店管理者和旅游网站平台研究其中的微观细节并更好地相应客户需求有深刻的意义。同时,我们的特征没有很好地预测评论有效性评分,这说明在有效性评分的时间累积效应之外,目前从文本内容中所提取到的特征并不能对其产生有效影响,可能还有其他尚未发现的有效因素。"
1953,基于一维卷积神经网络的供水管道泄漏检测算法的研究,"水在人们的生产生活中有着至关重要的作用,但是由于供水管道周围环境的变化和使用年限过长、人为破坏等自然或非自然因素的影响,管道破损、腐蚀问题层出不穷,如果不能及时的检测出管道是否漏水,将造成严重的经济财产损失和安全隐患,还导致水资源的大量浪费。传统的漏水检测方法耗时耗力,非常依赖人的经验。随着人工智能的发展,机器学习、深度学习逐渐应用到了漏水检测当中。前面的研究者将机器学习算法如svm,人工神经网络等来检测泄漏信号,此类方法需要人工进行特征的提取,进行大量的实验,不同的特征组合对于准确率有着非常大的影响。针对此问题,本文提出了使用一维卷积神经网络对漏水数据进行分类,由算法自动的提取特征,然后经过全连接层将提取的特征两两相连,最后通过sigmoid激活函数输出预测值。由于深度学习非常依赖数据量,而实际采集的数据远远不能满足模型训练的需要,本文针对一维的时间序列信号提出了偏移采样的数据增强技术。为了增强模型对含噪声信号的分类准确率,提出了基于BN的一维CNN分类算法模型,通过对比实验选出最优的卷积神经网络隐含层数量、激活函数等,最高分类准确率达到了100%。分析验证了基于BN的一维CNN在不同信噪比条件下的分类准确率。"
1954,多维光互联网络中的复杂拓扑构建机制及性能评估研究,"近年来,随着云计算以及大数据业务的兴起,互联网概念和技术发生了革命性的改变,这对数据中心的网络通信提出了越来越高的要求。光互联技术,特别是多维多粒度的全光交换技术,在此背景下,凭借其低功耗和丰富的带宽资源等优势,俨然被认为是面向云服务最具应用前景的网络技术。同时,为了适应数据中心高突发、高差异的流量特征,设计出高效的拓扑重构算法至关重要。因此,本文基于一个面向数据中心的小世界光互联网络架构――OpenScale,提出了针对不断变化的、不同分布的网络流量的拓扑构建方式,以充分发挥光交换的灵活可重构性,提升云服务性能。本文的工作可概括为以下几点:第一,介绍了OpenScale架构的设计原理、组网方式及节点结构,在此架构的基础上,首先讨论了不考虑流量分布的拓扑构建方式。提出与流量无关的确定性波长连接拓扑生成算法,仿真证明此算法可以降低拓扑平均路径长度;提出了与流量有关的基于动态阈值的拓扑重构机制,仿真表明,此机制能够有效提升时延和吞吐量性能。第二,讨论了考虑流量分布的拓扑构建方式。提出基于热点区域识别的拓扑重构机制,通过识别热点区域,能够对网络是否拥塞做出更准确的判断,从而减小区域拥塞对网络性能的影响;提出基于流量预测与流量识别的拓扑重构机制,本文将流量预测抽象理解为对时间序列的预测,通过流量预测,能够使重构后的拓扑适应最新的流量需求,流量识别用于识别是全局流量还是区域型流量,根据流量识别结果进行拓扑裁剪,能够节省OCS连接数目,提高波长连接利用率。"
1955,基于卷积神经网络的糖尿病病情预测研究,"糖尿病是一种常见的慢性非传染病,该种疾病主要表现是患者体内由于代谢紊乱而长期存在高血糖水平。该种疾病不易治愈,患者体内长期存在的高血糖值给患者的肾脏,心脑血管,神经系统等部位带来严重的危害,会引发诸多并发症,给患者的身心健康带来极大的伤害。然而,由于人口老龄化和人们不良的生活习惯,糖尿病的发病率依然高居不下,更呈现上升态势。可见,糖尿病的预防和治疗已成为亟待解决的医疗健康问题。随着医疗信息化的发展,各个医疗机构在病人的诊疗过程中也积累了海量的患者医疗电子数据。充分利用大量医疗数据,从中挖掘有价值的治疗规律,将规律用于辅助医生诊疗,可以缓解部分地区医疗资源紧张的问题;还有助于医师根据患者的病情发展及时调整治疗方案,提高治疗效率。机器学习作为一门多领域交叉学科,近些年得到了很大的发展。深度学习作为机器学习的分支,由于其强大的特征提取能力,可以发掘数据更深层次的特征,因此被广泛地应用于人脸识别,语音识别等诸多实际应用领域。将深度学习的强大信息挖掘功能应用于医疗数据挖掘,发掘数据之间潜在的有价值信息将会极具实际意义和社会价值。本文基于经过数据分析和特征处理后的糖尿病病人的入院病历记录,利用改进的卷积神经网络算法建立了预测糖尿病病情变化模型。该模型可以辅助医生根据住院病人诊疗的病例记录,利用模型判断病人的治疗效果,对住院病人出院后再次入院的风险进行预测,从而对治疗方案的有效性进行判别。本文所做的主要工作如下:1、提出了对病例数据进行数据统计分析和特征处理。由于本研究所用数据集是从医院获得的真实数据,该数据集数据量较大,维度较高,并且存在缺失值。为了保证在接下来的分析都可以建立在良好的结构化数据上,本实验首先对数据集进行数据分析。本文首先对缺失值进行清洗;对数据集的数据分布进行分布统计,确定数据的分布特征。针对数据集中类别分布不均衡的现象,利用基于少数类权重过采样技术进行数据均衡;利用孤立森林算法进行异常数据检测,找出异常数据进行删除,从而获取统计学上较为光滑的数据;使用Xgboost算法进行特征权重排序,去除对分类结果无贡献的特征,进行特征精简。2、本研究提出了基于卷积神经网络和集成学习的CNN-EI算法。本研究分析了本数据模型的特点,选用卷积神经网络为预测模型,并结合了集成学习的良好的数据分类能力对卷积神经网络进行算法改进,希望能够获得更好的预测效果来辅助医生诊疗。3、为了验证本文提出的数据处理方法的必要性和模型的有效性,研究过程中加入了对比实验。实验结果表明,与传统的卷积神经网络和分类算法相比,本研究的确有良好的可靠的预测效果,并且数据处理部分对模型性能的提升也大有裨益。4、本研究根据上述的研究成果构建了一个糖尿病病情发展预测模型,通过该模型可以用来实现对病人病情发展趋势的进行判断,判断病人短期内再次入院的可能性。"
1956,机器学习在学生通过率预测中的应用研究,"迄今为止,教育质量仍然是国家重点的关注对象。在教学过程中,学生质量主要体现在学生成绩或者学生毕业率上。根据已往的教学经验,学生成绩在一定程度上决定了学生的通过率。本文对学生通过率的研究,主要以学生的课程通过率和学生的毕业通过率为目标。通过文献阅读和以往教学研究的经验,发现学生通过率受很多因素的影响,例如父母的教育背景、学生是否获得额外的教学支持等。教学管理者和学生个体都希望能够找出影响课程通过率和毕业通过率的重要因素。对于教学管理者而言,及时找出影响学生通过率的重要因素,可以提出有针对性的教学方案,及时改变教学方针,真正实现对学生的个性化指导,提高学生通过率,从而提高教学质量;对于学生个体而言,及时了解自己的学习现状,可以有针对性的更改自己知识盲点,提升学习的兴趣,避免产生负面情绪(退学,厌学等)。因此,通过对学生通过率进行预测,找出影响学生通过率的因素至关重要。过去,教育教学管理者主要依据已有的教学结果,粗略地对学生通过率进行猜测。然而这并不能满足教育教学管理者的需求,管理者们希望通过某种方式,可以科学地、准确地预测学生通过率,而不是根据已有结果猜测下一次的结果。因此寻找影响学生通过率的重要因素和预测学生通过率已成为教育领域亟待解决的问题。近年来,机器学习技术在各行各业都有比较好的表现,得到了广泛的认可和推广,尤其是在教育领域,研究者已经利用机器学习算法在预测学生通过率和寻找学生的关键特征两个方面进行了探索。目前,教育模式主要包括两种:在线教育和线下教育。在线教育中,研究者已经涉足学生通过率预测领域,构建出预测模型已成为研究热点,目前针对在线教育研究中还没有引入深度神经网络算法,也没有考虑学生特征之间是否存在依赖关系,存在图形结构的特征以及系数的初始化值对算法造成的影响。线下教育中,考虑到决策树算法结构简单,容易实现;支持向量机在二分类问题中具有优势的特点。研究者已经利用决策树算法和支持向量机算法在学生通过率预测领域进行率探索。但目前的研究中还未考虑特征之间存在依赖或者特征之间产生图形结构,系数的初始化值以及参数等问题对算法的影响。综上,本文所做的主要工作可以归纳为以下几个方面:(1)针对在线教育,构建一个基于改进后的深度神经网络预测模型(Improved deep neural network:FDNN)。考虑学生特征之间的依赖和存在图形结构的特征对算法的影响,本文提出特征依赖和有向无环图(Directed acyclic graph:DAG)方法的新概念,并应用特征依赖和DAG方法优化深度神经网络算法,以提高预测精度;考虑初始系数对算法造成的影响,提出初始化系数规则,以使算法尽快收敛。(2)针对线下教育,构建了基于改进后决策树算法(Improved decision tree algorithm:FGDT)的预测模型和基于改进后支持向量机算法(Improved support vector machine algorithm:FGSM)的预测模型。决策树算法和支持向量机算法虽然已经在教育领域中表现出优势,但目前的研究并没有考虑特征之间是否存在依赖关系以及存在图形结构的特征,系数的初始化值,参数问题对算法造成的影响。针对这些问题,本文提出特征依赖和DAG方法解决存在依赖的学生特征和存在图形结构的特征对算法结果产生影响,以提升算法的准确度;本文提出初始化系数规则解决系数对算法结果造成的影响,以使算法尽快收敛;本文引入网格搜索算法优化决策树算法和支持向量机算法,以提高算法的准确度。(3)实验分析。本文针对线上教育和线下教育两种模式进行实验。在线上教育中,将FDNN算法与决策树算法和支持向量机算法进行比较,以预测学生通过率。实验结果表明FDNN算法拥有较好的效果和较优的性能表现。在线下教育中,将FGDT算法,FGSM算法分别与决策树算法、支持向量机算法做实验对比,以预测学生通过率并且找出影响学生通过率的重要的学生特征。实验结果表明FDNN算法拥有较好的效果和较优的性能表现。"
1957,基于NLP的机器智能写作技术研究,"随着时代的进步与发展,以及大数据、云计算和物联网相互融合的技术革命,使得自然语言处理技术在某一领域取得了快速发展,尤其在智能写作上起到了非常关键性的作用。本文以亚太地区双字节语言尤其是以中文汉字为研究对象,基于自然语言处理理论,尝试建立智能写作计算模型,并通过计算让机器获得自然语言要表达的思想和含义,然后做出一个合理的响应,探索文字之间的定量关系,进一步揭示自然语言处理机理、探索机器理解自然语言的规律。本文通过系统研究NLP技术,在探索文本自动生成模型规律的基础上,提出构建基于RNN双层网络算法的语言模型,为智能写作提供理论依据,RNN双层网络算法为文章的自动生成提供技术支撑。具体研究内容包括以下三个方面:1.通过分析和研究目前自然语言处理和机器学习相关技术,探索文本自动生成模型规律。本文在系统研究自然语言处理技术的基础上,着重研究了其在中文文本中应用,并且通过研究基于深度学习的机器学习方法,来探索文本的自动生成模型。2.构建了一个基于RNN的双层网络语言模型。在充分理解文本生成技术以及NLP技术基础上,提出构建基于RNN双层网络语言模型,该模型采用增加网络层数的方式,替代原有的一层网络以解决神经网络权值过多的问题,同时利用长短时记忆模型结构来替代原始的RNN结构来解决序列文本生成的长时间依赖问题。该模型是基于深度学习方法实现的,通过改进传统的循环神经网络算法,实现了对中文文本信息的处理,并利用TensorFlow机器学习工具完成了语言模型的构建。3.采用RNN双层网络算法,实现了一个基于NLP的智能写作系统。为了验证和评估本文构建的基于RNN双层网络语言模型,设计并实现了一个智能写诗系统。该系统以4万多首唐诗为数据集,在对数据集清洗之后,通过调用训练好的语言模型,最终,实现了给系统输入一个关键字可以让机器智能创作出来一首完整的诗歌,同时为了使生成的诗歌更加有意境,利用PIL库给系统集成了可视化的显示效果,把生成的诗歌嵌入到图片上显示。"
1958,基于机器学习的软件定义网络业务路由优化,"目前,随着通信技术、互联网应用以及云计算技术的高速发展,通信网络正经历着爆发式的流量增长。传统的路由优化方法通常需要收集网络流量信息,然后根据这些流量信息计算路由策略,最后进行路由配置。整个路由计算过程非常耗时,并且获取准确的网络流量信息通常非常困难,往往需要巨大的网络资源开销。最近,在机器学习以及人工智能领域取得的突破似乎为网络业务路由优化提供了一种可行的方法。基于机器学习的路由优化算法可以根据历史数据学习到流量特征和路由策略良好的映射关系,然后利用学习到的知识根据业务特征变化快速地进行路由决策,能够实现自适应的业务路由调度和管理。另一方面,SDN作为一种新型网络架构可以方便地获取到用于业务路由优化的统计信息。利用SDN的这种架构,在控制平面可以方便地获取到丰富的用于机器学习路由优化算法输入的业务流量特征,并且能够实现快速地进行路由策略下发和执行。本文主要研究在SDN场景下结合机器学习算法来更好地实现业务路由优化。据研究表明,通信网络中的大流占据了网络中80%的流量,通过识别这些大流然后对其进行路由管理和优化,可以更好地实现网络的负载均衡,并为后续的在线的路由规划和调度方法的研究奠定基础。因此,本文首先研究了基于机器学习的实时大流检测方法。该方法利用SDN交换机在数据平面收集流特征,并在控制平面基于机器学习方法构造大流检测模型。该方法相对于传统的方法能够实现更高的检测精准率,以及更低的交换机内存开销。接下来,为了实现网络流量的负载均衡,本文研究了基于监督式深度学习的路由优化方法。该方法首先构建路由优化数学模型,接下来使用该模型求解若干真实流量场景下的路由优化方案,并将这些路由优化方案作为深度学习算法学习的路由标签,然后使用神经网络来学习流量矩阵和这些路由标签的直接映射关系。根据实验结果,该方法能够实现良好的网络负载效果。上述监督式的机器学习路由算法存在数据标签难获取、真实流量矩阵难测量等问题,为了找到一种简单、可行的智能路由优化方法,本文继续研究并提出了一种基于深度强化学习的路由优化算法。强化学习路由算法通过最大化获取的奖励来调整神经网络参数,不需要人工构造样本标签,可以大大减少人工与时间成本。此外,该方法使用可以直接获取到的网络链路利用率作为算法模型输入,与直接使用流量矩阵相比可以有效避免流量矩阵的测量开销。"
1959,基于机器学习的信用评分模型研究,"当今社会,人工智能和互联网行业在不断快速发展,人们的经济消费模式逐渐由传统消费模式转变为信用经济模式,信用经济模式主要表现于个人消费信贷,其中信用卡消费、住房按揭、汽车贷款、教育贷款等都属于个人消费信贷。在消费信贷热不断升温的形势下,为保障银行和其它金融部门的安全设立了一种关于人身金融权限的划定模型,即信用评分模型。该模型指根据消费者的信用历史资料,利用机器学习或数据挖掘方法,得到不同等级的信用分数,根据消费者的信用分数,来决定消费者可以持有的信贷额度,从而保证还款等业务的安全性。信用评分模型主要对消费者进行信用评估,信用评估技术在处理信贷业务上具有快速、高效、标准的特点,信用评分模型的研发一方面可以保障金融秩序稳定,减少信用评估成本,改善信贷决策的一致性、速度和准确性,另一方面也有利于提高商业银行的授信工作效率及扩大消费信贷的发放。因此,开发出一个有效的信用评分模型对稳定银行业务发展及降低消费者信贷违约风险具有非常重要的作用。在现有信用评分模型中,国内外研究学者大多研究点聚焦在对传统机器学习方法进行改进或者对消费者的信用特征进行研究,即采用特征选择方法,然而基于传统机器学习方法构建的信用评分模型对大量的、不规则的信用数据来说,缺乏稳定性和精确度。针对现有信用评分模型存在的问题,本文结合网格搜索、数据预处理、信用矩阵、加权抽样、特征语义、混合组特征选择等方法来构建信用评分模型,并对消费者信用进行预测分析。本文的研究工作如下:(1)针对基于传统随机森林算法构建的信用评分模型对冗余特征敏感和输入参数不易确定的问题,提出基于随机森林的改进型信用评分模型。传统随机森林算法虽然有算法结构简单、容易实现等特点,但也存在输入参数不确定、对信用数据中冗余噪声数据较敏感等缺点。针对以上问题,本文结合网格搜索方法对随机森林算法参数进行优化及提出信用矩阵构建、加权抽样方法对训练数据进行抽取,同时,为提高其预测精度,结合相应的特征选择方法来提高基于随机森林构建的信用评分模型的预测性能。(2)针对现有利用特征选择方法构建的信用评分模型最终预测精度低、特征子集间稳定性弱的问题,提出基于混合聚类和支持向量机相结合的混合信用评分模型。对信用数据进行预处理的基础上,从多维视角进行研究,提出一个新的混合组特征构造策略及基于特征组对信用特征进行特征转置,以提高模型的预测精度和稳定特征子集间的稳定性,同时提出特征语义,构建雷达图对信用特征进行解释,以挖掘出更多有用信息。本文利用UCI数据库及网上公开的真实信用数据集进行验证,并和现有信用评分模型进行对比。实验结果表明,本文构建的信用评分模型在预测精度和稳定特征子集间稳定性上具有更好的表现。"
1960,基于多源数据的政务信息系统的研究与应用,"互联网在我们的生活中无处不在,而随着互联网的飞速发展,我们也逐渐进入了“数据爆炸”的时代。调查显示,过去的2年已产生了世界上超过90%的数据。庞大的数据体量背后是多样的数据来源。对多源数据实现有效地获取、整合和分析,是解决人们生活中遇到的问题的有力保障。20 15年以来,中国的“互联网+政务”模式发展迅猛。政府部门积极推动自建政务APP的建设,并依托第三方平台共建“互联网+政务”服务。因此,将信息技术与实际应用相结合,依托多源数据建立一套政务信息系统,切实解决城市建设、政务服务中遇到的问题,具有极大的研究价值。本文的研究课题是基于多源数据的政务信息系统的研究与应用。论文首先阐述了政务信息系统的整体架构和模块构成,介绍了各部分的主要功能和研究重点,为后面的研究提供了技术基础。在流动人口管理问题研究中,我们重点研究了基于机器学习的可疑人员识别算法,并搭建了基于多源公安数据的信息管理平台。在发票分类编码识别问题的研究中,我们从海量发票数据中抽取商品文本特征,基于朴素贝叶斯算法实现了发票的分类编码识别,并构建了高性能的分类编码模型训练模块和预测服务。在基于网络大数据的城市功能区识别问题的研究中,我们基于聚类算法探索了基于流量数据识别城市功能区的问题。最后,我们总结了课题的研究成果,并对未来可能的研究进行了展望。"
1961,基于机器学习的二进制软件漏洞挖掘技术研究,"随着代码量和代码复杂度的不断提高,存在越来越多容易被攻击者所利用而导致原始程序逻辑错误的漏洞。为了能尽早发现并修补软件中存在的漏洞,二进制软件漏洞挖掘技术成为了安全研究领域的热点课题之一。使用机器学习的二进制漏洞检测模型有着能批量处理大规模数据,检测速度快,检测成本低的优势。但是因为二进制级别的软件不能直接表达程序信息,无法从中提取有效的特征集,导致现有的基于机器学习的二进制漏洞挖掘方法往往具有较高的漏报率和误报率。在此情形下,本文结合机器学习和自然语言处理技术,提出一种二进制特征提取的方法并在Android平台上设计和实现了一个漏洞检测系统。本文的主要工作及成果如下:1、通过对二进制文件预处理和词嵌入技术的研究,提出一种基于底层语言的特征向量化模型,使用这种模型可以从二进制文件中初步构建出包含汇编指令内上下文关系的特征向量。2、通过对深度神经网络的研究,提出Att-BLSTM特征提取模型,该模型的核心是双向长短期记忆网络(BLSTM)及注意力(Attention)机制,通过这种模型可以从二进制文件中提取出包含丰富程序语义信息的二进制特征向量。3、经过研究,本文并未在网上和其他论文中找到可用的Android平台二进制软件的漏洞数据集。为了完成本文的实验工作,本文通过从漏洞信息发布平台收集到了从2000年到2018的漏洞信息,并建立了一个Android平台二进制软件(动态链接库文件)的数据集。4、基于所提的两个模型,本文在Android平台上设计并实现了一套二进制漏洞检测系统。测试结果表明,相较于现有的基于机器学习的二进制漏洞挖掘方法,本文所提出的模型能够更好地学习二进制文件的程序语义信息,基于该模型所设计的漏洞检测系统的精确度最高能够达到93.86%。"
1962,基于深度学习的PC恶意代码检测技术的研究与实现,"近年来,恶意代码和网络攻击日益频繁,造成的危害越来越大,新的威胁又不断涌现。日益严重的信息安全问题,不仅使企业蒙受巨大的经济损失,而且使国家的安全面临严重威胁。传统检测方法的能力在恶意代码日新月异的更替和发展面前显得越发疲软。面对恶意代码的爆发式增长,如何既准确又高效的对恶意代码进行多方面的检测,成为当前恶意代码检测技术的研究重点。借鉴于深度学习的相关技术研究在图像处理和自然语言处理等领域取得的丰富成果,本文将对深度学习在PC恶意代码检测方向的应用进行研究。本文首先对当前学术界针对恶意代码的检测方法进行了总结;并对当前基于样本转换灰度图的恶意代码检测方法进行了改进,并在此基础上提出了基于循环神经网络的压缩灰度图检测模型。由于改进方法检测结果存在提升空间,笔者提出了一种基于卷积神经网络的静态机器码检测模型。该模型采用可执行文件的反汇编指令作为训练数据。为了同时提高该模型的检测能力及检测效率,笔者提出了指令融合的方法。考虑到加壳样本的反汇编指令提取的局限性,笔者又提出了基于双向循环神经网络的动态API序列检测模型。该模型将在改进的Cuckoo沙箱环境中对样本进行动态模拟执行,并将监测到的API序列按进程和时间的顺序进行拼接,用于后续双向循环神经网络的训练。由于静态模型和动态模型本身的独立性,恶意代码检测并不能同时受益于静态特征和动态特征,这意味着对于独立模型而言,静态和动态分析的局限性(例如动态分析覆盖不完整、静态对抗手段多样等)在这类模型上依旧存在。为此,笔者采用改进的stacking模型算法,将静态特征模型和动态特征模型进行融合,从而给出更为全面且准确的恶意代码检测结果。最后,笔者对改进的压缩灰度图模型,以及提出的静态模型、动态模型、融合模型进行了实验验证,通过准确率、精确率、召回率以及训练损失等指标对各个模型进行了恶意代码检测能力的评估。实验结果证明,本文所提出的各个模型相比同类型的其他方法具有更加准确且高效的恶意代码检测能力。"
1963,基于深度学习的手势识别及人体行为识别算法研究,"随着人工智能的发展,手势识别和人体行为识别成为了人工智能领域的重要研究课题。在智能交通领域,手势识别能够实现车载人机交互,人体行为识别能够实现对驾驶员驾驶行为进行异常检测。手势,是人与人之间传递信息的方式之一,也是聋哑人和正常人进行交流的重要表达方式,所以理解手语意义至关重要。采用人工智能技术对手语进行自动识别,将会在一定程度上提高聋哑人与外界交互的效率,解决聋哑人交流困难等问题。人体行为是衡量人体姿态发生变化的重要尺度,从传感器获取的数据中分析人体姿态的变化,从而可以判断老年人是否跌倒,第一时间发出求救信息,启动GPS定位系统,为紧急救助提供可能。本文基于这两种应用背景,开展深度学习技术对手势识别和人体行为识别研究。本论文基于手势识别和人体行为的研究现状和相关深度学习理论的阐述,对手势识别算法和人体行为识别算法进行分析,从手势识别和人体行为识别两方面展开了相关研究。在手势识别方面,采集人机交互中常见的10种手势建立了数据库,基于目标检测算法框架YOLOv3进行了手势识别,在测试集上的mAP达到92.6%;提出了一种改进的卷积神经网络,通过数据增强技术、使用Maxout激活函数、增加输入图片的分辨率等方法最终在测试集上的mAP为98.2%,提高了手势识别率;引进了一种基于轻量化卷积网络MobileNet对模型进行了压缩,压缩后模型仅为10M左右,减少了模型占用内存,基于压缩后的卷积网络在测试集上的mAP为97.1%,同时兼顾了手势识别精度和模型占用内存,满足了实时性要求。在人体行为识别方面,本文设计了一种卷积神经网络对人体行为进行识别,在MobiAct数据集、MobiFall数据集、SisFall数据集上提取出了八种不同类别的人体行为数据,并对传感器获取的三轴加速度数据、三轴陀螺仪数据采用了卡尔曼滤波技术进行降噪处理,将其转化为RGB图像中的像素值,采用本文设计的卷积神经网络进行模型训练,并使用KNN算法与设计的卷积网络进行了效果对比,在测试集上进行了评估,使用KNN算法与设计的卷积神经网络的平均准确率分别为90.06%,97.42%。"
1964,基于机器学习的空气质量评价与预测,"随着经济建设和城市化进程的日益加快,人民的生活质量日益提高,但是能源的大量消耗和污染物排放造成的空气污染问题日趋严重,雾霾天数日渐增多,对人类的日常生活及身心健康产生了严重的威胁。空气质量指数(AQI)成为衡量空气质量的重要依据,因此空气质量预测对指导人们生活和工作具有极其重要的意义。空气质量的数据,属于非线性时间序列,其高度复杂性导致传统的方法难以达到预期的结果。近几年,智能优化算法的兴起为解决此类问题提供了一种思路。其较强的搜索能力,易于寻找最优解的特点,得到了研究学者的青睐。本文利用机器学习中的支持向量机、群优化算法和与神经网络对太原市2015年至2018年间的空气污染物监测数据进行研究,主要研究内容如下:(1)运用K最邻算法(KNN),对太原市和大同市的空气质量等级进行分类预测。在预测的过程中,以70%作为阈值点,将空气质量进行二分类和多分类,并对预测的结果误差分析,实验结果表明,分类预测与真实值比较接近。对预测结果进一步分析,建立皮尔森相关系数矩阵,得出了各种污染物浓度日均值之间的相关关系,通过计算AQI的数值与各种污染物浓度之间的皮尔森相关系数,找到了影响太原市空气质量的主要污染物因子,从而从源头治理空气污染。(2)运用思维进化算法(MEA)、粒子群优化算法(PSO)和遗传算法(GA)的混合模型优化BP神经网络参数,并预测太原市未来的空气质量指数。实验结果表明,MEA-PSO-GA-BP算法在预测精度、误差率和可靠性方面搜索速度更优,具有较好的有效性和可行性,对预测AQI有一定的现实意义。(3)针对飞蛾扑火优化(MFO)算法容易陷入局部最优和和支持向量机(SVM)惩罚函数c和核函数参数g难以寻优问题。借鉴支持向量机(SVM)所需样本少和全局最优的优点,提出了将SVM和MFO相结合的算法(MFO-SVM)。选择山西省太原市和大同市的日常空气质量指数(AQI)对该算法的可行性和有效性进行验证。实验结果表明,MFO-SVM算法的相对误差接近于零,预测值与实际值更接近,可以有效预测空气质量指数。本文提出的两个预测模型:MEA-PSO-GA-BP和MFO-SVM用于空气质量预测,为空气质量预测提供了一种新的思路,为大气污染防治以及有效措施的提出提供了科学合理的理论依据。"
1965,基于奶牛活动量数据和卷积神经网络的模板匹配奶牛识别的研究,"奶牛识别是奶牛管理的重要组成部分,传统的奶牛识别方式以人工识别为主,但这种工作效率低,识别结果因人而异。随着近几年的科技发展,电子标签识别(RFID)技术和图像识别技术也被应用于奶牛识别。但是,耳标式电子标签识别技术使用便捷但是存在掉标率高和工作范围受限的问题,瘤胃式电子标签则存在成本较高的问题;而图像识别技术则存在数据采集必须在本地工作、无法实时处理采集数据给出识别结果的问题。针对上述问题,本文提出了基于奶牛活动量数据和卷积神经网络的模板匹配识别奶牛的方法,该方法具有识别准确度高、可以远程实时进行奶牛识别工作的优点。本文主要研究基于奶牛活动量数据和卷积神经网络模板匹配识别奶牛,提出了基于卷积神经网络的奶牛识别算法和基于奶牛活动量特征值的奶牛识别算法,并将两者相结合,以卷积神经网络的奶牛识别算法作为奶牛识别的初步筛选算法,将奶牛活动量特征值的奶牛识别算法作为奶牛识别的确认算法。本文主要完成了以下工作:一是奶牛活动量数据收集及其预处理。奶牛活动量数据指奶牛头部运动数据、吞咽量数据、一般运动数据等的综合信息。本文通过数据采集装置将相应数据收集并上传至数据库进行存储。进入数据库内的奶牛活动量数据还将通过程序进行预处理提取出相应的特征值并存储。二是应用卷积神经网络对奶牛活动量数据进行训练分类。首先,将奶牛活动量数据制成12小时时段的波形图,然后将该波形图通过卷积神经网络进行训练分类获得分类模板,将被测试数据通过卷积神经网络进行训练后获得初步筛选的分类结果,将该结果作为初步匹配结果。三是提出了提取奶牛活动量数据特征值的算法以及通过该特征值识别奶牛的方法。将初步匹配识别结果识别匹配分类组的特征值进行二次识别,进而给出确认结果,通过该识别方法有效地提升了奶牛识别的准确率。最后,本文还进行了实地测试工作。通过对实例的研究与完善,压缩了所需测试数据的时间长度,进一步提升了系统的工作效率,使该方法具有工程应用价值。"
1966,基于深度学习的图像有序性估计研究,"图像有序性估计是计算机视觉中一个非常经典和有挑战性的问题,通常被定义成一个分类或者回归的任务。图像有序性数据集与普通图像分类数据集最大的区别是图像间存在着有序性关系,在计算机视觉领域有着非常广泛的应用,比如年龄估计、美学估计、颜值打分、图像质量评估等。有序性估计问题的标签可以是连续的或者离散的。近几年随着深度学习的广泛应用,该问题会呈现什么样的特点、与传统的方法有哪些不同、在哪些应用场景会得到进一步的发展?本论文将围绕这几个问题展开研究,具体研究内容主要分为以下五点:1.基于CNN的图像有序性估计近几年,随着深度学习的火热发展,许多应用问题将CNN模型看成一个应用工具,输入图片即可输出结果。基于深度学习的图像有序性估计问题也有类似的现象。本文针对两个问题:为什么CNN能在该问题上有较好的效果、如何让CNN在有序性问题上发挥更好的作用,在深度学习背景下重新思考图像的有序性估计,特别是针对有序性关系,提出了两种CNN模型。首先,提出了一种双任务的估计模型DTCNN(Double-task CNN model),一方面考虑有序性图像的类别属性,另一方面考虑其有序性关系。在该模型的基础上,本部分从三个方面进一步分析了DTCNN模型能起作用的原因:一是双任务间的关系;二是双任务中粗细化类别等级;三是双任务上的神经元激活情况。为了避免通过人为经验或者大量实验以选择合适的平衡因子,本文进一步提出了Risk-CNN模型,将有序性关系嵌入到分类任务中。基于贝叶斯风险规则,使用动态加权损失函数将类别信息和有序性信息进行融合。在两个不同的有序性数据集上,实验结果显示DTCNN和Risk-CNN都获得了非常有竞争力的性能。2.基于网格丢弃的图像有序性分类与理解图像有序性分类通常是给一张图片以有序性的离散标签。在实际的应用中,有序性的标签比较难获得,所以一般的有序性数据集都不够大,从而导致深度学习算法容易出现过拟合的问题。为了解决这个问题,许多的数据增强方法和神经元丢弃方法被提出,但是过拟合问题仍然十分严重。本文针对以上问题提出了一种网格丢弃的方法,随机地丢弃图片中的一些网格,以丢弃的图片作为训练样本。在学习过程中,将丢弃的网格位置也作为一种有监督的信息进行训练。最后,通过可视化类别激活图(CAM)来验证该方法的有效性,并发现网格丢弃的方法在模型学习过程中更多地关注在整个人脸区域。对于小数据集来说,网格丢弃的方法比神经元丢弃的方法更加有效,两者结合使用能达到最好的性能。在实验中,年龄估计的数据集Adience来验证了提出的方法的有效性。3.基于网格丢弃的多视角学习除了提出网格丢弃方法外,本文进一步发展了多视角的学习系统以提高模型的识别性能。一方面,提出了一个基于多视角最大池化(MVMP)的分类方法,其中每一张图片都以网格化的形式被随机地遮挡,以此产生多个视角的图片。另一方面,为了充分考虑有序性的关系,提出了一个基于多视角的最大池化的分类任务和基于平均池化的回归任务(MVMPAP),其中回归的任务有利于分类的任务。对比其他主流方法在Adience数据集上的结果,本文提出的两种方法获得了当前最好的性能。4.有序性视觉美学识别和理解视觉美学识别和理解是图像有序性估计的一个重要的应用问题。近几年,相比传统的使用手工特征和浅层分类器的方法,图像美学评估使用深度学习获得了非常好的性能。与识别问题类似,美学估计将图片按照美学属性划分成不同的等级。然而,受限于对美学的认知,目前还没有深入地理解为什么图片会呈现不同的美感,特别地,到底是图片的哪一部分有美感,美感的程度如何?事实上,大多数传统的方法都采用手工的特征来理解图片的美学和预测图片的目标/内容信息,但是在深度学习中,关于这一方面的研究较少。另外,美学估计是一个非常主观的评定,有时候很难给出一个非常明确的标签。这使得美学评估极容易导致不平衡的样本分布。为了处理这些问题,本文设计了一个端到端的CNN模型来同时执行图像美学分类和理解。为了应对不平衡的样本,提出了一种样本加权的分类方法,对重要程度不同的样本赋予不同的权值。事实上,将一些模棱两可的边界样本剔除也是一种特殊的样本加权分类方法。为了进一步理解深度CNN网络学到了什么,本部分在最后一个特征层上使用全局性的平均池化(GAP),以生成美学激活图(Aes AM)和属性激活图(Att AM)。美学激活图和属性激活图分别代表美学等级和美学属性在空间位置上的激活表现,特别地,Aes AM和Att AM主要考虑在深度学习模型中学到了什么。本部分采用公开的最大美学数据集AVA进行实验,并且获得了最好的性能。得益于Att AM,美学等级在内容上更有可解释性。最后,给出了一个简单的基于Aes AM的图像切割的应用。5.紧致的年龄估计模型年龄估计是图像有序性估计的一个重要应用。大量的研究比如Alex Net、Vgg Net、Goog Le Net、Res Net、Res Ne Xt、SENet等都侧重于在不同的数据集上提升性能,使得模型层数很深、参数量很多、计算量很大。然而,这些模型在实际应用中需要的存储和计算量太大,特别是对于一些嵌入式或者移动设备,难以满足实际需求。最近,Mobile Nets V1-V2系列和Shuffle Nets V1-V2系列相继被提出,用于减少模型的参数量、计算量和存储量,被称为轻量级的模型。但是这些系列工作对模型的性能有一些影响,往往只能在特定的数据上获得较好的效果,性能不够稳定。这主要是因为使用了可分离性卷积(Depth-wise separable convolution),打断了卷积操作中不同通道间的关联性,最终影响模型特征提取的能力。在本文中,针对小尺度图片和年龄估计问题,开展紧致性模型的设计工作。当给定一个数据集,如何设计一个实用的模型,使得该模型性能好、参数量和计算量少,刚好能适合该数据集,既不浪费参数也能获得较好的预测性能(既不过拟合也不欠拟合)。本章提出了一个紧致、高效、级联、基于周围环境的年龄估计模型C3AE。对比Mobile Nets/Shuffle Nets和Vgg Net系列工作,该模型分布仅需要约1/9和1/2000的参数量,但是能获得极有竞争力的结果。特别地,本部分将年龄估计问题进行了重新建模,提出了一种新的两点表示方法。通过该方法,能够得到一个只含两个非零元素的一维向量,并采用级联(Cascade)的方式将其嵌入到年龄估计网络中。另外,为了充分利用人脸周围的环境信息,提出了多支CNN网络,以更好地聚合多尺度的环境信息。在实验中,主要在三个不同的数据集WIKI-IMDB、MORPH II、FG-Net进行了测试,本文提出的方法获得了非常有竞争力的结果。"
1967,基于机器学习的结直肠癌预后模型及其泛化能力研究,"结直肠癌是世界范围内肿瘤相关死亡的主要原因之一,已严重威胁人们的生命健康,造成巨大的疾病负担。因此,为临床医生提供用于结直肠癌预后分析和治疗方案辅助制定的工具具有重要意义。数据驱动的预后预测模型被认为是提高结直肠癌预后预测准确性的重要工具。此外,模型的泛化能力,即利用训练数据学习获得的预后模型在面向更多医疗机构真实临床数据的应用中均能获得良好的预测效果,是预后模型在临床实践中应用的前提。然而,当前的预后模型研究停留于模型开发阶段,缺少模型的泛化能力验证与临床应用。因此,基于真实临床数据和机器学习方法,建立一个更精准的结直肠癌预后预测模型,提高预后模型的泛化能力和临床使用价值,使其能在更多医疗机构中应用并得到良好的效果,具有重要意义。本论文验证了结直肠癌预后预测因子的时间依赖和非线性效应,提出了基于深度学习的半监督多任务生存分析方法,有效提高了预后模型的准确性,并利用半监督逻辑回归方法来提高风险预测模型的泛化能力,促进预后预测模型在临床实践中的应用。论文主要创新点包括:提出了针对时间依赖和非线性效应的非转移性结直肠癌预后模型,比忽略时间依赖和非线性效应的模型更准确地预测了非转移性结直肠癌患者的预后风险,为临床医生预后分析和治疗方案选择提供决策支持工具。提出了 一种基于深度学习的半监督多任务生存分析方法,将生存分析问题转化为多时序点生存概率预测的半监督学习问题组成的多任务学习模型。提出利用半监督损失和排序损失处理数据删失和生存概率非递增趋势。同时,实现预后因子的重要性评估及其对生存结局影响的可视化。为临床复杂结构化数据预后生存分析提供了基于深度学习的有效方法。提出了基于半监督学习的预后模型泛化能力提升方法。充分利用无标签数据,基于半监督逻辑回归方法建立非转移性结直肠癌预后风险预测模型,并从判别能力、校准能力、泛化能力、可解释性和临床实用性等五个方面与监督学习方法比较,扩展了当前对不同模型泛化能力的认识,为临床预测模型的建立提供了参考。利用外部数据验证了该方法的有效性,为面向多中心真实临床数据构建具有应用价值的预后模型提供技术支撑。"
1968,基于机器学习的复杂噪声所致听力损失预测模型研究,"听力损失是全世界面临的重大公共健康问题。造成听力损失的最主要原因是噪声暴露。因此,充分挖掘噪声暴露大数据中包含的潜在价值从而准确评估噪声诱发的听力损失,对节约医疗成本和加强听力防护等具有重要作用。当前评估噪声引起听力损失的标准是国际噪声暴露标准(ISO-1999)。然而该标准的建立是基于20世纪50～60年代的稳态噪声数据,因而对噪声暴露类型不敏感,往往会低估复杂噪声造成的听力损失。此外,不能利用除能量之外的其他有效特征参量,成为限制该标准对复杂噪声所致生物效应做出准确预测的又一重要原因。数据驱动的机器学习方法可以充分利用数据包含的有效信息,因而基于噪声暴露大数据和机器学习算法,建立一个更精准的听力损失预测模型,以评估噪声暴露对听力危害的影响,具有重要意义。本论文从机器学习的角度研究复杂噪声暴露下听力损失预测新方法,提高听力损伤预测的性能。模型具有合理的听力学解释,并对听力损失预防及早期干预具有重要意义。主要创新点概括如下:针对复杂噪声所致听力损失预测,论文提出基于SVM、MLP、随机森林和AdaBoost的机器学习方法,有效利用复杂噪声数据中的潜在信息,建立了听力损失与损伤综合预测模型,并系统的对比分析了多种机器学习算法的效果。提出一种复杂噪声特性与个体特征融合方法,解决传统方法对噪声暴露类型的不敏感性问题,建立了听力损伤预测模型,预测性能显著优于现有行业国际标准。提出基于卷积神经网络的复杂噪声时序模型特征发现方法,捕获被处理成二维矩阵的噪声时序数据中存在的时间模式,建立了更精准的复杂噪声所致听力损伤预测模型。"
1969,地形因素影响下重庆市主要土壤的质地类型空间分布预测研究,"土壤质地是土壤的重要物理性质之一,不同质地的土壤,其孔隙度、通透性、热容量、保蓄性、温变和耕性等土壤性质不相同,影响土壤水分、养分、热量和空气的转化,是水文模型、陆面过程模型和耦合陆面过程大气模型的重要输入变量。重庆市位于我国内陆西南部,地形地貌复杂,全市约98%的土地为山地和丘陵,土壤质地类型具有较强的空间异质性。土壤质地类型测定方法主要有两类,精度最高的是实验室法,其通过对土壤粒径进行检测,并结合土壤质地划分标准,确定土壤质地类型,但这种方法时间成本和经济成本较高,通过该方法获取大尺度上的土壤质地类型数据较为困难。实际研究中,通常采用的是手测法,其被认为是一种适合于替代实验室法判定土壤质地类型的方法,根据土壤物理机械特性(粘结性和可塑性)的表现程度来确定土壤质地类型,一般可分为粘土、壤土和砂土三种类型。在更大尺度上,经典统计学和地统计学模型虽然可以进行土壤质地类型预测,但其误差不容忽视,不能很好的满足相关研究的需求,尚缺乏适宜在小流域尺度进行土壤质地空间分布预测方法。在成土母质和人类活动相对一致的条件下,地形因素显著影响土壤质地的空间分布。为此,基于有限的土壤质地样本,建立地形因素与土壤质地类型的相互联系,分析确定适合不同区域的最优预测模型,以快速、低成本地获得土壤质地类型空间分布数据,可为当前研究区水分循环模拟和农业生产规划等提供依据和数据支持,也可为其他小流域开展土壤质地类型空间分布预测提供方法借鉴,对于提高相关研究结果的准确性具有重要科学意义。本文根据重庆市主要土壤成土母质形成的土壤类型,兼顾主要的地形地貌特征(山地、丘陵),选取四种土壤类型(黄壤、石灰岩土、中性紫色土和石灰性紫色土)所在的典型小流域作为研究区,提取相关地形指数,综合运用支持向量机-多项式、支持向量机-高斯半径、人工神经网络、分类树和随机森林五种机器学习算法,开展地形因素对土壤质地类型空间分布影响研究,探究各研究区的最优预测模型;在此基础上,引入坡耕地类型变量(坡地、梯地)反映人类活动对微地形的改变,研究其对土壤质地类型空间变化的影响;利用不同时相遥感数据(陆地卫星Landsat 5和Landsat 8)提取归一化植被指数(NDVI),探讨采用一对一、一对多和混合分类策略,以及地形因素、成土母质和NDVI多种数据组合下,进行土壤质地类型空间分布预测的最佳分类策略和数据集组合。研究结果表明:(1)不同类型母质发育的土壤,其质地构成有明显差异。在成土母质为三叠系须家河组砂岩的黄壤小流域,共采集495个土壤样本,粘土、壤土和砂土的样本数分别为11、445和39个,其比例分别为2.2%、89.9%和7.9%;在成土母质为三叠系大冶组灰岩的石灰岩土小流域,共采集537个土壤样本,粘土、壤土和砂土的样本数分别为52、409和76个,其比例分别为9.7%、76.2%和14.1%;在成土母质为侏罗系沙溪庙组砂泥岩的中性紫色土小流域,共采集727个土壤样本,粘土、壤土和砂土的样本数分别为131、341和255个,其比例分别为18%、46.9%、35.1%;在成土母质为侏罗系遂宁组砂泥岩的石灰性紫色土小流域,共采集3636个土壤样本,粘土、壤土和砂土的样本数分别为1872、1764和0个,其比例分别为51.5%、48.5%和0%。这进一步说明,成土母质显著影响着土壤质地类型的构成。(2)不同的土壤质地类型有其对应的强关联地形指数。粘土主要分布的区域,海拔(Elevation)较低,地形湿度指数(TWI)和谷底平整度多分辨率指数(MRVBF)较高;壤土主要分布的区域,Elevation和脊顶平整度多分辨率指数(MRRTF)较高、坡度(Slope)较小;砂土主要分布的区域,其Slope、矢量稳健性测度(VRM)和流道长度(Flow_PathL)较高,TWI较低。研究发现,MRVBF和MRRTF在识别粘土和壤土时,有较强的指示作用。(3)运用机器学习模型均可利用地形因素进行土壤质地类型预测,但精度有所差异。黄壤和石灰岩土小流域(中低山区)的最佳模型是支持向量机-多项式(C=90、P=3),总体精度和Kappa系数分别为0.943和0.79;中性紫色土小流域(丘陵区)的最佳模型是随机森林(mtry=3、ntree=500),总体精度和Kappa系数分别为0.656和0.601;石灰性紫色土小流域(丘陵区)的最佳模型也是参数一致的随机森林,总体精度和Kappa系数分别为0.43和0.20,虽然预测精度有所下降,但都达到了显著性要求。应用各研究区的最佳模型制作了土壤质地类型空间分布预测图,总体而言,支持向量机-多项式模型和随机森林模型表现出更好的预测精度。(4)影响土壤质地类型分布的地形指数存在差异性。通过研究区的最优预测模型计算得出,在黄壤和石灰岩土小流域,Elevation、低地地形分类指数(TCI_Low)和Flow_PathL对土壤质地类型分布预测的相对重要性大于70%,按重要性从高到低排序为,Elevation>TCI_Low>Flow_PathL>VRM>坡高(Slope_Heig)>TWI>Slope>坡长(Slope_Leng)>汇流动力指数(SPI)>MRVBF>MRRTF;在中性紫色土小流域,Elevation是最重要的影响因子,VRM、Slope_Heig和TWI的相对重要性在30~52%之间,排序为Elevation>TWI>Slope_Heig>VRM>MRRTF>TCI_Low>SPI>Flow_PathL>Slope>Flow_Accum>Slope_Leng>MRVBF;在石灰性紫色土小流域,Elevation的相对重要性最大,其次是TWI,相对重要性达到了89.9%,坡度相关指数(Slope和Slope_Height)以及MRRTF的相对重要性介于65.1~71.2%之间,排序为Elevation>TWI>Slope>Slope_Heig>MRRTF>MRVBF>VRM>Flow_Accum>SPI>Flow_PathL>Slope_Leng。(5)地形因素和人类活动对土壤质地变化有较大影响。在石灰性紫色土小流域,以坡耕地类型(坡地和梯地)代表人类活动的强弱进行了调查,样本数分别为2502和1134个,将坡耕地类型变量引入随机森林模型进行计算,整个研究区的总体精度和Kappa系数分别为0.66和0.31,较原最优模型的总体精度和Kappa系数(0.60和0.20)分别提升9.8%和55%,显著提升了模型预测精度。分别研究地形指数对坡地和梯地中土壤质地变化的影响,对应的预测模型总体精度和Kappa系数分别为0.64、0.27和0.69、0.24。计算结果显示,坡耕地类型(坡地、梯地)显著影响研究区土壤质地类型变化;单独对坡地而言,TWI和Slope_Heig的相对重要性大于90%;单独对梯地而言,Elevation是影响土壤质地类型变化的最重要变量。(6)遥感数据能够辅助地形因素进一步识别土壤质地类型。在黄壤和石灰岩土小流域,利用不同时相遥感数据(陆地卫星Landsat 5和Landsat 8),选取能代表春(Day Of Year,DOY 116)、夏(DOY 244)、秋(DOY 284)、冬(DOY 351)四个季节的遥感影像数据,使用ENVI完成辐射校准和大气校正的预处理,通过计算得到NDVI,并采用分类树(父节点=3、子节点=1、树深=5)进行土壤质地类型空间分布预测。结果表明,一对一分类策略下,独立应用NDVI的模型总体精度和Kappa系数分别为0.939和0.781;独立应用地形指数和成土母质的模型总体精度和Kappa系数分别为0.935和0.764;综合应用NDVI加上地形指数和成土母质组合为输入数据的模型更优,其总体精度和Kappa系数分别为0.975和0.918,对粘土、壤土和砂土的识别改进分别为144%,0%和14%。这说明在使用地形指数和成土母质进行土壤质地类型预测的基础上,能够通过引入NDVI提高从壤土和砂土中识别粘土的准确性,并确定9月1日为本研究区进行土壤质地类型空间分布预测的最佳遥感时相。"
1970,基于机器学习的推荐算法研究与应用,"推荐系统作为一个处理信息过载的有效解决方案,近年来,被广泛应用于各个领域中。然而,大规模的用户和物品使推荐系统的在线推荐变慢,从而使推荐陷入低效的瓶颈。快速检索的哈希技术,成为解决在线推荐效率瓶颈的一个有效方案。目前存在两种基于哈希的推荐算法,第一种是基于二阶段量化的哈希算法。第二种是基于学习的哈希算法。前者的缺陷是过度简化了离散优化问题,导致大量信息损失,使推荐精度受到较大影响;后者的缺陷是针对推荐系统所建立的离散优化模型与推荐系统的终极目标不一致,以及利用离散坐标下降算法的时间复杂度较高,使更新推荐系统的开销高。为解决上述问题,本文分别对以上两种哈希算法进行了深入的研究,主要贡献总结如下:首先,为解决基于量化的哈希算法中由量化过程的信息损失导致的低精度推荐问题,本文提出了一种新的二阶段量化方案:基于量化的哈希算法(QBH),它包括相似度量化和模长量化,这种更精细的量化方法在很大程度上降低了量化过程的信息损失。本文通过QBH得到的哈希码建立两种不同的偏好预测模型:基于内积保持的哈希推荐算法(QBH_1)和无约束的偏好保持哈希推荐算法(QBH_2)。其中内积保持的哈希推荐算法中,受矩阵分解算法中用内积预测偏好的启发,设计了一种内积保持的偏好预测模型,并学习最佳的模长量化维度,减少信息损失,使基于量化的哈希算法的推荐精度得到较大提高;在无约束偏好保持的哈希推荐算法中,首先在无其它约束条件的矩阵分解模型下学到用户和物品的实数向量,然后对其相似度和模长分别进行量化,并根据相似度量化的结果,以最小化量化损失为目标学到模长量化的最佳维度,然后通过QBH方法分别对相似度和模长进行量化,从而减小量化过程的信息损失。其次,为了进一步降低哈希算法中的信息损失,从而提高推荐精度。本文提出一种基于学习的哈希协同过滤算法:离散偏好排序算法(DPR)。该算法将用户对物品的隐式反馈,建模为一个以排序损失为目标的推荐模型,该目标与推荐系统的终极目标一致:为用户提供一个个性化的物品排序,因此能够提供更准确的推荐。此外,为了得到紧凑且信息丰富的哈希码,本文将平衡约束和无相关约束加在哈希码上,采用交替迭代优化算法,将原问题转化为一系列混合整数规划子问题求解,并利用离散坐标下降算法学习用户和物品的哈希码。该算法通过设计一个与推荐系统目标一致的目标函数,并利用离散坐标下降算法直接学习离散优化问题,与基于量化的哈希推荐算法和以评分为目标的哈希学习算法相比,很大程度上降低了信息损失,使推荐精度得到较大提高。然后,为了解决推荐系统中数据稀疏和冷启动问题,本文提出了两种基于学习的哈希混合推荐算法:离散深度学习算法(DDL)和离散按对排序的哈希算法(DPH)。具体地,本文首先通过深度学习从内容数据中预先学习出物品的有效特征,然后将学到的特征转化到协同过滤目标的学习任务中,因此提出的DDL和DPH可以有效缓解由数据稀疏和冷启动导致的低推荐精度的问题。并对用户和物品的哈希码添加平衡和无相关约束,采用交替优化算法学习哈希码并微调深度网络,最终得到用户和物品的紧凑且信息丰富的哈希码,DDL和DPH作为一类高效的混合推荐算法,有效地解决了协同过滤算法中的数据稀疏问题和冷启动问题。最后,本文提出了一种基于整数规划的哈希学习算法:离散排序的矩阵分解算法(DRMF)。之前基于学习的哈希推荐算法通常采用按位迭代的离散坐标下降算法求解。由于离散模型的非凸和非连续性,离散坐标下降算法很容易陷入局部最优解。DRMF通过求解一系列二元二次规划(BQP)子问题,以向量的方式更新用户和物品的哈希码。值得注意的是:它在每次迭代中更新整个哈希码而不是只更新哈希码中的某一位,与离散坐标算法的按位更新方式相对应,我们称这种更新方式为按块更新,这种按块更新的哈希学习算法有效避免了模型陷入局部最优。此外,在DRMF模型的学习过程中加入自步学习,使模型从一个更好的初值开始迭代,进一步避免模型陷入局部最优,使推荐精度得到较大的提升。"
1971,同态加密关键技术研究,"科学技术的不断进步,带动信息化产业的迅速发展,云计算与大数据技术已经在人们生活中的各个领域得到广泛应用。目前云计算对于用户数据的处理方式一般是用户使用云计算平台将数据存储传输到云端,云服务商对用户的数据进行加密处理。用户使用数据的时候再将加密后的数据取回进行解密,云服务商不能对密文有任何变换,否则不能解密成正确的明文。同时,云服务商并不是完全可信,近年来隐私数据泄露事件频频发生。最佳的设想是充分利用云服务商的强大计算能力,对密文进行处理,如同对明文进行相应的处理一样,即密文可在云端上直接进行运算处理,同时保证能够解密为相应处理后的明文,而这就是同态加密的概念。尽管同态加密算法在构造上取得了重大进展,但是同态加密的计算开销过于庞大,这制约了其实用化的进程。虽然已有很多优化改进算法来推进同态加密的研究进程,但仍然存在着公钥开销过大、算法效率较低等不足。为此,本文把解决同态加密计算过程中公钥开销过大问题作为主要研究目标。另一方面,云计算环境下实际应用中的大数据安全和隐私现状亦不乐观,本文同时对网络编码污染攻击、数字图像隐私泄露以及机器学习的隐私保护等应用方面亟待解决的问题也进行了深入研究,取得主要研究成果如下:1.针对目前整数上的同态加密算法公钥开销过大的问题,提出一种基于PAGCD的较短公钥全同态加密算法。先构造一个部分同态加密算法,采用压缩解密电路技术使得算法具有自举性,从而构造出整数上的全同态加密算法。将公钥转化为二次形式,在语义安全性不变的情况下减少公钥开销。理论分析表明本算法与以前原始算法相比公钥尺寸较小,算法的效率显著提高。2.针对网络编码中数据易受污染攻击的问题,提出一种混合同态签名的网络编码抗污染攻击方案。首先,采用有向多重图的源节点、非源节点集和链路集对无线网络编码过程进行模型构建,并考虑数据污染攻击和标签污染攻击两种类型的污染攻击建立网络抗污染模型;其次,利用消息认证码、动态消息认证码以及同态签名方案,建立混合型的同态签名方案,实现对抗污染攻击模型的消息验证过程的改进,保证了每个消息编码数据包内容的完整性,并提升了算法的安全性能;最后,通过在基于自适应安全网络编码传输机制的实验模拟环境下对被污染节点百分比、流量累积分布和计算效率三个指标的实验对比中,验证了方案的安全性能。本文方案针对无线网络抗污染攻击中编码数据包易被窃取、篡改和污染的问题提出了一种新的思考方式。3.针对医学图像在网络传输中用户隐私易被泄露的问题,提出了一个基于全同态加密的医学图像信息隐藏方案。基本原理是,首先使用异或-置乱加密方法得到密文图像,然后对原始医学图像像素分类比特流和用户私密信息同态加密,将它们的密文进行同态操作并嵌入加密图像得到隐秘图像。为了保证接收方得到完整的隐秘图像,使用本文设计的网络抗污染攻击模型进行传输。实验结果表明,所提方案可以满足隐私保护和医学图像的完整性。4.针对云计算环境下医学图像隐私泄露的问题,提出了一种基于极限学习机的隐私保护全同态加密方案。在通用密文检索模型条件下,设计了一种由用户、加密服务器、密文索引服务器和分析服务器组成的四方参与模型。考虑到数据完整性,用户传输数据给加密服务器的过程中使用本文设计的网络抗污染模型。方案对医学图像数据集进行训练,实验结果表明,与其他的方案相比,本方案提出的隐私保护极限学习机具有较高的准确度。本文通过改进整数上的全同态加密算法,并利用改进的算法针对网络污染攻击、医学图像隐私泄露、机器学习隐私保护等关键问题提出了相应的解决方案。理论分析和实验结果表明,在本文研究的网络抗污染攻击模型下,采用现有的评价标准,所改进的全同态加密方案,在医学图像隐私保护和医学图像密文检索应用中均具有较好的效果。"
1972,基于机器学习的激光诱导击穿光谱应用于金属受热面失效检测的研究,"随着国民经济快速发展,电力、冶金、化工、机械等行业高效稳定的发展与运作成为现代化建设重要的基础,同时也有越来越多的关键高温承压热力设备在各行业生产中被投入使用。这些高温承压热力设备的运作安全性与可靠性便成为了直接影响生产安全与经济效益的决定性因素之一。高温承压热力设备的金属受热面材料在长期的服役过程中,因其所处的恶劣环境,其运行安全和服役寿命会受材料金相结构和力学性能的变化所影响,发生金属材料的老化现象。传统的受热面检测方法需要对受热面进行切割以进行离线分析,而目前现有的无损检测技术手段主要是针对已有宏观缺陷的检测与判断,所以非常有必要发展一种具有快速实时无损检测特点,又具备在缺陷出现前进行失效趋势预测能力的新技术。激光诱导击穿光谱(Laser-Induced Breakdown Spectroscopy,LIBS)是一种新型的原子光谱技术,其除了具有快速的多元素检测能力之外,还能反映待测对象的材料基体特性。因此本文致力于将激光诱导击穿光谱技术应用于金属受热面失效检测中,将此光谱技术与机器学习技术结合,针对不同失效程度的金属受热面材料的光谱数据特征展开了对激光诱导等离子体时空演化特性、基于机器学习的金属失效预测模型建立和光谱的特征选择的理论和实验研究。本文在对现有的金属受热面失效检测分析方法的技术水平和研究现状的进行了深入分析的基础上,对具有代表性的金属受热面检测方法进行了介绍,阐述了本文的研究背景和意义。此外,对目前LIBS结合机器学习的研究进展进行了阐述和总结,对LIBS应用于材料特性检测领域的研究的发展过程与现状进行了归纳与介绍。然后在此基础上明确了本文的研究路线与内容。同时,对LIBS技术的原理及其光谱特性和代表性的金属受热面材料T91和12Cr1MoV钢的失效机理进行了详细的阐述和总结。设计并搭建了可实现对等离子体图像信号时空演化特性进行高精度分析的实验系统。将基于机器学习的各类数据分析方法引入了LIBS的应用中,在对其的数学原理和计算过程进行了归纳阐述后,结合具体的实验应用研究证明了聚类分析、数据降维、分类模型和特征选择方法在LIBS应用上的潜力。为了深入研究LIBS金属受热面失效检测的物理机理,利用增强电荷耦合器件(ICCD)光谱仪对不同老化等级的T91钢的等离子体图像及特征谱线的时空演化规律进行了观察与分析。对比和分析了不同老化等级样品的特征谱线辐射图像与强度、谱线强度比值和等离子体温度的时空演化规律以及激光烧蚀坑特性,建立了以上等离子体特性与金属老化等级之间的关联性,并讨论了其物理机理和对实际应用的意义。分析了在普通电荷耦合器件(CCD)光谱仪上对不同老化等级T91钢进行点阵测量的光谱特性,引入支持向量机(SVM)建立金属老化预测模型,并针对实际测量中的光谱信号波动与激光脉冲数的问题对模型进行了优化,且对预测模型进行了鲁棒性分析,验证了SVM金属老化预测模型的稳定可靠性和泛用性。针对金属样品在LIBS中呈现出的高维复杂光谱数据,对比了几种具有代表性的特征选择方法在不同晶粒度等级的12Cr1MoV钢和不同老化等级的T91钢的光谱数据上的表现,并提出了一种新的波长区间分层迭代筛选方法(LIW)。同时利用基于SVM和逻辑回归(LGR)所建立的金属特性预测模型对这些特征选择方法的有效性进行检验,证明LIW特征选择方法拥有最佳的表现。此外引入了数据异常检测对LIBS测量中离群数据点进行剔除,利用主成分分析法和K均值聚类算法实现对LIBS测量样本的宏观数据特征分析。上述研究为LIBS测量的自动数据处理建立了一套具有系统性和泛用性的方法论,同时为基于LIBS技术的金属受热面失效预测分析应用提供了更深刻的理论基础和实践依据。"
1973,基于云服务平台的智能交通关键技术研究,"智能交通系统(intelligent transportation system,ITS)不仅需要合理的公交线网规划,还需要对公交客流进行精准的、实时的预测,适时对公交运营调度进行调整和优化,为市民提供实时、准确、有效的公交出行服务,实现公交资源动态配置优化,节约市民出行时间,有效缓解交通拥堵,从而达到绿色环保出行的目的。短时公交站点客流预测是调整公交发车频率,优化公交调度资源的重要依据。而公交调度是一类复杂的组合优化问题,需要对客流量、发车间隔、到站时间、停靠时间、公交车投放数量进行整体优化。针对这些问题,主要围绕公交公司的运营成本与乘客的满意度为主要指标,通过对调度优化模型的训练,实现无监督学习的实时公交动态调度,提升公交的整体服务水平。因此,研究公交短时客流预测、公交到站时间预测和公交动态调度具有重要的现实意义。针对城市公交客流存在随机性、时变性和不确定性的问题,提出了基于无监督特征学习理论和改进卷积神经网络的短时公交站点客流预测,为市民提供实时、准确、有效的公交出行服务。为了防止和减少过拟合的出现,运用改进的卷积神经网络预测训练方法构造一个高效高可信度的模型预测系统,在训练过程中,使用Adam算法的优化器对模型进行优化,更新网络模型参数,为自适应性学习率设置不同的参数。利用公交客流算法模型对广州实际公交站点的客流进行预测,该模型预测精度更准确、可靠性更高,说明本文所提出的方法预测误差更小,实例证明改进的模型和算法具有实用性、可靠性。通过实时提供公交车辆到站时间,有利于出行决策,可合理选择乘坐公交,缓解公交车辆的拥挤程度,是未来智能公交到站时间预测重要的研究方向。以预测的公交到站时间为基础,可以合理调整公交车辆的运营调度,提升公交运营管理水平。针对预测的精度和效果进行了比较和评价,基于聚类分析的曲线匹配预测模型相比曲线匹配预测模型,公交到站时间的预测精度更高、效果更好,减少了乘客候车时间,提高了公交调度运营效率。实验结果表明,该模型能较好地满足预测所需要的精度和实时性要求。通过对公交发车准点率、公交停站时间、公交到站时间间隔进行评价分析,这三项指标在高峰时段明显降低,在公交车辆实际运行过程中,由于道路交通状况的复杂性以及公交客流存在随机性、时变性和不确定性等原因,公交车辆不可能完全按照行车计划、车辆调度计划行进,导致了公交断班问题的发生。本文提出了无监督学习的实时公交动态调度方法,正是为了解决公交断班问题,确保公交按照行车计划、车辆调度计划执行,提升公交调度发班质量与运行效率。因此,公交发车准点率、公交停站时间、公交到站时间间隔是公交调度的基础,这三种评价结果是制定公交调度排班计划的重要保障,是建立公交调度模型、优化公交调度方案的重要依据。针对广州智能公交调度的优化问题,提出了基于无监督学习的实时公交动态调度算法应用到该问题中,结合乘客利益和公交公司利益总体最优为目标,通过无监督学习的方法对公交客流出行特征表达进行提取,利用吸引子传播聚类算法的优化数据集与支持向量机的训练样本集相结合建立预测模型训练,运用公交线网发车间隔和加权系数的目标函数优化调度模型,将多源信息融合及多策略的实时公交动态调度算法引入到求解模型中,实现调度优化模型的实时调整。通过实例证明模型和算法具有实用性和可靠性。本文是在智能交通云服务平台的基础上,运用机器学习关键技术,实现智能公交客流预测、公交动态调度,并与智能交通系统进行对接。以Cloudstack构建智能交通云计算基础设施平台,具备良好的资源伸缩特性,提供云主机服务和弹性块存储服务。提供不同资源配置的云主机,同时提供云主机之间私有互联;提供各种配置大小的弹性块存储,满足对公交客流、公交调度数据存放的需求。提供云主机服务,其上层可以运行各种各样的应用;由于提供弹性块存储服务,其上层可以根据需求分配不同容量的存储服务。通过上述研究,公交短时客流预测、公交到站时间预测与公交动态调度的内在作用机理复杂,本文建立的模型旨在提高系统的性能和运行效率,提高公交线性规划、公交动态调度设计及运行方案的科学性,为解决重大工程应用领域中的交通拥堵、出行难问题提供理论指导和数据支撑。"
1974,面向异构特征空间的迁移学习研究,"随着信息技术的飞速发展,机器学习技术在诸多实际问题中得到了成功的应用。传统机器学习假设训练数据与测试数据服从同样的分布,且需要充足的训练数据来学习高性能的分类器。然而,由于数据收集和标注的昂贵成本,问题领域中可能只有少量有标签的训练数据。为了解决问题领域(即目标领域)中的数据稀缺问题,研究者提出了迁移学习技术,将从相关领域(即源领域)中挖掘到的知识迁移到目标领域中。由于源领域和目标领域的数据分布不同,利用源领域数据对目标领域中的分类任务进行辅助是一个非平凡问题。在源领域和目标领域拥有不同的特征空间的问题中,领域之间的知识迁移变得更加困难,这一问题被称为异构迁移学习。为了利用异构源领域中的知识来提升目标领域中分类问题的精度,本文对异构迁移学习进行了系统的研究。本文的主要贡献总结如下:1)提出了一个在线集成迁移学习算法,利用多视图共现数据来衡量异构数据实例之间的相似度,并对源领域和目标领域中构建的预测函数进行结合,同时对算法的预测错误上界进行了理论分析。2)提出了一个在线多视图学习算法,利用多视图共现数据对两个领域的数据进行特征扩充,并学习一个在线多视图分类器,对两个领域中的数据进行分类,同时对算法的预测错误上界进行了理论分析。3)提出了一个基于典型相关分析的联合学习模型,寻找能够最大化源领域和目标领域数据相关性的领域共享特征子空间,同时学习一个能够最小化训练数据经验损失的分类器。4)提出了一个半监督最优传输模型来挖掘源领域和目标领域数据中隐含的几何信息,并将源领域数据传输到目标领域中,使得目标领域数据和传输后的源领域数据服从类似的分布。5)针对数据不平衡的问题,提出了一个基于最优传输理论的数据过采样算法,从少数类别数据中挖掘几何信息,使得过采样方法合成的少数类别数据与真实的少数类别数据服从类似的分布。"
1975,基于多源数据的公交客流预测及公交运营时段划分优化研究,"公交系统是一个相对开放的系统,影响公交运营的因素众多且复杂,其中公交系统的内部影响因素包括公交客流波动,车队车辆配置情况,调度方案的执行情况等,外部影响因素包括工作日节假日属性,气温,天气,道路交通状况等不可控因素。这些因素都以不同的方式影响着公交的运营过程,公交管理者需要根据这些因素的变动,不断优化自身的运营策略。以往的公交管理精细化程度较低,公交管理方案的提出与改变过程一般由专家经验驱动而非数据驱动。近年来随着基础设施的完善,大型城市每日可以产生数以千万计的乘客出行记录和公交车辆行驶记录。越来越多的公交数据可以为公交管理部门提供决策参考。对于客流量总量巨大,客流波动情况复杂,道路情况复杂的市区内部线路来说,行车计划基本很难准确实施。上述影响因素对公交系统的随机影响应该尽量降低,从而在源头上为公交系统的鲁棒性优化和实时控制过程提供一组较为稳定的环境变量。使这些变量变得更加稳定的主要策略有两种,一是对这些变量进行更加准确合理的预估,为计划层提供最优的参数设置,二是采用分而治之的思想,在上述最优参数预估的基础上,将公交运营时段进行合理的划分,使得每个运营时段内有着尽量准确稳定的运力供需状态,方便公交管理者选用最优的运营策略。本文分别对线路客流预测,最大断面客流预测,公交运营时段划分,公交运营时段划分与车队配置协同优化四个方面做了深入的理论研究。针对线路客流的准确预测问题,本文提出了一个考虑乘客行为模式的线路客流预测新方法。传统的客流预测方法均以时段客流总量为模型输入,忽略了不同类型的乘客对于外在影响因素变动的响应模式差异,忽略了不同类型乘客量波动的时变规律差异,本文针对此缺陷,提出了一组公交乘客分类的方法并论证了乘客分类预测对提高线路客流预测精度的必要性,在分析分类客流预测问题特性的基础上提出了一个新的混合机器学习模型,此模型充分挖掘了不同类型客流对外在影响因素变动的响应模式和不同类型客流内在的时变规律,相比于传统的集计预测模型,大幅提高了线路客流量的预测精度。针对最大断面客流预测问题,本文在深入分析最大断面客流预测误差对运营风险的结构性影响的基础上,提出了一个基于报童模型的最大断面客流预测模型。传统的断面客流预测问题均将此预测问题抽象为简单的数值型预测问题,忽略了最大断面客流对运营风险成本的实际影响,本文根据实际的公交运营参数,计算了最大断面客流预测误差在不同范围内对运营风险成本的增长的影响,并以运营风险成本最小化代替了传统预测方法中追求绝对误差最小化的损失评价函数。另外,本文选用并改进了预测稳定性和精确性均较高的Shepard插值预测模型,使之适用于本文所解决的基于报童模型的预测问题,取得了预测性能较优的最大断面客流预测模型。针对运营时段划分问题,针对公交运营时段划分问题的研究比较初步,现有的公交运营时段划分问题一般均以追求单一运营参数(如乘客需求或者公交行程时间)在时段内差异最小化为目标。此类研究均忽视了这些运营参数对公交运营优化工作的联合作用。本文深入分析了时段划分对公交运营优化的实践意义,深入分析了传统研究的不足之处,提出了一个以时段内部运力需求为指标,以多源公交数据为基础的优化环境变量计算框架。在此框架的基础上,以车队车时成本最小化为优化目标建立了时段划分优化模型并取得了良好的运营时段划分效果。通过对时段划分问题的深入研究,本文发现时段划分问题与车队配置问题有着密不可分的相互关系,在此基础上提出运营时段划分与车队配置方案的协同优化模型。前文通过对传统运营时段划分问题的深入研究,本文发现运力需求是一个较为合理的时段划分指标,但同时,运力需求也是一个复杂的概念,其包含了最优车型选择,车队规模优化两个重要的子问题,当把这两个子问题考虑进公交运营时段划分问题中时,问题变得更加复杂:时段划分方案和最优车队配置之间相互影响,共同决定着整条线路全天的运营成本。基于此,本文创新性的对运营时段划分和车队配置进行了协同优化。在成本计算过程中,依然利用了大量多源公交数据对全天的环境变量进行了计算,另外,还利用报童模型对不同车队配置的运营风险进行了深入分析与计算。在此基础上,本文以全天运营成本最小化为目标,建立优化模型对运营时段划分和车队配置进行了协同优化,并取得了良好的运营时段划分和车队配置优化方案。"
1976,生成对抗网络的改进方法与超分辨率图像重建研究,"自2014年生成对抗网络被提出以来,就受到了众多学者的高度关注和广泛研究。随着更多深度学习网络结构和优化技术的提出,生成对抗网络在理论和应用上也取得了很多的研究成果。尽管如此,生成对抗网络模型收敛的条件、如何稳定训练和提高生成图像的质量等关键问题仍然是一个具有挑战性和开放性的课题;如何更好地将对抗式的训练方法应用到像素级图像处理任务,比如图像超分辨也是一个值得深入研究的问题。本文针对生成对抗网络训练不稳定、梯度消失、模式崩塌以及其在超分辨图像重建的应用等关键问题进行了研究。对混合模型和标准模型提出了多种改进方案,提高了模型训练的稳定性和生成图像的质量;提出了一个新的单图像超分辨模型,通过引入自注意力、密集连接和对抗训练的方法提高超分辨图像的全局一致性和纹理清晰度。本文的主要研究成果概括如下。针对边界平衡生成对抗网络生成图像多样性不足、类噪声区域多、不平滑等关键问题,提出了一种简单而有效的方法。该方法为判断器增加降噪损失,提高判断器区分真实数据和生成数据的能力,使生成的人脸图像更加光滑;为网络增加批归一化,使生成的图像特征更加丰富;同时评估了不同方法在边界平衡生成对抗网络框架上的效果;并且通过空间一致性实验证明了生成器的泛化能力。针对标准生成对抗网络训练不稳定、生成器无梯度优化、生成图像多样性不足等关键问题,本文提出了两种简单有效且易于实现的方法DRRGAN和GAN-RL。DRRGAN通过为判断器增加一个特征输出作为生成器解噪真实数据的输入和潜在代码的重构,使整个网络可以学习到真实数据分布的一些特征信息,因此能改进标准生成对抗网络的性能,生成质量更好的图像。GAN-RL的生成器利用判断器学习到的特征来重构真实数据,能提高判断器学习数据特征和生成器生成每一种模式的能力。GANRL具有能提供稳定的梯度信号、对超参鲁棒、并能与其他正则方法相结合以改进其性能的优点。针对仅由像素损失生成的超分辨图像过于平滑和纹理不清晰等问题,本文利用对抗式训练方法生成了纹理更自然和真实的高分辨率图像。为充分提取低分辨率图像空间的特征和减少模型增大感受野对深度的依赖,所提模型DSSA_GAN为其生成器引入残差组之间密集连接和自注意力机制。生成器首先由像素损失预训练,然后引入对抗训练的方法,从而使判断器更加专注于真假图像之间的纹理判断,生成更真实的高分辨率图像。本文所提的方法均在相关的数据库上进行实验验证。实验结果表明针对边界平衡生成对抗网络的改进方法提高了训练稳定性;针对标准生成对抗网络的改进方法DRRGAN和GAN-RL不仅训练速度快,效率高,引入的计算负载少,而且能应用到多种网络结构上。在多个标准测试集上通过多种评估方法检验所提的超分辨模型DSSA_GAN的性能,实验结果证明了所提模型的有效性。本文的研究成果为生成对抗网络的理论研究和性能改进提供了思路,对对抗训练在图像超分辨上的应用具有指导意义。"
1977,多标签及多实例数据的分类模型算法研究,"随着手机、数据中心服务器以及庞大的互联网服务技术的发展,人工存储和处理数据的能力不断攀升,导致存储在各地的信息量的巨大增长,利用自动化系统高效地进行分类和标记这些信息变得越来越迫切,使得机器学习越来越重要。传统的机器学习中使用的是单实例单标签的数据假设,随着数据结构的复杂化,该假设已经不再适用于现实生活中。多标签学习中一个实例可以对应着多个标签的前提条件和多实例学习中多个实例对应一个标签的前提条件的出现更好的适应了现实生活中的场景。加强多标签学习和多实例学习的研究,对进一步促进机器学习发展,增强算法的实用性和提高模型效率等方面具有重要的意义。本文在已有的多标签分类和多实例分类的基础上,针对学习领域中发现的问题展开研究,主要工作如下:一、考虑到目前多标签数据集中数据不平衡问题。为了解决这个问题,我们提出了一个利用标签相关性的算法模型MLCI(multi-label learning model based on label correlation and imbalance)缓解多标签数据分布不平衡问题。模型通过耦合其他标签,将多标签数据集重构成多类别数据集,有效地避免单独处理海量的潜在子标签集合,减少了多标签数据集中标签不平衡的现象。同时,为避免过度依赖标签间相关性的影响,保持少见标签的独有性,模型还针对每个标签构建相应的二元分类器,以挖掘每个标签的特性,最后通过集成分类器,进行多标签数据的预测。本文提出的MLCI模型有效地缓解了数据集中复杂的标签不平衡问题,从理论分析和实验验证显示出MLCI的高效性。二、在多标签学习中,为进一步缓解标签问题为算法模型带来影响,提升多标签分类算法的性能,本文将迁移学习引入,提出了一个多标签度量迁移学习模型。该模型通过迁移学习的理念,利用实例的权重作为训练领域和测试领域分布的桥梁,缓解多标签数据集中不同领域之间同时出现的标签分布和实例分布不同的问题,为多标签分类的迁移学习打下基础。三、为了更好地挖掘多标签数据中标签空间内在的几何信息,本文在基于迁移学习的基础上,加入了度量学习,改良多标签迁移学习模型为MLMTL(multi-label metric transfer learning)。该方法在缓解领域间分布不同的问题后,还有效地保留了特征空间和标签空间的固有几何信息,在解决标签和实例双重分布不同问题的同时,提升了算法的性能。四、针对多实例学习中存在的分布不同问题,本文根据多标签度量迁移学习算法中应用到的技术基础进行技术拓展,提出了一种多实例度量迁移学习MIMTL(multi-instance metric transfer learning),缓解多实例数据中不同领域之间包级别分布不同的问题。模型利用度量迁移学习给训练领域中的多实例数据集中的包添加权重,构建两个领域之间包分布的桥梁。模型制定新的学习原则,用来调节类内和类间的参数,以此放宽严格的约束条件,然后利用加权包数据构建模型,解决了多实例学习模型中常见的参数过多的问题,并且提升运算效率。"
1978,嵌入式系统安全可信运行环境研究,"随着嵌入式系统的应用领域不断扩大,其重要性越来越凸显,同时因为网络连接的便捷性,网络攻防的热点正在向嵌入式系统转换。随着众多黑客纷纷将攻击目标转向嵌入式系统,其应对安全威胁能力不足的缺陷也逐渐显现出来。在对不同应用领域中嵌入式系统的安全性研究进行总结后,可以发现可信运行环境是提高嵌入式系统安全性比较有效的解决方案。但是当前的研究不管是可信运行环境的构建技术,可信运行环境提供的安全服务还是基于可信运行环境的系统安全增强方案等都还存在着不足之处,导致可信运行环境在应用中仍然存在着安全风险。针对上述问题,本文全面分析并总结了可信运行环境在信任根、信任链传递、隔离性以及可信操作系统安全缺陷等方面存在的安全挑战,提出了安全增强的可信运行环境架构。并针对可同时防御物理攻击和软件攻击的信任根、在TrustZone监控模式程序中提供主动防御能力、建立可信操作系统内核的安全模型、基于安全模型设计内核、基于微内核架构设计操作系统系统服务、对不可信的密码软件进行安全性分析、神经网络计算的可信性保证、基于可信运行环境的系统安全方案等关键问题,分别提出了相应的解决方案。最终,形成了一套可信运行环境中基础软件开发和针对部分关键机制或关键软件安全性进行形式化分析与验证的框架,还基于基础软件形成了应用系统,并在实验平台上实现了原型系统的开发和实验评估。结果表明,所设计的安全增强的可信运行环境在功能、性能和安全性方面可以满足嵌入式系统的需求;所设计的入侵检测系统能够有效识别网络攻击,实现系统的主动防御。本文的主要贡献和创新之处有:(1)提出了安全增强的可信运行环境架,并在嵌入式系统中基于TrustZone硬件框架设计并实现了可以同时防御物理攻击和软件攻击的信任根,保证嵌入式系统设备上电后执行代码的可信性。并且构建了从信任根到系统装载程序,再到可信操作系统,再到系统服务,最后到可信应用的完整信任链。(2)根据操作系统安全设计的思想和方法,通过形式化方法建立了可信操作系统内核的状态机安全模型,提供了一个可以用于推理内核安全策略执行能力的框架。基于安全模型,采用微内核架构的设计思想,设计了安全增强的可信操作系统内核,通过自主访问控制机制来控制所有对系统资源以及内核服务的访问,从而解决了当前可信操作系统缺乏安全设计和安全机制的问题。(3)提出了一种基于微内核架构实现用户态系统服务的方法和框架,并基于状态机安全模型对通过内核访问控制机制实现组件之间的隔离性的问题进行了形式化描述和证明。通过在用户态运行系统服务来实现内核与复杂系统服务组件之间的隔离,通过内核访问控制机制保证系统服务组件之间以及可信应用之间的隔离,可以有效解决当前可信操作系统软件规模膨胀可能导致的安全问题。(4)在可信操作系统中实现了NFC软件栈、密码服务和轻量级神经网络可信计算服务框架等用户态系统服务,简化了上层应用的开发。针对系统服务中的不可信组件,例如在密码服务中所采用的开源软件库,提出了一种安全性形式化分析方法。轻量级神经网络可信计算服务框架将神经网络计算中最耗时的线性代数操作(矩阵乘法)外包到丰富运行环境,并在可信运行环境中对外包计算的结果进行校验来保证神经网络计算的可信性,可以有效解决当前在丰富运行环境中进行神经网络计算时容易遭受攻击的问题。(5)基于Linux用户态入侵检测系统架构,提出了一种轻量级的实时网络入侵检测方法,基于该方法提出了基于可信运行环境的入侵检测系统框架。通过入侵检测识别网络威胁,通过可信运行环境保障入侵检测系统自身安全性并提供主动防御能力,提升系统的整体安全性。"
1979,图文结合UGC的图像语义知识提取方法及应用研究,"随着互联网不断地飞速发展,网民数量激增,人们的社交模式也逐渐发生了改变,从线下迁移到线上,人们在线下进行生活和工作的同时,也在线上精心经营着第二自我。具有相同兴趣的网民聚集在一起,组合成为虚拟社区,在虚拟社区上,大部分的内容都是用户所产生的,这些内容称为用户生成内容(User Generated Content,UGC)。UGC是互联网海量数据的重要来源,蕴含丰富的应用价值,是大数据时代发展的前提。但是UGC本身具有一定的缺点,随着社会化媒体的不断发展以及互联网技术的不断提高,造成了海量的UGC涌现,海量的UGC会放大UGC本身的缺点,并导致从UGC中提取出用户需要的信息和知识变得异常困难,目前关于此问题的研究仅集中于文本领域。尤其是当前UGC的表达方式从单一的文本转变为文本和图像的模式,然而,并无直接针对于图文结合内容的研究方法,如果针对于图文结合的UGC内容只使用关于文本方面的研究,会造成文本可用信息不足以完全表达原始意思,同时衡量内容的效果不如真实影响。那么,如何应用图像特征解决图文结合的UGC中文本信息不足是亟待解决的问题。本文的研究以虚拟社区中图文结合的UGC内容为研究对象,根据图像的语义理解理论,逐步地从图像的视觉层、对象层和概念层中提取及量化语义知识,并逐步地从如何考虑图像信息、到图像信息作为辅助信息、最后将图像信息和文本信息一并作为主要信息入手,同时解决目前虚拟社区中存在的内容水质、信息噪声和主题不符等问题。本文的研究对现有的图像信息提取及与文本的结合研究作了进一步地拓展,并对于图像不同层次语义知识的量化方式进行了探索和创新,为今后多媒体的知识提取及量化的研究并做了铺垫。具体研究工作如下所示:(1)基于图像语义理解理论,将图像视觉层的特征语义计算并量化,同文本等特征一并研究图文结合的UGC内容中添加图像的影响,并解决在图文结合的方式下,如何考虑图像信息解决UGC内容质量评估的问题。在真实的虚拟社区数据集上,该量化方法表现良好。该研究的指标选择结果为后续研究的图像筛选作了指导;(2)基于图像语义理解理论中视觉层的特征语义的指标选择方法,将图像对象层特征语义量化为主观评级和客观比例的方式,并将提取出的对象层信息作为辅助信息,解决文本信息作为主要信息时出现的数据稀疏性问题。在真实的虚拟社区数据集中,添加了图像信息的推荐方法较未添加时更精确。该研究的信息提取、加工处理结果为后续研究的图像学习模型作了铺垫;(3)基于图像语义理解理论中视觉层特征语义的指标选择方法和和对象层特征语义的信息量化方法,建立与图像概念层特征语义的映射关系,同时将图像概念层特征语义文本主题概率分布之间学习并发现联系,通过优质的内容训练模型后可以得知图像与文本主题的匹配度,用以解决图文结合的UGC内容中图文主题不符的问题。在真实的虚拟社区数据集中,添加了图文匹配度的质量预测方法较未添加时更准确。该研究的语义映射方法及验证作为最终解决图文深度结合UGC的语义知识提取方法。"
1980,CT图像头颈部组织器官分割方法研究,"头颈部癌症的发病率和致死率均为世界前列。放射治疗是医治头颈部癌症的一种重要且有效手段。在放射治疗过程中必须严格控制肿瘤靶区周围的危及器官接受到的放射剂量,以免造成其放射损伤从而影响患者的疗后生活质量。调强放射治疗可以在有效保护危及器官的同时实现与计划靶区体积高度适形的三维剂量分布,是目前治疗头颈部癌症的最先进方式。为了充分发挥调强放射治疗的优势,必须基于放疗计划CT(Computed Tomography)影像对危及器官进行精确的勾画。然而由于头颈部重要器官比较集中,解剖关系复杂,目前临床上仍普遍采用的手工勾画方式既耗时又费力,而且难以保证勾画的准确性。囿于手工勾画的不足,人们希望由计算机代替医师进行自动勾画,并对此开展了大量的研究工作。然而从CT图像中自动地分割头颈部组织器官是非常困难的。首先,由于CT图像中软组织的图像灰度分辨率较低,软组织间的边界非常模糊,在某些区域甚至根本无法仅仅通过图像灰度确定边界;其次,头颈部重要组织器官集中,解剖关系复杂,而且某些器官在患者个体之间存在很大的差异性,因此自动分割需要应对异常复杂的CT图像背景;再者,病人头颈部体内的金属植入物如假牙等会造成CT图像中严重的金属伪影。头颈部CT图像的上述特点给其组织器官的自动分割带来了非常大的挑战。目前基于CT图像的头颈部组织器官自动分割方法仍然无法满足实际临床需求。针对上述问题,为了提高头颈部CT图像中组织器官自动分割的准确性和鲁棒性,本文深入研究了基于随机森林机器学习算法和形变模型的CT图像分割方法。主要工作和研究成果如下:(1)基于组织器官解剖位置先验约束的CT图谱对齐新方法。图谱对齐的精确度对基于机器学习的图像分割方法影像很大。传统的图谱对齐是通过对图谱中灰度图像的配准实现的。由于CT图像中软组织的图像灰度分辨率很低,传统方法无法得到理想的图谱对齐结果。针对这一问题,所提方法充分利用了图谱中标签图像所包含的组织器官解剖位置先验信息。一方面将组织器官解剖位置先验信息与灰度图像信息相结合形成混合不相似性测度,并将其作为优化目标函数,驱动空间变换模型的演化;另一方面利用组织器官解剖位置先验信息构建基于B样条的初始化形变模型以获得更好的优化初值,增强图谱对齐算法的鲁棒性。实验证明,采用所提方法获得的图谱对齐精度比传统方法有明显提高。(2)基于多级顶点回归的头颈部CT图像自动分割。基于形变模型的分割方法可以利用形状先验引导并约束分割,从而克服CT图像中软组织分辨率低的问题,在CT图像的组织器官分割中获得了广泛应用。然而基于形变模型的分割方法存在对初始化敏感、对目标器官的个体差异适应性弱以及对具有复杂形状的器官分割失效的问题。针对这些问题,本文提出了新的根据形状模型顶点的关键性强弱,逐级迭代回归预测的形变模型。所提出的基于顶点位移回归的隐式形变方式,回避了传统的显式形变方式中需要确定顶点移动方向及移动距离的问题,从而提高了形变模型的柔韧性和形状拟合精度;所提出的基于机器学习的形变模型关键顶点的识别、定位机制可以根据顶点独特性及个体间一致性的强弱,识别出关键的形变模型顶点并对其进行预测定位;所提出的目标器官形状和CT图像表观特征联合学习框架可以将形状先验和图像表观特征有机融合进一个基于随机森林的机器学习模型中。实验证明,该算法取得了比现有方法更高的分割精度和鲁棒性。(3)基于非盲学习的具有金属伪影的CT图像分割。传统的基于机器学习的图像分割方法仅从训练图谱中提取知识,以训练学习模型。图像分割的过程也仅进行盲目的知识模型应用,模型的训练和应用之间只有单方向的联系。而在伪影区域中,由于在图像表观上与正常CT图像的差异巨大,会造成训练所得的知识模型与实际待分割的目标图像不匹配的情况。这种情况下,强行将知识模型应用到目标图像进行分割,就会导致分割错误。针对这一问题,本文提出了“学以致用”的非盲学习策略,将待分割图像信息引入到机器学习模型的训练过程中,建立模型的训练和应用之间的双向联系,进行有针对性的模型训练。所提方法首先检测出待分割图像中的伪影区域;然后将伪影区域的位置信息反馈到模型训练过程;在对模型进行训练时,对伪影区域,禁止与其相关的图像灰度特征分量参与决策,仅保留与其相关的形状特征分量的决策权。实验结果表明,所提方法有效克服了伪影对分割结果的影响。"
1981,精细化抠图算法的若干关键技术研究,"抠图是图像合成的基础,在图像编辑、影视特效、虚拟现实等方面有着广泛的应用。本文围绕抠图存在的抠图精度低、抠图速度慢、依赖人工辅助三个痛点逐一展开研究;从启发式优化角度探索了求解自然图像抠图问题的新思路,提高了抠图精度;研究了多目标优化采样的抠图算法,实现了快速的高精度抠图;利用行人在红外成像中的先验知识研究了无需人工辅助的行人三分图全自动生成算法,实现了红外图像中行人的自动抠图。本文的主要研究内容包括:1)从启发式优化角度研究免采样抠图技术。将抠图问题建模为大规模的前景背景像素对(下文简称像素对)优化问题,利用启发式优化算法实现了免采样的抠图问题求解。针对启发式优化算法在大规模的像素对优化问题求解过程中容易陷入局部最优解的缺点,设计了自适应收敛速度控制器。利用像素对适应值和透明度遮罩相似程度的启发式信息准确度量个体竞争力及种群的收敛性,从而自适应地调节种群收敛速度,解决了启发式优化算法早熟的问题。2)利用像素对评价中单个准则的启发式信息以及局部像素相关的启发式信息,设计了基于模糊多准则评价与分解的多目标协同优化抠图算法,显著地提高了抠图精度。针对像素对评价中多个评价准则存在满足程度不确定的问题,提出了基于模糊逻辑的多准则前景背景像素对评价方法。通过对多准则单目标优化问题的分解充分利用每一个准则带来的启发式信息,通过像素邻域分组协同优化充分利用图像局部平滑先验信息,从而实现了精确的抠图。3)结合基于优化的抠图算法与基于采样的抠图算法,设计了像素级多目标全局采样算法。通过多目标优化采样的方式缩减大规模像素对优化问题的搜索空间,实现了高精度的快速抠图。通过将抠图多准则采样问题建模为多目标优化问题,并将多目标优化问题所有的帕累托最优解作为像素样本,克服了多个采样准则之间的冲突问题。通过提出的快速多目标优化算法实现了大量多目标优化问题的高效求解,从而达到了像素级采样的研究目标,避免了超像素级采样因聚类导致的最优像素对丢失问题。4)针对抠图所使用的三分图依赖人工标记的问题,本文以红外行人分类任务为例讨论了三分图的自动生成问题,探索了利用红外图像中行人成像的先验知识实现红外行人目标的三分图自动生成研究思路。在此基础上利用全自动行人抠图增强红外图像的前景轮廓并抑制杂乱的背景,并在红外行人分类任务上实现以较低计算代价获得深度学习算法性能的显著提升。"
1982,基于图像多特征模式识别的木材分类分选算法研究,"我国林业资源相对匮乏,但目前国内主流木材加工厂的加工备料方法过于简单粗放,模式传统,致使原材料的加工利用率不高,加工生产效率较差。为有效的提高木材利用率、提高木材生产效率,本文基于多特征模式识别木材分类分选,通过将待选木材图像按树种进行检索分类,从而进一步按照提取的缺陷类别及检量标准实现基于机器视觉的木材等级分选。现有的基于机器视觉的木材缺陷分等,皆为按照缺陷本身形态特征参数对木材等级分选,并未实现在木材树种分类的基础上分等优选,这同生产实际的木材分等检量标准操作是不相符的。针对上述问题,本研究在对木材树种判别的基础上,对木材图像进行缺陷分类,根据针叶树材与阔叶树材缺陷类型的不同,按照提取的缺陷面积检量参数,将木材分为特等、一等、二等和三等。本研究在120个树种中选取有代表性的50个中国常见树种,每个树种对应径切面和弦切面两幅图像,作为检索实验的研究对象,构建多类树种样本库1。再采集5个东北常见树种的样本,制作这5个树种的2种切面(径切、弦切)的木材图像,每个树种100个,共计1000幅,其中包括104个死节、40个活节、72个虫害、92个裂纹缺陷图像,构建样本库2。研究内容及实验结果主要为:(1)为实现木材树种检索判别,本文研究了木材图像检索的颜色与纹理特征提取与相似度匹配判别方法。结合木材材色与纹理的自身特点,提出了适合木材树种判别的匹配检索方法。利用基于颜色空间非等间隔量化的主色调特征提取方法,可以对颜色分布范围较窄、树种间颜色差异相对细微的木材图像进行特征匹配,从而达到更为理想的检索判别效果。在经过颜色特征检索后,进一步利用6个纹理特征包括:对比度(CON),二阶角矩(ASM),方差和(SV),长行程加重因子(LRE),分形维数(FD),小波水平能量分布比重(EPLH)构建特征量体系以实现进一步检索,通过实验结果分析可知,分步检索可令检索判别结果趋近于更高的精准度。(2)提出了一种针对木材图像缺陷二值化局部阈值分割算法,该算法采用计算窗口模板均值、标准差、以及极值来计算各点阈值。实验结果表明,本研究提出的算法针对复杂背景木材图像缺陷分割具有良好的性能,性能明显优于全局阈值、Bernsen算法,略高于Niblack算法和Sauvola算法。算法对木材图像的缺陷分割精度可达92.58%,更适用于材色或光照不均一、有纹理噪声干扰等背景的木材缺陷图像。(3)在缺陷分割基础上,根据不同木材缺陷特异性的采用形态学方法进一步的改善缺陷提取效果,在大幅度的减少噪声的基础上,最大程度还原了缺陷二值特征。并利用形态学函数有效提取缺陷的长度、宽度、数量及位置等相关参数。(4)木材图像缺陷检测分类部分采用了 3种模型:BP神经网络模型、SVM支持向量机分类模型、CNN卷积神经网络模型。BP神经网络通过分别提取了 LBP特征以及HOG-LBP融合特征实现分类,分类准确率最高为50%。SVM分类模型提取了 HOG特征、LBP特征以及HOG-LBP融合3组特征,而以HOG-LBP融合特征实现缺陷分类效果明显优于采用HOG或LBP单一特征。分别采用4种核函数基于HOG-LBP融合特征实现分类,通过实验发现多项式核函数及高斯核函数分类性能最好,准确率均为98.68%。CNN卷积神经网络模型输入层维度512× 512× 3,采用尺寸为9× 9的1、0相间的卷积核,分别验证了其层数为2-4层时的分类准确率。采用CNN卷积神经网络测试最优为4层结构,分类准确率为98.68%。(5)通过对实验参数的优化设计,以及训练过程的监督及实验结果的比对分析,验证了不同模型的性能及优势所在。通过比对分析,认为BP神经网络虽为传统经典模型,但对于木材缺陷的HOG特征、LBP特征以及HOG-LBP融合特征并不敏感,因此,在当前特征提取情况下,不太适用于木材模型分类。CNN卷积神经网络模型及SVM支持向量机模型较之更适合木材缺陷检测分类,其对木材缺陷的检测及分类具有较高的分类准确率。"
1983,藏文陈述句复述生成研究,"复述是相同语义的不同表达方式,在自然语言中非常普遍,它反映了人类语言的灵活性、多样性和复杂性。复述研究主要包含三个内容:一是复述抽取,即从原文中抽取关键词,重新组合这些字或词并使语义与原句相同;二是复述识别,即从语料中找出语义相同的句子或段落等不同的语言单元。三是复述生成,给定一个输入,输出一个相同语义的文本。复述方式包括短语到短语、句子到句子等等长复述,也有从词到短语、从短语到句子的不等长度的复述。本文主要研究的是藏文陈述句复述生成。首先对藏文句子进行分类并抽取陈述句,然后对句子进行语义分析,在此基础上构建藏文复述句语料库,最后通过机器学习自动生成藏文复述句。本文包括如下5个主要问题和解决方法:1.基于循环卷积神经网络的藏文句类分类方法研究藏文句类分类是藏文语言学和自然语言处理领域中尚未关注的一个研究点,鲜见于有关文献。本文的研究对象为藏文陈述句复述自动生成,其存在的主要问题是藏文句子的句类自动分类问题。问题的难点是其他语言的传统句类的分类方法不适用于藏文的句子分类,因为藏文没有特殊的标点符号来识别不同的句子种类。本文在充分分析藏文不同句类特征信息的基础上,提出了以藏文句子语境信息和特征功能为识别和分类依据,采用循环卷积神经网络对藏文句子进行识别和分类。实验结果表明:对藏文句类识别和分类的平均准确率达85.61%、召回率达86.54%、F值达85.59%。2.基于空洞卷积网络的藏文句子语义分割方法研究当前藏文句义的研究内容和方法停留在句法分析上,因此,对藏文句义理解的研究还没有一个具体的研究方法,且在藏文句义理解的研究方面与其他语言相比存在着很大的差距。研究藏文复述生成,首先要解决的问题是在理解原文句义后才能生成藏文陈述句复述。其问题的主要难点是在其他语言句子语义分割中通常以词为分割单元,然而,如果对藏文进行以词为单元的分割时,由于颗粒度过细,会产生或造成很多词汇歧义和语义序列解码的不稳定性问题。本文在分析藏语语言特性和语言编码组合规律的基础上,提出了一种新的语义单元分割方法。该语义单元长度介于词义之上句义之下,使语法、语义、语境融为一体。然后采用空洞卷积神经网络对藏文句子进行语义分割。实验结果表明:空洞卷积网络模型对语义分割的准确率达到了92.39%。3.基于藏文语序和语义词典的复述句语料构建方法研究机器学习中,数据资源的规模与质量直接影响学习结果。本文在研究过程中需要较大规模的藏文数据资源用于生成藏文陈述句复述研究。然而,解决此问题的难点在于,目前国内外还没有一个公开、大规模、高质量的藏文数据资源用于机器学习,更没有复述句的数据集。为解决藏语复述句的数据资源匮乏问题,本文提出了利用藏文语序变换和藏文语义词典等方法来构建藏语复述语料资源。实验结果表明人工评测后基于语序变换的藏文复述生成准确率为97.31%;且基于藏文语义词典的复述生成准确率为93.33%。4.基于注意力机制的藏文复述句生成研究近年来,随着复述研究成果应用到机器翻译、自动问答、信息检索、信息抽取、文本生成及阅读理解等相关研究,这使越来越多的研究者和研究机构开始关注并重视复述研究工作。然而,目前还没有找到利用注意力机制对藏文陈述句复述句生成进行研究的相关文献。本文试图将注意力机制应用到藏文陈述句复述自动生成研究中,以扩充现有藏文复述句的数据资源。本文在以上已构建的复述数据资源的基础上,提出了基于注意力机制的藏文复述句自动生成方法。实验结果表明:藏文复述句生成结果的BLEU值为40.38%。5.基于注意力机制的藏文新词释义自动生成研究随着人类社会的进步和科学技术的发展,新的术语和词汇不断涌现。目前的藏文新词术语的释义已无法满足人们的需求,因此,为解决这一问题,本文尝试利用机器学习方法对藏文新词术语进行自动释义。本文提出了一种基于注意力机制的藏文新词术语释义自动生成方法。实验结果表明,词典原文释义生成准确率为87.17%,新词释义生成准确率为80.32%。本文利用各种方法构建了较大规模的藏文复述句的数据资源,并尝试利用这些数据资源对藏文复述的自动生成进行基于机器学习方法的研究。本研究取得了较好的初步成果,希望这些成果能对藏文自然语言理解研究提供借鉴。"
1984,基于物理特征的认证及恶意节点检测研究,"无线通信技术由于其传播介质的开放性,导致其信号易被截获和干扰,从而带来了不同于有线通信的安全隐患。如何在增强无线通信安全的同时,尽可能少地增加计算负担或硬件成本,是目前无线通信安全研究的热点问题。大多数的无线通信安全机制仍然延用了有线通信安全机制中的现代密码学机制。但在无线通信中,高安全强度的密码学安全机制不仅给通信终端带来了巨大的计算负担,还表现出了一些弊端,例如,随着计算能力的日益提高,攻击者很有可能在有效时间内破解合法通信双方的密钥,使整个安全系统崩溃。如果攻击者捕获了某一合法通信节点,并获得了该合法通信节点的秘密信息,便可以伪装成多个合法节点,散布于整个网络中,实施窃听或篡改合法信息包等攻击,例如,克隆节点攻击和Sybil节点攻击。由于攻击者拥有合法节点的密钥等信息,基于密码学的安全机制便很难检测出该攻击者的存在。近年来,物理层安全技术越来越受关注,其理论基础是无线信道的空时唯一性。物理层安全认证技术通过从接收信息包中提取的信道物理特征来判断该信息包的合法性,即进行信息包的认证。利用无线信道的空时唯一性,还可以进行恶意节点检测,例如,克隆节点检测和Sybil节点检测。由于物理层认证和检测方案采用的信道特征来源于解调模块中的信道估计,不需要额外地计算开销,避免了复杂上层的计算,使得其具有轻量级的特点。此外,来自不同发射源的信道特征具有唯一性,难以被攻击者伪造,因此,物理层认证和检测方案又具有高安全强度的特点。本文首先阐述了物理层认证和恶意节点检测的研究背景和现状,讨论了影响信道状态信息(Channel State Information,CSI)和物理层认证的无线信道特性及其空间分辨率;对基于CSI的物理层认证和恶意节点检测进行了建模;还简述了衡量认证性能的指标和采用的通信系统平台。其后,详细讲述了两种基于CSI的认证算法和四种恶意节点检测算法,具体如下:本文针对新一代的无线通信系统,提出了一种基于信道信息的辅助增强安全架构和D2D(Device to Device,端到端)跨层双向安全认证方案,并利用来源于四个不同通信场景的信道数据,分析了该认证方案的可行性。仿真实验证明,在静态场景下,该方案的认证性能可以达到理想状态,但在动态场景下,该方案的认证性能较差。为了改进动态场景下的物理层认证性能,本文提出了一种基于门限自由和机器学习(Threshold-Free and Machine Learning,TFML)的物理层认证方案。该方案无需门限判别,直接利用机器学习算法对信道差值或信道矩阵进行分类,得出认证结果。本文首先采用动态通信场景的信道数据对该方案进行了仿真,分析了其可行性,并且对方案中的参数进行了对比,得出的最优方案为采用128维的信道矩阵作为输入的装袋树(Bagging Trees,BT)认证方案。最后,通过通用软件无线电外设(Universal Software Radio Peripheral,USRP)平台,在真实工业环境中,对该最优方案的优越性进行了验证,并且证明了多输入多输出(Mutiple-Input Multiple-Output,MIMO)对该认证方案的增强效果。本文还在近场服务(Proximity Service,ProSe)通信场景下,提出了四种基于物理特征的恶意节点检测方案,包括基于物理层信誉度(Physical Layer Reputation,PHYR)的恶意节点检测方案、基于贪婪算法的恶意节点检测方案,以及基于反向传播神经网络(Back Propagation Neural Network,BPNN)的恶意节点单点检测方案和多点集成检测方案。基于PHYR的恶意节点检测方案首先通过累积同一ID的多个信道信息,得到该ID的物理层信誉度。然后,通过对信誉度的判断,进行恶意节点检测。该方案可以有效地降低随机噪声对恶意节点检测性能的影响,从而提高检测准确率。当信道条件较恶劣时,即系统检测准确率不理想的状态下,基于贪婪算法的恶意节点检测方案可以根据用户的需求选取检测门限值,即,采用最大化用户收益的原则代替最大化检测准确率的原则进行门限选取。基于BPNN的恶意节点检测方案根据单次检测节点的数目分为单点检测方案和多点集成检测方案。单点检测方案以单个节点的一种或多种信誉度作为输入,通过BPNN判断其是否为恶意节点。多点检测方案以一组节点的某一种信誉度作为输入,由BPNN对该组节点中是否存在恶意节点进行判断。本文通过实验,对四种恶意节点检测方案分别进行了分析,验证了其可行性、总结了其优缺点。"
1985,基于机器学习的影像组学分析在直肠癌异时性肝转移预测中的应用,"第一部分增强CT及MR影像组学特征预测直肠癌异时性肝转移目的:应用基于不同机器学习算法的增强静脉期CT及MR影像组学模型预测直肠癌异时性肝转移(metachronous liver metastases,MLM),并比较其价值。材料与方法:回顾性分析76例在我院治疗及规律随访的直肠癌患者,治疗前腹盆增强CT扫描均未发现肝转移。根据随访结果将患者分为24个月内MLM组(N=38)和无肝转移(non metachronous liver metastasis,nMLM)组(N=38)。比较两组间基线临床指标(年龄、性别、T分期、N分期、肿瘤标记物CEA及CA19-9)。对直肠癌原发灶增强CT、MR图像进行分割,分别提取了 1029个影像组学特征。应用最小绝对值收缩与选择算子(least absolute shrinkage and selection operator,LASSO)法分别对增强CT(1029个特征)、增强MR(1029个特征)以及两序列联合(2058个特征)提取的影像组学特征进行降维处理。采用五折交叉验证方法和六种机器学习算法(决策树,decision tree,DT;梯度提升,gradient boosting,GB;K-近邻,K-nearest neighbor,KNN;逻辑回归,logistic regression,LR;随机森林,random forest,RF;支持向量机,support vector machine,SVM)构建预测模型,不同模型的预测效能应用受试者工作特征(receiver operating characteristic,ROC)曲线及混淆矩阵评估,评价指标包括模型的准确性、灵敏度、特异性和曲线下面积(area under the curve,AUC)。结果:MLM组与nMLM组间基线临床指标无明显统计学差异(P<0.05)。应用LASSO算法分别从三个序列中筛选获得1个、4个和5个与MLM相关特征,构建三组预测模型。CT模型中,应用六种算法均未获得效能较好的预测模型(AUC值范围0.439～0.640)。MR模型中,应用LR算法(AUC值0.750±0.137)和SVM算法(AUC值0.764±0.128)可获得预测效能较好的模型,余四种模型效能较差(AUC值均0.05)。最终筛选获得与MLM相关特征:T2WI特征5个、增强VP特征8个和两序列组合特征22个;分别构建四组模型,包括T2WI模型(由5个最优T2WI特征集构建),VP模型(由8个最优静脉期特征集构建),T2WI+VP模型(由两序列分别筛选出的共13个特征集构建)和T2WI/VP模型(由两序列联合共2058个特征中筛选的22个最优特征集构建)。VP模型中,应用LR算法(AUC=0.74,95%CI:0.57,0.75)的模型预测效能明显优于SVM算法(AUC=0.68,95%CI:0.56,0.72)(P=0.0303)。应用LR算法获得的T2WI/VP模型的MLM预测效能明品优于其他三种模型(P=0.0019,0.0028和0.0081),其准确性、灵敏度、特异性和曲线下面积分别为0.80、0.76、0.83和0.87。100轮交叉验证证实结果具有较高的稳定性。结论:治疗前直肠癌MR影像组学模型具有较高的MLM的预测效能,尤其是应用LR算法构建的T2WI/VP模型效能最佳。此外,除了 VP模型中LR算法优于SVM算法,其余三组模型的两种算法间并无显著差异。第三部分基于机器学习的全肝CT影像组学模型预测直肠癌异时性肝转移目的:应用机器学习算法、基于治疗前“无病”全肝增强门静脉期CT影像组学模型预测直肠癌异时性肝转移(metachronous livermetastases,MLM)。材料与方法:本研究回顾性分析88例首诊无肝转移的直肠癌患者,根据随访结果分为 24 个月内 MLM 组(N=44)和无转移(non metachronous liver metastases,nMLM)组(N=44)。基线临床特征的统计分析应用SPSS软件。影像组学特征降维及构建模型采用Python语言完成。对治疗前增强门静脉期全肝CT图像进行手动逐层勾画(避开肝内大血管和可见的良性病灶),获得“无病”全肝体积感兴趣区(volumes of interest,VOIs),自动提取1029个影像组学特征。采用最小绝对值收缩与选择算子(least absolute shrinkage and selection operator regression,LASSO)算法对数据降维获得与MLM相关的最优特征。研究中将样本按照8:2的比例随机分为训练集和验证集,使用五折交叉验证及六种机器学习算法(逻辑回归,logistic regression,LR;支持向量机,support vector machine,SVM;决策树,decision tree,DT;K-近邻,K-nearest neighbor,KNN;随机森林,random forest,RF;多层感知器,multi-layer perception,MLP)训练模型,再用验证集病例对模型效能进行验证。获得训练集和验证集的受试者工作特征(receiver operating characteristic,ROC)曲线,模型预测效能的评价指标包括曲线下面积(area under the curve,AUC)、准确性、灵敏度和特异性。结果:MLM组与nMLM组的基线临床特征(包括性别、年龄、T分期、N分期、肿瘤标志物CEA及CA19-9水平)以及临床治疗方式间均无统计学差异(P>0.05)。LASSO算法对全部特征降维处理获得10个与MLM相关的特征。六组模型中,应用LR算法(训练集AUC=0.90±0.06,准确性0.80,特异性0.63,灵敏度0.97;验证集AUC=0.74±0.14,准确性0.67,特异性1,灵敏度0.33)和SVM算法(训练集AUC=0.83±0.10,准确性 0.73,特异性 0.86,灵敏度 0.60;验证集 AUC=0.78±0.10,准确性0.72,特异性0.67,灵敏度0.78)获得的预测模型具有较好的MLM预测效能。而应用DT、KNN、MLP算法构建的预测模型的效能较差,验证集AUC值均低于0.70(AUC值范围0.56～0.69)。结论:“无病”全肝增强CT影像组学模型具有较高预测直肠癌24个月内发生MLM的价值,尤其应用机器学习算法LR和SVM的模型效能更佳。"
1986,视觉工作记忆精度的计算模型、神经机制与临床应用,"视觉工作记忆是指在较短时间内对视觉信息进行保持和操作、以完成目标导向任务的能力。视觉工作记忆被认为是认知功能的基础,与注意、语言、逻辑推理、智力等多方面能力有着十分紧密的联系。然而,视觉工作记忆具体的加工机制至今还没有定论。广受认可的两大理论为离散插槽理论和连续资源理论,而这两个理论之间的争论,主要在于工作记忆存储形式是离散的组块还是连续可分的认知资源。在连续资源理论框架下,近期提出的变化精度模型认为记忆精度在客体与试次间存在动态变化,且平均记忆精度随记忆负荷增加而不断下降,并在行为数据拟合方面优于其它主流的计算模型。变化精度模型虽然在理论和计算层面占有优势,但缺乏神经科学上的证据,且仍缺乏实际的应用。本论文将从神经数据的角度为这一模型提供支撑,并尝试将模型应用于临床数据,从理论和实践两方面论证变化精度模型的价值。全文采用统一的连续回忆任务范式,在实验过程中首先呈现包含若干客体的记忆样本,要求被试记住客体的某些特征(如颜色、朝向),在一段时间的延迟后,被试需要按要求回忆出某一客体的具体特征,并通过鼠标在色环上点选或通过鼠标转动刺激朝向进行选择。第一部分的三个实验主要研究了变化精度模型的神经基础。首先,基于变化精度模型对记忆精度在试次间变化的假设,实验一使用单变量功能磁共振的方法,探索了大脑中与试次精度相关的脑区。结果发现,外侧枕叶复合区(LOC)的神经活动与试次水平的反应误差相关,活动越强则误差越小,亦即精度越高;并且LOC的活动可以预测磁共振外通过另一组行为数据建模得到的精度值。这些结果证明了感觉皮层在工作记忆精度维持中的重要作用。更进一步,在高记忆负荷时,LOC与额下联合区(IFJ)的功能连接增强,证明额叶皮层与感觉皮层共同完成高难度记忆任务。实验二使用经颅磁刺激的方式进一步验证上述皮层区域在视觉工作记忆中的因果性作用,包括LOC、早期视觉皮层(EVC)以及IFJ区域。结果发现,对于这三个脑区施加单脉冲经颅磁刺激均可以改变工作记忆精度,并且对LOC刺激的影响效果更强。这些结果表明,LOC的活动可以追踪试次间的视觉工作记忆精度变化,为变化精度模型提供了神经证据支持。那么这些精度变化以何种模式表征在神经层面上,又如何随记忆负荷发生变化?实验三使用了反向编码模型的多变量功能磁共振分析方法来考察视觉皮层对单一客体的表征随记忆负荷的变化情况。结果发现,在记忆负荷上升时,与记忆客体相对应的早期视觉皮层感受野的体素对视觉特征的表征强度降低,而位于更高视觉层级的V3a的表征强度随记忆负荷的增加而增加,且在延时过程中的表征持续时间长于早期视觉皮层,暗示了工作记忆中变化精度表征的层级结构,且高级皮层可能存在对初级皮层的调控作用。第二部分的两个实验进一步将变化精度模型应用于精神分裂症病人,结果证明变化精度模型仍然比传统模型具有数据拟合方面的优势。两个实验均发现精神分裂症患者在视觉工作记忆能力方面相对正常人存在显著的受损,然而仔细分析模型拟合结果发现,病人的视觉工作记忆容量(实验四)与选择性注意功能(实验五)并未体现出与健康对照组间显著的差异,挑战了前人的相关研究结论。值得注意的是,在变化精度模型中表示资源分配变异度的参数上,病人体现出了比健康被试更大的变异量,也就是说,精神分裂症患者工作记忆能力受损的原因在于,他们在试次间与客体间资源分配的变异性较大,从而体现为较差的行为表现。更进一步,这一资源分配的变异度可以预测病人的简明精神量表评分以及阴性症状评分,提示变化精度模型未来在临床上可能的应用价值。综上所述,本论文的系列研究发现与试次水平的记忆精度相关的神经活动,并证明其与行为之间存在因果关联,进一步感觉皮层的表征调谐曲线随记忆负荷的增加而降低,这些研究结果均为变化精度模型提供了神经证据支持。更有趣的是,变化精度模型的参数揭示出,资源分配的变异性增大才是导致精神分裂症病人工作记忆能力下降的主要原因,未来基于这一参数的方法可能为精神分裂症患者的诊断和干预提供帮助。"
1987,基于机器学习方法的分类与预测问题研究,"随着计算机与互联网技术的不断发展,海量数据信息存在于日常生活中的各个领域,人们可以从海量数据中获取丰富的有价值信息。伴随着大数据时代的到来,各个领域都迎来了新的挑战,如何提高对海量数据的分析与应用效率,已经成为人们关注的热点问题。机器学习作为人工智能的重要分支,在大数据的研究与处理方面处于最前沿的研究方法。绝大多数的机器学习算法本质都是建立优化模型,使用优化算法对目标函数进行优化,通过训练得到最优模型。因此,优化算法在机器学习算法的研究与实现中占有主导地位。本文主要对BP神经网络、支持向量机(Support Vector Machine,SVM)以及几种智能优化算法进行研究,并将这些算法应用到不同研究背景下分析其可行性和实用性。论文主要研究内容如下:(1)为了更好的平衡粒子的全局搜索能力和局部开发能力,解决GSA中存在的过早收敛、局部优化能力差等问题。将PSO算法中的群体信息交流功能与GSA算法中的局部搜索功能相结合,提出了基于时变惯性权重策略的PSO-GSA算法(TVIW-PSOGSA)。选取23个基准测试函数评估TVIW-PSO-GSA算法的寻优性能。实验结果表明,与PSO-GSA、GSA、GA和PSO算法的收敛精度相比,TVIW-PSO-GSA算法的收敛精度最高,稳定性最好,且收敛速度和性能均优于其他算法。(2)针对SVM方法的参数选择问题,使用TVIW-PSO-GSA算法优化SVM的惩罚参数C和核函数参数?,提出了改进的SVM方法(TVIW-PSO-GSA-SVM)。为验证所改进方法在实际问题中的可行性和有效性,将其应用到空气质量等级分类预测与UCI数据集分类问题中,并与其他算法的预测结果进行比较。实验结果表明,与PSO-GSA-SVM、GSA-SVM、GA-SVM和PSO-SVM方法相比,TVIW-PSO-GSA-SVM方法准确率更高。(3)考虑传统流感监测体系发布数据的滞后性,首先基于谷歌流感趋势数据(Google Flu Trends,GFT)建立了流感预测模型,并将基于遗传算法(Genetic Algorithm,GA)优化BP神经网络的模型应用到流感预测中,建立了基于GA-BP的非线性流感预测模型;其次,通过对美国十个区域的流感样病例(Influenza-Like Illness,ILI)数据进行分析,发现十个区域每年的流感样爆发人数均具有明显的季节性,从而将美国十个区域的流感发病分为流行期和非流行期,并在此基础上建立了分季流感预测模型;最后,通过对比各模型之间以及GA-BP与传统最小二乘法(Ordinary Least Squares,OLS)对美国十个区域流感预测的预测结果,可以发现:基于GA-BP非线性模型的预测结果在大部分区域均优于线性模型;区域间的交互作用对流感传播有一定的影响;分季流感预测模型相比于原始未分季流感预测模型,其预测精度更高,效果更好,更能反映流感传播的真实水平。(4)通过分析影响流感传播的因素,建立了基于推特(Twitter)数据和疾病预防控制中心(Center for Disease Control and Prevention,CDC)数据的流感预测模型(模型1-3),并提出了一种改进的PSO算法来优化支持向量回归机(Support Vector Regression,SVR)的参数(IPSO-SVR),并将其应用到流感预测模型中对区域ILI百分比(%ILI)进行预测。对比各模型间的预测结果,可以发现:Twitter数据与历史流感数据中包含的信息互补,即Twitter数据保障了流感实时预测的准确性,历史数据能够较好地预测未来的流感趋势变化;与基于改进人工树算法的BP神经网络(IAT-BPNN)流感预测模型相比,模型3中IPSO-SVR方法的预测结果更优;模型3中IPSO-SVR方法不仅适用于HHS定义的10个区域的流感预测,同时也为优化SVR的参数提供了一种新的方法。(5)在MEMS矢量水听器阵列信号处理的研究中,波达方向(Direction of Arrival,DOA)估计问题占据着重要的地位。本文针对该问题提出了基于TVIW-PSO-GSA-BP和TVIW-PSO-GSA-MUSIC的DOA估计方法,并将其应用于矢量水听器的波达方向估计中。通过仿真实验和汾河二库湖试实验,将提出的两种方法估计结果与其他方法估计结果进行比较,可以发现,TVIW-PSO-GSA-BP方法的DOA估计结果均优于BP、PSO-BP和GSA-BP方法;TVIW-PSO-GSA-MUSIC方法的DOA估计结果相比于MUSIC、PSOMUSIC和GSA-MUSIC方法效果更好,准确率更高。从而验证了本文提出两种DOA估计方法在MEMS矢量水听器波达方向估计问题中的有效性。"
1988,基于机器学习的水产养殖水质参数预测方法研究,"养殖水质的好坏直接关系到养殖安全,所以研究养殖水质参数变化趋势及新型监控方式,实现对水质参数的精准预测,提前预警,实现水质管理的科学化,解决因水质恶化导致的鱼类疾病爆发,具有重要经济价值。本文以水产养殖的水质参数为研究对象,主要对水质参数预测建模方法、模型的参数寻优、水质参数峰值区域预测精度提高算法、多核函数最小二乘支持向量机(LSSVR)、水质参数测量装备研制和水质参数预测模型的应用等方面展开研究。论文主要工作及主要结果如下:(1)研究了最小二乘支持向量机模型超参数γ和σ的寻优算法。对粒子群算法进行改进建立了IPSO-LSSVR模型。研究了分布估计算法并用混沌变异对其改进,用该算法对γ和σ组合进行了寻优,建立了CMEDA-LSSVR预测模型,将这两种模型分别用于溶解氧和pH值的预测,比较了两种模型对溶解氧和pH值的预测性能。从这两种模型对溶解氧的预测结果对比得出,前者比后者的标准误差和平均绝对百分比误差分别低10.62%和8.79%,证明了IPSO-LSSVR模型更适用于对溶解氧的预测。从这两种模型对于pH值的预测结果对比得出,前者比后者的标准误差和平均绝对百分比误差分别高7.27%和9.84%,证明了CMEDA-LSSVR模型更加适用于对pH值的预测。(2)研究了水质参数峰值区域最小二乘支持向量机模型预测精度提高的问题。分析了最小二乘支持向量机模型训练样本分布对模型性能的影响,在此基础上研究了一种利用训练样本分布密度和模型的输出期望幅值加权的最小二乘支持向量机预测模型。将改进的加权IPSO-LSSVR模型用于溶解氧的预测,结果表明,改进后的模型对溶解氧的预测结果标准误差和平均绝对百分比误差分别降低了14.95%和26.35%,这证明对标准IPSO-LSSVR模型的改进算法能够显著提高养殖水体溶解氧的预测精度。将改进的CMEDA-LSSVR模型用于螃蟹养殖水体pH值的预测,结果表明,改进后的模型对pH值的预测结果标准误差和平均绝对百分比误差分别降低了17.23%和22.19%。证明了对标准CMEDA-LSSVR模型的改进算法能够显著提高养殖水体pH值的预测精度。(3)对最小二乘支持向量机模型的多核函数的构建方法进行了研究。研究将学习样本集的所有输入向量按照同源特征进行分组,所有同源特征输入样本都采用同一个非线性映射函数,映射到高维特征空间进行回归拟合,建立了分组多核的最小二乘支持向量机预测模型。实验结果表明,该模型对溶解氧的预测结果标准误差和平均绝对百分比误差与采用单径向基核相比,分别降低了14.9%和23.6%。将该模型用于养殖水体pH值的预测,结果表明,该模型对pH值的预测结果误差值与采用单径向基核相比,标准误差和平均绝对百分比误差分别降低了15.5%和22.8%。证明采用本文分组多核最小二乘支持向量机模型能够显著提高养殖水体溶解氧和pH值的预测精度。(4)开发了游弋式水质参数测量平台,实现低成本实时获取大面积水域水质信息的目标。采用该测量平台研究了主要水质参数的分布规律,研究了水质参数和气象因子之间的关联性,为水质参数预测模型建立的输入参数选择提供指导。根据天气预报将阴天分成五个等级,验证了根据阴天不同等级对模型进行校正的效果,结果证明了该方法可以有效提高阴天条件下模型对溶解氧的预测精度。最后验证了水质预测模型应用于水质预警和无线传感节点的节能效果。结果表明,采用本文预测模型控制数据方式,水产养殖物联网系统的无线传感节点平均生存周期约相当于直接发送数据方式的2倍,这将大大提高了无线传感节点的时效性,节约了成本和提高了效率。"
1989,基于机器学习方法的CKD4期中医慢病管理疾病预测模型的建立与验证,"目的:本研究拟采集针对慢性肾脏病的慢病管理相关诊疗信息,构建慢病管理疾病风险预测模型,对预测模型进行数据分析并有效验证,为更优的管理方式提供理论依据,改善患者预后水平。方法:本研究采用回顾性数据分析方法,以2012年1月1日至2018年12月31日,于广东省中医院慢病管理门诊规律随访的慢性肾脏病4期患者作为研究对象,全面收集研究对象的人口统计学资料、实验室检查结果、中医症状与辨证分型、中医慢病管理实施情况、服用药物情况等相关变量,并记录患者主要结局发生情况,包括:透析、肾移植及死亡,并进行结局分组。通过结合知识图谱表示学习,应用机器学习方法,建立基于病、证、症、风险因素等多个维度的知识、关系、路径向量的分类模型,对肾脏疾病的中医慢病管理临床获益预测实验进行分析。通过特征选择、参数调整等多种实验手段,对不同预测模型的性能分析验证及优化。区分度方面,利用接收者操作特征曲线下面积(Area Under the Receiver Operating Characteristic curve,AUROC),及F1系数评估不同模型的性能;一致性方面,使用Kappa值和Accuracy值进行判断。结果:本研究一共纳入256名慢性肾脏病4期患者,其中未发生终点事件组155人,发生终点事件组101人。通过Boruta算法共筛选出21个变量,包括:裂纹,舌胖大,齿印,降压药,服药种类,药物作用,肾毒药物,饮食不健康,优质蛋白,食物禁忌,盐分摄入,恶化停药,微信文字版,ALT/AST,ALB,Urea,TC02,Cr,体重分数,BMI及上臂肌围百分比。随后共采用8种机器学习模型进行训练,在区分度方面,稳定线性判别分析(Stabilized Linear Discriminant Analysis,SLDA)模型取得了最优的性能,AUROC为0.8;偏最小平方(Partial Least Squares,PLS)模型取得了次优的性能,AUROC为0.78;另外,K近邻(k-Nearest Neighbors,KNN)模型的性能不十分理想,AUR0C最低,为0.54;其余的模型AUROC没有显著性的差别。与AUC性能表现相似,对不同模型的F1系数进行分析,结果提示:SLDA仍然是性能表现最优异的模型,F1系数为0.84,次优的是仍然是PLS模型,F1系数为0.83,但没有显著性的差别。KNN模型的F1值为0.67,表现不十分理想。结论:基于计算机的机器学习算法,如利用SLDA及PLS模型,可以实时识别实践层面的干预效果,并且能更有针对性地纠正慢性疾病管理中的偏差。因此,机器学习方法为肾脏疾病的中医慢病管理提供了一种常规的策略管理方法,或许可以推广至其他慢性非传染性疾病的慢病管理中。"
1990,甲状腺结节多模态超声成像智能化评估模型构建及验证研究,"第一部分 超声实时组织弹性成像提高甲状腺结节恶性风险分层的诊断效能目的探讨超声实时组织弹性成像(Real-Time Tissue Elastography,RTE)的超声弹性评分(elasticity score,ES)与甲状腺恶性风险分层(Malignancy Risk Stratification,MRS)的相关性,评价RTE对MRS鉴别结节良恶性的补充价值。材料与方法共有1498例患者(女性885例,男性613例,平均年龄43.5 ± 12.4岁),经细针抽吸(FNA)和/或手术证实的甲状腺结节1525个(最大直径D≤2.5 cm)。根据结节大小分为4组(D≤0.5 cm,0.5<D≤1.0cm、1.0<D≤2.0cm和2.0<D≤2.5cm的结节区间内具有较强的相关性(相关系数r分别为0.768、0.711及0.743)。RTE和MRS联合应用在各尺寸区间的诊断效果均优于单独应用RTE或MRS(P"
1991,面向低功耗物联网的高效传输及安全认证关键技术研究,"无线传感器网络为物联网提供了对物理世界的感知接口,为物联网的高效运行提供了数据支撑。本论文考虑一类部署在潮间带的无线传感器网络,由于其特殊的部署环境,系统具有网络连接动态性强、数据传输延迟大、节点能耗高等问题。对此,本论文研究了基于终端的低功耗配置问题,并通过设计低功耗、低延迟的路由算法提高收数效率。・为了最大化延长系统的寿命,传感器节点通常使用低占空比的工作模式,即节点仅周期性的工作很短一段时间,而大部分时间处于休眠状态。目前,大部分的能耗优化工作都主要关注如何降低节点工作期间的能耗,并认为休眠状态的功耗可以忽略不计。本文通过对低占空比系统能耗的分析发现,针对休眠状态功耗的优化对整体系统能耗优化有着至关重要的作用,同时休眠状态时不合理的GPIO(General Purpose Input Output)引脚配置会带来巨大的能耗。基于此,本文提出了 OPCIO,利用遗传算法,自动化实现终端节点休眠状态GPIO引脚的优化配置。通过对实际传感器节点的能耗优化结果表明,OPCIO从硬件角度提供了节点能耗优化的方案。・路由协议通常需要依赖准确实时的链路质量估计,以确保数据在动态网络中的可靠传输。通过对实际潮间带无线传感器网络的观察,发现频繁的链路质量估计带来了能量与带宽的浪费。本文就这一问题,分析调研了潮间带系统中的链路质量变化情况,研究了通过稀疏采样实现链路质量的准确估计的可行性。据此,本文提出一个基于压缩感知技术的链路质量估计协议,并结合路由选择,提出低功耗路由协议――LESS。LESS同时利用了网络部署环境在时间域和空间域的特点,设计了 3种采样策略以适应不同类型的动态网络,同时提高链路质量重构精度。通过对实际系统数据和大规模网络仿真的验证,LESS能在保证链路质量估计的精度上,有效降低50%的能量和带宽消耗。・基于潮间带环境的无线传感器网络由于其特殊的部署环境,导致系统延迟要远高于普通物联网。通过对网络延迟的分析和建模,发现结合节点状态估计的路由算法能够实现系统延迟的优化。基于此,本文首先提出了一个基于隐马尔科夫模型的轻量级节点当前状态估计算法;并进一步提出了基于机器学习的节点未来状态估计方法。结合以上两种估计方法,本文分别提出了低延迟路由算法SADO和PIDO。大规模仿真系统证明,SADO和PIDO分别能为不同低延迟需求的潮间带网络提供可靠的低延迟选路策略。另外,考虑到短距离物联网智能终端设备交互场景(Device to Device,D2D)的普及,本文还探索了智能终端设备的安全认证问题。・在D2D通信问题中,如何在双方设备没有协商秘钥的前提下,实现可靠设备认证是一个亟待解决的安全问题。本论文就这一问题,提出了终端设备安全认证机制――NAuth,以保证通信过程中设备的合法性和一致性。NAuth利用“扬声器-麦克风”系统非线性特性提取设备特征,设计了设备认证机制;同时利用多麦克风系统的TDOA(Time Difference of Arrival)设计了基于位置的验证模型。通过实际系统测试,NAuth能够提供快速的设备安全认证服务,并能防止近距离攻击者的重放攻击和中间人攻击。"
1992,深度学习正则化技术研究及其在驾驶安全风险领域的应用,"根据世界卫生组织提供的统计数据报告显示:全球每年因机动车道路交通事故造成约135万人死亡和5000万人受伤,由于我国巨大的机动车保有量,导致我国年均道路交通事故死亡人数占全球的22.6%,位居世界第一。此外,研究表明:驾驶员行为与道路交通安全风险具有极强的相关性,超过90%的道路交通事故均是由于驾驶员的危险驾驶行为所造成。因此,为进一步地提高我国道路网络的整体安全性和降低机动车交通事故的发生,对个体驾驶员的驾驶行为进行监测、规范和管控是一种有效的解决途径。随着智能交通系统(Intelligent Transportation Systems,ITS)的兴起,可通过智能设备实时获取高分辨率的“人、车、路、环境”等多维数据,这为深入理解和分析驾驶员的驾驶行为与驾驶安全风险提供了海量的基础数据源。此外,深度学习由于其所具有的强大的抽象特征表示性能,可作为深入挖掘海量驾驶行为数据所隐含的时空规律和行为风险的一种强有力的技术手段。本文首先针对深度学习在特征表示和正则化等方面所存在的关键技术问题进行深入研究;并基于改进的深度学习技术,充分融合“人、车、路”等多维海量实时数据以建立驾驶事件的整体视图,从而更全面地挖掘驾驶行为所隐含的时空规律,并以此深入理解相应的驾驶行为模式和其所具有的行为风险性,从更科学更完备的角度去分析驾驶行为与驾驶安全风险之间的关系。本文研究可为改进传统深度学习性能、规范驾驶行为提高道路交通安全性、基于驾驶行为的车险保费厘定以及高级驾驶辅助系统等领域提供理论基础和技术方案。论文的主要研究内容如下:(1)本文提出基于互协方差约束深度自编码的驾驶行为识别方法。首先,针对传统深度自编码(Deep Autoencoder,DAE)通常会产生重复的编码和解码滤波器所造成的特征冗余和过拟合问题,本文引入互协方差函数(Cross-covariance,XCov)正则化滤波器间的相关性,并构建新的目标函数用于消除特征冗余和降低过拟合。进一步地,针对目前的驾驶行为识别方法存在的滑动时间窗口的尺寸选取过大造成模型训练及预测时间较长、特征提取相对主观且很难完整捕捉驾驶行为的时空特征信息的问题,本文构建基于互协方差约束的非负自编码(XCov regularized Nonnegativity-Constrained Autoencoder,XCov-NCAE)的驾驶行为识别方法,该方法能够充分融合多维驾驶行为数据信息,自动提取更具代表性的隐含驾驶行为特征,从而实现对不同风格与模式的驾驶行为的精准刻画。基于大规模自然驾驶行为数据集验证了本文所提方法的有效性。(2)本文提出基于深度相关特征表示结构的驾驶员分心监测方法。首先,针对Dropout所导致的隐含特征信息丢失问题,本文提出一种称为DropMI(Mutual Information-Based Dropout,DropMI)的正则化策略,该策略通过引入互信息(Mutual information,MI)评估隐含层神经单元对目标表示的重要性,基于MI排序分布构建新的二进制掩码矩阵,并设计相应的动态DropMI策略,以提升深度网络的相关特征表示性能。进一步地,针对现有驾驶员分心监测的研究方法所存在的采集指标单一、特征提取主观性较强和缺乏对不同类型分心状态识别等问题,本文构建基于DropMI的深度相关特征表示结构,充分融合多源驾驶员状态数据信息(包括心电、脑电、视觉、驾驶车辆状态等)并实现对驾驶员不同类型分心状态(认知分心、情绪分心和感知运动分心)的精准监测。基于多模态驾驶员分心数据集验证了本文所提方法的有效性。(3)本文提出基于L1/L2非负约束代价敏感深度自编码的驾驶安全风险预测方法。针对现有的驾驶安全风险预测方法所存在的特征提取相对主观未充分考虑驾驶行为和近碰撞事件(Near-crash)的相关因素以及由于碰撞事件(Crash)样本量极少所造成的类别不平衡问题,本文首先建立驾驶安全风险与驾驶关键事件(正常、近碰撞和碰撞)的谱模型以定义不同驾驶关键事件与驾驶安全风险等级的对应关系,并充分融合与驾驶关键事件相关的时空因素,构建深度L1/L2非负约束自编码(L1/L2-Nonnegativity-Constrained Autoencoder,L1/L2-NCAE)用于无监督自动提取不同风险等级驾驶行为的隐含特征;进一步地,为解决类别不平衡,本文提出L1/L2非负约束的Focal Loss分类器(L1/L2-Nonnegativity-Constrained Focal Loss,L1/L2-NCFL),实现对不同等级驾驶安全风险的预测。基于100-CAR自然驾驶研究数据集验证了本文所提方法的有效性。"
1993,基于栈式自编码网络的故障诊断方法研究,"随着分布式控制系统的广泛应用和先进信息技术的实施,为了实时地检测并识别工业过程中的异常状况,数据驱动的故障诊断方法成为多变量过程控制的研究热点之一。然而海量高维度的过程测量信息给传统的故障诊断算法带来极大的计算复杂度和建模复杂度,且存在难以利用高阶量进行在线估计的不足。面对复杂工业过程中的低阶、动态、非线性、多模态以及微小故障等问题,本文结合深度学习与统计分析技术,提出了一系列基于栈式自编码网络的故障诊断算法:(1)将深度学习技术引入工业过程控制中,提出了基于栈式自编码网络的故障诊断技术,通过栈式自编码网络提取并表示工业过程数据中隐含的相关性特征,打破了传统方法针对微小故障检测的瓶颈;(2)从函数逼近角度阐述了栈式自编码网络结构:利用多重的非线性映射与优化的组合实现复杂函数的逼近;初步解释了栈式自编码网络在故障诊断上的可行性;结合加权时间序列保持工业过程的时间相关性;(3)从多项式泰勒展开的角度解析自编码网络,结合泰勒展开的高阶项O(xn)论证栈式自编码网络对细节特征的表示学习能力;鉴于动态过程中的时间最近邻并不一定是其空间最近邻,在不增加建模复杂度的前提下,提出了基于动态重建的栈式自编码网络故障诊断技术,通过样本重建在保持数据可分离性的同时增加类别间的可区分距离;(4)针对传统多元统计分析技术难以利用高阶信息的不足,提出了基于高阶相关性的故障诊断技术,结合栈式自编码网络的多隐层结构建立多级学习框架:堆叠的隐层数越多,提取特征的阶数越高;并给出对应度量指标监控系统运行是否保持在控制范围内;利用正常过程的测量数据进行网络参数训练,避免了类别间的数据不均衡问题;(5)考虑动态过程中在线数据的重要性,提出了基于栈式自编码网络的阈值自适应过程监控技术,通过一个综合的表示框架实现多模态辨识与故障诊断的整合,降低了多模态切换的代价;并基于Sigmoid函数重构进一步分析自编码网络的表示学习能力。基于栈式自编码网络的故障诊断方法可以更细致地反应过程运行状态及潜在的演变轨迹,仿真研究验证了其有效性与可靠性,丰富了数据驱动下故障诊断领域的研究成果,并揭示了进一步研究的必要和可能。"
1994,基于深度学习的网络舆情识别研究,"随着互联网技术的快速发展,网络数据也在以惊人的速度增加,如何对网络舆情实施有效的监管成为迫在眉睫的任务。中文文本情感识别是网络舆情识别的核心内容,也是网络监管的重要内容。文本情感识别是自然语言处理领域的核心研究方向。传统的文本情感识别方法在处理大规模网络数据时表现出一系列的缺点(例如,识别效率低,准确率下降等)。近年来,深度学习的兴起为解决这一问题提供了一种可能的、有效的解决方法。论文针对中文文本情感识别和深度学习进行了较广泛的阅读理解和深入研究。论文提出了基于长短期记忆(Long Short-Term Memory,LSTM)网络模型的中文分词方案以及基于卷积神经网络(Convolutional Neural Network,CNN)的中文文本情感识别方案,并分别采用典型语料集对提出的方案进行了验证。此外,论文基于本文提出的中文文本情感识别方案设计并实现了中文文本情感识别系统,用于实际舆情分析。论文的主要工作及贡献概括如下:1.对中文文本情感识别涉及的文本预处理、文本表示、特征提取及分类等关键技术进行了阐述,分析了目前中文文本情感识别的典型方法及其不足,指出了文本情感识别涉及的关键技术都具有适合深度学习处理的特征。回顾了深度学习的研究现状,介绍了文本特征提取的典型模型,详细分析了论文使用的神经网络语言模型及相关程序。2.针对目前已有的分词算法和程序在处理海量网络文本分词时性能下降的问题,提出了一种基于深度神经网络模型的中文分词方案。该方案利用基于LSTM网络的编码-解码模型训练分词模型,在此基础上,提出了一种基于词向量的修正方法,对采用上述模型的分词结果进行修正,以进一步提升分词性能。对典型微博语料数据集的实验结果表明,所提出中文分词方案的分词性能相对于传统的jieba分词软件的分词性能有了较大提升。3.针对传统基于机器学习的方法在分析大规模文本数据的情感时表现出准确率下降的问题,提出了一种基于深度学习中的卷积神经网络的中文文本情感识别方案。同时,为了改善CNN网络训练的收敛性,设计了一种CNN网络学习速率更新方法,并给出了其直观解释。通过对典型语料集的测试结果表明,论文提出的基于CNN网络的中文文本情感识别方案的准确率相对于传统的机器学习方法的准确率有了提高。4.提出了一种基于doc2vec程序的深度神经网络模型提取文本特征的方法,较好地挖掘了文本隐含意义。此外,为了克服提取的特征数值分布不均衡的问题,进一步设计了一种特征规整化方法。通过对典型语料集的测试结果表明,采用提出的文本特征提取方法在特征维数不高时可以获得满意的CNN网络分析性能。5.基于提出的中文文本情感识别方法,设计并实现了一个文本情感识别系统,用于舆情分析。详细描述了系统整体方案和各组成模块的设计方法。实现结果表明,设计的文本情感识别系统的功能可以基本满足实际情感识别的需求。"
1995,面向复杂调制格式的光性能监测技术研究,"在过去的几十年中,由于网络用户数量和每个用户消耗的流量不断增加,网络流量几乎呈指数增长。为了应对爆炸增长的网络流量,光通信技术发展迅速,例如,采用高级调制格式提高光网络的光谱效率;采用可重构光分插复用器增加网络灵活性,实现动态光网络。在动态光网络中,信号的发射功率、调制格式、比特率以及信道带宽、传输路径等均可调,进一步提高了资源利用率。为了实现动态光网络的智能管理,降低运行成本,保证资源的优化配置,必须能够连续监测各种光性能参数。在众多的光性能参数中,光信噪比是非常重要的指标,因为其直接反映了光链路质量,因此本论文主要就光信噪比监测展开研究。概括全文的研究成果,主要有以下几个方面:1、提出了一种基于归一化自相关函数的OSNR监测技术。该OSNR监测技术基于信号和噪声的归一化自相关函数不同,通过理论分析和实验验证证明带噪信号的归一化自相关函数与OSNR的相关性,从而实现OSNR监测。实验结果表明该方法有超宽的OSNR监测范围,对32 Gbaud PDM-QPSK信号实现了从-10 dB到25 dB误差在±0.5 dB以内的监测,该范围能够涵盖几乎所有的通信应用场景,是目前报道的OSNR监测方案中最宽的,且该监测方案对环境不敏感,重复性好。此外,通过对信号归一化自相关函数的多项式拟合实现了无需信号先验信息的OSNR监测,使得基于归一化自相关函数的OSNR监测方案能够更加实用,通过多项式拟合还扩展了 OSNR监测范围的上限,从25 dB扩展到27 dB,上限的扩展使得该方法能够兼容更高级更复杂的调制格式。2、提出了两种与神经网络相结合的OSNR监测方案。首先,提出了归一化自相关函数与神经网络结合实现调制格式识别和OSNR监测,实验结果表明该方案实现了准确率为100%的28 Gbaud QPSK信号、16QAM信号和PAM4信号的调制格式识别,且对上述三种信号的OSNR监测范围均能达到0到30 dB(误差在±0.5 dB之内)。此外,还提出了低速采样信号频谱与神经网络结合实现多参数光性能监测,包括调制格式识别、比特率识别、OSNR监测等。信号频谱通过低速光电探测器的输出波形傅里叶变换得到,能够有效降低光性能监测的成本。仿真结果表明,该方案实现了QPSK和16QAM信号的调制格式识别,以及25 Gbaud、28 Gbaud和32 Gbaud的信号速率识别,准确率均为100%;对上述所有信号OSNR的监测范围均达到了9.5 dB到27.5 dB(误差在±l dB之内)。3、提出了三种基于干涉法的OSNR监测技术。首先,提出了单延时干涉仪OSNR监测技术的延时选取原则,通过优化干涉仪的延时选取,能够有效减小OSNR监测误差,扩大OSNR监测范围。实验结果表明通过选取最优延时值,对112 Gb/s PDM-QPSK信号能够实现OSNR监测范围从1dB到30 dB(误差在±0.5 dB之内),且实验分析证明了此延时选取原则应用范围较广,能够适用于不同的滤波器带宽、滤波器形状、信号调制格式、信号速率等。其次,提出了基于Lyot-Sagnac干涉仪的OSNR监测技术,在Lyot-Sagnac干涉仪中,干涉信号所经历的路径完全相同,能够有效避免MZI干涉仪的干涉臂分光不均而导致干涉消光比下降的问题;通过调节偏振控制器在Lyot-Sagnac干涉仪中引入了两个不同的延时值从而实现对信号干涉特性的拟合,能够实现无需信号信息的OSNR测量。实验结果表明对200 GHz ITU间隔的4×40 GBaud NRZ-QPSK信号OSNR的监测范围为7.5 dB到25 dB(误差在±0.5 dB之内)。最后,设计制作并实验验证了一种基于并联不对称MZI的硅基可集成OSNR监测器,通过硅基集成实现了OSNR监测的小型化、集成化,具有广阔的应用前景;由于硅基芯片中采用了MMI实现分光,因此该OSNR监测器有很好的带宽特性能够应用于WDM系统中。实验结果表明对4X28 GBaud NRZ-QPSK WDM信号,该OSNR监测器的监测范围为7.7 dB到24.8 dB(误差在±0.5 dB之内)。"
1996,表面润湿对受限空间流体热力学性质影响的密度泛函研究,"许多化工过程涉及流体在微纳受限空间中的吸附与传递。在受限空间中,流体受到壁面较强的微观相互作用,其密度及组成剧烈变化,从而对应的热力学性质如压强、溶解度等与宏观均相流体大相径庭。这种受限效应一方面衍生出丰富的物理、化学现象,另一方面为微纳化工的界面调控提供可行途径。作为一种常见的调控方式,表面润湿改性受到广泛关注和工程应用。然而,表面润湿与受限流体热力学性质之间的定量关系尚不明确,其研究难点在于实验观测手段(特别是微观或介观的手段)的缺乏或不够精密,而传统的化工热力学并不能应用于微纳界面体系研究。本文采用经典密度泛函理论,围绕表面润湿对受限流体压强、溶解度以及溶剂化效应等热力学性质的影响开展研究,为实验现象和界面调控提供微观机制和理论依据。主要内容包括以下几个部分:(1)以安全阀在不同工质下整定压强差异为例,研究了表面润湿改性对受限气体压强的影响。安全阀是化工机械中常用的保护装置,实验发现,蒸汽和空气对同一安全阀的整定压强存在偏差。通过对安全阀阀瓣和阀座之间的密封面建立多尺度模型,并采用经典密度泛函研究蒸汽和空气在微纳孔道中的吸附。结果表明,不同工质在狭缝中产生的吸附压强不同,蒸汽的吸附压强要高于空气;吸附压强的差异造成了蒸汽或空气作为工质时整定压强上的偏差。进一步建立了安全阀整定压强的理论预测模型,理论结果与实验测量定性吻合。基于该模型,研究了表面润湿对整定压强的调控机制,提出对阀瓣和阀座的金属表面进行疏水改性,可有效降低不同工质之间的整定压强偏差。(2)以气体在受限流体中的溶解度为对象,研究了表面润湿改性对受限气体溶解度的影响。受限流体中气体的溶解度与非均相催化、油气开采、相分离、废气处理等化工过程相关,实验研究报道了气体在不同受限溶剂中的“过溶解度”和“低溶解度”现象,然而这两种现象背后的微观机理和调控机制尚不明确。经典密度泛函理论和机器学习的结合,为该现象的研究提供了可行的理论工具。研究发现,孔径大小和孔壁表面润湿性都会对受限气体溶解造成影响,其中溶剂和溶质的分子尺寸之比是关键变量,并给出了表面润湿对气体溶解度影响的二维相图。(3)以受限溶剂中链状分子的构象为目标,研究了表面润湿改性对烷烃分子在受限水溶液中构象的影响。实验发现,烷烃分子在不同的受限溶剂中,呈现直链或螺旋等不同构象。结合经典密度泛函和量子密度泛函,建立了一种多尺度的密度泛函研究方法。研究表明,长链分子以及润湿性较强的孔壁受限环境下,烷烃更易从直链构象变为螺旋构象,且烷烃构象受到链长、孔壁表面润湿性以及孔径大小的影响。理论预测与实验结果有较好的一致性,从而为受限溶剂中链状分子的构象变化提供了微观机理。(4)以原子密度泛函理论为基础,研究了直链型分子密度泛函理论框架的构建。原子密度泛函在处理简单流体时具有速度快、精度高的优势,但其较简单的模型导致在处理结构较为复杂的分子时计算精度降低,而现有的分子密度泛函理论计算直接关联函数的方法较复杂。利用平均球近似构建了分子间作用势与分子取向和分子距离的关系,发展了一种直线型分子直接关联函数的快速计算方法,以一氧化氮分子为例,构建了处理一氧化氮体系的分子密度泛函理论,计算得到的吸附等温线相比于原子密度泛函具有更高的计算精度。"
1997,Android应用软件的安全保护技术研究,"随着移动互联网的高速发展,越来越多的应用软件从PC端转移到了智能终端上。然而,由于Android平台的开源特性和应用市场的多样性,Android应用软件面临着更大的安全风险,针对移动应用在Android平台上的安全保护技术研究,变得至关重要。在移动应用中,涉及到大量的用户敏感数据,其自身的漏洞和缺陷会导致敏感数据的泄露,从而引发安全风险。而应用软件在移动终端面临的另一个挑战,是来自于恶意攻击者的代码攻击。攻击者通过篡改应用代码,注入恶意程序,实现对应用软件的劫持,获取用户的敏感数据。本文在对Android应用软件已有的安全解决方案充分总结的基础上,针对Android应用软件面临的数据安全和代码安全等问题,进行深入的分析,分别提出基于应用层容器、基于框架层加固和基于native层加固等技术的新的安全解决方案,本文的主要研究内容和贡献包括:(1)针对密码误用漏洞的防御技术的研究。针对Android应用软件上存在的大量密码误用漏洞问题,本文在前人研究的基础上,总结了密码误用漏洞的特征和安全风险,设计密码误用漏洞的修复模型,并且在此基础上,提出了一个针对Android应用软件密码误用漏洞的安全容器。通过实验验证,该安全容器增加的额外时间和内存损耗在可以接受的范围内,并且达到了预期的检测和修复效果。(2)基于系统层加固的社交应用缓存泄露保护技术的研究。针对Android社交应用软件的缓存泄露风险,本文进行了威胁建模,对缓存泄露点的安全风险进行了评级,并且在此基础上,设计并实现了基于框架层的缓存泄露检测和加固框架,为社交应用软件的缓存文件安全提供了有效保护。实验结果显示,本框架能够在用户无感知的性能损耗的基础上,有效遏制社交应用缓存文件泄露的威胁,实现了对社交应用缓存文件的安全保护。(3)基于应用层容器的隐私泄露保护技术的研究。针对Android应用软件中存在的隐私泄露问题,本文在对隐私数据的生命周期进行风险分析的基础上,提出了一种基于应用层容器的隐私保护方案。该方案首先对Android系统漏洞进行防御,然后通过动静结合的方式,追踪应用软件中的隐私数据泄露路径,并且根据策略文件通过Java hook和本地代码Hook,对目标应用中的隐私数据进行保护。通过实验验证,隐私数据保护容器可以有效对第三方应用程序中产生和使用的用户隐私数据进行保护,并且性能损耗控制在用户可接受的范围。(4)针对代码加固的安全技术的研究。本文针对Android应用软件中native代码面临的恶意攻击,提出了基于控制流完整性保护和基于代码增强型加密保护的native代码保护框架。该框架通过对被保护应用进行静态分析,提取其native代码的控制流特征,向开发者提供可视化策略配置视图设定关键函数,并根据策略配置生成对应的加固代码,与被保护应用的其他部分一起形成目标应用;目标应用在运行时,通过对关键函数进行动态控制流完整性检查判定是否遭遇上述攻击,从而达到保护目的。实验表明,本加固框架能够通过极小的性能开销,实现对应用软件native代码的安全性保护。综上所述,针对移动应用软件在Android平台上的安全风险,本文从应用软件的密码误用漏洞防御、缓存文件泄露保护、隐私数据泄露保护和代码加固技术研究等四个方面提出了一系列的安全解决方案,使Android应用软件能够在可接受的性能开销下,大大提升自身的安全能力,抵御攻击者的恶意攻击。"
1998,列车运行控制系统硬件安全完整性等级验证方法研究,"列车运行控制系统是用于控制和防护列车运行的典型安全苛求系统,其安全性是否能够满足系统的功能安全要求日益受到用户关注。IEC61508作为铁路领域安全评估主要参考标准,对安全相关系统提出了安全完整性等级(Safety Integrity Level,SIL)下每小时危险侧失效概率(Probability of Dangerous Failure per Hour,PFH)量化计算和硬件SIL验证的要求。在工程实践中,PFH计算模型中涉及的参数并不能完全准确获得,通过“确定”的参数得到的PFH计算结果及SIL评估结果可能导致系统的实际响应与预期情况存在较大偏差,给设备应用带来重大安全隐患。因此,为了提升安全评估结果的可信度,需要分析参数的不确定性对硬件安全完整性等级验证的影响。本文通过对我国铁路信号领域安全评估现状的深入分析,结合列车运行控制系统的架构需求,在查阅国内外相关领域研究文献的基础上,对系统输入参数贡献度计算、共因失效分数定量计算和硬件安全完整性等级验证方法展开研究。研究成果如下:(1)从“PFH计算”和“硬件安全完整性等级影响”两个方面,提出了输入参数的贡献度计算方法。在分析PFH计算模型中输入参数对输出结果影响特性的基础上,采用正交试验和极差分析方法,研究获得了列控系统两种典型冗余结构(2乘2取2结构和3取2结构)下输入参数对PFH计算结果的贡献度排序,并通过创建的多元线性回归机器学习模型,经过多次监督学习获得了线性回归系数,验证了正交试验的贡献度排序结果。同时,进一步研究了输入参数不确定性对列控系统硬件安全完整性等级影响的贡献度计算方法,提出了单一参数不确定对硬件安全完整性等级影响的贡献度计算模型,得出单通道危险侧失效概率、诊断覆盖率和未检测到的共因失效分数为影响硬件安全完整性等级验证结果的关键参数。(2)提出了适用于列控系统高阶冗余结构的共因失效分数定量计算模型。在分析了当前列控系统广泛采用的单一参数(SBF)模型计算共因失效分数的局限性后,将核能领域应用的Alpha参数模型引入到列控系统共因失效分数计算中。首先,通过归纳方法得到了高阶冗余结构下,共因失效导致的危险侧失效概率的计算模型,经过模型推导建立了共因失效因子与PFH计算模型间的耦合关系,并获得了可量化的共因失效分数计算模型。在此基础上,针对当前我国列车运行控制系统缺少共同原因失效数据的情况,在创建的量化共因失效分数计算模型基础上,提出了先验数据缺失条件下基于贝叶斯推断的共因失效分数计算模型,并提供了两种超参数先验数据的计算方法。通过构建的共因失效分数定量计算模型,实现对高阶冗余结构下共因失效导致的危险侧失效概率的量化计算。最后,以列控系统的两种典型冗余结构(2乘2取2结构和3取2结构)为对象,验证了本文所提模型的有效性和优越性。(3)针对列控系统PFH计算模型中输入参数不完全确定问题,提出了蒙特卡洛分析和模糊理论相结合的硬件安全完整性等级验证方法。首先,基于蒙特卡洛分析方法给出了列控系统输入参数为确定分布时的硬件SIL验证方法,并从安全评估结论保守程度出发,提出了硬件SIL验证时各输入参数推荐使用的分布。进而,基于模糊理论创建了列控系统PFH梯形模糊数计算模型,通过模糊运算及模糊测度理论,建立了硬件SIL验证的可能性测度和必然性测度方法,并通过研究PFH模糊数隶属分布,提出了SIL符合性概率计算方法,解决了当输入参数为完全不确定情况下的硬件SIL验证。考虑到输入参数可能存在不完全确定问题,提出了蒙特卡洛采样驱动下的PFH模糊数硬件SIL验证方法,并提供了解模糊化验证、平均模糊数验证两种SIL验证手段。最后,以实例应用说明了提出的硬件安全完整性等级验证方法的有效性,并通过两种验证手段的比较,获得了不同测度方法的保守程度。"
1999,面向个性化搜索的交互式分布估计算法,"个性化搜索问题是一类无法明确定义目标函数、普遍存在、难以求解的定性指标优化问题,传统基于明确定义目标函数的智能优化算法不再适用,融合用户个性化交互信息的交互式进化优化是解决上述问题的可行方法。现有基于交互式进化优化的个性化搜索多将搜索对象视为有限属性的组合,采用简单的数值编码方式,将其转化为组合优化模态,然后采用遗传算法求解。这些方法尚没有拓展其他模式的智能优化机制、未充分利用待搜索对象的领域知识、忽略了个性化搜索对象包含的大量文本信息,以及个性化搜索所特有的隐私保护需求等。针对上述问题,开展本文研究工作,主要内容如下:(1)领域知识驱动的快速交互式分布估计算法:针对个性化搜索中待搜索商品数值型表示所导致搜索空间稀疏的问题,首先,基于用户输入的检索词,确定用户偏好属性已知和未知的空间;利用用户历史搜索信息及其交互搜索对象,采用贝叶斯概率模型,进一步缩减用户可能感兴趣属性组合空间,做为初始搜索空间;采用区间数量化用户交互行为的偏好表示,构建基于RBF神经网络的偏好模型,实现对搜索个体的适应值估计和优势个体选择;给出基于贝叶斯概率模型的交互式分布估计算法。通过在笔记本电脑个性化搜索中与采用多种编码方案的交互式遗传算法、基于支持向量分类及逻辑回归分类的交互式个性化搜索算法相对比,证明了所提算法能有效提高搜索效率,减轻用户疲劳。(2)融合语言模型的交互式分布估计算法:针对现有研究仅利用数值属性描述搜索对象,进一步考虑个性化搜索对象的文本描述特性,从尽可能保留语义信息的角度出发,采用自然语言处理领域的语言模型Doc2Vec,给出文本向量化的编码表示;利用语言模型的词汇表及词频信息,将含有文本的个性化搜索转化为动态文本匹配问题;构建词频的Dirichlet-Multinomial共轭分布概率模型,给出基于优势个体贝叶斯推理的概率模型参数确定策略;将所提概率模型用于分布估计算法中,实现交互式分布估计算法的设计。将所提算法应用于图书和电影搜索中,与采用多种编码方案的交互式遗传算法、基于支持向量分类及逻辑回归分类的交互式个性化搜索算法进行对比,相应实验结果验证了所提方法的有效性。(3)基于协同/内容混合过滤双概率模型的交互式分布估计算法:从个性化推荐的角度,研究内容(2)仍未能摆脱现有个性化搜索研究仅利用内容信息、忽略协同信息的局限,进一步考虑对社会群体搜索信息的充分利用,将个性化推荐中的协同过滤和当前用户搜索信息的内容过滤进行融合,提出基于协同/内容混合过滤双概率模型的交互式分布估计算法。根据相似用户的偏好信息,利用协同过滤实现对当前用户偏好的估计,给出基于偏好估计的初始空间个体采样概率模型;基于用户交互行为,估计用户感兴趣内容,构建分布估计算法概率模型,通过采样生成评价列表;基于用户已评价对象信息,动态更新两个概率模型。将所提双概率模型交互式分布估计算法应用于电影及电视剧个性化搜索中,与基于内容的交互式遗传算法及基于支持向量分类交互式个性化搜索算法、基于协同及含改进策略的基于协同交互式个性化搜索算法进行对比,相应实验结果验证了其帮助用户找到满意解的高效性。(4)隐私保护的含异步模式和时效加权聚合增强联邦学习:作为后续考虑隐私保护交互式分布估计算法的基础,针对已有联邦学习算法存在的高通讯代价问题,给出含异步通讯和时效加权的增强联邦学习算法。首先,针对联邦学习本地模型――深度神经网络的特性,提出异步更新网络参数的通讯机制;然后,为充分利用历史信息,提出聚合操作时效加权策略,以提高聚合算子的性能;最后,将所提算法应用于基于卷积神经网络的手写数据识别,以及基于长短期记忆网络的人体活动识别,通过与FedAVG算法的实验对比验证了所提算法在降低通讯代价、改善模型学习精度方面的有效性。(5)隐私保护的联邦学习-双概率模型交互式分布估计算法:为了满足混合个性化搜索问题中保护用户隐私的需求,基于研究内容(3-4)给出联邦学习-双概率模型交互式分布估计算法。首先,将基于奇异值分解(SVD)的协同过滤嵌入内容(4)的联邦学习框架,提出隐私保护的联邦SVD协同过滤(Federated-SVD);然后,基于Federated-SVD获得群体评价概率模型,以生成初始搜索空间和种群;最后,与内容(3)的交互式分布估计算法融合,实现隐私保护。在隐私保护混合个性化搜索中,通过对比研究(3)中提出的双概率模型交互式分布估计算法、交互式遗传算法,验证了所提算法在兼顾隐私保护同时的高效搜索性能。上述研究内容针对的对象从简单到复杂,融合机器学习策略,设计了面向问题特性的交互式分布估计算法,通过广泛且详实的实验设计,验证了所提各算法在缓解用户疲劳、加快搜索进程、帮助用户找到更多的满意物品以及提供更优秀的综合用户体验各方面都取得令人满意的效果。上述研究成果不但能够丰富和深化已有的交互式进化优化理论,也能够推动上述理论与方法在个性化搜索等定性指标优化问题中的应用,为个性化搜索提供有效解决方法。"
